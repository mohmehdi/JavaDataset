package org.languagetool.tagging.uk;

import java.io.BufferedWriter;
import java.io.IOException;
import java.io.InputStream;
import java.nio.charset.Charset;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.Scanner;
import java.util.Set;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.jetbrains.annotations.Nullable;
import org.languagetool.AnalyzedToken;
import org.languagetool.JLanguageTool;
import org.languagetool.tagging.TaggedWord;
import org.languagetool.tagging.WordTagger;

class CompoundTagger {
  private static final String DEBUG_COMPOUNDS_PROPERTY = "org.languagetool.tagging.uk.UkrainianTagger.debugCompounds";

  private static final String TAG_ANIM = ":anim";
  private static final String NV_TAG = ":nv";
  private static final String COMPB_TAG = ":compb";

  private static final Pattern EXTRA_TAGS = Pattern.compile("(:(v-u|np|ns|bad|slang|rare))+");

  private static final Pattern NOUN_SING_V_ROD_REGEX = Pattern.compile("noun:[mfn]:v_rod.*");
  private static final Pattern NOUN_V_NAZ_REGEX = Pattern.compile("noun:.:v_naz.*");
  private static final Pattern SING_REGEX_F = Pattern.compile(":[mfn]:");
  private static final Pattern O_ADJ_PATTERN = Pattern.compile(".*(Ð¾|[ÑÑÑ]Ðµ)");
  private static final Pattern DASH_PREFIX_LAT_PATTERN = Pattern.compile("[a-zA-Z]{3,}");

  private static final Pattern MNP_NAZ_REGEX = Pattern.compile(".*:[mnp]:v_naz.*");
  private static final Pattern MNP_ZNA_REGEX = Pattern.compile(".*:[mnp]:v_zna.*");
  private static final Pattern MNP_ROD_REGEX = Pattern.compile(".*:[mnp]:v_rod.*");

  private static final String stdNounTag = IPOSTag.noun.getText() + ":.:v_";
  private static final int stdNounTagLen = stdNounTag.length();
  private static final Pattern stdNounTagRegex = Pattern.compile(stdNounTag + ".*");

  private static final Set<String> dashPrefixes;
  private static final Set<String> leftMasterSet;
  private static final Set<String> cityAvenue = new HashSet<>(Arrays.asList("Ñ?ÑÑÑ", "Ð°Ð²ÐµÐ½Ñ", "Ñ?ÑÑÑÑ", "ÑÑÑÐ°Ñ?Ñ?Ðµ"));
  private static final Map<String, Pattern> rightPartsWithLeftTagMap = new HashMap<>();
  private static final Set<String> slaveSet;
  private static final Map<String, List<String>> NUMR_ENDING_MAP;




  private static final String ADJ_TAG_FOR_PO_ADV_MIS = IPOSTag.adj.getText() + ":m:v_mis";
  private static final String ADJ_TAG_FOR_PO_ADV_NAZ = IPOSTag.adj.getText() + ":m:v_naz";

  private static final List<String> LEFT_O_ADJ = Arrays.asList(
      "Ð°Ð²Ñ?ÑÑÐ¾", "Ð°Ð´Ð¸Ð³Ð¾", "Ð°Ð¼ÐµÑÐ¸ÐºÐ°Ð½Ð¾", "Ð°Ð½Ð³Ð»Ð¾", "Ð°ÑÑÐ¾", "ÐµÐºÐ¾", "ÐµÑÐ½Ð¾", "ÑÐ½Ð´Ð¾", "ÑÑ?Ð¿Ð°Ð½Ð¾", "ÐºÐ¸ÑÐ²Ð¾", 
      "Ð¼Ð°ÑÐ¾ÐºÐ°Ð½Ð¾", "ÑÐ³ÑÐ¾"
    );


  static {
    Map<String, List<String>> map2 = new HashMap<>();
    map2.put("Ð¹", Arrays.asList(":m:v_naz", ":m:v_zna"));
    map2.put("Ð³Ð¾", Arrays.asList(":m:v_rod", ":m:v_zna", ":n:v_rod"));
    map2.put("Ð¼Ñ", Arrays.asList(":m:v_dav", ":m:v_mis", ":n:v_dav", ":n:v_mis", ":f:v_zna"));  
    map2.put("Ð¼", Arrays.asList(":m:v_oru", ":n:v_oru", ":p:v_dav"));









    map2.put("ÑÐµ", Arrays.asList(":n:v_naz", ":n:v_zna"));
    map2.put("ÑÑ", Arrays.asList(":p:v_naz", ":p:v_zna"));
    map2.put("Ñ", Arrays.asList(":p:v_rod", ":p:v_zna"));
    NUMR_ENDING_MAP = Collections.unmodifiableMap(map2);
    
    rightPartsWithLeftTagMap.put("Ð±Ð¾", Pattern.compile("(verb(:rev)?:impr|.*pron|noun|adv|excl|part|predic).*"));
    rightPartsWithLeftTagMap.put("Ð½Ð¾", Pattern.compile("(verb(:rev)?:(impr|futr)|excl).*")); 
    rightPartsWithLeftTagMap.put("Ð¾Ñ", Pattern.compile("(.*pron|adv|part).*"));
    rightPartsWithLeftTagMap.put("ÑÐ¾", Pattern.compile("(.*pron|noun|adv|part|conj).*"));
    rightPartsWithLeftTagMap.put("ÑÐ°ÐºÐ¸", Pattern.compile("(verb(:rev)?:(futr|past|pres)|.*pron|noun|part|predic|insert).*")); 
    
    dashPrefixes = loadSet("/uk/dash_prefixes.txt");
    leftMasterSet = loadSet("/uk/dash_left_master.txt");
    slaveSet = loadSet("/uk/dash_slaves.txt");
    
  }

  
  private BufferedWriter compoundUnknownDebugWriter;
  private BufferedWriter compoundTaggedDebugWriter;

  private final WordTagger wordTagger;
  private final Locale conversionLocale;
  private final UkrainianTagger ukrainianTagger;

  
  public CompoundTagger(UkrainianTagger ukrainianTagger, WordTagger wordTagger, Locale conversionLocale) {
    this.ukrainianTagger = ukrainianTagger;
    this.wordTagger = wordTagger;
    this.conversionLocale = conversionLocale;
    
    if( Boolean.valueOf( System.getProperty(DEBUG_COMPOUNDS_PROPERTY) ) ) {
      debugCompounds();
    }
  }
  

  @Nullable
  public List<AnalyzedToken> guessCompoundTag(String word) {
    List<AnalyzedToken> guessedCompoundTags = doGuessCompoundTag(word);
    debug_compound_tagged_write(guessedCompoundTags);
    return guessedCompoundTags;
  }
  
  private List<AnalyzedToken> doGuessCompoundTag(String word) {
    int dashIdx = word.lastIndexOf('-');
    if( dashIdx == 0 || dashIdx == word.length() - 1 )
      return null;

    int firstDashIdx = word.indexOf('-');
    if( dashIdx != firstDashIdx )
      return null;

    String leftWord = word.substring(0, dashIdx);
    String rightWord = word.substring(dashIdx + 1);

    List<TaggedWord> leftWdList = tagBothCases(leftWord);

    if( rightPartsWithLeftTagMap.containsKey(rightWord) ) {
      if( leftWdList.isEmpty() )
        return null;

      Pattern leftTagRegex = rightPartsWithLeftTagMap.get(rightWord);
      
      List<AnalyzedToken> leftAnalyzedTokens = ukrainianTagger.asAnalyzedTokenListForTaggedWordsInternal(leftWord, leftWdList);
      List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(leftAnalyzedTokens.size());
      for (AnalyzedToken analyzedToken : leftAnalyzedTokens) {
        String posTag = analyzedToken.getPOSTag();
        if( posTag != null && leftTagRegex.matcher(posTag).matches() ) {
          newAnalyzedTokens.add(new AnalyzedToken(word, posTag, analyzedToken.getLemma()));
        }
      }
      
      return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
    }

    if( UkrainianTagger.NUMBER.matcher(leftWord).matches() ) {
      List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>();
      
      if( NUMR_ENDING_MAP.containsKey(rightWord) ) {
        List<String> tags = NUMR_ENDING_MAP.get(rightWord);
        for (String tag: tags) {
          
          newAnalyzedTokens.add(new AnalyzedToken(word, IPOSTag.adj.getText()+tag, leftWord + "-" + "Ð¹"));
        }
      }
      else {
        List<TaggedWord> rightWdList = wordTagger.tag(rightWord);
        if( rightWdList.isEmpty() )
          return null;

        List<AnalyzedToken> rightAnalyzedTokens = ukrainianTagger.asAnalyzedTokenListForTaggedWordsInternal(rightWord, rightWdList);

        
        for (AnalyzedToken analyzedToken : rightAnalyzedTokens) {
          if( analyzedToken.getPOSTag().startsWith(IPOSTag.adj.getText()) ) {
            newAnalyzedTokens.add(new AnalyzedToken(word, analyzedToken.getPOSTag(), leftWord + "-" + analyzedToken.getLemma()));
          }
        }
      }
      return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
    }

    if( leftWord.equalsIgnoreCase("Ð¿Ð¾") && rightWord.endsWith("Ñ?ÑÐºÐ¸") ) {
      rightWord += "Ð¹";
    }

    List<TaggedWord> rightWdList = wordTagger.tag(rightWord);
    if( rightWdList.isEmpty() )
      return null;

    List<AnalyzedToken> rightAnalyzedTokens = ukrainianTagger.asAnalyzedTokenListForTaggedWordsInternal(rightWord, rightWdList);

    if( leftWord.equalsIgnoreCase("Ð¿Ð¾") ) {
      if( rightWord.endsWith("Ð¾Ð¼Ñ") ) {
        return poAdvMatch(word, rightAnalyzedTokens, ADJ_TAG_FOR_PO_ADV_MIS);
      }
      else if( rightWord.endsWith("Ñ?ÑÐºÐ¸Ð¹") ) {
        return poAdvMatch(word, rightAnalyzedTokens, ADJ_TAG_FOR_PO_ADV_NAZ);
      }
      return null;
    }

    if( dashPrefixes.contains( leftWord ) || dashPrefixes.contains( leftWord.toLowerCase() ) || DASH_PREFIX_LAT_PATTERN.matcher(leftWord).matches() ) {
      return getNvPrefixNounMatch(word, rightAnalyzedTokens, leftWord);
    }

    if( word.startsWith("Ð¿ÑÐ²-") && Character.isUpperCase(word.charAt(4)) ) {
      List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(rightAnalyzedTokens.size());
      
      for (AnalyzedToken rightAnalyzedToken : rightAnalyzedTokens) {
        String rightPosTag = rightAnalyzedToken.getPOSTag();

        if( rightPosTag == null )
          continue;

        if( NOUN_SING_V_ROD_REGEX.matcher(rightPosTag).matches() ) {
          for(String vid: PosTagHelper.VIDMINKY_MAP.keySet()) {
            if( vid.equals("v_kly") )
              continue;
            String posTag = rightPosTag.replace("v_rod", vid);
            newAnalyzedTokens.add(new AnalyzedToken(word, posTag, word));
          }
        }
      }

      return newAnalyzedTokens;
    }

    if( Character.isUpperCase(leftWord.charAt(0)) && cityAvenue.contains(rightWord) ) {
      if( leftWdList.isEmpty() )
        return null;
      
      List<AnalyzedToken> leftAnalyzedTokens = ukrainianTagger.asAnalyzedTokenListForTaggedWordsInternal(leftWord, leftWdList);
      return cityAvenueMatch(word, leftAnalyzedTokens);
    }

    if( ! leftWdList.isEmpty() ) {
      List<AnalyzedToken> leftAnalyzedTokens = ukrainianTagger.asAnalyzedTokenListForTaggedWordsInternal(leftWord, leftWdList);

      List<AnalyzedToken> tagMatch = tagMatch(word, leftAnalyzedTokens, rightAnalyzedTokens);
      if( tagMatch != null ) {
        return tagMatch;
      }
    }

    if( O_ADJ_PATTERN.matcher(leftWord).matches() ) {
      return oAdjMatch(word, rightAnalyzedTokens, leftWord);
    }

    debug_compound_unknown_write(word);
    
    return null;
  }

  private List<AnalyzedToken> cityAvenueMatch(String word, List<AnalyzedToken> leftAnalyzedTokens) {
    List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(leftAnalyzedTokens.size());
    
    for (AnalyzedToken analyzedToken : leftAnalyzedTokens) {
      String posTag = analyzedToken.getPOSTag();
      if( NOUN_V_NAZ_REGEX.matcher(posTag).matches() ) {
        newAnalyzedTokens.add(new AnalyzedToken(word, posTag.replaceFirst("v_naz", "nv"), word));
      }
    }
    
    return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
  }
  
  private List<AnalyzedToken> tagMatch(String word, List<AnalyzedToken> leftAnalyzedTokens, List<AnalyzedToken> rightAnalyzedTokens) {
    List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>();
    List<AnalyzedToken> newAnalyzedTokensAnimInanim = new ArrayList<>();
    
    String animInanimNotTagged = null;
    
    for (AnalyzedToken leftAnalyzedToken : leftAnalyzedTokens) {
      String leftPosTag = leftAnalyzedToken.getPOSTag();
      
      if( leftPosTag == null )
        continue;

      String leftPosTagExtra = "";
      boolean leftNv = false;

      if( leftPosTag.contains(NV_TAG) ) {
        leftNv = true;
        leftPosTag = leftPosTag.replace(NV_TAG, "");
      }

      Matcher matcher = EXTRA_TAGS.matcher(leftPosTag);
      if( matcher.find() ) {
        leftPosTagExtra += matcher.group();
        leftPosTag = matcher.replaceAll("");
      }
      if( leftPosTag.contains(COMPB_TAG) ) {
        leftPosTag = leftPosTag.replace(COMPB_TAG, "");
      }

      for (AnalyzedToken rightAnalyzedToken : rightAnalyzedTokens) {
        String rightPosTag = rightAnalyzedToken.getPOSTag();
        
        if( rightPosTag == null )
          continue;

        String extraNvTag = "";
        boolean rightNv = false;
        if( rightPosTag.contains(NV_TAG) ) {
          rightNv = true;
          
          if( leftNv ) {
            extraNvTag += NV_TAG;
          }
        }

        Matcher matcherR = EXTRA_TAGS.matcher(rightPosTag);
        if( matcherR.find() ) {
          rightPosTag = matcherR.replaceAll("");
        }
        if( rightPosTag.contains(COMPB_TAG) ) {
          rightPosTag = rightPosTag.replace(COMPB_TAG, "");
        }
        
        if (leftPosTag.equals(rightPosTag) 
            && IPOSTag.startsWith(leftPosTag, IPOSTag.numr, IPOSTag.adv, IPOSTag.adj, IPOSTag.excl, IPOSTag.verb) ) {
          newAnalyzedTokens.add(new AnalyzedToken(word, leftPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
        }
        
        else if ( leftPosTag.startsWith(IPOSTag.noun.getText()) && rightPosTag.startsWith(IPOSTag.noun.getText()) ) {
          String agreedPosTag = getAgreedPosTag(leftPosTag, rightPosTag, leftNv);

          if( agreedPosTag == null 
              && rightPosTag.startsWith("noun:m:v_naz")
              && isMinMax(rightAnalyzedToken.getToken()) ) {
            agreedPosTag = leftPosTag;
          }

          if( agreedPosTag == null && ! isSameAnimStatus(leftPosTag, rightPosTag) ) {

            agreedPosTag = tryAnimInanim(leftPosTag, rightPosTag, leftAnalyzedToken.getLemma(), rightAnalyzedToken.getLemma(), leftNv, rightNv);
            
            if( agreedPosTag == null ) {
              animInanimNotTagged = leftPosTag.contains(":anim") ? "anim-inanim" : "inanim-anim";
            }
            else {
              newAnalyzedTokensAnimInanim.add(new AnalyzedToken(word, agreedPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
              continue;
            }
          }
          
          if( agreedPosTag != null ) {
            newAnalyzedTokens.add(new AnalyzedToken(word, agreedPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
          }
        }
        
        else if ( leftPosTag.startsWith(IPOSTag.numr.getText()) && rightPosTag.startsWith(IPOSTag.numr.getText()) ) {
            String agreedPosTag = getNumAgreedPosTag(leftPosTag, rightPosTag, leftNv);
            if( agreedPosTag != null ) {
              newAnalyzedTokens.add(new AnalyzedToken(word, agreedPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
            }
        }
        
        else if ( IPOSTag.startsWith(leftPosTag, IPOSTag.noun) && IPOSTag.startsWith(rightPosTag, IPOSTag.numr) ) {
          
          String leftGenderConj = PosTagHelper.getGenderConj(leftPosTag);
          if( leftGenderConj != null && leftGenderConj.equals(PosTagHelper.getGenderConj(rightPosTag)) ) {
            newAnalyzedTokens.add(new AnalyzedToken(word, leftPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
          }
          else {
            
            String agreedPosTag = getNumAgreedPosTag(leftPosTag, rightPosTag, leftNv);
            if( agreedPosTag != null ) {
              newAnalyzedTokens.add(new AnalyzedToken(word, agreedPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
            }
          }
        }
        
        else if( leftPosTag.startsWith(IPOSTag.noun.getText()) 
            && IPOSTag.startsWith(rightPosTag, IPOSTag.adj, IPOSTag.numr) ) {
          String leftGenderConj = PosTagHelper.getGenderConj(leftPosTag);
          if( leftGenderConj != null && leftGenderConj.equals(PosTagHelper.getGenderConj(rightPosTag)) ) {
            newAnalyzedTokens.add(new AnalyzedToken(word, leftPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
          }
        }
      }
    }
    
    if( newAnalyzedTokens.isEmpty() ) {
      newAnalyzedTokens = newAnalyzedTokensAnimInanim;
    }

    if( animInanimNotTagged != null && newAnalyzedTokens.isEmpty() ) {
      debug_compound_unknown_write(word + " " + animInanimNotTagged);
    }
    
    return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
  }

  
  private String getNumAgreedPosTag(String leftPosTag, String rightPosTag, boolean leftNv) {
    String agreedPosTag = null;
    
    if( leftPosTag.contains(":p:") && SING_REGEX_F.matcher(rightPosTag).find()
        || SING_REGEX_F.matcher(leftPosTag).find() && rightPosTag.contains(":p:")) {
      String leftConj = PosTagHelper.getConj(leftPosTag);
      if( leftConj != null && leftConj.equals(PosTagHelper.getConj(rightPosTag)) ) {
        agreedPosTag = leftPosTag;
      }
    }
    return agreedPosTag;
  }

  @Nullable
  private String getAgreedPosTag(String leftPosTag, String rightPosTag, boolean leftNv) {
    if( isPlural(leftPosTag) && ! isPlural(rightPosTag)
        || ! isPlural(leftPosTag) && isPlural(rightPosTag) )
      return null;
    
    if( ! isSameAnimStatus(leftPosTag, rightPosTag) )
      return null;
    
    if( stdNounTagRegex.matcher(leftPosTag).matches() ) {
      if (stdNounTagRegex.matcher(rightPosTag).matches()) {
        String substring1 = leftPosTag.substring(stdNounTagLen, stdNounTagLen + 3);
        String substring2 = rightPosTag.substring(stdNounTagLen, stdNounTagLen + 3);
        if( substring1.equals(substring2) ) {
          if( leftNv )
            return rightPosTag;

          return leftPosTag;
        }
      }
    }

    return null;
  }

  private static boolean isMinMax(String rightToken) {
    return rightToken.equals("Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼")
        || rightToken.equals("Ð¼ÑÐ½ÑÐ¼ÑÐ¼");
  }

  private String tryAnimInanim(String leftPosTag, String rightPosTag, String leftLemma, String rightLemma, boolean leftNv, boolean rightNv) {
    String agreedPosTag = null;
    
    
    if( leftMasterSet.contains(leftLemma) ) {
      if( leftPosTag.contains(TAG_ANIM) ) {
        rightPosTag = rightPosTag.concat(TAG_ANIM);
      }
      else {
        rightPosTag = rightPosTag.replace(TAG_ANIM, "");
      }
      
      agreedPosTag = getAgreedPosTag(leftPosTag, rightPosTag, leftNv);
      
      if( agreedPosTag == null ) {
        if (! leftPosTag.contains(TAG_ANIM)) {
          if (MNP_ZNA_REGEX.matcher(leftPosTag).matches() && MNP_NAZ_REGEX.matcher(rightPosTag).matches()
              && ! leftNv && ! rightNv ) {
            agreedPosTag = leftPosTag;
          }
        }
        else {
          if (MNP_ZNA_REGEX.matcher(leftPosTag).matches() && MNP_ROD_REGEX.matcher(rightPosTag).matches()
              && ! leftNv && ! rightNv ) {
            agreedPosTag = leftPosTag;
          }
        }
      }
      
    }
    
    else if ( slaveSet.contains(rightLemma) ) {
      rightPosTag = rightPosTag.replace(":anim", "");
      agreedPosTag = getAgreedPosTag(leftPosTag, rightPosTag, false);
      if( agreedPosTag == null ) {
        if (! leftPosTag.contains(TAG_ANIM)) {
          if (MNP_ZNA_REGEX.matcher(leftPosTag).matches() && MNP_NAZ_REGEX.matcher(rightPosTag).matches()
              && PosTagHelper.getNum(leftPosTag).equals(PosTagHelper.getNum(rightPosTag))
              && ! leftNv && ! rightNv ) {
            agreedPosTag = leftPosTag;
          }
        }
      }
    }
    
    else if ( slaveSet.contains(leftLemma) ) {
      leftPosTag = leftPosTag.replace(":anim", "");
      agreedPosTag = getAgreedPosTag(rightPosTag, leftPosTag, false);
      if( agreedPosTag == null ) {
        if (! rightPosTag.contains(TAG_ANIM)) {
          if (MNP_ZNA_REGEX.matcher(rightPosTag).matches() && MNP_NAZ_REGEX.matcher(leftPosTag).matches()
              && PosTagHelper.getNum(leftPosTag).equals(PosTagHelper.getNum(rightPosTag))
              && ! leftNv && ! rightNv ) {
            agreedPosTag = rightPosTag;
          }
        }
      }
    }
    
    
    
    return agreedPosTag;
  }

  private static boolean isSameAnimStatus(String leftPosTag, String rightPosTag) {
    return leftPosTag.contains(TAG_ANIM) && rightPosTag.contains(TAG_ANIM)
        || ! leftPosTag.contains(TAG_ANIM) && ! rightPosTag.contains(TAG_ANIM);
  }

  private static boolean isPlural(String posTag) {
    return posTag.startsWith("noun:p:");
  }

  private List<AnalyzedToken> oAdjMatch(String word, List<AnalyzedToken> analyzedTokens, String leftWord) {
    List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(analyzedTokens.size());

    String leftBase = leftWord.substring(0, leftWord.length()-1);
    if( ! LEFT_O_ADJ.contains(leftWord.toLowerCase(conversionLocale))
        && tagBothCases(leftWord).isEmpty()            
        && tagBothCases(oToYj(leftWord)).isEmpty()  
        && tagBothCases(leftBase).isEmpty()         
        && tagBothCases(leftBase + "Ð°").isEmpty() ) 
      return null;
    
    for (AnalyzedToken analyzedToken : analyzedTokens) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag.startsWith( IPOSTag.adj.getText() ) ) {
        newAnalyzedTokens.add(new AnalyzedToken(word, posTag, leftWord + "-" + analyzedToken.getLemma()));
      }
    }
    
    return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
  }

  private static String oToYj(String leftWord) {
    return leftWord.endsWith("ÑÐ¾") 
        ? leftWord.substring(0, leftWord.length()-2) + "ÑÐ¹" 
        : leftWord.substring(0,  leftWord.length()-1) + "Ð¸Ð¹";
  }

  private List<AnalyzedToken> getNvPrefixNounMatch(String word, List<AnalyzedToken> analyzedTokens, String leftWord) {
    List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(analyzedTokens.size());
    
    for (AnalyzedToken analyzedToken : analyzedTokens) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag.startsWith( IPOSTag.noun.getText() ) ) {
        newAnalyzedTokens.add(new AnalyzedToken(word, posTag, leftWord + "-" + analyzedToken.getLemma()));
      }
    }
    
    return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
  }

  @Nullable
  private List<AnalyzedToken> poAdvMatch(String word, List<AnalyzedToken> analyzedTokens, String adjTag) {
    
    for (AnalyzedToken analyzedToken : analyzedTokens) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag.startsWith( adjTag ) ) {
        return Arrays.asList(new AnalyzedToken(word, IPOSTag.adv.getText(), word));
      }
    }
    
    return null;
  }


  private String capitalize(String word) {
    return word.substring(0, 1).toUpperCase(conversionLocale) + word.substring(1, word.length());
  }

  private List<TaggedWord> tagBothCases(String leftWord) {
    List<TaggedWord> leftWdList = wordTagger.tag(leftWord);
    String leftLowerCase = leftWord.toLowerCase(conversionLocale);
    if( ! leftWord.equals(leftLowerCase)) {
      leftWdList.addAll(wordTagger.tag(leftLowerCase));
    }
    else {
      String leftUpperCase = capitalize(leftWord);
      if( ! leftWord.equals(leftUpperCase)) {
        leftWdList.addAll(wordTagger.tag(leftUpperCase));
      }
    }

    return leftWdList;
  }

  private static Set<String> loadSet(String path) {
    Set<String> result = new HashSet<>();
    try (InputStream is = JLanguageTool.getDataBroker().getFromResourceDirAsStream(path);
         Scanner scanner = new Scanner(is,"UTF-8")) {
      while (scanner.hasNextLine()) {
        String line = scanner.nextLine();
        result.add(line);
      }
      return result;
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

  
  

  private void debugCompounds() {
    try {
      Path unknownFile = Paths.get("compounds-unknown.txt");
      Files.deleteIfExists(unknownFile);
      unknownFile = Files.createFile(unknownFile);
      compoundUnknownDebugWriter = Files.newBufferedWriter(unknownFile, Charset.defaultCharset());

      Path taggedFile = Paths.get("compounds-tagged.txt");
      Files.deleteIfExists(taggedFile);
      taggedFile = Files.createFile(taggedFile);
      compoundTaggedDebugWriter = Files.newBufferedWriter(taggedFile, Charset.defaultCharset());





    } catch (IOException ex) {
      throw new RuntimeException(ex);
    }
  }

  private void debug_compound_tagged_write(List<AnalyzedToken> guessedCompoundTags) {
    if( compoundTaggedDebugWriter == null || guessedCompoundTags == null )
      return;

    debug_tagged_write(guessedCompoundTags, compoundTaggedDebugWriter);
  }

  private void debug_compound_unknown_write(String word) {
    if( compoundUnknownDebugWriter == null )
      return;
    
    try {
      compoundUnknownDebugWriter.append(word);
      compoundUnknownDebugWriter.newLine();
      compoundUnknownDebugWriter.flush();
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }
  
  private void debug_tagged_write(List<AnalyzedToken> analyzedTokens, BufferedWriter writer) {
    if( analyzedTokens.get(0).getLemma() == null || analyzedTokens.get(0).getToken().trim().isEmpty() )
          return;

    try {
      String prevToken = "";
      String prevLemma = "";
      for (AnalyzedToken analyzedToken : analyzedTokens) {
        String token = analyzedToken.getToken();
        
        boolean firstTag = false;
        if (! prevToken.equals(token)) {
          if( prevToken.length() > 0 ) {
            writer.append(";  ");
            prevLemma = "";
          }
          writer.append(token).append(" ");
          prevToken = token;
          firstTag = true;
        }
        
        String lemma = analyzedToken.getLemma();

        if (! prevLemma.equals(lemma)) {
          if( prevLemma.length() > 0 ) {
            writer.append(", ");
          }
          writer.append(lemma); 
          prevLemma = lemma;
          firstTag = true;
        }

        writer.append(firstTag ? " " : "|").append(analyzedToken.getPOSTag());
        firstTag = false;
      }
      writer.newLine();
      writer.flush();
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

}
<code block>
package org.languagetool.tagging.uk;

import java.util.Collections;
import java.util.LinkedHashMap;
import java.util.Map;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.jetbrains.annotations.Nullable;
import org.languagetool.AnalyzedToken;
import org.languagetool.AnalyzedTokenReadings;


public class PosTagHelper {
  private static final Pattern NUM_REGEX = Pattern.compile("(noun|numr|adj|adjp.*):(.):v_.*");
  private static final Pattern CONJ_REGEX = Pattern.compile("(noun|numr|adj|adjp.*):[mfnp]:(v_...).*");
  private static final Pattern GENDER_REGEX = NUM_REGEX;
  private static final Pattern GENDER_CONJ_REGEX = Pattern.compile("(noun|adj|numr|adjp.*):(.:v_...).*");

  public static final Map<String, String> VIDMINKY_MAP;

  static {
    Map<String, String> map = new LinkedHashMap<>();
    map.put("v_naz", "Ð½Ð°Ð·Ð¸Ð²Ð½Ð¸Ð¹");
    map.put("v_rod", "ÑÐ¾Ð´Ð¾Ð²Ð¸Ð¹");
    map.put("v_dav", "Ð´Ð°Ð²Ð°Ð»ÑÐ½Ð¸Ð¹");
    map.put("v_zna", "Ð·Ð½Ð°ÑÑÐ´Ð½Ð¸Ð¹");
    map.put("v_oru", "Ð¾ÑÑÐ´Ð½Ð¸Ð¹");
    map.put("v_mis", "Ð¼ÑÑ?ÑÐµÐ²Ð¸Ð¹");
    map.put("v_kly", "ÐºÐ»Ð¸ÑÐ½Ð¸Ð¹");
    VIDMINKY_MAP = Collections.unmodifiableMap(map);
  }
  
  private PosTagHelper() {
  }
  
  @Nullable
  public static String getGender(String posTag) {
    Matcher pos4matcher = GENDER_REGEX.matcher(posTag);
    if( pos4matcher.matches() ) {
      return pos4matcher.group(2);
    }


    return null;
  }

  @Nullable
  public static String getNum(String posTag) {
    Matcher pos4matcher = NUM_REGEX.matcher(posTag);
    if( pos4matcher.matches() ) {
      String group = pos4matcher.group(2);
      if( ! group.equals("p") ) {
        group = "s";
      }
      return group;
    }
  

    return null;
  }

  @Nullable
  public static String getConj(String posTag) {
    Matcher pos4matcher = CONJ_REGEX.matcher(posTag);
    if( pos4matcher.matches() )
      return pos4matcher.group(2);
  

    return null;
  }

  @Nullable
  public static String getGenderConj(String posTag) {
    Matcher pos4matcher = GENDER_CONJ_REGEX.matcher(posTag);
    if( pos4matcher.matches() )
      return pos4matcher.group(2);


    return null;
  }

  public static boolean hasPosTag(AnalyzedTokenReadings analyzedTokenReadings, String posTagRegex) {
    for(AnalyzedToken analyzedToken: analyzedTokenReadings) {
      if( hasPosTag(analyzedToken, posTagRegex) )
        return true;
    }
    return false;
  }

  public static boolean hasPosTag(AnalyzedToken analyzedToken, String posTagRegex) {
    String posTag = analyzedToken.getPOSTag();
    return posTag != null && posTag.matches(posTagRegex);
  }














}

<code block>

package org.languagetool.tagging.uk;

import java.util.ArrayList;
import java.util.List;
import java.util.Locale;
import java.util.regex.Pattern;

import org.languagetool.AnalyzedToken;
import org.languagetool.tagging.BaseTagger;
import org.languagetool.tagging.TaggedWord;
import org.languagetool.tagging.WordTagger;


public class UkrainianTagger extends BaseTagger {
  
  
  static final Pattern NUMBER = Pattern.compile("[+-Â±]?[â¬â´\\$]?[0-9]+(,[0-9]+)?([-ââ][0-9]+(,[0-9]+)?)?(%|Â°Ð¡?)?|(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})");
  private static final Pattern DATE = Pattern.compile("[\\d]{2}\\.[\\d]{2}\\.[\\d]{4}");
  private static final Pattern TIME = Pattern.compile("([01]?[0-9]|2[0-3])[.:][0-5][0-9]");
  
  private final CompoundTagger compoundTagger = new CompoundTagger(this, wordTagger, conversionLocale);


  @Override
  public String getManualAdditionsFileName() {
    return "/uk/added.txt";
  }

  public UkrainianTagger() {
    super("/uk/ukrainian.dict", new Locale("uk", "UA"), false);
  }

  @Override
  public List<AnalyzedToken> additionalTags(String word, WordTagger wordTagger) {
    if ( NUMBER.matcher(word).matches() ) {
      List<AnalyzedToken> additionalTaggedTokens = new ArrayList<>();
      additionalTaggedTokens.add(new AnalyzedToken(word, IPOSTag.number.getText(), word));
      return additionalTaggedTokens;
    }

    if ( TIME.matcher(word).matches() ) {
      List<AnalyzedToken> additionalTaggedTokens = new ArrayList<>();
      additionalTaggedTokens.add(new AnalyzedToken(word, IPOSTag.time.getText(), word));
      return additionalTaggedTokens;
    }

    if ( DATE.matcher(word).matches() ) {
      List<AnalyzedToken> additionalTaggedTokens = new ArrayList<>();
      additionalTaggedTokens.add(new AnalyzedToken(word, IPOSTag.date.getText(), word));
      return additionalTaggedTokens;
    }
    
    if ( word.contains("-") ) {
      List<AnalyzedToken> guessedCompoundTags = compoundTagger.guessCompoundTag(word);
      return guessedCompoundTags;
    }
    
    return null;
  }

  protected List<AnalyzedToken> getAnalyzedTokens(String word) {
    List<AnalyzedToken> tkns = super.getAnalyzedTokens(word);

    if( tkns.get(0).getPOSTag() == null ) {
      if( (word.indexOf('\u2013') != -1) 
           && word.matches(".*[Ð°-Ñ?ÑÑÑÒ][\u2013][Ð°-Ñ?ÑÑÑÒ].*")) {
        String newWord = word.replace('\u2013', '-');
        
        List<AnalyzedToken> newTokens = super.getAnalyzedTokens(newWord);
        
        for (int i = 0; i < newTokens.size(); i++) {
          AnalyzedToken analyzedToken = newTokens.get(i);
          if( newWord.equals(analyzedToken.getToken()) ) {
            String lemma = analyzedToken.getLemma();
            if( lemma != null ) {
              lemma = lemma.replace('-', '\u2013');
            }
            AnalyzedToken newToken = new AnalyzedToken(word, analyzedToken.getPOSTag(), lemma);
            newTokens.set(i, newToken);
          }
        }
        
        tkns = newTokens;
      }
    }
    



    
    return tkns;
  }

  List<AnalyzedToken> asAnalyzedTokenListForTaggedWordsInternal(String word, List<TaggedWord> taggedWords) {
    return super.asAnalyzedTokenListForTaggedWords(word, taggedWords);
  }
  
}

<code block>

package org.languagetool.tokenizers.uk;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map.Entry;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.StringTokenizer;

import org.languagetool.tokenizers.Tokenizer;


public class UkrainianWordTokenizer implements Tokenizer {
  private static final String SPLIT_CHARS = "\u0020\u00A0\u115f\u1160\u1680" 
        + "\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007" 
        + "\u2008\u2009\u200A\u200B\u200c\u200d\u200e\u200f"
        + "\u2028\u2029\u202a\u202b\u202c\u202d\u202e\u202f"
        + "\u205F\u2060\u2061\u2062\u2063\u206A\u206b\u206c\u206d"
        + "\u206E\u206F\u3000\u3164\ufeff\uffa0\ufff9\ufffa\ufffb" 
        + ",.;()[]{}<>!?:/|\\\"Â«Â»ââ?â`Â´âââ²â¦Â¿Â¡\t\n\r\uE100\uE101\uE102\uE110";

  
  private static final Pattern DECIMAL_COMMA_PATTERN = Pattern.compile("([\\d]),([\\d])", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char DECIMAL_COMMA_SUBST = '\uE001'; 
  


  
  private static final Pattern DOTTED_NUMBERS_PATTERN = Pattern.compile("([\\d])\\.([\\d])", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char NUMBER_DOT_SUBST = '\uE002';
  
  private static final Pattern COLON_NUMBERS_PATTERN = Pattern.compile("([\\d]):([\\d])", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char COLON_DOT_SUBST = '\uE003';
  
  private static final Pattern DATE_PATTERN = Pattern.compile("([\\d]{2})\\.([\\d]{2})\\.([\\d]{4})|([\\d]{4})\\.([\\d]{2})\\.([\\d]{2})|([\\d]{4})-([\\d]{2})-([\\d]{2})", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char DATE_DOT_SUBST = '\uE004'; 
  
  private static final Pattern BRACE_IN_WORD_PATTERN = Pattern.compile("([Ð°-Ñ?ÑÑÑÒ'])\\(([Ð°-Ñ?ÑÑÑÒ']+)\\)", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char LEFT_BRACE_SUBST = '\uE005';
  private static final char RIGHT_BRACE_SUBST = '\uE006';
  
  
  private static final Pattern ABBR_DOT_PATTERN = Pattern.compile("(ÑÐ¸Ñ?)\\.([ \u00A0]+[Ð°-Ñ?ÑÑÑÒ])");
  private static final Pattern ABBR_DOT_PATTERN1 = Pattern.compile("([^Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?'-]Ð»Ð°Ñ)\\.([ \u00A0]+[a-zA-Z])");
  private static final Pattern ABBR_DOT_PATTERN2 = Pattern.compile("([Ð?Ð°]ÐºÐ°Ð´|[ÐÐ¿]ÑÐ¾Ñ|[ÐÐ´]Ð¾Ñ|[Ð?Ð°]Ñ?Ð¸Ñ?Ñ|Ð²ÑÐ»|Ð¾|Ñ|ÑÐ¼)\\.([\\s\u00A0]+[Ð?-Ð¯ÐÐÐÒ?])");
  
  private static final Pattern ABBR_DOT_PATTERN5 = Pattern.compile("((?:[0-9]|ÐºÐ²\\.?|ÐºÑÐ±\\.?)[\\s\u00A0]+[Ñ?Ð¼])\\.");
  private static final Pattern ABBR_DOT_PATTERN3 = Pattern.compile("(Ñ?)\\.(-Ð³)\\.");
  private static final Pattern ABBR_DOT_PATTERN4 = Pattern.compile("([^Ð°-Ñ?ÑÑÑÒ'-][Ð²ÐµÐºÐ½Ð¿ÑÑ?ÑÑÑ]{1,2})\\.([ÐµÐºÐ¼Ð½Ð¿ÑÑ?ÑÑ]{1,2})\\.");

  private static final Pattern ABBR_DOT_PATTERN6 = Pattern.compile("([^Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?'-]((ÑÐ°|Ð¹) ÑÐ½|Ð°Ð¼ÐµÑ|Ð°Ð½Ð³Ð»|Ð±Ð»(Ð¸Ð·ÑÐº)?|Ð²ÑÑÐ¼|Ð³ÑÐµÑ(ÑÐº)|Ð´Ð¸Ð²|Ð´Ð¾Ð»|Ð´Ð¾Ñ?Ð»|Ð´Ð¾Ñ|Ðµ|ÐµÐ»|Ð¶ÑÐ½|Ð·Ð°Ñ?Ñ|Ð·Ð²|ÑÐ¼|ÑÐ²Ñ|ÑÑ?Ð¿|ÑÑÐ°Ð»|Ðº|ÐºÐ²|[1-9]-ÐºÑÐ¼Ð½|ÐºÑÐ¼Ð½|ÐºÐ»|ÐºÐ¾Ð¿|Ð¼|Ð½|Ð½Ð°Ð¿Ñ|Ð¾Ð±Ð»|Ð¿|Ð¿ÐµÐ½|Ð¿ÐµÑÐµÐºÐ»|Ð¿Ð»|Ð¿Ð¾Ñ|Ð¿Ð¾Ñ|Ð¿ÑÐ¸Ð±Ð»|Ð¿ÑÐ¾Ð²|Ð¿ÑÐ¾Ñ?Ð¿|Ñ|[Ð Ñ]ÐµÐ´|[Ð Ñ]ÐµÐ¶|ÑÑ|ÑÑ|ÑÑÐ±|Ñ?|[Ð¡Ñ?]Ð²|Ñ?Ð¾Ñ|Ñ?Ð¿ÑÐ²Ð°Ð²Ñ|Ñ?Ñ|Ñ?ÑÐ¾Ð»|Ñ?ÑÐ¾Ñ|ÑÐ°Ð±Ð»|ÑÐµÐ»|ÑÐºÑ|ÑÑÐ»Ð¾Ð»|ÑÑ|ÑÑÐ°Ð½Ñ|Ñ|ÑÐ°Ð¹Ð½|ÑÐ¾Ð»|Ñ|ÑÑ))\\.");
  private static final Pattern ABBR_DOT_PATTERN7 = Pattern.compile("([ÑÐ¹][ \u00A0]+Ñ)\\.([ \u00A0]*(Ð´|Ð¿|ÑÐ½))\\.");
  private static final char ABBR_DOT_SUBST = '\uE007';
  private static final String BREAKING_PLACEHOLDER = "\uE110";
  
  private static final String ELLIPSIS = "...";
  private static final String ELLIPSIS_SUBST = "\uE100";
  private static final String ELLIPSIS2 = "!..";
  private static final String ELLIPSIS2_SUBST = "\uE101";
  private static final String ELLIPSIS3 = "?..";
  private static final String ELLIPSIS3_SUBST = "\uE102";
  
  private static final Pattern URL_PATTERN = Pattern.compile("^(https?|ftp):
  private static final int URL_START_REPLACE_CHAR = 0xE300;


  public UkrainianWordTokenizer() {
  }

  @Override
  public List<String> tokenize(String text) {
    HashMap<String, String> urls = new HashMap<String, String>();

    text = cleanup(text);
    
    if( text.contains(",") ) {
      text = DECIMAL_COMMA_PATTERN.matcher(text).replaceAll("$1" + DECIMAL_COMMA_SUBST + "$2");
    }

    
    if( text.contains("tp") ) { 
      Matcher matcher = URL_PATTERN.matcher(text);
      int urlReplaceChar = URL_START_REPLACE_CHAR;
      
      while( matcher.find() ) {
        String urlGroup = matcher.group();
        String replaceChar = String.valueOf((char)urlReplaceChar);
        urls.put(replaceChar, urlGroup);
        text = matcher.replaceAll(replaceChar);
        urlReplaceChar++;
      }
    }
    



    if( text.contains(ELLIPSIS) ) {
      text = text.replace(ELLIPSIS, ELLIPSIS_SUBST);
    }
    if( text.contains(ELLIPSIS2) ) {
      text = text.replace(ELLIPSIS2, ELLIPSIS2_SUBST);
    }
    if( text.contains(ELLIPSIS3) ) {
      text = text.replace(ELLIPSIS3, ELLIPSIS3_SUBST);
    }

    if( text.contains(".") ) {
    

      text = DATE_PATTERN.matcher(text).replaceAll("$1" + DATE_DOT_SUBST + "$2" + DATE_DOT_SUBST + "$3");
      text = DOTTED_NUMBERS_PATTERN.matcher(text).replaceAll("$1" + NUMBER_DOT_SUBST + "$2");


      text = ABBR_DOT_PATTERN4.matcher(text).replaceAll("$1" + ABBR_DOT_SUBST + BREAKING_PLACEHOLDER + "$2" + ABBR_DOT_SUBST);
      text = ABBR_DOT_PATTERN.matcher(text).replaceAll("$1" + ABBR_DOT_SUBST + "$2");
      text = ABBR_DOT_PATTERN1.matcher(text).replaceAll("$1" + ABBR_DOT_SUBST + "$2");
      text = ABBR_DOT_PATTERN2.matcher(text).replaceAll("$1" + ABBR_DOT_SUBST + "$2");
      text = ABBR_DOT_PATTERN5.matcher(text).replaceAll("$1" + BREAKING_PLACEHOLDER + ABBR_DOT_SUBST);
      text = ABBR_DOT_PATTERN3.matcher(text).replaceAll("$1" + ABBR_DOT_SUBST + "$2" + ABBR_DOT_SUBST);

      text = ABBR_DOT_PATTERN6.matcher(text).replaceAll("$1" + ABBR_DOT_SUBST);
      text = ABBR_DOT_PATTERN7.matcher(text).replaceAll("$1" + ABBR_DOT_SUBST + "$2" + ABBR_DOT_SUBST);
    }

    if( text.contains(":") ) {
      text = COLON_NUMBERS_PATTERN.matcher(text).replaceAll("$1" + COLON_DOT_SUBST + "$2");
    }

    if( text.contains("(") ) {
      text = BRACE_IN_WORD_PATTERN.matcher(text).replaceAll("$1" + LEFT_BRACE_SUBST + "$2" + RIGHT_BRACE_SUBST);
    }




    
    List<String> tokenList = new ArrayList<>();
    StringTokenizer st = new StringTokenizer(text, SPLIT_CHARS, true);

    while (st.hasMoreElements()) {
      String token = st.nextToken();
      
      if( token.equals(BREAKING_PLACEHOLDER) )
        continue;
      
      token = token.replace(DECIMAL_COMMA_SUBST, ',');
      
      
      token = token.replace(DATE_DOT_SUBST, '.');
      token = token.replace(NUMBER_DOT_SUBST, '.');
      token = token.replace(ABBR_DOT_SUBST, '.');
      
      token = token.replace(COLON_DOT_SUBST, ':');
      token = token.replace(LEFT_BRACE_SUBST, '(');
      token = token.replace(RIGHT_BRACE_SUBST, ')');
      token = token.replaceAll(ELLIPSIS_SUBST, ELLIPSIS);
      token = token.replaceAll(ELLIPSIS2_SUBST, ELLIPSIS2);
      token = token.replaceAll(ELLIPSIS3_SUBST, ELLIPSIS3);


      if( ! urls.isEmpty() ) {
        for(Entry<String, String> entry : urls.entrySet()) {
          token = token.replace(entry.getKey(), entry.getValue());
        }
      }
      
      tokenList.add( token );
    }

    return tokenList;
  }

  private static String cleanup(String text) {
    text = text.replace('â', '\'').replace('Ê¼', '\'');









    return text;
  }

}

<code block>
package org.languagetool.rules.uk;

import java.util.*;

import org.languagetool.AnalyzedToken;
import org.languagetool.AnalyzedTokenReadings;
import org.languagetool.JLanguageTool;
import org.languagetool.Language;
import org.languagetool.rules.RuleMatch;
import org.languagetool.rules.WordRepeatRule;
import org.languagetool.tagging.uk.IPOSTag;
import org.languagetool.tagging.uk.PosTagHelper;


public class UkrainianWordRepeatRule extends WordRepeatRule {
  private static final HashSet<String> REPEAT_ALLOWED_SET = new HashSet<>(
      Arrays.asList("ÑÐ¾", "Ð½Ñ", "Ð¾Ð´Ð½Ðµ", "Ð¾Ñ?Ñ", "Ñ?Ñ.")
  );
  private static final HashSet<String> REPEAT_ALLOWED_CAPS_SET = new HashSet<>(
      Arrays.asList("ÐÐ Ð", "ÐÐ¶ÐµÐ¹", "ÐÑ")
  );

  public UkrainianWordRepeatRule(ResourceBundle messages, Language language) {
    super(messages, language);
  }

  @Override
  public String getId() {
    return "UKRAINIAN_WORD_REPEAT_RULE";
  }

  @Override
  public boolean ignore(AnalyzedTokenReadings[] tokens, int position) {
    AnalyzedTokenReadings analyzedTokenReadings = tokens[position];
    String token = analyzedTokenReadings.getToken();
    
    
    if( position > 1 && token.equals("Ð´Ð¾Ð±ÑÐ°")
        && tokens[position-2].getToken().equalsIgnoreCase("Ð²ÑÐ´") )
      return true;
    
    if( REPEAT_ALLOWED_SET.contains(token.toLowerCase()) )
      return true;

    if( REPEAT_ALLOWED_CAPS_SET.contains(token) )
      return true;
    
    if( PosTagHelper.hasPosTag(analyzedTokenReadings, "date|time|number") )
      return true;
    
    for(AnalyzedToken analyzedToken: analyzedTokenReadings.getReadings()) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag != null ) {
        if ( ! isInitial(analyzedToken, tokens, position)

            && ! posTag.equals(JLanguageTool.SENTENCE_END_TAGNAME) )
          return false;
      }
    }
    return true;
  }

  private boolean isInitial(AnalyzedToken analyzedToken, AnalyzedTokenReadings[] tokens, int position) {
    return analyzedToken.getPOSTag().contains(IPOSTag.abbr.getText())
        || (analyzedToken.getToken().length() == 1 
        && Character.isUpperCase(analyzedToken.getToken().charAt(0))
        && position < tokens.length-1 && tokens[position+1].getToken().equals("."));
  }

  @Override
  protected RuleMatch createRuleMatch(String prevToken, String token, int prevPos, int pos, String msg) {
    boolean doubleI = prevToken.equals("Ð") && token.equals("Ñ");
    if( doubleI ) {
      msg += " Ð°Ð±Ð¾, Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾, Ð¿ÐµÑÑÐ° Ð Ð¼Ð°Ñ Ð±ÑÑÐ¸ Ð»Ð°ÑÐ¸Ð½Ñ?ÑÐºÐ¾Ñ.";
    }
    
    RuleMatch ruleMatch = super.createRuleMatch(prevToken, token, prevPos, pos, msg);

    if( doubleI ) {
      List<String> replacements = new ArrayList<>(ruleMatch.getSuggestedReplacements());
      replacements.add("I Ñ");
      ruleMatch.setSuggestedReplacements(replacements);
    }
    return ruleMatch;
  }
}

<code block>

package org.languagetool.rules.uk;

import java.io.IOException;
import java.text.MessageFormat;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.HashSet;
import java.util.List;
import java.util.ResourceBundle;
import java.util.Set;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.apache.commons.lang.StringUtils;
import org.jetbrains.annotations.Nullable;
import org.languagetool.AnalyzedSentence;
import org.languagetool.AnalyzedToken;
import org.languagetool.AnalyzedTokenReadings;
import org.languagetool.JLanguageTool;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.Category;
import org.languagetool.rules.Rule;
import org.languagetool.rules.RuleMatch;
import org.languagetool.synthesis.Synthesizer;
import org.languagetool.tagging.uk.IPOSTag;
import org.languagetool.tagging.uk.PosTagHelper;


public class TokenAgreementRule extends Rule {
  private static final String NO_VIDMINOK_SUBSTR = ":nv";
  private static final String REQUIRE_VIDMINOK_SUBSTR = ":rv_";
  private static final String VIDMINOK_SUBSTR = ":v_";
  private static final Pattern REQUIRE_VIDMINOK_REGEX = Pattern.compile(":r(v_[a-z]+)");
  private static final Pattern VIDMINOK_REGEX = Pattern.compile(":(v_[a-z]+)");

  private final Ukrainian ukrainian = new Ukrainian();

  private static final Set<String> STREETS = new HashSet<>(Arrays.asList(
      "Ð¨ÑÑÐ°Ñ?Ñ?Ðµ", "Ð?Ð²ÐµÐ½Ñ", "Ð¡ÑÑÑÑ"
      ));

  public TokenAgreementRule(final ResourceBundle messages) throws IOException {
    super.setCategory(new Category(messages.getString("category_misc")));
  }

  @Override
  public final String getId() {
    return "UK_TOKEN_AGREEMENT";
  }

  @Override
  public String getDescription() {
    return "Ð£Ð·Ð³Ð¾Ð´Ð¶ÐµÐ½Ð½Ñ? Ñ?Ð»ÑÐ² Ñ ÑÐµÑÐµÐ½Ð½Ñ";
  }

  public String getShort() {
    return "Ð£Ð·Ð³Ð¾Ð´Ð¶ÐµÐ½Ð½Ñ? Ñ?Ð»ÑÐ² Ñ ÑÐµÑÐµÐ½Ð½Ñ";
  }
  
  public boolean isCaseSensitive() {
    return false;
  }

  @Override
  public final RuleMatch[] match(final AnalyzedSentence text) {
    List<RuleMatch> ruleMatches = new ArrayList<>();
    AnalyzedTokenReadings[] tokens = text.getTokensWithoutWhitespace();    
    boolean insideMultiword = false;

    AnalyzedTokenReadings reqTokenReadings = null;
    for (int i = 0; i < tokens.length; i++) {
      AnalyzedTokenReadings tokenReadings = tokens[i];

      String posTag = tokenReadings.getAnalyzedToken(0).getPOSTag();

      

      if (posTag == null
          || posTag.contains(IPOSTag.unknown.getText())
          || posTag.equals(JLanguageTool.SENTENCE_START_TAGNAME) ){
        reqTokenReadings = null;
        continue;
      }

      
      String thisToken = tokenReadings.getToken();
      if( i > 1 && thisToken.length() == 1 && Character.isUpperCase(thisToken.charAt(0)) 
          && tokenReadings.isWhitespaceBefore() && ! tokens[i-1].getToken().matches("[:ââ-]")) {  
        reqTokenReadings = null;
        continue;
      }

      AnalyzedToken multiwordReqToken = getMultiwordToken(tokenReadings);
      if( multiwordReqToken != null ) {
        String mwPosTag = multiwordReqToken.getPOSTag();
        if( mwPosTag.startsWith("</") ) {
          insideMultiword = false;
        }
        else {
          insideMultiword = true;
        }
        
        if (mwPosTag.startsWith("</") && mwPosTag.contains(REQUIRE_VIDMINOK_SUBSTR)) { 
          posTag = multiwordReqToken.getPOSTag();
          reqTokenReadings = tokenReadings;
          continue;
        }
        else {
          if( ! mwPosTag.contains("adv") && ! mwPosTag.contains("insert") ) {
            reqTokenReadings = null;
          }
          continue;
        }
      }
      
      if( insideMultiword ) {
        continue;
      }

      String token = tokenReadings.getAnalyzedToken(0).getToken();
      if( posTag.contains(REQUIRE_VIDMINOK_SUBSTR) && tokenReadings.getReadingsLength() == 1 ) {
        String prep = token;

        if( prep.equals("Ð·Ð°") && reverseSearch(tokens, i, "ÑÐ¾") ) 
          continue;

        if( prep.equalsIgnoreCase("Ð¿Ð¾Ð½Ð°Ð´") )
          continue;

        if( (prep.equalsIgnoreCase("Ð¾ÐºÑÑÐ¼") || prep.equalsIgnoreCase("ÐºÑÑÐ¼"))
            && tokens.length > i+1 && tokens[i+1].getAnalyzedToken(0).getToken().equalsIgnoreCase("Ñ?Ðº") ) {
          reqTokenReadings = null;
          continue;
        }

        reqTokenReadings = tokenReadings;
        continue;
      }

      if( reqTokenReadings == null )
        continue;


      

      ArrayList<String> posTagsToFind = new ArrayList<>();
      String reqPosTag = reqTokenReadings.getAnalyzedToken(0).getPOSTag();
      String prep = reqTokenReadings.getAnalyzedToken(0).getLemma();
      






      
      if( prep.equalsIgnoreCase("Ð¿Ð¾Ð½Ð°Ð´") ) { 
        posTagsToFind.add("v_naz");
      }
      else if( prep.equalsIgnoreCase("Ð·Ð°Ð¼ÑÑ?ÑÑ") ) {
        posTagsToFind.add("v_naz");
      }

      Matcher matcher = REQUIRE_VIDMINOK_REGEX.matcher(reqPosTag);
      while( matcher.find() ) {
        posTagsToFind.add(matcher.group(1));
      }

      for(AnalyzedToken readingToken: tokenReadings) {
        if( IPOSTag.numr.match(readingToken.getPOSTag()) ) {
          posTagsToFind.add("v_naz");  
          break;
        }
      }

      
      if( ! getReadingWithVidmPosTag(posTagsToFind, tokenReadings) ) {
        if( isTokenToSkip(tokenReadings) )
          continue;







        
        if( prep.equalsIgnoreCase("Ð²") || prep.equalsIgnoreCase("Ñ") || prep.equals("Ð¼ÐµÐ¶Ð¸") || prep.equals("Ð¼ÑÐ¶") ) {
          if( PosTagHelper.hasPosTag(tokenReadings, ".*p:v_naz[^&]*") ) { 
            reqTokenReadings = null;
            continue;
          }
        }

        
        if (prep.equalsIgnoreCase("Ð½Ð°")
            && Character.isUpperCase(token.charAt(0)) && posTag.matches("noun:.:v_rod.*")) {
          reqTokenReadings = null;
          continue;
        }

        if( prep.equalsIgnoreCase("Ð·") ) {
          if( token.equals("ÑÐ°Ð½Ð°") ) {
            reqTokenReadings = null;
            continue;
          }
        }
        
        if( prep.equalsIgnoreCase("Ð²ÑÐ´") ) {
          if( token.equalsIgnoreCase("Ð°") || token.equals("ÑÐ°Ð½Ð°") || token.equals("ÐºÐ¾ÑÐºÐ¸") || token.equals("Ð¼Ð°Ð»Ð°") ) {  
            reqTokenReadings = null;
            continue;
          }
        }
        else if( prep.equalsIgnoreCase("Ð´Ð¾") ) {
          if( token.equalsIgnoreCase("Ñ?") || token.equals("ÐºÐ¾ÑÐºÐ¸") || token.equals("Ð²ÐµÐ»Ð¸ÐºÐ°") ) {  
            reqTokenReadings = null;
            continue;
          }
        }

        
        if( tokens.length > i+1 ) {
          
          
          
          

          if( isCapitalized( token ) 
              && STREETS.contains( tokens[i+1].getAnalyzedToken(0).getToken()) ) {
            reqTokenReadings = null;
            continue;
          }

          if( IPOSTag.isNum(tokens[i+1].getAnalyzedToken(0).getPOSTag())
              && (token.equals("Ð¼ÑÐ½ÑÑ?") || token.equals("Ð¿Ð»ÑÑ?")
                  || token.equals("Ð¼ÑÐ½ÑÐ¼ÑÐ¼") || token.equals("Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼") ) ) {
            reqTokenReadings = null;
            continue;
          }

          
          if( PosTagHelper.hasPosTag(tokenReadings, "noun:.:v_oru.*")
              && tokens[i+1].hasPartialPosTag("adjp") ) {
            continue;
          }
          
          if( (prep.equalsIgnoreCase("ÑÐµÑÐµÐ·") || prep.equalsIgnoreCase("Ð½Ð°"))  
              && (posTag.startsWith("noun:p:v_naz") || posTag.startsWith("noun:p:v_rod")) 
              && IPOSTag.isNum(tokens[i+1].getAnalyzedToken(0).getPOSTag()) ) {
            reqTokenReadings = null;
            continue;
          }

          if( (token.equals("Ð²Ð°Ð¼Ð¸") || token.equals("ÑÐ¾Ð±Ð¾Ñ") || token.equals("ÑÐ¼Ð¸"))
              && tokens[i+1].getAnalyzedToken(0).getToken().startsWith("Ð¶") ) {
            continue;
          }
          if( (token.equals("Ñ?Ð¾Ð±Ñ") || token.equals("Ð¹Ð¾Ð¼Ñ") || token.equals("ÑÐ¼"))
              && tokens[i+1].getAnalyzedToken(0).getToken().startsWith("Ð¿Ð¾Ð´ÑÐ±Ð½") ) {
            continue;
          }
          if( (token.equals("ÑÑ?ÑÐ¼") || token.equals("Ð²Ñ?ÑÐ¼"))
              && tokens[i+1].getAnalyzedToken(0).getToken().startsWith("Ð²ÑÐ´Ð¾Ð¼") ) {
            continue;
          }

          if( prep.equalsIgnoreCase("Ð´Ð¾") && token.equals("Ñ?ÑÑÐ´") 
                && tokens[i+1].getAnalyzedToken(0).getToken().equals("Ñ?Ð¾Ð½ÑÑ?") ) {
            reqTokenReadings = null;
            continue;
          }
          
          if( tokens[i+1].getAnalyzedToken(0).getToken().equals("Â«") 
              && tokens[i].getAnalyzedToken(0).getPOSTag().contains(":abbr") ) {
            reqTokenReadings = null;
            continue;
          }

          if( tokens.length > i+2 ) {
            
            if ( posTag.matches("adj.*:[mfn]:v_rod.*")) {
              String gender = PosTagHelper.getGender(posTag);
              if( gender == null ) {
                System.err.println("unknown gender for " + token);
              }
              
              if ( PosTagHelper.hasPosTag(tokens[i+1], "noun.*:"+gender+":v_rod.*")) {
                i += 1;
                continue;
              }
            }

            if ((token.equals("Ð½ÑÐºÐ¾Ð¼Ñ") || token.equals("Ð½ÑÐºÐ¸Ð¼") || token.equals("Ð½ÑÑÐ¸Ð¼") || token.equals("Ð½ÑÑÐ¾Ð¼Ñ")) 
                && tokens[i+1].getAnalyzedToken(0).getToken().equals("Ð½Ðµ")) {
              
              continue;
            }








          }
        }

        RuleMatch potentialRuleMatch = createRuleMatch(tokenReadings, reqTokenReadings, posTagsToFind);
        ruleMatches.add(potentialRuleMatch);
      }

      reqTokenReadings = null;
    }

    return toRuleMatchArray(ruleMatches);
  }

  private static boolean isCapitalized(String token) {
    return token.length() > 1 && Character.isUpperCase(token.charAt(0)) && Character.isLowerCase(token.charAt(1));
  }

  private boolean reverseSearch(AnalyzedTokenReadings[] tokens, int pos, String string) {
    for(int i=pos-1; i >= 0 && i > pos-4; i--) {
      if( tokens[i].getAnalyzedToken(0).getToken().equalsIgnoreCase(string) )
        return true;
    }
    return false;
  }

  private boolean forwardSearch(AnalyzedTokenReadings[] tokens, int pos, String string, int maxSkip) {
    for(int i=pos+1; i < tokens.length && i <= pos + maxSkip; i++) {
      if( tokens[i].getAnalyzedToken(0).getToken().equalsIgnoreCase(string) )
        return true;
    }
    return false;
  }

  private boolean isTokenToSkip(AnalyzedTokenReadings tokenReadings) {
    for(AnalyzedToken token: tokenReadings) {

      if( IPOSTag.adv.match(token.getPOSTag())
          || IPOSTag.contains(token.getPOSTag(), "adv>")
          ||  IPOSTag.insert.match(token.getPOSTag()) )
        return true;
    }
    return false;
  }









  private boolean getReadingWithVidmPosTag(Collection<String> posTagsToFind, AnalyzedTokenReadings tokenReadings) {
    boolean vidminokFound = false;  

    for(AnalyzedToken token: tokenReadings) {
      String posTag = token.getPOSTag();

      if( posTag == null ) {
        if( tokenReadings.getReadingsLength() == 1) 
          return true;
        
        continue;
      }
      
      if( posTag.contains(NO_VIDMINOK_SUBSTR) )
        return true;

      if( posTag.contains(VIDMINOK_SUBSTR) ) {
        vidminokFound = true;

        for(String posTagToFind: posTagsToFind) {
          

          if ( posTag.contains(posTagToFind) )
            return true;
        }
      }
    }

    return ! vidminokFound; 
  }

  private RuleMatch createRuleMatch(AnalyzedTokenReadings tokenReadings, AnalyzedTokenReadings reqTokenReadings, List<String> posTagsToFind) {
    String tokenString = tokenReadings.getToken();

    Synthesizer ukrainianSynthesizer = ukrainian.getSynthesizer();

    ArrayList<String> suggestions = new ArrayList<>();
    String oldPosTag = tokenReadings.getAnalyzedToken(0).getPOSTag();
    String requiredPostTagsRegEx = ":(" + StringUtils.join(posTagsToFind,"|") + ")";
    String posTag = oldPosTag.replaceFirst(":v_[a-z]+", requiredPostTagsRegEx);

    

    try {
      String[] synthesized = ukrainianSynthesizer.synthesize(tokenReadings.getAnalyzedToken(0), posTag, true);

      
      suggestions.addAll( Arrays.asList(synthesized) );
    } catch (IOException e) {
      throw new RuntimeException(e);
    }

    ArrayList<String> reqVidminkyNames = new ArrayList<>();
    for (String vidm: posTagsToFind) {
      reqVidminkyNames.add(PosTagHelper.VIDMINKY_MAP.get(vidm));
    }

    ArrayList<String> foundVidminkyNames = new ArrayList<>();
    for(AnalyzedToken token: tokenReadings) {
      String posTag2 = token.getPOSTag();
      if( posTag2 != null && posTag2.contains(VIDMINOK_SUBSTR) ) {
        String vidmName = PosTagHelper.VIDMINKY_MAP.get(posTag2.replaceFirst("^.*"+VIDMINOK_REGEX+".*$", "$1"));
        if( foundVidminkyNames.contains(vidmName) ) {
          if (posTag2.contains(":p:")) {
            vidmName = vidmName + " (Ð¼Ð½.)";
            foundVidminkyNames.add(vidmName);
          }
          
        }
        else {
          foundVidminkyNames.add(vidmName);
        }
      }
    }

    String msg = MessageFormat.format("ÐÑÐ¸Ð¹Ð¼ÐµÐ½Ð½Ð¸Ðº Â«{0}Â» Ð²Ð¸Ð¼Ð°Ð³Ð°Ñ ÑÐ½ÑÐ¾Ð³Ð¾ Ð²ÑÐ´Ð¼ÑÐ½ÐºÐ°: {1}, Ð° Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾: {2}", 
        reqTokenReadings.getToken(), StringUtils.join(reqVidminkyNames, ", "), StringUtils.join(foundVidminkyNames, ", "));
        
    if( tokenString.equals("ÑÑ") ) {
      msg += ". ÐÐ¾Ð¶Ð»Ð¸Ð²Ð¾ ÑÑÑ Ð¿Ð¾ÑÑÑÐ±Ð½Ð¾ Ð¿ÑÐ¸Ñ?Ð²ÑÐ¹Ð½Ð¸Ð¹ Ð·Ð°Ð¹Ð¼ÐµÐ½Ð½Ð¸Ðº Â«ÑÑÐ½ÑÐ¹Â»?";
      try {
        String newYihPostag = "adj:p" + requiredPostTagsRegEx + ".*";
        String[] synthesized = ukrainianSynthesizer.synthesize(new AnalyzedToken("ÑÑÐ½ÑÐ¹", "adj:m:v_naz:&pron:pos", "ÑÑÐ½ÑÐ¹"), newYihPostag, true);
        suggestions.addAll( Arrays.asList(synthesized) );
      } catch (IOException e) {
        throw new RuntimeException(e);
      }
    }
    else if( reqTokenReadings.getToken().equalsIgnoreCase("Ð¾") ) {
      for(AnalyzedToken token: tokenReadings.getReadings()) {
        String posTag2 = token.getPOSTag();
        if( posTag2.matches(".*:v_naz.*:anim.*") ) {
          msg += ". ÐÐ¾Ð¶Ð»Ð¸Ð²Ð¾ ÑÑÑ Â«Ð¾Â» â ÑÐµ Ð²Ð¸Ð³ÑÐº Ñ Ð¿Ð¾ÑÑÑÐ±Ð½Ð¾ ÐºÐ»Ð¸ÑÐ½Ð¸Ð¹ Ð²ÑÐ´Ð¼ÑÐ½Ð¾Ðº?";
          try {
            String newPostag = posTag2.replace("v_naz", "v_kly");
            String[] synthesized = ukrainianSynthesizer.synthesize(token, newPostag, false);
            for (String string : synthesized) {
              if( ! string.equals(token.getToken()) && ! suggestions.contains(string) ) {
                suggestions.add( string );
              }
            }
            break;
          } catch (IOException e) {
            throw new RuntimeException(e);
          }
        }
      }
      
    }
        
    RuleMatch potentialRuleMatch = new RuleMatch(this, tokenReadings.getStartPos(), tokenReadings.getEndPos(), msg, getShort());

    potentialRuleMatch.setSuggestedReplacements(suggestions);

    return potentialRuleMatch;
  }

  @Nullable
  private static AnalyzedToken getMultiwordToken(AnalyzedTokenReadings analyzedTokenReadings) {
      for(AnalyzedToken analyzedToken: analyzedTokenReadings) {
        String posTag = analyzedToken.getPOSTag();
        if( posTag != null && posTag.startsWith("<") )
          return analyzedToken;
      }
      return null;
  }

  @Override
  public void reset() {
  }

}

<code block>

package org.languagetool.rules.uk;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.ResourceBundle;
import java.util.regex.Pattern;

import org.apache.commons.lang.StringUtils;
import org.languagetool.AnalyzedSentence;
import org.languagetool.AnalyzedTokenReadings;
import org.languagetool.rules.Category;
import org.languagetool.rules.Rule;
import org.languagetool.rules.RuleMatch;


public class MixedAlphabetsRule extends Rule {

  private static final Pattern LIKELY_LATIN_NUMBER = Pattern.compile("[XVIÐ¥Ð]{2,8}");
  private static final Pattern LATIN_NUMBER_WITH_CYRILLICS = Pattern.compile("Ð¥{1,3}Ð{1,3}|Ð{1,3}Ð¥{1,3}|Ð¥{2,3}|Ð{2,3}");
  private static final Pattern MIXED_ALPHABETS = Pattern.compile(".*([a-zA-Z]'?[Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?]|[Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?]'?[a-zA-Z]).*");
  private static final Pattern CYRILLIC_ONLY = Pattern.compile(".*[Ð±Ð²Ð³ÒÐ´ÑÐ¶Ð·Ð¹ÑÐ»Ð½Ð¿ÑÑÑÑÑÑÑÑ?ÐÐÒ?ÐÐÐÐÐÐÐÐÐÐ¤Ð¦Ð§Ð¨Ð©Ð¬Ð®Ð¯].*");
  private static final Pattern LATIN_ONLY = Pattern.compile(".*[bdfghjlqrsvzDFGLNQRSUVZ].*");
  private static final Pattern COMMON_CYR_LETTERS = Pattern.compile("[Ð?ÐÐÐÐÐÐ Ð¡Ð¢Ð£Ð¥]+");

  public MixedAlphabetsRule(final ResourceBundle messages) throws IOException {
    super.setCategory(new Category(messages.getString("category_misc")));
  }

  @Override
  public final String getId() {
    return "UK_MIXED_ALPHABETS";
  }

  @Override
  public String getDescription() {
    return "ÐÐ¼ÑÑÑÐ²Ð°Ð½Ð½Ñ? ÐºÐ¸ÑÐ¸Ð»Ð¸ÑÑ Ð¹ Ð»Ð°ÑÐ¸Ð½Ð¸ÑÑ";
  }

  public String getShort() {
    return "ÐÑÑÐ°Ð½Ð¸Ð½Ð° ÑÐ¾Ð·ÐºÐ»Ð°Ð´Ð¾Ðº";
  }

  public String getSuggestion(String word) {
    String highlighted = word.replaceAll("([a-zA-Z])([Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?])", "$1/$2");
    highlighted = highlighted.replaceAll("([Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?])([a-zA-Z])", "$1/$2");
    return " Ð¼ÑÑ?ÑÐ¸ÑÑ Ñ?ÑÐ¼ÑÑ ÐºÐ¸ÑÐ¸Ð»Ð¸ÑÑ ÑÐ° Ð»Ð°ÑÐ¸Ð½Ð¸ÑÑ: Â«"+ highlighted +"Â», Ð²Ð¸Ð¿ÑÐ°Ð²Ð»ÐµÐ½Ð½Ñ?: ";
  }

  
  public boolean isCaseSensitive() {
    return true;  
  }

  @Override
  public final RuleMatch[] match(final AnalyzedSentence sentence) {
    List<RuleMatch> ruleMatches = new ArrayList<>();
    AnalyzedTokenReadings[] tokens = sentence.getTokensWithoutWhitespace();

    int i=0;
    for (AnalyzedTokenReadings tokenReadings: tokens) {
      String tokenString = tokenReadings.getToken();

      if( MIXED_ALPHABETS.matcher(tokenString).matches() ) {
      
        List<String> replacements = new ArrayList<>();

        if(!LATIN_ONLY.matcher(tokenString).matches() && ! LIKELY_LATIN_NUMBER.matcher(tokenString).matches()) {
          replacements.add( toCyrillic(tokenString) );
        }
        if(!CYRILLIC_ONLY.matcher(tokenString).matches() || LIKELY_LATIN_NUMBER.matcher(tokenString).matches()) {
          replacements.add( toLatin(tokenString) );
        }

        if (replacements.size() > 0) {
          RuleMatch potentialRuleMatch = createRuleMatch(tokenReadings, replacements);
          ruleMatches.add(potentialRuleMatch);
        }
      }
      else if(LATIN_NUMBER_WITH_CYRILLICS.matcher(tokenString).matches()) {
        List<String> replacements = new ArrayList<>();
        replacements.add( toLatin(tokenString) );

        RuleMatch potentialRuleMatch = createRuleMatch(tokenReadings, replacements);
        ruleMatches.add(potentialRuleMatch);
      }
      else if (i>1 && COMMON_CYR_LETTERS.matcher(tokenString).matches()) {
        String prevLemma = tokens[i-1].getAnalyzedToken(0).getLemma();
        if( prevLemma != null && prevLemma.matches("Ð³ÐµÐ¿Ð°ÑÐ¸Ñ|Ð³ÑÑÐ¿Ð°|ÑÑÑÐ½ÑÑ") ) {
          List<String> replacements = new ArrayList<>();
          replacements.add( toLatin(tokenString) );

          String msg = "ÐÐ¶Ð¸ÑÐ¾ ÐºÐ¸ÑÐ¸Ð»ÑÑÐ½Ñ Ð»ÑÑÐµÑÑ Ð·Ð°Ð¼ÑÑ?ÑÑ Ð»Ð°ÑÐ¸Ð½Ñ?ÑÐºÐ¾Ñ";

          RuleMatch potentialRuleMatch = new RuleMatch(this, tokenReadings.getStartPos(), tokenReadings.getEndPos(), msg, getShort());
          potentialRuleMatch.setSuggestedReplacements(replacements);
          ruleMatches.add(potentialRuleMatch);
        }
      }
      else if( tokenString.endsWith("Â°Ð¡") ) {  
        List<String> replacements = new ArrayList<>();
        int length = tokenString.length();
        replacements.add( tokenString.substring(0,  length-1) + toLatin(tokenString.substring(length-1, tokenString.length())) );

        String msg = "ÐÐ¶Ð¸ÑÐ¾ ÐºÐ¸ÑÐ¸Ð»ÑÑÐ½Ñ Ð»ÑÑÐµÑÑ Ð·Ð°Ð¼ÑÑ?ÑÑ Ð»Ð°ÑÐ¸Ð½Ñ?ÑÐºÐ¾Ñ";

        RuleMatch potentialRuleMatch = new RuleMatch(this, tokenReadings.getStartPos(), tokenReadings.getEndPos(), msg, getShort());
        potentialRuleMatch.setSuggestedReplacements(replacements);
        ruleMatches.add(potentialRuleMatch);
      }
      i++;
    }
    return toRuleMatchArray(ruleMatches);
  }

  private RuleMatch createRuleMatch(AnalyzedTokenReadings readings, List<String> replacements) {
    String tokenString = readings.getToken();
    String msg = tokenString + getSuggestion(tokenString) + StringUtils.join(replacements, ", ");

    RuleMatch potentialRuleMatch = new RuleMatch(this, readings.getStartPos(), readings.getEndPos(), msg, getShort());
    potentialRuleMatch.setSuggestedReplacements(replacements);

    return potentialRuleMatch;
  }

  @Override
  public void reset() {
  }

  private static final Map<Character, Character> toLatMap = new HashMap<>();
  private static final Map<Character, Character> toCyrMap = new HashMap<>();
  private static final String cyrChars = "Ð°ÐµÑÐºÐ¼Ð¾ÑÑ?ÑÑÑÐ?ÐÐÐÐÐÐ?ÐÐ Ð¡Ð¢Ð£Ð¥";
  private static final String latChars = "aeikmopctyxABEIKMHOPCTYX";

  static {
    for (int i = 0; i < cyrChars.length(); i++) {
      toLatMap.put(cyrChars.charAt(i), latChars.charAt(i));
      toCyrMap.put(latChars.charAt(i), cyrChars.charAt(i));
    }
  }

  private static String toCyrillic(String word) {
    for (Map.Entry<Character, Character> entry : toCyrMap.entrySet()) {
      word = word.replace(entry.getKey(), entry.getValue());
    }
    return word;
  }

  private static String toLatin(String word) {
    for (Map.Entry<Character, Character> entry : toLatMap.entrySet()) {
      word = word.replace(entry.getKey(), entry.getValue());
    }
    return word;
  }

}

<code block>


package org.languagetool.rules.uk;

import java.io.IOException;
import java.util.ResourceBundle;
import java.util.regex.Pattern;

import org.languagetool.AnalyzedToken;
import org.languagetool.AnalyzedTokenReadings;
import org.languagetool.JLanguageTool;
import org.languagetool.Language;
import org.languagetool.rules.spelling.morfologik.MorfologikSpellerRule;
import org.languagetool.tagging.uk.IPOSTag;

public final class MorfologikUkrainianSpellerRule extends MorfologikSpellerRule {

  private static final String ABBREVIATION_CHAR = ".";
  private static final String RESOURCE_FILENAME = "/uk/hunspell/uk_UA.dict";
  private static final Pattern UKRAINIAN_LETTERS = Pattern.compile(".*[Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?].*");

  public MorfologikUkrainianSpellerRule(ResourceBundle messages,
                                        Language language) throws IOException {
    super(messages, language);

  }

  @Override
  public String getFileName() {
    return RESOURCE_FILENAME;
  }

  @Override
  public String getId() {
    return "MORFOLOGIK_RULE_UK_UA";
  }

  @Override
  protected boolean ignoreToken(AnalyzedTokenReadings[] tokens, int idx) throws IOException {
    String word = tokens[idx].getToken();

    
    if( ! UKRAINIAN_LETTERS.matcher(word).matches() )
      return true;

    if( super.ignoreToken(tokens, idx) )
      return true;

    if( idx < tokens.length - 1 && tokens[idx+1].getToken().equals(ABBREVIATION_CHAR) ) {
      if( super.ignoreWord(word + ABBREVIATION_CHAR) ) {
        return true;
      }
      if( word.matches("[Ð?-Ð¯ÐÐÐÒ?]") ) {  
        return true;
      }
    }
    
    if( word.contains("-") || word.endsWith(".") ) {
      return hasGoodTag(tokens[idx]);
    }

    return false;
  }

  private boolean hasGoodTag(AnalyzedTokenReadings tokens) {
    for (AnalyzedToken analyzedToken : tokens) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag != null 
            && ! posTag.equals(JLanguageTool.SENTENCE_START_TAGNAME) 
            && ! posTag.equals(JLanguageTool.SENTENCE_END_TAGNAME) 
            && ! posTag.contains(IPOSTag.bad.getText()) )
        return true;
    }
    return false;
  }


}

<code block>

package org.languagetool.tagging.uk;

import java.io.IOException;

import junit.framework.TestCase;

import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.tokenizers.uk.UkrainianWordTokenizer;

public class UkrainianTaggerTest extends TestCase {
    
  private UkrainianTagger tagger;
  private UkrainianWordTokenizer tokenizer;
      
  @Override
  public void setUp() {
    tagger = new UkrainianTagger();
    tokenizer = new UkrainianWordTokenizer();
  }

  public void testDictionary() throws IOException {
    TestTools.testDictionary(tagger, new Ukrainian());
  }
  
  public void testTagger() throws IOException {

    
    TestTools.myAssert("ÐºÐ¸ÑÐ²Ñ", "ÐºÐ¸ÑÐ²Ñ/[ÐºÐ¸Ð¹]noun:m:v_dav|ÐºÐ¸ÑÐ²Ñ/[ÐºÐ¸Ð¹]noun:m:v_mis", tokenizer, tagger);
    TestTools.myAssert("ÐÐ¸ÑÐ²Ñ", "ÐÐ¸ÑÐ²Ñ/[ÐÐ¸ÑÐ²]noun:m:v_mis|ÐÐ¸ÑÐ²Ñ/[ÐºÐ¸Ð¹]noun:m:v_dav|ÐÐ¸ÑÐ²Ñ/[ÐºÐ¸Ð¹]noun:m:v_mis", tokenizer, tagger);
    TestTools.myAssert("Ð²ÑÐ»", "Ð²ÑÐ»/[Ð²ÑÐ»]noun:m:v_naz:anim", tokenizer, tagger);
    TestTools.myAssert("ÐÑÐ»", "ÐÑÐ»/[Ð²ÑÐ»]noun:m:v_naz:anim", tokenizer, tagger);
    TestTools.myAssert("ÐÐÐ", "ÐÐÐ/[ÐÐÐ]noun:m:v_dav:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_mis:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_naz:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_oru:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_rod:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_zna:nv:np:abbr|ÐÐÐ/[Ð²ÑÐ»]noun:m:v_naz:anim", tokenizer, tagger);
    TestTools.myAssert("Ð´Ð°Ð»Ñ", "Ð´Ð°Ð»Ñ/[Ð´Ð°Ð»Ñ]adv", tokenizer, tagger);
    TestTools.myAssert("ÐÐ°Ð»Ñ", "ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_mis:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_dav:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_mis:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_naz:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_oru:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_rod:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_zna:nv:np:anim:lname|ÐÐ°Ð»Ñ/[Ð´Ð°Ð»Ñ]adv", tokenizer, tagger);
    TestTools.myAssert("ÐÐµÐ½", "ÐÐµÐ½/[ÐÐµÐ½]noun:m:v_naz:anim:fname|ÐÐµÐ½/[Ð±ÐµÐ½]unknown", tokenizer, tagger);
    TestTools.myAssert("Ð±ÐµÐ½", "Ð±ÐµÐ½/[Ð±ÐµÐ½]unknown", tokenizer, tagger);


    TestTools.myAssert("Ð¡Ð¿ÑÐ°Ð²Ñ Ð¿Ð¾ÑÑÑÐµÐ½Ð¾ Ñ?ÑÐ´Ð¾Ð¼", 
      "Ð¡Ð¿ÑÐ°Ð²Ñ/[Ñ?Ð¿ÑÐ°Ð²Ð°]noun:f:v_zna -- Ð¿Ð¾ÑÑÑÐµÐ½Ð¾/[Ð¿Ð¾ÑÑÑÐ¸ÑÐ¸]verb:impers:perf -- Ñ?ÑÐ´Ð¾Ð¼/[Ñ?ÑÐ´]noun:m:v_oru|Ñ?ÑÐ´Ð¾Ð¼/[Ñ?ÑÐ´Ð¾Ð¼Ð°]noun:p:v_rod",
       tokenizer, tagger);
       
    String expected = 
      "ÐÐ°Ð¹Ð¶Ðµ/[Ð¼Ð°Ð¹Ð¶Ðµ]adv -- Ð´Ð²Ð°/[Ð´Ð²Ð°]numr:m:v_naz|Ð´Ð²Ð°/[Ð´Ð²Ð°]numr:m:v_zna|Ð´Ð²Ð°/[Ð´Ð²Ð°]numr:n:v_naz|Ð´Ð²Ð°/[Ð´Ð²Ð°]numr:n:v_zna -- ÑÐ¾ÐºÐ¸/[ÑÑÐº]noun:p:v_naz|ÑÐ¾ÐºÐ¸/[ÑÑÐº]noun:p:v_zna"
    + " -- ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¹]adj:m:v_dav:&pron:dem|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¹]adj:m:v_mis:&pron:dem|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¹]adj:n:v_dav:&pron:dem|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¹]adj:n:v_mis:&pron:dem|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼]noun:m:v_dav|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼]noun:m:v_mis|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼]noun:m:v_rod|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼Ñ]adv|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼Ñ]conj:subord"
    + " -- ÐÑÐ±Ð°/[ÐÑÐ±Ð°]noun:f:v_naz:anim:fname|ÐÑÐ±Ð°/[Ð»ÑÐ±Ð¸Ð¹]adj:f:v_naz -- ÑÐ°Ð·Ð¾Ð¼/[ÑÐ°Ð·]noun:m:v_oru|ÑÐ°Ð·Ð¾Ð¼/[ÑÐ°Ð·Ð¾Ð¼]adv -- ÑÐ·/[ÑÐ·]prep:rv_rod:rv_zna:rv_oru"
    + " -- ÑÐ¾Ð»Ð¾Ð²ÑÐºÐ¾Ð¼/[ÑÐ¾Ð»Ð¾Ð²ÑÐº]noun:m:v_oru:anim -- Ð¡ÑÐµÐ¿Ð°Ð½Ð¾Ð¼/[Ð¡ÑÐµÐ¿Ð°Ð½]noun:m:v_oru:anim:fname -- Ð²Ð¸ÑÑÐ°Ð»Ð¸/[Ð²Ð¸ÑÑÐ°ÑÐ¸]verb:past:m:perf -- ÑÑÐ´Ð¸/[ÑÑÐ´Ð¸]adv:&pron:dem"
    + " -- Ð½Ð°/[Ð½Ð°]excl|Ð½Ð°/[Ð½Ð°]part|Ð½Ð°/[Ð½Ð°]prep:rv_zna:rv_mis -- "
    + "Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:n:v_naz|Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:n:v_rod|Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:n:v_zna|Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:p:v_naz|Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:p:v_zna";
  
    TestTools.myAssert("ÐÐ°Ð¹Ð¶Ðµ Ð´Ð²Ð° ÑÐ¾ÐºÐ¸ ÑÐ¾Ð¼Ñ ÐÑÐ±Ð° ÑÐ°Ð·Ð¾Ð¼ ÑÐ· ÑÐ¾Ð»Ð¾Ð²ÑÐºÐ¾Ð¼ Ð¡ÑÐµÐ¿Ð°Ð½Ð¾Ð¼ Ð²Ð¸ÑÑÐ°Ð»Ð¸ ÑÑÐ´Ð¸ Ð½Ð° Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?.",
        expected, tokenizer, tagger);
  }

  public void testNumberTagging() throws IOException {
    TestTools.myAssert("101,234", "101,234/[101,234]number", tokenizer, tagger);
    TestTools.myAssert("3,5-5,6% 7Â° 7,4Â°Ð¡", "3,5-5,6%/[3,5-5,6%]number -- 7Â°/[7Â°]number -- 7,4Â°Ð¡/[7,4Â°Ð¡]number", tokenizer, tagger);
    TestTools.myAssert("XIX", "XIX/[XIX]number", tokenizer, tagger);

    TestTools.myAssert("14.07.2001", "14.07.2001/[14.07.2001]date", tokenizer, tagger);

    TestTools.myAssert("Ð¾ 15.33", "Ð¾/[Ð¾]excl|Ð¾/[Ð¾]prep:rv_zna:rv_mis -- 15.33/[15.33]time", tokenizer, tagger);
    TestTools.myAssert("Ð 1:05", "Ð/[Ð¾]excl|Ð/[Ð¾]prep:rv_zna:rv_mis -- 1:05/[1:05]time", tokenizer, tagger);
  }
  
  public void testTaggingWithDots() throws IOException {
    TestTools.myAssert("300 Ñ. Ð´Ð¾ Ð½. Ðµ.", 
      "300/[300]number -- Ñ./[Ñ.]noun:f:v_dav:nv:np:abbr|Ñ./[Ñ.]noun:f:v_mis:nv:np:abbr|Ñ./[Ñ.]noun:f:v_naz:nv:np:abbr|Ñ./[Ñ.]noun:f:v_oru:nv:np:abbr|Ñ./[Ñ.]noun:f:v_rod:nv:np:abbr|Ñ./[Ñ.]noun:f:v_zna:nv:np:abbr|Ñ./[Ñ.]noun:m:v_dav:nv:np:abbr|Ñ./[Ñ.]noun:m:v_mis:nv:np:abbr|Ñ./[Ñ.]noun:m:v_naz:nv:np:abbr|Ñ./[Ñ.]noun:m:v_oru:nv:np:abbr|Ñ./[Ñ.]noun:m:v_rod:nv:np:abbr|Ñ./[Ñ.]noun:m:v_zna:nv:np:abbr -- Ð´Ð¾/[Ð´Ð¾]noun:n:v_dav:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_mis:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_naz:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_oru:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_rod:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_zna:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_dav:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_mis:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_naz:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_oru:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_rod:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_zna:nv|Ð´Ð¾/[Ð´Ð¾]prep:rv_rod -- "
       + "Ð½./[Ð½.]adj:f:v_dav:nv:abbr|Ð½./[Ð½.]adj:f:v_mis:nv:abbr|Ð½./[Ð½.]adj:f:v_naz:nv:abbr|Ð½./[Ð½.]adj:f:v_oru:nv:abbr|Ð½./[Ð½.]adj:f:v_rod:nv:abbr|Ð½./[Ð½.]adj:f:v_zna:nv:abbr|Ð½./[Ð½.]adj:m:v_dav:nv:abbr|Ð½./[Ð½.]adj:m:v_mis:nv:abbr|Ð½./[Ð½.]adj:m:v_naz:nv:abbr|Ð½./[Ð½.]adj:m:v_oru:nv:abbr|Ð½./[Ð½.]adj:m:v_rod:nv:abbr|Ð½./[Ð½.]adj:m:v_zna:nv:abbr|Ð½./[Ð½.]adj:n:v_dav:nv:abbr|Ð½./[Ð½.]adj:n:v_mis:nv:abbr|Ð½./[Ð½.]adj:n:v_naz:nv:abbr|Ð½./[Ð½.]adj:n:v_oru:nv:abbr|Ð½./[Ð½.]adj:n:v_rod:nv:abbr|Ð½./[Ð½.]adj:n:v_zna:nv:abbr|Ð½./[Ð½.]adj:p:v_dav:nv:abbr|Ð½./[Ð½.]adj:p:v_mis:nv:abbr|Ð½./[Ð½.]adj:p:v_naz:nv:abbr|Ð½./[Ð½.]adj:p:v_oru:nv:abbr|Ð½./[Ð½.]adj:p:v_rod:nv:abbr|Ð½./[Ð½.]adj:p:v_zna:nv:abbr -- "
       + "Ðµ./[Ðµ.]noun:f:v_dav:nv:abbr|Ðµ./[Ðµ.]noun:f:v_mis:nv:abbr|Ðµ./[Ðµ.]noun:f:v_naz:nv:abbr|Ðµ./[Ðµ.]noun:f:v_oru:nv:abbr|Ðµ./[Ðµ.]noun:f:v_rod:nv:abbr|Ðµ./[Ðµ.]noun:f:v_zna:nv:abbr|Ðµ./[Ðµ.]noun:p:v_dav:nv:abbr|Ðµ./[Ðµ.]noun:p:v_mis:nv:abbr|Ðµ./[Ðµ.]noun:p:v_naz:nv:abbr|Ðµ./[Ðµ.]noun:p:v_oru:nv:abbr|Ðµ./[Ðµ.]noun:p:v_rod:nv:abbr|Ðµ./[Ðµ.]noun:p:v_zna:nv:abbr",
       tokenizer, tagger);

    TestTools.myAssert("300 ÑÐ¸Ñ?. Ð³ÑÐ¸Ð²ÐµÐ½Ñ", 
        "300/[300]number -- ÑÐ¸Ñ?./[ÑÐ¸Ñ?.]numr:f:v_dav:nv:abbr|ÑÐ¸Ñ?./[ÑÐ¸Ñ?.]numr:f:v_mis:nv:abbr|ÑÐ¸Ñ?./[ÑÐ¸Ñ?.]numr:f:v_naz:nv:abbr|ÑÐ¸Ñ?./[ÑÐ¸Ñ?.]numr:f:v_oru:nv:abbr|ÑÐ¸Ñ?./[ÑÐ¸Ñ?.]numr:f:v_rod:nv:abbr|ÑÐ¸Ñ?./[ÑÐ¸Ñ?.]numr:f:v_zna:nv:abbr -- Ð³ÑÐ¸Ð²ÐµÐ½Ñ/[Ð³ÑÐ¸Ð²Ð½Ñ?]noun:p:v_rod",
         tokenizer, tagger);




  }
  
  public void testDynamicTagging() throws IOException {
    TestTools.myAssert("Ð³-Ð³-Ð³", "Ð³-Ð³-Ð³/[null]null", tokenizer, tagger);
    
    TestTools.myAssert("100-ÑÑÑÐ½Ð¾Ð¼Ñ", "100-ÑÑÑÐ½Ð¾Ð¼Ñ/[100-ÑÑÑÐ½Ð¸Ð¹]adj:m:v_dav|100-ÑÑÑÐ½Ð¾Ð¼Ñ/[100-ÑÑÑÐ½Ð¸Ð¹]adj:m:v_mis|100-ÑÑÑÐ½Ð¾Ð¼Ñ/[100-ÑÑÑÐ½Ð¸Ð¹]adj:n:v_dav|100-ÑÑÑÐ½Ð¾Ð¼Ñ/[100-ÑÑÑÐ½Ð¸Ð¹]adj:n:v_mis", tokenizer, tagger);
    TestTools.myAssert("100-Ð¹", "100-Ð¹/[100-Ð¹]adj:m:v_naz|100-Ð¹/[100-Ð¹]adj:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("50-Ñ", "50-Ñ/[50-Ð¹]adj:p:v_rod|50-Ñ/[50-Ð¹]adj:p:v_zna", tokenizer, tagger);

    TestTools.myAssert("Ð¿Ð¾-Ñ?Ð²Ð¸Ð½Ñ?ÑÐ¾Ð¼Ñ", "Ð¿Ð¾-Ñ?Ð²Ð¸Ð½Ñ?ÑÐ¾Ð¼Ñ/[Ð¿Ð¾-Ñ?Ð²Ð¸Ð½Ñ?ÑÐ¾Ð¼Ñ]adv", tokenizer, tagger);
    TestTools.myAssert("Ð¿Ð¾-Ñ?Ð¸Ð±ÑÑÑ?ÑÐºÐ¸", "Ð¿Ð¾-Ñ?Ð¸Ð±ÑÑÑ?ÑÐºÐ¸/[Ð¿Ð¾-Ñ?Ð¸Ð±ÑÑÑ?ÑÐºÐ¸]adv", tokenizer, tagger);

    TestTools.myAssert("Ð´Ð°Ð²Ð°Ð¹-Ð½Ð¾", "Ð´Ð°Ð²Ð°Ð¹-Ð½Ð¾/[Ð´Ð°Ð²Ð°ÑÐ¸]verb:impr:s:2:imperf", tokenizer, tagger);
    TestTools.myAssert("Ð´Ð¸Ð²ÑÑÑÑ?Ñ?-Ð½Ð¾", "Ð´Ð¸Ð²ÑÑÑÑ?Ñ?-Ð½Ð¾/[Ð´Ð¸Ð²Ð¸ÑÐ¸Ñ?Ñ?]verb:rev:impr:p:2:imperf", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸", "ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸/[ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸]adj:m:v_naz:&pron:dem|ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸/[ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸]adj:m:v_zna:&pron:dem", tokenizer, tagger);
    TestTools.myAssert("Ð±ÑÐ´Ðµ-ÑÐ°ÐºÐ¸", "Ð±ÑÐ´Ðµ-ÑÐ°ÐºÐ¸/[Ð±ÑÑÐ¸]verb:futr:s:3:imperf", tokenizer, tagger);
    TestTools.myAssert("Ð¾ÑÐµÐ¹-Ð¾Ñ", "Ð¾ÑÐµÐ¹-Ð¾Ñ/[Ð¾ÑÐµÐ¹]adj:m:v_naz:&pron:dem|Ð¾ÑÐµÐ¹-Ð¾Ñ/[Ð¾ÑÐµÐ¹]adj:m:v_zna:&pron:dem", tokenizer, tagger);
    TestTools.myAssert("Ð¾ÑÑÐ°ÐºÐ¸Ð¹-ÑÐ¾", "Ð¾ÑÑÐ°ÐºÐ¸Ð¹-ÑÐ¾/[Ð¾ÑÑÐ°ÐºÐ¸Ð¹]adj:m:v_naz:&pron:dem:rare|Ð¾ÑÑÐ°ÐºÐ¸Ð¹-ÑÐ¾/[Ð¾ÑÑÐ°ÐºÐ¸Ð¹]adj:m:v_zna:&pron:dem:rare", tokenizer, tagger);
    TestTools.myAssert("Ð³ÐµÑÑ-ÑÐ¾", "Ð³ÐµÑÑ-ÑÐ¾/[Ð³ÐµÑÑ]adv|Ð³ÐµÑÑ-ÑÐ¾/[Ð³ÐµÑÑ]part", tokenizer, tagger);
    TestTools.myAssert("Ð°Ð½Ñ-Ð±Ð¾", "Ð°Ð½Ñ-Ð±Ð¾/[Ð°Ð½Ñ]excl|Ð°Ð½Ñ-Ð±Ð¾/[Ð°Ð½Ñ]part", tokenizer, tagger);
    TestTools.myAssert("Ð³Ð¾Ð´Ñ-Ð±Ð¾", "Ð³Ð¾Ð´Ñ-Ð±Ð¾/[Ð³Ð¾Ð´Ñ]predic", tokenizer, tagger);
    TestTools.myAssert("Ð³ÐµÐ¹-Ð½Ð¾", "Ð³ÐµÐ¹-Ð½Ð¾/[Ð³ÐµÐ¹]excl", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¸ÑÑ-Ð½Ð¾", "ÑÐ¸ÑÑ-Ð½Ð¾/[ÑÐ¸ÑÑ]excl", tokenizer, tagger);

    TestTools.myAssert("ÐµÐºÑ?-Ð¿Ð°ÑÑÐ½ÐµÑ", "ÐµÐºÑ?-Ð¿Ð°ÑÑÐ½ÐµÑ/[ÐµÐºÑ?-Ð¿Ð°ÑÑÐ½ÐµÑ]noun:m:v_naz:anim", tokenizer, tagger);

    
    TestTools.myAssert("Ð?Ð»ÑÑÐ²Ð°-Ñ?ÑÐ°ÑÑÐ¾Ð³Ð¾", "Ð?Ð»ÑÑÐ²Ð°-Ñ?ÑÐ°ÑÑÐ¾Ð³Ð¾/[Ð?Ð»ÑÑÐ²-Ñ?ÑÐ°ÑÐ¸Ð¹]noun:m:v_rod:anim:lname|Ð?Ð»ÑÑÐ²Ð°-Ñ?ÑÐ°ÑÑÐ¾Ð³Ð¾/[Ð?Ð»ÑÑÐ²-Ñ?ÑÐ°ÑÐ¸Ð¹]noun:m:v_zna:anim:lname", tokenizer, tagger);


    
    TestTools.myAssert("Ð¶Ð¸Ð»Ð¾-Ð±ÑÐ»Ð¾", "Ð¶Ð¸Ð»Ð¾-Ð±ÑÐ»Ð¾/[Ð¶Ð¸ÑÐ¸-Ð±ÑÑÐ¸]verb:past:n:imperf", tokenizer, tagger);
    TestTools.myAssert("ÑÑÐ¸Ñ-ÑÑÐ¸Ñ", "ÑÑÐ¸Ñ-ÑÑÐ¸Ñ/[ÑÑÐ¸ÑÐ¸-ÑÑÐ¸ÑÐ¸]verb:pres:s:2:imperf:v-u", tokenizer, tagger);

    TestTools.myAssert("Ð²Ð³Ð¾ÑÑ-Ð²Ð½Ð¸Ð·", "Ð²Ð³Ð¾ÑÑ-Ð²Ð½Ð¸Ð·/[Ð²Ð³Ð¾ÑÑ-Ð²Ð½Ð¸Ð·]adv:v-u", tokenizer, tagger);

    TestTools.myAssert("Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾-Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾", "Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾-Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾/[Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾-Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾]adv", tokenizer, tagger);
    TestTools.myAssert("ÑÐ°ÐºÐ¾Ð³Ð¾-Ñ?Ñ?ÐºÐ¾Ð³Ð¾", "ÑÐ°ÐºÐ¾Ð³Ð¾-Ñ?Ñ?ÐºÐ¾Ð³Ð¾/[ÑÐ°ÐºÐ¸Ð¹-Ñ?Ñ?ÐºÐ¸Ð¹]adj:m:v_rod:&pron:def|ÑÐ°ÐºÐ¾Ð³Ð¾-Ñ?Ñ?ÐºÐ¾Ð³Ð¾/[ÑÐ°ÐºÐ¸Ð¹-Ñ?Ñ?ÐºÐ¸Ð¹]adj:m:v_zna:&pron:def|ÑÐ°ÐºÐ¾Ð³Ð¾-Ñ?Ñ?ÐºÐ¾Ð³Ð¾/[ÑÐ°ÐºÐ¸Ð¹-Ñ?Ñ?ÐºÐ¸Ð¹]adj:n:v_rod:&pron:def", tokenizer, tagger);
    TestTools.myAssert("Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹", "Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹/[Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹]adj:m:v_naz|Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹/[Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹]adj:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¾ÑÐ½ÑÐ¹-ÑÐ¾ÑÐ½ÑÐ¹", "ÑÐ¾ÑÐ½ÑÐ¹-ÑÐ¾ÑÐ½ÑÐ¹/[ÑÐ¾ÑÐ½Ð¸Ð¹-ÑÐ¾ÑÐ½Ð¸Ð¹]adj:f:v_dav|ÑÐ¾ÑÐ½ÑÐ¹-ÑÐ¾ÑÐ½ÑÐ¹/[ÑÐ¾ÑÐ½Ð¸Ð¹-ÑÐ¾ÑÐ½Ð¸Ð¹]adj:f:v_mis|ÑÐ¾ÑÐ½ÑÐ¹-ÑÐ¾ÑÐ½ÑÐ¹/[ÑÐ¾ÑÐ½ÑÑÐ¸-ÑÐ¾ÑÐ½ÑÑÐ¸]verb:impr:s:2:imperf", tokenizer, tagger);

    TestTools.myAssert("Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ", "Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ/[Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ]noun:m:v_naz:anim", tokenizer, tagger);
    TestTools.myAssert("Ð»ÑÐºÐ°ÑÑ?-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°ÑÐ°", "Ð»ÑÐºÐ°ÑÑ?-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°ÑÐ°/[Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ]noun:m:v_rod:anim|Ð»ÑÐºÐ°ÑÑ?-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°ÑÐ°/[Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ]noun:m:v_zna:anim", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¼ÐºÑ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ", "ÑÐ¼ÐºÑ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ/[null]null", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¼ÐºÑ-ÑÐºÑ", "ÑÐ¼ÐºÑ-ÑÐºÑ/[null]null", tokenizer, tagger);

    TestTools.myAssert("Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´", "Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´/[Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´]noun:m:v_naz:v-u|Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´/[Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´]noun:m:v_zna:v-u", tokenizer, tagger);
    TestTools.myAssert("Ð¼ÑÑ?ÑÐ°-ÑÐ¾ÑÑÐµÑÑ", "Ð¼ÑÑ?ÑÐ°-ÑÐ¾ÑÑÐµÑÑ/[Ð¼ÑÑ?ÑÐ¾-ÑÐ¾ÑÑÐµÑÑ?]noun:n:v_rod|Ð¼ÑÑ?ÑÐ°-ÑÐ¾ÑÑÐµÑÑ/[Ð¼ÑÑ?ÑÐ¾-ÑÐ¾ÑÑÐµÑÑ?]noun:p:v_naz|Ð¼ÑÑ?ÑÐ°-ÑÐ¾ÑÑÐµÑÑ/[Ð¼ÑÑ?ÑÐ¾-ÑÐ¾ÑÑÐµÑÑ?]noun:p:v_zna", tokenizer, tagger);

    
    TestTools.myAssert("Ð²ÑÐµÐ½Ð¸Ñ-Ð½Ð¾Ð²Ð°ÑÐ¾ÑÑÐ²", "Ð²ÑÐµÐ½Ð¸Ñ-Ð½Ð¾Ð²Ð°ÑÐ¾ÑÑÐ²/[Ð²ÑÐµÐ½Ð¸Ð¹-Ð½Ð¾Ð²Ð°ÑÐ¾Ñ]noun:p:v_rod:anim:v-u|Ð²ÑÐµÐ½Ð¸Ñ-Ð½Ð¾Ð²Ð°ÑÐ¾ÑÑÐ²/[Ð²ÑÐµÐ½Ð¸Ð¹-Ð½Ð¾Ð²Ð°ÑÐ¾Ñ]noun:p:v_zna:anim:v-u", tokenizer, tagger);
    TestTools.myAssert("ÐºÑÐ°ÑÐ½Ð°-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº", "ÐºÑÐ°ÑÐ½Ð°-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº/[ÐºÑÐ°ÑÐ½Ð°-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº]noun:f:v_naz", tokenizer, tagger);
    TestTools.myAssert("Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº", "Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº/[Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº]noun:m:v_naz|Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº/[Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº]noun:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸", "Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸/[Ð±Ð°Ð½Ðº-Ð°Ð³ÐµÐ½Ñ]noun:p:v_naz|Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸/[Ð±Ð°Ð½Ðº-Ð°Ð³ÐµÐ½Ñ]noun:p:v_zna|Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸/[Ð±Ð°Ð½ÐºÐ°-Ð°Ð³ÐµÐ½Ñ]noun:p:v_naz|Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸/[Ð±Ð°Ð½ÐºÐ°-Ð°Ð³ÐµÐ½Ñ]noun:p:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ", "Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ/[Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ]noun:n:v_naz|Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ/[Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ]noun:n:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÐºÑÐ°ÑÐ½Ð¸-Ð°Ð³ÑÐµÑ?Ð¾ÑÐ¸", "ÐºÑÐ°ÑÐ½Ð¸-Ð°Ð³ÑÐµÑ?Ð¾ÑÐ¸/[ÐºÑÐ°ÑÐ½Ð°-Ð°Ð³ÑÐµÑ?Ð¾Ñ]noun:p:v_naz|ÐºÑÐ°ÑÐ½Ð¸-Ð°Ð³ÑÐµÑ?Ð¾ÑÐ¸/[ÐºÑÐ°ÑÐ½Ð°-Ð°Ð³ÑÐµÑ?Ð¾Ñ]noun:p:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ", "Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ/[Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ]noun:n:v_naz|Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ/[Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ]noun:n:v_zna", tokenizer, tagger);
    
    TestTools.myAssert("Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ", "Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ/[Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ]noun:m:v_naz|Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ/[Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ]noun:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ", "ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ/[ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ]noun:m:v_naz|ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ/[ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ]noun:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð´ÐµÐ¿ÑÑÐ°ÑÑÐ²-Ð¿ÑÐ¸Ð²Ð¸Ð´ÑÐ²", "Ð´ÐµÐ¿ÑÑÐ°ÑÑÐ²-Ð¿ÑÐ¸Ð²Ð¸Ð´ÑÐ²/[Ð´ÐµÐ¿ÑÑÐ°Ñ-Ð¿ÑÐ¸Ð²Ð¸Ð´]noun:p:v_rod:anim|Ð´ÐµÐ¿ÑÑÐ°ÑÑÐ²-Ð¿ÑÐ¸Ð²Ð¸Ð´ÑÐ²/[Ð´ÐµÐ¿ÑÑÐ°Ñ-Ð¿ÑÐ¸Ð²Ð¸Ð´]noun:p:v_zna:anim", tokenizer, tagger);
    TestTools.myAssert("Ð´ÑÐ²ÑÐ°ÑÐ°-Ð·ÑÑÐ¾ÑÐºÐ¸", "Ð´ÑÐ²ÑÐ°ÑÐ°-Ð·ÑÑÐ¾ÑÐºÐ¸/[Ð´ÑÐ²ÑÐ°-Ð·ÑÑÐ¾ÑÐºÐ°]noun:p:v_naz:anim", tokenizer, tagger);

    TestTools.myAssert("Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°", "Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°/[Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°]noun:m:v_naz|Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°/[Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°]noun:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ñ?Ð¾ÑÐ½Ñ-Ð´Ð²Ñ", "Ñ?Ð¾ÑÐ½Ñ-Ð´Ð²Ñ/[Ñ?Ð¾ÑÐ½Ñ?-Ð´Ð²Ð°]noun:p:v_naz|Ñ?Ð¾ÑÐ½Ñ-Ð´Ð²Ñ/[Ñ?Ð¾ÑÐ½Ñ?-Ð´Ð²Ð°]noun:p:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¸Ñ?Ñ?ÑÐµÑ-ÑÑÑÐ¾Ð¼Ð°", "ÑÐ¸Ñ?Ñ?ÑÐµÑ-ÑÑÑÐ¾Ð¼Ð°/[ÑÐ¸Ñ?Ñ?ÑÐ°-ÑÑÐ¸]noun:f:v_oru|ÑÐ¸Ñ?Ñ?ÑÐµÑ-ÑÑÑÐ¾Ð¼Ð°/[ÑÐ¸Ñ?Ñ?ÑÐ°-ÑÑÐ¾Ñ]noun:f:v_oru", tokenizer, tagger);

    TestTools.myAssert("Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°", "Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð°]numr:m:v_oru|Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð°]numr:n:v_oru|Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð¾Ñ]numr:m:v_oru|Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð¾Ñ]numr:n:v_oru", tokenizer, tagger);
    

    TestTools.myAssert("Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸", "Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸/[Ð¿'Ñ?ÑÐ°-ÑÑÑ?ÑÑ]noun:f:v_rod|Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸/[Ð¿'Ñ?ÑÑ-ÑÑÑ?ÑÑ]numr:p:v_dav|Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸/[Ð¿'Ñ?ÑÑ-ÑÑÑ?ÑÑ]numr:p:v_mis|Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸/[Ð¿'Ñ?ÑÑ-ÑÑÑ?ÑÑ]numr:p:v_rod", tokenizer, tagger);
    TestTools.myAssert("Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ñ", "Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ñ/[Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ð°]numr:f:v_naz|Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ñ/[Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ð°]numr:f:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸", "ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸/[ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸]numr:p:v_naz|ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸/[ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸]numr:p:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸", "Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸/[Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸]numr:m:v_naz|Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸/[Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸]numr:m:v_zna|Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸/[Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸]numr:n:v_naz|Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸/[Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸]numr:n:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ", "Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð°]numr:m:v_mis|Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð°]numr:n:v_mis|Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð¾Ñ]numr:m:v_mis|Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð¾Ñ]numr:n:v_mis", tokenizer, tagger);
    
    TestTools.myAssert("ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸", "ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸/[ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸]numr:p:v_naz|ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸/[ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸]numr:p:v_zna", tokenizer, tagger);
    






    TestTools.myAssert("Ð°-Ð°", "Ð°-Ð°/[Ð°-Ð°]excl", tokenizer, tagger);

    TestTools.myAssert("ÐÐ¾Ñ?ÐºÐ²Ð¸-ÑÑÐºÐ¸", "ÐÐ¾Ñ?ÐºÐ²Ð¸-ÑÑÐºÐ¸/[ÐÐ¾Ñ?ÐºÐ²Ð°-ÑÑÐºÐ°]noun:f:v_rod", tokenizer, tagger);
    
    TestTools.myAssert("Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸", "Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_dav|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_mis|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_naz|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_oru|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_rod|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_zna", tokenizer, tagger);

    TestTools.myAssert("ÐºÐ°Ð²Ð°-ÐµÑ?Ð¿ÑÐµÑ?Ð¾", "ÐºÐ°Ð²Ð°-ÐµÑ?Ð¿ÑÐµÑ?Ð¾/[ÐºÐ°Ð²Ð°-ÐµÑ?Ð¿ÑÐµÑ?Ð¾]noun:f:v_naz", tokenizer, tagger);
    TestTools.myAssert("ÐºÐ°Ð²Ð¸-ÐµÑ?Ð¿ÑÐµÑ?Ð¾", "ÐºÐ°Ð²Ð¸-ÐµÑ?Ð¿ÑÐµÑ?Ð¾/[ÐºÐ°Ð²Ð°-ÐµÑ?Ð¿ÑÐµÑ?Ð¾]noun:f:v_rod", tokenizer, tagger);
    TestTools.myAssert("ÐµÑ?Ð¿ÑÐµÑ?Ð¾-Ð¼Ð°ÑÐ¸Ð½Ð°", "ÐµÑ?Ð¿ÑÐµÑ?Ð¾-Ð¼Ð°ÑÐ¸Ð½Ð°/[ÐµÑ?Ð¿ÑÐµÑ?Ð¾-Ð¼Ð°ÑÐ¸Ð½Ð°]noun:f:v_naz", tokenizer, tagger);
    TestTools.myAssert("Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¾Ñ-Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼", "Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¾Ñ-Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼/[Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð°-Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼]noun:f:v_oru", tokenizer, tagger);

    TestTools.myAssert("ÐÐµÐ½Ñ?Ð¸Ð»ÑÐ²Ð°Ð½ÑÑ?-Ð°Ð²ÐµÐ½Ñ", "ÐÐµÐ½Ñ?Ð¸Ð»ÑÐ²Ð°Ð½ÑÑ?-Ð°Ð²ÐµÐ½Ñ/[ÐÐµÐ½Ñ?Ð¸Ð»ÑÐ²Ð°Ð½ÑÑ?-Ð°Ð²ÐµÐ½Ñ]noun:f:nv", tokenizer, tagger);

    TestTools.myAssert("Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹", "Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹/[Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹]adj:m:v_naz|Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹/[Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹]adj:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð¿Ð°ÑÐ°Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹", "Ð¿Ð°ÑÐ°Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹/[null]null", tokenizer, tagger);
    

    TestTools.myAssert("Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð³Ð¼ÐºÐ½Ñ", "Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð³Ð¼ÐºÐ½Ñ/[null]null", tokenizer, tagger);
    TestTools.myAssert("Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð³Ð¾Ð»Ð¾Ð²Ð°", "Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð³Ð¾Ð»Ð¾Ð²Ð°/[null]null", tokenizer, tagger);
    
    TestTools.myAssert("Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹", "Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹/[Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹]adj:m:v_naz:compb|Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹/[Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹]adj:m:v_zna:compb", tokenizer, tagger);
    TestTools.myAssert("Ð±ÑÑÐ¼ÑÐºÐ¾Ð²Ð¾-Ð±Ð»Ð°ÐºÐ¸ÑÐ½Ð¸Ð¹", "Ð±ÑÑÐ¼ÑÐºÐ¾Ð²Ð¾-Ð±Ð»Ð°ÐºÐ¸ÑÐ½Ð¸Ð¹/[null]null", tokenizer, tagger);
    TestTools.myAssert("Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¾Ð³Ð¾", "Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¾Ð³Ð¾/[Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¸Ð¹]adj:m:v_rod:compb|Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¾Ð³Ð¾/[Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¸Ð¹]adj:m:v_zna:compb|Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¾Ð³Ð¾/[Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¸Ð¹]adj:n:v_rod:compb", tokenizer, tagger);
    TestTools.myAssert("Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹", "Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹/[Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹]adj:m:v_naz|Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹/[Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹]adj:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹", "ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹/[ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹]adj:m:v_naz|ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹/[ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹]adj:m:v_zna", tokenizer, tagger);



    TestTools.myAssert("ÐÑÐ²ÑÐ¸Ð½ÐºÐ°-Ð¿ÐµÑÑÐ¾ÐºÐ»Ð°Ñ?Ð½Ð¸ÑÑ?", "ÐÑÐ²ÑÐ¸Ð½ÐºÐ°-Ð¿ÐµÑÑÐ¾ÐºÐ»Ð°Ñ?Ð½Ð¸ÑÑ?/[Ð´ÑÐ²ÑÐ¸Ð½ÐºÐ°-Ð¿ÐµÑÑÐ¾ÐºÐ»Ð°Ñ?Ð½Ð¸ÑÑ?]noun:f:v_naz:anim", tokenizer, tagger);

    TestTools.myAssert("RPM-Ð¿Ð°ÐºÑÐ½Ð¾Ðº", "RPM-Ð¿Ð°ÐºÑÐ½Ð¾Ðº/[RPM-Ð¿Ð°ÐºÑÐ½Ð¾Ðº]noun:m:v_naz|RPM-Ð¿Ð°ÐºÑÐ½Ð¾Ðº/[RPM-Ð¿Ð°ÐºÑÐ½Ð¾Ðº]noun:m:v_zna", tokenizer, tagger);

    
    
    
    
    
    
  }

}

<code block>


package org.languagetool.tokenizers.uk;

import java.util.Arrays;
import java.util.List;

import junit.framework.TestCase;

public class UkrainianWordTokenizerTest extends TestCase {
  private final UkrainianWordTokenizer w = new UkrainianWordTokenizer();

  public void testTokenizeUrl() {
    String url = "http:
    List<String> testList = w.tokenize(url);
    assertEquals(Arrays.asList(url), testList);
  }
  
  public void testNumbers() {
    List<String> testList = w.tokenize("300 Ð³ÑÐ½ Ð½Ð° Ð±Ð°Ð»Ð°Ð½Ñ?Ñ");
    assertEquals(Arrays.asList("300", " ", "Ð³ÑÐ½", " ", "Ð½Ð°", " ", "Ð±Ð°Ð»Ð°Ð½Ñ?Ñ"), testList);

    testList = w.tokenize("Ð½Ð°Ð´ÑÐ¹ÑÐ»Ð¾ 2,2 Ð¼ÑÐ»ÑÐ¹Ð¾Ð½Ð°");
    assertEquals(Arrays.asList("Ð½Ð°Ð´ÑÐ¹ÑÐ»Ð¾", " ", "2,2", " ", "Ð¼ÑÐ»ÑÐ¹Ð¾Ð½Ð°"), testList);

    testList = w.tokenize("Ð½Ð°Ð´ÑÐ¹ÑÐ»Ð¾ 84,46 Ð¼ÑÐ»ÑÐ¹Ð¾Ð½Ð°");
    assertEquals(Arrays.asList("Ð½Ð°Ð´ÑÐ¹ÑÐ»Ð¾", " ", "84,46", " ", "Ð¼ÑÐ»ÑÐ¹Ð¾Ð½Ð°"), testList);

    






    testList = w.tokenize("Ñ?ÑÐ°Ð»Ð¾Ñ?Ñ? 14.07.2001 Ð²Ð½Ð¾ÑÑ");
    assertEquals(Arrays.asList("Ñ?ÑÐ°Ð»Ð¾Ñ?Ñ?", " ", "14.07.2001", " ", "Ð²Ð½Ð¾ÑÑ"), testList);

    testList = w.tokenize("Ð²ÑÐ¾ÑÐ° Ð¾ 7.30 ÑÐ°Ð½ÐºÑ");
    assertEquals(Arrays.asList("Ð²ÑÐ¾ÑÐ°", " ", "Ð¾", " ", "7.30", " ", "ÑÐ°Ð½ÐºÑ"), testList);
  }
  
  public void testTokenize() {
    List<String> testList = w.tokenize("ÐÐ¾Ð½Ð¸ Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸ Ð´Ð¾Ð´Ð¾Ð¼Ñ.");
    assertEquals(Arrays.asList("ÐÐ¾Ð½Ð¸", " ", "Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸", " ", "Ð´Ð¾Ð´Ð¾Ð¼Ñ", "."), testList);

    testList = w.tokenize("ÐÐ¾Ð½Ð¸ Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸ Ð¿Ê¼Ñ?ÑÐ¸Ð¼Ð¸ Ð·ÑÐ²âÑ?Ð»Ð¸Ð¼Ð¸.");
    assertEquals(Arrays.asList("ÐÐ¾Ð½Ð¸", " ", "Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸", " ", "Ð¿'Ñ?ÑÐ¸Ð¼Ð¸", " ", "Ð·ÑÐ²'Ñ?Ð»Ð¸Ð¼Ð¸", "."), testList);




    testList = w.tokenize("Ñ? ÑÐºÑÐ°ÑÐ½ÐµÑÑ(Ñ?Ð¼ÑÑÑÑÑ?Ñ?");
    assertEquals(Arrays.asList("Ñ?", " ", "ÑÐºÑÐ°ÑÐ½ÐµÑÑ", "(", "Ñ?Ð¼ÑÑÑÑÑ?Ñ?"), testList);
        
    testList = w.tokenize("ÐÐ£Ð?(Ð±) ÑÐ° ÐÐ(Ð±)Ð£");
    assertEquals(Arrays.asList("ÐÐ£Ð?(Ð±)", " ", "ÑÐ°", " ", "ÐÐ(Ð±)Ð£"), testList);

    testList = w.tokenize("Ð?ÐµÐ³Ð¾Ð´Ð° Ñ... Ð·Ð°Ñ?ÑÑÐ¿Ð½Ð¸ÐºÐ¾Ð¼");
    assertEquals(Arrays.asList("Ð?ÐµÐ³Ð¾Ð´Ð°", " ", "Ñ", "...", " ", "Ð·Ð°Ñ?ÑÑÐ¿Ð½Ð¸ÐºÐ¾Ð¼"), testList);

    testList = w.tokenize("ÐÐ°Ð¿Ð°Ð³ÑÐ±Ð¸Ð»Ð¸!.. ÑÐ°ÐºÐ¾Ð¶");
    assertEquals(Arrays.asList("ÐÐ°Ð¿Ð°Ð³ÑÐ±Ð¸Ð»Ð¸", "!..", " ", "ÑÐ°ÐºÐ¾Ð¶"), testList);

    testList = w.tokenize("Ð¦ÐµÐ¹ Ð³ÑÐ°ÑÐ¸Ð½.");
    assertEquals(Arrays.asList("Ð¦ÐµÐ¹", " ", "Ð³ÑÐ°ÑÐ¸Ð½", "."), testList);

    testList = w.tokenize("â ÐÐ¼.");
    assertEquals(Arrays.asList("â", " ", "ÐÐ¼", "."), testList);
  }
  
  public void testAbbreviations() {
    List<String> testList = w.tokenize("ÐÐ°Ñ?ÑÐ´Ð°Ð² Ð.ÐÑÐ¼Ð¾Ð»ÑÐº.");
    assertEquals(Arrays.asList("ÐÐ°Ñ?ÑÐ´Ð°Ð²", " ", "Ð", ".", "ÐÑÐ¼Ð¾Ð»ÑÐº", "."), testList);

    testList = w.tokenize("ÐÐ°Ñ?ÑÐ´Ð°Ð² Ð.Ð.ÐÑÐ¼Ð¾Ð»ÑÐº.");
    assertEquals(Arrays.asList("ÐÐ°Ñ?ÑÐ´Ð°Ð²", " ", "Ð", ".", "Ð", ".", "ÐÑÐ¼Ð¾Ð»ÑÐº", "."), testList);

    testList = w.tokenize("Ð.\u00A0ÐÑÐ¼Ð¾Ð»ÑÐº.");
    assertEquals(Arrays.asList("Ð", ".", "\u00A0", "ÐÑÐ¼Ð¾Ð»ÑÐº", "."), testList);

    
    
    testList = w.tokenize("140 ÑÐ¸Ñ?. Ð¿ÑÐ°ÑÑÐ²Ð½Ð¸ÐºÑÐ²");
    assertEquals(Arrays.asList("140", " ", "ÑÐ¸Ñ?.", " ", "Ð¿ÑÐ°ÑÑÐ²Ð½Ð¸ÐºÑÐ²"), testList);

    testList = w.tokenize("Ð¿ÑÐ¾Ñ. Ð?ÑÑÑÑÐ¾Ð²");
    assertEquals(Arrays.asList("Ð¿ÑÐ¾Ñ.", " ", "Ð?ÑÑÑÑÐ¾Ð²"), testList);

    testList = w.tokenize("Ð¿ÑÐ¾Ñ.\u00A0Ð?ÑÑÑÑÐ¾Ð²");
    assertEquals(Arrays.asList("Ð¿ÑÐ¾Ñ.", "\u00A0", "Ð?ÑÑÑÑÐ¾Ð²"), testList);

    testList = w.tokenize("Ð´Ð¾ Ð½. Ðµ.");
    assertEquals(Arrays.asList("Ð´Ð¾", " ", "Ð½.", " ", "Ðµ."), testList);
 
    testList = w.tokenize("Ð´Ð¾ Ð½.Ðµ.");
    assertEquals(Arrays.asList("Ð´Ð¾", " ", "Ð½.", "Ðµ."), testList);

    testList = w.tokenize("1998 Ñ.Ð½.");
    assertEquals(Arrays.asList("1998", " ", "Ñ.", "Ð½."), testList);

    testList = w.tokenize("18-19 Ñ?Ñ.Ñ?Ñ. Ð±ÑÐ»Ð¸");
    assertEquals(Arrays.asList("18-19", " ", "Ñ?Ñ.", "Ñ?Ñ.", " ", "Ð±ÑÐ»Ð¸"), testList);
    
    testList = w.tokenize("Ð Ñ?Ñ. 11");
    assertEquals(Arrays.asList("Ð", " ", "Ñ?Ñ.", " ", "11"), testList);

    testList = w.tokenize("Ð£ Ñ?. ÐÐ¸Ð¶Ð²Ð°");
    assertEquals(Arrays.asList("Ð£", " ", "Ñ?.", " ", "ÐÐ¸Ð¶Ð²Ð°"), testList);

    testList = w.tokenize("ÐÐ¾Ð²Ð¶Ð¸Ð½Ð¾Ñ 30 Ñ?. Ð· Ð³Ð°ÐºÐ¾Ð¼.");
    assertEquals(Arrays.asList("ÐÐ¾Ð²Ð¶Ð¸Ð½Ð¾Ñ", " ", "30", " ", "Ñ?", ".", " ", "Ð·", " ", "Ð³Ð°ÐºÐ¾Ð¼", "."), testList);

    testList = w.tokenize("ÐÐ¾Ð²Ð¶Ð¸Ð½Ð¾Ñ 30 Ñ?. ÐÐ¾ÑÑÐ°Ð»Ð¸.");
    assertEquals(Arrays.asList("ÐÐ¾Ð²Ð¶Ð¸Ð½Ð¾Ñ", " ", "30", " ", "Ñ?", ".", " ", "ÐÐ¾ÑÑÐ°Ð»Ð¸", "."), testList);

    testList = w.tokenize("100 Ð¼. Ð´Ð¾ÑÐ¾Ð³Ð¸.");
    assertEquals(Arrays.asList("100", " ", "Ð¼", ".", " ", "Ð´Ð¾ÑÐ¾Ð³Ð¸", "."), testList);

    testList = w.tokenize("Ð?Ð° Ð²Ð¸Ñ?Ð¾ÑÑ 4000 Ð¼...");
    assertEquals(Arrays.asList("Ð?Ð°", " ", "Ð²Ð¸Ñ?Ð¾ÑÑ", " ", "4000", " ", "Ð¼", "..."), testList);

    testList = w.tokenize("â47 (Ð¼. Ð¡Ð»Ð¾Ð²'Ñ?Ð½Ñ?ÑÐº)");
    assertEquals(Arrays.asList("â47", " ", "(", "Ð¼.", " ", "Ð¡Ð»Ð¾Ð²'Ñ?Ð½Ñ?ÑÐº", ")"), testList);

    testList = w.tokenize("Ñ?.-Ð³.");
    assertEquals(Arrays.asList("Ñ?.-Ð³."), testList);

    testList = w.tokenize("100 Ð³ÑÐ½. Ð² Ð±Ð°Ð½Ðº");
    assertEquals(Arrays.asList("100", " ", "Ð³ÑÐ½", ".", " ", "Ð²", " ", "Ð±Ð°Ð½Ðº"), testList);
    
    testList = w.tokenize("ÑÐ°ÐºÐµ ÑÐ° ÑÐ½.");
    assertEquals(Arrays.asList("ÑÐ°ÐºÐµ", " ", "ÑÐ°", " ", "ÑÐ½."), testList);

    testList = w.tokenize("Ñ Ñ. ÑÐ½.");
    assertEquals(Arrays.asList("Ñ", " ", "Ñ.", " ", "ÑÐ½."), testList);

    testList = w.tokenize("ÐÐ½Ñ?ÑÐ¸ÑÑÑ ÑÐ¼. Ð°ÐºÐ°Ð´. ÐÐµÑÐ½Ð°Ð´Ñ?ÑÐºÐ¾Ð³Ð¾.");
    assertEquals(Arrays.asList("ÐÐ½Ñ?ÑÐ¸ÑÑÑ", " ", "ÑÐ¼.", " ", "Ð°ÐºÐ°Ð´.", " ", "ÐÐµÑÐ½Ð°Ð´Ñ?ÑÐºÐ¾Ð³Ð¾", "."), testList);

    testList = w.tokenize("ÐÐ°Ð»Ð°Ñ ÑÐ¼. Ð³ÐµÑÑÐ¼Ð°Ð½Ð° Ð¡ÐºÐ¾ÑÐ¾Ð¿Ð°Ð´Ñ?ÑÐºÐ¾Ð³Ð¾.");
    assertEquals(Arrays.asList("ÐÐ°Ð»Ð°Ñ", " ", "ÑÐ¼.", " ", "Ð³ÐµÑÑÐ¼Ð°Ð½Ð°", " ", "Ð¡ÐºÐ¾ÑÐ¾Ð¿Ð°Ð´Ñ?ÑÐºÐ¾Ð³Ð¾", "."), testList);

    testList = w.tokenize("Ð²ÑÐ´ Ð»Ð°Ñ. momento");
    assertEquals(Arrays.asList("Ð²ÑÐ´", " ", "Ð»Ð°Ñ.", " ", "momento"), testList);

    testList = w.tokenize("Ð½Ð° 1-ÐºÑÐ¼Ð½. ÐºÐ². Ð² ÑÐµÐ½ÑÑÑ");
    assertEquals(Arrays.asList("Ð½Ð°", " " , "1-ÐºÑÐ¼Ð½.", " ", "ÐºÐ².", " ", "Ð²", " ", "ÑÐµÐ½ÑÑÑ"), testList);
  }

}

<code block>


package org.languagetool.tokenizers.uk;

import java.util.Arrays;

import junit.framework.TestCase;

import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.tokenizers.SRXSentenceTokenizer;

public class UkrainianSRXSentenceTokenizerTest extends TestCase {

  private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer(new Ukrainian());

  public final void testTokenize() {
    testSplit("Ð¦Ðµ Ð¿ÑÐ¾Ñ?ÑÐµ ÑÐµÑÐµÐ½Ð½Ñ?.");
    testSplit("ÐÐ¾Ð½Ð¸ Ð¿ÑÐ¸ÑÑÐ°Ð»Ð¸ Ð² ÐÐ°ÑÐ¸Ð¶. ", "Ð?Ð»Ðµ ÑÐ°Ð¼ ÑÐ¼ Ð³ÐµÑÑ Ð½Ðµ Ñ?Ð¿Ð¾Ð´Ð¾Ð±Ð°Ð»Ð¾Ñ?Ñ?.");
    testSplit("ÐÐ°Ð½Ðº-ÑÐ¾Ðº â Ð½Ð°Ð¿ÑÑ?Ð¼ Ñ ÑÐ¾Ðº-Ð¼ÑÐ·Ð¸ÑÑ, ÑÐ¾ Ð²Ð¸Ð½Ð¸Ðº Ñ Ñ?ÐµÑÐµÐ´Ð¸Ð½Ñ 1970-Ñ ÑÑ. Ñ Ð¡Ð¨Ð? Ñ ÐÐµÐ»Ð¸ÐºÐ¾Ð±ÑÐ¸ÑÐ°Ð½ÑÑ.");
    testSplit("Ð Ð°Ð·Ð¾Ð¼ ÑÐ· Ð²ÑÐµÑÐ°Ð¼Ð¸, Ð²Ð¶Ðµ Ñ XV Ñ?Ñ. Ð¿Ð¾ÑÐ°Ñ?ÑÑÑÐ°Ð»Ð¸ Ð·Ð±ÑÐ¾Ð¹Ð½Ñ Ð²Ð¸Ñ?ÑÑÐ¿Ð¸ Ñ?ÐµÐ»Ñ?Ð½.");
    testSplit("Ð?Ð° Ð¿Ð¾ÑÐ°ÑÐ¾Ðº 1994 Ñ. Ð´ÐµÑÐ¶Ð°Ð²Ð½Ð¸Ð¹ Ð±Ð¾ÑÐ³ Ð£ÐºÑÐ°ÑÐ½Ð¸ Ñ?ÑÐ°Ð½Ð¾Ð²Ð¸Ð² 4,8 Ð¼Ð»ÑÐ´. Ð´Ð¾Ð».");
    testSplit("ÐÐ¸ÑÐ², Ð²ÑÐ». Ð¡Ð°Ð³Ð°Ð¹Ð´Ð°ÑÐ½Ð¾Ð³Ð¾, Ð±ÑÐ´. 43, ÐºÐ². 4.");
    testSplit("Ð?Ð°ÑÐ° Ð·ÑÑ?ÑÑÑÑ Ð· Ð?. ÐÐ°ÑÑÑÐºÐ¾Ð¼ Ñ Ð. Ð. Ð¢ÑÑÑ?ÐºÐ¾Ñ Ð²ÑÐ´Ð±ÑÐ»Ð°Ñ?Ñ? Ð² Ð³ÑÑÐ´Ð½Ñ Ð¼Ð¸Ð½ÑÐ»Ð¾Ð³Ð¾ ÑÐ¾ÐºÑ.");
    testSplit("Ð?Ð°ÑÐ° Ð·ÑÑ?ÑÑÑÑ Ð· Ð?.ÐÐ°ÑÑÑÐºÐ¾Ð¼ Ñ Ð.Ð.Ð¥Ð²Ð¸Ð»ÐµÑ Ð²ÑÐ´Ð±ÑÐ»Ð°Ñ?Ñ? Ð² Ð³ÑÑÐ´Ð½Ñ Ð¼Ð¸Ð½ÑÐ»Ð¾Ð³Ð¾ ÑÐ¾ÐºÑ.");
    testSplit("ÐÐ¾Ð¼ÐµÐ½Ð´Ð°Ð½Ñ Ð¿ÑÐµÐ¿Ð¾Ð´Ð¾Ð±Ð½Ð¸Ð¹ Ð¡.\u00A0ÐÐ¾ÐºÑÑÑÐ¼Ñ");
    testSplit("ÐÐ¾Ð¼ÐµÐ½Ð´Ð°Ð½Ñ Ð¿ÑÐµÐ¿Ð¾Ð´Ð¾Ð±Ð½Ð¸Ð¹ Ð¡.\u00A0Ð¡.\u00A0ÐÐ¾ÐºÑÑÑÐ¼Ñ 1.");
    testSplit("ÐÐ¾Ð¼ÐµÐ½Ð´Ð°Ð½Ñ Ð¿ÑÐµÐ¿Ð¾Ð´Ð¾Ð±Ð½Ð¸Ð¹ Ð¡.\u00A0Ð¡. ÐÐ¾ÐºÑÑÑÐ¼Ñ 2.");
    testSplit("Ð¡ÐºÐ»Ð°Ð´: Ð°ÐºÐ°Ð´. ÐÐµÑÐ½Ð°Ð´Ñ?ÑÐºÐ¸Ð¹, Ð¿ÑÐ¾Ñ. Ð¥Ð°ÑÑÐµÐ½ÐºÐ¾, Ð´Ð¾Ñ. Ð¡ÐµÐ¼ÐµÐ½Ñ?Ðº.");
    testSplit("ÐÐ¿ÐµÑÐ³ÑÑÐ¿Ð° Ð¿ÑÐ¸ÑÑÐ°Ð»Ð° Ð² Ñ?. ÐÑÑ?Ð¾Ð²Ðµ.");
    testSplit("300 Ñ. Ð´Ð¾ Ð½. Ðµ.");
    testSplit("Ð 300 Ñ. Ð´Ð¾ Ð½.Ðµ., Ñ Ð¿Ð¾ ÑÐµÐ¹ Ð´ÐµÐ½Ñ.");
    testSplit("ÐÑÐ¾Ð»ÑÑ?Ð¾Ðº (ÑÐ¾Ñ?. Ð¿ÑÐ¾Ð»ÐµÑ?Ð¾Ðº) â Ð¼Ð°Ð»ÐµÐ½ÑÐºÐ° ÐºÐ²ÑÑÐºÐ°.");
    testSplit("ÐÐ²ÑÑÐºÐ° Ð¦ÑÑ?Ð¸Ðº (Ð°Ð½Ð³Ð». Kvitka Cisyk ÑÐ°ÐºÐ¾Ð¶ Kacey Cisyk Ð²ÑÐ´ ÑÐ½ÑÑÑÐ°Ð»ÑÐ² Ð.Ð¡.); 4 ÐºÐ²ÑÑÐ½Ñ? 1953Ñ., ÐÐ²ÑÐ½Ð·, Ð?ÑÑ-ÐÐ¾ÑÐº â 29 Ð±ÐµÑÐµÐ·Ð½Ñ? 1998 Ñ., ÐÐ°Ð½Ð³ÐµÑÑÐµÐ½, Ð?ÑÑ-ÐÐ¾ÑÐº) â Ð°Ð¼ÐµÑÐ¸ÐºÐ°Ð½Ñ?ÑÐºÐ° Ñ?Ð¿ÑÐ²Ð°ÑÐºÐ° ÑÐºÑÐ°ÑÐ½Ñ?ÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾ÑÐ¾Ð´Ð¶ÐµÐ½Ð½Ñ?.");
    testSplit("ÐÐ¾ ÐÐ½Ñ?ÑÐ¸ÑÑÑÑ ÑÐ¼. ÐÐ»ÑÑÑÐ° Ð¿ÑÐ´'ÑÐ¶Ð´Ð¶Ð°Ñ ÑÐ¾ÑÐ½Ðµ Ð°Ð²ÑÐ¾."); 
    testSplit("ÐÐ¾ ÐÐ½Ñ?ÑÐ¸ÑÑÑÑ ÑÐ¼. Ð°ÐºÐ°Ð´. ÐÐµÑÐ½Ð°Ð´Ñ?ÑÐºÐ¾Ð³Ð¾."); 
    testSplit("ÐÐ¾ Ð²ÑÐ»Ð¸ÑÑ Ð³ÐµÑÑÐ¼Ð°Ð½Ð° Ð¡ÐºÐ¾ÑÐ¾Ð¿Ð°Ð´Ñ?ÑÐºÐ¾Ð³Ð¾ Ð¿ÑÐ´'ÑÐ¶Ð´Ð¶Ð°Ñ ÑÐ¾ÑÐ½Ðµ Ð°Ð²ÑÐ¾."); 
    testSplit("ÐÐ¾ ÑÐ°Ð±Ð¾ÑÑ Â«Ð?ÑÑÐµÐºÂ».");
    testSplit("Ð¡Ð¿ÑÐ»ÑÐ½Ñ Ð¿ÑÐ°Ð»ÑÐ½Ñ Ð¹ Ñ. Ð´.");
    testSplit("Ð¡Ð¿ÑÐ»ÑÐ½Ñ Ð¿ÑÐ°Ð»ÑÐ½Ñ Ð¹ Ñ. Ð´. Ð¹ Ñ. Ð¿.");
    testSplit("Ð´Ð¸Ð². Ñ?ÑÐ¾Ñ. 24.");
    testSplit("Ð.ÐÐ°ÐºÑÐ»ÑÐ½Ð°");
    testSplit("ÐÑÐ´ Ð°Ð½Ð³Ð».\n  File.");
    testSplit("ÐÑÐ´ ÑÑ.  \nparachute.");
    testSplit("Ð ÑÐ¸Ñ Ñ?Ð²ÑÑÐ»Ð¸Ñ Ð¿ÑÐ¾Ñ?ÑÐ¾ÑÐ¸Ñ Ð°Ð¿Ð°ÑÑÐ°Ð¼ÐµÐ½ÑÐ°Ñ...  Ð¼âÑ?ÐºÑ ÐºÑÑÑ?Ð»Ð°, ÐºÐ¸Ð»Ð¸Ð¼Ð¸, Ð´Ð¾ÑÐ¾Ð³Ñ Ñ?ÑÐ°ÑÑÐµÑÐºÐ¸");
    testSplit("(Ð²Ð¾Ð½Ð¸ Ñ?Ð°Ð¼Ñ ÑÐµ Ð²Ð¸Ð·Ð½Ð°Ð»Ð¸. - Ð ÐµÐ´.)");
    testSplit("ÐÑ?ÑÐ¾Ð³Ð¾ 33 ÑÐ¸Ñ?. 356 Ð¾Ñ?Ð¾Ð±Ð¸");
    testSplit("ÐÑ?ÑÐ¾Ð³Ð¾ 33 ÑÐ¸Ñ?. (Ð·Ð° Ñ?Ð»Ð¾Ð²Ð°Ð¼Ð¸ Ð¿ÑÐ¾ÑÐ°Ð±Ð°)");
    testSplit("Ð· Ñ?ÐºÐ¸Ñ Ð¿ÑÐ¸Ð±Ð»Ð¸Ð·Ð½Ð¾   1,2 ÑÐ¸Ñ?. â ÑÐ¾Ð»Ð¾Ð²ÑÐºÐ¸.");
    testSplit("Ð£ Ñ?. ÐÐ¸Ð¶Ð²Ð°");
    testSplit("ÐÐ½Ð¸Ð¶ÐºÐ° (Ñ?. 200)");
    testSplit("Ð¿Ð¾Ð·Ð½Ð°ÑÐµÐ½Ñ: Â«Ñ?. ÐÐ¸Ð¶Ð²Ð°Â»");
    testSplit("ÐÐ¸ÐºÐ¾Ð»Ð° ÐÐ°Ñ?ÑÐº (Ñ?. ÐÐ¾ÑÐ½ÑÑÐ½ÐºÐ¸, ÐÐ¾Ð»ÑÐ°Ð²Ñ?ÑÐºÐ° Ð¾Ð±Ð».)");
    testSplit("U.S. Marine");
    testSplit("B.B. King");
    testSplit("Ð¦ÐµÑÐºÐ²Ð° Ð¡Ð². ÐÑÑÐ° Ñ ÑÐµÑÐºÐ²Ð° Ñ?Ð². ÐÑÑÐ°");
  }
  
  public void testTokenizeWithSplit() {
    testSplit("ÐÑ?ÑÐ¾Ð³Ð¾ 33 ÑÐ¸Ñ?.", "Ð? Ð¼Ð¾Ð¶ÐµÐ¹ Ð¹ Ð±ÑÐ»ÑÑÐµ");
    testSplit("ÐÑ Ð±ÑÐ»Ð¾ 7,5 Ð¼Ð»Ð½.", "Ð ÐºÐ¾Ð¶Ð½Ð¾Ð³Ð¾ Ð±ÑÐ»Ð° Ñ?Ð¾ÑÐ¾ÑÐºÐ°.");
    testSplit("ÐÐ¾Ð²Ð¶Ð¸Ð½Ð¾Ñ 30 Ñ?. ", "ÐÐ¾ÑÑÐ°Ð»Ð¸.");
    testSplit("Ð¨Ð²Ð¸Ð´ÐºÑÑ?ÑÑ 30 Ð¼/Ñ?. ", "ÐÐ¾ÑÑÐ°Ð»Ð¸.");
    testSplit("ÐÑ?ÑÐ°Ð½Ð½Ñ 100 Ð¼. ", "Ð ÑÑÑ Ð²Ñ?Ðµ Ð¿ÑÐ¾Ð¿Ð°Ð»Ð¾.");
    testSplit("ÐÐ¾ÑÐ¸Ñ?Ð½Ð° Ð¿Ð»Ð¾ÑÐ° 67 ÑÐ¸Ñ?. ÐºÐ².  Ð¼. ", "Ð£ 1954 ÑÐ¾ÑÑ Ð½Ð°Ð´ ÐÐµÑÐ¶Ð¿ÑÐ¾Ð¼Ð¾Ð¼...");
    testSplit("Ð?Ð° 0,6Â°C. ", "Ð?Ð»Ðµ Ð¼Ð¸ Ð²Ñ?Ðµ Ð¼Ð°ÑÐ¼Ð¾."); 
    testSplit("Ð?Ð° 0,6Â°Ð¡. ", "Ð?Ð»Ðµ Ð¼Ð¸ Ð²Ñ?Ðµ Ð¼Ð°ÑÐ¼Ð¾."); 
    testSplit("Ð?Ð° 0,6 Â°C. ", "Ð?Ð»Ðµ Ð¼Ð¸ Ð²Ñ?Ðµ Ð¼Ð°ÑÐ¼Ð¾."); 
    testSplit("Ð?Ð° 0,6 Â°Ð¡. ", "Ð?Ð»Ðµ Ð¼Ð¸ Ð²Ñ?Ðµ Ð¼Ð°ÑÐ¼Ð¾."); 
    testSplit("ÐÑÐ¸ÑÑÐ°Ð² Ñ Ð¡Ð¨Ð?. ", "ÐÑÐ¾ÑÐµ Ð½Ð° Ð´ÑÑÐ³Ð¸Ð¹ ÑÑÐº.");
  }

  private void testSplit(final String... sentences) {
    TestTools.testSplit(sentences, stokenizer);
  }

}

<code block>

package org.languagetool.rules.uk;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;

import java.io.IOException;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;

import org.junit.Before;
import org.junit.Test;
import org.languagetool.AnalyzedSentence;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

public class TokenAgreementRuleTest {

  private JLanguageTool langTool;
  private TokenAgreementRule rule;

  @Before
  public void setUp() throws IOException {
    rule = new TokenAgreementRule(TestTools.getMessages("uk"));
    langTool = new JLanguageTool(new Ukrainian());
  }
  
  @Test
  public void testRule() throws IOException {

    
    assertEmptyMatch("Ð±ÐµÐ· Ð¿Ð¾Ð²Ð½Ð¾Ð³Ð¾");
    assertEmptyMatch("Ð±ÐµÐ· Ð½ÐµÐ±Ð°");

    assertEmptyMatch("Ð¿Ð¾ Ð°Ð²ÐµÐ½Ñ");

    assertEmptyMatch("ÑÐ¾ Ð·Ð° Ð³Ð°Ð½ÐµÐ±Ð½Ð° Ð½ÐµÐ¿Ð¾Ñ?Ð»ÑÐ´Ð¾Ð²Ð½ÑÑ?ÑÑ?");

    assertEmptyMatch("ÑÐ¾Ð´Ð¾ Ð²Ð»Ð°Ñ?Ð½Ðµ Ð»ÑÐ´Ð¸Ð½Ð¸");
    assertEmptyMatch("Ñ Ð·Ð°Ð³Ð°Ð»Ð¾Ð¼ Ñ?Ð¸Ð¼Ð¿Ð°ÑÐ¸ÑÐ½ÑÐ¹ Ð¿Ð¾Ð²ÑÑ?ÑÐ¸Ð½Ñ");

    assertEmptyMatch("Ð¿Ð¾Ð½Ð°Ð´ Ð¿Ð¾Ð»Ð¾Ð²Ð¸Ð½Ð° Ð»ÑÐ´ÐµÐ¹");
    assertEmptyMatch("Ð· Ð¿Ð¾Ð½Ð°Ð´ Ñ?ÑÐ° Ð»ÑÐ´ÐµÐ¹");

    assertEmptyMatch("Ð¿Ð¾ Ð½ÐµÑÐ²Ð°Ñ");
    assertEmptyMatch("Ð· Ð¾Ñ?Ð¾Ð±Ð»Ð¸Ð²Ð¾Ñ ÑÐ²Ð°Ð³Ð¾Ñ");

    assertEmptyMatch("ÑÐ¾Ð´Ð¾ Ð±Ð¾Ð´Ð°Ð¹ Ð³ÑÐ¿Ð¾ÑÐµÑÐ¸ÑÐ½Ð¾Ñ Ð·Ð´Ð°ÑÐ½Ð¾Ñ?ÑÑ");
    assertEmptyMatch("ÑÑÐ¾ ÑÐ´Ðµ Ð½Ð° Ð·Ð°ÑÐ¾Ð±ÑÑÐºÐ¸ Ð·Ð° ÐºÐ¾ÑÐ´Ð¾Ð½");

    assertEmptyMatch("Ð¿ÑÑÐ¸ Ð² Ð¿ÑÐµÐ·Ð¸Ð´ÐµÐ½ÑÐ¸");
    assertEmptyMatch("Ð¿ÑÑÐ¸ Ð¼ÐµÐ¶Ñ Ð»ÑÐ´Ð¸");

    assertEmptyMatch("ÑÐ¾ ÑÐ¾ Ð±ÑÐ»Ð° Ð·Ð° Ð»ÑÐ´Ð¸Ð½Ð°");
    assertEmptyMatch("ÑÐ¾ Ð·Ð° Ð»ÑÐ´Ð¸Ð½Ð°");
    assertEmptyMatch("ÑÐ¾ Ð±Ð°Ð»Ð¾ÑÑÐ²Ð°Ð²Ñ?Ñ? Ð·Ð° ÑÑÐ¼ Ð¾ÐºÑÑÐ³Ð¾Ð¼");

    assertEmptyMatch("Ð½Ð° Ð´Ð¾Ð¼Ñ");

    assertEmptyMatch("Ð¾ÐºÑÑÐ¼ Ñ?Ðº ÑÐºÑÐ°ÑÐ½ÑÑ");
    assertEmptyMatch("Ð·Ð° Ð´Ð²ÑÑ?ÑÑ Ð¼ÐµÑÑÑÐ²");
    assertEmptyMatch("Ð¿ÐµÑÐµÑÐ¾Ð´Ð¸ÑÑ Ñ Ð¤ÑÑÐ´ÑÑÑ Ð¨ÑÑÐ°Ñ?Ñ?Ðµ");
    assertEmptyMatch("Ð²ÑÐ´ Ð¼ÑÐ½ÑÑ? 1 Ð´Ð¾ Ð¿Ð»ÑÑ? 1");
    assertEmptyMatch("Ð´Ð¾ Ð¼ÑÐ½ÑÑ? Ñ?Ð¾ÑÐ¾ÐºÐ° Ð³ÑÐ°Ð´");
    assertEmptyMatch("Ð´Ð¾ Ð¼ÑÐ½ÑÑ? ÑÑÑ?ÑÐ´ÐµÑ?Ñ?ÑÐ¸");
    assertEmptyMatch("ÑÐµÑÐµÐ· ÑÐ¾ÐºÑÐ² 10");
    assertEmptyMatch("Ð½Ð° ÑÐ²Ð¸Ð»Ð¸Ð½ 9-10");
    assertEmptyMatch("Ñ?Ð¿ÑÐ²Ð¿ÑÐ°ÑÑÐ²Ð°ÑÐ¸ ÑÐ· Ñ?Ð¾Ð±Ñ Ð¿Ð¾Ð´ÑÐ±Ð½Ð¸Ð¼Ð¸");
    assertEmptyMatch("ÑÐµÑÐµÐ· ÑÑ?ÑÐ¼ Ð²ÑÐ´Ð¾Ð¼Ñ Ð¿ÑÐ¸ÑÐ¸Ð½Ð¸");
    assertEmptyMatch("ÑÐµÑÐµÐ· Ð½ÑÐºÐ¾Ð¼Ñ Ð½Ðµ Ð²ÑÐ´Ð¾Ð¼Ñ Ð¿ÑÐ¸ÑÐ¸Ð½Ð¸");
    assertEmptyMatch("Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸ Ð´Ð¾ ÐÐ?Ð¢ Â«ÐÑÐ¸Ð²Ð¸Ð¹ Ð ÑÐ³ ÑÐµÐ¼ÐµÐ½ÑÂ»");
    assertEmptyMatch("Ð²ÑÐ´ Ð? Ð´Ð¾ Ð¯");
    assertEmptyMatch("Ð´Ð¾ ÑÐ° Ð¿ÑÑ?Ð»Ñ?");
    assertEmptyMatch("Ð´Ð¾ Ñ?ÑÑÐ´ Ñ?Ð¾Ð½ÑÑ?");
    assertEmptyMatch("Ð· ÑÐ°Ð½Ð° Ð´Ð¾ Ð²ÐµÑÐ¾ÑÐ°, Ð²ÑÐ´ ÑÐ°Ð½Ð° Ð´Ð¾ Ð½Ð¾ÑÑ");
    assertEmptyMatch("Ð´Ð¾ Ð?Ð?Ð Â«Ð?Ð°Ð´ÑÐ° Ð£ÐºÑÐ°ÑÐ½Ð¸Â»");
    assertEmptyMatch("Ð¿ÑÐ¸Ð·Ð²ÑÐ² Ð´Ð¾ Ð·Ð½Ð°ÑÐ½Ð¾Ñ Ð¼ÑÑÐ¾Ñ Ð´ÐµÐ¼Ð¾ÐºÑÐ°ÑÐ¸ÑÐ½Ð¾Ð³Ð¾ Ñ?ÐµÑÐµÐ´Ð½ÑÐ¾Ð³Ð¾ ÐºÐ»Ð°Ñ?Ñ");
    assertEmptyMatch("ÐÐ¾Ð½Ð¸ Ð·Ð°Ð¼ÑÑ?ÑÑ Ð?Ð½Ð´ÑÑÐ¹ Ð²Ð¸Ð±ÑÐ°Ð»Ð¸ Ð®ÑÑÐ¹");
    assertEmptyMatch("Ð½Ð° Ð¼Ð¾ÑÐ¾Ð¼ Ñ?ÑÐµÐ»ÐµÐ½Ð¾Ð¼Ñ Ð´Ð½Ñ");
    assertEmptyMatch("ÑÐ°Ñ? Ð²ÑÐ´ ÑÐ°Ñ?Ñ Ð½Ð°Ð¼ Ð´Ð¾Ð²Ð¾Ð´Ð¸Ð»Ð¾Ñ?Ñ");
    assertEmptyMatch("Ñ?ÐºÐ¸Ð¹ Ð´Ð¾ ÑÐµÑÑ Ð²Ð¾Ð½Ð¸ Ð¿ÑÐ¸Ñ?Ñ?Ð³Ð°Ð»Ð¸Ñ?Ñ?");
    assertEmptyMatch("Ð½Ñ Ð´Ð¾ ÑÐ¾Ð³Ð¾ Ð´Ð¾Ð±ÑÐ¾Ð³Ð¾ Ñ?Ð¸Ð»Ð¾Ð²Ñ Ð´ÑÑ Ð½Ðµ Ð¿ÑÐ¸Ð·Ð²ÐµÐ´ÑÑÑ");


    assertEquals(1, rule.match(langTool.getAnalyzedSentence("Ð¿ÑÐ¸Ð·Ð²ÑÐ² Ð´Ð¾ Ð·Ð½Ð°ÑÐ½Ð¾Ñ Ð¼ÑÑÐ¾Ñ Ð´ÐµÐ¼Ð¾ÐºÑÐ°ÑÐ¸ÑÐ½Ð¾Ð¼Ñ Ñ?ÐµÑÐµÐ´Ð½ÑÐ¾Ð¼Ñ ÐºÐ»Ð°Ñ?Ñ")).length);




    
    

    RuleMatch[] matches = rule.match(langTool.getAnalyzedSentence("Ð±ÐµÐ· Ð½ÐµÐ±Ñ"));
    
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("Ð½ÐµÐ±Ð°"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð½Ðµ Ð² Ð¾Ñ?ÑÐ°Ð½Ð½Ñ ÑÐµÑÐ³Ñ ÑÐµÑÐµÐ·    ÐºÐ¾ÑÑÐ¿ÑÑÑÑ, Ð¼ÑÐ¶ÑÐµÐ»ÑÐ³ÑÐ¹Ð½Ñ Ð²Ð¾ÑÐ¾Ð¶Ð½ÐµÑÑ"));
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("Ð¿Ð¾ Ð½ÐµÑÐ²Ð°Ð¼"));
    
    assertEquals(1, matches.length);
    assertEquals(3, matches[0].getFromPos());
    assertEquals(9, matches[0].getToPos());
    assertEquals(Arrays.asList("Ð½ÐµÑÐ²Ð°Ñ", "Ð½ÐµÑÐ²Ð¸"), matches[0].getSuggestedReplacements());
    
    assertEquals(1, rule.match(langTool.getAnalyzedSentence("Ð² Ð¿'Ñ?ÑÑÐ¾Ð¼ Ð»ÑÐ´Ñ?Ð¼")).length);
    assertEquals(1, rule.match(langTool.getAnalyzedSentence("Ð² Ð¿Ð¾Ð½Ð°Ð´ Ð¿'Ñ?ÑÑÐ¾Ð¼ Ð»ÑÐ´Ñ?Ð¼")).length);

    AnalyzedSentence analyzedSentence = langTool.getAnalyzedSentence("Ð·Ð°Ð²Ð´Ñ?ÐºÐ¸ ÑÑ Ð²Ð´Ð°Ð»Ð¸Ð¼ ÑÑÑÐºÐ°Ð¼");
    RuleMatch[] match = rule.match(analyzedSentence);
    assertEquals(1, match.length);
    List<String> suggestedReplacements = match[0].getSuggestedReplacements();
    assertTrue("Did not find Â«ÑÑÐ½ÑÐ¹Â»: " + suggestedReplacements, suggestedReplacements.contains("ÑÑÐ½ÑÐ¼"));

    analyzedSentence = langTool.getAnalyzedSentence("Ð Ð´ÑÐ²ÑÐ¸Ð½Ð°!");
    match = rule.match(analyzedSentence);
    assertEquals(1, match.length);
    suggestedReplacements = match[0].getSuggestedReplacements();
    assertTrue("Did not find ÐºÐ»Ð¸ÑÐ½Ð¸Ð¹ Â«Ð´ÑÐ²ÑÐ¸Ð½Ð¾Â»: " + suggestedReplacements, suggestedReplacements.contains("Ð´ÑÐ²ÑÐ¸Ð½Ð¾"));

    matches = rule.match(langTool.getAnalyzedSentence("Ð¿Ð¾ ÑÐµÑÐºÐ¾Ð²Ð½Ð¸Ð¼ ÐºÐ°Ð½Ð¾Ð½Ð°Ð¼"));
    
    assertEquals(1, matches.length);

    
    assertEmptyMatch("Ð½Ð° ÐÑÐ¿Ð°Ð»Ð°");
    assertEmptyMatch("Ð½Ð° Ð¯Ð²Ð´Ð¾ÑÐ¸");
    
    assertEmptyMatch("Ð½Ð° ÐÐ°Ð·ÐµÐ¿Ð¸");
    assertEmptyMatch("Ð½Ð° ÐÑÐ»ÑÑÐ¸ÑÑÐºÐ¾Ñ");
    assertEmptyMatch("Ð½Ð° ÐÑÐ°Ð²Ð´Ð¸");
    assertEmptyMatch("Ð½Ð° ÐÐ¾Ð¼Ð¾Ð½Ð¾Ñ?Ð¾Ð²Ð°");
    
    assertEmptyMatch("Ñ?Ðº Ð½Ð° ÐÑÑÐ¼Ð¸ ÑÐ¼ÐµÐ½Ð¸Ð½Ð¸");

    assertEmptyMatch("Ñ?Ð¿Ð¸ÑÐ°Ð»Ð¾Ñ?Ñ? Ð½Ð° Ð¼ÑÑ?Ñ?ÑÐ½Ð¾Ñ Ð´Ð°Ð²Ð½Ð¸Ð½Ð¸ ÑÑÑÐµÐ½Ð½Ñ?");
    assertEmptyMatch("Ð?Ð° Ñ?ÐµÑÐµÐ´Ð½ÑÐ¾Ñ Ð´Ð¾Ð²Ð¶Ð¸Ð½Ð¸ ÑÑÐ±Ñ");

    matches = rule.match(langTool.getAnalyzedSentence("Ñ?Ð¿Ð¸ÑÐ°Ð»Ð¾Ñ?Ñ? Ð½Ð° Ð¼ÑÑ?Ñ?ÑÐ½Ð¾Ñ Ð´Ð°Ð²Ð½Ð¸Ð½Ð¸ ÑÑÑÐµÐ½Ð½Ñ?Ð¼"));
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("ÐÑÐ´ Ñ?ÑÑ?Ð³Ñ Ð?ÑÐ°ÑÑÑÐºÐ° Ð´Ð¾ Ð¿ÑÑÐ°ÑÑ?ÑÐºÐ¾Ð³Ð¾ Ð¿ÑÐ°Ð¿Ð¾ÑÑ"));
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("Ð·Ð³ÑÐ´Ð½Ð¾ Ð· Ð´Ð¾ÐºÑÐ¼ÐµÐ½ÑÐ°"));
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("Ð·Ð°ÑÑÐºÐ°Ð²Ð»ÐµÐ½Ð¸Ñ Ñ Ð²Ð¸ ÐºÐ¾ÑÐ¸Ñ?ÑÐ°Ð½Ð½Ñ"));
    assertEquals(1, matches.length);






    matches = rule.match(langTool.getAnalyzedSentence("Ð Ð¹Ð¾Ð¼Ñ Ð·Ð°Ð³ÑÐ°Ð»Ð° ÐºÑÐ¾Ð²."));
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("  Ð Ð¹Ð¾Ð¼Ñ Ð·Ð°Ð³ÑÐ°Ð»Ð° ÐºÑÐ¾Ð²."));
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("Ð Ð¾Ñ Â«Ð Ð¹Ð¾Ð¼Ñ Ð·Ð°Ð³ÑÐ°Ð»Ð° ÐºÑÐ¾Ð²Â»."));
    assertEquals(1, matches.length);

    assertEmptyMatch("Ð³ÐµÐ¿Ð°ÑÐ¸ÑÑÐ² Ð ÑÐ° Ð¡");
    
    matches = rule.match(langTool.getAnalyzedSentence("â Ð Ð¿Ð°Ð½ ÐÐ·ÑÑ?, Ð·Ð°ÑÐ¸Ñ?ÑÐ¸ ÑÑ!"));
    assertEquals(1, matches.length);
    
    matches = rule.match(langTool.getAnalyzedSentence("Ð?Ð° ÑÐ¾ÑÐ¾: Ð ÐÐ¾Ð»Ð»ÑÐ²ÑÐ´Ñ Ð¯ÑÐ¸Ð½ÐºÐ° Ð¨ÑÑ?Ñ Ð¿ÑÐ¸Ð²ÐµÐ·Ð»Ð° Ð´Ð²Ñ Ð·Ð¾Ð»Ð¾ÑÑ Ð¼ÐµÐ´Ð°Ð»Ñ"));
    assertEquals(1, matches.length);
  }

  private void assertEmptyMatch(String text) throws IOException {
    assertEquals(Collections.<RuleMatch>emptyList(), Arrays.asList(rule.match(langTool.getAnalyzedSentence(text))));
  }
  
  @Test
  public void testSpecialChars() throws IOException {
    TokenAgreementRule rule = new TokenAgreementRule(TestTools.getMessages("uk"));

    JLanguageTool langTool = new JLanguageTool(new Ukrainian());

    RuleMatch[] matches = rule.match(langTool.getAnalyzedSentence("Ð¿Ð¾ Ð½ÐµÌ?ÑÐ²Ð°Ð¼, Ð¿Ð¾ Ð¼Ð¾\u00ADÑ?ÑÐ°Ð¼, Ð¿Ð¾ Ð²Ð¾ÑÐ¾ÑÐ°Ð¼"));
    
    assertEquals(3, matches.length);

    assertEmptyMatch("Ð´Ð¾ ÑÐ¼ Ð¿Ð¾Ð´Ñ\u00ADÐ±Ð½Ð¸Ñ");

    assertEquals(3, matches[0].getFromPos());
    assertEquals(10, matches[0].getToPos());
    assertEquals(Arrays.asList("Ð½ÐµÑÐ²Ð°Ñ", "Ð½ÐµÑÐ²Ð¸"), matches[0].getSuggestedReplacements());


    assertEquals(15, matches[1].getFromPos());
    assertEquals(Arrays.asList("Ð¼Ð¾Ñ?ÑÐ°Ñ", "Ð¼Ð¾Ñ?ÑÐ¸"), matches[1].getSuggestedReplacements());


    assertEquals(27, matches[2].getFromPos());
    assertEquals(Arrays.asList("Ð²Ð¾ÑÐ¾ÑÐ°Ñ", "Ð²Ð¾ÑÐ¾ÑÐ°"), matches[2].getSuggestedReplacements());
  }

}

<code block>

package org.languagetool.rules.uk;

import java.io.IOException;
import java.util.Arrays;
import java.util.Collections;

import org.junit.Before;
import org.junit.Test;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

import static org.junit.Assert.assertEquals;

public class UkrainianWordRepeatRuleTest {
  
  private JLanguageTool langTool;
  private UkrainianWordRepeatRule rule;

  @Before
  public void setUp() throws IOException {
    langTool = new JLanguageTool(new Ukrainian());
    rule = new UkrainianWordRepeatRule(TestTools.getMessages("uk"), langTool.getLanguage());
  }
  
  @Test
  public void testRule() throws IOException {
    assertEmptyMatch("Ð±ÐµÐ· Ð¿Ð¾Ð²Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð·ÑÐ°ÑÑÐ½ÐºÑ");
    assertEmptyMatch("Ð±ÐµÐ· Ð±ÑÐ³ÑÐ¼Ð° Ð±ÑÐ³ÑÐ¼Ð°");
    assertEmptyMatch("Ð±ÐµÐ· 100 100");
    assertEmptyMatch("1.30 3.20 3.20");
    assertEmptyMatch("ÑÐµ Ð² Ð.ÐÐ°Ð½Ð´Ð¸Ð½Ñ?ÑÐºÐ¾Ð³Ð¾");
    assertEmptyMatch("ÐÑÐ´ Ð´Ð¾Ð±ÑÐ° Ð´Ð¾Ð±ÑÐ° Ð½Ðµ ÑÑÐºÐ°ÑÑÑ.");
    assertEmptyMatch("Ð©Ð¾ ÑÐ¾, Ð° ÐºÑÐ½Ð¾ Ð² Ð£ÐºÑÐ°ÑÐ½Ñ...");
    assertEmptyMatch("ÐÑÐ´Ð¿Ð¾Ð²ÑÐ´Ð½Ð¾ Ð´Ð¾ Ñ?Ñ. Ñ?Ñ. 3, 7, 18.");

    assertEquals(1, rule.match(langTool.getAnalyzedSentence("Ð±ÐµÐ· Ð±ÐµÐ· Ð¿Ð¾Ð²Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð·ÑÐ°ÑÑÐ½ÐºÑ")).length);
    RuleMatch[] match = rule.match(langTool.getAnalyzedSentence("ÐÐµÑÑÐ¾Ð²Ð½Ð¾Ñ Ð Ð°Ð´Ð¸ Ð Ñ ÐÐ Ñ?ÐºÐ»Ð¸ÐºÐ°Ð½Ñ"));
    assertEquals(1, match.length);
    assertEquals(2, match[0].getSuggestedReplacements().size());
  }

  private void assertEmptyMatch(String text) throws IOException {
    assertEquals(text, Collections.<RuleMatch>emptyList(), Arrays.asList(rule.match(langTool.getAnalyzedSentence(text))));
  }

}

<code block>

package org.languagetool.rules.uk;

import org.junit.Test;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

import java.io.IOException;
import java.util.Arrays;

import static org.junit.Assert.assertEquals;

public class MixedAlphabetsRuleTest {

  @Test
  public void testRule() throws IOException {
    final MixedAlphabetsRule rule = new MixedAlphabetsRule(TestTools.getMessages("uk"));
    final JLanguageTool langTool = new JLanguageTool(new Ukrainian());

    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("Ñ?Ð¼ÑÑÑÑ?")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("not mixed")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("123454")).length);

    

    RuleMatch[] matches = rule.match(langTool.getAnalyzedSentence("Ñ?Ð¼iÑÑÑ?"));  
    
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("Ñ?Ð¼ÑÑÑÑ?"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("mÑÑed"));  

    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("mixed"), matches[0].getSuggestedReplacements());
    
    matches = rule.match(langTool.getAnalyzedSentence("XÐ")); 

    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("XI"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð¥I")); 

    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("XI"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð¥Ð")); 

    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("XI"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð©ÐµÐ¿Ð»ÐµÐ½Ð½Ñ? Ð²ÑÐ´ Ð³ÐµÐ¿Ð°ÑÐ¸ÑÑ Ð.")); 
    assertEquals(1, matches.length);
    assertEquals("B", matches[0].getSuggestedReplacements().get(0));

    matches = rule.match(langTool.getAnalyzedSentence("Ð³ÑÑÐ¿Ð° Ð?")); 
    assertEquals(1, matches.length);
    assertEquals("A", matches[0].getSuggestedReplacements().get(0));
    
    matches = rule.match(langTool.getAnalyzedSentence("Ð?Ð° 0,6Â°Ð¡.")); 
    assertEquals(1, matches.length);
    assertEquals("0,6Â°C", matches[0].getSuggestedReplacements().get(0));
  }

}

<code block>


package org.languagetool.rules.uk;

import junit.framework.TestCase;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

import java.io.IOException;
import java.util.Arrays;


public class SimpleReplaceRuleTest extends TestCase {

  public void testRule() throws IOException {
    SimpleReplaceRule rule = new SimpleReplaceRule(TestTools.getEnglishMessages());

    RuleMatch[] matches;
    JLanguageTool langTool = new JLanguageTool(new Ukrainian());

    
    matches = rule.match(langTool.getAnalyzedSentence("Ð¦Ñ ÑÑ?Ð´ÐºÐ¸ Ð¿Ð¾Ð²Ð¸Ð½Ð½Ñ Ð·Ð±ÑÐ³Ð°ÑÐ¸Ñ?Ñ?."));
    assertEquals(0, matches.length);

    
    matches = rule.match(langTool.getAnalyzedSentence("Ð¦Ñ ÑÑ?Ð´ÐºÐ¸ Ð¿Ð¾Ð²Ð¸Ð½Ð½Ñ Ñ?Ð¿ÑÐ²Ð¿Ð°Ð´Ð°ÑÐ¸."));
    assertEquals(1, matches.length);
    assertEquals(2, matches[0].getSuggestedReplacements().size());
    assertEquals(Arrays.asList("Ð·Ð±ÑÐ³Ð°ÑÐ¸Ñ?Ñ?", "Ñ?ÑÐ¾Ð´Ð¸ÑÐ¸Ñ?Ñ?"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð?Ð°Ð¿Ð°Ð´Ð°ÑÑÐ¸Ð¹"));
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("Ð?Ð°Ð¿Ð°Ð´Ð½Ð¸Ðº", "Ð?Ð°Ð¿Ð°Ð´Ð°Ð»ÑÐ½Ð¸Ð¹", "Ð?Ð°Ð¿Ð°Ð´Ð½Ð¸Ð¹"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð?Ð°Ð¿Ð°Ð´Ð°ÑÑÐ¾Ð³Ð¾"));
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("Ð?Ð°Ð¿Ð°Ð´Ð½Ð¸Ðº", "Ð?Ð°Ð¿Ð°Ð´Ð°Ð»ÑÐ½Ð¸Ð¹", "Ð?Ð°Ð¿Ð°Ð´Ð½Ð¸Ð¹"), matches[0].getSuggestedReplacements());

    
    matches = rule.match(langTool.getAnalyzedSentence("Ð²ÑÐ´Ð¾Ð±ÑÐ°Ð¶Ð°ÑÑÑÑ?Ñ?"));
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("Ð¿Ð¾ÐºÐ°Ð·ÑÐ²Ð°ÑÐ¸Ñ?Ñ?", "Ð·Ð¾Ð±ÑÐ°Ð¶Ð°ÑÐ¸Ñ?Ñ?", "Ð²ÑÐ´Ð±Ð¸Ð²Ð°ÑÐ¸Ñ?Ñ?"), matches[0].getSuggestedReplacements());

    
    matches = rule.match(langTool.getAnalyzedSentence("ÑÐµÐ´ÑÐ¾ÑÐ°"));
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("ÑÐµÐ´ÑÑÑ?ÑÑ", "Ð³Ð¾Ð¹Ð½ÑÑ?ÑÑ", "ÑÐµÐ´ÑÐ¸Ð½Ñ?"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("ÑÐµÐ´ÑÐ¾ÑÐ¸"));
    assertEquals(0, matches.length);
  }
}

<code block>

package org.languagetool.rules.uk;

import static org.junit.Assert.assertEquals;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;

import org.junit.Test;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

public class MorfologikUkrainianSpellerRuleTest {

  @Test
  public void testMorfologikSpeller() throws IOException {
    MorfologikUkrainianSpellerRule rule = new MorfologikUkrainianSpellerRule (TestTools.getMessages("uk"), new Ukrainian());

    JLanguageTool langTool = new JLanguageTool(new Ukrainian());

    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐÐ¾ Ð²Ð°Ñ? Ð¿ÑÐ¸Ð¹Ð´Ðµ Ð·Ð°Ð²Ð²ÑÐ´Ð´ÑÐ»Ñ!")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence(",")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("123454")).length);

    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐÐ¾ Ð½Ð°Ñ? Ð¿ÑÐ¸ÑÐ´Ðµ The Beatles!")).length);

    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("Ð¿ÑÑ?\u00ADÐ½Ñ")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("Ð¿ÑÑ?\u00ADÐ½Ñ Ð¿ÑÑ?\u00ADÐ½Ñ")).length);
    
    
    

    RuleMatch[] matches = rule.match(langTool.getAnalyzedSentence("Ð°ÑÐ°ÐºÑÑÑÐ¸Ð¹"));
    
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("ÑÐºÐ»Ñ?Ð½Ð¸Ð¹"));

    assertEquals(1, matches.length);
    assertEquals("Ñ?ÐºÐ»Ñ?Ð½Ð¸Ð¹", matches[0].getSuggestedReplacements().get(0));

    assertEquals(0, rule.match(langTool.getAnalyzedSentence("Ð°")).length);

    
    matches = rule.match(langTool.getAnalyzedSentence("Ð¿ÑÐ¸Ð¹Ð´ÐµÑÐ½iÐ¹"));   

    assertEquals(1, matches.length);
    assertEquals("Ð¿ÑÐ¸Ð¹Ð´ÐµÑÐ½ÑÐ¹", matches[0].getSuggestedReplacements().get(0));

    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐÐ°ÐºÐµÑ Ð±ÑÐ² Ñ?Ð¸Ð½ÑÐ¾-Ð¶Ð¾Ð²ÑÐ¾Ð³Ð¾ ÐºÐ¾Ð»ÑÐ¾ÑÑ")).length);

    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐÑÐ½ Ð±Ð°Ð³Ð°ÑÐ¾ Ñ?Ð¸Ð´ÑÐ² Ð½Ð° ÑÐ½ÑÐµÑÐ½ÐµÑ-ÑÐ¾ÑÑÐ¼Ð°Ñ")).length);

    assertEquals(1, rule.match(langTool.getAnalyzedSentence("ÐÑÐ½ Ð±Ð°Ð³Ð°ÑÐ¾ Ñ?Ð¸Ð´ÑÐ² Ð½Ð° ÑÐ½ÑÐµÑÐ¼ÐµÑ-ÑÐ¾ÑÑÐ¼Ð°Ñ")).length);

    
    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐµÐºÑ?-ÐºÑÐµÐ²ÐµÑÐºÐ°")).length);

    assertEquals(1, rule.match(langTool.getAnalyzedSentence("Ð±Ð°Ð½Ð´-ÑÐ¾ÑÐ¼ÑÐ²Ð°Ð½Ð½Ñ?.")).length);


    

    RuleMatch[] match = rule.match(langTool.getAnalyzedSentence("Ð§Ð¸ÑÐ°Ð½Ð½Ñ? Ð²ÑÑÑÑÐ² Ð¢.Ð.Ð¨ÐµÐ²ÑÐµÐ½ÐºÐ¾ Ñ Ð.Ð¢ÑÑÑÐ½Ð½Ð¸ÐºÐ°"));
    assertEquals(new ArrayList<RuleMatch>(), Arrays.asList(match));

    match = rule.match(langTool.getAnalyzedSentence("Ð§Ð¸ÑÐ°Ð½Ð½Ñ? Ð²ÑÑÑÑÐ² Ð¢. Ð. Ð¨ÐµÐ²ÑÐµÐ½ÐºÐ¾ Ñ Ð. Ð¢ÑÑÑÐ½Ð½Ð¸ÐºÐ°"));
    assertEquals(new ArrayList<RuleMatch>(), Arrays.asList(match));

    match = rule.match(langTool.getAnalyzedSentence("Ð?Ð½Ð³Ð»ÑÌ?Ð¹Ñ?ÑÐºÐ° Ð¼Ð¾Ð²Ð° (Ð°Ð½Ð³Ð». English language, English) Ð½Ð°Ð»ÐµÐ¶Ð¸ÑÑ Ð´Ð¾ Ð³ÐµÑÐ¼Ð°Ð½Ñ?ÑÐºÐ¾Ñ Ð³ÑÑÐ¿Ð¸"));
    assertEquals(new ArrayList<RuleMatch>(), Arrays.asList(match));

    match = rule.match(langTool.getAnalyzedSentence("Ð?Ð½Ð³Ð»ÑÌ?Ð¹Ñ?ÑÐºÐ° Ð¼Ð¾Ð²Ð° (Ð°Ð½Ð³Ð» English language, English) Ð½Ð°Ð»ÐµÐ¶Ð¸ÑÑ Ð´Ð¾ Ð³ÐµÑÐ¼Ð°Ð½Ñ?ÑÐºÐ¾Ñ Ð³ÑÑÐ¿Ð¸"));
    assertEquals(1, match.length);

  
    match = rule.match(langTool.getAnalyzedSentence("100 ÑÐ¸Ñ?. Ð³ÑÐ¸Ð²ÐµÐ½Ñ"));
    assertEquals(new ArrayList<RuleMatch>(), Arrays.asList(match));

    match = rule.match(langTool.getAnalyzedSentence("100 ÐºÐ². Ð¼"));
    assertEquals(new ArrayList<RuleMatch>(), Arrays.asList(match));

    match = rule.match(langTool.getAnalyzedSentence("100 ÐºÐ² Ð¼"));
    assertEquals(1, Arrays.asList(match).size());
  }

}

<code block>
package org.languagetool.tagging.uk;

import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.jetbrains.annotations.Nullable;
import org.languagetool.AnalyzedToken;
import org.languagetool.AnalyzedTokenReadings;


public class PosTagHelper {
  private static final Pattern GENDER_REGEX = Pattern.compile("(noun|adjp?|numr):(.):v_.*");
  private static final Pattern GENDER_CONJ_REGEX = Pattern.compile("(noun|adjp?|numr):(.:v_...).*");

  private PosTagHelper() {
  }
  
  @Nullable
  public static String getGender(String posTag) {
    Matcher pos4matcher = GENDER_REGEX.matcher(posTag);
    if( pos4matcher.matches() ) {
      return pos4matcher.group(2);
    }

    return null;
  }

  @Nullable
  public static String getNum(String posTag) {
    Matcher pos4matcher = Pattern.compile("(noun|adjp?|numr):(.):v_.*").matcher(posTag);
    if( pos4matcher.matches() ) {
      String group = pos4matcher.group(2);
      if( ! group.equals("p") ) {
        group = "s";
      }
      return group;
    }
  
    return null;
  }

  @Nullable
  public static String getConj(String posTag) {
    Matcher pos4matcher = Pattern.compile("(noun|adjp?|numr):[mfnp]:(v_...).*").matcher(posTag);
    if( pos4matcher.matches() )
      return pos4matcher.group(2);
  
    return null;
  }

  @Nullable
  public static String getGenderConj(String posTag) {
    Matcher pos4matcher = GENDER_CONJ_REGEX.matcher(posTag);
    if( pos4matcher.matches() )
      return pos4matcher.group(2);

    return null;
  }

  public static boolean hasPosTag(AnalyzedTokenReadings analyzedTokenReadings, String posTagRegex) {
    for(AnalyzedToken analyzedToken: analyzedTokenReadings) {
      if( hasPosTag(analyzedToken, posTagRegex) )
        return true;
    }
    return false;
  }

  public static boolean hasPosTag(AnalyzedToken analyzedToken, String posTagRegex) {
    String posTag = analyzedToken.getPOSTag();
    return posTag != null && posTag.matches(posTagRegex);
  }














}

<code block>

package org.languagetool.tagging.uk;

import java.io.BufferedWriter;
import java.io.IOException;
import java.io.InputStream;
import java.nio.charset.Charset;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.Scanner;
import java.util.Set;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.jetbrains.annotations.Nullable;
import org.languagetool.AnalyzedToken;
import org.languagetool.JLanguageTool;
import org.languagetool.tagging.BaseTagger;
import org.languagetool.tagging.TaggedWord;
import org.languagetool.tagging.WordTagger;


public class UkrainianTagger extends BaseTagger {

  public static final Map<String, String> VIDMINKY_MAP;

  private static final String NV_TAG = ":nv";
  private static final String COMPB_TAG = ":compb";

  private static final Pattern EXTRA_TAGS = Pattern.compile("(:(v-u|np|ns|bad|slang|rare))+");

  private static final String DEBUG_COMPOUNDS_PROPERTY = "org.languagetool.tagging.uk.UkrainianTagger.debugCompounds";
  private static final String TAG_ANIM = ":anim";
  
  private static final Pattern MNP_NAZ_REGEX = Pattern.compile(".*:[mnp]:v_naz.*");
  private static final Pattern MNP_ZNA_REGEX = Pattern.compile(".*:[mnp]:v_zna.*");
  private static final Pattern MNP_ROD_REGEX = Pattern.compile(".*:[mnp]:v_rod.*");
  private static final Pattern NOUN_SING_V_ROD_REGEX = Pattern.compile("noun:[mfn]:v_rod.*");
  private static final Pattern NOUN_V_NAZ_REGEX = Pattern.compile("noun:.:v_naz.*");
  private static final Pattern SING_REGEX_F = Pattern.compile(":[mfn]:");
  private static final Pattern O_ADJ_PATTERN = Pattern.compile(".*(Ð¾|[ÑÑÑ]Ðµ)");
  


  private static final String ADJ_TAG_FOR_PO_ADV_MIS = IPOSTag.adj.getText() + ":m:v_mis";
  private static final String ADJ_TAG_FOR_PO_ADV_NAZ = IPOSTag.adj.getText() + ":m:v_naz";
  
  private static final Pattern NUMBER = Pattern.compile("[+-Â±]?[â¬â´\\$]?[0-9]+(,[0-9]+)?([-ââ][0-9]+(,[0-9]+)?)?(%|Â°Ð¡?)?|(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})");
  private static final Pattern DATE = Pattern.compile("[\\d]{2}\\.[\\d]{2}\\.[\\d]{4}");
  private static final Pattern TIME = Pattern.compile("([01]?[0-9]|2[0-3])[.:][0-5][0-9]");
  private static final String stdNounTag = IPOSTag.noun.getText() + ":.:v_";
  private static final int stdNounTagLen = stdNounTag.length();
  private static final Pattern stdNounTagRegex = Pattern.compile(stdNounTag + ".*");

  private static final Set<String> dashPrefixes;
  private static final Set<String> leftMasterSet;
  private static final Set<String> cityAvenue = new HashSet<>(Arrays.asList("Ñ?ÑÑÑ", "Ð°Ð²ÐµÐ½Ñ", "Ñ?ÑÑÑÑ", "ÑÑÑÐ°Ñ?Ñ?Ðµ"));
  private static final Map<String, Pattern> rightPartsWithLeftTagMap = new HashMap<>();
  private static final Set<String> slaveSet;
  
  private List<String> LEFT_O_ADJ = Arrays.asList(
    "Ð°Ð²Ñ?ÑÑÐ¾", "Ð°Ð´Ð¸Ð³Ð¾", "Ð°Ð¼ÐµÑÐ¸ÐºÐ°Ð½Ð¾", "Ð°Ð½Ð³Ð»Ð¾", "Ð°ÑÑÐ¾", "ÐµÐºÐ¾", "ÐµÑÐ½Ð¾", "ÑÐ½Ð´Ð¾", "ÑÑ?Ð¿Ð°Ð½Ð¾", "ÐºÐ¸ÑÐ²Ð¾", 
    "Ð¼Ð°ÑÐ¾ÐºÐ°Ð½Ð¾", "ÑÐ³ÑÐ¾"
  ); 
  
  private static final Map<String, List<String>> NUMR_ENDING_MAP;
  private BufferedWriter compoundUnknownDebugWriter;
  private BufferedWriter compoundTaggedDebugWriter;
  private BufferedWriter taggedDebugWriter;

  static {
    Map<String, String> map = new LinkedHashMap<>();
    map.put("v_naz", "Ð½Ð°Ð·Ð¸Ð²Ð½Ð¸Ð¹");
    map.put("v_rod", "ÑÐ¾Ð´Ð¾Ð²Ð¸Ð¹");
    map.put("v_dav", "Ð´Ð°Ð²Ð°Ð»ÑÐ½Ð¸Ð¹");
    map.put("v_zna", "Ð·Ð½Ð°ÑÑÐ´Ð½Ð¸Ð¹");
    map.put("v_oru", "Ð¾ÑÑÐ´Ð½Ð¸Ð¹");
    map.put("v_mis", "Ð¼ÑÑ?ÑÐµÐ²Ð¸Ð¹");
    map.put("v_kly", "ÐºÐ»Ð¸ÑÐ½Ð¸Ð¹");
    VIDMINKY_MAP = Collections.unmodifiableMap(map);

    Map<String, List<String>> map2 = new HashMap<>();
    map2.put("Ð¹", Arrays.asList(":m:v_naz", ":m:v_zna"));
    map2.put("Ð³Ð¾", Arrays.asList(":m:v_rod", ":m:v_zna", ":n:v_rod"));
    map2.put("Ð¼Ñ", Arrays.asList(":m:v_dav", ":m:v_mis", ":n:v_dav", ":n:v_mis", ":f:v_zna"));  









    map2.put("ÑÐµ", Arrays.asList(":n:v_naz", ":n:v_zna"));
    map2.put("ÑÑ", Arrays.asList(":p:v_naz", ":p:v_zna"));
    map2.put("Ñ", Arrays.asList(":p:v_rod", ":p:v_zna"));
    NUMR_ENDING_MAP = Collections.unmodifiableMap(map2);
    
    rightPartsWithLeftTagMap.put("Ð±Ð¾", Pattern.compile("(verb(:rev)?:impr|.*pron|noun|adv|excl|part|predic).*"));
    rightPartsWithLeftTagMap.put("Ð½Ð¾", Pattern.compile("(verb(:rev)?:(impr|futr)|excl).*")); 
    rightPartsWithLeftTagMap.put("Ð¾Ñ", Pattern.compile("(.*pron|adv|part).*"));
    rightPartsWithLeftTagMap.put("ÑÐ¾", Pattern.compile("(.*pron|noun|adv|part|conj).*"));
    rightPartsWithLeftTagMap.put("ÑÐ°ÐºÐ¸", Pattern.compile("(verb(:rev)?:(futr|past|pres)|.*pron|noun|part|predic|insert).*")); 
    
    dashPrefixes = loadSet("/uk/dash_prefixes.txt");
    leftMasterSet = loadSet("/uk/dash_left_master.txt");
    slaveSet = loadSet("/uk/dash_slaves.txt");
    
  }

  private static Set<String> loadSet(String path) {
    Set<String> result = new HashSet<>();
    try (InputStream is = JLanguageTool.getDataBroker().getFromResourceDirAsStream(path);
         Scanner scanner = new Scanner(is,"UTF-8")) {
      while (scanner.hasNextLine()) {
        String line = scanner.nextLine();
        result.add(line);
      }
      return result;
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

  @Override
  public String getManualAdditionsFileName() {
    return "/uk/added.txt";
  }

  public UkrainianTagger() {
    super("/uk/ukrainian.dict", new Locale("uk", "UA"), false);
    if( Boolean.valueOf( System.getProperty(DEBUG_COMPOUNDS_PROPERTY) ) ) {
      debugCompounds();
    }
  }

  @Override
  public List<AnalyzedToken> additionalTags(String word, WordTagger wordTagger) {
    if ( NUMBER.matcher(word).matches() ) {
      List<AnalyzedToken> additionalTaggedTokens = new ArrayList<>();
      additionalTaggedTokens.add(new AnalyzedToken(word, IPOSTag.number.getText(), word));
      return additionalTaggedTokens;
    }

    if ( TIME.matcher(word).matches() ) {
      List<AnalyzedToken> additionalTaggedTokens = new ArrayList<>();
      additionalTaggedTokens.add(new AnalyzedToken(word, IPOSTag.time.getText(), word));
      return additionalTaggedTokens;
    }

    if ( DATE.matcher(word).matches() ) {
      List<AnalyzedToken> additionalTaggedTokens = new ArrayList<>();
      additionalTaggedTokens.add(new AnalyzedToken(word, IPOSTag.date.getText(), word));
      return additionalTaggedTokens;
    }
    
    if ( word.contains("-") ) {
      List<AnalyzedToken> guessedCompoundTags = guessCompoundTag(word);
      debug_compound_tagged_write(guessedCompoundTags);
      
      return guessedCompoundTags;
    }
    
    return null;
  }

  @Nullable
  private List<AnalyzedToken> guessCompoundTag(String word) {
    int dashIdx = word.lastIndexOf('-');
    if( dashIdx == 0 || dashIdx == word.length() - 1 )
      return null;

    int firstDashIdx = word.indexOf('-');
    if( dashIdx != firstDashIdx )
      return null;

    String leftWord = word.substring(0, dashIdx);
    String rightWord = word.substring(dashIdx + 1);

    List<TaggedWord> leftWdList = tagBothCases(leftWord);

    if( rightPartsWithLeftTagMap.containsKey(rightWord) ) {
      if( leftWdList.isEmpty() )
        return null;

      Pattern leftTagRegex = rightPartsWithLeftTagMap.get(rightWord);
      
      List<AnalyzedToken> leftAnalyzedTokens = asAnalyzedTokenListForTaggedWords(leftWord, leftWdList);
      List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(leftAnalyzedTokens.size());
      for (AnalyzedToken analyzedToken : leftAnalyzedTokens) {
        String posTag = analyzedToken.getPOSTag();
        if( posTag != null && leftTagRegex.matcher(posTag).matches() ) {
          newAnalyzedTokens.add(new AnalyzedToken(word, posTag, analyzedToken.getLemma()));
        }
      }
      
      return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
    }

    if( NUMBER.matcher(leftWord).matches() ) {
      List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>();
      
      if( NUMR_ENDING_MAP.containsKey(rightWord) ) {
        List<String> tags = NUMR_ENDING_MAP.get(rightWord);
        for (String tag: tags) {
          
          newAnalyzedTokens.add(new AnalyzedToken(word, IPOSTag.adj.getText()+tag, leftWord + "-" + "Ð¹"));
        }
      }
      else {
        List<TaggedWord> rightWdList = wordTagger.tag(rightWord);
        if( rightWdList.isEmpty() )
          return null;

        List<AnalyzedToken> rightAnalyzedTokens = asAnalyzedTokenListForTaggedWords(rightWord, rightWdList);

        
        for (AnalyzedToken analyzedToken : rightAnalyzedTokens) {
          if( analyzedToken.getPOSTag().startsWith(IPOSTag.adj.getText()) ) {
            newAnalyzedTokens.add(new AnalyzedToken(word, analyzedToken.getPOSTag(), leftWord + "-" + analyzedToken.getLemma()));
          }
        }
      }
      return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
    }

    if( leftWord.equalsIgnoreCase("Ð¿Ð¾") && rightWord.endsWith("Ñ?ÑÐºÐ¸") ) {
      rightWord += "Ð¹";
    }

    List<TaggedWord> rightWdList = wordTagger.tag(rightWord);
    if( rightWdList.isEmpty() )
      return null;

    List<AnalyzedToken> rightAnalyzedTokens = asAnalyzedTokenListForTaggedWords(rightWord, rightWdList);

    if( leftWord.equalsIgnoreCase("Ð¿Ð¾") ) {
      if( rightWord.endsWith("Ð¾Ð¼Ñ") ) {
        return poAdvMatch(word, rightAnalyzedTokens, ADJ_TAG_FOR_PO_ADV_MIS);
      }
      else if( rightWord.endsWith("Ñ?ÑÐºÐ¸Ð¹") ) {
        return poAdvMatch(word, rightAnalyzedTokens, ADJ_TAG_FOR_PO_ADV_NAZ);
      }
      return null;
    }

    if( dashPrefixes.contains( leftWord ) || dashPrefixes.contains( leftWord.toLowerCase() ) ) {
      return getNvPrefixNounMatch(word, rightAnalyzedTokens, leftWord);
    }

    if( word.startsWith("Ð¿ÑÐ²-") && Character.isUpperCase(word.charAt(4)) ) {
      List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(rightAnalyzedTokens.size());
      
      for (AnalyzedToken rightAnalyzedToken : rightAnalyzedTokens) {
        String rightPosTag = rightAnalyzedToken.getPOSTag();

        if( rightPosTag == null )
          continue;

        if( NOUN_SING_V_ROD_REGEX.matcher(rightPosTag).matches() ) {
          for(String vid: VIDMINKY_MAP.keySet()) {
            if( vid.equals("v_kly") )
              continue;
            String posTag = rightPosTag.replace("v_rod", vid);
            newAnalyzedTokens.add(new AnalyzedToken(word, posTag, word));
          }
        }
      }

      return newAnalyzedTokens;
    }

    if( Character.isUpperCase(leftWord.charAt(0)) && cityAvenue.contains(rightWord) ) {
      if( leftWdList.isEmpty() )
        return null;
      
      List<AnalyzedToken> leftAnalyzedTokens = asAnalyzedTokenListForTaggedWords(leftWord, leftWdList);
      return cityAvenueMatch(word, leftAnalyzedTokens);
    }

    if( ! leftWdList.isEmpty() ) {
      List<AnalyzedToken> leftAnalyzedTokens = asAnalyzedTokenListForTaggedWords(leftWord, leftWdList);

      List<AnalyzedToken> tagMatch = tagMatch(word, leftAnalyzedTokens, rightAnalyzedTokens);
      if( tagMatch != null ) {
        return tagMatch;
      }
    }

    if( O_ADJ_PATTERN.matcher(leftWord).matches() ) {
      return oAdjMatch(word, rightAnalyzedTokens, leftWord);
    }

    debug_compound_unknown_write(word);
    
    return null;
  }

  private List<TaggedWord> tagBothCases(String leftWord) {
    List<TaggedWord> leftWdList = wordTagger.tag(leftWord);
    String leftLowerCase = leftWord.toLowerCase(conversionLocale);
    if( ! leftWord.equals(leftLowerCase)) {
      leftWdList.addAll(wordTagger.tag(leftLowerCase));
    }
    else {
      String leftUpperCase = capitalize(leftWord);
      if( ! leftWord.equals(leftUpperCase)) {
        leftWdList.addAll(wordTagger.tag(leftUpperCase));
      }
    }

    return leftWdList;
  }

  private String capitalize(String word) {
    return word.substring(0, 1).toUpperCase(conversionLocale) + word.substring(1, word.length());
  }

  private List<AnalyzedToken> cityAvenueMatch(String word, List<AnalyzedToken> leftAnalyzedTokens) {
    List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(leftAnalyzedTokens.size());
    
    for (AnalyzedToken analyzedToken : leftAnalyzedTokens) {
      String posTag = analyzedToken.getPOSTag();
      if( NOUN_V_NAZ_REGEX.matcher(posTag).matches() ) {
        newAnalyzedTokens.add(new AnalyzedToken(word, posTag.replaceFirst("v_naz", "nv"), word));
      }
    }
    
    return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
  }
  
  private List<AnalyzedToken> tagMatch(String word, List<AnalyzedToken> leftAnalyzedTokens, List<AnalyzedToken> rightAnalyzedTokens) {
    List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>();
    List<AnalyzedToken> newAnalyzedTokensAnimInanim = new ArrayList<>();
    
    String animInanimNotTagged = null;
    
    for (AnalyzedToken leftAnalyzedToken : leftAnalyzedTokens) {
      String leftPosTag = leftAnalyzedToken.getPOSTag();
      
      if( leftPosTag == null )
        continue;

      String leftPosTagExtra = "";
      boolean leftNv = false;

      if( leftPosTag.contains(NV_TAG) ) {
        leftNv = true;
        leftPosTag = leftPosTag.replace(NV_TAG, "");
      }

      Matcher matcher = EXTRA_TAGS.matcher(leftPosTag);
      if( matcher.find() ) {
        leftPosTagExtra += matcher.group();
        leftPosTag = matcher.replaceAll("");
      }
      if( leftPosTag.contains(COMPB_TAG) ) {
        leftPosTag = leftPosTag.replace(COMPB_TAG, "");
      }

      for (AnalyzedToken rightAnalyzedToken : rightAnalyzedTokens) {
        String rightPosTag = rightAnalyzedToken.getPOSTag();
        
        if( rightPosTag == null )
          continue;

        String extraNvTag = "";
        boolean rightNv = false;
        if( rightPosTag.contains(NV_TAG) ) {
          rightNv = true;
          
          if( leftNv ) {
            extraNvTag += NV_TAG;
          }
        }

        Matcher matcherR = EXTRA_TAGS.matcher(rightPosTag);
        if( matcherR.find() ) {
          rightPosTag = matcherR.replaceAll("");
        }
        if( rightPosTag.contains(COMPB_TAG) ) {
          rightPosTag = rightPosTag.replace(COMPB_TAG, "");
        }
        
        if (leftPosTag.equals(rightPosTag) 
            && IPOSTag.startsWith(leftPosTag, IPOSTag.numr, IPOSTag.adv, IPOSTag.adj, IPOSTag.excl, IPOSTag.verb) ) {
          newAnalyzedTokens.add(new AnalyzedToken(word, leftPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
        }
        
        else if ( leftPosTag.startsWith(IPOSTag.noun.getText()) && rightPosTag.startsWith(IPOSTag.noun.getText()) ) {
          String agreedPosTag = getAgreedPosTag(leftPosTag, rightPosTag, leftNv);

          if( agreedPosTag == null 
              && rightPosTag.startsWith("noun:m:v_naz")
              && isMinMax(rightAnalyzedToken.getToken()) ) {
            agreedPosTag = leftPosTag;
          }

          if( agreedPosTag == null && ! isSameAnimStatus(leftPosTag, rightPosTag) ) {

            agreedPosTag = tryAnimInanim(leftPosTag, rightPosTag, leftAnalyzedToken.getLemma(), rightAnalyzedToken.getLemma(), leftNv, rightNv);
            
            if( agreedPosTag == null ) {
              animInanimNotTagged = leftPosTag.contains(":anim") ? "anim-inanim" : "inanim-anim";
            }
            else {
              newAnalyzedTokensAnimInanim.add(new AnalyzedToken(word, agreedPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
              continue;
            }
          }
          
          if( agreedPosTag != null ) {
            newAnalyzedTokens.add(new AnalyzedToken(word, agreedPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
          }
        }
        
        else if ( leftPosTag.startsWith(IPOSTag.numr.getText()) && rightPosTag.startsWith(IPOSTag.numr.getText()) ) {
            String agreedPosTag = getNumAgreedPosTag(leftPosTag, rightPosTag, leftNv);
            if( agreedPosTag != null ) {
              newAnalyzedTokens.add(new AnalyzedToken(word, agreedPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
            }
        }
        
        else if ( IPOSTag.startsWith(leftPosTag, IPOSTag.noun) && IPOSTag.startsWith(rightPosTag, IPOSTag.numr) ) {
          
          String leftGenderConj = PosTagHelper.getGenderConj(leftPosTag);
          if( leftGenderConj != null && leftGenderConj.equals(PosTagHelper.getGenderConj(rightPosTag)) ) {
            newAnalyzedTokens.add(new AnalyzedToken(word, leftPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
          }
          else {
            
            String agreedPosTag = getNumAgreedPosTag(leftPosTag, rightPosTag, leftNv);
            if( agreedPosTag != null ) {
              newAnalyzedTokens.add(new AnalyzedToken(word, agreedPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
            }
          }
        }
        
        else if( leftPosTag.startsWith(IPOSTag.noun.getText()) 
            && IPOSTag.startsWith(rightPosTag, IPOSTag.adj, IPOSTag.numr) ) {
          String leftGenderConj = PosTagHelper.getGenderConj(leftPosTag);
          if( leftGenderConj != null && leftGenderConj.equals(PosTagHelper.getGenderConj(rightPosTag)) ) {
            newAnalyzedTokens.add(new AnalyzedToken(word, leftPosTag + extraNvTag + leftPosTagExtra, leftAnalyzedToken.getLemma() + "-" + rightAnalyzedToken.getLemma()));
          }
        }
      }
    }
    
    if( newAnalyzedTokens.isEmpty() ) {
      newAnalyzedTokens = newAnalyzedTokensAnimInanim;
    }

    if( animInanimNotTagged != null && newAnalyzedTokens.isEmpty() ) {
      debug_compound_unknown_write(word + " " + animInanimNotTagged);
    }
    
    return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
  }

  private static boolean isMinMax(String rightToken) {
    return rightToken.equals("Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼")
        || rightToken.equals("Ð¼ÑÐ½ÑÐ¼ÑÐ¼");
  }

  private String tryAnimInanim(String leftPosTag, String rightPosTag, String leftLemma, String rightLemma, boolean leftNv, boolean rightNv) {
    String agreedPosTag = null;
    
    
    if( leftMasterSet.contains(leftLemma) ) {
      if( leftPosTag.contains(TAG_ANIM) ) {
        rightPosTag = rightPosTag.concat(TAG_ANIM);
      }
      else {
        rightPosTag = rightPosTag.replace(TAG_ANIM, "");
      }
      
      agreedPosTag = getAgreedPosTag(leftPosTag, rightPosTag, leftNv);
      
      if( agreedPosTag == null ) {
        if (! leftPosTag.contains(TAG_ANIM)) {
          if (MNP_ZNA_REGEX.matcher(leftPosTag).matches() && MNP_NAZ_REGEX.matcher(rightPosTag).matches()
              && ! leftNv && ! rightNv ) {
            agreedPosTag = leftPosTag;
          }
        }
        else {
          if (MNP_ZNA_REGEX.matcher(leftPosTag).matches() && MNP_ROD_REGEX.matcher(rightPosTag).matches()
              && ! leftNv && ! rightNv ) {
            agreedPosTag = leftPosTag;
          }
        }
      }
      
    }
    
    else if ( slaveSet.contains(rightLemma) ) {
      rightPosTag = rightPosTag.replace(":anim", "");
      agreedPosTag = getAgreedPosTag(leftPosTag, rightPosTag, false);
      if( agreedPosTag == null ) {
        if (! leftPosTag.contains(TAG_ANIM)) {
          if (MNP_ZNA_REGEX.matcher(leftPosTag).matches() && MNP_NAZ_REGEX.matcher(rightPosTag).matches()
              && PosTagHelper.getNum(leftPosTag).equals(PosTagHelper.getNum(rightPosTag))
              && ! leftNv && ! rightNv ) {
            agreedPosTag = leftPosTag;
          }
        }
      }
    }
    
    else if ( slaveSet.contains(leftLemma) ) {
      leftPosTag = leftPosTag.replace(":anim", "");
      agreedPosTag = getAgreedPosTag(rightPosTag, leftPosTag, false);
      if( agreedPosTag == null ) {
        if (! rightPosTag.contains(TAG_ANIM)) {
          if (MNP_ZNA_REGEX.matcher(rightPosTag).matches() && MNP_NAZ_REGEX.matcher(leftPosTag).matches()
              && PosTagHelper.getNum(leftPosTag).equals(PosTagHelper.getNum(rightPosTag))
              && ! leftNv && ! rightNv ) {
            agreedPosTag = rightPosTag;
          }
        }
      }
    }
    
    
    
    return agreedPosTag;
  }

  
  private String getNumAgreedPosTag(String leftPosTag, String rightPosTag, boolean leftNv) {
    String agreedPosTag = null;
    
    if( leftPosTag.contains(":p:") && SING_REGEX_F.matcher(rightPosTag).find()
        || SING_REGEX_F.matcher(leftPosTag).find() && rightPosTag.contains(":p:")) {
      if( PosTagHelper.getConj(leftPosTag).equals(PosTagHelper.getConj(rightPosTag)) ) {
        agreedPosTag = leftPosTag;
      }
    }
    return agreedPosTag;
  }

  @Nullable
  private String getAgreedPosTag(String leftPosTag, String rightPosTag, boolean leftNv) {
    if( isPlural(leftPosTag) && ! isPlural(rightPosTag)
        || ! isPlural(leftPosTag) && isPlural(rightPosTag) )
      return null;
    
    if( ! isSameAnimStatus(leftPosTag, rightPosTag) )
      return null;
    
    if( stdNounTagRegex.matcher(leftPosTag).matches() ) {
      if (stdNounTagRegex.matcher(rightPosTag).matches()) {
        String substring1 = leftPosTag.substring(stdNounTagLen, stdNounTagLen + 3);
        String substring2 = rightPosTag.substring(stdNounTagLen, stdNounTagLen + 3);
        if( substring1.equals(substring2) ) {
          if( leftNv )
            return rightPosTag;

          return leftPosTag;
        }
      }
    }

    return null;
  }

  private static boolean isSameAnimStatus(String leftPosTag, String rightPosTag) {
    return leftPosTag.contains(TAG_ANIM) && rightPosTag.contains(TAG_ANIM)
        || ! leftPosTag.contains(TAG_ANIM) && ! rightPosTag.contains(TAG_ANIM);
  }

  private static boolean isPlural(String posTag) {
    return posTag.startsWith("noun:p:");
  }

  private List<AnalyzedToken> oAdjMatch(String word, List<AnalyzedToken> analyzedTokens, String leftWord) {
    List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(analyzedTokens.size());

    String leftBase = leftWord.substring(0, leftWord.length()-1);
    if( ! LEFT_O_ADJ.contains(leftWord.toLowerCase(conversionLocale))
        && tagBothCases(leftWord).isEmpty()            
        && tagBothCases(oToYj(leftWord)).isEmpty()  
        && tagBothCases(leftBase).isEmpty()         
        && tagBothCases(leftBase + "Ð°").isEmpty() ) 
      return null;
    
    for (AnalyzedToken analyzedToken : analyzedTokens) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag.startsWith( IPOSTag.adj.getText() ) ) {
        newAnalyzedTokens.add(new AnalyzedToken(word, posTag, leftWord + "-" + analyzedToken.getLemma()));
      }
    }
    
    return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
  }

  private static String oToYj(String leftWord) {
    return leftWord.endsWith("ÑÐ¾") 
        ? leftWord.substring(0, leftWord.length()-2) + "ÑÐ¹" 
        : leftWord.substring(0,  leftWord.length()-1) + "Ð¸Ð¹";
  }

  private List<AnalyzedToken> getNvPrefixNounMatch(String word, List<AnalyzedToken> analyzedTokens, String leftWord) {
    List<AnalyzedToken> newAnalyzedTokens = new ArrayList<>(analyzedTokens.size());
    
    for (AnalyzedToken analyzedToken : analyzedTokens) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag.startsWith( IPOSTag.noun.getText() ) ) {
        newAnalyzedTokens.add(new AnalyzedToken(word, posTag, leftWord + "-" + analyzedToken.getLemma()));
      }
    }
    
    return newAnalyzedTokens.isEmpty() ? null : newAnalyzedTokens;
  }

  @Nullable
  private List<AnalyzedToken> poAdvMatch(String word, List<AnalyzedToken> analyzedTokens, String adjTag) {
    
    for (AnalyzedToken analyzedToken : analyzedTokens) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag.startsWith( adjTag ) ) {
        return Arrays.asList(new AnalyzedToken(word, IPOSTag.adv.getText(), word));
      }
    }
    
    return null;
  }

  

  private void debugCompounds() {
    try {
      Path unknownFile = Paths.get("compounds-unknown.txt");
      Files.deleteIfExists(unknownFile);
      unknownFile = Files.createFile(unknownFile);
      compoundUnknownDebugWriter = Files.newBufferedWriter(unknownFile, Charset.defaultCharset());

      Path taggedFile = Paths.get("compounds-tagged.txt");
      Files.deleteIfExists(taggedFile);
      taggedFile = Files.createFile(taggedFile);
      compoundTaggedDebugWriter = Files.newBufferedWriter(taggedFile, Charset.defaultCharset());





    } catch (IOException ex) {
      throw new RuntimeException(ex);
    }
  }

  private void debug_compound_unknown_write(String word) {
    if( compoundUnknownDebugWriter == null )
      return;
    
    try {
      compoundUnknownDebugWriter.append(word);
      compoundUnknownDebugWriter.newLine();
      compoundUnknownDebugWriter.flush();
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

  protected List<AnalyzedToken> getAnalyzedTokens(String word) {
    List<AnalyzedToken> tkns = super.getAnalyzedTokens(word);

    if( tkns.get(0).getPOSTag() == null ) {
      if( (word.indexOf('\u2013') != -1) 
           && word.matches(".*[Ð°-Ñ?ÑÑÑÒ][\u2013][Ð°-Ñ?ÑÑÑÒ].*")) {
        String newWord = word.replace('\u2013', '-');
        
        List<AnalyzedToken> newTokens = super.getAnalyzedTokens(newWord);
        
        for (int i = 0; i < newTokens.size(); i++) {
          AnalyzedToken analyzedToken = newTokens.get(i);
          if( newWord.equals(analyzedToken.getToken()) ) {
            String lemma = analyzedToken.getLemma();
            if( lemma != null ) {
              lemma = lemma.replace('-', '\u2013');
            }
            AnalyzedToken newToken = new AnalyzedToken(word, analyzedToken.getPOSTag(), lemma);
            newTokens.set(i, newToken);
          }
        }
        
        tkns = newTokens;
      }
    }
    
    if( taggedDebugWriter != null && ! tkns.isEmpty() ) {
      debug_tagged_write(tkns, taggedDebugWriter);
    }
    
    return tkns;
  }

  private void debug_compound_tagged_write(List<AnalyzedToken> guessedCompoundTags) {
    if( compoundTaggedDebugWriter == null || guessedCompoundTags == null )
      return;

    debug_tagged_write(guessedCompoundTags, compoundTaggedDebugWriter);
  }
  
  private void debug_tagged_write(List<AnalyzedToken> analyzedTokens, BufferedWriter writer) {
    if( analyzedTokens.get(0).getLemma() == null || analyzedTokens.get(0).getToken().trim().isEmpty() )
          return;

    try {
      String prevToken = "";
      String prevLemma = "";
      for (AnalyzedToken analyzedToken : analyzedTokens) {
        String token = analyzedToken.getToken();
        
        boolean firstTag = false;
        if (! prevToken.equals(token)) {
          if( prevToken.length() > 0 ) {
            writer.append(";  ");
            prevLemma = "";
          }
          writer.append(token).append(" ");
          prevToken = token;
          firstTag = true;
        }
        
        String lemma = analyzedToken.getLemma();

        if (! prevLemma.equals(lemma)) {
          if( prevLemma.length() > 0 ) {
            writer.append(", ");
          }
          writer.append(lemma); 
          prevLemma = lemma;
          firstTag = true;
        }

        writer.append(firstTag ? " " : "|").append(analyzedToken.getPOSTag());
        firstTag = false;
      }
      writer.newLine();
      writer.flush();
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
  }

  
}

<code block>

package org.languagetool.tokenizers.uk;

import java.util.ArrayList;
import java.util.List;
import java.util.regex.Pattern;
import java.util.StringTokenizer;

import org.languagetool.tokenizers.Tokenizer;


public class UkrainianWordTokenizer implements Tokenizer {
  private static final String SPLIT_CHARS = "\u0020\u00A0\u115f\u1160\u1680" 
        + "\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007" 
        + "\u2008\u2009\u200A\u200B\u200c\u200d\u200e\u200f"
        + "\u2028\u2029\u202a\u202b\u202c\u202d\u202e\u202f"
        + "\u205F\u2060\u2061\u2062\u2063\u206A\u206b\u206c\u206d"
        + "\u206E\u206F\u3000\u3164\ufeff\uffa0\ufff9\ufffa\ufffb" 
        + ",.;()[]{}<>!?:/|\\\"Â«Â»ââ?â`Â´âââ²â¦Â¿Â¡\t\n\r\uE100";

  
  private static final Pattern DECIMAL_COMMA_PATTERN = Pattern.compile("([\\d]),([\\d])", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char DECIMAL_COMMA_SUBST = '\uE001'; 
  


  
  private static final Pattern DOTTED_NUMBERS_PATTERN = Pattern.compile("([\\d])\\.([\\d])", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char NUMBER_DOT_SUBST = '\uE002';
  
  private static final Pattern COLON_NUMBERS_PATTERN = Pattern.compile("([\\d]):([\\d])", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char COLON_DOT_SUBST = '\uE003';
  
  private static final Pattern DATE_PATTERN = Pattern.compile("([\\d]{2})\\.([\\d]{2})\\.([\\d]{4})|([\\d]{4})\\.([\\d]{2})\\.([\\d]{2})|([\\d]{4})-([\\d]{2})-([\\d]{2})", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char DATE_DOT_SUBST = '\uE004'; 
  
  private static final Pattern BRACE_IN_WORD_PATTERN = Pattern.compile("([Ð°-Ñ?ÑÑÑÒ'])\\(([Ð°-Ñ?ÑÑÑÒ']+)\\)", Pattern.CASE_INSENSITIVE|Pattern.UNICODE_CASE);
  private static final char LEFT_BRACE_SUBST = '\uE005';
  private static final char RIGHT_BRACE_SUBST = '\uE006';
  
  
  private static final Pattern ABBR_DOT_PATTERN = Pattern.compile("([Ð°-Ñ?ÑÑÑÒ])\\. ([Ð°-Ñ?ÑÑÑÒ])");
  private static final Pattern ABBR_DOT_PATTERN2 = Pattern.compile("([Ð?Ð°]ÐºÐ°Ð´|[ÐÐ¿]ÑÐ¾Ñ|[ÐÐ´]Ð¾Ñ|[Ð?Ð°]Ñ?Ð¸Ñ?Ñ|Ñ?|Ð¼|Ð²ÑÐ»|Ð¾|Ñ|ÑÐ¼)\\.\\s([Ð?-Ð¯ÐÐÐÒ?])");
  private static final char ABBR_DOT_SUBST = '\uE007';
  
  private static final String ELLIPSIS = "...";
  private static final String ELLIPSIS_SUBST = "\uE100";


  public UkrainianWordTokenizer() {
  }

  @Override
  public List<String> tokenize(String text) {
    text = cleanup(text);
    
    if( text.contains(",") ) {
      text = DECIMAL_COMMA_PATTERN.matcher(text).replaceAll("$1" + DECIMAL_COMMA_SUBST + "$2");
    }
    
    if( text.contains(".") ) {
      text = DATE_PATTERN.matcher(text).replaceAll("$1" + DATE_DOT_SUBST + "$2" + DATE_DOT_SUBST + "$3");
      text = DOTTED_NUMBERS_PATTERN.matcher(text).replaceAll("$1" + NUMBER_DOT_SUBST + "$2");
      text = ABBR_DOT_PATTERN.matcher(text).replaceAll("$1" + ABBR_DOT_SUBST + " $2");
      text = ABBR_DOT_PATTERN2.matcher(text).replaceAll("$1" + ABBR_DOT_SUBST + " $2");
    }

    if( text.contains(":") ) {
      text = COLON_NUMBERS_PATTERN.matcher(text).replaceAll("$1" + COLON_DOT_SUBST + "$2");
    }

    if( text.contains("(") ) {
      text = BRACE_IN_WORD_PATTERN.matcher(text).replaceAll("$1" + LEFT_BRACE_SUBST + "$2" + RIGHT_BRACE_SUBST);
    }




    
    if( text.contains(ELLIPSIS) ) {
      text = text.replace(ELLIPSIS, ELLIPSIS_SUBST);
    }
    
    List<String> tokenList = new ArrayList<>();
    StringTokenizer st = new StringTokenizer(text, SPLIT_CHARS, true);

    while (st.hasMoreElements()) {
      String token = st.nextToken();
      
      token = token.replace(DECIMAL_COMMA_SUBST, ',');
      
      
      token = token.replace(DATE_DOT_SUBST, '.');
      token = token.replace(NUMBER_DOT_SUBST, '.');
      token = token.replace(ABBR_DOT_SUBST, '.');
      
      token = token.replace(COLON_DOT_SUBST, ':');
      token = token.replace(LEFT_BRACE_SUBST, '(');
      token = token.replace(RIGHT_BRACE_SUBST, ')');
      token = token.replaceAll(ELLIPSIS_SUBST, ELLIPSIS);

      tokenList.add( token );
    }

    return tokenList;
  }

  private static String cleanup(String text) {
    text = text.replace('â', '\'').replace('Ê¼', '\'');









    return text;
  }

}

<code block>
package org.languagetool.rules.uk;

import java.util.*;

import org.languagetool.AnalyzedToken;
import org.languagetool.AnalyzedTokenReadings;
import org.languagetool.JLanguageTool;
import org.languagetool.Language;
import org.languagetool.rules.RuleMatch;
import org.languagetool.rules.WordRepeatRule;
import org.languagetool.tagging.uk.IPOSTag;
import org.languagetool.tagging.uk.PosTagHelper;


public class UkrainianWordRepeatRule extends WordRepeatRule {
  private static final HashSet<String> REPEAT_ALLOWED_SET = new HashSet<>(
      Arrays.asList("ÑÐ¾", "Ð½Ñ", "Ð¾Ð´Ð½Ðµ", "Ð¾Ñ?Ñ")
  );
  private static final HashSet<String> REPEAT_ALLOWED_CAPS_SET = new HashSet<>(
      Arrays.asList("ÐÐ Ð", "ÐÐ¶ÐµÐ¹", "ÐÑ")
  );

  public UkrainianWordRepeatRule(ResourceBundle messages, Language language) {
    super(messages, language);
  }

  @Override
  public String getId() {
    return "UKRAINIAN_WORD_REPEAT_RULE";
  }

  @Override
  public boolean ignore(AnalyzedTokenReadings[] tokens, int position) {
    AnalyzedTokenReadings analyzedTokenReadings = tokens[position];
    String token = analyzedTokenReadings.getToken();
    
    
    if( position > 1 && token.equals("Ð´Ð¾Ð±ÑÐ°")
        && tokens[position-2].getToken().equalsIgnoreCase("Ð²ÑÐ´") )
      return true;
    
    if( REPEAT_ALLOWED_SET.contains(token.toLowerCase()) )
      return true;

    if( REPEAT_ALLOWED_CAPS_SET.contains(token) )
      return true;
    
    if( PosTagHelper.hasPosTag(analyzedTokenReadings, "date|time|number") )
      return true;
    
    for(AnalyzedToken analyzedToken: analyzedTokenReadings.getReadings()) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag != null ) {
        if ( ! isInitial(analyzedToken, tokens, position)

            && ! posTag.equals(JLanguageTool.SENTENCE_END_TAGNAME) )
          return false;
      }
    }
    return true;
  }

  private boolean isInitial(AnalyzedToken analyzedToken, AnalyzedTokenReadings[] tokens, int position) {
    return analyzedToken.getPOSTag().contains(IPOSTag.abbr.getText())
        || (analyzedToken.getToken().length() == 1 
        && Character.isUpperCase(analyzedToken.getToken().charAt(0))
        && position < tokens.length-1 && tokens[position+1].getToken().equals("."));
  }

  @Override
  protected RuleMatch createRuleMatch(String prevToken, String token, int prevPos, int pos, String msg) {
    boolean doubleI = prevToken.equals("Ð") && token.equals("Ñ");
    if( doubleI ) {
      msg += " Ð°Ð±Ð¾, Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾, Ð¿ÐµÑÑÐ° Ð Ð¼Ð°Ñ Ð±ÑÑÐ¸ Ð»Ð°ÑÐ¸Ð½Ñ?ÑÐºÐ¾Ñ.";
    }
    
    RuleMatch ruleMatch = super.createRuleMatch(prevToken, token, prevPos, pos, msg);

    if( doubleI ) {
      List<String> replacements = new ArrayList<>(ruleMatch.getSuggestedReplacements());
      replacements.add("I Ñ");
      ruleMatch.setSuggestedReplacements(replacements);
    }
    return ruleMatch;
  }
}

<code block>

package org.languagetool.rules.uk;

import java.io.IOException;
import java.text.MessageFormat;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.HashSet;
import java.util.List;
import java.util.ResourceBundle;
import java.util.Set;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.apache.commons.lang.StringUtils;
import org.jetbrains.annotations.Nullable;
import org.languagetool.AnalyzedSentence;
import org.languagetool.AnalyzedToken;
import org.languagetool.AnalyzedTokenReadings;
import org.languagetool.JLanguageTool;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.Category;
import org.languagetool.rules.Rule;
import org.languagetool.rules.RuleMatch;
import org.languagetool.synthesis.Synthesizer;
import org.languagetool.tagging.uk.IPOSTag;
import org.languagetool.tagging.uk.PosTagHelper;
import org.languagetool.tagging.uk.UkrainianTagger;


public class TokenAgreementRule extends Rule {
  private static final String NO_VIDMINOK_SUBSTR = ":nv";
  private static final String REQUIRE_VIDMINOK_SUBSTR = ":rv_";
  private static final String VIDMINOK_SUBSTR = ":v_";
  private static final Pattern REQUIRE_VIDMINOK_REGEX = Pattern.compile(":r(v_[a-z]+)");
  private static final Pattern VIDMINOK_REGEX = Pattern.compile(":(v_[a-z]+)");

  private final Ukrainian ukrainian = new Ukrainian();

  private static final Set<String> STREETS = new HashSet<>(Arrays.asList(
      "Ð¨ÑÑÐ°Ñ?Ñ?Ðµ", "Ð?Ð²ÐµÐ½Ñ", "Ð¡ÑÑÑÑ"
      ));

  public TokenAgreementRule(final ResourceBundle messages) throws IOException {
    super.setCategory(new Category(messages.getString("category_misc")));
  }

  @Override
  public final String getId() {
    return "UK_TOKEN_AGREEMENT";
  }

  @Override
  public String getDescription() {
    return "Ð£Ð·Ð³Ð¾Ð´Ð¶ÐµÐ½Ð½Ñ? Ñ?Ð»ÑÐ² Ñ ÑÐµÑÐµÐ½Ð½Ñ";
  }

  public String getShort() {
    return "Ð£Ð·Ð³Ð¾Ð´Ð¶ÐµÐ½Ð½Ñ? Ñ?Ð»ÑÐ² Ñ ÑÐµÑÐµÐ½Ð½Ñ";
  }
  
  public boolean isCaseSensitive() {
    return false;
  }

  @Override
  public final RuleMatch[] match(final AnalyzedSentence text) {
    List<RuleMatch> ruleMatches = new ArrayList<>();
    AnalyzedTokenReadings[] tokens = text.getTokensWithoutWhitespace();    
    boolean insideMultiword = false;

    AnalyzedTokenReadings reqTokenReadings = null;
    for (int i = 0; i < tokens.length; i++) {
      AnalyzedTokenReadings tokenReadings = tokens[i];

      String posTag = tokenReadings.getAnalyzedToken(0).getPOSTag();

      

      if (posTag == null
          || posTag.contains(IPOSTag.unknown.getText())
          || posTag.equals(JLanguageTool.SENTENCE_START_TAGNAME) ){
        reqTokenReadings = null;
        continue;
      }

      AnalyzedToken multiwordReqToken = getMultiwordToken(tokenReadings);
      if( multiwordReqToken != null ) {
        String mwPosTag = multiwordReqToken.getPOSTag();
        if( mwPosTag.startsWith("</") ) {
          insideMultiword = false;
        }
        else {
          insideMultiword = true;
        }
        
        if (mwPosTag.startsWith("</") && mwPosTag.contains(REQUIRE_VIDMINOK_SUBSTR)) { 
          posTag = multiwordReqToken.getPOSTag();
          reqTokenReadings = tokenReadings;
          continue;
        }
        else {
          if( ! mwPosTag.contains("adv") && ! mwPosTag.contains("insert") ) {
            reqTokenReadings = null;
          }
          continue;
        }
      }
      
      if( insideMultiword ) {
        continue;
      }

      String token = tokenReadings.getAnalyzedToken(0).getToken();
      if( posTag.contains(REQUIRE_VIDMINOK_SUBSTR) && tokenReadings.getReadingsLength() == 1 ) {
        String prep = token;

        if( prep.equals("Ð·Ð°") && reverseSearch(tokens, i, "ÑÐ¾") ) 
          continue;

        if( prep.equalsIgnoreCase("Ð¿Ð¾Ð½Ð°Ð´") )
          continue;

        if( (prep.equalsIgnoreCase("Ð¾ÐºÑÑÐ¼") || prep.equalsIgnoreCase("ÐºÑÑÐ¼"))
            && tokens.length > i+1 && tokens[i+1].getAnalyzedToken(0).getToken().equalsIgnoreCase("Ñ?Ðº") ) {
          reqTokenReadings = null;
          continue;
        }

        reqTokenReadings = tokenReadings;
        continue;
      }

      if( reqTokenReadings == null )
        continue;


      

      ArrayList<String> posTagsToFind = new ArrayList<>();
      String reqPosTag = reqTokenReadings.getAnalyzedToken(0).getPOSTag();
      String prep = reqTokenReadings.getAnalyzedToken(0).getLemma();
      






      
      if( prep.equalsIgnoreCase("Ð¿Ð¾Ð½Ð°Ð´") ) { 
        posTagsToFind.add("v_naz");
      }
      else if( prep.equalsIgnoreCase("Ð·Ð°Ð¼ÑÑ?ÑÑ") ) {
        posTagsToFind.add("v_naz");
      }

      Matcher matcher = REQUIRE_VIDMINOK_REGEX.matcher(reqPosTag);
      while( matcher.find() ) {
        posTagsToFind.add(matcher.group(1));
      }

      for(AnalyzedToken readingToken: tokenReadings) {
        if( IPOSTag.numr.match(readingToken.getPOSTag()) ) {
          posTagsToFind.add("v_naz");  
          break;
        }
      }

      
      if( ! hasRequiredPosTag(posTagsToFind, tokenReadings) ) {
        if( isTokenToSkip(tokenReadings) )
          continue;







        
        if( prep.equalsIgnoreCase("Ð²") || prep.equalsIgnoreCase("Ñ") || prep.equals("Ð¼ÐµÐ¶Ð¸") || prep.equals("Ð¼ÑÐ¶") ) {
          if( hasRequiredPosTag(Arrays.asList("p:v_naz"), tokenReadings) ) {
            reqTokenReadings = null;
            continue;
          }
        }

        
        if (prep.equalsIgnoreCase("Ð½Ð°")
            && Character.isUpperCase(token.charAt(0)) && posTag.matches("noun:.:v_rod.*")) {
          reqTokenReadings = null;
          continue;
        }

        if( prep.equalsIgnoreCase("Ð·") ) {
          if( token.equals("ÑÐ°Ð½Ð°") ) {
            reqTokenReadings = null;
            continue;
          }
        }
        
        if( prep.equalsIgnoreCase("Ð²ÑÐ´") ) {
          if( token.equalsIgnoreCase("Ð°") || token.equals("ÑÐ°Ð½Ð°") || token.equals("ÐºÐ¾ÑÐºÐ¸") || token.equals("Ð¼Ð°Ð»Ð°") ) {  
            reqTokenReadings = null;
            continue;
          }
        }
        else if( prep.equalsIgnoreCase("Ð´Ð¾") ) {
          if( token.equalsIgnoreCase("Ñ?") || token.equals("ÐºÐ¾ÑÐºÐ¸") || token.equals("Ð²ÐµÐ»Ð¸ÐºÐ°") ) {  
            reqTokenReadings = null;
            continue;
          }
        }

        
        if( tokens.length > i+1 ) {
          
          
          
          

          if( isCapitalized( token ) 
              && STREETS.contains( tokens[i+1].getAnalyzedToken(0).getToken()) ) {
            reqTokenReadings = null;
            continue;
          }

          if( IPOSTag.isNum(tokens[i+1].getAnalyzedToken(0).getPOSTag())
              && (token.equals("Ð¼ÑÐ½ÑÑ?") || token.equals("Ð¿Ð»ÑÑ?")
                  || token.equals("Ð¼ÑÐ½ÑÐ¼ÑÐ¼") || token.equals("Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼") ) ) {
            reqTokenReadings = null;
            continue;
          }

          
          if( PosTagHelper.hasPosTag(tokenReadings, "noun:.:v_oru.*")
              && tokens[i+1].hasPartialPosTag("adjp") ) {
            continue;
          }
          
          if( (prep.equalsIgnoreCase("ÑÐµÑÐµÐ·") || prep.equalsIgnoreCase("Ð½Ð°"))  
              && (posTag.startsWith("noun:p:v_naz") || posTag.startsWith("noun:p:v_rod")) 
              && IPOSTag.isNum(tokens[i+1].getAnalyzedToken(0).getPOSTag()) ) {
            reqTokenReadings = null;
            continue;
          }

          if( (token.equals("Ð²Ð°Ð¼Ð¸") || token.equals("ÑÐ¾Ð±Ð¾Ñ") || token.equals("ÑÐ¼Ð¸"))
              && tokens[i+1].getAnalyzedToken(0).getToken().startsWith("Ð¶") ) {
            continue;
          }
          if( (token.equals("Ñ?Ð¾Ð±Ñ") || token.equals("Ð¹Ð¾Ð¼Ñ") || token.equals("ÑÐ¼"))
              && tokens[i+1].getAnalyzedToken(0).getToken().startsWith("Ð¿Ð¾Ð´ÑÐ±Ð½") ) {
            continue;
          }
          if( (token.equals("ÑÑ?ÑÐ¼") || token.equals("Ð²Ñ?ÑÐ¼"))
              && tokens[i+1].getAnalyzedToken(0).getToken().startsWith("Ð²ÑÐ´Ð¾Ð¼") ) {
            continue;
          }

          if( prep.equalsIgnoreCase("Ð´Ð¾") && token.equals("Ñ?ÑÑÐ´") 
                && tokens[i+1].getAnalyzedToken(0).getToken().equals("Ñ?Ð¾Ð½ÑÑ?") ) {
            reqTokenReadings = null;
            continue;
          }
          
          if( tokens[i+1].getAnalyzedToken(0).getToken().equals("Â«") 
              && tokens[i].getAnalyzedToken(0).getPOSTag().contains(":abbr") ) {
            reqTokenReadings = null;
            continue;
          }

          if( tokens.length > i+2 ) {
            
            if ( posTag.matches("adj.*:[mfn]:v_rod.*")) {
              String gender = PosTagHelper.getGender(posTag);
              if ( PosTagHelper.hasPosTag(tokens[i+1], "noun.*:"+gender+":v_rod.*")) {
                i += 1;
                continue;
              }
            }

            if ((token.equals("Ð½ÑÐºÐ¾Ð¼Ñ") || token.equals("Ð½ÑÐºÐ¸Ð¼") || token.equals("Ð½ÑÑÐ¸Ð¼") || token.equals("Ð½ÑÑÐ¾Ð¼Ñ")) 
                && tokens[i+1].getAnalyzedToken(0).getToken().equals("Ð½Ðµ")) {
              
              continue;
            }








          }
        }

        RuleMatch potentialRuleMatch = createRuleMatch(tokenReadings, reqTokenReadings, posTagsToFind);
        ruleMatches.add(potentialRuleMatch);
      }

      reqTokenReadings = null;
    }

    return toRuleMatchArray(ruleMatches);
  }

  private static boolean isCapitalized(String token) {
    return token.length() > 1 && Character.isUpperCase(token.charAt(0)) && Character.isLowerCase(token.charAt(1));
  }

  private boolean reverseSearch(AnalyzedTokenReadings[] tokens, int pos, String string) {
    for(int i=pos-1; i >= 0 && i > pos-4; i--) {
      if( tokens[i].getAnalyzedToken(0).getToken().equalsIgnoreCase(string) )
        return true;
    }
    return false;
  }

  private boolean forwardSearch(AnalyzedTokenReadings[] tokens, int pos, String string, int maxSkip) {
    for(int i=pos+1; i < tokens.length && i <= pos + maxSkip; i++) {
      if( tokens[i].getAnalyzedToken(0).getToken().equalsIgnoreCase(string) )
        return true;
    }
    return false;
  }

  private boolean isTokenToSkip(AnalyzedTokenReadings tokenReadings) {
    for(AnalyzedToken token: tokenReadings) {

      if( IPOSTag.adv.match(token.getPOSTag())
          || IPOSTag.contains(token.getPOSTag(), "adv>")
          ||  IPOSTag.insert.match(token.getPOSTag()) )
        return true;
    }
    return false;
  }









  private boolean hasRequiredPosTag(Collection<String> posTagsToFind, AnalyzedTokenReadings tokenReadings) {
    boolean vidminokFound = false;  

    for(AnalyzedToken token: tokenReadings) {
      String posTag = token.getPOSTag();

      if( posTag == null ) {
        if( tokenReadings.getReadingsLength() == 1) 
          return true;
        
        continue;
      }
      
      if( posTag.contains(NO_VIDMINOK_SUBSTR) )
        return true;

      if( posTag.contains(VIDMINOK_SUBSTR) ) {
        vidminokFound = true;

        for(String posTagToFind: posTagsToFind) {
          

          if ( posTag.contains(posTagToFind) )
            return true;
        }
      }
    }

    return ! vidminokFound; 
  }

  private RuleMatch createRuleMatch(AnalyzedTokenReadings tokenReadings, AnalyzedTokenReadings reqTokenReadings, List<String> posTagsToFind) {
    String tokenString = tokenReadings.getToken();

    Synthesizer ukrainianSynthesizer = ukrainian.getSynthesizer();

    ArrayList<String> suggestions = new ArrayList<>();
    String oldPosTag = tokenReadings.getAnalyzedToken(0).getPOSTag();
    String requiredPostTagsRegEx = ":(" + StringUtils.join(posTagsToFind,"|") + ")";
    String posTag = oldPosTag.replaceFirst(":v_[a-z]+", requiredPostTagsRegEx);

    

    try {
      String[] synthesized = ukrainianSynthesizer.synthesize(tokenReadings.getAnalyzedToken(0), posTag, true);

      
      suggestions.addAll( Arrays.asList(synthesized) );
    } catch (IOException e) {
      throw new RuntimeException(e);
    }

    ArrayList<String> reqVidminkyNames = new ArrayList<>();
    for (String vidm: posTagsToFind) {
      reqVidminkyNames.add(UkrainianTagger.VIDMINKY_MAP.get(vidm));
    }

    ArrayList<String> foundVidminkyNames = new ArrayList<>();
    for(AnalyzedToken token: tokenReadings) {
      String posTag2 = token.getPOSTag();
      if( posTag2 != null && posTag2.contains(VIDMINOK_SUBSTR) ) {
        String vidmName = UkrainianTagger.VIDMINKY_MAP.get(posTag2.replaceFirst("^.*"+VIDMINOK_REGEX+".*$", "$1"));
        if( foundVidminkyNames.contains(vidmName) ) {
          if (posTag2.contains(":p:")) {
            vidmName = vidmName + " (Ð¼Ð½.)";
            foundVidminkyNames.add(vidmName);
          }
          
        }
        else {
          foundVidminkyNames.add(vidmName);
        }
      }
    }

    String msg = MessageFormat.format("ÐÑÐ¸Ð¹Ð¼ÐµÐ½Ð½Ð¸Ðº Â«{0}Â» Ð²Ð¸Ð¼Ð°Ð³Ð°Ñ ÑÐ½ÑÐ¾Ð³Ð¾ Ð²ÑÐ´Ð¼ÑÐ½ÐºÐ°: {1}, Ð° Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾: {2}", 
        reqTokenReadings.getToken(), StringUtils.join(reqVidminkyNames, ", "), StringUtils.join(foundVidminkyNames, ", "));
        
    if( tokenString.equals("ÑÑ") ) {
      msg += ". ÐÐ¾Ð¶Ð»Ð¸Ð²Ð¾ ÑÑÑ Ð¿Ð¾ÑÑÑÐ±Ð½Ð¾ Ð¿ÑÐ¸Ñ?Ð²ÑÐ¹Ð½Ð¸Ð¹ Ð·Ð°Ð¹Ð¼ÐµÐ½Ð½Ð¸Ðº Â«ÑÑÐ½ÑÐ¹Â»?";
      try {
        String newYihPostag = "adj:p" + requiredPostTagsRegEx + ".*";
        String[] synthesized = ukrainianSynthesizer.synthesize(new AnalyzedToken("ÑÑÐ½ÑÐ¹", "adj:m:v_naz:&pron", "ÑÑÐ½ÑÐ¹"), newYihPostag, true);
        suggestions.addAll( Arrays.asList(synthesized) );
      } catch (IOException e) {
        throw new RuntimeException(e);
      }
    }
    else if( reqTokenReadings.getToken().equalsIgnoreCase("Ð¾") ) {
      for(AnalyzedToken token: tokenReadings.getReadings()) {
        String posTag2 = token.getPOSTag();
        if( posTag2.matches(".*:v_naz.*:anim.*") ) {
          msg += ". ÐÐ¾Ð¶Ð»Ð¸Ð²Ð¾ ÑÑÑ Â«Ð¾Â» â ÑÐµ Ð²Ð¸Ð³ÑÐº Ñ Ð¿Ð¾ÑÑÑÐ±Ð½Ð¾ ÐºÐ»Ð¸ÑÐ½Ð¸Ð¹ Ð²ÑÐ´Ð¼ÑÐ½Ð¾Ðº?";
          try {
            String newPostag = posTag2.replace("v_naz", "v_kly");
            String[] synthesized = ukrainianSynthesizer.synthesize(token, newPostag, false);
            for (String string : synthesized) {
              if( ! string.equals(token.getToken()) && ! suggestions.contains(string) ) {
                suggestions.add( string );
              }
            }
            break;
          } catch (IOException e) {
            throw new RuntimeException(e);
          }
        }
      }
      
    }
        
    RuleMatch potentialRuleMatch = new RuleMatch(this, tokenReadings.getStartPos(), tokenReadings.getEndPos(), msg, getShort());

    potentialRuleMatch.setSuggestedReplacements(suggestions);

    return potentialRuleMatch;
  }

  @Nullable
  private static AnalyzedToken getMultiwordToken(AnalyzedTokenReadings analyzedTokenReadings) {
      for(AnalyzedToken analyzedToken: analyzedTokenReadings) {
        String posTag = analyzedToken.getPOSTag();
        if( posTag != null && posTag.startsWith("<") )
          return analyzedToken;
      }
      return null;
  }

  @Override
  public void reset() {
  }

}

<code block>

package org.languagetool.rules.uk;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.ResourceBundle;
import java.util.regex.Pattern;

import org.apache.commons.lang.StringUtils;
import org.languagetool.AnalyzedSentence;
import org.languagetool.AnalyzedTokenReadings;
import org.languagetool.rules.Category;
import org.languagetool.rules.Rule;
import org.languagetool.rules.RuleMatch;


public class MixedAlphabetsRule extends Rule {

  private static final Pattern LIKELY_LATIN_NUMBER = Pattern.compile("[XVIÐ¥Ð]{2,8}");
  private static final Pattern LATIN_NUMBER_WITH_CYRILLICS = Pattern.compile("Ð¥{1,3}Ð{1,3}|Ð{1,3}Ð¥{1,3}|Ð¥{2,3}|Ð{2,3}");
  private static final Pattern MIXED_ALPHABETS = Pattern.compile(".*([a-zA-Z]'?[Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?]|[Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?]'?[a-zA-Z]).*");
  private static final Pattern CYRILLIC_ONLY = Pattern.compile(".*[Ð±Ð²Ð³ÒÐ´ÑÐ¶Ð·Ð¹ÑÐ»Ð½Ð¿ÑÑÑÑÑÑÑÑ?ÐÐÒ?ÐÐÐÐÐÐÐÐÐÐ¤Ð¦Ð§Ð¨Ð©Ð¬Ð®Ð¯].*");
  private static final Pattern LATIN_ONLY = Pattern.compile(".*[bdfghjlqrsvzDFGLNQRSUVZ].*");

  public MixedAlphabetsRule(final ResourceBundle messages) throws IOException {
    super.setCategory(new Category(messages.getString("category_misc")));
  }

  @Override
  public final String getId() {
    return "UK_MIXED_ALPHABETS";
  }

  @Override
  public String getDescription() {
    return "ÐÐ¼ÑÑÑÐ²Ð°Ð½Ð½Ñ? ÐºÐ¸ÑÐ¸Ð»Ð¸ÑÑ Ð¹ Ð»Ð°ÑÐ¸Ð½Ð¸ÑÑ";
  }

  public String getShort() {
    return "ÐÑÑÐ°Ð½Ð¸Ð½Ð° ÑÐ¾Ð·ÐºÐ»Ð°Ð´Ð¾Ðº";
  }

  public String getSuggestion(String word) {
    String highlighted = word.replaceAll("([a-zA-Z])([Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?])", "$1/$2");
    highlighted = highlighted.replaceAll("([Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?])([a-zA-Z])", "$1/$2");
    return " Ð¼ÑÑ?ÑÐ¸ÑÑ Ñ?ÑÐ¼ÑÑ ÐºÐ¸ÑÐ¸Ð»Ð¸ÑÑ ÑÐ° Ð»Ð°ÑÐ¸Ð½Ð¸ÑÑ: Â«"+ highlighted +"Â», Ð²Ð¸Ð¿ÑÐ°Ð²Ð»ÐµÐ½Ð½Ñ?: ";
  }

  
  public boolean isCaseSensitive() {
    return true;  
  }

  @Override
  public final RuleMatch[] match(final AnalyzedSentence sentence) {
    List<RuleMatch> ruleMatches = new ArrayList<>();
    AnalyzedTokenReadings[] tokens = sentence.getTokensWithoutWhitespace();

    for (AnalyzedTokenReadings tokenReadings: tokens) {
      String tokenString = tokenReadings.getToken();

      if( MIXED_ALPHABETS.matcher(tokenString).matches() ) {
      
        List<String> replacements = new ArrayList<>();

        if(!LATIN_ONLY.matcher(tokenString).matches() && ! LIKELY_LATIN_NUMBER.matcher(tokenString).matches()) {
          replacements.add( toCyrillic(tokenString) );
        }
        if(!CYRILLIC_ONLY.matcher(tokenString).matches() || LIKELY_LATIN_NUMBER.matcher(tokenString).matches()) {
          replacements.add( toLatin(tokenString) );
        }

        if (replacements.size() > 0) {
          RuleMatch potentialRuleMatch = createRuleMatch(tokenReadings, replacements);
          ruleMatches.add(potentialRuleMatch);
        }
      }
      else if(LATIN_NUMBER_WITH_CYRILLICS.matcher(tokenString).matches()) {
        List<String> replacements = new ArrayList<>();
        replacements.add( toLatin(tokenString) );

        RuleMatch potentialRuleMatch = createRuleMatch(tokenReadings, replacements);
        ruleMatches.add(potentialRuleMatch);
      }
    }
    return toRuleMatchArray(ruleMatches);
  }

  private RuleMatch createRuleMatch(AnalyzedTokenReadings readings, List<String> replacements) {
    String tokenString = readings.getToken();
    String msg = tokenString + getSuggestion(tokenString) + StringUtils.join(replacements, ", ");

    RuleMatch potentialRuleMatch = new RuleMatch(this, readings.getStartPos(), readings.getEndPos(), msg, getShort());
    potentialRuleMatch.setSuggestedReplacements(replacements);

    return potentialRuleMatch;
  }

  @Override
  public void reset() {
  }

  private static final Map<Character, Character> toLatMap = new HashMap<>();
  private static final Map<Character, Character> toCyrMap = new HashMap<>();
  private static final String cyrChars = "Ð°ÐµÑÐºÐ¼Ð¾ÑÑ?ÑÑÑÐ?ÐÐÐÐÐÐ?ÐÐ Ð¡Ð¢Ð£Ð¥";
  private static final String latChars = "aeikmopctyxABEIKMHOPCTYX";

  static {
    for (int i = 0; i < cyrChars.length(); i++) {
      toLatMap.put(cyrChars.charAt(i), latChars.charAt(i));
      toCyrMap.put(latChars.charAt(i), cyrChars.charAt(i));
    }
  }

  private static String toCyrillic(String word) {
    for (Map.Entry<Character, Character> entry : toCyrMap.entrySet()) {
      word = word.replace(entry.getKey(), entry.getValue());
    }
    return word;
  }

  private static String toLatin(String word) {
    for (Map.Entry<Character, Character> entry : toLatMap.entrySet()) {
      word = word.replace(entry.getKey(), entry.getValue());
    }
    return word;
  }

}

<code block>


package org.languagetool.rules.uk;

import java.io.IOException;
import java.util.ResourceBundle;
import java.util.regex.Pattern;

import org.languagetool.AnalyzedToken;
import org.languagetool.AnalyzedTokenReadings;
import org.languagetool.JLanguageTool;
import org.languagetool.Language;
import org.languagetool.rules.spelling.morfologik.MorfologikSpellerRule;
import org.languagetool.tagging.uk.IPOSTag;

public final class MorfologikUkrainianSpellerRule extends MorfologikSpellerRule {

  private static final String ABBREVIATION_CHAR = ".";
  private static final String RESOURCE_FILENAME = "/uk/hunspell/uk_UA.dict";
  private static final Pattern UKRAINIAN_LETTERS = Pattern.compile(".*[Ð°-Ñ?ÑÑÑÒÐ?-Ð¯ÐÐÐÒ?].*");

  public MorfologikUkrainianSpellerRule(ResourceBundle messages,
                                        Language language) throws IOException {
    super(messages, language);

  }

  @Override
  public String getFileName() {
    return RESOURCE_FILENAME;
  }

  @Override
  public String getId() {
    return "MORFOLOGIK_RULE_UK_UA";
  }

  @Override
  protected boolean ignoreToken(AnalyzedTokenReadings[] tokens, int idx) throws IOException {
    String word = tokens[idx].getToken();

    
    if( ! UKRAINIAN_LETTERS.matcher(word).matches() )
      return true;

    if( super.ignoreToken(tokens, idx) )
      return true;

    if( idx < tokens.length - 1 && tokens[idx+1].getToken().equals(ABBREVIATION_CHAR) ) {
      if( super.ignoreWord(word + ABBREVIATION_CHAR) ) {
        return true;
      }
      if( word.matches("[Ð?-Ð¯ÐÐÐÒ?]") ) {  
        return true;
      }
    }
    
    if( word.contains("-") ) {
      return hasGoodTag(tokens[idx]);
    }

    return false;
  }

  private boolean hasGoodTag(AnalyzedTokenReadings tokens) {
    for (AnalyzedToken analyzedToken : tokens) {
      String posTag = analyzedToken.getPOSTag();
      if( posTag != null 
            && ! posTag.equals(JLanguageTool.SENTENCE_START_TAGNAME) 
            && ! posTag.equals(JLanguageTool.SENTENCE_END_TAGNAME) 
            && ! posTag.contains(IPOSTag.bad.getText()) )
        return true;
    }
    return false;
  }


}

<code block>

package org.languagetool.tagging.uk;

import java.io.IOException;

import junit.framework.TestCase;

import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.tokenizers.uk.UkrainianWordTokenizer;

public class UkrainianTaggerTest extends TestCase {
    
  private UkrainianTagger tagger;
  private UkrainianWordTokenizer tokenizer;
      
  @Override
  public void setUp() {
    tagger = new UkrainianTagger();
    tokenizer = new UkrainianWordTokenizer();
  }

  public void testDictionary() throws IOException {
    TestTools.testDictionary(tagger, new Ukrainian());
  }
  
  public void testTagger() throws IOException {

    
    TestTools.myAssert("ÐºÐ¸ÑÐ²Ñ", "ÐºÐ¸ÑÐ²Ñ/[ÐºÐ¸Ð¹]noun:m:v_dav", tokenizer, tagger);
    TestTools.myAssert("ÐÐ¸ÑÐ²Ñ", "ÐÐ¸ÑÐ²Ñ/[ÐÐ¸ÑÐ²]noun:m:v_mis|ÐÐ¸ÑÐ²Ñ/[ÐºÐ¸Ð¹]noun:m:v_dav", tokenizer, tagger);
    TestTools.myAssert("Ð²ÑÐ»", "Ð²ÑÐ»/[Ð²ÑÐ»]noun:m:v_naz:anim", tokenizer, tagger);
    TestTools.myAssert("ÐÑÐ»", "ÐÑÐ»/[Ð²ÑÐ»]noun:m:v_naz:anim", tokenizer, tagger);
    TestTools.myAssert("ÐÐÐ", "ÐÐÐ/[ÐÐÐ]noun:m:v_dav:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_mis:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_naz:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_oru:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_rod:nv:np:abbr|ÐÐÐ/[ÐÐÐ]noun:m:v_zna:nv:np:abbr|ÐÐÐ/[Ð²ÑÐ»]noun:m:v_naz:anim", tokenizer, tagger);
    TestTools.myAssert("Ð´Ð°Ð»Ñ", "Ð´Ð°Ð»Ñ/[Ð´Ð°Ð»Ñ]adv", tokenizer, tagger);
    TestTools.myAssert("ÐÐ°Ð»Ñ", "ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_mis:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_dav:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_mis:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_naz:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_oru:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_rod:nv:np:anim:lname|ÐÐ°Ð»Ñ/[ÐÐ°Ð»Ñ]noun:m:v_zna:nv:np:anim:lname|ÐÐ°Ð»Ñ/[Ð´Ð°Ð»Ñ]adv", tokenizer, tagger);
    TestTools.myAssert("ÐÐµÐ½", "ÐÐµÐ½/[ÐÐµÐ½]noun:m:v_naz:anim:fname|ÐÐµÐ½/[Ð±ÐµÐ½]unknown", tokenizer, tagger);
    TestTools.myAssert("Ð±ÐµÐ½", "Ð±ÐµÐ½/[Ð±ÐµÐ½]unknown", tokenizer, tagger);


    TestTools.myAssert("Ð¡Ð¿ÑÐ°Ð²Ñ Ð¿Ð¾ÑÑÑÐµÐ½Ð¾ Ñ?ÑÐ´Ð¾Ð¼", 
      "Ð¡Ð¿ÑÐ°Ð²Ñ/[Ñ?Ð¿ÑÐ°Ð²Ð°]noun:f:v_zna -- Ð¿Ð¾ÑÑÑÐµÐ½Ð¾/[Ð¿Ð¾ÑÑÑÐ¸ÑÐ¸]verb:impers:perf -- Ñ?ÑÐ´Ð¾Ð¼/[Ñ?ÑÐ´]noun:m:v_oru|Ñ?ÑÐ´Ð¾Ð¼/[Ñ?ÑÐ´Ð¾Ð¼Ð°]noun:p:v_rod",
       tokenizer, tagger);
       
    String expected = 
      "ÐÐ°Ð¹Ð¶Ðµ/[Ð¼Ð°Ð¹Ð¶Ðµ]adv -- Ð´Ð²Ð°/[Ð´Ð²Ð°]numr:m:v_naz|Ð´Ð²Ð°/[Ð´Ð²Ð°]numr:m:v_zna|Ð´Ð²Ð°/[Ð´Ð²Ð°]numr:n:v_naz|Ð´Ð²Ð°/[Ð´Ð²Ð°]numr:n:v_zna -- ÑÐ¾ÐºÐ¸/[ÑÑÐº]noun:p:v_naz|ÑÐ¾ÐºÐ¸/[ÑÑÐº]noun:p:v_zna"
    + " -- ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¹]adj:m:v_dav:&pron:dem|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¹]adj:m:v_mis:&pron:dem|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¹]adj:n:v_dav:&pron:dem|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¹]adj:n:v_mis:&pron:dem|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼]noun:m:v_dav|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼]noun:m:v_mis|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼]noun:m:v_rod|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼Ñ]adv|ÑÐ¾Ð¼Ñ/[ÑÐ¾Ð¼Ñ]conj:subord"
    + " -- ÐÑÐ±Ð°/[ÐÑÐ±Ð°]noun:f:v_naz:anim:fname|ÐÑÐ±Ð°/[Ð»ÑÐ±Ð¸Ð¹]adj:f:v_naz -- ÑÐ°Ð·Ð¾Ð¼/[ÑÐ°Ð·]noun:m:v_oru|ÑÐ°Ð·Ð¾Ð¼/[ÑÐ°Ð·Ð¾Ð¼]adv -- ÑÐ·/[ÑÐ·]prep:rv_rod:rv_zna:rv_oru"
    + " -- ÑÐ¾Ð»Ð¾Ð²ÑÐºÐ¾Ð¼/[ÑÐ¾Ð»Ð¾Ð²ÑÐº]noun:m:v_oru:anim -- Ð¡ÑÐµÐ¿Ð°Ð½Ð¾Ð¼/[Ð¡ÑÐµÐ¿Ð°Ð½]noun:m:v_oru:anim:fname -- Ð²Ð¸ÑÑÐ°Ð»Ð¸/[Ð²Ð¸ÑÑÐ°ÑÐ¸]verb:past:m:perf -- ÑÑÐ´Ð¸/[ÑÑÐ´Ð¸]adv:&pron:dem"
    + " -- Ð½Ð°/[Ð½Ð°]excl|Ð½Ð°/[Ð½Ð°]part|Ð½Ð°/[Ð½Ð°]prep:rv_zna:rv_mis -- "
    + "Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:n:v_naz|Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:n:v_rod|Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:n:v_zna|Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:p:v_naz|Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?/[Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?]noun:p:v_zna";
  
    TestTools.myAssert("ÐÐ°Ð¹Ð¶Ðµ Ð´Ð²Ð° ÑÐ¾ÐºÐ¸ ÑÐ¾Ð¼Ñ ÐÑÐ±Ð° ÑÐ°Ð·Ð¾Ð¼ ÑÐ· ÑÐ¾Ð»Ð¾Ð²ÑÐºÐ¾Ð¼ Ð¡ÑÐµÐ¿Ð°Ð½Ð¾Ð¼ Ð²Ð¸ÑÑÐ°Ð»Ð¸ ÑÑÐ´Ð¸ Ð½Ð° Ð¿ÑÐ¾Ð¶Ð¸Ð²Ð°Ð½Ð½Ñ?.",
        expected, tokenizer, tagger);
  }

  public void testNumberTagging() throws IOException {
    TestTools.myAssert("101,234", "101,234/[101,234]number", tokenizer, tagger);
    TestTools.myAssert("3,5-5,6% 7Â° 7,4Â°Ð¡", "3,5-5,6%/[3,5-5,6%]number -- 7Â°/[7Â°]number -- 7,4Â°Ð¡/[7,4Â°Ð¡]number", tokenizer, tagger);
    TestTools.myAssert("XIX", "XIX/[XIX]number", tokenizer, tagger);

    TestTools.myAssert("14.07.2001", "14.07.2001/[14.07.2001]date", tokenizer, tagger);

    TestTools.myAssert("Ð¾ 15.33", "Ð¾/[Ð¾]excl|Ð¾/[Ð¾]prep:rv_zna:rv_mis -- 15.33/[15.33]time", tokenizer, tagger);
    TestTools.myAssert("Ð 1:05", "Ð/[Ð¾]excl|Ð/[Ð¾]prep:rv_zna:rv_mis -- 1:05/[1:05]time", tokenizer, tagger);
  }
  
  public void testTaggingWithDots() throws IOException {
    TestTools.myAssert("300 Ñ. Ð´Ð¾ Ð½. Ðµ.", 
      "300/[300]number -- Ñ./[null]null -- Ð´Ð¾/[Ð´Ð¾]noun:n:v_dav:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_mis:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_naz:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_oru:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_rod:nv|Ð´Ð¾/[Ð´Ð¾]noun:n:v_zna:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_dav:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_mis:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_naz:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_oru:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_rod:nv|Ð´Ð¾/[Ð´Ð¾]noun:p:v_zna:nv|Ð´Ð¾/[Ð´Ð¾]prep:rv_rod -- Ð½./[null]null -- Ðµ/[Ðµ]excl",
       tokenizer, tagger);
  



  }
  
  public void testDynamicTagging() throws IOException {
    TestTools.myAssert("Ð³-Ð³-Ð³", "Ð³-Ð³-Ð³/[null]null", tokenizer, tagger);
    
    TestTools.myAssert("100-ÑÑÑÐ½Ð¾Ð¼Ñ", "100-ÑÑÑÐ½Ð¾Ð¼Ñ/[100-ÑÑÑÐ½Ð¸Ð¹]adj:m:v_dav|100-ÑÑÑÐ½Ð¾Ð¼Ñ/[100-ÑÑÑÐ½Ð¸Ð¹]adj:m:v_mis|100-ÑÑÑÐ½Ð¾Ð¼Ñ/[100-ÑÑÑÐ½Ð¸Ð¹]adj:n:v_dav|100-ÑÑÑÐ½Ð¾Ð¼Ñ/[100-ÑÑÑÐ½Ð¸Ð¹]adj:n:v_mis", tokenizer, tagger);
    TestTools.myAssert("100-Ð¹", "100-Ð¹/[100-Ð¹]adj:m:v_naz|100-Ð¹/[100-Ð¹]adj:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("50-Ñ", "50-Ñ/[50-Ð¹]adj:p:v_rod|50-Ñ/[50-Ð¹]adj:p:v_zna", tokenizer, tagger);

    TestTools.myAssert("Ð¿Ð¾-Ñ?Ð²Ð¸Ð½Ñ?ÑÐ¾Ð¼Ñ", "Ð¿Ð¾-Ñ?Ð²Ð¸Ð½Ñ?ÑÐ¾Ð¼Ñ/[Ð¿Ð¾-Ñ?Ð²Ð¸Ð½Ñ?ÑÐ¾Ð¼Ñ]adv", tokenizer, tagger);
    TestTools.myAssert("Ð¿Ð¾-Ñ?Ð¸Ð±ÑÑÑ?ÑÐºÐ¸", "Ð¿Ð¾-Ñ?Ð¸Ð±ÑÑÑ?ÑÐºÐ¸/[Ð¿Ð¾-Ñ?Ð¸Ð±ÑÑÑ?ÑÐºÐ¸]adv", tokenizer, tagger);

    TestTools.myAssert("Ð´Ð°Ð²Ð°Ð¹-Ð½Ð¾", "Ð´Ð°Ð²Ð°Ð¹-Ð½Ð¾/[Ð´Ð°Ð²Ð°ÑÐ¸]verb:impr:s:2:imperf", tokenizer, tagger);
    TestTools.myAssert("Ð´Ð¸Ð²ÑÑÑÑ?Ñ?-Ð½Ð¾", "Ð´Ð¸Ð²ÑÑÑÑ?Ñ?-Ð½Ð¾/[Ð´Ð¸Ð²Ð¸ÑÐ¸Ñ?Ñ?]verb:rev:impr:p:2:imperf", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸", "ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸/[ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸]adj:m:v_naz:&pron:dem|ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸/[ÑÐ¾Ð¹-ÑÐ°ÐºÐ¸]adj:m:v_zna:&pron:dem", tokenizer, tagger);
    TestTools.myAssert("Ð±ÑÐ´Ðµ-ÑÐ°ÐºÐ¸", "Ð±ÑÐ´Ðµ-ÑÐ°ÐºÐ¸/[Ð±ÑÑÐ¸]verb:futr:s:3:imperf", tokenizer, tagger);
    TestTools.myAssert("Ð¾ÑÐµÐ¹-Ð¾Ñ", "Ð¾ÑÐµÐ¹-Ð¾Ñ/[Ð¾ÑÐµÐ¹]adj:m:v_naz:&pron:dem|Ð¾ÑÐµÐ¹-Ð¾Ñ/[Ð¾ÑÐµÐ¹]adj:m:v_zna:&pron:dem", tokenizer, tagger);
    TestTools.myAssert("Ð¾ÑÑÐ°ÐºÐ¸Ð¹-ÑÐ¾", "Ð¾ÑÑÐ°ÐºÐ¸Ð¹-ÑÐ¾/[Ð¾ÑÑÐ°ÐºÐ¸Ð¹]adj:m:v_naz:&pron:dem:rare|Ð¾ÑÑÐ°ÐºÐ¸Ð¹-ÑÐ¾/[Ð¾ÑÑÐ°ÐºÐ¸Ð¹]adj:m:v_zna:&pron:dem:rare", tokenizer, tagger);
    TestTools.myAssert("Ð³ÐµÑÑ-ÑÐ¾", "Ð³ÐµÑÑ-ÑÐ¾/[Ð³ÐµÑÑ]adv|Ð³ÐµÑÑ-ÑÐ¾/[Ð³ÐµÑÑ]part", tokenizer, tagger);
    TestTools.myAssert("Ð°Ð½Ñ-Ð±Ð¾", "Ð°Ð½Ñ-Ð±Ð¾/[Ð°Ð½Ñ]excl|Ð°Ð½Ñ-Ð±Ð¾/[Ð°Ð½Ñ]part", tokenizer, tagger);
    TestTools.myAssert("Ð³Ð¾Ð´Ñ-Ð±Ð¾", "Ð³Ð¾Ð´Ñ-Ð±Ð¾/[Ð³Ð¾Ð´Ñ]predic", tokenizer, tagger);
    TestTools.myAssert("Ð³ÐµÐ¹-Ð½Ð¾", "Ð³ÐµÐ¹-Ð½Ð¾/[Ð³ÐµÐ¹]excl", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¸ÑÑ-Ð½Ð¾", "ÑÐ¸ÑÑ-Ð½Ð¾/[ÑÐ¸ÑÑ]excl", tokenizer, tagger);

    TestTools.myAssert("ÐµÐºÑ?-Ð¿Ð°ÑÑÐ½ÐµÑ", "ÐµÐºÑ?-Ð¿Ð°ÑÑÐ½ÐµÑ/[ÐµÐºÑ?-Ð¿Ð°ÑÑÐ½ÐµÑ]noun:m:v_naz:anim", tokenizer, tagger);

    
    TestTools.myAssert("Ð?Ð»ÑÑÐ²Ð°-Ñ?ÑÐ°ÑÑÐ¾Ð³Ð¾", "Ð?Ð»ÑÑÐ²Ð°-Ñ?ÑÐ°ÑÑÐ¾Ð³Ð¾/[Ð?Ð»ÑÑÐ²-Ñ?ÑÐ°ÑÐ¸Ð¹]noun:m:v_rod:anim:lname|Ð?Ð»ÑÑÐ²Ð°-Ñ?ÑÐ°ÑÑÐ¾Ð³Ð¾/[Ð?Ð»ÑÑÐ²-Ñ?ÑÐ°ÑÐ¸Ð¹]noun:m:v_zna:anim:lname", tokenizer, tagger);


    
    TestTools.myAssert("Ð¶Ð¸Ð»Ð¾-Ð±ÑÐ»Ð¾", "Ð¶Ð¸Ð»Ð¾-Ð±ÑÐ»Ð¾/[Ð¶Ð¸ÑÐ¸-Ð±ÑÑÐ¸]verb:past:n:imperf", tokenizer, tagger);
    TestTools.myAssert("ÑÑÐ¸Ñ-ÑÑÐ¸Ñ", "ÑÑÐ¸Ñ-ÑÑÐ¸Ñ/[ÑÑÐ¸ÑÐ¸-ÑÑÐ¸ÑÐ¸]verb:pres:s:2:imperf:v-u", tokenizer, tagger);

    TestTools.myAssert("Ð²Ð³Ð¾ÑÑ-Ð²Ð½Ð¸Ð·", "Ð²Ð³Ð¾ÑÑ-Ð²Ð½Ð¸Ð·/[Ð²Ð³Ð¾ÑÑ-Ð²Ð½Ð¸Ð·]adv:v-u", tokenizer, tagger);

    TestTools.myAssert("Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾-Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾", "Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾-Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾/[Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾-Ð½Ð¸Ð·ÐµÐ½ÑÐºÐ¾]adv", tokenizer, tagger);
    TestTools.myAssert("ÑÐ°ÐºÐ¾Ð³Ð¾-Ñ?Ñ?ÐºÐ¾Ð³Ð¾", "ÑÐ°ÐºÐ¾Ð³Ð¾-Ñ?Ñ?ÐºÐ¾Ð³Ð¾/[ÑÐ°ÐºÐ¸Ð¹-Ñ?Ñ?ÐºÐ¸Ð¹]adj:m:v_rod:&pron:def|ÑÐ°ÐºÐ¾Ð³Ð¾-Ñ?Ñ?ÐºÐ¾Ð³Ð¾/[ÑÐ°ÐºÐ¸Ð¹-Ñ?Ñ?ÐºÐ¸Ð¹]adj:m:v_zna:&pron:def|ÑÐ°ÐºÐ¾Ð³Ð¾-Ñ?Ñ?ÐºÐ¾Ð³Ð¾/[ÑÐ°ÐºÐ¸Ð¹-Ñ?Ñ?ÐºÐ¸Ð¹]adj:n:v_rod:&pron:def", tokenizer, tagger);
    TestTools.myAssert("Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹", "Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹/[Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹]adj:m:v_naz|Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹/[Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹-Ð¿ÑÐµÐ²ÐµÐ»Ð¸ÐºÐ¸Ð¹]adj:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¾ÑÐ½ÑÐ¹-ÑÐ¾ÑÐ½ÑÐ¹", "ÑÐ¾ÑÐ½ÑÐ¹-ÑÐ¾ÑÐ½ÑÐ¹/[ÑÐ¾ÑÐ½Ð¸Ð¹-ÑÐ¾ÑÐ½Ð¸Ð¹]adj:f:v_dav|ÑÐ¾ÑÐ½ÑÐ¹-ÑÐ¾ÑÐ½ÑÐ¹/[ÑÐ¾ÑÐ½Ð¸Ð¹-ÑÐ¾ÑÐ½Ð¸Ð¹]adj:f:v_mis|ÑÐ¾ÑÐ½ÑÐ¹-ÑÐ¾ÑÐ½ÑÐ¹/[ÑÐ¾ÑÐ½ÑÑÐ¸-ÑÐ¾ÑÐ½ÑÑÐ¸]verb:impr:s:2:imperf", tokenizer, tagger);

    TestTools.myAssert("Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ", "Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ/[Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ]noun:m:v_naz:anim", tokenizer, tagger);
    TestTools.myAssert("Ð»ÑÐºÐ°ÑÑ?-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°ÑÐ°", "Ð»ÑÐºÐ°ÑÑ?-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°ÑÐ°/[Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ]noun:m:v_rod:anim|Ð»ÑÐºÐ°ÑÑ?-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°ÑÐ°/[Ð»ÑÐºÐ°Ñ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ]noun:m:v_zna:anim", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¼ÐºÑ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ", "ÑÐ¼ÐºÑ-Ð³Ð¾Ð¼ÐµÐ¾Ð¿Ð°Ñ/[null]null", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¼ÐºÑ-ÑÐºÑ", "ÑÐ¼ÐºÑ-ÑÐºÑ/[null]null", tokenizer, tagger);

    TestTools.myAssert("Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´", "Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´/[Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´]noun:m:v_naz:v-u|Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´/[Ð²ÑÐ¸Ð½Ð¾Ðº-Ð¿ÑÐ¸ÐºÐ»Ð°Ð´]noun:m:v_zna:v-u", tokenizer, tagger);
    TestTools.myAssert("Ð¼ÑÑ?ÑÐ°-ÑÐ¾ÑÑÐµÑÑ", "Ð¼ÑÑ?ÑÐ°-ÑÐ¾ÑÑÐµÑÑ/[Ð¼ÑÑ?ÑÐ¾-ÑÐ¾ÑÑÐµÑÑ?]noun:n:v_rod|Ð¼ÑÑ?ÑÐ°-ÑÐ¾ÑÑÐµÑÑ/[Ð¼ÑÑ?ÑÐ¾-ÑÐ¾ÑÑÐµÑÑ?]noun:p:v_naz|Ð¼ÑÑ?ÑÐ°-ÑÐ¾ÑÑÐµÑÑ/[Ð¼ÑÑ?ÑÐ¾-ÑÐ¾ÑÑÐµÑÑ?]noun:p:v_zna", tokenizer, tagger);

    
    TestTools.myAssert("Ð²ÑÐµÐ½Ð¸Ñ-Ð½Ð¾Ð²Ð°ÑÐ¾ÑÑÐ²", "Ð²ÑÐµÐ½Ð¸Ñ-Ð½Ð¾Ð²Ð°ÑÐ¾ÑÑÐ²/[Ð²ÑÐµÐ½Ð¸Ð¹-Ð½Ð¾Ð²Ð°ÑÐ¾Ñ]noun:p:v_rod:anim:v-u|Ð²ÑÐµÐ½Ð¸Ñ-Ð½Ð¾Ð²Ð°ÑÐ¾ÑÑÐ²/[Ð²ÑÐµÐ½Ð¸Ð¹-Ð½Ð¾Ð²Ð°ÑÐ¾Ñ]noun:p:v_zna:anim:v-u", tokenizer, tagger);
    TestTools.myAssert("ÐºÑÐ°ÑÐ½Ð°-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº", "ÐºÑÐ°ÑÐ½Ð°-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº/[ÐºÑÐ°ÑÐ½Ð°-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº]noun:f:v_naz", tokenizer, tagger);
    TestTools.myAssert("Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº", "Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº/[Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº]noun:m:v_naz|Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº/[Ð±Ð°Ð½Ðº-Ð²Ð¸ÑÐ¾Ð±Ð½Ð¸Ðº]noun:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸", "Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸/[Ð±Ð°Ð½Ðº-Ð°Ð³ÐµÐ½Ñ]noun:p:v_naz|Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸/[Ð±Ð°Ð½Ðº-Ð°Ð³ÐµÐ½Ñ]noun:p:v_zna|Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸/[Ð±Ð°Ð½ÐºÐ°-Ð°Ð³ÐµÐ½Ñ]noun:p:v_naz|Ð±Ð°Ð½ÐºÐ¸-Ð°Ð³ÐµÐ½ÑÐ¸/[Ð±Ð°Ð½ÐºÐ°-Ð°Ð³ÐµÐ½Ñ]noun:p:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ", "Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ/[Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ]noun:n:v_naz|Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ/[Ð¼ÑÑ?ÑÐ¾-Ð³ÑÐ³Ð°Ð½Ñ]noun:n:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÐºÑÐ°ÑÐ½Ð¸-Ð°Ð³ÑÐµÑ?Ð¾ÑÐ¸", "ÐºÑÐ°ÑÐ½Ð¸-Ð°Ð³ÑÐµÑ?Ð¾ÑÐ¸/[ÐºÑÐ°ÑÐ½Ð°-Ð°Ð³ÑÐµÑ?Ð¾Ñ]noun:p:v_naz|ÐºÑÐ°ÑÐ½Ð¸-Ð°Ð³ÑÐµÑ?Ð¾ÑÐ¸/[ÐºÑÐ°ÑÐ½Ð°-Ð°Ð³ÑÐµÑ?Ð¾Ñ]noun:p:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ", "Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ/[Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ]noun:n:v_naz|Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ/[Ð¿Ð¾Ñ?ÐµÐ»ÐµÐ½Ð½Ñ?-Ð³ÑÐ³Ð°Ð½Ñ]noun:n:v_zna", tokenizer, tagger);
    
    TestTools.myAssert("Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ", "Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ/[Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ]noun:m:v_naz|Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ/[Ñ?Ð¾Ð½Ñ?Ñ-ÐºÑÐ°Ñ?ÐµÐ½Ñ]noun:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ", "ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ/[ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ]noun:m:v_naz|ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ/[ÐºÑÐ°Ñ?ÐµÐ½Ñ-Ñ?Ð¾Ð½Ñ?Ñ]noun:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð´ÐµÐ¿ÑÑÐ°ÑÑÐ²-Ð¿ÑÐ¸Ð²Ð¸Ð´ÑÐ²", "Ð´ÐµÐ¿ÑÑÐ°ÑÑÐ²-Ð¿ÑÐ¸Ð²Ð¸Ð´ÑÐ²/[Ð´ÐµÐ¿ÑÑÐ°Ñ-Ð¿ÑÐ¸Ð²Ð¸Ð´]noun:p:v_rod:anim|Ð´ÐµÐ¿ÑÑÐ°ÑÑÐ²-Ð¿ÑÐ¸Ð²Ð¸Ð´ÑÐ²/[Ð´ÐµÐ¿ÑÑÐ°Ñ-Ð¿ÑÐ¸Ð²Ð¸Ð´]noun:p:v_zna:anim", tokenizer, tagger);
    TestTools.myAssert("Ð´ÑÐ²ÑÐ°ÑÐ°-Ð·ÑÑÐ¾ÑÐºÐ¸", "Ð´ÑÐ²ÑÐ°ÑÐ°-Ð·ÑÑÐ¾ÑÐºÐ¸/[Ð´ÑÐ²ÑÐ°-Ð·ÑÑÐ¾ÑÐºÐ°]noun:p:v_naz:anim", tokenizer, tagger);

    TestTools.myAssert("Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°", "Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°/[Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°]noun:m:v_naz|Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°/[Ð°Ð±Ð·Ð°Ñ-Ð´Ð²Ð°]noun:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ñ?Ð¾ÑÐ½Ñ-Ð´Ð²Ñ", "Ñ?Ð¾ÑÐ½Ñ-Ð´Ð²Ñ/[Ñ?Ð¾ÑÐ½Ñ?-Ð´Ð²Ð°]noun:p:v_naz|Ñ?Ð¾ÑÐ½Ñ-Ð´Ð²Ñ/[Ñ?Ð¾ÑÐ½Ñ?-Ð´Ð²Ð°]noun:p:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÑÐ¸Ñ?Ñ?ÑÐµÑ-ÑÑÑÐ¾Ð¼Ð°", "ÑÐ¸Ñ?Ñ?ÑÐµÑ-ÑÑÑÐ¾Ð¼Ð°/[ÑÐ¸Ñ?Ñ?ÑÐ°-ÑÑÐ¸]noun:f:v_oru|ÑÐ¸Ñ?Ñ?ÑÐµÑ-ÑÑÑÐ¾Ð¼Ð°/[ÑÐ¸Ñ?Ñ?ÑÐ°-ÑÑÐ¾Ñ]noun:f:v_oru", tokenizer, tagger);

    TestTools.myAssert("Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°", "Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð°]numr:m:v_oru|Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð°]numr:n:v_oru|Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð¾Ñ]numr:m:v_oru|Ð¾Ð´Ð½Ð¸Ð¼-Ð´Ð²Ð¾Ð¼Ð°/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð¾Ñ]numr:n:v_oru", tokenizer, tagger);
    

    TestTools.myAssert("Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸", "Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸/[Ð¿'Ñ?ÑÐ°-ÑÑÑ?ÑÑ]noun:f:v_rod|Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸/[Ð¿'Ñ?ÑÑ-ÑÑÑ?ÑÑ]numr:p:v_dav|Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸/[Ð¿'Ñ?ÑÑ-ÑÑÑ?ÑÑ]numr:p:v_mis|Ð¿'Ñ?ÑÐ¸-ÑÐµÑ?ÑÐ¸/[Ð¿'Ñ?ÑÑ-ÑÑÑ?ÑÑ]numr:p:v_rod", tokenizer, tagger);
    TestTools.myAssert("Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ñ", "Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ñ/[Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ð°]numr:f:v_naz|Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ñ/[Ð¿ÑÐ²ÑÐ¾ÑÐ¸-Ð´Ð²Ð°]numr:f:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸", "ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸/[ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸]numr:p:v_naz|ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸/[ÑÑÐ¸-ÑÐ¾ÑÐ¸ÑÐ¸]numr:p:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸", "Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸/[Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸]numr:m:v_naz|Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸/[Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸]numr:m:v_zna|Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸/[Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸]numr:n:v_naz|Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸/[Ð´Ð²Ð°-ÑÐ¾ÑÐ¸ÑÐ¸]numr:n:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ", "Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð°]numr:m:v_mis|Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð°]numr:n:v_mis|Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð¾Ñ]numr:m:v_mis|Ð¾Ð´Ð½Ð¾Ð¼Ñ-Ð´Ð²Ð¾Ñ/[Ð¾Ð´Ð¸Ð½-Ð´Ð²Ð¾Ñ]numr:n:v_mis", tokenizer, tagger);
    
    TestTools.myAssert("ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸", "ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸/[ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸]numr:p:v_naz|ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸/[ÑÑÐ¸âÑÐ¾ÑÐ¸ÑÐ¸]numr:p:v_zna", tokenizer, tagger);
    






    TestTools.myAssert("Ð°-Ð°", "Ð°-Ð°/[Ð°-Ð°]excl", tokenizer, tagger);

    TestTools.myAssert("ÐÐ¾Ñ?ÐºÐ²Ð¸-ÑÑÐºÐ¸", "ÐÐ¾Ñ?ÐºÐ²Ð¸-ÑÑÐºÐ¸/[ÐÐ¾Ñ?ÐºÐ²Ð°-ÑÑÐºÐ°]noun:f:v_rod", tokenizer, tagger);
    
    TestTools.myAssert("Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸", "Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_dav|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_mis|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_naz|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_oru|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_rod|Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸/[Ð¿ÑÐ²-Ð£ÐºÑÐ°ÑÐ½Ð¸]noun:f:v_zna", tokenizer, tagger);

    TestTools.myAssert("ÐºÐ°Ð²Ð°-ÐµÑ?Ð¿ÑÐµÑ?Ð¾", "ÐºÐ°Ð²Ð°-ÐµÑ?Ð¿ÑÐµÑ?Ð¾/[ÐºÐ°Ð²Ð°-ÐµÑ?Ð¿ÑÐµÑ?Ð¾]noun:f:v_naz", tokenizer, tagger);
    TestTools.myAssert("ÐºÐ°Ð²Ð¸-ÐµÑ?Ð¿ÑÐµÑ?Ð¾", "ÐºÐ°Ð²Ð¸-ÐµÑ?Ð¿ÑÐµÑ?Ð¾/[ÐºÐ°Ð²Ð°-ÐµÑ?Ð¿ÑÐµÑ?Ð¾]noun:f:v_rod", tokenizer, tagger);
    TestTools.myAssert("ÐµÑ?Ð¿ÑÐµÑ?Ð¾-Ð¼Ð°ÑÐ¸Ð½Ð°", "ÐµÑ?Ð¿ÑÐµÑ?Ð¾-Ð¼Ð°ÑÐ¸Ð½Ð°/[ÐµÑ?Ð¿ÑÐµÑ?Ð¾-Ð¼Ð°ÑÐ¸Ð½Ð°]noun:f:v_naz", tokenizer, tagger);
    TestTools.myAssert("Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¾Ñ-Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼", "Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¾Ñ-Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼/[Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð°-Ð¼Ð°ÐºÑ?Ð¸Ð¼ÑÐ¼]noun:f:v_oru", tokenizer, tagger);

    TestTools.myAssert("ÐÐµÐ½Ñ?Ð¸Ð»ÑÐ²Ð°Ð½ÑÑ?-Ð°Ð²ÐµÐ½Ñ", "ÐÐµÐ½Ñ?Ð¸Ð»ÑÐ²Ð°Ð½ÑÑ?-Ð°Ð²ÐµÐ½Ñ/[ÐÐµÐ½Ñ?Ð¸Ð»ÑÐ²Ð°Ð½ÑÑ?-Ð°Ð²ÐµÐ½Ñ]noun:f:nv", tokenizer, tagger);

    TestTools.myAssert("Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹", "Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹/[Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹]adj:m:v_naz|Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹/[Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹]adj:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("Ð¿Ð°ÑÐ°Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹", "Ð¿Ð°ÑÐ°Ð»Ð¾Ð³Ð¾-Ð°Ð½Ð°ÑÐ¾Ð¼ÑÑÐ½Ð¸Ð¹/[null]null", tokenizer, tagger);
    

    TestTools.myAssert("Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð³Ð¼ÐºÐ½Ñ", "Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð³Ð¼ÐºÐ½Ñ/[null]null", tokenizer, tagger);
    TestTools.myAssert("Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð³Ð¾Ð»Ð¾Ð²Ð°", "Ð¿Ð°ÑÐ¾Ð»Ð¾Ð³Ð¾-Ð³Ð¾Ð»Ð¾Ð²Ð°/[null]null", tokenizer, tagger);
    
    TestTools.myAssert("Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹", "Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹/[Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹]adj:m:v_naz:compb|Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹/[Ð¾Ñ?Ð²ÑÑÐ½ÑÐ¾-ÐºÑÐ»ÑÑÑÑÐ½Ð¸Ð¹]adj:m:v_zna:compb", tokenizer, tagger);
    TestTools.myAssert("Ð±ÑÑÐ¼ÑÐºÐ¾Ð²Ð¾-Ð±Ð»Ð°ÐºÐ¸ÑÐ½Ð¸Ð¹", "Ð±ÑÑÐ¼ÑÐºÐ¾Ð²Ð¾-Ð±Ð»Ð°ÐºÐ¸ÑÐ½Ð¸Ð¹/[null]null", tokenizer, tagger);
    TestTools.myAssert("Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¾Ð³Ð¾", "Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¾Ð³Ð¾/[Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¸Ð¹]adj:m:v_rod:compb|Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¾Ð³Ð¾/[Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¸Ð¹]adj:m:v_zna:compb|Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¾Ð³Ð¾/[Ñ?Ð»ÑÐ¿ÑÑÐµ-Ñ?Ñ?ÐºÑÐ°Ð²Ð¸Ð¹]adj:n:v_rod:compb", tokenizer, tagger);
    TestTools.myAssert("Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹", "Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹/[Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹]adj:m:v_naz|Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹/[Ð´Ð²Ð¾-ÑÑÐ¸Ð¼ÐµÑÑÐ¾Ð²Ð¸Ð¹]adj:m:v_zna", tokenizer, tagger);
    TestTools.myAssert("ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹", "ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹/[ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹]adj:m:v_naz|ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹/[ÑÐºÑÐ°ÑÐ½Ð¾-Ð±Ð¾Ð»Ð³Ð°ÑÑ?ÑÐºÐ¸Ð¹]adj:m:v_zna", tokenizer, tagger);



    TestTools.myAssert("ÐÑÐ²ÑÐ¸Ð½ÐºÐ°-Ð¿ÐµÑÑÐ¾ÐºÐ»Ð°Ñ?Ð½Ð¸ÑÑ?", "ÐÑÐ²ÑÐ¸Ð½ÐºÐ°-Ð¿ÐµÑÑÐ¾ÐºÐ»Ð°Ñ?Ð½Ð¸ÑÑ?/[Ð´ÑÐ²ÑÐ¸Ð½ÐºÐ°-Ð¿ÐµÑÑÐ¾ÐºÐ»Ð°Ñ?Ð½Ð¸ÑÑ?]noun:f:v_naz:anim", tokenizer, tagger);

    
    
    
    
    
    
  }

}

<code block>


package org.languagetool.tokenizers.uk;

import java.util.Arrays;
import java.util.List;

import junit.framework.TestCase;

public class UkrainianWordTokenizerTest extends TestCase {
  private final UkrainianWordTokenizer w = new UkrainianWordTokenizer();

  public void testTokenize() {
    List<String> testList = w.tokenize("ÐÐ¾Ð½Ð¸ Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸ Ð´Ð¾Ð´Ð¾Ð¼Ñ.");
    assertEquals(Arrays.asList("ÐÐ¾Ð½Ð¸", " ", "Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸", " ", "Ð´Ð¾Ð´Ð¾Ð¼Ñ", "."), testList);

    testList = w.tokenize("ÐÐ¾Ð½Ð¸ Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸ Ð¿Ê¼Ñ?ÑÐ¸Ð¼Ð¸ Ð·ÑÐ²âÑ?Ð»Ð¸Ð¼Ð¸.");
    assertEquals(Arrays.asList("ÐÐ¾Ð½Ð¸", " ", "Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸", " ", "Ð¿'Ñ?ÑÐ¸Ð¼Ð¸", " ", "Ð·ÑÐ²'Ñ?Ð»Ð¸Ð¼Ð¸", "."), testList);




    testList = w.tokenize("ÐÐ°Ñ?ÑÐ´Ð°Ð² Ð.ÐÑÐ¼Ð¾Ð»ÑÐº.");
    assertEquals(Arrays.asList("ÐÐ°Ñ?ÑÐ´Ð°Ð²", " ", "Ð", ".", "ÐÑÐ¼Ð¾Ð»ÑÐº", "."), testList);

    testList = w.tokenize("ÐÐ°Ñ?ÑÐ´Ð°Ð² Ð.Ð.ÐÑÐ¼Ð¾Ð»ÑÐº.");
    assertEquals(Arrays.asList("ÐÐ°Ñ?ÑÐ´Ð°Ð²", " ", "Ð", ".", "Ð", ".", "ÐÑÐ¼Ð¾Ð»ÑÐº", "."), testList);

    testList = w.tokenize("Ð.\u00A0ÐÑÐ¼Ð¾Ð»ÑÐº.");
    assertEquals(Arrays.asList("Ð", ".", "\u00A0", "ÐÑÐ¼Ð¾Ð»ÑÐº", "."), testList);

    testList = w.tokenize("300 Ð³ÑÐ½. Ð½Ð° Ð±Ð°Ð»Ð°Ð½Ñ?Ñ");
    assertEquals(Arrays.asList("300", " ", "Ð³ÑÐ½.", " ", "Ð½Ð°", " ", "Ð±Ð°Ð»Ð°Ð½Ñ?Ñ"), testList);

    testList = w.tokenize("Ð½Ð°Ð´ÑÐ¹ÑÐ»Ð¾ 2,2 Ð¼ÑÐ»ÑÐ¹Ð¾Ð½Ð°");
    assertEquals(Arrays.asList("Ð½Ð°Ð´ÑÐ¹ÑÐ»Ð¾", " ", "2,2", " ", "Ð¼ÑÐ»ÑÐ¹Ð¾Ð½Ð°"), testList);

    testList = w.tokenize("Ð½Ð°Ð´ÑÐ¹ÑÐ»Ð¾ 84,46 Ð¼ÑÐ»ÑÐ¹Ð¾Ð½Ð°");
    assertEquals(Arrays.asList("Ð½Ð°Ð´ÑÐ¹ÑÐ»Ð¾", " ", "84,46", " ", "Ð¼ÑÐ»ÑÐ¹Ð¾Ð½Ð°"), testList);




    testList = w.tokenize("Ñ?ÑÐ°Ð»Ð¾Ñ?Ñ? 14.07.2001 Ð²Ð½Ð¾ÑÑ");
    assertEquals(Arrays.asList("Ñ?ÑÐ°Ð»Ð¾Ñ?Ñ?", " ", "14.07.2001", " ", "Ð²Ð½Ð¾ÑÑ"), testList);

    testList = w.tokenize("Ð²ÑÐ¾ÑÐ° Ð¾ 7.30 ÑÐ°Ð½ÐºÑ");
    assertEquals(Arrays.asList("Ð²ÑÐ¾ÑÐ°", " ", "Ð¾", " ", "7.30", " ", "ÑÐ°Ð½ÐºÑ"), testList);

    testList = w.tokenize("Ñ? ÑÐºÑÐ°ÑÐ½ÐµÑÑ(Ñ?Ð¼ÑÑÑÑÑ?Ñ?");
    assertEquals(Arrays.asList("Ñ?", " ", "ÑÐºÑÐ°ÑÐ½ÐµÑÑ", "(", "Ñ?Ð¼ÑÑÑÑÑ?Ñ?"), testList);
        
    testList = w.tokenize("ÐÐ£Ð?(Ð±) ÑÐ° ÐÐ(Ð±)Ð£");
    assertEquals(Arrays.asList("ÐÐ£Ð?(Ð±)", " ", "ÑÐ°", " ", "ÐÐ(Ð±)Ð£"), testList);

    testList = w.tokenize("Ð?ÐµÐ³Ð¾Ð´Ð° Ñ... Ð·Ð°Ñ?ÑÑÐ¿Ð½Ð¸ÐºÐ¾Ð¼");
    assertEquals(Arrays.asList("Ð?ÐµÐ³Ð¾Ð´Ð°", " ", "Ñ", "...", " ", "Ð·Ð°Ñ?ÑÑÐ¿Ð½Ð¸ÐºÐ¾Ð¼"), testList);

    testList = w.tokenize("140 ÑÐ¸Ñ?. Ð¿ÑÐ°ÑÑÐ²Ð½Ð¸ÐºÑÐ²");
    assertEquals(Arrays.asList("140", " ", "ÑÐ¸Ñ?.", " ", "Ð¿ÑÐ°ÑÑÐ²Ð½Ð¸ÐºÑÐ²"), testList);

    testList = w.tokenize("Ð¿ÑÐ¾Ñ. Ð?ÑÑÑÑÐ¾Ð²");
    assertEquals(Arrays.asList("Ð¿ÑÐ¾Ñ.", " ", "Ð?ÑÑÑÑÐ¾Ð²"), testList);
  }

}

<code block>


package org.languagetool.tokenizers.uk;

import junit.framework.TestCase;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.tokenizers.SRXSentenceTokenizer;

public class UkrainianSRXSentenceTokenizerTest extends TestCase {

  private final SRXSentenceTokenizer stokenizer = new SRXSentenceTokenizer(new Ukrainian());

  public final void testTokenize() {
    testSplit("Ð¦Ðµ Ð¿ÑÐ¾Ñ?ÑÐµ ÑÐµÑÐµÐ½Ð½Ñ?.");
    testSplit("ÐÐ¾Ð½Ð¸ Ð¿ÑÐ¸ÑÑÐ°Ð»Ð¸ Ð² ÐÐ°ÑÐ¸Ð¶. ", "Ð?Ð»Ðµ ÑÐ°Ð¼ ÑÐ¼ Ð³ÐµÑÑ Ð½Ðµ Ñ?Ð¿Ð¾Ð´Ð¾Ð±Ð°Ð»Ð¾Ñ?Ñ?.");
    testSplit("ÐÐ°Ð½Ðº-ÑÐ¾Ðº â Ð½Ð°Ð¿ÑÑ?Ð¼ Ñ ÑÐ¾Ðº-Ð¼ÑÐ·Ð¸ÑÑ, ÑÐ¾ Ð²Ð¸Ð½Ð¸Ðº Ñ Ñ?ÐµÑÐµÐ´Ð¸Ð½Ñ 1970-Ñ ÑÑ. Ñ Ð¡Ð¨Ð? Ñ ÐÐµÐ»Ð¸ÐºÐ¾Ð±ÑÐ¸ÑÐ°Ð½ÑÑ.");
    testSplit("Ð Ð°Ð·Ð¾Ð¼ ÑÐ· Ð²ÑÐµÑÐ°Ð¼Ð¸, Ð²Ð¶Ðµ Ñ XV Ñ?Ñ. Ð¿Ð¾ÑÐ°Ñ?ÑÑÑÐ°Ð»Ð¸ Ð·Ð±ÑÐ¾Ð¹Ð½Ñ Ð²Ð¸Ñ?ÑÑÐ¿Ð¸ Ñ?ÐµÐ»Ñ?Ð½.");
    testSplit("Ð?Ð° Ð¿Ð¾ÑÐ°ÑÐ¾Ðº 1994 Ñ. Ð´ÐµÑÐ¶Ð°Ð²Ð½Ð¸Ð¹ Ð±Ð¾ÑÐ³ Ð£ÐºÑÐ°ÑÐ½Ð¸ Ñ?ÑÐ°Ð½Ð¾Ð²Ð¸Ð² 4,8 Ð¼Ð»ÑÐ´. Ð´Ð¾Ð».");
    testSplit("ÐÐ¸ÑÐ², Ð²ÑÐ». Ð¡Ð°Ð³Ð°Ð¹Ð´Ð°ÑÐ½Ð¾Ð³Ð¾, Ð±ÑÐ´. 43, ÐºÐ². 4.");
    testSplit("Ð?Ð°ÑÐ° Ð·ÑÑ?ÑÑÑÑ Ð· Ð?. ÐÐ°ÑÑÑÐºÐ¾Ð¼ Ñ Ð. Ð. Ð¢ÑÑÑ?ÐºÐ¾Ñ Ð²ÑÐ´Ð±ÑÐ»Ð°Ñ?Ñ? Ð² Ð³ÑÑÐ´Ð½Ñ Ð¼Ð¸Ð½ÑÐ»Ð¾Ð³Ð¾ ÑÐ¾ÐºÑ.");
    testSplit("Ð?Ð°ÑÐ° Ð·ÑÑ?ÑÑÑÑ Ð· Ð?.ÐÐ°ÑÑÑÐºÐ¾Ð¼ Ñ Ð.Ð.Ð¥Ð²Ð¸Ð»ÐµÑ Ð²ÑÐ´Ð±ÑÐ»Ð°Ñ?Ñ? Ð² Ð³ÑÑÐ´Ð½Ñ Ð¼Ð¸Ð½ÑÐ»Ð¾Ð³Ð¾ ÑÐ¾ÐºÑ.");
    testSplit("ÐÐ¾Ð¼ÐµÐ½Ð´Ð°Ð½Ñ Ð¿ÑÐµÐ¿Ð¾Ð´Ð¾Ð±Ð½Ð¸Ð¹ Ð¡.\u00A0ÐÐ¾ÐºÑÑÑÐ¼Ñ");
    testSplit("ÐÐ¾Ð¼ÐµÐ½Ð´Ð°Ð½Ñ Ð¿ÑÐµÐ¿Ð¾Ð´Ð¾Ð±Ð½Ð¸Ð¹ Ð¡.\u00A0Ð¡.\u00A0ÐÐ¾ÐºÑÑÑÐ¼Ñ 1.");
    testSplit("ÐÐ¾Ð¼ÐµÐ½Ð´Ð°Ð½Ñ Ð¿ÑÐµÐ¿Ð¾Ð´Ð¾Ð±Ð½Ð¸Ð¹ Ð¡.\u00A0Ð¡. ÐÐ¾ÐºÑÑÑÐ¼Ñ 2.");
    testSplit("Ð¡ÐºÐ»Ð°Ð´: Ð°ÐºÐ°Ð´. ÐÐµÑÐ½Ð°Ð´Ñ?ÑÐºÐ¸Ð¹, Ð¿ÑÐ¾Ñ. Ð¥Ð°ÑÑÐµÐ½ÐºÐ¾, Ð´Ð¾Ñ. Ð¡ÐµÐ¼ÐµÐ½Ñ?Ðº.");
    testSplit("ÐÐ¿ÐµÑÐ³ÑÑÐ¿Ð° Ð¿ÑÐ¸ÑÑÐ°Ð»Ð° Ð² Ñ?. ÐÑÑ?Ð¾Ð²Ðµ.");
    testSplit("300 Ñ. Ð´Ð¾ Ð½. Ðµ.");
    testSplit("ÐÑÐ¾Ð»ÑÑ?Ð¾Ðº (ÑÐ¾Ñ?. Ð¿ÑÐ¾Ð»ÐµÑ?Ð¾Ðº) â Ð¼Ð°Ð»ÐµÐ½ÑÐºÐ° ÐºÐ²ÑÑÐºÐ°.");
    testSplit("ÐÐ²ÑÑÐºÐ° Ð¦ÑÑ?Ð¸Ðº (Ð°Ð½Ð³Ð». Kvitka Cisyk ÑÐ°ÐºÐ¾Ð¶ Kacey Cisyk Ð²ÑÐ´ ÑÐ½ÑÑÑÐ°Ð»ÑÐ² Ð.Ð¡.); 4 ÐºÐ²ÑÑÐ½Ñ? 1953Ñ., ÐÐ²ÑÐ½Ð·, Ð?ÑÑ-ÐÐ¾ÑÐº â 29 Ð±ÐµÑÐµÐ·Ð½Ñ? 1998 Ñ., ÐÐ°Ð½Ð³ÐµÑÑÐµÐ½, Ð?ÑÑ-ÐÐ¾ÑÐº) â Ð°Ð¼ÐµÑÐ¸ÐºÐ°Ð½Ñ?ÑÐºÐ° Ñ?Ð¿ÑÐ²Ð°ÑÐºÐ° ÑÐºÑÐ°ÑÐ½Ñ?ÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾ÑÐ¾Ð´Ð¶ÐµÐ½Ð½Ñ?.");
    testSplit("ÐÐ¾ ÐÐ½Ñ?ÑÐ¸ÑÑÑÑ ÑÐ¼. ÐÐ»ÑÑÑÐ° Ð¿ÑÐ´'ÑÐ¶Ð´Ð¶Ð°Ñ ÑÐ¾ÑÐ½Ðµ Ð°Ð²ÑÐ¾."); 
    testSplit("ÐÐ¾ ÑÐ°Ð±Ð¾ÑÑ Â«Ð?ÑÑÐµÐºÂ».");
  }

  private void testSplit(final String... sentences) {
    TestTools.testSplit(sentences, stokenizer);
  }

}

<code block>

package org.languagetool.rules.uk;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;

import java.io.IOException;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;

import org.junit.Before;
import org.junit.Test;
import org.languagetool.AnalyzedSentence;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

public class TokenAgreementRuleTest {

  private JLanguageTool langTool;
  private TokenAgreementRule rule;

  @Before
  public void setUp() throws IOException {
    rule = new TokenAgreementRule(TestTools.getMessages("uk"));
    langTool = new JLanguageTool(new Ukrainian());
  }
  
  @Test
  public void testRule() throws IOException {

    
    assertEmptyMatch("Ð±ÐµÐ· Ð¿Ð¾Ð²Ð½Ð¾Ð³Ð¾");
    assertEmptyMatch("Ð±ÐµÐ· Ð½ÐµÐ±Ð°");

    assertEmptyMatch("Ð¿Ð¾ Ð°Ð²ÐµÐ½Ñ");

    assertEmptyMatch("ÑÐ¾ Ð·Ð° Ð³Ð°Ð½ÐµÐ±Ð½Ð° Ð½ÐµÐ¿Ð¾Ñ?Ð»ÑÐ´Ð¾Ð²Ð½ÑÑ?ÑÑ?");

    assertEmptyMatch("ÑÐ¾Ð´Ð¾ Ð²Ð»Ð°Ñ?Ð½Ðµ Ð»ÑÐ´Ð¸Ð½Ð¸");
    assertEmptyMatch("Ñ Ð·Ð°Ð³Ð°Ð»Ð¾Ð¼ Ñ?Ð¸Ð¼Ð¿Ð°ÑÐ¸ÑÐ½ÑÐ¹ Ð¿Ð¾Ð²ÑÑ?ÑÐ¸Ð½Ñ");

    assertEmptyMatch("Ð¿Ð¾Ð½Ð°Ð´ Ð¿Ð¾Ð»Ð¾Ð²Ð¸Ð½Ð° Ð»ÑÐ´ÐµÐ¹");
    assertEmptyMatch("Ð· Ð¿Ð¾Ð½Ð°Ð´ Ñ?ÑÐ° Ð»ÑÐ´ÐµÐ¹");

    assertEmptyMatch("Ð¿Ð¾ Ð½ÐµÑÐ²Ð°Ñ");
    assertEmptyMatch("Ð· Ð¾Ñ?Ð¾Ð±Ð»Ð¸Ð²Ð¾Ñ ÑÐ²Ð°Ð³Ð¾Ñ");

    assertEmptyMatch("ÑÐ¾Ð´Ð¾ Ð±Ð¾Ð´Ð°Ð¹ Ð³ÑÐ¿Ð¾ÑÐµÑÐ¸ÑÐ½Ð¾Ñ Ð·Ð´Ð°ÑÐ½Ð¾Ñ?ÑÑ");
    assertEmptyMatch("ÑÑÐ¾ ÑÐ´Ðµ Ð½Ð° Ð·Ð°ÑÐ¾Ð±ÑÑÐºÐ¸ Ð·Ð° ÐºÐ¾ÑÐ´Ð¾Ð½");

    assertEmptyMatch("Ð¿ÑÑÐ¸ Ð² Ð¿ÑÐµÐ·Ð¸Ð´ÐµÐ½ÑÐ¸");
    assertEmptyMatch("Ð¿ÑÑÐ¸ Ð¼ÐµÐ¶Ñ Ð»ÑÐ´Ð¸");

    assertEmptyMatch("ÑÐ¾ ÑÐ¾ Ð±ÑÐ»Ð° Ð·Ð° Ð»ÑÐ´Ð¸Ð½Ð°");
    assertEmptyMatch("ÑÐ¾ Ð·Ð° Ð»ÑÐ´Ð¸Ð½Ð°");
    assertEmptyMatch("ÑÐ¾ Ð±Ð°Ð»Ð¾ÑÑÐ²Ð°Ð²Ñ?Ñ? Ð·Ð° ÑÑÐ¼ Ð¾ÐºÑÑÐ³Ð¾Ð¼");

    assertEmptyMatch("Ð½Ð° Ð´Ð¾Ð¼Ñ");

    assertEmptyMatch("Ð¾ÐºÑÑÐ¼ Ñ?Ðº ÑÐºÑÐ°ÑÐ½ÑÑ");
    assertEmptyMatch("Ð·Ð° Ð´Ð²ÑÑ?ÑÑ Ð¼ÐµÑÑÑÐ²");
    assertEmptyMatch("Ð¿ÐµÑÐµÑÐ¾Ð´Ð¸ÑÑ Ñ Ð¤ÑÑÐ´ÑÑÑ Ð¨ÑÑÐ°Ñ?Ñ?Ðµ");
    assertEmptyMatch("Ð²ÑÐ´ Ð¼ÑÐ½ÑÑ? 1 Ð´Ð¾ Ð¿Ð»ÑÑ? 1");
    assertEmptyMatch("Ð´Ð¾ Ð¼ÑÐ½ÑÑ? Ñ?Ð¾ÑÐ¾ÐºÐ° Ð³ÑÐ°Ð´");
    assertEmptyMatch("Ð´Ð¾ Ð¼ÑÐ½ÑÑ? ÑÑÑ?ÑÐ´ÐµÑ?Ñ?ÑÐ¸");
    assertEmptyMatch("ÑÐµÑÐµÐ· ÑÐ¾ÐºÑÐ² 10");
    assertEmptyMatch("Ð½Ð° ÑÐ²Ð¸Ð»Ð¸Ð½ 9-10");
    assertEmptyMatch("Ñ?Ð¿ÑÐ²Ð¿ÑÐ°ÑÑÐ²Ð°ÑÐ¸ ÑÐ· Ñ?Ð¾Ð±Ñ Ð¿Ð¾Ð´ÑÐ±Ð½Ð¸Ð¼Ð¸");
    assertEmptyMatch("ÑÐµÑÐµÐ· ÑÑ?ÑÐ¼ Ð²ÑÐ´Ð¾Ð¼Ñ Ð¿ÑÐ¸ÑÐ¸Ð½Ð¸");
    assertEmptyMatch("ÑÐµÑÐµÐ· Ð½ÑÐºÐ¾Ð¼Ñ Ð½Ðµ Ð²ÑÐ´Ð¾Ð¼Ñ Ð¿ÑÐ¸ÑÐ¸Ð½Ð¸");
    assertEmptyMatch("Ð¿ÑÐ¸Ð¹ÑÐ»Ð¸ Ð´Ð¾ ÐÐ?Ð¢ Â«ÐÑÐ¸Ð²Ð¸Ð¹ Ð ÑÐ³ ÑÐµÐ¼ÐµÐ½ÑÂ»");
    assertEmptyMatch("Ð²ÑÐ´ Ð? Ð´Ð¾ Ð¯");
    assertEmptyMatch("Ð´Ð¾ ÑÐ° Ð¿ÑÑ?Ð»Ñ?");
    assertEmptyMatch("Ð´Ð¾ Ñ?ÑÑÐ´ Ñ?Ð¾Ð½ÑÑ?");
    assertEmptyMatch("Ð· ÑÐ°Ð½Ð° Ð´Ð¾ Ð²ÐµÑÐ¾ÑÐ°, Ð²ÑÐ´ ÑÐ°Ð½Ð° Ð´Ð¾ Ð½Ð¾ÑÑ");
    assertEmptyMatch("Ð´Ð¾ Ð?Ð?Ð Â«Ð?Ð°Ð´ÑÐ° Ð£ÐºÑÐ°ÑÐ½Ð¸Â»");
    assertEmptyMatch("Ð¿ÑÐ¸Ð·Ð²ÑÐ² Ð´Ð¾ Ð·Ð½Ð°ÑÐ½Ð¾Ñ Ð¼ÑÑÐ¾Ñ Ð´ÐµÐ¼Ð¾ÐºÑÐ°ÑÐ¸ÑÐ½Ð¾Ð³Ð¾ Ñ?ÐµÑÐµÐ´Ð½ÑÐ¾Ð³Ð¾ ÐºÐ»Ð°Ñ?Ñ");
    assertEmptyMatch("ÐÐ¾Ð½Ð¸ Ð·Ð°Ð¼ÑÑ?ÑÑ Ð?Ð½Ð´ÑÑÐ¹ Ð²Ð¸Ð±ÑÐ°Ð»Ð¸ Ð®ÑÑÐ¹");
    assertEmptyMatch("Ð½Ð° Ð¼Ð¾ÑÐ¾Ð¼ Ñ?ÑÐµÐ»ÐµÐ½Ð¾Ð¼Ñ Ð´Ð½Ñ");
    assertEmptyMatch("ÑÐ°Ñ? Ð²ÑÐ´ ÑÐ°Ñ?Ñ Ð½Ð°Ð¼ Ð´Ð¾Ð²Ð¾Ð´Ð¸Ð»Ð¾Ñ?Ñ");
    assertEmptyMatch("Ñ?ÐºÐ¸Ð¹ Ð´Ð¾ ÑÐµÑÑ Ð²Ð¾Ð½Ð¸ Ð¿ÑÐ¸Ñ?Ñ?Ð³Ð°Ð»Ð¸Ñ?Ñ?");
    assertEmptyMatch("Ð½Ñ Ð´Ð¾ ÑÐ¾Ð³Ð¾ Ð´Ð¾Ð±ÑÐ¾Ð³Ð¾ Ñ?Ð¸Ð»Ð¾Ð²Ñ Ð´ÑÑ Ð½Ðµ Ð¿ÑÐ¸Ð·Ð²ÐµÐ´ÑÑÑ");


    assertEquals(1, rule.match(langTool.getAnalyzedSentence("Ð¿ÑÐ¸Ð·Ð²ÑÐ² Ð´Ð¾ Ð·Ð½Ð°ÑÐ½Ð¾Ñ Ð¼ÑÑÐ¾Ñ Ð´ÐµÐ¼Ð¾ÐºÑÐ°ÑÐ¸ÑÐ½Ð¾Ð¼Ñ Ñ?ÐµÑÐµÐ´Ð½ÑÐ¾Ð¼Ñ ÐºÐ»Ð°Ñ?Ñ")).length);




    
    

    RuleMatch[] matches = rule.match(langTool.getAnalyzedSentence("Ð±ÐµÐ· Ð½ÐµÐ±Ñ"));
    
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("Ð½ÐµÐ±Ð°"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð½Ðµ Ð² Ð¾Ñ?ÑÐ°Ð½Ð½Ñ ÑÐµÑÐ³Ñ ÑÐµÑÐµÐ·    ÐºÐ¾ÑÑÐ¿ÑÑÑÑ, Ð¼ÑÐ¶ÑÐµÐ»ÑÐ³ÑÐ¹Ð½Ñ Ð²Ð¾ÑÐ¾Ð¶Ð½ÐµÑÑ"));
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("Ð¿Ð¾ Ð½ÐµÑÐ²Ð°Ð¼"));
    
    assertEquals(1, matches.length);
    assertEquals(3, matches[0].getFromPos());
    assertEquals(9, matches[0].getToPos());
    assertEquals(Arrays.asList("Ð½ÐµÑÐ²Ð°Ñ", "Ð½ÐµÑÐ²Ð¸"), matches[0].getSuggestedReplacements());
    
    assertEquals(1, rule.match(langTool.getAnalyzedSentence("Ð² Ð¿'Ñ?ÑÑÐ¾Ð¼ Ð»ÑÐ´Ñ?Ð¼")).length);
    assertEquals(1, rule.match(langTool.getAnalyzedSentence("Ð² Ð¿Ð¾Ð½Ð°Ð´ Ð¿'Ñ?ÑÑÐ¾Ð¼ Ð»ÑÐ´Ñ?Ð¼")).length);

    AnalyzedSentence analyzedSentence = langTool.getAnalyzedSentence("Ð·Ð°Ð²Ð´Ñ?ÐºÐ¸ ÑÑ Ð²Ð´Ð°Ð»Ð¸Ð¼ ÑÑÑÐºÐ°Ð¼");
    RuleMatch[] match = rule.match(analyzedSentence);
    assertEquals(1, match.length);
    List<String> suggestedReplacements = match[0].getSuggestedReplacements();
    assertTrue("Did not find Â«ÑÑÐ½ÑÐ¹Â»: " + suggestedReplacements, suggestedReplacements.contains("ÑÑÐ½ÑÐ¼"));

    analyzedSentence = langTool.getAnalyzedSentence("Ð Ð´ÑÐ²ÑÐ¸Ð½Ð°!");
    match = rule.match(analyzedSentence);
    assertEquals(1, match.length);
    suggestedReplacements = match[0].getSuggestedReplacements();
    assertTrue("Did not find ÐºÐ»Ð¸ÑÐ½Ð¸Ð¹ Â«Ð´ÑÐ²ÑÐ¸Ð½Ð¾Â»: " + suggestedReplacements, suggestedReplacements.contains("Ð´ÑÐ²ÑÐ¸Ð½Ð¾"));

    matches = rule.match(langTool.getAnalyzedSentence("Ð¿Ð¾ ÑÐµÑÐºÐ¾Ð²Ð½Ð¸Ð¼ ÐºÐ°Ð½Ð¾Ð½Ð°Ð¼"));
    
    assertEquals(1, matches.length);

    
    assertEmptyMatch("Ð½Ð° ÐÑÐ¿Ð°Ð»Ð°");
    assertEmptyMatch("Ð½Ð° Ð¯Ð²Ð´Ð¾ÑÐ¸");
    
    assertEmptyMatch("Ð½Ð° ÐÐ°Ð·ÐµÐ¿Ð¸");
    assertEmptyMatch("Ð½Ð° ÐÑÐ»ÑÑÐ¸ÑÑÐºÐ¾Ñ");
    assertEmptyMatch("Ð½Ð° ÐÑÐ°Ð²Ð´Ð¸");
    assertEmptyMatch("Ð½Ð° ÐÐ¾Ð¼Ð¾Ð½Ð¾Ñ?Ð¾Ð²Ð°");
    
    assertEmptyMatch("Ñ?Ðº Ð½Ð° ÐÑÑÐ¼Ð¸ ÑÐ¼ÐµÐ½Ð¸Ð½Ð¸");

    assertEmptyMatch("Ñ?Ð¿Ð¸ÑÐ°Ð»Ð¾Ñ?Ñ? Ð½Ð° Ð¼ÑÑ?Ñ?ÑÐ½Ð¾Ñ Ð´Ð°Ð²Ð½Ð¸Ð½Ð¸ ÑÑÑÐµÐ½Ð½Ñ?");
    assertEmptyMatch("Ð?Ð° Ñ?ÐµÑÐµÐ´Ð½ÑÐ¾Ñ Ð´Ð¾Ð²Ð¶Ð¸Ð½Ð¸ ÑÑÐ±Ñ");

    matches = rule.match(langTool.getAnalyzedSentence("Ñ?Ð¿Ð¸ÑÐ°Ð»Ð¾Ñ?Ñ? Ð½Ð° Ð¼ÑÑ?Ñ?ÑÐ½Ð¾Ñ Ð´Ð°Ð²Ð½Ð¸Ð½Ð¸ ÑÑÑÐµÐ½Ð½Ñ?Ð¼"));
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("ÐÑÐ´ Ñ?ÑÑ?Ð³Ñ Ð?ÑÐ°ÑÑÑÐºÐ° Ð´Ð¾ Ð¿ÑÑÐ°ÑÑ?ÑÐºÐ¾Ð³Ð¾ Ð¿ÑÐ°Ð¿Ð¾ÑÑ"));
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("Ð·Ð³ÑÐ´Ð½Ð¾ Ð· Ð´Ð¾ÐºÑÐ¼ÐµÐ½ÑÐ°"));
    assertEquals(1, matches.length);






  }

  private void assertEmptyMatch(String text) throws IOException {
    assertEquals(Collections.<RuleMatch>emptyList(), Arrays.asList(rule.match(langTool.getAnalyzedSentence(text))));
  }
  
  @Test
  public void testSpecialChars() throws IOException {
    TokenAgreementRule rule = new TokenAgreementRule(TestTools.getMessages("uk"));

    JLanguageTool langTool = new JLanguageTool(new Ukrainian());

    RuleMatch[] matches = rule.match(langTool.getAnalyzedSentence("Ð¿Ð¾ Ð½ÐµÌ?ÑÐ²Ð°Ð¼, Ð¿Ð¾ Ð¼Ð¾\u00ADÑ?ÑÐ°Ð¼, Ð¿Ð¾ Ð²Ð¾ÑÐ¾ÑÐ°Ð¼"));
    
    assertEquals(3, matches.length);

    assertEmptyMatch("Ð´Ð¾ ÑÐ¼ Ð¿Ð¾Ð´Ñ\u00ADÐ±Ð½Ð¸Ñ");

    assertEquals(3, matches[0].getFromPos());
    assertEquals(10, matches[0].getToPos());
    assertEquals(Arrays.asList("Ð½ÐµÑÐ²Ð°Ñ", "Ð½ÐµÑÐ²Ð¸"), matches[0].getSuggestedReplacements());


    assertEquals(15, matches[1].getFromPos());
    assertEquals(Arrays.asList("Ð¼Ð¾Ñ?ÑÐ°Ñ", "Ð¼Ð¾Ñ?ÑÐ¸"), matches[1].getSuggestedReplacements());


    assertEquals(27, matches[2].getFromPos());
    assertEquals(Arrays.asList("Ð²Ð¾ÑÐ¾ÑÐ°Ñ", "Ð²Ð¾ÑÐ¾ÑÐ°"), matches[2].getSuggestedReplacements());
  }

}

<code block>

package org.languagetool.rules.uk;

import java.io.IOException;
import java.util.Arrays;
import java.util.Collections;

import org.junit.Before;
import org.junit.Test;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

import static org.junit.Assert.assertEquals;

public class UkrainianWordRepeatRuleTest {
  
  private JLanguageTool langTool;
  private UkrainianWordRepeatRule rule;

  @Before
  public void setUp() throws IOException {
    langTool = new JLanguageTool(new Ukrainian());
    rule = new UkrainianWordRepeatRule(TestTools.getMessages("uk"), langTool.getLanguage());
  }
  
  @Test
  public void testRule() throws IOException {
    assertEmptyMatch("Ð±ÐµÐ· Ð¿Ð¾Ð²Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð·ÑÐ°ÑÑÐ½ÐºÑ");
    assertEmptyMatch("Ð±ÐµÐ· Ð±ÑÐ³ÑÐ¼Ð° Ð±ÑÐ³ÑÐ¼Ð°");
    assertEmptyMatch("Ð±ÐµÐ· 100 100");
    assertEmptyMatch("1.30 3.20 3.20");
    assertEmptyMatch("ÑÐµ Ð² Ð.ÐÐ°Ð½Ð´Ð¸Ð½Ñ?ÑÐºÐ¾Ð³Ð¾");
    assertEmptyMatch("ÐÑÐ´ Ð´Ð¾Ð±ÑÐ° Ð´Ð¾Ð±ÑÐ° Ð½Ðµ ÑÑÐºÐ°ÑÑÑ.");
    assertEmptyMatch("Ð©Ð¾ ÑÐ¾, Ð° ÐºÑÐ½Ð¾ Ð² Ð£ÐºÑÐ°ÑÐ½Ñ...");

    assertEquals(1, rule.match(langTool.getAnalyzedSentence("Ð±ÐµÐ· Ð±ÐµÐ· Ð¿Ð¾Ð²Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð·ÑÐ°ÑÑÐ½ÐºÑ")).length);
    RuleMatch[] match = rule.match(langTool.getAnalyzedSentence("ÐÐµÑÑÐ¾Ð²Ð½Ð¾Ñ Ð Ð°Ð´Ð¸ Ð Ñ ÐÐ Ñ?ÐºÐ»Ð¸ÐºÐ°Ð½Ñ"));
    assertEquals(1, match.length);
    assertEquals(2, match[0].getSuggestedReplacements().size());
  }

  private void assertEmptyMatch(String text) throws IOException {
    assertEquals(text, Collections.<RuleMatch>emptyList(), Arrays.asList(rule.match(langTool.getAnalyzedSentence(text))));
  }

}

<code block>

package org.languagetool.rules.uk;

import org.junit.Test;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

import java.io.IOException;
import java.util.Arrays;

import static org.junit.Assert.assertEquals;

public class MixedAlphabetsRuleTest {

  @Test
  public void testRule() throws IOException {
    final MixedAlphabetsRule rule = new MixedAlphabetsRule(TestTools.getMessages("uk"));
    final JLanguageTool langTool = new JLanguageTool(new Ukrainian());

    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("Ñ?Ð¼ÑÑÑÑ?")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("not mixed")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("123454")).length);

    

    RuleMatch[] matches = rule.match(langTool.getAnalyzedSentence("Ñ?Ð¼iÑÑÑ?"));  
    
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("Ñ?Ð¼ÑÑÑÑ?"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("mÑÑed"));  

    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("mixed"), matches[0].getSuggestedReplacements());
    
    matches = rule.match(langTool.getAnalyzedSentence("XÐ")); 

    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("XI"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð¥I")); 

    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("XI"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð¥Ð")); 

    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("XI"), matches[0].getSuggestedReplacements());
  }

}

<code block>


package org.languagetool.rules.uk;

import junit.framework.TestCase;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

import java.io.IOException;
import java.util.Arrays;


public class SimpleReplaceRuleTest extends TestCase {

  public void testRule() throws IOException {
    SimpleReplaceRule rule = new SimpleReplaceRule(TestTools.getEnglishMessages());

    RuleMatch[] matches;
    JLanguageTool langTool = new JLanguageTool(new Ukrainian());

    
    matches = rule.match(langTool.getAnalyzedSentence("Ð¦Ñ ÑÑ?Ð´ÐºÐ¸ Ð¿Ð¾Ð²Ð¸Ð½Ð½Ñ Ð·Ð±ÑÐ³Ð°ÑÐ¸Ñ?Ñ?."));
    assertEquals(0, matches.length);

    
    matches = rule.match(langTool.getAnalyzedSentence("Ð¦Ñ ÑÑ?Ð´ÐºÐ¸ Ð¿Ð¾Ð²Ð¸Ð½Ð½Ñ Ñ?Ð¿ÑÐ²Ð¿Ð°Ð´Ð°ÑÐ¸."));
    assertEquals(1, matches.length);
    assertEquals(2, matches[0].getSuggestedReplacements().size());
    assertEquals(Arrays.asList("Ð·Ð±ÑÐ³Ð°ÑÐ¸Ñ?Ñ?", "Ñ?ÑÐ¾Ð´Ð¸ÑÐ¸Ñ?Ñ?"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð?Ð°Ð¿Ð°Ð´Ð°ÑÑÐ¸Ð¹"));
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("Ð?Ð°Ð¿Ð°Ð´Ð½Ð¸Ðº", "Ð?Ð°Ð¿Ð°Ð´Ð°Ð»ÑÐ½Ð¸Ð¹", "Ð?Ð°Ð¿Ð°Ð´Ð½Ð¸Ð¹"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("Ð?Ð°Ð¿Ð°Ð´Ð°ÑÑÐ¾Ð³Ð¾"));
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("Ð?Ð°Ð¿Ð°Ð´Ð½Ð¸Ðº", "Ð?Ð°Ð¿Ð°Ð´Ð°Ð»ÑÐ½Ð¸Ð¹", "Ð?Ð°Ð¿Ð°Ð´Ð½Ð¸Ð¹"), matches[0].getSuggestedReplacements());

    
    matches = rule.match(langTool.getAnalyzedSentence("ÑÐµÐ´ÑÐ¾ÑÐ°"));
    assertEquals(1, matches.length);
    assertEquals(Arrays.asList("ÑÐµÐ´ÑÑÑ?ÑÑ", "Ð³Ð¾Ð¹Ð½ÑÑ?ÑÑ", "ÑÐµÐ´ÑÐ¸Ð½Ñ?"), matches[0].getSuggestedReplacements());

    matches = rule.match(langTool.getAnalyzedSentence("ÑÐµÐ´ÑÐ¾ÑÐ¸"));
    assertEquals(0, matches.length);
  }
}

<code block>

package org.languagetool.rules.uk;

import static org.junit.Assert.assertEquals;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;

import org.junit.Test;
import org.languagetool.JLanguageTool;
import org.languagetool.TestTools;
import org.languagetool.language.Ukrainian;
import org.languagetool.rules.RuleMatch;

public class MorfologikUkrainianSpellerRuleTest {

  @Test
  public void testMorfologikSpeller() throws IOException {
    MorfologikUkrainianSpellerRule rule = new MorfologikUkrainianSpellerRule (TestTools.getMessages("uk"), new Ukrainian());

    JLanguageTool langTool = new JLanguageTool(new Ukrainian());

    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐÐ¾ Ð²Ð°Ñ? Ð¿ÑÐ¸Ð¹Ð´Ðµ Ð·Ð°Ð²Ð²ÑÐ´Ð´ÑÐ»Ñ!")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence(",")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("123454")).length);

    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐÐ¾ Ð½Ð°Ñ? Ð¿ÑÐ¸ÑÐ´Ðµ The Beatles!")).length);

    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("Ð¿ÑÑ?\u00ADÐ½Ñ")).length);
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("Ð¿ÑÑ?\u00ADÐ½Ñ Ð¿ÑÑ?\u00ADÐ½Ñ")).length);
    
    
    

    RuleMatch[] matches = rule.match(langTool.getAnalyzedSentence("Ð°ÑÐ°ÐºÑÑÑÐ¸Ð¹"));
    
    assertEquals(1, matches.length);

    matches = rule.match(langTool.getAnalyzedSentence("ÑÐºÐ»Ñ?Ð½Ð¸Ð¹"));

    assertEquals(1, matches.length);
    assertEquals("Ñ?ÐºÐ»Ñ?Ð½Ð¸Ð¹", matches[0].getSuggestedReplacements().get(0));

    assertEquals(0, rule.match(langTool.getAnalyzedSentence("Ð°")).length);

    
    matches = rule.match(langTool.getAnalyzedSentence("Ð¿ÑÐ¸Ð¹Ð´ÐµÑÐ½iÐ¹"));   

    assertEquals(1, matches.length);
    assertEquals("Ð¿ÑÐ¸Ð¹Ð´ÐµÑÐ½ÑÐ¹", matches[0].getSuggestedReplacements().get(0));

    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐÐ°ÐºÐµÑ Ð±ÑÐ² Ñ?Ð¸Ð½ÑÐ¾-Ð¶Ð¾Ð²ÑÐ¾Ð³Ð¾ ÐºÐ¾Ð»ÑÐ¾ÑÑ")).length);

    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐÑÐ½ Ð±Ð°Ð³Ð°ÑÐ¾ Ñ?Ð¸Ð´ÑÐ² Ð½Ð° ÑÐ½ÑÐµÑÐ½ÐµÑ-ÑÐ¾ÑÑÐ¼Ð°Ñ")).length);

    assertEquals(1, rule.match(langTool.getAnalyzedSentence("ÐÑÐ½ Ð±Ð°Ð³Ð°ÑÐ¾ Ñ?Ð¸Ð´ÑÐ² Ð½Ð° ÑÐ½ÑÐµÑÐ¼ÐµÑ-ÑÐ¾ÑÑÐ¼Ð°Ñ")).length);

    
    assertEquals(0, rule.match(langTool.getAnalyzedSentence("ÐµÐºÑ?-ÐºÑÐµÐ²ÐµÑÐºÐ°")).length);


    

    RuleMatch[] match = rule.match(langTool.getAnalyzedSentence("Ð§Ð¸ÑÐ°Ð½Ð½Ñ? Ð²ÑÑÑÑÐ² Ð¢.Ð.Ð¨ÐµÐ²ÑÐµÐ½ÐºÐ¾ Ñ Ð.Ð¢ÑÑÑÐ½Ð½Ð¸ÐºÐ°"));
    assertEquals(new ArrayList<RuleMatch>(), Arrays.asList(match));

    match = rule.match(langTool.getAnalyzedSentence("Ð§Ð¸ÑÐ°Ð½Ð½Ñ? Ð²ÑÑÑÑÐ² Ð¢. Ð. Ð¨ÐµÐ²ÑÐµÐ½ÐºÐ¾ Ñ Ð. Ð¢ÑÑÑÐ½Ð½Ð¸ÐºÐ°"));
    assertEquals(new ArrayList<RuleMatch>(), Arrays.asList(match));

    match = rule.match(langTool.getAnalyzedSentence("Ð?Ð½Ð³Ð»ÑÌ?Ð¹Ñ?ÑÐºÐ° Ð¼Ð¾Ð²Ð° (Ð°Ð½Ð³Ð». English language, English) Ð½Ð°Ð»ÐµÐ¶Ð¸ÑÑ Ð´Ð¾ Ð³ÐµÑÐ¼Ð°Ð½Ñ?ÑÐºÐ¾Ñ Ð³ÑÑÐ¿Ð¸"));
    assertEquals(new ArrayList<RuleMatch>(), Arrays.asList(match));

    match = rule.match(langTool.getAnalyzedSentence("Ð?Ð½Ð³Ð»ÑÌ?Ð¹Ñ?ÑÐºÐ° Ð¼Ð¾Ð²Ð° (Ð°Ð½Ð³Ð» English language, English) Ð½Ð°Ð»ÐµÐ¶Ð¸ÑÑ Ð´Ð¾ Ð³ÐµÑÐ¼Ð°Ð½Ñ?ÑÐºÐ¾Ñ Ð³ÑÑÐ¿Ð¸"));
    assertEquals(1, match.length);
  }

}

<code block>

package org.languagetool.gui;

import org.jetbrains.annotations.NotNull;
import org.jetbrains.annotations.Nullable;
import org.languagetool.JLanguageTool;
import org.languagetool.Language;
import org.languagetool.Languages;
import org.languagetool.rules.Rule;

import javax.swing.*;
import javax.swing.event.DocumentEvent;
import javax.swing.event.DocumentListener;
import javax.swing.event.TreeModelEvent;
import javax.swing.event.TreeModelListener;
import javax.swing.tree.DefaultMutableTreeNode;
import javax.swing.tree.DefaultTreeModel;
import javax.swing.tree.TreeNode;
import javax.swing.tree.TreePath;
import java.awt.*;
import java.awt.event.*;
import java.util.*;
import java.util.List;


public class ConfigurationDialog implements ActionListener {

  private static final String NO_MOTHER_TONGUE = "---";
  private static final int MAX_PORT = 65536;

  private final ResourceBundle messages;
  private final Configuration original;
  private final Configuration config;
  private final Frame owner;
  private final boolean insideOffice;

  private JButton okButton;
  private JButton cancelButton;
  private JDialog dialog;
  private JComboBox<String> motherTongueBox;
  private JCheckBox serverCheckbox;
  private JTextField serverPortField;
  private JTree configTree;
  private JCheckBox serverSettingsCheckbox;

  public ConfigurationDialog(Frame owner, boolean insideOffice, Configuration config) {
    this.owner = owner;
    this.insideOffice = insideOffice;
    this.original = config;
    this.config = original.copy(original);
    messages = JLanguageTool.getMessageBundle();
  }

  private DefaultMutableTreeNode createTree(List<Rule> rules) {
    DefaultMutableTreeNode root = new DefaultMutableTreeNode("Rules");
    String lastRuleId = null;
    Map<String, DefaultMutableTreeNode> parents = new TreeMap<>();
    for (final Rule rule : rules) {
      if (!parents.containsKey(rule.getCategory().getName())) {
        boolean enabled = true;
        if (config.getDisabledCategoryNames() != null && config.getDisabledCategoryNames().contains(rule.getCategory().getName())) {
          enabled = false;
        }
        DefaultMutableTreeNode categoryNode = new CategoryNode(rule.getCategory(), enabled);
        root.add(categoryNode);
        parents.put(rule.getCategory().getName(), categoryNode);
      }
      if (!rule.getId().equals(lastRuleId)) {
        RuleNode ruleNode = new RuleNode(rule, getState(rule));
        parents.get(rule.getCategory().getName()).add(ruleNode);
      }
      lastRuleId = rule.getId();
    }
    return root;
  }

  private boolean getState(Rule rule) {
    boolean ret = true;

    if (config.getDisabledRuleIds().contains(rule.getId())) {
      ret = false;
    }
    if (config.getDisabledCategoryNames().contains(rule.getCategory().getName())) {
      ret = false;
    }
    if (rule.isDefaultOff() && !config.getEnabledRuleIds().contains(rule.getId())) {
      ret = false;
    }
    if (rule.isDefaultOff() && rule.getCategory().isDefaultOff()
            && config.getEnabledRuleIds().contains(rule.getId())) {
      config.getDisabledCategoryNames().remove(rule.getCategory().getName());
    }
    return ret;
  }

  public void show(List<Rule> rules) {
    if (original != null) {
      config.restoreState(original);
    }
    dialog = new JDialog(owner, true);
    dialog.setTitle(messages.getString("guiConfigWindowTitle"));
    
    final KeyStroke stroke = KeyStroke.getKeyStroke(KeyEvent.VK_ESCAPE, 0);
    final ActionListener actionListener = new ActionListener() {
      @Override
      public void actionPerformed(@SuppressWarnings("unused") ActionEvent actionEvent) {
        dialog.setVisible(false);
      }
    };
    final JRootPane rootPane = dialog.getRootPane();
    rootPane.registerKeyboardAction(actionListener, stroke,
        JComponent.WHEN_IN_FOCUSED_WINDOW);

    final JPanel checkBoxPanel = new JPanel();
    checkBoxPanel.setLayout(new GridBagLayout());
    GridBagConstraints cons = new GridBagConstraints();
    cons.anchor = GridBagConstraints.NORTHWEST;
    cons.gridx = 0;
    cons.weightx = 1.0;
    cons.weighty = 1.0;
    cons.fill = GridBagConstraints.BOTH;
    Collections.sort(rules, new CategoryComparator());
    DefaultMutableTreeNode rootNode = createTree(rules);
    configTree = new JTree(getTreeModel(rootNode));

    Language lang = config.getLanguage();
    if (lang == null) {
      lang = Languages.getLanguageForLocale(Locale.getDefault());
    }
    configTree.applyComponentOrientation(ComponentOrientation.getOrientation(lang.getLocale()));

    configTree.setRootVisible(false);
    configTree.setEditable(false);
    configTree.setCellRenderer(new CheckBoxTreeCellRenderer());
    TreeListener.install(configTree);
    checkBoxPanel.add(configTree, cons);
    configTree.addMouseListener(getMouseAdapter());
    
    final JPanel portPanel = new JPanel();
    portPanel.setLayout(new GridBagLayout());
    cons = new GridBagConstraints();
    cons.insets = new Insets(0, 4, 0, 0);
    cons.gridx = 0;
    cons.gridy = 0;
    cons.anchor = GridBagConstraints.WEST;
    cons.fill = GridBagConstraints.NONE;
    cons.weightx = 0.0f;
    if (!insideOffice) {
      createNonOfficeElements(cons, portPanel);
    }

    final JPanel buttonPanel = new JPanel();
    buttonPanel.setLayout(new GridBagLayout());
    okButton = new JButton(Tools.getLabel(messages.getString("guiOKButton")));
    okButton.setMnemonic(Tools.getMnemonic(messages.getString("guiOKButton")));
    okButton.addActionListener(this);
    cancelButton = new JButton(Tools.getLabel(messages.getString("guiCancelButton")));
    cancelButton.setMnemonic(Tools.getMnemonic(messages.getString("guiCancelButton")));
    cancelButton.addActionListener(this);
    cons = new GridBagConstraints();
    cons.insets = new Insets(0, 4, 0, 0);
    buttonPanel.add(okButton, cons);
    buttonPanel.add(cancelButton, cons);

    final Container contentPane = dialog.getContentPane();
    contentPane.setLayout(new GridBagLayout());
    cons = new GridBagConstraints();
    cons.insets = new Insets(4, 4, 4, 4);
    cons.gridx = 0;
    cons.gridy = 0;
    cons.weightx = 10.0f;
    cons.weighty = 10.0f;
    cons.fill = GridBagConstraints.BOTH;
    contentPane.add(new JScrollPane(checkBoxPanel), cons);

    cons.gridx = 0;
    cons.gridy++;
    cons.fill = GridBagConstraints.NONE;
    cons.anchor = GridBagConstraints.LINE_END;
    contentPane.add(getTreeButtonPanel(), cons);
    
    cons.gridy++;
    cons.anchor = GridBagConstraints.WEST;
    contentPane.add(getMotherTonguePanel(cons), cons);

    cons.gridy++;
    cons.anchor = GridBagConstraints.WEST;
    contentPane.add(portPanel, cons);

    cons.gridy++;
    cons.anchor = GridBagConstraints.EAST;
    contentPane.add(buttonPanel, cons);

    dialog.pack();
    dialog.setSize(500, 500);
    
    final Dimension screenSize = Toolkit.getDefaultToolkit().getScreenSize();
    final Dimension frameSize = dialog.getSize();
    dialog.setLocation(screenSize.width / 2 - frameSize.width / 2,
        screenSize.height / 2 - frameSize.height / 2);
    dialog.setLocationByPlatform(true);
    dialog.setVisible(true);
  }

  private void createNonOfficeElements(GridBagConstraints cons, JPanel portPanel) {
    serverCheckbox = new JCheckBox(Tools.getLabel(messages.getString("guiRunOnPort")));
    serverCheckbox.setMnemonic(Tools.getMnemonic(messages.getString("guiRunOnPort")));
    serverCheckbox.setSelected(config.getRunServer());
    portPanel.add(serverCheckbox, cons);
    serverCheckbox.addActionListener(new ActionListener() {
      @Override
      public void actionPerformed(@SuppressWarnings("unused") ActionEvent e) {
        serverPortField.setEnabled(serverCheckbox.isSelected());
        serverSettingsCheckbox.setEnabled(serverCheckbox.isSelected());
      }
    });
    serverCheckbox.addItemListener(new ItemListener() {
      @Override
      public void itemStateChanged(ItemEvent e) {
        config.setRunServer(serverCheckbox.isSelected());
      }
    });

    serverPortField = new JTextField(Integer.toString(config.getServerPort()));
    serverPortField.setEnabled(serverCheckbox.isSelected());
    serverSettingsCheckbox = new JCheckBox(Tools.getLabel(messages.getString("useGUIConfig")));
    serverPortField.setMinimumSize(new Dimension(100, 25));  
    cons.gridx = 1;
    portPanel.add(serverPortField, cons);
    serverPortField.getDocument().addDocumentListener(new DocumentListener() {

      @Override
      public void insertUpdate(DocumentEvent e) {
        changedUpdate(e);
      }

      @Override
      public void removeUpdate(DocumentEvent e) {
        changedUpdate(e);
      }

      @Override
      public void changedUpdate(DocumentEvent e) {
        try {
          int serverPort = Integer.parseInt(serverPortField.getText());
          if (serverPort > -1 && serverPort < MAX_PORT) {
            serverPortField.setForeground(null);
            config.setServerPort(serverPort);
          } else {
            serverPortField.setForeground(Color.RED);
          }
        } catch (NumberFormatException ex) {
          serverPortField.setForeground(Color.RED);
        }
      }
    });

    cons.gridx = 0;
    cons.gridy = 10;
    serverSettingsCheckbox.setMnemonic(Tools.getMnemonic(messages.getString("useGUIConfig")));
    serverSettingsCheckbox.setSelected(config.getUseGUIConfig());
    serverSettingsCheckbox.setEnabled(config.getRunServer());
    serverSettingsCheckbox.addItemListener(new ItemListener() {
      @Override
      public void itemStateChanged(ItemEvent e) {
        config.setUseGUIConfig(serverSettingsCheckbox.isSelected());
      }
    });
    portPanel.add(serverSettingsCheckbox, cons);
  }

  @NotNull
  private DefaultTreeModel getTreeModel(DefaultMutableTreeNode rootNode) {
    DefaultTreeModel treeModel = new DefaultTreeModel(rootNode);
    treeModel.addTreeModelListener(new TreeModelListener() {
      @Override
      public void treeNodesChanged(TreeModelEvent e) {
        DefaultMutableTreeNode node = (DefaultMutableTreeNode) e.getTreePath().getLastPathComponent();
        int index = e.getChildIndices()[0];
        node = (DefaultMutableTreeNode) node.getChildAt(index);
        if (node instanceof RuleNode) {
          RuleNode o = (RuleNode) node;
          if (o.getRule().isDefaultOff()) {
            if (o.isEnabled()) {
              config.getEnabledRuleIds().add(o.getRule().getId());
            } else {
              config.getEnabledRuleIds().remove(o.getRule().getId());
            }
          } else {
            if (o.isEnabled()) {
              config.getDisabledRuleIds().remove(o.getRule().getId());
            } else {
              config.getDisabledRuleIds().add(o.getRule().getId());
            }
          }
        }
        if (node instanceof CategoryNode) {
          CategoryNode o = (CategoryNode) node;
          if (o.isEnabled()) {
            config.getDisabledCategoryNames().remove(o.getCategory().getName());
          } else {
            config.getDisabledCategoryNames().add(o.getCategory().getName());
          }
        }
      }
      @Override
      public void treeNodesInserted(TreeModelEvent e) {}
      @Override
      public void treeNodesRemoved(TreeModelEvent e) {}
      @Override
      public void treeStructureChanged(TreeModelEvent e) {}
    });
    return treeModel;
  }

  @NotNull
  private MouseAdapter getMouseAdapter() {
    return new MouseAdapter() {
        private void handlePopupEvent(MouseEvent e) {
          final JTree tree = (JTree) e.getSource();
          TreePath path = tree.getPathForLocation(e.getX(), e.getY());
          if (path == null) {
            return;
          }
          DefaultMutableTreeNode node
                  = (DefaultMutableTreeNode) path.getLastPathComponent();
          TreePath[] paths = tree.getSelectionPaths();
          boolean isSelected = false;
          if (paths != null) {
            for (TreePath selectionPath : paths) {
              if (selectionPath.equals(path)) {
                isSelected = true;
              }
            }
          }
          if (!isSelected) {
            tree.setSelectionPath(path);
          }
          if (node.isLeaf()) {
            JPopupMenu popup = new JPopupMenu();
            final JMenuItem aboutRuleMenuItem = new JMenuItem(messages.getString("guiAboutRuleMenu"));
            aboutRuleMenuItem.addActionListener(new ActionListener() {
              @Override
              public void actionPerformed(ActionEvent actionEvent) {
                RuleNode node = (RuleNode) tree.getSelectionPath().getLastPathComponent();
                Rule rule = node.getRule();
                Language lang = config.getLanguage();
                if(lang == null) {
                  lang = Languages.getLanguageForLocale(Locale.getDefault());
                }
                Tools.showRuleInfoDialog(tree, messages.getString("guiAboutRuleTitle"),
                        rule.getDescription(), rule, messages,
                        lang.getShortNameWithCountryAndVariant());
              }
            });
            popup.add(aboutRuleMenuItem);
            popup.show(tree, e.getX(), e.getY());
          }
        }
  
        @Override
        public void mousePressed(MouseEvent e) {
          if (e.isPopupTrigger()) {
            handlePopupEvent(e);
          }
        }
  
        @Override
        public void mouseReleased(MouseEvent e) {
          if (e.isPopupTrigger()) {
            handlePopupEvent(e);
          }
        }
      };
  }

  @NotNull
  private JPanel getTreeButtonPanel() {
    GridBagConstraints cons;
    final JPanel treeButtonPanel = new JPanel();
    cons = new GridBagConstraints();
    cons.gridx = 0;
    cons.gridy = 0;
    final JButton expandAllButton = new JButton(messages.getString("guiExpandAll"));
    treeButtonPanel.add(expandAllButton, cons);
    expandAllButton.addActionListener(new ActionListener() {

      @Override
      public void actionPerformed(ActionEvent e) {
        TreeNode root = (TreeNode) configTree.getModel().getRoot();
        TreePath parent = new TreePath(root);
        for (Enumeration cat = root.children(); cat.hasMoreElements();) {
          TreeNode n = (TreeNode) cat.nextElement();
          TreePath child = parent.pathByAddingChild(n);
          configTree.expandPath(child);
        }
      }
    });

    cons.gridx = 1;
    cons.gridy = 0;
    final JButton collapseAllButton = new JButton(messages.getString("guiCollapseAll"));
    treeButtonPanel.add(collapseAllButton, cons);
    collapseAllButton.addActionListener(new ActionListener() {

      @Override
      public void actionPerformed(ActionEvent e) {
        TreeNode root = (TreeNode) configTree.getModel().getRoot();
        TreePath parent = new TreePath(root);
        for (Enumeration categ = root.children(); categ.hasMoreElements();) {
          TreeNode n = (TreeNode) categ.nextElement();
          TreePath child = parent.pathByAddingChild(n);
          configTree.collapsePath(child);
        }
      }
    });
    return treeButtonPanel;
  }

  @NotNull
  private JPanel getMotherTonguePanel(GridBagConstraints cons) {
    final JPanel motherTonguePanel = new JPanel();
    motherTonguePanel.add(new JLabel(messages.getString("guiMotherTongue")), cons);
    motherTongueBox = new JComboBox<>(getPossibleMotherTongues());
    if (config.getMotherTongue() != null) {
      motherTongueBox.setSelectedItem(config.getMotherTongue().getTranslatedName(messages));
    }
    motherTongueBox.addItemListener(new ItemListener() {

      @Override
      public void itemStateChanged(ItemEvent e) {
        if (e.getStateChange() == ItemEvent.SELECTED) {
          Language motherTongue;
          if (motherTongueBox.getSelectedItem() instanceof String) {
            motherTongue = getLanguageForLocalizedName(motherTongueBox.getSelectedItem().toString());
          } else {
            motherTongue = (Language) motherTongueBox.getSelectedItem();
          }
          config.setMotherTongue(motherTongue);
        }
      }
    });
    motherTonguePanel.add(motherTongueBox, cons);
    return motherTonguePanel;
  }

  private String[] getPossibleMotherTongues() {
    final List<String> motherTongues = new ArrayList<>();
    motherTongues.add(NO_MOTHER_TONGUE);
    for (final Language lang : Languages.get()) {
     motherTongues.add(lang.getTranslatedName(messages));
    }
    return motherTongues.toArray(new String[motherTongues.size()]);
  }

  @Override
  public void actionPerformed(ActionEvent e) {
    if (e.getSource() == okButton) {
      if(original != null) {
        original.restoreState(config);
      }
      dialog.setVisible(false);
    } else if (e.getSource() == cancelButton) {
      dialog.setVisible(false);
    }
  }

  
  @Nullable
  private Language getLanguageForLocalizedName(final String languageName) {
    for (final Language element : Languages.get()) {
      if (languageName.equals(element.getTranslatedName(messages))) {
        return element;
      }
    }
    return null;
  }

  static class CategoryComparator implements Comparator<Rule> {

    @Override
    public int compare(final Rule r1, final Rule r2) {
      final boolean hasCat = r1.getCategory() != null && r2.getCategory() != null;
      if (hasCat) {
        final int res = r1.getCategory().getName().compareTo(r2.getCategory().getName());
        if (res == 0) {
          return r1.getDescription().compareToIgnoreCase(r2.getDescription());
        }
        return res;
      }
      return r1.getDescription().compareToIgnoreCase(r2.getDescription());
    }

  }

}

<code block>

package org.languagetool.gui;

import org.jetbrains.annotations.Nullable;
import org.languagetool.JLanguageTool;
import org.languagetool.Language;
import org.languagetool.Languages;
import org.languagetool.rules.Rule;

import javax.swing.*;
import javax.swing.event.DocumentEvent;
import javax.swing.event.DocumentListener;
import javax.swing.event.TreeModelEvent;
import javax.swing.event.TreeModelListener;
import javax.swing.tree.DefaultMutableTreeNode;
import javax.swing.tree.DefaultTreeModel;
import javax.swing.tree.TreeNode;
import javax.swing.tree.TreePath;
import java.awt.*;
import java.awt.event.*;
import java.util.*;
import java.util.List;


public class ConfigurationDialog implements ActionListener {

  private static final String NO_MOTHER_TONGUE = "---";
  private static final int MAX_PORT = 65536;

  private final ResourceBundle messages;
  private final Configuration original;
  private final Configuration config;
  private final Frame owner;
  private final boolean insideOffice;

  private JButton okButton;
  private JButton cancelButton;
  private JDialog dialog;
  private JComboBox<String> motherTongueBox;
  private JCheckBox serverCheckbox;
  private JTextField serverPortField;
  private JTree configTree;
  private JCheckBox serverSettingsCheckbox;

  public ConfigurationDialog(Frame owner, boolean insideOffice, Configuration config) {
    this.owner = owner;
    this.insideOffice = insideOffice;
    this.original = config;
    this.config = original.copy(original);
    messages = JLanguageTool.getMessageBundle();
  }

  private DefaultMutableTreeNode createTree(List<Rule> rules) {
    DefaultMutableTreeNode root = new DefaultMutableTreeNode("Rules");
    String lastRuleId = null;
    Map<String, DefaultMutableTreeNode> parents = new TreeMap<>();
    for (final Rule rule : rules) {
      if (!parents.containsKey(rule.getCategory().getName())) {
        boolean enabled = true;
        if (config.getDisabledCategoryNames() != null && config.getDisabledCategoryNames().contains(rule.getCategory().getName())) {
          enabled = false;
        }
        DefaultMutableTreeNode categoryNode = new CategoryNode(rule.getCategory(), enabled);
        root.add(categoryNode);
        parents.put(rule.getCategory().getName(), categoryNode);
      }
      if (!rule.getId().equals(lastRuleId)) {
        RuleNode ruleNode = new RuleNode(rule, getState(rule));
        parents.get(rule.getCategory().getName()).add(ruleNode);
      }
      lastRuleId = rule.getId();
    }
    return root;
  }

  private boolean getState(Rule rule) {
    boolean ret = true;

    if (config.getDisabledRuleIds().contains(rule.getId())) {
      ret = false;
    }
    if (config.getDisabledCategoryNames().contains(rule.getCategory().getName())) {
      ret = false;
    }
    if (rule.isDefaultOff() && !config.getEnabledRuleIds().contains(rule.getId())) {
      ret = false;
    }
    if (rule.isDefaultOff() && rule.getCategory().isDefaultOff()
            && config.getEnabledRuleIds().contains(rule.getId())) {
      config.getDisabledCategoryNames().remove(rule.getCategory().getName());
    }
    return ret;
  }

  public void show(List<Rule> rules) {
    if (original != null) {
      config.restoreState(original);
    }
    dialog = new JDialog(owner, true);
    dialog.setTitle(messages.getString("guiConfigWindowTitle"));

    Collections.sort(rules, new CategoryComparator());

    
    final KeyStroke stroke = KeyStroke.getKeyStroke(KeyEvent.VK_ESCAPE, 0);
    final ActionListener actionListener = new ActionListener() {
      @Override
      public void actionPerformed(@SuppressWarnings("unused") ActionEvent actionEvent) {
        dialog.setVisible(false);
      }
    };
    final JRootPane rootPane = dialog.getRootPane();
    rootPane.registerKeyboardAction(actionListener, stroke,
        JComponent.WHEN_IN_FOCUSED_WINDOW);

    
    final JPanel checkBoxPanel = new JPanel();
    checkBoxPanel.setLayout(new GridBagLayout());
    GridBagConstraints cons = new GridBagConstraints();
    cons.anchor = GridBagConstraints.NORTHWEST;
    cons.gridx = 0;
    cons.weightx = 1.0;
    cons.weighty = 1.0;
    cons.fill = GridBagConstraints.BOTH;
    DefaultMutableTreeNode rootNode = createTree(rules);
    DefaultTreeModel treeModel = new DefaultTreeModel(rootNode);
    treeModel.addTreeModelListener(new TreeModelListener() {

      @Override
      public void treeNodesChanged(TreeModelEvent e) {
        DefaultMutableTreeNode node = (DefaultMutableTreeNode) e.getTreePath().getLastPathComponent();
        int index = e.getChildIndices()[0];
        node = (DefaultMutableTreeNode) node.getChildAt(index);
        if (node instanceof RuleNode) {
          RuleNode o = (RuleNode) node;
          if (o.getRule().isDefaultOff()) {
            if (o.isEnabled()) {
              config.getEnabledRuleIds().add(o.getRule().getId());
            } else {
              config.getEnabledRuleIds().remove(o.getRule().getId());
            }
          } else {
            if (o.isEnabled()) {
              config.getDisabledRuleIds().remove(o.getRule().getId());
            } else {
              config.getDisabledRuleIds().add(o.getRule().getId());
            }
          }
        }
        if (node instanceof CategoryNode) {
          CategoryNode o = (CategoryNode) node;
          if (o.isEnabled()) {
            config.getDisabledCategoryNames().remove(o.getCategory().getName());
          } else {
            config.getDisabledCategoryNames().add(o.getCategory().getName());
          }
        }
      }

      @Override
      public void treeNodesInserted(TreeModelEvent e) {
      }

      @Override
      public void treeNodesRemoved(TreeModelEvent e) {
      }

      @Override
      public void treeStructureChanged(TreeModelEvent e) {
      }
    });
    configTree = new JTree(treeModel);

    Language lang = config.getLanguage();
    if (lang == null) {
      lang = Languages.getLanguageForLocale(Locale.getDefault());
    }
    configTree.applyComponentOrientation(
      ComponentOrientation.getOrientation(lang.getLocale()));

    configTree.setRootVisible(false);
    configTree.setEditable(false);
    configTree.setCellRenderer(new CheckBoxTreeCellRenderer());
    TreeListener.install(configTree);
    checkBoxPanel.add(configTree, cons);

    MouseAdapter ma = new MouseAdapter() {
      private void handlePopupEvent(MouseEvent e) {
        final JTree tree = (JTree) e.getSource();

        TreePath path = tree.getPathForLocation(e.getX(), e.getY());
        if (path == null) {
          return;
        }

        DefaultMutableTreeNode node
                = (DefaultMutableTreeNode) path.getLastPathComponent();

        TreePath[] paths = tree.getSelectionPaths();

        boolean isSelected = false;
        if (paths != null) {
          for (TreePath selectionPath : paths) {
            if (selectionPath.equals(path)) {
              isSelected = true;
            }
          }
        }
        if (!isSelected) {
          tree.setSelectionPath(path);
        }
        if (node.isLeaf()) {
          JPopupMenu popup = new JPopupMenu();
          final JMenuItem aboutRuleMenuItem = new JMenuItem(messages.getString("guiAboutRuleMenu"));
          aboutRuleMenuItem.addActionListener(new ActionListener() {
            @Override
            public void actionPerformed(ActionEvent actionEvent) {
              RuleNode node = (RuleNode) tree.getSelectionPath().getLastPathComponent();
              Rule rule = node.getRule();
              Language lang = config.getLanguage();
              if(lang == null) {
                lang = Languages.getLanguageForLocale(Locale.getDefault());
              }
              Tools.showRuleInfoDialog(tree, messages.getString("guiAboutRuleTitle"),
                      rule.getDescription(), rule, messages,
                      lang.getShortNameWithCountryAndVariant());
            }
          });
          popup.add(aboutRuleMenuItem);
          popup.show(tree, e.getX(), e.getY());
        }
      }

      @Override
      public void mousePressed(MouseEvent e) {
        if (e.isPopupTrigger()) {
          handlePopupEvent(e);
        }
      }

      @Override
      public void mouseReleased(MouseEvent e) {
        if (e.isPopupTrigger()) {
          handlePopupEvent(e);
        }
      }
    };
    configTree.addMouseListener(ma);
    final JPanel treeButtonPanel = new JPanel();
    cons = new GridBagConstraints();
    cons.gridx = 0;
    cons.gridy = 0;
    final JButton expandAllButton = new JButton(messages.getString("guiExpandAll"));
    treeButtonPanel.add(expandAllButton, cons);
    expandAllButton.addActionListener(new ActionListener() {

      @Override
      public void actionPerformed(ActionEvent e) {
        TreeNode root = (TreeNode) configTree.getModel().getRoot();
        TreePath parent = new TreePath(root);
        for (Enumeration cat = root.children(); cat.hasMoreElements();) {
          TreeNode n = (TreeNode) cat.nextElement();
          TreePath child = parent.pathByAddingChild(n);
          configTree.expandPath(child);
        }
      }
    });

    cons.gridx = 1;
    cons.gridy = 0;
    final JButton collapseAllButton = new JButton(messages.getString("guiCollapseAll"));
    treeButtonPanel.add(collapseAllButton, cons);
    collapseAllButton.addActionListener(new ActionListener() {

      @Override
      public void actionPerformed(ActionEvent e) {
        TreeNode root = (TreeNode) configTree.getModel().getRoot();
        TreePath parent = new TreePath(root);
        for (Enumeration categ = root.children(); categ.hasMoreElements();) {
          TreeNode n = (TreeNode) categ.nextElement();
          TreePath child = parent.pathByAddingChild(n);
          configTree.collapsePath(child);
        }
      }
    });

    final JPanel motherTonguePanel = new JPanel();
    motherTonguePanel.add(new JLabel(messages.getString("guiMotherTongue")), cons);
    motherTongueBox = new JComboBox<>(getPossibleMotherTongues());
    if (config.getMotherTongue() != null) {
      motherTongueBox.setSelectedItem(config.getMotherTongue().getTranslatedName(messages));
    }
    motherTongueBox.addItemListener(new ItemListener() {

      @Override
      public void itemStateChanged(ItemEvent e) {
        if (e.getStateChange() == ItemEvent.SELECTED) {
          Language motherTongue;
          if (motherTongueBox.getSelectedItem() instanceof String) {
            motherTongue = getLanguageForLocalizedName(motherTongueBox.getSelectedItem().toString());
          } else {
            motherTongue = (Language) motherTongueBox.getSelectedItem();
          }
          config.setMotherTongue(motherTongue);
        }
      }
    });
    motherTonguePanel.add(motherTongueBox, cons);
    
    final JPanel portPanel = new JPanel();
    portPanel.setLayout(new GridBagLayout());
    cons = new GridBagConstraints();
    cons.insets = new Insets(0, 4, 0, 0);
    cons.gridx = 0;
    cons.gridy = 0;
    cons.anchor = GridBagConstraints.WEST;
    cons.fill = GridBagConstraints.NONE;
    cons.weightx = 0.0f;
    if (!insideOffice) {
      serverCheckbox = new JCheckBox(Tools.getLabel(messages.getString("guiRunOnPort")));
      serverCheckbox.setMnemonic(Tools.getMnemonic(messages.getString("guiRunOnPort")));
      serverCheckbox.setSelected(config.getRunServer());
      portPanel.add(serverCheckbox, cons);
      serverCheckbox.addActionListener(new ActionListener() {
        @Override
        public void actionPerformed(@SuppressWarnings("unused") ActionEvent e) {
          serverPortField.setEnabled(serverCheckbox.isSelected());
          serverSettingsCheckbox.setEnabled(serverCheckbox.isSelected());
        }
      });
      serverCheckbox.addItemListener(new ItemListener() {

        @Override
        public void itemStateChanged(ItemEvent e) {
          config.setRunServer(serverCheckbox.isSelected());
        }
      });

      serverPortField = new JTextField(Integer.toString(config.getServerPort()));
      serverPortField.setEnabled(serverCheckbox.isSelected());
      serverSettingsCheckbox = new JCheckBox(Tools.getLabel(messages.getString("useGUIConfig")));
      serverPortField.setMinimumSize(new Dimension(100, 25));  
      cons.gridx = 1;
      portPanel.add(serverPortField, cons);
      serverPortField.getDocument().addDocumentListener(new DocumentListener() {

        @Override
        public void insertUpdate(DocumentEvent e) {
          changedUpdate(e);
        }

        @Override
        public void removeUpdate(DocumentEvent e) {
          changedUpdate(e);
        }

        @Override
        public void changedUpdate(DocumentEvent e) {
          try {
            int serverPort = Integer.parseInt(serverPortField.getText());
            if (serverPort > -1 && serverPort < MAX_PORT) {
              serverPortField.setForeground(null);
              config.setServerPort(serverPort);
            } else {
              serverPortField.setForeground(Color.RED);
            }
          } catch (NumberFormatException ex) {
            serverPortField.setForeground(Color.RED);
          }
        }
      });

      cons.gridx = 0;
      cons.gridy = 10;      
      serverSettingsCheckbox.setMnemonic(Tools.getMnemonic(messages
          .getString("useGUIConfig")));
      serverSettingsCheckbox.setSelected(config.getUseGUIConfig());
      serverSettingsCheckbox.setEnabled(config.getRunServer());
      serverSettingsCheckbox.addItemListener(new ItemListener() {
        @Override
        public void itemStateChanged(ItemEvent e) {
          config.setUseGUIConfig(serverSettingsCheckbox.isSelected());
        }
      });
      portPanel.add(serverSettingsCheckbox, cons);
    }

    final JPanel buttonPanel = new JPanel();
    buttonPanel.setLayout(new GridBagLayout());
    okButton = new JButton(Tools.getLabel(messages.getString("guiOKButton")));
    okButton.setMnemonic(Tools.getMnemonic(messages.getString("guiOKButton")));
    okButton.addActionListener(this);
    cancelButton = new JButton(Tools.getLabel(messages.getString("guiCancelButton")));
    cancelButton.setMnemonic(Tools.getMnemonic(messages.getString("guiCancelButton")));
    cancelButton.addActionListener(this);
    cons = new GridBagConstraints();
    cons.insets = new Insets(0, 4, 0, 0);
    buttonPanel.add(okButton, cons);
    buttonPanel.add(cancelButton, cons);

    final Container contentPane = dialog.getContentPane();
    contentPane.setLayout(new GridBagLayout());
    cons = new GridBagConstraints();
    cons.insets = new Insets(4, 4, 4, 4);
    cons.gridx = 0;
    cons.gridy = 0;
    cons.weightx = 10.0f;
    cons.weighty = 10.0f;
    cons.fill = GridBagConstraints.BOTH;
    contentPane.add(new JScrollPane(checkBoxPanel), cons);

    cons.gridx = 0;
    cons.gridy++;
    cons.fill = GridBagConstraints.NONE;
    cons.anchor = GridBagConstraints.LINE_END;
    contentPane.add(treeButtonPanel, cons);
    
    cons.gridy++;
    cons.anchor = GridBagConstraints.WEST;
    contentPane.add(motherTonguePanel, cons);

    cons.gridy++;
    cons.anchor = GridBagConstraints.WEST;
    contentPane.add(portPanel, cons);

    cons.gridy++;
    cons.anchor = GridBagConstraints.EAST;
    contentPane.add(buttonPanel, cons);

    dialog.pack();
    dialog.setSize(500, 500);
    
    final Dimension screenSize = Toolkit.getDefaultToolkit().getScreenSize();
    final Dimension frameSize = dialog.getSize();
    dialog.setLocation(screenSize.width / 2 - frameSize.width / 2,
        screenSize.height / 2 - frameSize.height / 2);
    dialog.setLocationByPlatform(true);
    dialog.setVisible(true);
  }

  private String[] getPossibleMotherTongues() {
    final List<String> motherTongues = new ArrayList<>();
    motherTongues.add(NO_MOTHER_TONGUE);
    for (final Language lang : Languages.get()) {
     motherTongues.add(lang.getTranslatedName(messages));
    }
    return motherTongues.toArray(new String[motherTongues.size()]);
  }

  @Override
  public void actionPerformed(ActionEvent e) {
    if (e.getSource() == okButton) {
      if(original != null) {
        original.restoreState(config);
      }
      dialog.setVisible(false);
    } else if (e.getSource() == cancelButton) {
      dialog.setVisible(false);
    }
  }

  
  @Nullable
  private Language getLanguageForLocalizedName(final String languageName) {
    for (final Language element : Languages.get()) {
      if (languageName.equals(element.getTranslatedName(messages))) {
        return element;
      }
    }
    return null;
  }

  static class CategoryComparator implements Comparator<Rule> {

    @Override
    public int compare(final Rule r1, final Rule r2) {
      final boolean hasCat = r1.getCategory() != null && r2.getCategory() != null;
      if (hasCat) {
        final int res = r1.getCategory().getName().compareTo(r2.getCategory().getName());
        if (res == 0) {
          return r1.getDescription().compareToIgnoreCase(r2.getDescription());
        }
        return res;
      }
      return r1.getDescription().compareToIgnoreCase(r2.getDescription());
    }

  }

}
