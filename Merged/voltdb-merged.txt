

package org.voltdb;

import java.util.concurrent.TimeUnit;

import org.voltcore.logging.Level;
import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.CoreUtils;
import org.voltcore.utils.EstTime;
import org.voltcore.utils.RateLimitedLogger;
import org.voltdb.client.ProcedureCallback;
import org.voltdb.importer.ImportContext;

import com.google_voltpatches.common.util.concurrent.ListeningExecutorService;


public class ImportHandler {

    private static final VoltLogger m_logger = new VoltLogger("IMPORT");

    private final ListeningExecutorService m_es;
    private final ImportContext m_importContext;
    private volatile boolean m_stopped = false;

    final static long SUPPRESS_INTERVAL = 60;

    
    public ImportHandler(ImportContext importContext) {
        
        m_es = CoreUtils.getListeningExecutorService("ImportHandler - " + importContext.getName(), 2);
        m_importContext = importContext;
    }

    
    public void readyForData() {
        m_es.submit(new Runnable() {
            @Override
            public void run() {
                m_logger.info("Importer ready importing data for: " + m_importContext.getName());
                try {
                    m_importContext.readyForData();
                } catch (Throwable t) {
                    m_logger.error("ImportContext stopped with following exception", t);
                }
                m_logger.info("Importer finished importing data for: " + m_importContext.getName());
            }
        });
    }

    public void stop() {
        m_stopped = true;
        m_es.submit(new Runnable() {

            @Override
            public void run() {
                try {
                    
                    VoltDB.instance().getClientInterface().getInternalConnectionHandler().drain();
                    m_importContext.stop();
                } catch (Exception ex) {
                    ex.printStackTrace();
                }
                m_logger.info("Importer stopped: " + m_importContext.getName());
            }
        });
        try {
            m_es.shutdown();
            m_es.awaitTermination(1, TimeUnit.DAYS);
        } catch (Exception ex) {
            m_logger.warn("Importer did not stop gracefully.", ex);
        }
    }

    
    public boolean hasTable(String name) {
        return VoltDB.instance().getClientInterface().getInternalConnectionHandler().hasTable(name);
    }

    public boolean callProcedure(ImportContext ic, String proc, Object... fieldList) {
        return callProcedure(ic, null, proc, fieldList);
    }

    public boolean callProcedure(ImportContext ic, ProcedureCallback procCallback, String proc, Object... fieldList) {
        if (!m_stopped) {
            return VoltDB.instance().getClientInterface().getInternalConnectionHandler()
                    .callProcedure(ic.getBackpressureTimeout(), procCallback, proc, fieldList);
        } else {
            m_logger.warn("Importer is in stopped state. Cannot execute procedures");
            return false;
        }
    }


    
    private void rateLimitedLog(Level level, Throwable cause, String format, Object...args) {
        RateLimitedLogger.tryLogForMessage(
                EstTime.currentTimeMillis(),
                SUPPRESS_INTERVAL, TimeUnit.SECONDS,
                m_logger, level,
                cause, format, args
                );
    }

    
    public void info(String message) {
        m_logger.info(message);
    }

    
    public void error(String message) {
        m_logger.error(message);
    }

    
    public void warn(String message) {
        m_logger.warn(message);
    }

    public boolean isDebugEnabled() {
        return m_logger.isDebugEnabled();
    }

    public boolean isTraceEnabled() {
        return m_logger.isTraceEnabled();
    }

    public boolean isInfoEnabled() {
        return m_logger.isInfoEnabled();
    }

    
    public void debug(String message) {
        m_logger.debug(message);
    }

    
    public void error(String message, Throwable t) {
        m_logger.error(message, t);
    }

    public void error(Throwable t, String format, Object...args) {
        rateLimitedLog(Level.ERROR, t, format, args);
    }

    public void warn(Throwable t, String format, Object...args) {
        rateLimitedLog(Level.WARN, t, format, args);
    }

}

<code block>


package org.voltdb;

import static org.voltdb.ClientInterface.getPartitionForProcedure;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.concurrent.atomic.AtomicLong;

import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.DBBPool;
import org.voltcore.utils.DBBPool.BBContainer;
import org.voltdb.catalog.Procedure;
import org.voltdb.catalog.Table;
import org.voltdb.client.ProcedureCallback;
import org.voltdb.client.ProcedureInvocationType;


public class InternalConnectionHandler {

    private static final VoltLogger m_logger = new VoltLogger("InternalConnectionHandler");

    
    private final AtomicLong m_failedCount = new AtomicLong();
    private final AtomicLong m_submitSuccessCount = new AtomicLong();
    private final InternalClientResponseAdapter m_adapter;

    private static final long MAX_PENDING_TRANSACTIONS = Integer.getInteger("IMPORTER_MAX_PENDING_TRANSACTIONS", 5000);

    public InternalConnectionHandler(InternalClientResponseAdapter adapter) {
        m_adapter = adapter;
    }

    
    private BBContainer getBuffer(int sz) {
        return DBBPool.allocateDirectAndPool(sz);
    }

    
    public boolean hasTable(String name) {
        Table table = VoltDB.instance().getCatalogContext().tables.get(name);
        return (table!=null);
    }

    
    public boolean callProcedure(long backPressureTimeout, ProcedureCallback procCallback, String proc, Object... fieldList) {
        
        if (VoltDB.instance().getMode() == OperationMode.PAUSED) {
            m_logger.warn("Server is paused and is currently unavailable - please try again later.");
            m_failedCount.incrementAndGet();
            return false;
        }
        Procedure catProc = VoltDB.instance().getClientInterface().getProcedureFromName(proc, VoltDB.instance().getCatalogContext());
        if (catProc == null) {
            m_logger.error("Can not invoke procedure from streaming interface procedure not found.");
            m_failedCount.incrementAndGet();
            return false;
        }

        int counter = 1;
        int maxSleepNano = 100000;
        long start = System.nanoTime();
        long currNanos = start;
        while ((backPressureTimeout > 0) && (m_adapter.getPendingCount() > MAX_PENDING_TRANSACTIONS)) {
            try {
                int nanos = 500 * counter++;
                int sleepNanos = nanos > maxSleepNano ? maxSleepNano : nanos;
                Thread.sleep(0, sleepNanos);
                
                currNanos += sleepNanos;
                if (currNanos > start + backPressureTimeout) {
                    return false;
                }
            } catch (InterruptedException ex) { }
        }
        final long nowNanos = System.nanoTime();
        StoredProcedureInvocation task = new StoredProcedureInvocation();
        ParameterSet pset = ParameterSet.fromArrayWithCopy(fieldList);
        
        int sz = 1 + 4 + proc.length() + 8 + pset.getSerializedSize();
        
        final BBContainer tcont = getBuffer(sz);
        final ByteBuffer taskbuf = tcont.b();
        try {
            taskbuf.put(ProcedureInvocationType.ORIGINAL.getValue());
            taskbuf.putInt(proc.length());
            taskbuf.put(proc.getBytes());
            taskbuf.putLong(m_adapter.connectionId());
            pset.flattenToBuffer(taskbuf);
            taskbuf.flip();
            task.initFromBuffer(taskbuf);
        } catch (IOException ex) {
            m_failedCount.incrementAndGet();
            m_logger.error("Failed to serialize parameters for stream: " + proc, ex);
            tcont.discard();
            return false;
        }

        int partition = -1;
        try {
            partition = getPartitionForProcedure(catProc, task);
        } catch (Exception e) {
            m_logger.error("Can not invoke SP procedure from streaming interface partition not found.");
            m_failedCount.incrementAndGet();
            tcont.discard();
            return false;
        }

        boolean success = m_adapter.createTransaction(catProc, procCallback, task, tcont, partition, nowNanos);
        if (!success) {
            tcont.discard();
            m_failedCount.incrementAndGet();
        } else {
            m_submitSuccessCount.incrementAndGet();
        }

        return success;
    }

    public void drain() {
        m_adapter.drain();
    }
}

<code block>


package org.voltdb;

import java.util.concurrent.TimeUnit;

import org.voltcore.logging.Level;
import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.CoreUtils;
import org.voltcore.utils.EstTime;
import org.voltcore.utils.RateLimitedLogger;
import org.voltdb.importer.ImportContext;

import com.google_voltpatches.common.util.concurrent.ListeningExecutorService;


public class ImportHandler {

    private static final VoltLogger m_logger = new VoltLogger("IMPORT");

    private final ListeningExecutorService m_es;
    private final ImportContext m_importContext;
    private volatile boolean m_stopped = false;

    final static long SUPPRESS_INTERVAL = 60;

    
    public ImportHandler(ImportContext importContext) {
        
        m_es = CoreUtils.getListeningExecutorService("ImportHandler - " + importContext.getName(), 2);
        m_importContext = importContext;
    }

    
    public void readyForData() {
        m_es.submit(new Runnable() {
            @Override
            public void run() {
                m_logger.info("Importer ready importing data for: " + m_importContext.getName());
                try {
                    m_importContext.readyForData();
                } catch (Throwable t) {
                    m_logger.error("ImportContext stopped with following exception", t);
                }
                m_logger.info("Importer finished importing data for: " + m_importContext.getName());
            }
        });
    }

    public void stop() {
        m_stopped = true;
        m_es.submit(new Runnable() {

            @Override
            public void run() {
                try {
                    
                    VoltDB.instance().getClientInterface().getInternalConnectionHandler().drain();
                    m_importContext.stop();
                } catch (Exception ex) {
                    ex.printStackTrace();
                }
                m_logger.info("Importer stopped: " + m_importContext.getName());
            }
        });
        try {
            m_es.shutdown();
            m_es.awaitTermination(1, TimeUnit.DAYS);
        } catch (Exception ex) {
            m_logger.warn("Importer did not stop gracefully.", ex);
        }
    }

    
    public boolean hasTable(String name) {
        return VoltDB.instance().getClientInterface().getInternalConnectionHandler().hasTable(name);
    }

    public boolean callProcedure(ImportContext ic, String proc, Object... fieldList) {
        if (!m_stopped) {
            return VoltDB.instance().getClientInterface().getInternalConnectionHandler()
                    .callProcedure(ic.getBackpressureTimeout(), proc, fieldList);
        } else {
            m_logger.warn("Importer is in stopped state. Cannot execute procedures");
            return false;
        }
    }


    
    private void rateLimitedLog(Level level, Throwable cause, String format, Object...args) {
        RateLimitedLogger.tryLogForMessage(
                EstTime.currentTimeMillis(),
                SUPPRESS_INTERVAL, TimeUnit.SECONDS,
                m_logger, level,
                cause, format, args
                );
    }

    
    public void info(String message) {
        m_logger.info(message);
    }

    
    public void error(String message) {
        m_logger.error(message);
    }

    
    public void warn(String message) {
        m_logger.warn(message);
    }

    public boolean isDebugEnabled() {
        return m_logger.isDebugEnabled();
    }

    public boolean isTraceEnabled() {
        return m_logger.isTraceEnabled();
    }

    public boolean isInfoEnabled() {
        return m_logger.isInfoEnabled();
    }

    
    public void debug(String message) {
        m_logger.debug(message);
    }

    
    public void error(String message, Throwable t) {
        m_logger.error(message, t);
    }

    public void error(Throwable t, String format, Object...args) {
        rateLimitedLog(Level.ERROR, t, format, args);
    }

    public void warn(Throwable t, String format, Object...args) {
        rateLimitedLog(Level.WARN, t, format, args);
    }

}

<code block>


package org.voltdb;

import static org.voltdb.ClientInterface.getPartitionForProcedure;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.concurrent.atomic.AtomicLong;

import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.DBBPool;
import org.voltcore.utils.DBBPool.BBContainer;
import org.voltdb.catalog.Procedure;
import org.voltdb.catalog.Table;
import org.voltdb.client.ProcedureInvocationType;


public class InternalConnectionHandler {

    private static final VoltLogger m_logger = new VoltLogger("InternalConnectionHandler");

    
    private final AtomicLong m_failedCount = new AtomicLong();
    private final AtomicLong m_submitSuccessCount = new AtomicLong();
    private final InternalClientResponseAdapter m_adapter;

    private static final long MAX_PENDING_TRANSACTIONS = Integer.getInteger("IMPORTER_MAX_PENDING_TRANSACTIONS", 5000);

    public InternalConnectionHandler(InternalClientResponseAdapter adapter) {
        m_adapter = adapter;
    }

    
    private BBContainer getBuffer(int sz) {
        return DBBPool.allocateDirectAndPool(sz);
    }

    
    public boolean hasTable(String name) {
        Table table = VoltDB.instance().getCatalogContext().tables.get(name);
        return (table!=null);
    }

    
    public boolean callProcedure(long backPressureTimeout, String proc, Object... fieldList) {
        
        if (VoltDB.instance().getMode() == OperationMode.PAUSED) {
            m_logger.warn("Server is paused and is currently unavailable - please try again later.");
            m_failedCount.incrementAndGet();
            return false;
        }
        Procedure catProc = VoltDB.instance().getClientInterface().getProcedureFromName(proc, VoltDB.instance().getCatalogContext());
        if (catProc == null) {
            m_logger.error("Can not invoke procedure from streaming interface procedure not found.");
            m_failedCount.incrementAndGet();
            return false;
        }

        int counter = 1;
        int maxSleepNano = 100000;
        long start = System.nanoTime();
        long currNanos = start;
        while ((backPressureTimeout > 0) && (m_adapter.getPendingCount() > MAX_PENDING_TRANSACTIONS)) {
            try {
                int nanos = 500 * counter++;
                int sleepNanos = nanos > maxSleepNano ? maxSleepNano : nanos;
                Thread.sleep(0, sleepNanos);
                
                currNanos += sleepNanos;
                if (currNanos > start + backPressureTimeout) {
                    return false;
                }
            } catch (InterruptedException ex) { }
        }
        final long nowNanos = System.nanoTime();
        StoredProcedureInvocation task = new StoredProcedureInvocation();
        ParameterSet pset = ParameterSet.fromArrayWithCopy(fieldList);
        
        int sz = 1 + 4 + proc.length() + 8 + pset.getSerializedSize();
        
        final BBContainer tcont = getBuffer(sz);
        final ByteBuffer taskbuf = tcont.b();
        try {
            taskbuf.put(ProcedureInvocationType.ORIGINAL.getValue());
            taskbuf.putInt(proc.length());
            taskbuf.put(proc.getBytes());
            taskbuf.putLong(m_adapter.connectionId());
            pset.flattenToBuffer(taskbuf);
            taskbuf.flip();
            task.initFromBuffer(taskbuf);
        } catch (IOException ex) {
            m_failedCount.incrementAndGet();
            m_logger.error("Failed to serialize parameters for stream: " + proc, ex);
            tcont.discard();
            return false;
        }

        int partition = -1;
        try {
            partition = getPartitionForProcedure(catProc, task);
        } catch (Exception e) {
            m_logger.error("Can not invoke SP procedure from streaming interface partition not found.");
            m_failedCount.incrementAndGet();
            tcont.discard();
            return false;
        }

        boolean success = m_adapter.createTransaction(catProc, null, task, tcont, partition, nowNanos);
        if (!success) {
            tcont.discard();
            m_failedCount.incrementAndGet();
        } else {
            m_submitSuccessCount.incrementAndGet();
        }

        return success;
    }

    public void drain() {
        m_adapter.drain();
    }
}

<code block>


package org.voltdb;

import java.io.IOException;
import java.io.PrintWriter;
import java.io.StringWriter;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.AsynchronousCloseException;
import java.nio.channels.SelectionKey;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.concurrent.Callable;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.FutureTask;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;

import org.HdrHistogram_voltpatches.AbstractHistogram;
import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.json_voltpatches.JSONObject;
import org.voltcore.logging.Level;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.BinaryPayloadMessage;
import org.voltcore.messaging.ForeignHost;
import org.voltcore.messaging.HostMessenger;
import org.voltcore.messaging.LocalObjectMessage;
import org.voltcore.messaging.Mailbox;
import org.voltcore.messaging.VoltMessage;
import org.voltcore.network.Connection;
import org.voltcore.network.InputHandler;
import org.voltcore.network.NIOReadStream;
import org.voltcore.network.QueueMonitor;
import org.voltcore.network.ReverseDNSPolicy;
import org.voltcore.network.VoltNetworkPool;
import org.voltcore.network.VoltPort;
import org.voltcore.network.VoltProtocolHandler;
import org.voltcore.network.WriteStream;
import org.voltcore.utils.CoreUtils;
import org.voltcore.utils.DeferredSerialization;
import org.voltcore.utils.EstTime;
import org.voltcore.utils.Pair;
import org.voltcore.utils.RateLimitedLogger;
import org.voltdb.AuthSystem.AuthProvider;
import org.voltdb.AuthSystem.AuthUser;
import org.voltdb.CatalogContext.ProcedurePartitionInfo;
import org.voltdb.ClientInterfaceHandleManager.Iv2InFlight;
import org.voltdb.SystemProcedureCatalog.Config;
import org.voltdb.VoltTable.ColumnInfo;
import org.voltdb.catalog.CatalogMap;
import org.voltdb.catalog.Column;
import org.voltdb.catalog.Database;
import org.voltdb.catalog.Procedure;
import org.voltdb.catalog.SnapshotSchedule;
import org.voltdb.catalog.Statement;
import org.voltdb.catalog.Table;
import org.voltdb.client.ClientAuthHashScheme;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureInvocationType;
import org.voltdb.common.Constants;
import org.voltdb.compiler.AdHocPlannedStatement;
import org.voltdb.compiler.AdHocPlannedStmtBatch;
import org.voltdb.compiler.AdHocPlannerWork;
import org.voltdb.compiler.AsyncCompilerResult;
import org.voltdb.compiler.AsyncCompilerWork.AsyncCompilerWorkCompletionHandler;
import org.voltdb.compiler.CatalogChangeResult;
import org.voltdb.compiler.CatalogChangeWork;
import org.voltdb.dtxn.InitiatorStats.InvocationInfo;
import org.voltdb.iv2.Cartographer;
import org.voltdb.iv2.Iv2Trace;
import org.voltdb.iv2.MpInitiator;
import org.voltdb.messaging.FastDeserializer;
import org.voltdb.messaging.InitiateResponseMessage;
import org.voltdb.messaging.Iv2EndOfLogMessage;
import org.voltdb.messaging.Iv2InitiateTaskMessage;
import org.voltdb.messaging.LocalMailbox;
import org.voltdb.messaging.MultiPartitionParticipantMessage;
import org.voltdb.parser.SQLLexer;
import org.voltdb.security.AuthenticationRequest;
import org.voltdb.sysprocs.saverestore.SnapshotUtil;
import org.voltdb.utils.Encoder;
import org.voltdb.utils.MiscUtils;

import com.google_voltpatches.common.base.Charsets;
import com.google_voltpatches.common.base.Predicate;
import com.google_voltpatches.common.base.Supplier;
import com.google_voltpatches.common.base.Throwables;
import com.google_voltpatches.common.collect.ImmutableMap;
import com.google_voltpatches.common.util.concurrent.ListenableFuture;
import com.google_voltpatches.common.util.concurrent.ListenableFutureTask;


public class ClientInterface implements SnapshotDaemon.DaemonInitiator {

    static long TOPOLOGY_CHANGE_CHECK_MS = Long.getLong("TOPOLOGY_CHANGE_CHECK_MS", 5000);
    static long AUTH_TIMEOUT_MS = Long.getLong("AUTH_TIMEOUT_MS", 30000);

    
    public static final long ASYNC_TOPO_HANDLE = Long.MAX_VALUE - 1;

    
    public static final byte AUTHENTICATION_FAILURE = Constants.AUTHENTICATION_FAILURE;
    public static final byte MAX_CONNECTIONS_LIMIT_ERROR = Constants.MAX_CONNECTIONS_LIMIT_ERROR;
    public static final byte WIRE_PROTOCOL_TIMEOUT_ERROR = Constants.WIRE_PROTOCOL_TIMEOUT_ERROR;
    public static final byte WIRE_PROTOCOL_FORMAT_ERROR = Constants.WIRE_PROTOCOL_FORMAT_ERROR;
    public static final byte AUTHENTICATION_FAILURE_DUE_TO_REJOIN = Constants.AUTHENTICATION_FAILURE_DUE_TO_REJOIN;
    public static final byte EXPORT_DISABLED_REJECTION = Constants.EXPORT_DISABLED_REJECTION;

    
    public static final byte AUTH_HANDSHAKE_VERSION = Constants.AUTH_HANDSHAKE_VERSION;
    public static final byte AUTH_SERVICE_NAME = Constants.AUTH_SERVICE_NAME;
    public static final byte AUTH_HANDSHAKE = Constants.AUTH_HANDSHAKE;

    
    public static final long RESTORE_AGENT_CID          = Long.MIN_VALUE + 1;
    public static final long SNAPSHOT_UTIL_CID          = Long.MIN_VALUE + 2;
    public static final long ELASTIC_JOIN_CID           = Long.MIN_VALUE + 3;
    public static final long DR_REPLICATION_CID         = Long.MIN_VALUE + 4;
    public static final long IMPORTER_CID               = Long.MIN_VALUE + 5;
    
    public static final long CL_REPLAY_BASE_CID         = Long.MIN_VALUE + 100;

    private static final VoltLogger log = new VoltLogger(ClientInterface.class.getName());
    private static final VoltLogger authLog = new VoltLogger("AUTH");
    private static final VoltLogger hostLog = new VoltLogger("HOST");
    private static final VoltLogger networkLog = new VoltLogger("NETWORK");

    
    public enum ExplainMode {
        NONE, EXPLAIN_ADHOC, EXPLAIN_DEFAULT_PROC;
    }

    private final ClientAcceptor m_acceptor;
    private ClientAcceptor m_adminAcceptor;

    private final SnapshotDaemon m_snapshotDaemon = new SnapshotDaemon();
    private final SnapshotDaemonAdapter m_snapshotDaemonAdapter = new SnapshotDaemonAdapter();

    
    private final AtomicReference<CatalogContext> m_catalogContext = new AtomicReference<CatalogContext>(null);

    
    private final AtomicInteger m_numConnections = new AtomicInteger(0);

    
    ZooKeeper m_zk;

    
    private final ConcurrentHashMap<Long, ClientInterfaceHandleManager> m_cihm =
            new ConcurrentHashMap<Long, ClientInterfaceHandleManager>(2048, .75f, 128);

    private final RateLimitedClientNotifier m_notifier = new RateLimitedClientNotifier();

    private final Cartographer m_cartographer;


    
    private final PermissionValidator m_permissionValidator = new PermissionValidator();
    
    private final InvocationValidator m_invocationValidator;

    
    private final  AsyncCompilerWorkCompletionHandler m_adhocCompletionHandler = new AsyncCompilerWorkCompletionHandler() {
        @Override
        public void onCompletion(AsyncCompilerResult result) {
            processFinishedCompilerWork(result);
        }
    };

    
    private final CopyOnWriteArrayList<AdmissionControlGroup> m_allACGs =
            new CopyOnWriteArrayList<AdmissionControlGroup>();

    
    private final ThreadLocal<AdmissionControlGroup> m_acg = new ThreadLocal<AdmissionControlGroup>() {
        @Override
        public AdmissionControlGroup initialValue() {
            AdmissionControlGroup acg = new AdmissionControlGroup( 1024 * 1024 * 8, 1000);
            m_allACGs.add(acg);
            return acg;
        }
    };

    
    private final int m_allPartitions[];
    private ImmutableMap<Integer, Long> m_localReplicas = ImmutableMap.<Integer, Long>builder().build();
    final long m_siteId;
    final long m_plannerSiteId;

    final Mailbox m_mailbox;

    
    private final boolean m_hasDTXNBackPressure = false;

    
    private final AtomicInteger MAX_CONNECTIONS = new AtomicInteger(800);
    private ScheduledFuture<?> m_maxConnectionUpdater;

    private final boolean m_isConfiguredForHSQL;

    
    public class ClientAcceptor implements Runnable {
        private final int m_port;
        private final ServerSocketChannel m_serverSocket;
        private final VoltNetworkPool m_network;
        private volatile boolean m_running = true;
        private Thread m_thread = null;
        private final boolean m_isAdmin;
        private final InetAddress m_interface;

        
        private final ExecutorService m_executor = CoreUtils.getBoundedThreadPoolExecutor(128, 10L, TimeUnit.SECONDS,
                        CoreUtils.getThreadFactory("Client authentication threads", "Client authenticator"));

        ClientAcceptor(InetAddress intf, int port, VoltNetworkPool network, boolean isAdmin)
        {
            m_interface = intf;
            m_network = network;
            m_port = port;
            m_isAdmin = isAdmin;
            ServerSocketChannel socket;
            try {
                socket = ServerSocketChannel.open();
            } catch (IOException e) {
                if (m_isAdmin) {
                    hostLog.fatal("Failed to open admin wire protocol listener on port "
                            + m_port + "(" + e.getMessage() + ")");
                }
                else {
                    hostLog.fatal("Failed to open native wire protocol listener on port "
                            + m_port + "(" + e.getMessage() + ")");
                }
                throw new RuntimeException(e);
            }
            m_serverSocket = socket;
        }

        public void start() throws IOException {
            if (m_thread != null) {
                throw new IllegalStateException("A thread for this ClientAcceptor is already running");
            }
            if (!m_serverSocket.socket().isBound()) {
                try {
                    if (m_interface != null) {
                        m_serverSocket.socket().bind(new InetSocketAddress(m_interface, m_port));
                    } else {
                        m_serverSocket.socket().bind(new InetSocketAddress(m_port));
                    }
                }
                catch (IOException e) {
                    String msg = "Client interface failed to bind to"
                            + (m_isAdmin ? " Admin " : " ") + "port: " + m_port;
                    MiscUtils.printPortsInUse(hostLog);
                    VoltDB.crashLocalVoltDB(msg, false, e);
                }
            }
            m_running = true;
            String threadName = m_isAdmin ? "AdminPort connection acceptor" : "ClientPort connection acceptor";
            m_thread = new Thread( null, this, threadName, 262144);
            m_thread.setDaemon(true);
            m_thread.start();
        }

        public void shutdown() throws InterruptedException {
            
            if (m_thread != null) {
                synchronized (this) {
                    m_running = false;
                    m_thread.interrupt();
                }
                m_thread.join();
            }
        }

        
        class AuthRunnable implements Runnable {
            final SocketChannel m_socket;

            AuthRunnable(SocketChannel socket) {
                this.m_socket = socket;
            }

            @Override
            public void run() {
                if (m_socket != null) {
                    boolean success = false;
                    
                    AtomicReference<String> timeoutRef = new AtomicReference<String>();
                    try {
                        final InputHandler handler = authenticate(m_socket, timeoutRef);
                        if (handler != null) {
                            m_socket.configureBlocking(false);
                            if (handler instanceof ClientInputHandler) {
                                m_socket.socket().setTcpNoDelay(true);
                            }
                            m_socket.socket().setKeepAlive(true);

                            if (handler instanceof ClientInputHandler) {
                                m_network.registerChannel(
                                                m_socket,
                                                handler,
                                                0,
                                                ReverseDNSPolicy.ASYNCHRONOUS);
                                
                            } else {
                                m_network.registerChannel(
                                        m_socket,
                                        handler,
                                        SelectionKey.OP_READ,
                                        ReverseDNSPolicy.ASYNCHRONOUS);
                            }
                            success = true;
                        }
                    } catch (Exception e) {
                        try {
                            m_socket.close();
                        } catch (IOException e1) {
                            
                        }
                        if (m_running) {
                            if (timeoutRef.get() != null) {
                                hostLog.warn(timeoutRef.get());
                            } else {
                                hostLog.warn("Exception authenticating and "
                                        + "registering user in ClientAcceptor", e);
                            }
                        }
                    } finally {
                        if (!success) {
                            m_numConnections.decrementAndGet();
                        }
                    }
                }
            }
        }

        @Override
        public void run() {
            try {
                do {
                    final SocketChannel socket;
                    try
                    {
                        socket = m_serverSocket.accept();
                    }
                    catch (IOException ioe)
                    {
                        if (ioe.getMessage() != null &&
                            ioe.getMessage().contains("Too many open files"))
                        {
                            networkLog.warn("Rejected accepting new connection due to too many open files");
                            continue;
                        }
                        else
                        {
                            throw ioe;
                        }
                    }

                    
                    if (m_numConnections.get() >= MAX_CONNECTIONS.get()) {
                        networkLog.warn("Rejected connection from " +
                                socket.socket().getRemoteSocketAddress() +
                                " because the connection limit of " + MAX_CONNECTIONS + " has been reached");
                        try {
                            
                            final ByteBuffer b = ByteBuffer.allocate(1);
                            b.put(MAX_CONNECTIONS_LIMIT_ERROR);
                            b.flip();
                            socket.configureBlocking(true);
                            for (int ii = 0; ii < 4 && b.hasRemaining(); ii++) {
                                socket.write(b);
                            }
                            socket.close();
                        } catch (IOException e) {}
                        continue;
                    }

                    
                    m_numConnections.incrementAndGet();

                    final AuthRunnable authRunnable = new AuthRunnable(socket);
                    while (true) {
                        try {
                            m_executor.execute(authRunnable);
                            break;
                        } catch (RejectedExecutionException e) {
                            Thread.sleep(1);
                        }
                    }
                } while (m_running);
            } catch (Exception e) {
                if (m_running) {
                    hostLog.error("Exception in ClientAcceptor. The acceptor has died", e);
                }
            } finally {
                try {
                    m_serverSocket.close();
                } catch (IOException e) {
                    hostLog.fatal(null, e);
                }
                
                synchronized (this) {
                    Thread.interrupted();
                    m_executor.shutdownNow();
                    try {
                        m_executor.awaitTermination(5, TimeUnit.MINUTES);
                    } catch (InterruptedException e) {
                        String msg = "Client Listener Interrupted while shutting down "
                                + (m_isAdmin ? " Admin " : " ") + "port: " + m_port;
                        VoltDB.crashLocalVoltDB(msg, false, e);
                    }
                }
            }
        }

        
        private InputHandler
        authenticate(final SocketChannel socket, final AtomicReference<String> timeoutRef) throws IOException
        {
            ByteBuffer responseBuffer = ByteBuffer.allocate(6);
            byte version = (byte)0;
            responseBuffer.putInt(2);
            responseBuffer.put(version);

            
            socket.configureBlocking(true);
            socket.socket().setTcpNoDelay(true);
            final ByteBuffer lengthBuffer = ByteBuffer.allocate(4);

            
            final long start = System.currentTimeMillis();
            ScheduledFuture<?> timeoutFuture =
                    VoltDB.instance().schedulePriorityWork(new Runnable() {
                        @Override
                        public void run() {
                            long delta = System.currentTimeMillis() - start;
                            double seconds = delta / 1000.0;
                            StringBuilder sb = new StringBuilder();
                            sb.append("Timed out authenticating client from ");
                            sb.append(socket.socket().getRemoteSocketAddress().toString());
                            sb.append(String.format(" after %.2f seconds (timeout target is %.2f seconds)", seconds, AUTH_TIMEOUT_MS / 1000.0));
                            timeoutRef.set(sb.toString());
                            try {
                                socket.close();
                            } catch (IOException e) {
                                
                            }
                        }
                    }, AUTH_TIMEOUT_MS, 0, TimeUnit.MILLISECONDS);

            try {
                while (lengthBuffer.hasRemaining()) {
                    int read = socket.read(lengthBuffer);
                    if (read == -1) {
                        socket.close();
                        timeoutFuture.cancel(false);
                        return null;
                    }
                }
            } catch (AsynchronousCloseException e) {}

            
            if (lengthBuffer.hasRemaining()) {
                timeoutFuture.cancel(false);
                authLog.debug("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                              "): wire protocol violation (timeout reading message length).");
                
                responseBuffer.put(WIRE_PROTOCOL_TIMEOUT_ERROR).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }
            lengthBuffer.flip();

            final int messageLength = lengthBuffer.getInt();
            if (messageLength < 0) {
                timeoutFuture.cancel(false);
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                             "): wire protocol violation (message length " + messageLength + " is negative).");
                
                responseBuffer.put(WIRE_PROTOCOL_FORMAT_ERROR).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }
            if (messageLength > ((1024 * 1024) * 2)) {
                timeoutFuture.cancel(false);
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                             "): wire protocol violation (message length " + messageLength + " is too large).");
                
                responseBuffer.put(WIRE_PROTOCOL_FORMAT_ERROR).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
              }

            final ByteBuffer message = ByteBuffer.allocate(messageLength);

            try {
                while (message.hasRemaining()) {
                    int read = socket.read(message);
                    if (read == -1) {
                        socket.close();
                        timeoutFuture.cancel(false);
                        return null;
                    }
                }
            } catch (AsynchronousCloseException e) {}

            
            if (message.hasRemaining()) {
                timeoutFuture.cancel(false);
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                             "): wire protocol violation (timeout reading authentication strings).");
                
                responseBuffer.put(WIRE_PROTOCOL_TIMEOUT_ERROR).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }

            
            if (!timeoutFuture.cancel(false)) {
                return null;
            }

            message.flip();
            int aversion = message.get(); 
            ClientAuthHashScheme hashScheme = ClientAuthHashScheme.HASH_SHA1;
            
            if (aversion > 0) {
                try {
                    hashScheme = ClientAuthHashScheme.get(message.get());
                } catch (IllegalArgumentException ex) {
                    authLog.warn("Failure to authenticate connection Invalid Hash Scheme presented.");
                    
                    responseBuffer.put(WIRE_PROTOCOL_FORMAT_ERROR).flip();
                    socket.write(responseBuffer);
                    socket.close();
                    return null;
                }
            }
            FastDeserializer fds = new FastDeserializer(message);
            final String service = fds.readString();
            final String username = fds.readString();
            final int digestLen = ClientAuthHashScheme.getDigestLength(hashScheme);
            final byte password[] = new byte[digestLen];
            
            if (message.remaining() != digestLen) {
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress()
                        + "): user " + username + " failed authentication.");
                
                responseBuffer.put(AUTHENTICATION_FAILURE).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }
            message.get(password);

            CatalogContext context = m_catalogContext.get();

            AuthProvider ap = null;
            try {
                ap = AuthProvider.fromService(service);
            } catch (IllegalArgumentException unkownProvider) {
                
            }

            if (ap == null) {
                
                responseBuffer.put(EXPORT_DISABLED_REJECTION).flip();
                socket.write(responseBuffer);
                socket.close();
                authLog.warn("Rejected user " + username +
                        " attempting to use disabled or unconfigured service " +
                        service + ".");
                authLog.warn("VoltDB Export services are no longer available through clients.");
                return null;
            }

            
            if (!VoltDB.instance().rejoining()) {
                AuthenticationRequest arq;
                if (ap == AuthProvider.KERBEROS) {
                    arq = context.authSystem.new KerberosAuthenticationRequest(socket);
                } else {
                    arq = context.authSystem.new HashAuthenticationRequest(username, password, hashScheme);
                }
                
                boolean authenticated = arq.authenticate(hashScheme);

                if (!authenticated) {
                    Exception faex = arq.getAuthenticationFailureException();

                    boolean isItIo = false;
                    for (Throwable cause = faex; faex != null && !isItIo; cause = cause.getCause()) {
                        isItIo = cause instanceof IOException;
                    }

                    if (faex != null) {
                        authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                                 "):", faex);
                    } else {
                        authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                                     "): user " + username + " failed authentication.");
                    }
                    
                    if (!isItIo) {
                        responseBuffer.put(AUTHENTICATION_FAILURE).flip();
                        socket.write(responseBuffer);
                    }
                    socket.close();
                    return null;
                }
            } else {
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                        "): user " + username + " because this node is rejoining.");
                
                responseBuffer.put(AUTHENTICATION_FAILURE_DUE_TO_REJOIN).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }

            
            InputHandler handler = new ClientInputHandler(username, m_isAdmin);

            byte buildString[] = VoltDB.instance().getBuildString().getBytes(Charsets.UTF_8);
            responseBuffer = ByteBuffer.allocate(34 + buildString.length);
            responseBuffer.putInt(30 + buildString.length);
            responseBuffer.put((byte)0);

            
            responseBuffer.put((byte)0);
            responseBuffer.putInt(VoltDB.instance().getHostMessenger().getHostId());
            responseBuffer.putLong(handler.connectionId());
            responseBuffer.putLong(VoltDB.instance().getHostMessenger().getInstanceId().getTimestamp());
            responseBuffer.putInt(VoltDB.instance().getHostMessenger().getInstanceId().getCoord());
            responseBuffer.putInt(buildString.length);
            responseBuffer.put(buildString).flip();
            socket.write(responseBuffer);
            return handler;
        }
    }

    
    public class ClientInputHandler extends VoltProtocolHandler implements AdmissionControlGroup.ACGMember {
        public static final int MAX_READ = 8192 * 4;

        private Connection m_connection;
        private final boolean m_isAdmin;

        
        private final String m_username;

        public ClientInputHandler(String username,
                                  boolean isAdmin)
        {
            m_username = username.intern();
            m_isAdmin = isAdmin;
        }

        public boolean isAdmin()
        {
            return m_isAdmin;
        }

        @Override
        public int getMaxRead() {
            if (m_hasDTXNBackPressure) {
                return 0;
            } else {
                return Math.max( MAX_READ, getNextMessageLength());
            }
        }

        @Override
        public void handleMessage(ByteBuffer message, Connection c) {
            try {
                final ClientResponseImpl error = handleRead(message, this, c);
                if (error != null) {
                    ByteBuffer buf = ByteBuffer.allocate(error.getSerializedSize() + 4);
                    buf.putInt(buf.capacity() - 4);
                    error.flattenToBuffer(buf).flip();
                    c.writeStream().enqueue(buf);
                }
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }

        @Override
        public void started(final Connection c) {
            m_connection = c;
            m_cihm.put(c.connectionId(),
                       new ClientInterfaceHandleManager( m_isAdmin, c, null, m_acg.get()));
            m_acg.get().addMember(this);
            if (!m_acg.get().hasBackPressure()) {
                c.enableReadSelection();
            }
        }

        @Override
        public void stopped(Connection c) {
            m_numConnections.decrementAndGet();
            
            ClientInterfaceHandleManager cihm = m_cihm.remove(connectionId());
            cihm.freeOutstandingTxns();
            cihm.m_acg.removeMember(this);
            m_notifier.removeConnection(c);
        }

        
        @Override
        public Runnable offBackPressure() {
            return new Runnable() {
                @Override
                public void run() {
                    if (!m_acg.get().hasBackPressure()) {
                        m_connection.enableReadSelection();
                    }
                }
            };
        }

        @Override
        public Runnable onBackPressure() {
            return new Runnable() {
                @Override
                public void run() {
                    m_connection.disableReadSelection();
                }
            };
        }

        
        @Override
        public QueueMonitor writestreamMonitor() {
            return new QueueMonitor() {
                @Override
                public boolean queue(int bytes) {
                    return m_acg.get().queue(bytes);
                }
            };
        }

        
        @Override
        public void onBackpressure() {
            m_connection.disableReadSelection();
        }

        @Override
        public void offBackpressure() {
            m_connection.enableReadSelection();
        }
    }

    
    public class ClientResponseWork implements DeferredSerialization {
        private final ClientInterfaceHandleManager cihm;
        private final InitiateResponseMessage response;
        private final Procedure catProc;
        private ClientResponseImpl clientResponse;

        private ClientResponseWork(InitiateResponseMessage response,
                                   ClientInterfaceHandleManager cihm,
                                   Procedure catProc)
        {
            this.response = response;
            this.clientResponse = response.getClientResponseData();
            this.cihm = cihm;
            this.catProc = catProc;
        }

        @Override
        public void serialize(ByteBuffer buf) throws IOException
        {
            buf.putInt(buf.capacity() - 4);
            clientResponse.flattenToBuffer(buf);
        }

        @Override
        public void cancel() {
        }

        @Override
        public int getSerializedSize() throws IOException {
            
            
            
            
            ClientInterfaceHandleManager.Iv2InFlight clientData;
            if (clientResponse != null &&
                    clientResponse.getStatusString() != null &&
                    clientResponse.getStatusString().equals(ClientResponseImpl.IGNORED_TRANSACTION)) {
                clientData = cihm.removeHandle(response.getClientInterfaceHandle());
            }
            else {
                clientData = cihm.findHandle(response.getClientInterfaceHandle());
            }
            if (clientData == null) {
                return DeferredSerialization.EMPTY_MESSAGE_LENGTH;
            }

            
            if (restartTransaction(clientData.m_messageSize, clientData.m_creationTimeNanos)) {
                
                
                return DeferredSerialization.EMPTY_MESSAGE_LENGTH;
            }

            final long now = System.nanoTime();
            final long delta = now - clientData.m_creationTimeNanos;

            
            cihm.m_acg.logTransactionCompleted(
                    cihm.connection.connectionId(),
                    cihm.connection.getHostnameOrIP(),
                    clientData.m_procName,
                    delta,
                    clientResponse.getStatus());

            clientResponse.setClientHandle(clientData.m_clientHandle);
            clientResponse.setClusterRoundtrip((int)TimeUnit.NANOSECONDS.toMillis(delta));
            clientResponse.setHash(null); 

            return clientResponse.getSerializedSize() + 4;
        }

        @Override
        public String toString() {
            return clientResponse.getClass().getName();
        }

        
        private boolean restartTransaction(int messageSize, long nowNanos)
        {
            if (response.isMispartitioned()) {
                
                assert response.getInvocation() != null;
                assert response.getCurrentHashinatorConfig() != null;
                assert(catProc != null);

                
                TheHashinator.updateHashinator(
                        TheHashinator.getConfiguredHashinatorClass(),
                        response.getCurrentHashinatorConfig().getFirst(), 
                        response.getCurrentHashinatorConfig().getSecond(), 
                        false); 

                
                
                if (VoltDB.instance().getMode() == OperationMode.INITIALIZING) {
                    return false;
                }

                boolean isReadonly = catProc.getReadonly();

                try {
                    ProcedurePartitionInfo ppi = (ProcedurePartitionInfo)catProc.getAttachment();
                    int partition = getPartitionForProcedure(ppi.index,
                            ppi.type, response.getInvocation());
                    createTransaction(cihm.connection.connectionId(),
                            response.getInvocation(),
                            isReadonly,
                            true, 
                            false, 
                            partition,
                            messageSize,
                            nowNanos);
                    return true;
                } catch (Exception e) {
                    
                    assert(clientResponse == null);
                    clientResponse = getMispartitionedErrorResponse(response.getInvocation(), catProc, e);
                }
            }

            return false;
        }
    }

    
    public boolean createTransaction(
            final long connectionId,
            final StoredProcedureInvocation invocation,
            final boolean isReadOnly,
            final boolean isSinglePartition,
            final boolean isEveryPartition,
            final int partition,
            final int messageSize,
            final long nowNanos)
    {
        return createTransaction(
                connectionId,
                Iv2InitiateTaskMessage.UNUSED_MP_TXNID,
                0, 
                invocation,
                isReadOnly,
                isSinglePartition,
                isEveryPartition,
                partition,
                messageSize,
                nowNanos,
                false);  
    }

    
    public  boolean createTransaction(
            final long connectionId,
            final long txnId,
            final long uniqueId,
            final StoredProcedureInvocation invocation,
            final boolean isReadOnly,
            final boolean isSinglePartition,
            final boolean isEveryPartition,
            final int partition,
            final int messageSize,
            long nowNanos,
            final boolean isForReplay)
    {
        assert(!isSinglePartition || (partition >= 0));
        final ClientInterfaceHandleManager cihm = m_cihm.get(connectionId);

        Long initiatorHSId = null;
        boolean isShortCircuitRead = false;

        
        if (isSinglePartition && !isEveryPartition) {
            if (isReadOnly) {
                initiatorHSId = m_localReplicas.get(partition);
            }
            if (initiatorHSId != null) {
                isShortCircuitRead = true;
            } else {
                initiatorHSId = m_cartographer.getHSIdForSinglePartitionMaster(partition);
            }
        }
        else {
            
            initiatorHSId = m_cartographer.getHSIdForMultiPartitionInitiator();
            
            
            if (isReadOnly) {
                isShortCircuitRead = true;
            }
        }

        if (initiatorHSId == null) {
            hostLog.error("Failed to find master initiator for partition: "
                    + Integer.toString(partition) + ". Transaction not initiated.");
            return false;
        }

        long handle = cihm.getHandle(isSinglePartition, partition, invocation.getClientHandle(),
                messageSize, nowNanos, invocation.getProcName(), initiatorHSId, isReadOnly, isShortCircuitRead);

        Iv2InitiateTaskMessage workRequest =
            new Iv2InitiateTaskMessage(m_siteId,
                    initiatorHSId,
                    Iv2InitiateTaskMessage.UNUSED_TRUNC_HANDLE,
                    txnId,
                    uniqueId,
                    isReadOnly,
                    isSinglePartition,
                    invocation,
                    handle,
                    connectionId,
                    isForReplay);

        Iv2Trace.logCreateTransaction(workRequest);
        m_mailbox.send(initiatorHSId, workRequest);
        return true;
    }



    
    public static ClientInterface create(
            HostMessenger messenger,
            CatalogContext context,
            ReplicationRole replicationRole,
            Cartographer cartographer,
            int partitionCount,
            InetAddress clientIntf,
            int clientPort,
            InetAddress adminIntf,
            int adminPort,
            long timestampTestingSalt) throws Exception {

        
        int[] allPartitions = new int[partitionCount];
        int index = 0;
        for (Integer partition : cartographer.getPartitions()) {
            if (partition != MpInitiator.MP_INIT_PID) {
                allPartitions[index++] = partition;
            }
        }

        
        final ClientInterface ci = new ClientInterface(
                clientIntf, clientPort, adminIntf, adminPort, context, messenger, replicationRole, cartographer, allPartitions);

        return ci;
    }

    ClientInterface(InetAddress clientIntf, int clientPort, InetAddress adminIntf, int adminPort,
            CatalogContext context, HostMessenger messenger, ReplicationRole replicationRole,
            Cartographer cartographer, int[] allPartitions) throws Exception {
        m_catalogContext.set(context);
        m_cartographer = cartographer;

        
        m_allPartitions = allPartitions;
        m_acceptor = new ClientAcceptor(clientIntf, clientPort, messenger.getNetwork(), false);
        m_adminAcceptor = null;
        m_adminAcceptor = new ClientAcceptor(adminIntf, adminPort, messenger.getNetwork(), true);
        m_invocationValidator = new InvocationValidator(replicationRole);

        m_mailbox = new LocalMailbox(messenger,  messenger.getHSIdForLocalSite(HostMessenger.CLIENT_INTERFACE_SITE_ID)) {
            LinkedBlockingQueue<VoltMessage> m_d = new LinkedBlockingQueue<VoltMessage>();
            @Override
            public void deliver(final VoltMessage message) {
                if (message instanceof InitiateResponseMessage) {
                    final CatalogContext catalogContext = m_catalogContext.get();
                    
                    InitiateResponseMessage response = (InitiateResponseMessage)message;
                    StoredProcedureInvocation invocation = response.getInvocation();
                    Iv2Trace.logFinishTransaction(response, m_mailbox.getHSId());
                    ClientInterfaceHandleManager cihm = m_cihm.get(response.getClientConnectionId());
                    Procedure procedure = null;

                    if (invocation != null) {
                        procedure = catalogContext.procedures.get(invocation.getProcName());
                        if (procedure == null) {
                            procedure = SystemProcedureCatalog.listing.get(invocation.getProcName())
                                                              .asCatalogProcedure();
                        }
                    }

                    
                    if (cihm != null) {
                        
                        
                        cihm.connection.writeStream().fastEnqueue(new ClientResponseWork(response, cihm, procedure));
                    }
                } else if (message instanceof BinaryPayloadMessage) {
                    handlePartitionFailOver((BinaryPayloadMessage)message);
                } else {
                    m_d.offer(message);
                }
            }

            @Override
            public VoltMessage recv() {
                return m_d.poll();
            }
        };
        messenger.createMailbox(m_mailbox.getHSId(), m_mailbox);
        m_plannerSiteId = messenger.getHSIdForLocalSite(HostMessenger.ASYNC_COMPILER_SITE_ID);
        m_zk = messenger.getZK();
        m_siteId = m_mailbox.getHSId();
        m_isConfiguredForHSQL = (VoltDB.instance().getBackendTargetType() == BackendTarget.HSQLDB_BACKEND);
    }

    private void handlePartitionFailOver(BinaryPayloadMessage message) {
        try {
            JSONObject jsObj = new JSONObject(new String(message.m_payload, "UTF-8"));
            final int partitionId = jsObj.getInt(Cartographer.JSON_PARTITION_ID);
            final long initiatorHSId = jsObj.getLong(Cartographer.JSON_INITIATOR_HSID);
            for (final ClientInterfaceHandleManager cihm : m_cihm.values()) {
                try {
                    cihm.connection.queueTask(new Runnable() {
                        @Override
                        public void run() {
                            failOverConnection(partitionId, initiatorHSId, cihm.connection);
                        }
                    });
                } catch (UnsupportedOperationException ignore) {
                    
                    failOverConnection(partitionId, initiatorHSId, cihm.connection);
                }
            }
        } catch (Exception e) {
            hostLog.warn("Error handling partition fail over at ClientInterface, continuing anyways", e);
        }
    }

    
    private void failOverConnection(Integer partitionId, Long initiatorHSId, Connection c) {
        ClientInterfaceHandleManager cihm = m_cihm.get(c.connectionId());
        if (cihm == null) {
            return;
        }

        List<Iv2InFlight> transactions =
                cihm.removeHandlesForPartitionAndInitiator( partitionId, initiatorHSId);

        for (Iv2InFlight inFlight : transactions) {
            ClientResponseImpl response =
                    new ClientResponseImpl(
                            ClientResponseImpl.RESPONSE_UNKNOWN,
                            ClientResponse.UNINITIALIZED_APP_STATUS_CODE,
                            null,
                            new VoltTable[0],
                            "Transaction dropped due to change in mastership. " +
                            "It is possible the transaction was committed");
            response.setClientHandle( inFlight.m_clientHandle );
            ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
            buf.putInt(buf.capacity() - 4);
            response.flattenToBuffer(buf);
            buf.flip();
            c.writeStream().enqueue(buf);
        }

        if (cihm.repairCallback != null) {
            cihm.repairCallback.repairCompleted(partitionId, initiatorHSId);
        }
    }

    
    public void setReplicationRole(ReplicationRole role) {
        m_invocationValidator.setReplicationRole(role);
    }

    
    public void initializeSnapshotDaemon(HostMessenger messenger, GlobalServiceElector gse) {
        m_snapshotDaemon.init(this, messenger, new Runnable() {
            @Override
            public void run() {
                bindAdapter(m_snapshotDaemonAdapter, null);
            }
        },
        gse);
    }

    
    public ClientInterfaceHandleManager bindAdapter(final Connection adapter, final ClientInterfaceRepairCallback repairCallback) {
        if (m_cihm.get(adapter.connectionId()) == null) {
            ClientInterfaceHandleManager cihm = ClientInterfaceHandleManager.makeThreadSafeCIHM(true, adapter, repairCallback,
                        AdmissionControlGroup.getDummy());
            m_cihm.put(adapter.connectionId(), cihm);
        }
        return m_cihm.get(adapter.connectionId());
    }

    
    
    public void mayActivateSnapshotDaemon() {
        SnapshotSchedule schedule = m_catalogContext.get().database.getSnapshotschedule().get("default");
        if (schedule != null)
        {
            final ListenableFuture<Void> future = m_snapshotDaemon.mayGoActiveOrInactive(schedule);
            future.addListener(new Runnable() {
                @Override
                public void run() {
                    try {
                        future.get();
                    } catch (InterruptedException e) {
                        VoltDB.crashLocalVoltDB("Failed to make SnapshotDaemon active", false, e);
                    } catch (ExecutionException e) {
                        VoltDB.crashLocalVoltDB("Failed to make SnapshotDaemon active", false, e);
                    }
                }
            }, CoreUtils.SAMETHREADEXECUTOR);
        }
    }

    
    public void notifyOfCatalogUpdate() {
        m_catalogContext.set(VoltDB.instance().getCatalogContext());
        
        if (VoltDB.instance().getMode() != OperationMode.INITIALIZING) {
            mayActivateSnapshotDaemon();
        }
    }

    private ClientResponseImpl errorResponse(Connection c, long handle, byte status, String reason, Exception e, boolean log) {
        String realReason = reason;
        if (e != null) {
            StringWriter sw = new StringWriter();
            PrintWriter pw = new PrintWriter(sw);
            e.printStackTrace(pw);
            realReason = sw.toString();
        }
        if (log) {
            hostLog.warn(realReason);
        }
        return new ClientResponseImpl(status,
                new VoltTable[0], realReason, handle);
    }

    
    private void processExplainPlannedStmtBatch(  AdHocPlannedStmtBatch planBatch ) {
        final Connection c = (Connection)planBatch.clientData;
        Database db = m_catalogContext.get().database;
        int size = planBatch.getPlannedStatementCount();

        VoltTable[] vt = new VoltTable[ size ];
        for (int i = 0; i < size; ++i) {
            vt[i] = new VoltTable(new VoltTable.ColumnInfo("EXECUTION_PLAN", VoltType.STRING));
            String str = planBatch.explainStatement(i, db);
            vt[i].addRow(str);
        }

        ClientResponseImpl response =
                new ClientResponseImpl(
                        ClientResponseImpl.SUCCESS,
                        ClientResponse.UNINITIALIZED_APP_STATUS_CODE,
                        null,
                        vt,
                        null);
        response.setClientHandle( planBatch.clientHandle );
        ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
        buf.putInt(buf.capacity() - 4);
        response.flattenToBuffer(buf);
        buf.flip();
        c.writeStream().enqueue(buf);
    }

    
    private void processExplainDefaultProc(AdHocPlannedStmtBatch planBatch) {
        final Connection c = (Connection)planBatch.clientData;
        Database db = m_catalogContext.get().database;

        
        
        assert(planBatch.getPlannedStatementCount() == 1);
        AdHocPlannedStatement ahps = planBatch.getPlannedStatement(0);
        String sql = new String(ahps.sql, Charsets.UTF_8);
        String explain = planBatch.explainStatement(0, db);

        VoltTable vt = new VoltTable(new VoltTable.ColumnInfo( "SQL_STATEMENT", VoltType.STRING),
                new VoltTable.ColumnInfo( "EXECUTION_PLAN", VoltType.STRING));
        vt.addRow(sql, explain);

        ClientResponseImpl response =
                new ClientResponseImpl(
                        ClientResponseImpl.SUCCESS,
                        ClientResponse.UNINITIALIZED_APP_STATUS_CODE,
                        null,
                        new VoltTable[] { vt },
                        null);
        response.setClientHandle( planBatch.clientHandle );
        ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
        buf.putInt(buf.capacity() - 4);
        response.flattenToBuffer(buf);
        buf.flip();
        c.writeStream().enqueue(buf);
    }

    
    ClientResponseImpl dispatchExplainProcedure(StoredProcedureInvocation task, ClientInputHandler handler, Connection ccxn, AuthUser user) {
        ParameterSet params = task.getParams();
        
        
        List<String> procNames = SQLLexer.splitStatements( (String)params.toArray()[0]);
        int size = procNames.size();
        VoltTable[] vt = new VoltTable[ size ];
        for( int i=0; i<size; i++ ) {
            String procName = procNames.get(i);

            
            Procedure proc = m_catalogContext.get().procedures.get(procName);
            if (proc == null) {
                
                
                proc = m_catalogContext.get().m_defaultProcs.checkForDefaultProcedure(procName);
                if (proc != null) {
                    String sql = m_catalogContext.get().m_defaultProcs.sqlForDefaultProc(proc);
                    dispatchAdHocCommon(task, handler, ccxn, ExplainMode.EXPLAIN_DEFAULT_PROC, sql, new Object[0], null, user);
                    return null;
                }

                ClientResponseImpl errorResponse =
                        new ClientResponseImpl(
                                ClientResponseImpl.UNEXPECTED_FAILURE,
                                new VoltTable[0], "Procedure "+procName+" not in catalog",
                                task.clientHandle);
                return errorResponse;
            }

            vt[i] = new VoltTable(new VoltTable.ColumnInfo( "SQL_STATEMENT", VoltType.STRING),
                                  new VoltTable.ColumnInfo( "EXECUTION_PLAN", VoltType.STRING));

            for( Statement stmt : proc.getStatements() ) {
                vt[i].addRow( stmt.getSqltext(), Encoder.hexDecodeToString( stmt.getExplainplan() ) );
            }
        }

        ClientResponseImpl response =
                new ClientResponseImpl(
                        ClientResponseImpl.SUCCESS,
                        ClientResponse.UNINITIALIZED_APP_STATUS_CODE,
                        null,
                        vt,
                        null);
        response.setClientHandle( task.clientHandle );
        ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
        buf.putInt(buf.capacity() - 4);
        response.flattenToBuffer(buf);
        buf.flip();
        ccxn.writeStream().enqueue(buf);
        return null;
    }

    private final ClientResponseImpl dispatchAdHoc(StoredProcedureInvocation task,
            ClientInputHandler handler, Connection ccxn, boolean isExplain, AuthSystem.AuthUser user) {
        ParameterSet params = task.getParams();
        Object[] paramArray = params.toArray();
        String sql = (String) paramArray[0];
        Object[] userParams = null;
        if (params.size() > 1) {
            userParams = Arrays.copyOfRange(paramArray, 1, paramArray.length);
        }
        ExplainMode explainMode = isExplain ? ExplainMode.EXPLAIN_ADHOC : ExplainMode.NONE;
        dispatchAdHocCommon(task, handler, ccxn, explainMode, sql, userParams, null, user);
        return null;
    }

    private final ClientResponseImpl dispatchAdHocSpForTest(StoredProcedureInvocation task,
            ClientInputHandler handler, Connection ccxn, boolean isExplain, AuthSystem.AuthUser user) {
        ParameterSet params = task.getParams();
        assert(params.size() > 1);
        Object[] paramArray = params.toArray();
        String sql = (String) paramArray[0];
        
        Object[] userPartitionKey = Arrays.copyOfRange(paramArray, 1, 2);
        Object[] userParams = null;
        
        
        if (params.size() > 2) {
            userParams = Arrays.copyOfRange(paramArray, 2, paramArray.length);
        }
        ExplainMode explainMode = isExplain ? ExplainMode.EXPLAIN_ADHOC : ExplainMode.NONE;
        dispatchAdHocCommon(task, handler, ccxn, explainMode, sql, userParams, userPartitionKey, user);
        return null;
    }

    private final void dispatchAdHocCommon(StoredProcedureInvocation task,
            ClientInputHandler handler, Connection ccxn, ExplainMode explainMode,
            String sql, Object[] userParams, Object[] userPartitionKey, AuthSystem.AuthUser user) {
        List<String> sqlStatements = SQLLexer.splitStatements(sql);
        String[] stmtsArray = sqlStatements.toArray(new String[sqlStatements.size()]);

        AdHocPlannerWork ahpw = new AdHocPlannerWork(
                m_siteId,
                task.clientHandle, handler.connectionId(),
                handler.isAdmin(), ccxn,
                sql, stmtsArray, userParams, null, explainMode,
                userPartitionKey == null, userPartitionKey,
                task.procName, task.type, task.originalTxnId, task.originalUniqueId,
                VoltDB.instance().getReplicationRole() == ReplicationRole.REPLICA,
                VoltDB.instance().getCatalogContext().cluster.getUseddlschema(),
                m_adhocCompletionHandler, user);
        LocalObjectMessage work = new LocalObjectMessage( ahpw );

        m_mailbox.send(m_plannerSiteId, work);
    }

    ClientResponseImpl dispatchUpdateApplicationCatalog(StoredProcedureInvocation task,
            ClientInputHandler handler, Connection ccxn, AuthSystem.AuthUser user)
    {
        ParameterSet params = task.getParams();
        
        
        byte[] catalogBytes = null;
        Object catalogObj = params.toArray()[0];
        if (catalogObj != null) {
            if (catalogObj instanceof String) {
                
                String catalogString = (String) catalogObj;
                if (!catalogString.isEmpty()) {
                    catalogBytes = Encoder.hexDecode(catalogString);
                }
            } else if (catalogObj instanceof byte[]) {
                
                byte[] catalogArr = (byte[]) catalogObj;
                if (catalogArr.length != 0) {
                    catalogBytes = catalogArr;
                }
            }
        }
        String deploymentString = (String) params.toArray()[1];
        LocalObjectMessage work = new LocalObjectMessage(
                new CatalogChangeWork(
                    m_siteId,
                    task.clientHandle, handler.connectionId(), ccxn.getHostnameAndIPAndPort(),
                    handler.isAdmin(), ccxn, catalogBytes, deploymentString,
                    task.procName, task.type, task.originalTxnId, task.originalUniqueId,
                    VoltDB.instance().getReplicationRole() == ReplicationRole.REPLICA,
                    VoltDB.instance().getCatalogContext().cluster.getUseddlschema(),
                    m_adhocCompletionHandler, user));

        m_mailbox.send(m_plannerSiteId, work);
        return null;
    }

    
    ClientResponseImpl dispatchLoadSinglepartitionTable(ByteBuffer buf,
                                                        Procedure catProc,
                                                        StoredProcedureInvocation task,
                                                        ClientInputHandler handler,
                                                        Connection ccxn)
    {
        int partition = -1;
        try {
            CatalogMap<Table> tables = m_catalogContext.get().database.getTables();
            int partitionParamType = getLoadSinglePartitionTablePartitionParamType(tables, task);
            byte[] valueToHash = (byte[])task.getParameterAtIndex(0);
            partition = TheHashinator.getPartitionForParameter(partitionParamType, valueToHash);
        }
        catch (Exception e) {
            authLog.warn(e.getMessage());
            return new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                                          new VoltTable[0], e.getMessage(), task.clientHandle);
        }
        assert(partition != -1);
        createTransaction(handler.connectionId(),
                          task,
                          catProc.getReadonly(),
                          catProc.getSinglepartition(),
                          catProc.getEverysite(),
                          partition,
                          buf.capacity(),
                          System.nanoTime());
        return null;
    }

    
    private static int getLoadSinglePartitionTablePartitionParamType(CatalogMap<Table> tables,
                                                                     StoredProcedureInvocation spi)
        throws Exception
    {
        String tableName = (String) spi.getParameterAtIndex(1);

        
        Table catTable = tables.getIgnoreCase(tableName);
        if (catTable == null) {
            throw new Exception(String .format("Unable to find target table \"%s\" for LoadSinglepartitionTable.",
                                               tableName));
        }

        Column pCol = catTable.getPartitioncolumn();
        return pCol.getType();
    }

    
    void sendSentinelsToAllPartitions(long txnId)
    {
        for (int partition : m_allPartitions) {
            final long initiatorHSId = m_cartographer.getHSIdForSinglePartitionMaster(partition);
            
            sendSentinel(txnId, initiatorHSId, -1, -1, true);
        }
    }

    
    void dispatchSendSentinel(long connectionId, long nowNanos, int size,
                              StoredProcedureInvocation invocation)
    {
        ClientInterfaceHandleManager cihm = m_cihm.get(connectionId);
        
        int pid = (Integer) invocation.getParameterAtIndex(0);
        final long initiatorHSId = m_cartographer.getHSIdForSinglePartitionMaster(pid);
        long handle = cihm.getHandle(true, pid, invocation.getClientHandle(), size, nowNanos,
                invocation.getProcName(), initiatorHSId, true, false);

        
        sendSentinel(invocation.getOriginalTxnId(), initiatorHSId, handle, connectionId, false);
    }

    ClientResponseImpl dispatchStatistics(OpsSelector selector, StoredProcedureInvocation task, Connection ccxn)
    {
        try {
            OpsAgent agent = VoltDB.instance().getOpsAgent(selector);
            if (agent != null) {
                agent.performOpsAction(ccxn, task.clientHandle, selector, task.getParams());
            }
            else {
                return errorResponse(ccxn, task.clientHandle, ClientResponse.GRACEFUL_FAILURE,
                        "Unknown OPS selector", null, true);
            }

            return null;
        } catch (Exception e) {
            return errorResponse( ccxn, task.clientHandle, ClientResponse.UNEXPECTED_FAILURE, null, e, true);
        }
    }

    ClientResponseImpl dispatchPromote(Procedure sysProc,
                                       ByteBuffer buf,
                                       StoredProcedureInvocation task,
                                       ClientInputHandler handler,
                                       Connection ccxn)
    {
        if (VoltDB.instance().getReplicationRole() == ReplicationRole.NONE)
        {
            return new ClientResponseImpl(ClientResponseImpl.GRACEFUL_FAILURE,
                    new VoltTable[0], "@Promote issued on master cluster." +
                    " No action taken.",
                    task.clientHandle);
        }

        
        createTransaction(
                handler.connectionId(),
                task,
                sysProc.getReadonly(),
                sysProc.getSinglepartition(),
                sysProc.getEverysite(),
                0,
                buf.capacity(),
                System.nanoTime());

        return null;
    }

    
    final ClientResponseImpl handleRead(ByteBuffer buf, ClientInputHandler handler, Connection ccxn) throws IOException {
        final long nowNanos = System.nanoTime();
        StoredProcedureInvocation task = new StoredProcedureInvocation();
        try {
            task.initFromBuffer(buf);
        } catch (Exception ex) {
            return new ClientResponseImpl(
                    ClientResponseImpl.UNEXPECTED_FAILURE,
                    new VoltTable[0], ex.getMessage(), ccxn.connectionId());
        }

        
        final CatalogContext catalogContext = m_catalogContext.get();
        final AuthSystem.AuthUser user = catalogContext.authSystem.getUser(handler.m_username);

        Procedure catProc = catalogContext.procedures.get(task.procName);
        if (catProc == null) {
            catProc = catalogContext.m_defaultProcs.checkForDefaultProcedure(task.procName);
        }

        if (catProc == null) {
            String proc = task.procName;
            if (task.procName.equals("@AdHoc") || task.procName.equals("@AdHocSpForTest")) {
                
                
                
                
                proc = "@AdHoc_RW_MP";
            }
            else if (task.procName.equals("@UpdateClasses")) {
                
                
                
                
                proc = "@UpdateApplicationCatalog";
            }
            Config sysProc = SystemProcedureCatalog.listing.get(proc);
            if (sysProc != null) {
                catProc = sysProc.asCatalogProcedure();
            }
        }

        if (user == null) {
            authLog.info("User " + handler.m_username + " has been removed from the system via a catalog update");
            return new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                    new VoltTable[0], "User " + handler.m_username +
                    " has been removed from the system via a catalog update",
                    task.clientHandle);
        }

        if (catProc == null) {
            String errorMessage = "Procedure " + task.procName + " was not found";
            RateLimitedLogger.tryLogForMessage(System.currentTimeMillis(),
                            60, TimeUnit.SECONDS,
                            authLog,
                            Level.WARN, errorMessage + ". This message is rate limited to once every 60 seconds.");
            return new ClientResponseImpl(
                    ClientResponseImpl.UNEXPECTED_FAILURE,
                    new VoltTable[0], errorMessage, task.clientHandle);
        }

        
        if (!allowPauseModeExecution(handler, catProc, task))
        {
            return new ClientResponseImpl(ClientResponseImpl.SERVER_UNAVAILABLE,
                    new VoltTable[0], "Server is paused and is available in read-only mode - please try again later.",
                    task.clientHandle);
        }

        final ProcedurePartitionInfo ppi = (ProcedurePartitionInfo)catProc.getAttachment();

        ClientResponseImpl error = null;
        
        if ((error = m_permissionValidator.shouldAccept(task.procName, user, task, catProc)) != null) {
            return error;
        }

        
        if ((error = m_invocationValidator.shouldAccept(task.procName, user, task, catProc)) != null) {
            return error;
        }

        if (catProc.getSystemproc()) {
            

            
            
            if (task.procName.equals("@Ping")) {
                return new ClientResponseImpl(ClientResponseImpl.SUCCESS, new VoltTable[0], "", task.clientHandle);
            }
            else if (task.procName.equals("@GetPartitionKeys")) {
                return dispatchGetPartitionKeys(task);
            }
            else if (task.procName.equals("@Subscribe")) {
                return dispatchSubscribe( handler, task);
            }
            else if (task.procName.equals("@Statistics")) {
                return dispatchStatistics(OpsSelector.STATISTICS, task, ccxn);
            }
            else if (task.procName.equals("@SystemCatalog")) {
                return dispatchStatistics(OpsSelector.SYSTEMCATALOG, task, ccxn);
            }
            else if (task.procName.equals("@SystemInformation")) {
                return dispatchStatistics(OpsSelector.SYSTEMINFORMATION, task, ccxn);
            }
            else if (task.procName.equals("@GC")) {
                return dispatchSystemGC(handler, task);
            }
            else if (task.procName.equals("@StopNode")) {
                return dispatchStopNode(task);
            }

            else if (task.procName.equals("@Explain")) {
                return dispatchAdHoc(task, handler, ccxn, true, user);
            }
            else if (task.procName.equals("@ExplainProc")) {
                return dispatchExplainProcedure(task, handler, ccxn, user);
            }
            else if (task.procName.equals("@SendSentinel")) {
                dispatchSendSentinel(handler.connectionId(), nowNanos, buf.capacity(), task);
                return null;
            }

            else if (task.procName.equals("@AdHoc")) {
                return dispatchAdHoc(task, handler, ccxn, false, user);
            }
            else if (task.procName.equals("@AdHocSpForTest")) {
                return dispatchAdHocSpForTest(task, handler, ccxn, false, user);
            }
            else if (task.procName.equals("@LoadMultipartitionTable")) {
                
                if (task.getType() == ProcedureInvocationType.REPLICATED) {
                    sendSentinelsToAllPartitions(task.getOriginalTxnId());
                }
            }
            else if (task.procName.equals("@LoadSinglepartitionTable")) {
                
                return dispatchLoadSinglepartitionTable(buf, catProc, task, handler, ccxn);
            }

            

            if (!MiscUtils.isPro()) {
                SystemProcedureCatalog.Config sysProcConfig = SystemProcedureCatalog.listing.get(task.procName);
                if ((sysProcConfig != null) && (sysProcConfig.commercial)) {
                    return new ClientResponseImpl(ClientResponseImpl.GRACEFUL_FAILURE,
                            new VoltTable[0],
                            task.procName + " is available in the Enterprise Edition of VoltDB only.",
                            task.clientHandle);
                }
            }

            

            if (task.procName.equals("@UpdateApplicationCatalog")) {
                return dispatchUpdateApplicationCatalog(task, handler, ccxn, user);
            }
            else if (task.procName.equals("@UpdateClasses")) {
                return dispatchUpdateApplicationCatalog(task, handler, ccxn, user);
            }
            else if (task.procName.equals("@SnapshotSave")) {
                m_snapshotDaemon.requestUserSnapshot(task, ccxn);
                return null;
            }
            else if (task.procName.equals("@Promote")) {
                return dispatchPromote(catProc, buf, task, handler, ccxn);
            }
            else if (task.procName.equals("@SnapshotStatus")) {
                
                
                Object[] params = new Object[1];
                params[0] = "SNAPSHOTSTATUS";
                task.setParams(params);
                return dispatchStatistics(OpsSelector.STATISTICS, task, ccxn);
            }
            else if (task.procName.equals("@SnapshotScan")) {
                return dispatchStatistics(OpsSelector.SNAPSHOTSCAN, task, ccxn);
            }
            else if (task.procName.equals("@SnapshotDelete")) {
                return dispatchStatistics(OpsSelector.SNAPSHOTDELETE, task, ccxn);
            }
            else if (task.procName.equals("@SnapshotRestore")) {
                ClientResponseImpl retval = SnapshotUtil.transformRestoreParamsToJSON(task);
                if (retval != null) {
                    return retval;
                }
            }

            
            

            
            
            if (task.procName.equals("@Pause") || task.procName.equals("@Resume")) {
                if (!handler.isAdmin()) {
                    return new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                            new VoltTable[0],
                            "" + task.procName + " is not available to this client",
                            task.clientHandle);
                }
            }
        }

        int partition = -1;
        if (catProc.getSinglepartition()) {
            
            try {
                partition =
                        getPartitionForProcedure(
                                ppi.index,
                                ppi.type,
                                task);
            } catch (Exception e) {
                
                return getMispartitionedErrorResponse(task, catProc, e);
            }
        }
        boolean success =
                createTransaction(handler.connectionId(),
                        task,
                        catProc.getReadonly(),
                        catProc.getSinglepartition(),
                        catProc.getEverysite(),
                        partition,
                        buf.capacity(),
                        nowNanos);
        if (!success) {
            
            
            
            
            return new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                    new VoltTable[0],
                    ClientResponseImpl.IGNORED_TRANSACTION,
                    task.clientHandle);
        }
        return null;
    }

    private boolean allowPauseModeExecution(ClientInputHandler handler, Procedure procedure, StoredProcedureInvocation invocation) {
        if (VoltDB.instance().getMode() != OperationMode.PAUSED || handler.isAdmin()) {
            return true;
        }

        
        if (procedure.getSystemproc() &&
                (invocation.procName.equals("@AdHoc") || invocation.procName.equals("@AdHocSpForTest"))) {
            
            return true;
        } else {
            return procedure.getReadonly();
        }
    }

    
    
    
    private final ExecutorService m_systemGCThread =
            CoreUtils.getCachedSingleThreadExecutor("System.gc() invocation thread", 1000);

    
    private ClientResponseImpl dispatchSystemGC(final ClientInputHandler handler,
                                                final StoredProcedureInvocation task) {
        m_systemGCThread.execute(new Runnable() {
            @Override
            public void run() {
                final long start = System.nanoTime();
                System.gc();
                final long duration = System.nanoTime() - start;
                VoltTable vt = new VoltTable(
                        new ColumnInfo[] { new ColumnInfo("SYSTEM_GC_DURATION_NANOS", VoltType.BIGINT) });
                vt.addRow(duration);
                final ClientResponseImpl response = new ClientResponseImpl(
                        ClientResponseImpl.SUCCESS,
                        new VoltTable[] { vt },
                        null,
                        task.clientHandle);
                ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
                buf.putInt(buf.capacity() - 4);
                response.flattenToBuffer(buf).flip();

                ClientInterfaceHandleManager cihm = m_cihm.get(handler.connectionId());
                if (cihm == null) {
                    return;
                }
                cihm.connection.writeStream().enqueue(buf);
            }
        });
        return null;
    }

    private ClientResponseImpl dispatchSubscribe(ClientInputHandler c, StoredProcedureInvocation task) {
        final ParameterSet ps = task.getParams();
        final Object params[] = ps.toArray();
        String err = null;
        final ClientInterfaceHandleManager cihm = m_cihm.get(c.connectionId());
        
        if (cihm == null) {
            return null;
        }
        for (int ii = 0; ii < params.length; ii++) {
            final Object param = params[ii];
            if (param == null) {
                err = "Parameter index " + ii + " was null"; break;
            }
            if (!(param instanceof String)) {
                err = "Parameter index " + ii + " was not a String"; break;
            }

            if (param.equals("TOPOLOGY")) {
                cihm.setWantsTopologyUpdates(true);
            } else {
                err = "Parameter \"" + param + "\" is not recognized/supported"; break;
            }
        }
        return new ClientResponseImpl(
                       err == null ? ClientResponse.SUCCESS : ClientResponse.GRACEFUL_FAILURE,
                       new VoltTable[] { },
                       err,
                       task.clientHandle);
    }

    private ClientResponseImpl dispatchGetPartitionKeys(StoredProcedureInvocation task) {
        Object params[] = task.getParams().toArray();
        String typeString = "the type of partition key to return and can be one of " +
                            "INTEGER, STRING or VARCHAR (equivalent), or VARBINARY";
        if (params.length != 1 || params[0] == null) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "GetPartitionKeys must have one string parameter specifying " + typeString,
                    task.clientHandle);
        }
        if (!(params[0] instanceof String)) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "GetPartitionKeys must have one string parameter specifying " + typeString +
                    " provided type was " + params[0].getClass().getName(),
                    task.clientHandle);
        }
        VoltType voltType = null;
        String typeStr = ((String)params[0]).trim().toUpperCase();
        if (typeStr.equals("INTEGER")) {
            voltType = VoltType.INTEGER;
        } else if (typeStr.equals("STRING") || typeStr.equals("VARCHAR")) {
            voltType = VoltType.STRING;
        } else if (typeStr.equals("VARBINARY")) {
            voltType = VoltType.VARBINARY;
        } else {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "Type " + typeStr + " is not a supported type of partition key, " + typeString,
                    task.clientHandle);
        }
        VoltTable partitionKeys = TheHashinator.getPartitionKeys(voltType);
        if (partitionKeys == null) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "Type " + typeStr + " is not a supported type of partition key, " + typeString,
                    task.clientHandle);
        }
        return new ClientResponseImpl(ClientResponse.SUCCESS, new VoltTable[] { partitionKeys }, null, task.clientHandle);
    }

    private ClientResponseImpl dispatchStopNode(StoredProcedureInvocation task) {
        Object params[] = task.getParams().toArray();
        if (params.length != 1 || params[0] == null) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "@StopNode must provide hostId",
                    task.clientHandle);
        }
        if (!(params[0] instanceof Integer)) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "@StopNode must have one Integer parameter specified. Provided type was " + params[0].getClass().getName(),
                    task.clientHandle);
        }
        int ihid = (Integer) params[0];
        List<Integer> liveHids = VoltDB.instance().getHostMessenger().getLiveHostIds();
        if (!liveHids.contains(ihid)) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "Invalid Host Id or Host Id not member of cluster: " + ihid,
                    task.clientHandle);
        }
        if (!m_cartographer.isClusterSafeIfNodeDies(liveHids, ihid)) {
            hostLog.info("Its unsafe to shutdown node with hostId: " + ihid
                    + " Cannot stop the requested node. Stopping individual nodes is only allowed on a K-safe cluster."
                    + " Use shutdown to stop the cluster.");
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "Cannot stop the requested node. Stopping individual nodes is only allowed on a K-safe cluster."
                            + " Use shutdown to stop the cluster.", task.clientHandle);
        }

        int hid = VoltDB.instance().getHostMessenger().getHostId();
        if (hid == ihid) {
            
            VoltDB.instance().halt();
        } else {
            
            VoltDB.instance().getHostMessenger().sendPoisonPill("@StopNode", ihid, ForeignHost.CRASH_ME);
        }
        return new ClientResponseImpl(ClientResponse.SUCCESS, new VoltTable[0], "SUCCESS", task.clientHandle);
    }

    void createAdHocTransaction(final AdHocPlannedStmtBatch plannedStmtBatch, Connection c)
            throws VoltTypeException
    {
        ByteBuffer buf = null;
        try {
            buf = plannedStmtBatch.flattenPlanArrayToBuffer();
        }
        catch (IOException e) {
            VoltDB.crashLocalVoltDB(e.getMessage(), true, e);
        }
        assert(buf.hasArray());

        
        StoredProcedureInvocation task = new StoredProcedureInvocation();
        
        task.type = plannedStmtBatch.work.invocationType;
        task.originalTxnId = plannedStmtBatch.work.originalTxnId;
        task.originalUniqueId = plannedStmtBatch.work.originalUniqueId;
        
        
        boolean isSinglePartition = plannedStmtBatch.isSinglePartitionCompatible() || m_isConfiguredForHSQL;
        int partition = -1;

        if (isSinglePartition) {
            if (plannedStmtBatch.isReadOnly()) {
                task.procName = "@AdHoc_RO_SP";
            }
            else {
                task.procName = "@AdHoc_RW_SP";
            }
            int type = VoltType.NULL.getValue();
            
            
            
            
            Object partitionParam = plannedStmtBatch.partitionParam();
            byte[] param = null;
            if (partitionParam != null) {
                type = VoltType.typeFromClass(partitionParam.getClass()).getValue();
                param = TheHashinator.valueToBytes(partitionParam);
            }
            partition = TheHashinator.getPartitionForParameter(type, partitionParam);

            
            
            task.setParams(param, (byte)type, buf.array());
        }
        else {
            if (plannedStmtBatch.isReadOnly()) {
                task.procName = "@AdHoc_RO_MP";
            }
            else {
                task.procName = "@AdHoc_RW_MP";
            }
            task.setParams(buf.array());
        }
        task.clientHandle = plannedStmtBatch.clientHandle;

        ClientResponseImpl error = null;
        if (VoltDB.instance().getMode() == OperationMode.PAUSED &&
                !plannedStmtBatch.isReadOnly() && !plannedStmtBatch.adminConnection) {
            error = new ClientResponseImpl(
                    ClientResponseImpl.SERVER_UNAVAILABLE,
                    new VoltTable[0],
                    "Server is paused and is available in read-only mode - please try again later",
                    plannedStmtBatch.clientHandle);
            ByteBuffer buffer = ByteBuffer.allocate(error.getSerializedSize() + 4);
            buffer.putInt(buffer.capacity() - 4);
            error.flattenToBuffer(buffer).flip();
            c.writeStream().enqueue(buffer);
        }
        else
        if ((error = m_permissionValidator.shouldAccept(task.procName, plannedStmtBatch.work.user, task,
                SystemProcedureCatalog.listing.get(task.procName).asCatalogProcedure())) != null) {
            ByteBuffer buffer = ByteBuffer.allocate(error.getSerializedSize() + 4);
            buffer.putInt(buffer.capacity() - 4);
            error.flattenToBuffer(buffer).flip();
            c.writeStream().enqueue(buffer);
        }
        else
        if ((error = m_invocationValidator.shouldAccept(task.procName, plannedStmtBatch.work.user, task,
                SystemProcedureCatalog.listing.get(task.procName).asCatalogProcedure())) != null) {
            ByteBuffer buffer = ByteBuffer.allocate(error.getSerializedSize() + 4);
            buffer.putInt(buffer.capacity() - 4);
            error.flattenToBuffer(buffer).flip();
            c.writeStream().enqueue(buffer);
        }
        else {
            
            try {
                task = MiscUtils.roundTripForCL(task);
            } catch (Exception e) {
                VoltDB.crashLocalVoltDB(e.getMessage(), true, e);
            }

            
            createTransaction(plannedStmtBatch.connectionId, task,
                    plannedStmtBatch.isReadOnly(), isSinglePartition, false,
                    partition,
                    task.getSerializedSize(), System.nanoTime());
        }
    }

    
    public ListenableFutureTask<?> processFinishedCompilerWork(final AsyncCompilerResult result) {
        
        final Connection c = (Connection)result.clientData;
        final ListenableFutureTask<?> ft = ListenableFutureTask.create(new Runnable() {
            @Override
            public void run() {
                if (result.errorMsg == null) {
                    if (result instanceof AdHocPlannedStmtBatch) {
                        final AdHocPlannedStmtBatch plannedStmtBatch = (AdHocPlannedStmtBatch) result;
                        ExplainMode explainMode = plannedStmtBatch.getExplainMode();

                        
                        if ((plannedStmtBatch.getPlannedStatementCount() > 0) &&
                                (!plannedStmtBatch.getPlannedStatement(0).core.wasPlannedAgainstHash(m_catalogContext.get().getCatalogHash())))
                        {

                            
                            LocalObjectMessage work = new LocalObjectMessage(
                                    AdHocPlannerWork.rework(plannedStmtBatch.work, m_adhocCompletionHandler));

                            m_mailbox.send(m_plannerSiteId, work);
                        }
                        else if (explainMode == ExplainMode.EXPLAIN_ADHOC) {
                            processExplainPlannedStmtBatch(plannedStmtBatch);
                        }
                        else if (explainMode == ExplainMode.EXPLAIN_DEFAULT_PROC) {
                            processExplainDefaultProc(plannedStmtBatch);
                        }
                        else {
                            try {
                                createAdHocTransaction(plannedStmtBatch, c);
                            }
                            catch (VoltTypeException vte) {
                                String msg = "Unable to execute adhoc sql statement(s): " +
                                        vte.getMessage();
                                ClientResponseImpl errorResponse =
                                        new ClientResponseImpl(
                                                ClientResponseImpl.GRACEFUL_FAILURE,
                                                new VoltTable[0], msg,
                                                result.clientHandle);
                                writeResponseToConnection(errorResponse);
                            }
                        }
                    }
                    else if (result instanceof CatalogChangeResult) {
                        final CatalogChangeResult changeResult = (CatalogChangeResult) result;

                        
                        if (changeResult.encodedDiffCommands.trim().length() == 0) {
                            ClientResponseImpl shortcutResponse =
                                    new ClientResponseImpl(
                                            ClientResponseImpl.SUCCESS,
                                            new VoltTable[0], "Catalog update with no changes was skipped.",
                                            result.clientHandle);
                            writeResponseToConnection(shortcutResponse);
                        }
                        else {
                            
                            StoredProcedureInvocation task = new StoredProcedureInvocation();
                            task.procName = "@UpdateApplicationCatalog";
                            task.setParams(changeResult.encodedDiffCommands,
                                           changeResult.catalogHash,
                                           changeResult.catalogBytes,
                                           changeResult.expectedCatalogVersion,
                                           changeResult.deploymentString,
                                           changeResult.tablesThatMustBeEmpty,
                                           changeResult.reasonsForEmptyTables,
                                           changeResult.requiresSnapshotIsolation ? 1 : 0,
                                           changeResult.worksWithElastic ? 1 : 0,
                                           changeResult.deploymentHash);
                            task.clientHandle = changeResult.clientHandle;
                            
                            task.type = changeResult.invocationType;
                            task.originalTxnId = changeResult.originalTxnId;
                            task.originalUniqueId = changeResult.originalUniqueId;

                            ClientResponseImpl error = null;
                            if ((error = m_permissionValidator.shouldAccept(task.procName, result.user, task,
                                    SystemProcedureCatalog.listing.get(task.procName).asCatalogProcedure())) != null) {
                                writeResponseToConnection(error);
                            }
                            else {
                                
                                try {
                                    task = MiscUtils.roundTripForCL(task);
                                } catch (Exception e) {
                                    hostLog.fatal(e);
                                    VoltDB.crashLocalVoltDB(e.getMessage(), true, e);
                                }

                                
                                
                                createTransaction(changeResult.connectionId,
                                        task, false, false, false, 0, task.getSerializedSize(),
                                        System.nanoTime());
                            }
                        }
                    }
                    else {
                        throw new RuntimeException(
                                "Should not be able to get here (ClientInterface.checkForFinishedCompilerWork())");
                    }
                }
                else {
                    ClientResponseImpl errorResponse =
                        new ClientResponseImpl(
                                ClientResponseImpl.GRACEFUL_FAILURE,
                                new VoltTable[0], result.errorMsg,
                                result.clientHandle);
                    writeResponseToConnection(errorResponse);
                }
            }

            private final void writeResponseToConnection(ClientResponseImpl response) {
                ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
                buf.putInt(buf.capacity() - 4);
                response.flattenToBuffer(buf);
                buf.flip();
                c.writeStream().enqueue(buf);
            }
        }, null);
        if (c != null) {
            c.queueTask(ft);
        }

        
        ft.addListener(new Runnable() {
            @Override
            public void run() {
                try {
                     ft.get();
                } catch (Exception e) {
                    String realReason = result.errorMsg;
                    
                    
                    
                    
                    
                    if (realReason == null) {
                        StringWriter sw = new StringWriter();
                        PrintWriter pw = new PrintWriter(sw);
                        e.printStackTrace(pw);
                        Throwable cause = e.getCause();
                        if (cause != null) {
                            cause.printStackTrace(pw);
                        }
                        pw.flush();
                        realReason = sw.toString();
                    }
                    ClientResponseImpl errorResponse =
                            new ClientResponseImpl(
                                    ClientResponseImpl.UNEXPECTED_FAILURE,
                                    new VoltTable[0], realReason,
                                    result.clientHandle);
                    ByteBuffer buf = ByteBuffer.allocate(errorResponse.getSerializedSize() + 4);
                    buf.putInt(buf.capacity() - 4);
                    errorResponse.flattenToBuffer(buf);
                    buf.flip();
                    c.writeStream().enqueue(buf);
                }
            }
        }, CoreUtils.SAMETHREADEXECUTOR);

        
        return ft;
    }

    private ScheduledFuture<?> m_deadConnectionFuture;
    private ScheduledFuture<?> m_topologyCheckFuture;
    public void schedulePeriodicWorks() {
        m_deadConnectionFuture = VoltDB.instance().scheduleWork(new Runnable() {
            @Override
            public void run() {
                try {
                    
                    checkForDeadConnections(EstTime.currentTimeMillis());
                } catch (Exception ex) {
                    log.warn("Exception while checking for dead connections", ex);
                }
            }
        }, 200, 200, TimeUnit.MILLISECONDS);
        
        m_topologyCheckFuture = VoltDB.instance().scheduleWork(new Runnable() {
            @Override
            public void run() {
                checkForTopologyChanges();
            }
        }, 0, TOPOLOGY_CHANGE_CHECK_MS, TimeUnit.MILLISECONDS);
    }

    
    private final AtomicReference<DeferredSerialization> m_currentTopologyValues =
            new AtomicReference<>(null);
    private final Supplier<DeferredSerialization> m_currentTopologySupplier = new Supplier<DeferredSerialization>() {
        @Override
        public DeferredSerialization get() {
            return m_currentTopologyValues.get();
        }
    };

    
    private final Predicate<ClientInterfaceHandleManager> m_wantsTopologyUpdatesPredicate =
            new Predicate<ClientInterfaceHandleManager>() {
                @Override
                public boolean apply(ClientInterfaceHandleManager input) {
                    return input.wantsTopologyUpdates();
                }};

    
    private void checkForTopologyChanges() {
        final Pair<SimpleClientResponseAdapter, ListenableFuture<ClientResponseImpl>> p =
                SimpleClientResponseAdapter.getAsListenableFuture();
        final ListenableFuture<ClientResponseImpl> fut = p.getSecond();
        fut.addListener(new Runnable() {
            @Override
            public void run() {
                try {
                    final ClientResponseImpl r = fut.get();
                    if (r.getStatus() != ClientResponse.SUCCESS) {
                        hostLog.warn("Received error response retrieving topology: " + r.getStatusString());
                        return;
                    }

                    final int size = r.getSerializedSize();
                    final ByteBuffer buf = ByteBuffer.allocate(size + 4);
                    buf.putInt(size);
                    r.flattenToBuffer(buf);
                    buf.flip();

                    
                    ByteBuffer oldValue = null;
                    DeferredSerialization ds = m_currentTopologyValues.get();
                    if (ds != null) {
                        oldValue = ByteBuffer.allocate(ds.getSerializedSize());
                        ds.serialize(oldValue);
                        oldValue.flip();
                    }

                    if (buf.equals(oldValue)) {
                        return;
                    }

                    m_currentTopologyValues.set(new DeferredSerialization() {
                        @Override
                        public void serialize(ByteBuffer outbuf) throws IOException {
                            outbuf.put(buf.duplicate());
                        }
                        @Override
                        public void cancel() {}

                        @Override
                        public int getSerializedSize() {
                            return buf.remaining();
                        }
                    });
                    if (oldValue != null) {
                        m_notifier.queueNotification(
                                m_cihm.values(),
                                m_currentTopologySupplier,
                                m_wantsTopologyUpdatesPredicate);
                    }

                } catch (Throwable t) {
                    hostLog.error("Error checking for topology updates", Throwables.getRootCause(t));
                }
            }
        }, CoreUtils.SAMETHREADEXECUTOR);
        final StoredProcedureInvocation spi = new StoredProcedureInvocation();
        spi.setProcName("@Statistics");
        spi.setParams("TOPO", 0);
        spi.setClientHandle(ASYNC_TOPO_HANDLE);
        dispatchStatistics(OpsSelector.STATISTICS, spi, p.getFirst());
    }

    private static final long CLIENT_HANGUP_TIMEOUT = Long.getLong("CLIENT_HANGUP_TIMEOUT", 30000);

    
    private final void checkForDeadConnections(final long now) {
        final ArrayList<Pair<Connection, Integer>> connectionsToRemove = new ArrayList<Pair<Connection, Integer>>();
        for (final ClientInterfaceHandleManager cihm : m_cihm.values()) {
            
            if (VoltPort.class == cihm.connection.getClass()) {
                final int delta = cihm.connection.writeStream().calculatePendingWriteDelta(now);
                if (delta > CLIENT_HANGUP_TIMEOUT) {
                    connectionsToRemove.add(Pair.of(cihm.connection, delta));
                }
            }
        }

        for (final Pair<Connection, Integer> p : connectionsToRemove) {
            Connection c = p.getFirst();
            networkLog.warn("Closing connection to " + c +
                    " because it hasn't read a response that was pending for " +  p.getSecond() + " milliseconds");
            c.unregister();
        }
    }

    
    
    
    
    protected void shutdown() throws InterruptedException {
        if (m_deadConnectionFuture != null) {
            m_deadConnectionFuture.cancel(false);
            try {m_deadConnectionFuture.get();} catch (Throwable t) {}
        }
        if (m_topologyCheckFuture != null) {
            m_topologyCheckFuture.cancel(false);
            try {m_topologyCheckFuture.get();} catch (Throwable t) {}
        }
        if (m_maxConnectionUpdater != null) {
            m_maxConnectionUpdater.cancel(false);
        }
        if (m_acceptor != null) {
            m_acceptor.shutdown();
        }
        if (m_adminAcceptor != null)
        {
            m_adminAcceptor.shutdown();
        }
        if (m_snapshotDaemon != null) {
            m_snapshotDaemon.shutdown();
        }
        if (m_localReplicasBuilder != null) {
            m_localReplicasBuilder.join(10000);
            if (m_localReplicasBuilder.isAlive()) {
                hostLog.error("Local replica map builder took more than ten seconds, probably hung");
            }
            m_localReplicasBuilder.join();
        }
        m_notifier.shutdown();
    }

    private volatile Thread m_localReplicasBuilder = null;
    public void startAcceptingConnections() throws IOException {
        
        m_localReplicasBuilder = new Thread() {
            @Override
            public void run() {
                    
                final int thisHostId = CoreUtils.getHostIdFromHSId(m_mailbox.getHSId());
                ImmutableMap.Builder<Integer, Long> localReplicas = ImmutableMap.builder();
                for (int partition : m_cartographer.getPartitions()) {
                    for (Long replica : m_cartographer.getReplicasForPartition(partition)) {
                        if (CoreUtils.getHostIdFromHSId(replica) == thisHostId) {
                            localReplicas.put(partition, replica);
                        }
                    }
                }
                m_localReplicas = localReplicas.build();
            }
        };
        m_localReplicasBuilder.start();

        
        m_maxConnectionUpdater = VoltDB.instance().scheduleWork(new Runnable() {
            @Override
            public void run() {
                Integer limit = org.voltdb.utils.CLibrary.getOpenFileLimit();
                if (limit != null) {
                    
                    MAX_CONNECTIONS.set(limit - 300);
                }
            }
        }, 0, 10, TimeUnit.MINUTES);
        m_acceptor.start();
        if (m_adminAcceptor != null)
        {
            m_adminAcceptor.start();
        }
        mayActivateSnapshotDaemon();
        m_notifier.start();
    }

    
    static int getPartitionForProcedure(int partitionIndex, VoltType partitionType,
                                        StoredProcedureInvocation task)
            throws Exception
    {
        Object invocationParameter = task.getParameterAtIndex(partitionIndex);
        return TheHashinator.getPartitionForParameter(partitionType, invocationParameter);
    }

    @Override
    public void initiateSnapshotDaemonWork(final String procedureName, long clientData, final Object params[]) {
        final Config sysProc = SystemProcedureCatalog.listing.get(procedureName);
        if (sysProc == null) {
            throw new RuntimeException("SnapshotDaemon attempted to invoke " + procedureName +
            " which is not a known procedure");
        }
        Procedure catProc = sysProc.asCatalogProcedure();
        StoredProcedureInvocation spi = new StoredProcedureInvocation();
        spi.procName = procedureName;
        spi.params = new FutureTask<ParameterSet>(new Callable<ParameterSet>() {
            @Override
            public ParameterSet call() {
                ParameterSet paramSet = ParameterSet.fromArrayWithCopy(params);
                return paramSet;
            }
        });
        spi.clientHandle = clientData;
        
        if (procedureName.equals("@SnapshotScan")) {
            dispatchStatistics(OpsSelector.SNAPSHOTSCAN, spi, m_snapshotDaemonAdapter);
            return;
        }
        else if (procedureName.equals("@SnapshotDelete")) {
            dispatchStatistics(OpsSelector.SNAPSHOTDELETE, spi, m_snapshotDaemonAdapter);
            return;
        }
        
        createTransaction(m_snapshotDaemonAdapter.connectionId(),
                spi, catProc.getReadonly(),
                catProc.getSinglepartition(), catProc.getEverysite(),
                0,
                0, System.nanoTime());
    }

    
    private class SnapshotDaemonAdapter implements Connection, WriteStream {

        @Override
        public void disableReadSelection() {
            throw new UnsupportedOperationException();
        }

        @Override
        public void enableReadSelection() {
            throw new UnsupportedOperationException();
        }

        @Override
        public NIOReadStream readStream() {
            throw new UnsupportedOperationException();
        }

        @Override
        public WriteStream writeStream() {
            return this;
        }

        @Override
        public int calculatePendingWriteDelta(long now) {
            throw new UnsupportedOperationException();
        }

        @Override
        public boolean hadBackPressure() {
            throw new UnsupportedOperationException();
        }

        @Override
        public boolean isEmpty() {
            throw new UnsupportedOperationException();
        }

        @Override
        public String getHostnameAndIPAndPort() {
            return "SnapshotDaemon";
        }

        @Override
        public String getHostnameOrIP() {
            return "SnapshotDaemon";
        }

        @Override
        public int getRemotePort() {
            return -1;
        }

        @Override
        public InetSocketAddress getRemoteSocketAddress() {
            return null;
        }

        @Override
        public Future<?> unregister() {
            return null;
        }

        @Override
        public long connectionId()
        {
            return Long.MIN_VALUE;
        }

        @Override
        public int getOutstandingMessageCount()
        {
            throw new UnsupportedOperationException();
        }

        @Override
        public void fastEnqueue(final org.voltcore.utils.DeferredSerialization ds) {
            enqueue(ds);
        }

        @Override
        public void enqueue(final org.voltcore.utils.DeferredSerialization ds)
        {

            m_snapshotDaemon.processClientResponse(new Callable<ClientResponseImpl>() {
                @Override
                public ClientResponseImpl call() throws Exception {
                    ClientResponseImpl resp = new ClientResponseImpl();
                    ByteBuffer b = ByteBuffer.allocate(ds.getSerializedSize());
                    ds.serialize(b);
                    b.position(4);
                    resp.initFromBuffer(b);
                    return resp;
                }
            });
        }

        @Override
        public void enqueue(final ByteBuffer b)
        {
            m_snapshotDaemon.processClientResponse(new Callable<ClientResponseImpl>() {
                @Override
                public ClientResponseImpl call() throws Exception {
                    ClientResponseImpl resp = new ClientResponseImpl();
                    b.position(4);
                    resp.initFromBuffer(b);
                    return resp;
                }
            });
        }

        @Override
        public void enqueue(ByteBuffer[] b)
        {
            if (b.length == 1)
            {
                
                
                enqueue(b[0]);
            }
            else
            {
                log.error("Something is using buffer chains with enqueue");
            }
        }

        @Override
        public void queueTask(Runnable r) {
            
            r.run();
        }
    }

    public Map<Long, Pair<String, long[]>> getLiveClientStats()
    {
        final Map<Long, Pair<String, long[]>> client_stats =
            new HashMap<Long, Pair<String, long[]>>();

        
        
        for (Map.Entry<Long, ClientInterfaceHandleManager> e : m_cihm.entrySet()) {
            
            
            if (e.getKey() > 0) {
                long adminMode = e.getValue().isAdmin ? 1 : 0;
                long readWait = e.getValue().connection.readStream().dataAvailable();
                long writeWait = e.getValue().connection.writeStream().getOutstandingMessageCount();
                long outstandingTxns = e.getValue().getOutstandingTxns();
                client_stats.put(
                        e.getKey(), new Pair<String, long[]>(
                            e.getValue().connection.getHostnameOrIP(),
                            new long[] {adminMode, readWait, writeWait, outstandingTxns}));
            }
        }
        return client_stats;
    }

    public SnapshotDaemon getSnapshotDaemon() {
        return m_snapshotDaemon;
    }

    
    public void sendSentinel(long txnId, int partitionId) {
        final long initiatorHSId = m_cartographer.getHSIdForSinglePartitionMaster(partitionId);
        sendSentinel(txnId, initiatorHSId, -1, -1, true);
    }

    private void sendSentinel(long txnId, long initiatorHSId, long ciHandle,
                              long connectionId, boolean forReplay) {
        
        MultiPartitionParticipantMessage mppm =
                new MultiPartitionParticipantMessage(
                        m_siteId,
                        initiatorHSId,
                        txnId,
                        ciHandle,
                        connectionId,
                        false,  
                        forReplay);  
        m_mailbox.send(initiatorHSId, mppm);
    }

    
    public void sendEOLMessage(int partitionId) {
        final long initiatorHSId = m_cartographer.getHSIdForMaster(partitionId);
        Iv2EndOfLogMessage message = new Iv2EndOfLogMessage(partitionId);
        m_mailbox.send(initiatorHSId, message);
    }

    public List<Iterator<Map.Entry<Long, Map<String, InvocationInfo>>>> getIV2InitiatorStats() {
        ArrayList<Iterator<Map.Entry<Long, Map<String, InvocationInfo>>>> statsIterators =
                new ArrayList<Iterator<Map.Entry<Long, Map<String, InvocationInfo>>>>();
        for(AdmissionControlGroup acg : m_allACGs) {
            statsIterators.add(acg.getInitiationStatsIterator());
        }
        return statsIterators;
    }

    public List<AbstractHistogram> getLatencyStats() {
        List<AbstractHistogram> latencyStats = new ArrayList<AbstractHistogram>();
        for (AdmissionControlGroup acg : m_allACGs) {
            latencyStats.add(acg.getLatencyInfo());
        }
        return latencyStats;
    }

    
    private ClientResponseImpl getMispartitionedErrorResponse(StoredProcedureInvocation task,
            Procedure catProc, Exception ex) {
        Object invocationParameter = null;
        try {
            invocationParameter = task.getParameterAtIndex(catProc.getPartitionparameter());
        } catch (Exception ex2) {
        }
        String exMsg = "Unknown";
        if (ex != null) {
            exMsg = ex.getMessage();
        }
        String errorMessage = "Error sending procedure " + task.procName
                + " to the correct partition. Make sure parameter values are correct."
                + " Parameter value " + invocationParameter
                + ", partition column " + catProc.getPartitioncolumn().getName()
                + " type " + catProc.getPartitioncolumn().getType()
                + " Message: " + exMsg;
        authLog.warn(errorMessage);
        ClientResponseImpl clientResponse = new ClientResponseImpl(ClientResponse.UNEXPECTED_FAILURE,
                new VoltTable[0], errorMessage, task.clientHandle);
        return clientResponse;
    }

}

<code block>


package org.voltdb.compiler;

import org.voltcore.network.Connection;
import org.voltdb.AuthSystem;
import org.voltdb.CatalogContext;
import org.voltdb.ClientInterface.ExplainMode;
import org.voltdb.client.ProcedureInvocationType;


public class AdHocPlannerWork extends AsyncCompilerWork {
    private static final long serialVersionUID = -6567283432846270119L;

    final String sqlBatchText;
    final String[] sqlStatements;
    final Object[] userParamSet;
    final CatalogContext catalogContext;
    final boolean inferPartitioning;
    
    
    
    final Object[] userPartitionKey;
    public final ExplainMode explainMode;

    public AdHocPlannerWork(long replySiteId, long clientHandle, long connectionId,
            boolean adminConnection, Connection clientConnection,
            String sqlBatchText, String[] sqlStatements,
            Object[] userParamSet, CatalogContext context, ExplainMode explainMode,
            boolean inferPartitioning, Object[] userPartitionKey,
            String invocationName, ProcedureInvocationType type,
            long originalTxnId, long originalUniqueId,
            boolean onReplica, boolean useAdhocDDL,
            AsyncCompilerWorkCompletionHandler completionHandler, AuthSystem.AuthUser user)
    {
        super(replySiteId, false, clientHandle, connectionId,
              clientConnection == null ? "" : clientConnection.getHostnameAndIPAndPort(),
              adminConnection, clientConnection, invocationName, type,
              originalTxnId, originalUniqueId, onReplica, useAdhocDDL,
              completionHandler, user);
        this.sqlBatchText = sqlBatchText;
        this.sqlStatements = sqlStatements;
        this.userParamSet = userParamSet;
        this.catalogContext = context;
        this.explainMode = explainMode;
        this.inferPartitioning = inferPartitioning;
        this.userPartitionKey = userPartitionKey;
    }

    
    public static AdHocPlannerWork rework(AdHocPlannerWork orig,
            AsyncCompilerWorkCompletionHandler completionHandler) {
        return new AdHocPlannerWork(orig.replySiteId,
                orig.clientHandle,
                orig.connectionId,
                orig.adminConnection,
                (Connection) orig.clientData,
                orig.sqlBatchText,
                orig.sqlStatements,
                orig.userParamSet,
                null ,
                orig.explainMode,
                orig.inferPartitioning,
                orig.userPartitionKey,
                orig.invocationName,
                orig.invocationType,
                orig.originalTxnId,
                orig.originalUniqueId,
                orig.onReplica,
                orig.useAdhocDDL,
                completionHandler,
                orig.user);
        }

    
    public static AdHocPlannerWork makeStoredProcAdHocPlannerWork(long replySiteId,
            String sql, Object[] userParams, boolean singlePartition, CatalogContext context,
            AsyncCompilerWorkCompletionHandler completionHandler)
    {
        return makeStoredProcAdHocPlannerWork(replySiteId, sql, userParams, singlePartition, context, completionHandler, false);
    }
    public static AdHocPlannerWork makeStoredProcAdHocPlannerWork(long replySiteId,
            String sql, Object[] userParams, boolean singlePartition, CatalogContext context,
            AsyncCompilerWorkCompletionHandler completionHandler,
            boolean isAdmin)
    {
        return new AdHocPlannerWork(replySiteId, 0, 0, isAdmin, null,
            sql, new String[] { sql },
            userParams, context, ExplainMode.NONE,
            
            
            
            
            
            
            
            false, (singlePartition ? new Object[1]  : null),
            "@AdHoc_RW_MP", ProcedureInvocationType.ORIGINAL, 0, 0,
            false, false, 
            completionHandler, new AuthSystem.AuthDisabledUser());
    }

    @Override
    public String toString() {
        String retval = super.toString();
        if (userParamSet == null || (userParamSet.length == 0)) {
            retval += "\n  user params: empty";
        } else {
            int i = 0;
            for (Object param : userParamSet) {
                i++;
                retval += String.format("\n  user param[%d]: %s",
                                        i, (param == null ? "null" : param.toString()));
            }
        }
        if (userPartitionKey == null) {
            retval += "\n  user partitioning: none";
        } else {
            retval += "\n  user partitioning: " +
                      (userPartitionKey[0] == null ? "null" : userPartitionKey[0].toString());
        }
        assert(sqlStatements != null);
        if (sqlStatements.length == 0) {
            retval += "\n  sql: empty";
        } else {
            int i = 0;
            for (String sql : sqlStatements) {
                i++;
                retval += String.format("\n  sql[%d]: %s", i, sql);
            }
        }
        return retval;
    }

    public int getStatementCount()
    {
        return (this.sqlStatements != null ? this.sqlStatements.length : 0);
    }

    public int getParameterCount()
    {
        return (this.userParamSet != null ? this.userParamSet.length : 0);
    }

}

<code block>


package org.voltdb.compiler;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.List;

import org.json_voltpatches.JSONException;
import org.json_voltpatches.JSONObject;
import org.voltcore.network.Connection;
import org.voltdb.ClientInterface.ExplainMode;
import org.voltdb.ParameterConverter;
import org.voltdb.ParameterSet;
import org.voltdb.VoltType;
import org.voltdb.VoltTypeException;
import org.voltdb.catalog.Database;
import org.voltdb.common.Constants;
import org.voltdb.compiler.AsyncCompilerWork.AsyncCompilerWorkCompletionHandler;
import org.voltdb.planner.CorePlan;
import org.voltdb.plannodes.PlanNodeTree;
import org.voltdb.plannodes.SendPlanNode;


public class AdHocPlannedStmtBatch extends AsyncCompilerResult implements Cloneable {
    private static final long serialVersionUID = -8627490621430290801L;

    
    
    public final int partitionParamIndex;
    public final VoltType partitionParamType;
    public final Object partitionParamValue;

    
    public final List<AdHocPlannedStatement> plannedStatements;

    
    public final boolean readOnly;

    
    public final AdHocPlannerWork work;

    
    public AdHocPlannedStmtBatch(
            AdHocPlannerWork work,
            List<AdHocPlannedStatement> stmts,
            int partitionParamIndex,
            VoltType partitionParamType,
            Object partitionParamValue,
            String errors) {
        this.work = work;

        this.clientHandle = work.clientHandle;
        this.connectionId = work.connectionId;
        this.hostname =
            (work.clientData == null) ? "" : ((Connection)work.clientData).getHostnameAndIPAndPort();
        this.adminConnection = work.adminConnection;
        this.clientData = work.clientData;

        this.plannedStatements = stmts;
        boolean allReadOnly = true;
        for (AdHocPlannedStatement plannedStmt : stmts) {
            
            if (!plannedStmt.core.readOnly) {
                allReadOnly = false;
                break;
            }
        }
        this.readOnly = allReadOnly;
        this.partitionParamIndex = partitionParamIndex;
        this.partitionParamType = partitionParamType;
        this.partitionParamValue = partitionParamValue;
        this.errorMsg = errors;
    }

    public static AdHocPlannedStmtBatch mockStatementBatch(long replySiteId, String sql,
            Object[] extractedValues, VoltType[] paramTypes,
            Object[] userParams, int partitionParamIndex, byte[] catalogHash)
    {
        return mockStatementBatch(replySiteId, sql, extractedValues, paramTypes, userParams, partitionParamIndex, catalogHash, true, false);
    }

    public static AdHocPlannedStmtBatch mockStatementBatch(long replySiteId, String sql,
            Object[] extractedValues, VoltType[] paramTypes,
            Object[] userParams, int partitionParamIndex, byte[] catalogHash,
            boolean readOnly, boolean isAdmin)
    {
        
        AsyncCompilerWorkCompletionHandler dummyHandler = new AsyncCompilerWorkCompletionHandler() {

            @Override
            public void onCompletion(AsyncCompilerResult result) {
                System.out.println("Hmm. Never expected to call this dummy handler.");
            }
        };
        
        AdHocPlannerWork work = AdHocPlannerWork.makeStoredProcAdHocPlannerWork(replySiteId,
                                                                                sql,
                                                                                userParams,
                                                                                false, 
                                                                                null, dummyHandler,
                                                                                isAdmin);
        
        CorePlan core = new CorePlan(new byte[0],
                partitionParamIndex == -1 ? new byte[20] : null,
                new byte[20],
                partitionParamIndex == -1 ? new byte[20] : null,
                false,
                readOnly,
                paramTypes,
                catalogHash);
        AdHocPlannedStatement s = new AdHocPlannedStatement(sql.getBytes(Constants.UTF8ENCODING),
                core,
                extractedValues == null ? ParameterSet.emptyParameterSet() :
                                          ParameterSet.fromArrayNoCopy(extractedValues),
                null);
        List<AdHocPlannedStatement> stmts = new ArrayList<AdHocPlannedStatement>();
        stmts.add(s);
        VoltType partitionParamType = null;
        Object partitionParamValue = null;
        if (work.userPartitionKey != null) {
            partitionParamValue = work.userPartitionKey[0];
        }
        else if (partitionParamIndex > -1) {
            partitionParamValue = userParams[partitionParamIndex];
        }
        if (partitionParamValue != null) {
            partitionParamType = VoltType.typeFromObject(partitionParamValue);
        }
        
        AdHocPlannedStmtBatch plannedStmtBatch = new AdHocPlannedStmtBatch(work,
                                                                           stmts,
                                                                           partitionParamIndex,
                                                                           partitionParamType,
                                                                           partitionParamValue,
                                                                           null);
        return plannedStmtBatch;
    }

    @Override
    public String toString() {
        String retval = super.toString();
        retval += "\n  partition param: " + ((partitionParamValue != null) ? partitionParamValue.toString() : "null");
        retval += "\n  partition param index: " + partitionParamIndex;
        retval += "\n  sql: " + work.sqlBatchText;
        return retval;
    }

    @Override
    public Object clone() {
        try {
            return super.clone();
        } catch (CloneNotSupportedException e) {
            throw new RuntimeException(e);
        }
    }

    
    public List<String> getSQLStatements() {
        List<String> sqlStatements = new ArrayList<String>(plannedStatements.size());
        for (AdHocPlannedStatement plannedStatement : plannedStatements) {
            sqlStatements.add(new String(plannedStatement.sql, Constants.UTF8ENCODING));
        }
        return sqlStatements;
    }

    
    public boolean isSinglePartitionCompatible() {
        for (AdHocPlannedStatement plannedStmt : plannedStatements) {
            if (plannedStmt.core.collectorFragment != null) {
                return false;
            }
        }
        return true;
    }

    
    public int getPlannedStatementCount() {
        return plannedStatements.size();
    }

    
    public AdHocPlannedStatement getPlannedStatement(int index) {
        return plannedStatements.get(index);
    }

    
    public boolean isReadOnly() {
        return readOnly;
    }

    
    public ByteBuffer flattenPlanArrayToBuffer() throws IOException {
        int size = 0; 

        ParameterSet userParamCache = null;
        if (work.userParamSet == null) {
            userParamCache = ParameterSet.emptyParameterSet();
        } else {
            Object[] typedUserParams = new Object[work.userParamSet.length];
            int ii = 0;
            for (AdHocPlannedStatement cs : plannedStatements) {
                for (VoltType paramType : cs.core.parameterTypes) {
                    if (ii >= typedUserParams.length) {
                        String errorMsg =
                            "Too few actual arguments were passed for the parameters in the sql statement(s): (" +
                            typedUserParams.length + " vs. " + ii + ")";
                        
                        throw new VoltTypeException(errorMsg);
                    }
                    typedUserParams[ii] =
                            ParameterConverter.tryToMakeCompatible(paramType.classFromType(),
                                                                   work.userParamSet[ii]);
                    
                    
                    ii++;
                }
            }
            
            
            if (ii < typedUserParams.length) {
                
                String errorMsg =
                        "Too many actual arguments were passed for the parameters in the sql statement(s): (" +
                        typedUserParams.length + " vs. " + ii + ")";
                        throw new VoltTypeException(errorMsg);
            }
            userParamCache = ParameterSet.fromArrayNoCopy(typedUserParams);
        }
        size += userParamCache.getSerializedSize();

        size += 2; 
        for (AdHocPlannedStatement cs : plannedStatements) {
            size += cs.getSerializedSize();
        }

        ByteBuffer buf = ByteBuffer.allocate(size);
        userParamCache.flattenToBuffer(buf);
        buf.putShort((short) plannedStatements.size());
        for (AdHocPlannedStatement cs : plannedStatements) {
            cs.flattenToBuffer(buf);
        }
        return buf;
    }

    
    public static Object[] userParamsFromBuffer(ByteBuffer buf) throws IOException {
        return ParameterSet.fromByteBuffer(buf).toArray();
    }

    
    public static AdHocPlannedStatement[] planArrayFromBuffer(ByteBuffer buf) throws IOException {
        short csCount = buf.getShort();
        AdHocPlannedStatement[] statements = new AdHocPlannedStatement[csCount];
        for (int i = 0; i < csCount; ++i) {
            AdHocPlannedStatement cs = AdHocPlannedStatement.fromBuffer(buf);
            statements[i] = cs;
        }
        return statements;
    }

    public ExplainMode getExplainMode() {
        return work.explainMode;
    }

    
    public Object partitionParam() {
        if (work.userPartitionKey != null) {
            return work.userPartitionKey[0];
        }
        if (partitionParamIndex > -1 && work.userParamSet != null &&
                work.userParamSet.length > partitionParamIndex) {
            Object userParamValue = work.userParamSet[partitionParamIndex];
            if (partitionParamType == null) {
                return userParamValue;
            } else {
                return ParameterConverter.tryToMakeCompatible(partitionParamType.classFromType(), userParamValue);
            }
        }
        return partitionParamValue;
    }

    
    public String explainStatement(int i, Database db) {
        String str = "";
        AdHocPlannedStatement plannedStatement = plannedStatements.get(i);
        String aggplan = new String(plannedStatement.core.aggregatorFragment, Constants.UTF8ENCODING);
        PlanNodeTree pnt = new PlanNodeTree();
        try {
            JSONObject jobj = new JSONObject( aggplan );
            pnt.loadFromJSONPlan(jobj, db);

            if( plannedStatement.core.collectorFragment != null ) {
                
                String collplan = new String(plannedStatement.core.collectorFragment, Constants.UTF8ENCODING);
                PlanNodeTree collpnt = new PlanNodeTree();
                
                JSONObject jobMP = new JSONObject( collplan );
                collpnt.loadFromJSONPlan(jobMP, db);
                assert( collpnt.getRootPlanNode() instanceof SendPlanNode);
                pnt.getRootPlanNode().reattachFragment( (SendPlanNode) collpnt.getRootPlanNode() );
            }
            str = pnt.getRootPlanNode().toExplainPlanString();
        } catch (JSONException e) {
            System.out.println(e.getMessage());
        }
        return str;
    }

}

<code block>


package org.voltdb;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import static org.mockito.Matchers.any;
import static org.mockito.Matchers.anyInt;
import static org.mockito.Matchers.anyLong;
import static org.mockito.Matchers.anyObject;
import static org.mockito.Matchers.eq;
import static org.mockito.Mockito.doAnswer;
import static org.mockito.Mockito.doReturn;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.never;
import static org.mockito.Mockito.reset;
import static org.mockito.Mockito.spy;
import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.when;

import java.io.File;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayDeque;
import java.util.Arrays;
import java.util.HashSet;
import java.util.Queue;
import java.util.Set;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.Executors;
import java.util.concurrent.LinkedTransferQueue;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;

import org.apache.zookeeper_voltpatches.CreateMode;
import org.apache.zookeeper_voltpatches.ZooDefs.Ids;
import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.junit.After;
import org.junit.Before;
import org.junit.BeforeClass;
import org.junit.Test;
import org.mockito.ArgumentCaptor;
import org.mockito.invocation.InvocationOnMock;
import org.mockito.stubbing.Answer;
import org.voltcore.messaging.HostMessenger;
import org.voltcore.messaging.LocalObjectMessage;
import org.voltcore.messaging.VoltMessage;
import org.voltcore.network.Connection;
import org.voltcore.network.VoltNetworkPool;
import org.voltcore.utils.DeferredSerialization;
import org.voltcore.utils.Pair;
import org.voltdb.ClientInterface.ClientInputHandler;
import org.voltdb.VoltDB.Configuration;
import org.voltdb.VoltTable.ColumnInfo;
import org.voltdb.catalog.Catalog;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureInvocationType;
import org.voltdb.common.Constants;
import org.voltdb.compiler.AdHocPlannedStatement;
import org.voltdb.compiler.AdHocPlannedStmtBatch;
import org.voltdb.compiler.AdHocPlannerWork;
import org.voltdb.compiler.CatalogChangeResult;
import org.voltdb.compiler.CatalogChangeWork;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.iv2.Cartographer;
import org.voltdb.messaging.InitiateResponseMessage;
import org.voltdb.messaging.Iv2InitiateTaskMessage;
import org.voltdb.utils.CatalogUtil;
import org.voltdb.utils.Encoder;
import org.voltdb.utils.MiscUtils;

public class TestClientInterface {
    
    private VoltDBInterface m_volt;
    private Queue<DeferredSerialization> statsAnswers = new ArrayDeque<DeferredSerialization>();
    private int drStatsInvoked = 0;
    private StatsAgent m_statsAgent = new StatsAgent() {
        @Override
        public void performOpsAction(final Connection c, final long clientHandle, final OpsSelector selector,
                                     final ParameterSet params) throws Exception {
            final String stat = (String)params.toArray()[0];
            if (stat.equals("TOPO") && !statsAnswers.isEmpty()) {
                c.writeStream().enqueue(statsAnswers.poll());
            } else if (stat.equals("DR")) {
                drStatsInvoked++;
            }
        }
    };
    private SystemInformationAgent m_sysinfoAgent;
    private HostMessenger m_messenger;
    private ClientInputHandler m_handler;
    private Cartographer m_cartographer;
    private SimpleClientResponseAdapter m_cxn;
    private ZooKeeper m_zk;

    
    private static CatalogContext m_context = null;

    
    private static ClientInterface m_ci = null;
    
    

    private static int[] m_allPartitions = new int[] {0, 1, 2};

    @BeforeClass
    public static void setUpOnce() throws Exception {
        buildCatalog();

    }

    BlockingQueue<ByteBuffer> responses = new LinkedTransferQueue<ByteBuffer>();
    BlockingQueue<DeferredSerialization> responsesDS = new LinkedTransferQueue<DeferredSerialization>();
    private static final ScheduledExecutorService ses = Executors.newScheduledThreadPool(1);

    @Before
    public void setUp() throws Exception {
        
        m_volt = mock(VoltDBInterface.class);
        m_sysinfoAgent = mock(SystemInformationAgent.class);
        m_messenger = mock(HostMessenger.class);
        m_handler = mock(ClientInputHandler.class);
        m_cartographer = mock(Cartographer.class);
        m_zk = mock(ZooKeeper.class);
        responses = new LinkedTransferQueue<ByteBuffer>();
        responsesDS = new LinkedTransferQueue<DeferredSerialization>();
        
        drStatsInvoked = 0;
        m_cxn = new SimpleClientResponseAdapter(0, "foo") {
            @Override
            public void enqueue(ByteBuffer buf) {responses.offer(buf);}
            @Override
            public void enqueue(ByteBuffer bufs[]) {responses.offer(bufs[0]);}
            @Override
            public void enqueue(DeferredSerialization ds) {responsesDS.offer(ds);}
            @Override
            public void queueTask(Runnable r) {}
        };


        
        VoltDB.replaceVoltDBInstanceForTest(m_volt);
        doReturn(m_cxn.connectionId()).when(m_handler).connectionId();
        doReturn(m_statsAgent).when(m_volt).getStatsAgent();
        doReturn(m_statsAgent).when(m_volt).getOpsAgent(OpsSelector.STATISTICS);
        doReturn(m_sysinfoAgent).when(m_volt).getOpsAgent(OpsSelector.SYSTEMINFORMATION);
        doReturn(mock(SnapshotCompletionMonitor.class)).when(m_volt).getSnapshotCompletionMonitor();
        doReturn(m_messenger).when(m_volt).getHostMessenger();
        doReturn(mock(VoltNetworkPool.class)).when(m_messenger).getNetwork();
        doReturn(m_zk).when(m_messenger).getZK();
        doReturn(mock(Configuration.class)).when(m_volt).getConfig();
        doReturn(32L).when(m_messenger).getHSIdForLocalSite(HostMessenger.ASYNC_COMPILER_SITE_ID);
        doReturn(ReplicationRole.NONE).when(m_volt).getReplicationRole();
        doReturn(m_context).when(m_volt).getCatalogContext();
        doAnswer(new Answer<Object>() {
            @Override
            public Object answer(InvocationOnMock invocation)
            {
                Object args[] = invocation.getArguments();
                return ses.scheduleAtFixedRate((Runnable) args[0], (long) args[1], (long) args[2], (TimeUnit) args[3]);
            }
        }).when(m_volt).scheduleWork(any(Runnable.class), anyLong(), anyLong(), (TimeUnit)anyObject());

        m_ci = spy(new ClientInterface(null, VoltDB.DEFAULT_PORT, null, VoltDB.DEFAULT_ADMIN_PORT,
                m_context, m_messenger, ReplicationRole.NONE,
                m_cartographer, m_allPartitions));
        m_ci.bindAdapter(m_cxn, null);

        
    }

    private static void buildCatalog() throws IOException {
        
        File cat = File.createTempFile("temp-log-reinitiator", "catalog");
        cat.deleteOnExit();

        VoltProjectBuilder builder = new VoltProjectBuilder();
        String schema = "create table A (i integer not null, primary key (i));";
        builder.addLiteralSchema(schema);
        builder.addPartitionInfo("A", "i");
        builder.addStmtProcedure("hello", "select * from A where i = ?", "A.i: 0");
        builder.addStmtProcedure("hellorw", "delete from A where i = ?", "A.i: 0");

        if (!builder.compile(cat.getAbsolutePath())) {
            throw new IOException();
        }

        byte[] bytes = MiscUtils.fileToBytes(cat);
        String serializedCat =
            CatalogUtil.getSerializedCatalogStringFromJar(CatalogUtil.loadAndUpgradeCatalogFromJar(bytes).getFirst());
        assertNotNull(serializedCat);
        Catalog catalog = new Catalog();
        catalog.execute(serializedCat);

        String deploymentPath = builder.getPathToDeployment();
        CatalogUtil.compileDeployment(catalog, deploymentPath, false);

        m_context = new CatalogContext(0, 0, catalog, bytes, new byte[] {}, 0);
        TheHashinator.initialize(TheHashinator.getConfiguredHashinatorClass(), TheHashinator.getConfigureBytes(3));
    }

    @After
    public void tearDown() {
        reset(m_messenger);
        reset(m_handler);
    }

    private static ByteBuffer createMsg(String name, final Object...params) throws IOException {
        return createMsg(null, name, params);
    }

    
    private static ByteBuffer createMsg(Long origTxnId, String name,
                                        final Object...params) throws IOException
    {
        StoredProcedureInvocation proc = new StoredProcedureInvocation();
        proc.setProcName(name);
        if (origTxnId != null) {
            proc.setOriginalTxnId(origTxnId);
        }
        proc.setParams(params);
        ByteBuffer buf = ByteBuffer.allocate(proc.getSerializedSize());
        proc.flattenToBuffer(buf);
        buf.flip();
        return buf;
    }

    
    private Iv2InitiateTaskMessage readAndCheck(ByteBuffer msg, String procName, Object partitionParam,
                                                boolean isReadonly, boolean isSinglePart) throws Exception {
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);

        return checkInitMsgSent(procName, partitionParam, isReadonly, isSinglePart);
    }

    private Iv2InitiateTaskMessage checkInitMsgSent(String procName, Object partitionParam,
                                                    boolean isReadonly, boolean isSinglePart)
    {

        ArgumentCaptor<Long> destinationCaptor =
            ArgumentCaptor.forClass(Long.class);
        ArgumentCaptor<Iv2InitiateTaskMessage> messageCaptor =
            ArgumentCaptor.forClass(Iv2InitiateTaskMessage.class);
        verify(m_messenger).send(destinationCaptor.capture(), messageCaptor.capture());

        Iv2InitiateTaskMessage message = messageCaptor.getValue();
        assertEquals(isReadonly, message.isReadOnly()); 
        assertEquals(isSinglePart, message.isSinglePartition()); 
        assertEquals(procName, message.getStoredProcedureName());
        if (isSinglePart) {
            int expected = TheHashinator.getPartitionForParameter(VoltType.typeFromObject(partitionParam).getValue(),
                                                                  partitionParam);
            assertEquals(new Long(m_cartographer.getHSIdForMaster(expected)), destinationCaptor.getValue());
        } else {
            assertEquals(new Long(m_cartographer.getHSIdForMultiPartitionInitiator()), destinationCaptor.getValue());
        }
        return message;
    }

    @Test
    public void testExplain() throws IOException {
        ByteBuffer msg = createMsg("@Explain", "select * from a");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        ArgumentCaptor<LocalObjectMessage> captor = ArgumentCaptor.forClass(LocalObjectMessage.class);
        verify(m_messenger).send(eq(32L), captor.capture());
        assertTrue(captor.getValue().payload instanceof AdHocPlannerWork );
        System.out.println( captor.getValue().payload.toString() );
        String payloadString = captor.getValue().payload.toString();
        assertTrue(payloadString.contains("user partitioning: none"));
    }

    @Test
    public void testAdHoc() throws IOException {
        ByteBuffer msg = createMsg("@AdHoc", "select * from a");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        ArgumentCaptor<LocalObjectMessage> captor = ArgumentCaptor.forClass(LocalObjectMessage.class);
        verify(m_messenger).send(eq(32L), captor.capture());
        assertTrue(captor.getValue().payload instanceof AdHocPlannerWork);
        String payloadString = captor.getValue().payload.toString();
        assertTrue(payloadString.contains("user partitioning: none"));

        
        reset(m_messenger);
        msg = createMsg("@AdHocSpForTest", "select * from a where i = 3", 3);
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        verify(m_messenger).send(eq(32L), captor.capture());
        assertTrue(captor.getValue().payload instanceof AdHocPlannerWork);
        payloadString = captor.getValue().payload.toString();
        assertTrue(payloadString.contains("user params: empty"));
        assertTrue(payloadString.contains("user partitioning: 3"));
    }

    @Test
    public void testFinishedSPAdHocPlanning() throws Exception {
        
        String query = "select * from a where i = ?";
        int partitionParamIndex = 0;
        Object[] extractedValues =  new Object[0];
        VoltType[] paramTypes =  new VoltType[]{VoltType.INTEGER};
        AdHocPlannedStmtBatch plannedStmtBatch =
                AdHocPlannedStmtBatch.mockStatementBatch(3, query, extractedValues, paramTypes,
                                                         new Object[]{3}, partitionParamIndex,
                                                         m_context.getCatalogHash());
        m_ci.processFinishedCompilerWork(plannedStmtBatch).run();

        ArgumentCaptor<Long> destinationCaptor =
                ArgumentCaptor.forClass(Long.class);
        ArgumentCaptor<Iv2InitiateTaskMessage> messageCaptor =
                ArgumentCaptor.forClass(Iv2InitiateTaskMessage.class);
        verify(m_messenger).send(destinationCaptor.capture(), messageCaptor.capture());
        Iv2InitiateTaskMessage message = messageCaptor.getValue();

        assertTrue(message.isReadOnly());  
        assertTrue(message.isSinglePartition()); 
        assertEquals("@AdHoc_RO_SP", message.getStoredProcedureName());

        
        Object partitionParam = message.getStoredProcedureInvocation().getParameterAtIndex(0);
        assertTrue(partitionParam instanceof byte[]);
        VoltType type = VoltType.get((Byte) message.getStoredProcedureInvocation().getParameterAtIndex(1));
        assertTrue(type.isInteger());
        byte[] serializedData = (byte[]) message.getStoredProcedureInvocation().getParameterAtIndex(2);
        ByteBuffer buf = ByteBuffer.wrap(serializedData);
        Object[] parameters = AdHocPlannedStmtBatch.userParamsFromBuffer(buf);
        assertEquals(1, parameters.length);
        assertEquals(3, parameters[0]);
        AdHocPlannedStatement[] statements = AdHocPlannedStmtBatch.planArrayFromBuffer(buf);
        assertTrue(Arrays.equals(TheHashinator.valueToBytes(3), (byte[]) partitionParam));
        assertEquals(1, statements.length);
        String sql = new String(statements[0].sql, Constants.UTF8ENCODING);
        assertEquals(query, sql);
    }

    
    @Test
    public void testFinishedMPAdHocPlanning() throws Exception {
        
        String query = "select * from a";
        Object[] extractedValues =  new Object[0];
        VoltType[] paramTypes =  new VoltType[0];
        AdHocPlannedStmtBatch plannedStmtBatch =
            AdHocPlannedStmtBatch.mockStatementBatch(3, query, extractedValues, paramTypes, null, -1,
                    m_context.getCatalogHash());
        m_ci.processFinishedCompilerWork(plannedStmtBatch).run();

        ArgumentCaptor<Long> destinationCaptor =
                ArgumentCaptor.forClass(Long.class);
        ArgumentCaptor<Iv2InitiateTaskMessage> messageCaptor =
                ArgumentCaptor.forClass(Iv2InitiateTaskMessage.class);
        verify(m_messenger).send(destinationCaptor.capture(), messageCaptor.capture());
        Iv2InitiateTaskMessage message = messageCaptor.getValue();

        
        assertTrue(message.isReadOnly());  
        assertFalse(message.isSinglePartition()); 
        
        assertEquals("@AdHoc_RO_MP", message.getStoredProcedureName());

        byte[] serializedData = (byte[]) message.getStoredProcedureInvocation().getParameterAtIndex(0);
        ByteBuffer buf = ByteBuffer.wrap(serializedData);
        Object[] parameters = AdHocPlannedStmtBatch.userParamsFromBuffer(buf);
        assertEquals(0, parameters.length);
        AdHocPlannedStatement[] statements = AdHocPlannedStmtBatch.planArrayFromBuffer(buf);
        assertEquals(1, statements.length);
        String sql = new String(statements[0].sql, Constants.UTF8ENCODING);
        assertEquals(query, sql);
    }

    @Test
    public void testUpdateCatalog() throws IOException {
        
        if (VoltDB.instance().getConfig().m_isEnterprise) {
            String catalogHex = Encoder.hexEncode("blah");
            ByteBuffer msg = createMsg("@UpdateApplicationCatalog", catalogHex, "blah");
            ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
            assertNull(resp);
            ArgumentCaptor<LocalObjectMessage> captor = ArgumentCaptor.forClass(LocalObjectMessage.class);
            verify(m_messenger).send(eq(32L), 
                                     captor.capture());
            assertTrue(captor.getValue().payload instanceof CatalogChangeWork);
        }
    }

    @Test
    public void testNegativeUpdateCatalog() throws IOException {
        ByteBuffer msg = createMsg("@UpdateApplicationCatalog", new Integer(1), new Long(0));
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        
        assertNotNull(resp);
        assertTrue(resp.getStatus() != 0);
    }


    
    @Test
    public void testFinishedCatalogDiffing() {
        CatalogChangeResult catalogResult = new CatalogChangeResult();
        catalogResult.clientData = null;
        catalogResult.clientHandle = 0;
        catalogResult.connectionId = 0;
        catalogResult.adminConnection = false;
        
        catalogResult.catalogHash = "blah".getBytes();
        catalogResult.catalogBytes = "blah".getBytes();
        catalogResult.deploymentString = "blah";
        catalogResult.expectedCatalogVersion = 3;
        catalogResult.encodedDiffCommands = "diff";
        catalogResult.invocationType = ProcedureInvocationType.REPLICATED;
        catalogResult.originalTxnId = 12345678l;
        catalogResult.originalUniqueId = 87654321l;
        catalogResult.user = new AuthSystem.AuthDisabledUser();
        m_ci.processFinishedCompilerWork(catalogResult).run();

        ArgumentCaptor<Long> destinationCaptor =
                ArgumentCaptor.forClass(Long.class);
        ArgumentCaptor<Iv2InitiateTaskMessage> messageCaptor =
                ArgumentCaptor.forClass(Iv2InitiateTaskMessage.class);
        verify(m_messenger).send(destinationCaptor.capture(), messageCaptor.capture());
        Iv2InitiateTaskMessage message = messageCaptor.getValue();
        
        assertFalse(message.isReadOnly()); 
        assertFalse(message.isSinglePartition()); 
        
        assertEquals("@UpdateApplicationCatalog", message.getStoredProcedureName());
        assertEquals("diff", message.getStoredProcedureInvocation().getParameterAtIndex(0));
        assertTrue(Arrays.equals("blah".getBytes(), (byte[]) message.getStoredProcedureInvocation().getParameterAtIndex(2)));
        assertEquals(3, message.getStoredProcedureInvocation().getParameterAtIndex(3));
        assertEquals("blah", message.getStoredProcedureInvocation().getParameterAtIndex(4));
        assertEquals(ProcedureInvocationType.REPLICATED, message.getStoredProcedureInvocation().getType());
        assertEquals(12345678l, message.getStoredProcedureInvocation().getOriginalTxnId());
        assertEquals(87654321l, message.getStoredProcedureInvocation().getOriginalUniqueId());
    }

    @Test
    public void testUserProc() throws Exception {
        ByteBuffer msg = createMsg("hello", 1);
        StoredProcedureInvocation invocation =
                readAndCheck(msg, "hello", 1, true, true).getStoredProcedureInvocation();
        assertEquals(1, invocation.getParameterAtIndex(0));
    }

    @Test
    public void testGC() throws Exception {
        ByteBuffer msg = createMsg("@GC");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);

        ByteBuffer b = responses.take();
        resp = new ClientResponseImpl();
        b.position(4);
        resp.initFromBuffer(b);
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        VoltTable vt = resp.getResults()[0];
        assertTrue(vt.advanceRow());
        
        assertTrue(resp.getResults()[0].getLong(0) > 10000);
    }

    @Test
    public void testSystemInformation() throws Exception {
        ByteBuffer msg = createMsg("@SystemInformation");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        verify(m_sysinfoAgent).performOpsAction(any(Connection.class), anyInt(), eq(OpsSelector.SYSTEMINFORMATION),
                any(ParameterSet.class));
    }

    
    @Test
    public void testDRStats() throws Exception {
        ByteBuffer msg = createMsg("@Statistics", "DR", 0);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        assertEquals(drStatsInvoked, 1);
    }

    @Test
    public void testLoadSinglePartTable() throws Exception {
        VoltTable table = new VoltTable(new ColumnInfo("i", VoltType.INTEGER));
        table.addRow(1);

        byte[] partitionParam = {0, 0, 0, 0, 0, 0, 0, 4};
        ByteBuffer msg = createMsg("@LoadSinglepartitionTable", partitionParam, "a", table);
        readAndCheck(msg, "@LoadSinglepartitionTable", partitionParam, false, true);
    }

    @Test
    public void testPausedMode() throws IOException {
        runPausedMode(false);
    }

    @Test
    public void testPausedModeAdmin() throws IOException {
        when(m_handler.isAdmin()).thenReturn(true);
        runPausedMode(true);
        when(m_handler.isAdmin()).thenReturn(false);
    }

    private void runPausedMode(boolean isAdmin) throws IOException {
        
        when(m_volt.getMode()).thenReturn(OperationMode.PAUSED);

        
        ByteBuffer msg = createMsg("hello", 1);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);

        
        msg = createMsg("hellorw", "10");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        if (isAdmin) {
            assertNull(resp);
        } else {
            assertNotNull(resp);
            assertEquals(ClientResponse.SERVER_UNAVAILABLE, resp.getStatus());
            assert(resp.getStatusString().startsWith("Server is paused"));
        }

        when(m_volt.getMode()).thenReturn(OperationMode.RUNNING);
    }

    @Test
    public void testPausedModeAdHoc() throws IOException {
        runPausedModeAdHoc(false);
    }

    @Test
    public void testPausedModeAdHocAdmin() throws IOException {
        when(m_handler.isAdmin()).thenReturn(true);
        runPausedModeAdHoc(true);
        when(m_handler.isAdmin()).thenReturn(false);
    }

    private void runPausedModeAdHoc(boolean isAdmin) throws IOException {
        
        when(m_volt.getMode()).thenReturn(OperationMode.PAUSED);

        responses.clear();
        String query = "select * from A";
        ByteBuffer msg = createMsg("@AdHoc", query);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        
        AdHocPlannedStmtBatch plannedStmt =
                AdHocPlannedStmtBatch.mockStatementBatch(0, query, null, new VoltType[] { }, null, -1, m_context.getCatalogHash());
        plannedStmt.clientData = m_cxn;
        m_ci.processFinishedCompilerWork(plannedStmt).run();
        assertEquals(0, responses.size());

        query = "insert into A values (10)";
        msg = createMsg("@AdHoc", query);
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        plannedStmt =
                AdHocPlannedStmtBatch.mockStatementBatch(0, query, null, new VoltType[] { }, null, -1, m_context.getCatalogHash(), false, isAdmin);
        plannedStmt.clientData = m_cxn;
        m_ci.processFinishedCompilerWork(plannedStmt).run();
        if (isAdmin) {
            assertEquals(0, responses.size());
        } else {
            assertEquals(1, responses.size());
            ByteBuffer buf = responses.remove();
            resp = new ClientResponseImpl();
            buf.position(4);
            resp.initFromBuffer(buf);
            assertEquals(ClientResponse.SERVER_UNAVAILABLE, resp.getStatus());
        }

        when(m_volt.getMode()).thenReturn(OperationMode.RUNNING);
    }

    @Test
    public void testInvalidProcedure() throws IOException {
        ByteBuffer msg = createMsg("hellooooo", 1);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.UNEXPECTED_FAILURE, resp.getStatus());
    }

    @Test
    public void testAdminProcsOnNonAdminPort() throws IOException {
        ByteBuffer msg = createMsg("@Pause");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.UNEXPECTED_FAILURE, resp.getStatus());

        msg = createMsg("@Resume");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.UNEXPECTED_FAILURE, resp.getStatus());
    }

    @Test
    public void testRejectDupInvocation() throws IOException {
        
        ByteBuffer msg = createMsg(12345l, "hello", 1);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.UNEXPECTED_FAILURE, resp.getStatus());
    }

    @Test
    public void testPolicyRejection() throws IOException {
        
        ByteBuffer msg = createMsg("@AdHoc", 1, 3, 3);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());
    }

    @Test
    public void testPromoteWithoutCommandLogging() throws Exception {
        final ByteBuffer msg = createMsg("@Promote");
        m_ci.handleRead(msg, m_handler, m_cxn);
        
        verify(m_zk, never()).create(eq(VoltZK.request_truncation_snapshot_node), any(byte[].class),
                                     eq(Ids.OPEN_ACL_UNSAFE), eq(CreateMode.PERSISTENT));
    }

    @Test
    public void testPromoteWithCommandLogging() throws Exception {
        org.voltdb.catalog.CommandLog logConfig = m_context.cluster.getLogconfig().get("log");
        boolean wasEnabled = logConfig.getEnabled();
        logConfig.setEnabled(true);
        try {
            final ByteBuffer msg = createMsg("@Promote");
            m_ci.handleRead(msg, m_handler, m_cxn);
            
            verify(m_zk, never()).create(eq(VoltZK.request_truncation_snapshot_node), any(byte[].class),
                                eq(Ids.OPEN_ACL_UNSAFE), eq(CreateMode.PERSISTENT_SEQUENTIAL));
        }
        finally {
            logConfig.setEnabled(wasEnabled);
        }
    }

    @Test
    public void testTransactionRestart() throws Exception {
        initMsgAndSendRestartResp(true);
    }

    @Test
    public void testTransactionRestartIgnored() throws Exception {
        
        doReturn(OperationMode.INITIALIZING).when(m_volt).getMode();
        initMsgAndSendRestartResp(false);


    }

    private void initMsgAndSendRestartResp(boolean shouldRestart) throws Exception
    {
        
        TheHashinator.constructHashinator(TheHashinator.getConfiguredHashinatorClass(),
                                          TheHashinator.getConfigureBytes(3),
                                          false);
        Pair<Long, byte[]> hashinatorConfig = TheHashinator.getCurrentVersionedConfig();
        long newHashinatorVersion = hashinatorConfig.getFirst() + 1;

        ByteBuffer msg = createMsg("hello", 1);
        Iv2InitiateTaskMessage initMsg = readAndCheck(msg, "hello", 1, true, true);
        assertEquals(1, initMsg.getStoredProcedureInvocation().getParameterAtIndex(0));

        
        InitiateResponseMessage respMsg = new InitiateResponseMessage(initMsg);
        respMsg.setMispartitioned(true, initMsg.getStoredProcedureInvocation(),
                                  Pair.of(newHashinatorVersion, hashinatorConfig.getSecond()));

        
        reset(m_messenger);

        
        m_ci.m_mailbox.deliver(respMsg);

        
        DeferredSerialization resp = responsesDS.take();

        if (shouldRestart) {
            assertEquals(-1, resp.getSerializedSize());
            checkInitMsgSent("hello", 1, true, true);
        } else {
            assertTrue(-1 != resp.getSerializedSize());
            verify(m_messenger, never()).send(anyLong(), any(VoltMessage.class));
        }

        
        assertEquals(newHashinatorVersion, TheHashinator.getCurrentVersionedConfig().getFirst().longValue());
    }

    @Test
    public void testGetPartitionKeys() throws IOException {
        
        ByteBuffer msg = createMsg("@GetPartitionKeys", "BIGINT");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", new Object[] { null });
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", "");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", "ryanlikestheyankees");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", "INTEGER", 99);
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", "InTeGeR");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        VoltTable vt = resp.getResults()[0];
        assertEquals(3, vt.getRowCount());
        assertEquals(VoltType.INTEGER, vt.getColumnType(1));

        Set<Integer> partitions = new HashSet<Integer>(Arrays.asList( 0, 1, 2));
        while (vt.advanceRow()) {
            int partition = TheHashinator.getPartitionForParameter(VoltType.INTEGER.getValue(), vt.getLong(1));
            assertTrue(partitions.remove(partition));
        }
        assertTrue(partitions.isEmpty());
    }

    @Test
    public void testSubscribe() throws Exception {
        RateLimitedClientNotifier.WARMUP_MS = 0;
        ClientInterface.TOPOLOGY_CHANGE_CHECK_MS = 1;
        try {
            m_ci.startAcceptingConnections();
            ByteBuffer msg = createMsg("@Subscribe", "TOPOLOGY");
            ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
            assertNotNull(resp);
            assertEquals(ClientResponse.SUCCESS, resp.getStatus());
            statsAnswers.offer(dsOf(getClientResponse("foo")));
            m_ci.schedulePeriodicWorks();

            
            assertNull(responsesDS.poll(50, TimeUnit.MILLISECONDS));

            statsAnswers.offer(dsOf(getClientResponse("foo")));
            assertNull(responsesDS.poll(50, TimeUnit.MILLISECONDS));

            
            
            ByteBuffer expectedBuf = getClientResponse("bar");
            statsAnswers.offer(dsOf(expectedBuf));
            DeferredSerialization ds = responsesDS.take();
            ByteBuffer actualBuf = ByteBuffer.allocate(ds.getSerializedSize());
            ds.serialize(actualBuf);
            assertEquals(expectedBuf, actualBuf);
        } finally {
            RateLimitedClientNotifier.WARMUP_MS = 1000;
            ClientInterface.TOPOLOGY_CHANGE_CHECK_MS = 5000;
            m_ci.shutdown();
        }
    }

    private DeferredSerialization dsOf(final ByteBuffer buf) {
        return new DeferredSerialization() {
            @Override
            public void serialize(final ByteBuffer outbuf) throws IOException {
                outbuf.put(buf);
            }
            @Override
            public void cancel() {}
            @Override
            public int getSerializedSize() {
                return buf.remaining();
            }
        };
    }

    public ByteBuffer getClientResponse(String str) {
        ClientResponseImpl response = new ClientResponseImpl(ClientResponse.SUCCESS,
                new VoltTable[0], str, ClientInterface.ASYNC_TOPO_HANDLE);
        ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
        buf.putInt(buf.capacity() - 4);
        response.flattenToBuffer(buf);
        buf.flip();
        return buf;
    }
}

<code block>



package org.voltdb;

import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import java.io.UnsupportedEncodingException;
import java.math.BigDecimal;
import java.net.HttpURLConnection;
import java.net.URL;
import java.net.URLEncoder;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;

import junit.framework.TestCase;

import org.codehaus.jackson.map.ObjectMapper;
import org.json_voltpatches.JSONArray;
import org.json_voltpatches.JSONException;
import org.json_voltpatches.JSONObject;
import org.voltcore.utils.CoreUtils;
import org.voltdb.VoltDB.Configuration;
import org.voltdb.client.Client;
import org.voltdb.client.ClientAuthHashScheme;
import org.voltdb.client.ClientConfig;
import org.voltdb.client.ClientFactory;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureCallback;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.compiler.VoltProjectBuilder.ProcedureInfo;
import org.voltdb.compiler.VoltProjectBuilder.RoleInfo;
import org.voltdb.compiler.VoltProjectBuilder.UserInfo;
import org.voltdb.compiler.deploymentfile.DeploymentType;
import org.voltdb.compiler.deploymentfile.HeartbeatType;
import org.voltdb.compiler.deploymentfile.SystemSettingsType;
import org.voltdb.compiler.deploymentfile.SystemSettingsType.Query;
import org.voltdb.compiler.deploymentfile.UsersType;
import org.voltdb.compiler.procedures.CrazyBlahProc;
import org.voltdb.compiler.procedures.DelayProc;
import org.voltdb.compiler.procedures.SelectStarHelloWorld;
import org.voltdb.types.TimestampType;
import org.voltdb.utils.Base64;
import org.voltdb.utils.Encoder;
import org.voltdb.utils.MiscUtils;

public class TestJSONInterface extends TestCase {

    ServerThread server;
    Client client;

    static class Response {

        public byte status = 0;
        public String statusString = null;
        public byte appStatus = Byte.MIN_VALUE;
        public String appStatusString = null;
        public VoltTable[] results = new VoltTable[0];
        public String exception = null;
    }

    static String japaneseTestVarStrings = "Procedure=Insert&Parameters=%5B%22%5Cu3053%5Cu3093%5Cu306b%5Cu3061%5Cu306f%22%2C%22%5Cu4e16%5Cu754c%22%2C%22Japanese%22%5D";

    static String getHTTPVarString(Map<String, String> params) throws UnsupportedEncodingException {
        String s = "";
        for (Entry<String, String> e : params.entrySet()) {
            String encodedValue = URLEncoder.encode(e.getValue(), "UTF-8");
            s += "&" + e.getKey() + "=" + encodedValue;
        }
        s = s.substring(1);
        return s;
    }

    static String getHTTPURL(Integer port, String path) {
        if (port == null) {
            port = VoltDB.DEFAULT_HTTP_PORT;
        }
        return String.format("http:
    }

    public static String callProcOverJSONRaw(String varString, int expectedCode) throws Exception {
        URL jsonAPIURL = new URL("http:

        HttpURLConnection conn = (HttpURLConnection) jsonAPIURL.openConnection();
        conn.setRequestMethod("POST");
        conn.setDoOutput(true);
        conn.connect();

        OutputStreamWriter out = new OutputStreamWriter(conn.getOutputStream());
        out.write(varString);
        out.flush();
        out.close();
        out = null;
        conn.getOutputStream().close();

        BufferedReader in = null;
        try {
            if (conn.getInputStream() != null) {
                in = new BufferedReader(
                        new InputStreamReader(
                                conn.getInputStream(), "UTF-8"));
            }
        } catch (IOException e) {
            if (conn.getErrorStream() != null) {
                in = new BufferedReader(
                        new InputStreamReader(
                                conn.getErrorStream(), "UTF-8"));
            }
        }
        if (in == null) {
            throw new Exception("Unable to read response from server");
        }

        StringBuilder decodedString = new StringBuilder();
        String line;
        while ((line = in.readLine()) != null) {
            decodedString.append(line);
        }
        in.close();
        in = null;
        
        int responseCode = conn.getResponseCode();

        String response = decodedString.toString();

        assertEquals(expectedCode, responseCode);

        try {
            conn.getInputStream().close();
            conn.disconnect();
        } 
        catch (Exception e) {
        }
        conn = null;

        
        return response;
    }

    private static String getUrlOverJSON(String url, String user, String password, String scheme, int expectedCode, String expectedCt) throws Exception {
        return httpUrlOverJSON("GET", url, user, password, scheme, expectedCode, expectedCt, null);
    }

    private static String postUrlOverJSON(String url, String user, String password, String scheme, int expectedCode, String expectedCt, Map<String,String> params) throws Exception {
        return httpUrlOverJSON("POST", url, user, password, scheme, expectedCode, expectedCt, params);
    }

    private static String putUrlOverJSON(String url, String user, String password, String scheme, int expectedCode, String expectedCt, Map<String,String> params) throws Exception {
        return httpUrlOverJSON("PUT", url, user, password, scheme, expectedCode, expectedCt, params);
    }

    private static String deleteUrlOverJSON(String url, String user, String password, String scheme, int expectedCode, String expectedCt) throws Exception {
        return httpUrlOverJSON("DELETE", url, user, password, scheme, expectedCode, expectedCt, null);
    }

    private static String httpUrlOverJSON(String method, String url, String user, String password, String scheme, int expectedCode, String expectedCt, Map<String,String> params) throws Exception {
        URL jsonAPIURL = new URL(url);

        HttpURLConnection conn = (HttpURLConnection) jsonAPIURL.openConnection();
        conn.setRequestMethod(method);
        conn.setDoOutput(true);
        conn.setRequestProperty("Content-Type", "application/x-www-form-urlencoded");
        if (user != null && password != null) {
            if (scheme.equalsIgnoreCase("hashed")) {
                MessageDigest md = MessageDigest.getInstance("SHA-1");
                byte hashedPasswordBytes[] = md.digest(password.getBytes("UTF-8"));
                String h = user + ":" + Encoder.hexEncode(hashedPasswordBytes);
                conn.setRequestProperty("Authorization", "Hashed " + h);
            } else if (scheme.equalsIgnoreCase("hashed256")) {
                MessageDigest md = MessageDigest.getInstance("SHA-256");
                byte hashedPasswordBytes[] = md.digest(password.getBytes("UTF-8"));
                String h = user + ":" + Encoder.hexEncode(hashedPasswordBytes);
                conn.setRequestProperty("Authorization", "Hashed " + h);
            } else if (scheme.equalsIgnoreCase("basic")) {
                conn.setRequestProperty("Authorization", "Basic " + new String(Base64.encodeToString(new String(user + ":" + password).getBytes(), false)));
            }
        }
        conn.connect();
        byte andbyte[] = String.valueOf('&').getBytes();
        if (params != null && params.size() > 0) {
            OutputStream os = conn.getOutputStream();
            for (String key : params.keySet()) {
                os.write(key.getBytes());
                if (params.get(key) != null) {
                    String b = "=" + params.get(key);
                    os.write(b.getBytes());
                }
                os.write(andbyte);
            }
        }

        BufferedReader in = null;
        try {
            if (conn.getInputStream() != null) {
                in = new BufferedReader(
                        new InputStreamReader(
                                conn.getInputStream(), "UTF-8"));
            }
        } catch (IOException e) {
            if (conn.getErrorStream() != null) {
                in = new BufferedReader(
                        new InputStreamReader(
                                conn.getErrorStream(), "UTF-8"));
            }
        }
        if (in == null) {
            throw new Exception("Unable to read response from server");
        }
        String ct = conn.getContentType();
        assertTrue(ct.contains(expectedCt));

        StringBuilder decodedString = new StringBuilder();
        String line;
        try {
            while ((line = in.readLine()) != null) {
                decodedString.append(line);
            }
        } catch (Exception ex) {
            ex.printStackTrace();
        } finally {
            in.close();
            in = null;
        }
        
        int responseCode = conn.getResponseCode();

        String response = decodedString.toString();

        assertEquals(expectedCode, responseCode);

        try {
            conn.getInputStream().close();
            conn.disconnect();
        } 
        catch (Exception e) {
        }
        conn = null;

        
        return response;
    }

    public static String getHashedPasswordForHTTPVar(String password, ClientAuthHashScheme scheme) {
        assert (password != null);

        MessageDigest md = null;
        try {
            md = MessageDigest.getInstance(ClientAuthHashScheme.getDigestScheme(scheme));
        } catch (NoSuchAlgorithmException e) {
            fail();
        }
        byte hashedPassword[] = null;
        try {
            hashedPassword = md.digest(password.getBytes("UTF-8"));
        } catch (UnsupportedEncodingException e) {
            throw new RuntimeException("JVM doesn't support UTF-8. Please use a supported JVM", e);
        }

        String retval = Encoder.hexEncode(hashedPassword);
        assertEquals(ClientAuthHashScheme.getHexencodedDigestLength(scheme), retval.length());
        return retval;
    }

    public static String callProcOverJSON(String procName, ParameterSet pset, String username, String password, boolean preHash) throws Exception {
        return callProcOverJSON(procName, pset, username, password, preHash, false, 200 , ClientAuthHashScheme.HASH_SHA256);
    }

    public static String callProcOverJSON(String procName, ParameterSet pset, String username, String password, boolean preHash, boolean admin) throws Exception {
        return callProcOverJSON(procName, pset, username, password, preHash, admin, 200 , ClientAuthHashScheme.HASH_SHA256);
    }

    public static String callProcOverJSON(String procName, ParameterSet pset, String username, String password, boolean preHash, boolean admin, int expectedCode, ClientAuthHashScheme scheme) throws Exception {
        
        String paramsInJSON = pset.toJSONString();
        
        HashMap<String, String> params = new HashMap<String, String>();
        params.put("Procedure", procName);
        params.put("Parameters", paramsInJSON);
        if (username != null) {
            params.put("User", username);
        }
        if (password != null) {
            if (preHash) {
                params.put("Hashedpassword", getHashedPasswordForHTTPVar(password, scheme));
            } else {
                params.put("Password", password);
            }
        }
        if (admin) {
            params.put("admin", "true");
        }

        String varString = getHTTPVarString(params);

        varString = getHTTPVarString(params);

        String ret = callProcOverJSONRaw(varString, expectedCode);
        if (preHash) {
            
            params.put("Hashedpassword", getHashedPasswordForHTTPVar(password, ClientAuthHashScheme.HASH_SHA1));
            varString = getHTTPVarString(params);

            varString = getHTTPVarString(params);
            callProcOverJSONRaw(varString, expectedCode);
        }
        return ret;
    }

    public static Response responseFromJSON(String jsonStr) throws JSONException, IOException {
        Response response = new Response();
        JSONObject jsonObj = new JSONObject(jsonStr);
        JSONArray resultsJson = jsonObj.getJSONArray("results");
        response.results = new VoltTable[resultsJson.length()];
        for (int i = 0; i < response.results.length; i++) {
            JSONObject tableJson = resultsJson.getJSONObject(i);
            response.results[i] = VoltTable.fromJSONObject(tableJson);
        }
        if (jsonObj.isNull("status") == false) {
            response.status = (byte) jsonObj.getInt("status");
        }
        if (jsonObj.isNull("appstatus") == false) {
            response.appStatus = (byte) jsonObj.getInt("appstatus");
        }
        if (jsonObj.isNull("statusstring") == false) {
            response.statusString = jsonObj.getString("statusstring");
        }
        if (jsonObj.isNull("appstatusstring") == false) {
            response.appStatusString = jsonObj.getString("appstatusstring");
        }
        if (jsonObj.isNull("exception") == false) {
            response.exception = jsonObj.getString("exception");
        }

        return response;
    }

    public void testPausedMode() throws Exception {
        try {
            String testSchema
                    = "CREATE TABLE foo (\n"
                    + "  ival bigint default 23 not null, "
                    + "  sval varchar(200) default 'foo', "
                    + "  PRIMARY KEY (ival)\n"
                    + ");";

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addLiteralSchema(testSchema);
            builder.addPartitionInfo("foo", "ival");
            builder.addStmtProcedure("fooinsert", "insert into foo values (?, ?);");
            builder.addStmtProcedure("foocount", "select count(*) from foo;");
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            int pkStart = 0;
            pkStart = runPauseTests(pkStart, false, false);
            pkStart = runPauseTests(pkStart, false, true);

            
            ParameterSet pset = ParameterSet.emptyParameterSet();
            Response response = responseFromJSON(callProcOverJSON("@Pause", pset, null, null, false, true));
            assertTrue(response.status == ClientResponse.SUCCESS);

            pkStart = runPauseTests(pkStart, true, false);
            pkStart = runPauseTests(pkStart, true, true);

            
            pset = ParameterSet.emptyParameterSet();
            response = responseFromJSON(callProcOverJSON("@Resume", pset, null, null, false, true));
            assertTrue(response.status == ClientResponse.SUCCESS);

            pkStart = runPauseTests(pkStart, false, false);
            pkStart = runPauseTests(pkStart, false, true);

        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    private int runPauseTests(int pkStart, boolean paused, boolean useAdmin) throws Exception {
        ParameterSet pset;
        String responseJSON;
        Response response;

        pset = ParameterSet.fromArrayNoCopy(pkStart++, "hello");
        responseJSON = callProcOverJSON("fooinsert", pset, null, null, false, useAdmin);
        response = responseFromJSON(responseJSON);
        if (paused && !useAdmin) {
            assertEquals(ClientResponse.SERVER_UNAVAILABLE, response.status);
            assertTrue(response.statusString.contains("is paused"));
            pkStart--;
        } else {
            assertEquals(ClientResponse.SUCCESS, response.status);
            assertEquals(1L, response.results[0].fetchRow(0).getLong(0));
        }

        pset = ParameterSet.emptyParameterSet();
        responseJSON = callProcOverJSON("foocount", pset, null, null, false, useAdmin);
        response = responseFromJSON(responseJSON);
        assertEquals(ClientResponse.SUCCESS, response.status);
        assertEquals(pkStart, response.results[0].fetchRow(0).getLong(0));

        
        pset = ParameterSet.fromArrayNoCopy("insert into foo values (" + (pkStart++) + ", 'adhochello')");
        responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false, useAdmin);
        response = responseFromJSON(responseJSON);
        if (paused && !useAdmin) {
            assertEquals(ClientResponse.SERVER_UNAVAILABLE, response.status);
            assertTrue(response.statusString.contains("is paused"));
            pkStart--;
        } else {
            assertEquals(ClientResponse.SUCCESS, response.status);
        }

        pset = ParameterSet.fromArrayNoCopy("select count(*) from foo");
        responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false, useAdmin);
        response = responseFromJSON(responseJSON);
        assertEquals(ClientResponse.SUCCESS, response.status);
        assertEquals(pkStart, response.results[0].fetchRow(0).getLong(0));

        return pkStart;
    }

    public void testAJAXAndClientTogether() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addLiteralSchema(simpleSchema);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            client = ClientFactory.createClient(new ClientConfig());
            client.createConnection("localhost");

            final AtomicLong fcnt = new AtomicLong(0);
            final AtomicLong scnt = new AtomicLong(0);
            final AtomicLong cfcnt = new AtomicLong(0);
            final AtomicLong cscnt = new AtomicLong(0);
            final int jsonRunnerCount = 50;
            final int clientRunnerCount = 50;
            final ParameterSet pset = ParameterSet.fromArrayNoCopy("select count(*) from foo");
            String responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            Response r = responseFromJSON(responseJSON);
            assertEquals(ClientResponse.SUCCESS, r.status);
            
            class JSONRunner implements Runnable {

                @Override
                public void run() {
                    try {
                        String rresponseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
                        System.out.println("Response: " + rresponseJSON);
                        Response rr = responseFromJSON(rresponseJSON);
                        assertEquals(ClientResponse.SUCCESS, rr.status);
                        scnt.incrementAndGet();
                    } catch (Exception ex) {
                        fcnt.incrementAndGet();
                        ex.printStackTrace();
                    }
                }

            }

            
            class ClientRunner implements Runnable {

                class Callback implements ProcedureCallback {

                    @Override
                    public void clientCallback(ClientResponse clientResponse) throws Exception {
                        if (clientResponse.getStatus() == ClientResponse.SUCCESS) {
                            cscnt.incrementAndGet();
                        } else {
                            System.out.println("Client failed: " + clientResponse.getStatusString());
                            cfcnt.incrementAndGet();
                        }
                    }

                }
                @Override
                public void run() {
                    try {
                        if (!client.callProcedure(new Callback(), "@AdHoc", "SELECT count(*) from foo")) {
                            cfcnt.decrementAndGet();
                        }
                    } catch (Exception ex) {
                        fcnt.incrementAndGet();
                        ex.printStackTrace();
                    }
                }

            }

            
            ExecutorService es = CoreUtils.getBoundedSingleThreadExecutor("runners", jsonRunnerCount);
            for (int i = 0; i < jsonRunnerCount; i++) {
                es.submit(new JSONRunner());
            }
            ExecutorService ces = CoreUtils.getBoundedSingleThreadExecutor("crunners", clientRunnerCount);
            for (int i = 0; i < clientRunnerCount; i++) {
                ces.submit(new ClientRunner());
            }

            es.shutdown();
            es.awaitTermination(1, TimeUnit.DAYS);
            assertEquals(jsonRunnerCount, scnt.get());
            ces.shutdown();
            ces.awaitTermination(1, TimeUnit.DAYS);
            client.drain();
            assertEquals(clientRunnerCount, cscnt.get());
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            r = responseFromJSON(responseJSON);
            assertEquals(ClientResponse.SUCCESS, r.status);
            
            ClientResponse resp = client.callProcedure("@AdHoc", "SELECT count(*) from foo");
            assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
            if (client != null) {
                client.close();
            }
        }
    }


    public void testAdminMode() throws Exception {
        try {
            String simpleSchema
                    = "create table blah ("
                    + "ival bigint default 23 not null, "
                    + "sval varchar(200) default 'foo', "
                    + "dateval timestamp, "
                    + "fval float, "
                    + "decval decimal, "
                    + "PRIMARY KEY(ival));";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltDB.Configuration config = new VoltDB.Configuration();

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("blah", "ival");
            builder.addStmtProcedure("Insert", "insert into blah values (?,?,?,?,?);");
            builder.addProcedures(CrazyBlahProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"), 1, 1, 0, 21213, true);
            assertTrue(success);

            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();

            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            ParameterSet pset;
            String responseJSON;
            Response response;

            
            pset = ParameterSet.fromArrayNoCopy(1, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(2, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SERVER_UNAVAILABLE);

            
            pset = ParameterSet.emptyParameterSet();
            responseJSON = callProcOverJSON("@Resume", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(2, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(3, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.emptyParameterSet();
            responseJSON = callProcOverJSON("@Pause", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(4, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(5, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SERVER_UNAVAILABLE);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testSimple() throws Exception {
        try {
            String simpleSchema
                    = "create table blah ("
                    + "ival bigint default 23 not null, "
                    + "sval varchar(200) default 'foo', "
                    + "dateval timestamp, "
                    + "fval float, "
                    + "decval decimal, "
                    + "PRIMARY KEY(ival));";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltDB.Configuration config = new VoltDB.Configuration();

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("blah", "ival");
            builder.addStmtProcedure("Insert", "insert into blah values (?,?,?,?,?);");
            builder.addProcedures(CrazyBlahProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"), 1, 1, 0, 21213, false);
            assertTrue(success);

            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();

            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            ParameterSet pset;
            String responseJSON;
            Response response;

            
            pset = ParameterSet.fromArrayNoCopy(1, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            responseJSON = callProcOverJSON("Insert", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status != ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    5,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    new BigDecimal(5),
                    new BigDecimal[]{},
                    new TimestampType(System.currentTimeMillis()));

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertEquals(ClientResponse.SUCCESS, response.status);

            
            JSONObject jsonObj = new JSONObject(responseJSON);
            JSONArray results = jsonObj.getJSONArray("results");
            assertEquals(4, response.results.length);
            JSONObject table = results.getJSONObject(0);
            JSONArray data = table.getJSONArray("data");
            assertEquals(1, data.length());
            JSONArray row = data.getJSONArray(0);
            assertEquals(1, row.length());
            long value = row.getLong(0);
            assertEquals(1, value);

            
            java.sql.Timestamp ts = new java.sql.Timestamp(System.currentTimeMillis());
            ts.setNanos(123456000);
            pset = ParameterSet.fromArrayNoCopy(1,
                    5,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    new BigDecimal(5),
                    new BigDecimal[]{},
                    ts.toString());

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertEquals(ClientResponse.SUCCESS, response.status);
            response.results[3].advanceRow();
            System.out.println(response.results[3].getTimestampAsTimestamp(0).getTime());
            assertEquals(123456, response.results[3].getTimestampAsTimestamp(0).getTime() % 1000000);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    VoltType.NULL_SMALLINT,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    new BigDecimal(5),
                    new BigDecimal[]{},
                    new TimestampType(System.currentTimeMillis()));

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertFalse(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    Long.MAX_VALUE - 100,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    new BigDecimal(5),
                    new BigDecimal[]{},
                    new TimestampType(System.currentTimeMillis()));

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertFalse(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    4,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    5,
                    new BigDecimal[]{},
                    new TimestampType(System.currentTimeMillis()));

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    4,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    5,
                    new BigDecimal[]{},
                    null);

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

            
            responseJSON = callProcOverJSONRaw("Procedure=@Statistics&Parameters=[TABLE]&jsonp=fooBar", 200);
            System.out.println(responseJSON);
            assertTrue(responseJSON.startsWith("fooBar("));

            
            pset = ParameterSet.fromArrayNoCopy("select * from blah");
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

            
            pset = ParameterSet.fromArrayNoCopy("insert into blah values (974599638818488300, NULL, NULL, NULL, NULL);");
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

            pset = ParameterSet.fromArrayNoCopy("select * from blah where ival = 974599638818488300;");
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);
            assertEquals(1, response.results.length);
            assertEquals(1, response.results[0].getRowCount());

            
            pset = ParameterSet.emptyParameterSet();
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            assertTrue(responseJSON.contains("Adhoc system procedure requires at least the query parameter."));

            
            pset = ParameterSet.fromArrayNoCopy("select * from blah", "foo", "bar");
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.err.println(responseJSON);
            assertTrue(responseJSON.contains("Too many actual arguments were passed for the parameters in the sql "
                    + "statement(s): (2 vs. 0)"));

        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testJapaneseNastiness() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE HELLOWORLD (\n"
                    + "    HELLO VARCHAR(15),\n"
                    + "    WORLD VARCHAR(15),\n"
                    + "    DIALECT VARCHAR(15) NOT NULL,\n"
                    + "    PRIMARY KEY (DIALECT)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("HELLOWORLD", "DIALECT");
            builder.addStmtProcedure("Insert", "insert into HELLOWORLD values (?,?,?);");
            builder.addStmtProcedure("Select", "select * from HELLOWORLD;");
            builder.addProcedures(SelectStarHelloWorld.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            String response = callProcOverJSONRaw(japaneseTestVarStrings, 200);
            Response r = responseFromJSON(response);
            assertEquals(1, r.status);

        
            
            char[] test1 = { 'a'}

            String test2 = new String(test1);

            ParameterSet pset = ParameterSet.emptyParameterSet();
            response = callProcOverJSON("Select", pset, null, null, false);
            System.out.println(response);
            System.out.println(test2);
            r = responseFromJSON(response);
            assertEquals(1, r.status);

            response = callProcOverJSON("SelectStarHelloWorld", pset, null, null, false);
            r = responseFromJSON(response);
            assertEquals(1, r.status);
            assertTrue(response.contains(test2));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testJSONAuth() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE HELLOWORLD (\n"
                    + "    HELLO VARCHAR(15),\n"
                    + "    WORLD VARCHAR(20),\n"
                    + "    DIALECT VARCHAR(15) NOT NULL,\n"
                    + "    PRIMARY KEY (DIALECT)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("HELLOWORLD", "DIALECT");

            RoleInfo gi = new RoleInfo("foo", true, false, true, true, false, false);
            builder.addRoles(new RoleInfo[]{gi});

            
            UserInfo[] ui = new UserInfo[15];
            ui[0] = new UserInfo("ry@nlikesthe", "y@nkees", new String[]{"foo"});
            for (int i = 1; i < ui.length; i++) {
                ui[i] = new UserInfo("USER" + String.valueOf(i), "PASS" + String.valueOf(i), new String[]{"foo"});
            }
            builder.addUsers(ui);

            builder.setSecurityEnabled(true, true);

            ProcedureInfo[] pi = new ProcedureInfo[2];
            pi[0] = new ProcedureInfo(new String[]{"foo"}, "Insert", "insert into HELLOWORLD values (?,?,?);", null);
            pi[1] = new ProcedureInfo(new String[]{"foo"}, "Select", "select * from HELLOWORLD;", null);
            builder.addProcedures(pi);

            builder.setHTTPDPort(8095);

            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            ParameterSet pset;

            
            for (UserInfo u : ui) {
                pset = ParameterSet.fromArrayNoCopy(u.name, u.password, u.name);
                String response = callProcOverJSON("Insert", pset, u.name, u.password, true);
                Response r = responseFromJSON(response);
                assertEquals(ClientResponse.SUCCESS, r.status);
            }
            
            for (UserInfo u : ui) {
                pset = ParameterSet.fromArrayNoCopy(u.name + "-X", u.password + "-X", u.name + "-X");
                String response = callProcOverJSON("Insert", pset, u.name, u.password, false);
                Response r = responseFromJSON(response);
                assertEquals(ClientResponse.SUCCESS, r.status);
            }

            
            UserInfo u = ui[0];
            pset = ParameterSet.fromArrayNoCopy(u.name + "-X1", u.password + "-X1", u.name + "-X1");
            String response = callProcOverJSON("Insert", pset, u.name, "ick", true);
            Response r = responseFromJSON(response);
            assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);
            response = callProcOverJSON("Insert", pset, u.name, "ick", false);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);

            
            pset = ParameterSet.fromArrayNoCopy(u.name + "-X2", u.password + "-X2", u.name + "-X2");
            String paramsInJSON = pset.toJSONString();
            HashMap<String, String> params = new HashMap<String, String>();
            params.put("Procedure", "Insert");
            params.put("Parameters", paramsInJSON);
            params.put("User", u.name);
            params.put("Password", Encoder.hexEncode(new byte[]{1, 2, 3}));
            String varString = getHTTPVarString(params);
            response = callProcOverJSONRaw(varString, 200);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);

            
            pset = ParameterSet.fromArrayNoCopy(u.name + "-X3", u.password + "-X3", u.name + "-X3");
            paramsInJSON = pset.toJSONString();
            params = new HashMap<String, String>();
            params.put("Procedure", "Insert");
            params.put("Parameters", paramsInJSON);
            params.put("User", u.name);
            params.put("Password", "abcdefghiabcdefghiabcdefghiabcdefghi");
            varString = getHTTPVarString(params);
            response = callProcOverJSONRaw(varString, 200);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);

            
            if (VoltDB.instance().getConfig().m_isEnterprise == false) {
                return;
            }

        
            
            VoltProjectBuilder builder2 = new VoltProjectBuilder();
            builder2.addSchema(schemaPath);
            builder2.addPartitionInfo("HELLOWORLD", "DIALECT");

            
            builder2.addRoles(new RoleInfo[]{gi});

            
            ui = new UserInfo[15];
            ui[0] = new UserInfo("ry@nlikesthe", "y@nkees", new String[]{"foo"});
            for (int i = 1; i < ui.length; i++) {
                ui[i] = new UserInfo("USER" + String.valueOf(i),
                        "welcomehackers" + String.valueOf(i),
                        new String[]{"foo"});
            }
            builder2.addUsers(ui);

            builder2.setSecurityEnabled(true, true);
            builder2.addProcedures(pi);
            builder2.setHTTPDPort(8095);

            success = builder2.compile(Configuration.getPathToCatalogForTest("json-update.jar"));
            assertTrue(success);

            pset = ParameterSet.fromArrayNoCopy(Encoder.hexEncode(MiscUtils.fileToBytes(new File(config.m_pathToCatalog))),
                    new String(MiscUtils.fileToBytes(new File(builder2.getPathToDeployment())), "UTF-8"));
            response = callProcOverJSON("@UpdateApplicationCatalog", pset,
                    ui[0].name, ui[0].password, true);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);

            
            for (UserInfo user : ui) {
                ParameterSet ps = ParameterSet.fromArrayNoCopy(user.name + "-X3", user.password + "-X3", user.name + "-X3");
                String respstr = callProcOverJSON("Insert", ps, user.name, user.password, false);
                Response resp = responseFromJSON(respstr);
                assertEquals(ClientResponse.SUCCESS, resp.status);
            }

            VoltProjectBuilder builder3 = new VoltProjectBuilder();
            builder3.addSchema(schemaPath);
            builder3.addPartitionInfo("HELLOWORLD", "DIALECT");

            
            builder3.addRoles(new RoleInfo[]{gi});

            ui = new UserInfo[1];
            ui[0] = new UserInfo("ry@nlikesthe",
                    "D033E22AE348AEB5660FC2140AEC35850C4DA9978C6976E5B5410415BDE908BD4DEE15DFB167A9C873FC4BB8A81F6F2AB448A918",
                    new String[]{"foo"}, false);
            builder3.addUsers(ui);

            builder3.setSecurityEnabled(true, true);
            builder3.addProcedures(pi);
            builder3.setHTTPDPort(8095);

            success = builder3.compile(Configuration.getPathToCatalogForTest("json-update.jar"));
            assertTrue(success);

            pset = ParameterSet.fromArrayNoCopy(Encoder.hexEncode(MiscUtils.fileToBytes(new File(config.m_pathToCatalog))),
                    new String(MiscUtils.fileToBytes(new File(builder3.getPathToDeployment())), "UTF-8"));
            response = callProcOverJSON("@UpdateApplicationCatalog", pset,
                    "ry@nlikesthe", "y@nkees", true);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);

            
            ParameterSet ps = ParameterSet.fromArrayNoCopy(ui[0].name + "-X4", "admin-X4", ui[0].name + "-X4");
            String respstr = callProcOverJSON("Insert", ps, ui[0].name, "admin", false);
            Response resp = responseFromJSON(respstr);
            assertEquals(ClientResponse.SUCCESS, resp.status);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testJSONDisabled() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE HELLOWORLD (\n"
                    + "    HELLO VARCHAR(15),\n"
                    + "    WORLD VARCHAR(15),\n"
                    + "    DIALECT VARCHAR(15) NOT NULL,\n"
                    + "    PRIMARY KEY (DIALECT)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("HELLOWORLD", "DIALECT");

            builder.addStmtProcedure("Insert", "insert into HELLOWORLD values (?,?,?);");

            builder.setHTTPDPort(8095);
            builder.setJSONAPIEnabled(false);

            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            ParameterSet pset = ParameterSet.fromArrayNoCopy("foo", "bar", "foobar");
            try {
                callProcOverJSON("Insert", pset, null, null, false, false, 403, ClientAuthHashScheme.HASH_SHA256); 
            } catch (Exception e) {
                
                assertTrue(e.getMessage().contains("403"));
            }
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testLongProc() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addLiteralSchema(simpleSchema);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            ParameterSet pset = ParameterSet.fromArrayNoCopy(30000);
            String response = callProcOverJSON("DelayProc", pset, null, null, false);
            Response r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testLongQuerySTring() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addLiteralSchema(simpleSchema);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            final StringBuilder b = new StringBuilder();
            b.append("Procedure=@Statistics&Parameters=[TABLE]&jsonpxx=");
            for (int i = 0; i < 450000; i++) {
                b.append(i);
            }
            
            for (int i = 0; i < 500; i++) {
                String response = callProcOverJSONRaw(b.toString(), 200);
                System.out.println(response);
                Response r = responseFromJSON(response);
                assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);
                
                ParameterSet pset = ParameterSet.fromArrayNoCopy("select * from foo");
                String responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
                System.out.println(responseJSON);
                r = responseFromJSON(responseJSON);
                System.out.println(r.statusString);
                assertEquals(ClientResponse.SUCCESS, r.status);
            }
            
            ParameterSet pset = ParameterSet.fromArrayNoCopy("select * from foo");
            String responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.out.println(responseJSON);
            Response response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testBinaryProc() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    b VARBINARY(256) DEFAULT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addLiteralSchema(simpleSchema);
            builder.addPartitionInfo("foo", "bar");
            builder.addStmtProcedure("Insert", "insert into foo values (?, ?);");
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String varString = "Procedure=Insert&Parameters=[5,\"aa\"]";
            String response = callProcOverJSONRaw(varString, 200);
            System.out.println(response);
            Response r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);

            
            varString = "Procedure=Insert&Parameters=[6,\"aaa\"]";
            response = callProcOverJSONRaw(varString, 200);
            System.out.println(response);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.GRACEFUL_FAILURE, r.status);
            varString = "Procedure=Insert&Parameters=[7,\"aaay\"]";
            response = callProcOverJSONRaw(varString, 200);
            System.out.println(response);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.GRACEFUL_FAILURE, r.status);

            
            varString = "Procedure=Insert&Parameters=[8,NULL]";
            response = callProcOverJSONRaw(varString, 200);
            System.out.println(response);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testGarbageProcs() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            callProcOverJSONRaw(getHTTPURL(null, "api/1.0/Tim"), 404);
            callProcOverJSONRaw(getHTTPURL(null, "api/1.0/Tim?Procedure=foo&Parameters=[x4{]"), 404);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testDeployment() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            
            String xdep = getUrlOverJSON("http:
            assertTrue(xdep.contains("<deployment>"));
            assertTrue(xdep.contains("</deployment>"));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testUpdateDeployment() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            
            String pdep = postUrlOverJSON("http:
            assertTrue(pdep.contains("Failed"));
            Map<String,String> params = new HashMap<>();
            params.put("deployment", jdep);
            pdep = postUrlOverJSON("http:
            assertTrue(pdep.contains("Deployment Updated"));

            
            params.put("admin", "true");
            pdep = postUrlOverJSON("http:
            assertTrue(pdep.contains("Deployment Updated"));

            ObjectMapper mapper = new ObjectMapper();
            DeploymentType deptype = mapper.readValue(jdep, DeploymentType.class);

            
            if (deptype.getHeartbeat() == null) {
                HeartbeatType hb = new HeartbeatType();
                hb.setTimeout(99);
                deptype.setHeartbeat(hb);
            } else {
                deptype.getHeartbeat().setTimeout(99);
            }
            String ndeptype = mapper.writeValueAsString(deptype);
            params.put("deployment", ndeptype);
            pdep = postUrlOverJSON("http:
            System.out.println("POST result is: " + pdep);
            assertTrue(pdep.contains("Deployment Updated"));
            jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            deptype = mapper.readValue(jdep, DeploymentType.class);
            int nto = deptype.getHeartbeat().getTimeout();
            assertEquals(99, nto);

            
            SystemSettingsType ss = deptype.getSystemsettings();
            if (ss == null) {
                ss = new SystemSettingsType();
                deptype.setSystemsettings(ss);
            }
            Query qv = ss.getQuery();
            if (qv == null) {
                qv = new Query();
                qv.setTimeout(99);
            } else {
                qv.setTimeout(99);
            }
            ss.setQuery(qv);
            deptype.setSystemsettings(ss);
            ndeptype = mapper.writeValueAsString(deptype);
            params.put("deployment", ndeptype);
            pdep = postUrlOverJSON("http:
            System.out.println("POST result is: " + pdep);
            assertTrue(pdep.contains("Deployment Updated"));
            jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            deptype = mapper.readValue(jdep, DeploymentType.class);
            nto = deptype.getSystemsettings().getQuery().getTimeout();
            assertEquals(99, nto);

            qv.setTimeout(88);
            ss.setQuery(qv);
            deptype.setSystemsettings(ss);
            ndeptype = mapper.writeValueAsString(deptype);
            params.put("deployment", ndeptype);
            pdep = postUrlOverJSON("http:
            System.out.println("POST result is: " + pdep);
            assertTrue(pdep.contains("Deployment Updated"));
            jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            deptype = mapper.readValue(jdep, DeploymentType.class);
            nto = deptype.getSystemsettings().getQuery().getTimeout();
            assertEquals(88, nto);

        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testDeploymentSecurity() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            UserInfo users[] = new UserInfo[] {
                    new UserInfo("user1", "admin", new String[] {"user"}),
                    new UserInfo("user2", "admin", new String[] {"administrator"}),
                    new UserInfo("user3", "admin", new String[] {"administrator"}), 
            };
            builder.addUsers(users);

            
            builder.setSecurityEnabled(true, false);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            
            
            
            String dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));

            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            assertTrue(dep.contains("jackson5"));
            assertTrue(dep.matches("^jackson5(.*)"));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testDeploymentSecurityAuthorizationHashed() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            UserInfo users[] = new UserInfo[] {
                    new UserInfo("user1", "admin", new String[] {"user"}),
                    new UserInfo("user2", "admin", new String[] {"administrator"}),
            };
            builder.addUsers(users);

            
            builder.setSecurityEnabled(true, false);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));

        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testDeploymentSecurityAuthorizationBasic() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            UserInfo users[] = new UserInfo[] {
                    new UserInfo("user1", "admin", new String[] {"user"}),
                    new UserInfo("user2", "admin", new String[] {"administrator"}),
            };
            builder.addUsers(users);

            
            builder.setSecurityEnabled(true, false);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testUsers() throws Exception {
        try {
            String simpleSchema
            = "CREATE TABLE foo (\n"
            + "    bar BIGINT NOT NULL,\n"
            + "    PRIMARY KEY (bar)\n"
            + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            builder.setUseDDLSchema(true);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String json = getUrlOverJSON("http:
            assertEquals(json, "");
            getUrlOverJSON("http:

            
            ObjectMapper mapper = new ObjectMapper();
            UsersType.User user = new UsersType.User();
            user.setName("foo");
            user.setPassword("foo");
            String map = mapper.writeValueAsString(user);
            Map<String,String> params = new HashMap<>();
            params.put("user", map);
            putUrlOverJSON("http:

            
            json = getUrlOverJSON("http:
            JSONArray jarray = new JSONArray(json);
            assertEquals(jarray.length(), 1);
            JSONObject jobj = jarray.getJSONObject(0);
            assertTrue(jobj.getString("id").contains("/deployment/users/foo"));
            assertTrue(jobj.getString("roles").equalsIgnoreCase("null"));

            
            user.setRoles("foo");
            map = mapper.writeValueAsString(user);
            params.put("user", map);
            postUrlOverJSON("http:

            
            json = getUrlOverJSON("http:
            jarray = new JSONArray(json);
            assertEquals(jarray.length(), 1);
            jobj = jarray.getJSONObject(0);
            assertTrue(jobj.getString("roles").equals("foo"));

            
            deleteUrlOverJSON("http:

            
            json = getUrlOverJSON("http:
            assertEquals(json, "");
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testProfile() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String dep = getUrlOverJSON("http:
            assertTrue(dep.contains("\"user\""));
            assertTrue(dep.contains("\"permissions\""));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }
}

<code block>


package org.voltdb.regressionsuites;

import java.io.File;
import java.io.IOException;
import java.util.List;

import org.voltdb.compiler.VoltProjectBuilder;


public interface VoltServerConfig {

    
    public boolean compile(VoltProjectBuilder builder);

    
    public void startUp();

    
    public void startUp(boolean clearDataDirectories);

    
    public void shutDown() throws InterruptedException;

    
    public String getListenerAddress(int hostId);

    
    public String getAdminAddress(int hostId);

    
    public List<String> getListenerAddresses();

    
    public int getListenerCount();

    
    public String getName();

    public void setCallingMethodName(String name);

    
    public int getNodeCount();

    
    public boolean isHSQL();

    
    public boolean isValgrind();

    boolean compileWithPartitionDetection(VoltProjectBuilder builder,
            String snapshotPath,
            String ppdPrefix);

    boolean compileWithAdminMode(VoltProjectBuilder builder, int adminPort,
                                 boolean adminOnStartup);

    
    public void createDirectory(File path) throws IOException;

    
    public void deleteDirectory(File path) throws IOException;

    
    public List<File> listFiles(File path) throws IOException;

    public File[] getPathInSubroots(File path) throws IOException;

    public void setMaxHeap(int max);

    
    public int getLogicalPartitionCount();
}

<code block>


package org.voltdb.regressionsuites;

import java.io.IOException;
import java.util.Random;

import junit.framework.Test;

import org.voltdb.BackendTarget;
import org.voltdb.VoltDB;
import org.voltdb.VoltTable;
import org.voltdb.VoltType;
import org.voltdb.client.Client;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.NoConnectionsException;
import org.voltdb.client.NullCallback;
import org.voltdb.client.ProcCallException;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.utils.MiscUtils;
import org.voltdb_testprocs.regressionsuites.malicious.GoSleep;

public class TestSystemProcedureSuite extends RegressionSuite {

    private static int SITES = 3;
    private static int HOSTS = MiscUtils.isPro() ? 2 : 1;
    private static int KFACTOR = MiscUtils.isPro() ? 1 : 0;
    private static boolean hasLocalServer = false;

    static final Class<?>[] PROCEDURES =
    {
     GoSleep.class
    };

    public TestSystemProcedureSuite(String name) {
        super(name);
    }

    public void testPing() throws IOException, ProcCallException {
        Client client = getClient();
        ClientResponse cr = client.callProcedure("@Ping");
        assertEquals(ClientResponse.SUCCESS, cr.getStatus());
    }

    private void checkProSysprocError(Client client, String name, int paramCount)
            throws NoConnectionsException, IOException
    {
        
        Object[] params = new Object[paramCount];
        for (int i = 0; i < paramCount; i++) {
            params[i] = i;
        }

        try {
            client.callProcedure(name, params);
            fail();
        }
        catch (ProcCallException e) {
            assertEquals(ClientResponse.GRACEFUL_FAILURE, e.getClientResponse().getStatus());
            if (!e.getClientResponse().getStatusString().contains("Enterprise Edition")) {
                System.out.println("sup");
                System.out.println("MESSAGE: " + e.getClientResponse().getStatusString());
            }
            assertTrue(e.getClientResponse().getStatusString().contains("Enterprise"));
        }
    }

    public void testProSysprocErrorOnCommunity() throws Exception {
        
        if (MiscUtils.isPro()) {
            return;
        }

        Client client = getClient();

        checkProSysprocError(client, "@SnapshotSave", 3);
        checkProSysprocError(client, "@SnapshotRestore", 2);
        checkProSysprocError(client, "@SnapshotStatus", 0);
        checkProSysprocError(client, "@SnapshotScan", 2);
        checkProSysprocError(client, "@SnapshotDelete", 2);
        
        
    }

    public void testInvalidProcedureName() throws IOException {
        Client client = getClient();
        try {
            client.callProcedure("@SomeInvalidSysProcName", "1", "2");
        }
        catch (Exception e2) {
            assertEquals("Procedure @SomeInvalidSysProcName was not found", e2.getMessage());
            return;
        }
        fail("Expected exception.");
    }

    private final String m_loggingConfig =
        "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>" +
        "<!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\">" +
        "<log4j:configuration xmlns:log4j=\"http:
            "<appender name=\"Console\" class=\"org.apache.log4j.ConsoleAppender\">" +
                "<param name=\"Target\" value=\"System.out\" />" +
                "<layout class=\"org.apache.log4j.TTCCLayout\">" +
                "</layout>" +
            "</appender>" +
            "<appender name=\"Async\" class=\"org.apache.log4j.AsyncAppender\">" +
                "<param name=\"Blocking\" value=\"true\" />" +
                "<appender-ref ref=\"Console\" /> " +
            "</appender>" +
            "<root>" +
               "<priority value=\"info\" />" +
               "<appender-ref ref=\"Async\" />" +
            "</root>" +
        "</log4j:configuration>";

    public void testUpdateLogging() throws Exception {
        Client client = getClient();
        VoltTable results[] = null;
        results = client.callProcedure("@UpdateLogging", m_loggingConfig).getResults();
        for (VoltTable result : results) {
            assertEquals( 0, result.asScalarLong());
        }
    }

    public void testPromoteMaster() throws Exception {
        Client client = getClient();
        try {
            client.callProcedure("@Promote");
            fail();
        }
        catch (ProcCallException pce) {
            assertEquals(ClientResponse.GRACEFUL_FAILURE, pce.getClientResponse().getStatus());
        }
    }

    
    
    public void testQuiesce() throws IOException, ProcCallException {
        Client client = getClient();
        VoltTable results[] = client.callProcedure("@Quiesce").getResults();
        assertEquals(1, results.length);
        results[0].advanceRow();
        assertEquals(results[0].get(0, VoltType.BIGINT), new Long(0));
    }

    public void testLoadMultipartitionTableAndIndexStatsAndValidatePartitioning() throws Exception {
        Client client = getClient();

        
        Random r = new Random(0);
        for (int ii = 0; ii < 50; ii++) {
            client.callProcedure(new NullCallback(), "@AdHoc",
                    "INSERT INTO new_order values (" + (short)(r.nextDouble() * Short.MAX_VALUE) + ");");
        }

        
        try {
            client.callProcedure("@LoadMultipartitionTable", "DOES_NOT_EXIST", null, 1);
            fail();
        } catch (ProcCallException ex) {}

        
        VoltTable partitioned_table = new VoltTable(
                new VoltTable.ColumnInfo("W_ID", org.voltdb.VoltType.SMALLINT),
                new VoltTable.ColumnInfo("W_NAME", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_STREET_1", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_STREET_2", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_CITY", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_STATE", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_ZIP", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_TAX",org.voltdb.VoltType.get((byte)8)),
                new VoltTable.ColumnInfo("W_YTD", org.voltdb.VoltType.get((byte)8))
        );

        for (int i = 1; i < 21; i++) {
            Object[] row = new Object[] {new Short((short) i),
                                         "name_" + i,
                                         "street1_" + i,
                                         "street2_" + i,
                                         "city_" + i,
                                         "ma",
                                         "zip_"  + i,
                                         new Double(i),
                                         new Double(i)};
            partitioned_table.addRow(row);
        }

        
        VoltTable replicated_table =
            new VoltTable(new VoltTable.ColumnInfo("I_ID", VoltType.INTEGER),
                          new VoltTable.ColumnInfo("I_IM_ID", VoltType.INTEGER),
                          new VoltTable.ColumnInfo("I_NAME", VoltType.STRING),
                          new VoltTable.ColumnInfo("I_PRICE", VoltType.FLOAT),
                          new VoltTable.ColumnInfo("I_DATA", VoltType.STRING));

        for (int i = 1; i < 21; i++) {
            Object[] row = new Object[] {i,
                                         i,
                                         "name_" + i,
                                         new Double(i),
                                         "data_"  + i};

            replicated_table.addRow(row);
        }

        try {
            try {
                client.callProcedure("@LoadMultipartitionTable", "WAREHOUSE",
                                 partitioned_table);
                fail();
            } catch (ProcCallException e) {}
            client.callProcedure("@LoadMultipartitionTable", "ITEM",
                                 replicated_table);

            
            int rowcount = 0;
            VoltTable results[] = client.callProcedure("@Statistics", "table", 0).getResults();
            while (rowcount != (20 * SITES * HOSTS)) {
                rowcount = 0;
                results = client.callProcedure("@Statistics", "table", 0).getResults();
                
                while(results[0].advanceRow()) {
                    if (results[0].getString("TABLE_NAME").equals("ITEM"))
                    {
                        rowcount += results[0].getLong("TUPLE_COUNT");
                    }
                }
            }

            System.out.println(results[0]);

            
            int foundItem = 0;
            results = client.callProcedure("@Statistics", "table", 0).getResults();
            while(results[0].advanceRow()) {
                if (results[0].getString("TABLE_NAME").equals("ITEM"))
                {
                    ++foundItem;
                    
                    assertEquals(20, results[0].getLong("TUPLE_COUNT"));
                }
            }
            assertEquals(MiscUtils.isPro() ? 6 : 3, foundItem);

            
            VoltTable indexStats =
                    client.callProcedure("@Statistics", "INDEX", 0).getResults()[0];
            System.out.println(indexStats);
            long memorySum = 0;
            while (indexStats.advanceRow()) {
                memorySum += indexStats.getLong("MEMORY_ESTIMATE");
            }

            
            long indexMemorySum = 0;
            for (int ii = 0; ii < 1000; ii++) {
                indexMemorySum = 0;
                indexStats = client.callProcedure("@Statistics", "MEMORY", 0).getResults()[0];
                System.out.println(indexStats);
                while (indexStats.advanceRow()) {
                    indexMemorySum += indexStats.getLong("INDEXMEMORY");
                }
                boolean success = indexMemorySum != 120;
                if (success) {
                    success = memorySum == indexMemorySum;
                    if (success) {
                        break;
                    }
                }
                Thread.sleep(1);
            }
            assertTrue(indexMemorySum != 120);
            assertEquals(memorySum, indexMemorySum);

            
            ClientResponse cr = client.callProcedure("@ValidatePartitioning", 0, null);

            VoltTable hashinatorMatches = cr.getResults()[1];
            while (hashinatorMatches.advanceRow()) {
                assertEquals(1L, hashinatorMatches.getLong("HASHINATOR_MATCHES"));
            }

            VoltTable validateResult = cr.getResults()[0];
            System.out.println(validateResult);
            while (validateResult.advanceRow()) {
                assertEquals(0L, validateResult.getLong("MISPARTITIONED_ROWS"));
            }

            
            cr = client.callProcedure("@ValidatePartitioning", 0, new byte[] { 0, 0, 0, 9 });

            hashinatorMatches = cr.getResults()[1];
            while (hashinatorMatches.advanceRow()) {
                assertEquals(0L, hashinatorMatches.getLong("HASHINATOR_MATCHES"));
            }

            validateResult = cr.getResults()[0];
            System.out.println(validateResult);
            while (validateResult.advanceRow()) {
                if (validateResult.getString("TABLE").equals("NEW_ORDER")) {
                    assertTrue(validateResult.getLong("MISPARTITIONED_ROWS") > 0);
                }
            }
        }
        catch (Exception e) {
            e.printStackTrace();
            fail();
        }
    }

    
    public void testProfCtl() throws Exception {
        Client client = getClient();

        
        
        
        ClientResponse resp = client.callProcedure("@ProfCtl", "SAMPLER_START");
        VoltTable vt = resp.getResults()[0];
        boolean foundResponse = false;
        while (vt.advanceRow()) {
            if (!vt.getString("Result").equalsIgnoreCase("sampler_start")) {
                fail();
            }
            foundResponse = true;
        }
        assertTrue(foundResponse);

        
        
        
        resp = client.callProcedure("@ProfCtl", "GPERF_ENABLE");
        vt = resp.getResults()[0];
        foundResponse = false;
        while (vt.advanceRow()) {
            if (vt.getString("Result").equalsIgnoreCase("GPERF_ENABLE")) {
                foundResponse = true;
            }
            else {
                assertTrue(vt.getString("Result").equalsIgnoreCase("GPERF_NOOP"));
            }
        }
        assertTrue(foundResponse);

        
        
        
        resp = client.callProcedure("@ProfCtl", "GPERF_DISABLE");
        vt = resp.getResults()[0];
        foundResponse = false;
        while (vt.advanceRow()) {
            if (vt.getString("Result").equalsIgnoreCase("gperf_disable")) {
                foundResponse = true;
            }
            else {
                assertTrue(vt.getString("Result").equalsIgnoreCase("GPERF_NOOP"));
            }
        }
        assertTrue(foundResponse);

        
        
        
        resp = client.callProcedure("@ProfCtl", "MakeAPony");
        vt = resp.getResults()[0];
        assertTrue(true);
    }

    public void testPause() throws Exception {
        Client client = getClient();
        VoltTable[] results = client.callProcedure("@UpdateLogging", m_loggingConfig).getResults();
        for (VoltTable result : results) {
            assertEquals(0, result.asScalarLong());
        }

        ClientResponse resp = client.callProcedure("pauseTestInsert");
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        client.callProcedure("@AdHoc", "INSERT INTO pause_test_tbl values (10);");
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());

        
        Client admin = getAdminClient();
        resp = admin.callProcedure("@Pause");
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());

        try {
            client.callProcedure("@AdHoc", "INSERT INTO pause_test_tbl values (20);");
            fail("AdHoc insert did not fail in pause mode");
        } catch(ProcCallException e) {
            assertEquals(ClientResponse.SERVER_UNAVAILABLE, e.getClientResponse().getStatus());
        }
        try {
            resp = client.callProcedure("@UpdateLogging", m_loggingConfig);
            fail();
        } catch(ProcCallException e) {
            assertEquals(ClientResponse.SERVER_UNAVAILABLE, e.getClientResponse().getStatus());
        }

        try {
            resp = client.callProcedure("pauseTestInsert");
            fail();
        } catch(ProcCallException e) {
            assertEquals(ClientResponse.SERVER_UNAVAILABLE, e.getClientResponse().getStatus());
        }

        resp = client.callProcedure("@Ping");
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        resp = client.callProcedure("@AdHoc", "SELECT COUNT(*) FROM pause_test_tbl");
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        assertEquals(2, resp.getResults()[0].asScalarLong());
        resp = client.callProcedure("pauseTestCount");
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        assertEquals(2, resp.getResults()[0].asScalarLong());

        
        resp = admin.callProcedure("@Resume");
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());

        results = client.callProcedure("@UpdateLogging", m_loggingConfig).getResults();
        for (VoltTable result : results) {
            assertEquals(0, result.asScalarLong());
        }
    }

    
    
    
    
    
    static public Test suite() throws IOException {
        VoltServerConfig config = null;

        MultiConfigSuiteBuilder builder =
            new MultiConfigSuiteBuilder(TestSystemProcedureSuite.class);

        
        
        
        VoltProjectBuilder project = new VoltProjectBuilder();
        project.addLiteralSchema(
                        "CREATE TABLE WAREHOUSE (\n" +
                        "  W_ID SMALLINT DEFAULT '0' NOT NULL,\n" +
                        "  W_NAME VARCHAR(16) DEFAULT NULL,\n" +
                        "  W_STREET_1 VARCHAR(32) DEFAULT NULL,\n" +
                        "  W_STREET_2 VARCHAR(32) DEFAULT NULL,\n" +
                        "  W_CITY VARCHAR(32) DEFAULT NULL,\n" +
                        "  W_STATE VARCHAR(2) DEFAULT NULL,\n" +
                        "  W_ZIP VARCHAR(9) DEFAULT NULL,\n" +
                        "  W_TAX FLOAT DEFAULT NULL,\n" +
                        "  W_YTD FLOAT DEFAULT NULL,\n" +
                        "  CONSTRAINT W_PK_TREE PRIMARY KEY (W_ID)\n" +
                        ");\n" +
                        "CREATE TABLE ITEM (\n" +
                        "  I_ID INTEGER DEFAULT '0' NOT NULL,\n" +
                        "  I_IM_ID INTEGER DEFAULT NULL,\n" +
                        "  I_NAME VARCHAR(32) DEFAULT NULL,\n" +
                        "  I_PRICE FLOAT DEFAULT NULL,\n" +
                        "  I_DATA VARCHAR(64) DEFAULT NULL,\n" +
                        "  CONSTRAINT I_PK_TREE PRIMARY KEY (I_ID)\n" +
                        ");\n" +
                        "CREATE TABLE NEW_ORDER (\n" +
                        "  NO_W_ID SMALLINT DEFAULT '0' NOT NULL\n" +
                        ");\n" +
                        "CREATE TABLE PAUSE_TEST_TBL (\n" +
                        "  TEST_ID SMALLINT DEFAULT '0' NOT NULL\n" +
                        ");\n");

        project.addPartitionInfo("WAREHOUSE", "W_ID");
        project.addPartitionInfo("NEW_ORDER", "NO_W_ID");
        project.addProcedures(PROCEDURES);
        project.addStmtProcedure("pauseTestCount", "SELECT COUNT(*) FROM pause_test_tbl");
        project.addStmtProcedure("pauseTestInsert", "INSERT INTO pause_test_tbl VALUES (1)");

        

        
        config = new LocalCluster("sysproc-cluster.jar", TestSystemProcedureSuite.SITES, TestSystemProcedureSuite.HOSTS, TestSystemProcedureSuite.KFACTOR,
                                  BackendTarget.NATIVE_EE_JNI);
        ((LocalCluster) config).setHasLocalServer(hasLocalServer);
        
        boolean success = config.compileWithAdminMode(project, VoltDB.DEFAULT_ADMIN_PORT, false);
        assertTrue(success);
        builder.addServerConfig(config);

        return builder;
    }
}



<code block>


package org.voltdb.regressionsuites;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import org.voltdb.BackendTarget;
import org.voltdb.ServerThread;
import org.voltdb.StartAction;
import org.voltdb.VoltDB.Configuration;
import org.voltdb.compiler.VoltProjectBuilder;


@Deprecated
public abstract class LocalSingleProcessServer implements VoltServerConfig {

    public final String m_jarFileName;
    public int m_siteCount;
    public final BackendTarget m_target;

    ServerThread m_server = null;
    boolean m_compiled = false;
    protected String m_pathToDeployment;
    private File m_pathToVoltRoot = null;
    private EEProcess m_siteProcess = null;
    private int m_adminPort;

    public LocalSingleProcessServer(String jarFileName, int siteCount,
                                    BackendTarget target)
    {
        assert(jarFileName != null);
        assert(siteCount > 0);
        m_jarFileName = Configuration.getPathToCatalogForTest(jarFileName);
        m_siteCount = siteCount;
        if (LocalCluster.isMemcheckDefined() && target.equals(BackendTarget.NATIVE_EE_JNI)) {
            m_target = BackendTarget.NATIVE_EE_VALGRIND_IPC;
        } else {
            m_target = target;
        }
    }

    @Override
    public void setCallingMethodName(String name) {
        
    }

    @Override
    public boolean compile(VoltProjectBuilder builder) {
        if (m_compiled == true) {
            return true;
        }

        m_compiled = builder.compile(m_jarFileName, m_siteCount, 1, 0);
        m_pathToDeployment = builder.getPathToDeployment();
        m_pathToVoltRoot = builder.getPathToVoltRoot();

        return m_compiled;
    }

    @Override
    public boolean compileWithPartitionDetection(VoltProjectBuilder builder, String snapshotPath, String ppdPrefix) {
        
        
        int hostCount = 1;
        int replication = 0;

        if (m_compiled) {
            return true;
        }
        m_compiled = builder.compile(m_jarFileName, m_siteCount, hostCount, replication,
                                     null, true, snapshotPath, ppdPrefix);
        m_pathToDeployment = builder.getPathToDeployment();
        m_pathToVoltRoot = builder.getPathToVoltRoot();

        return m_compiled;
    }

    @Override
    public boolean compileWithAdminMode(VoltProjectBuilder builder,
                                        int adminPort, boolean adminOnStartup)
    {
        int hostCount = 1;
        int replication = 0;

        if (m_compiled) {
            return true;
        }
        m_adminPort = adminPort;
        m_compiled = builder.compile(m_jarFileName, m_siteCount, hostCount, replication,
                                     adminPort, adminOnStartup);
        m_pathToDeployment = builder.getPathToDeployment();
        return m_compiled;

    }

    @Override
    public int getListenerCount() {
        return 1;
    }

    @Override
    public List<String> getListenerAddresses() {
        
        if (m_server == null)
            return null;
        ArrayList<String> listeners = new ArrayList<String>();
        listeners.add("localhost");
        return listeners;
    }

    @Override
    public String getListenerAddress(int hostId) {
        if (m_server == null)
            return null;
        return "localhost";
    }

    @Override
    public String getAdminAddress(int hostId) {
        if (m_server == null)
            return null;
        return "localhost:" + m_adminPort;
    }

    @Override
    public String getName() {
        

        String retval = "localSingleProcess-";
        retval += String.valueOf(m_siteCount);
        if (m_target == BackendTarget.HSQLDB_BACKEND)
            retval += "-HSQL";
        else if (m_target == BackendTarget.NATIVE_EE_IPC)
            retval += "-IPC";
        else
            retval += "-JNI";
        return retval;
    }

    @Override
    public int getNodeCount()
    {
        return 1;
    }

    @Override
    public void shutDown() throws InterruptedException {
        m_server.shutdown();
        m_siteProcess.waitForShutdown();
        if (m_target == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
            if (!EEProcess.m_valgrindErrors.isEmpty()) {
                String failString = "";
                for (final String error : EEProcess.m_valgrindErrors) {
                    failString = failString + "\n" +  error;
                }
                org.junit.Assert.fail(failString);
            }
        }
    }

    @Override
    public void startUp(boolean clearLocalDataDirectories) {
        if (clearLocalDataDirectories) {
            File exportOverflow = new File( m_pathToVoltRoot, "export_overflow");
            if (exportOverflow.exists()) {
                assert(exportOverflow.isDirectory());
                for (File f : exportOverflow.listFiles()) {
                    if (f.isFile() && f.getName().endsWith(".pbd") || f.getName().endsWith(".ad")) {
                        f.delete();
                    }
                }
            }
        }

        Configuration config = new Configuration();
        config.m_backend = m_target;
        config.m_noLoadLibVOLTDB = (m_target == BackendTarget.HSQLDB_BACKEND);
        
        config.m_pathToCatalog = m_jarFileName;
        config.m_pathToDeployment = m_pathToDeployment;
        config.m_startAction = StartAction.CREATE;

        m_siteProcess = new EEProcess(m_target, m_siteCount, "LocalSingleProcessServer.log");
        config.m_ipcPort = m_siteProcess.port();

        m_server = new ServerThread(config);
        m_server.start();
        m_server.waitForInitialization();
    }

    @Override
    public boolean isHSQL() {
        return m_target == BackendTarget.HSQLDB_BACKEND;
    }

    @Override
    public boolean isValgrind() {
        return m_target == BackendTarget.NATIVE_EE_VALGRIND_IPC;
    }
    @Override
    public void startUp() {
        startUp(true);
    }
    @Override
    public void createDirectory(File path) throws IOException {
        throw new UnsupportedOperationException();
    }
    @Override
    public void deleteDirectory(File path) throws IOException {
        throw new UnsupportedOperationException();
    }
    @Override
    public List<File> listFiles(File path) throws IOException {
        throw new UnsupportedOperationException();
    }
    @Override
    public File[] getPathInSubroots(File path) throws IOException {
        throw new UnsupportedOperationException();
    }

    @Override
    public int getLogicalPartitionCount() {
        return 1;
    }
}

<code block>

package org.voltdb.regressionsuites;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.Random;

import org.voltcore.logging.VoltLogger;
import org.voltdb.BackendTarget;
import org.voltdb.ReplicationRole;
import org.voltdb.ServerThread;
import org.voltdb.StartAction;
import org.voltdb.VoltDB;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.utils.CommandLine;
import org.voltdb.utils.MiscUtils;
import org.voltdb.utils.VoltFile;


public class LocalCluster implements VoltServerConfig {

    public enum FailureState {
        ALL_RUNNING,
        ONE_FAILURE,
        ONE_RECOVERING
    }

    
    
    public static final String clusterHostIdProperty = "__VOLTDB_CLUSTER_HOSTID__";

    private VoltLogger log = new VoltLogger("HOST");

    
    
    static final int TIMESTAMP_SALT_VARIANCE = 3;

    int getRandomTimestampSalt() {
        Random r = new Random();
        
        int retval = r.nextInt(TIMESTAMP_SALT_VARIANCE * 2 + 1);
        
        retval -= TIMESTAMP_SALT_VARIANCE;
        return retval;
    }

    
    static final long PIPE_WAIT_MAX_TIMEOUT = 60 * 1000 *2; 

    String m_callingClassName = "";
    String m_callingMethodName = "";
    boolean m_compiled = false;
    protected int m_siteCount;
    int m_hostCount;
    int m_kfactor = 0;
    protected BackendTarget m_target;
    protected String m_jarFileName;
    boolean m_running = false;
    private final boolean m_debug;
    FailureState m_failureState;
    int m_nextIPCPort = 10000;
    ArrayList<Process> m_cluster = new ArrayList<Process>();
    int perLocalClusterExtProcessIndex = 0;
    VoltProjectBuilder m_builder;
    private boolean m_expectedToCrash = false;
    private boolean m_expectedToInitialize = true;

    
    ArrayList<File> m_subRoots = new ArrayList<File>();
    public ArrayList<File> getSubRoots() {
        return m_subRoots;
    }

    boolean m_hasLocalServer = true;
    public void setHasLocalServer(boolean hasLocalServer) {
        m_hasLocalServer = hasLocalServer;
    }

    ArrayList<PipeToFile> m_pipes = null;
    ArrayList<CommandLine> m_cmdLines = null;
    ServerThread m_localServer = null;
    ProcessBuilder m_procBuilder;
    private final ArrayList<EEProcess> m_eeProcs = new ArrayList<EEProcess>();
    
    
    private Map<String, String> m_additionalProcessEnv = null;
    
    public final PortGeneratorForTest portGenerator = new PortGeneratorForTest();
    private String m_voltdbroot = "";

    private String[] m_versionOverrides = null;
    private String[] m_versionCheckRegexOverrides = null;
    private String[] m_buildStringOverrides = null;

    
    
    
    
    private final CommandLine templateCmdLine = new CommandLine(StartAction.CREATE);

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target)
    {
        this(jarFileName, siteCount, hostCount, kfactor, target, null);
    }

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target,
                        Map<String, String> env)
    {
        this(jarFileName, siteCount, hostCount, kfactor, target,
                FailureState.ALL_RUNNING, false, false, env);

    }

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target,
                        boolean isRejoinTest)
    {
        this(jarFileName, siteCount, hostCount, kfactor, target,
                FailureState.ALL_RUNNING, false, isRejoinTest, null);
    }

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target,
                        FailureState failureState,
                        boolean debug)
    {
        this(jarFileName, siteCount, hostCount, kfactor, target,
                failureState, debug, false, null);
    }

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target,
                        FailureState failureState,
                        boolean debug,
                        boolean isRejoinTest,
                        Map<String, String> env)
    {
        assert (jarFileName != null);
        assert (siteCount > 0);
        assert (hostCount > 0);

        m_additionalProcessEnv = env;
        
        StackTraceElement[] traces = Thread.currentThread().getStackTrace();
        m_callingClassName = "UnknownClass";
        m_callingMethodName = "unknownMethod";
        
        int i;
        
        for (i = 0; traces[i].getClassName().equals(getClass().getName()) == false; i++);
        
        for (;      traces[i].getClassName().equals(getClass().getName()); i++);
        
        int dot = traces[i].getClassName().lastIndexOf('.');
        m_callingClassName = traces[i].getClassName().substring(dot + 1);
        m_callingMethodName = traces[i].getMethodName();

        log.info("Instantiating LocalCluster for " + jarFileName + " with class.method: " +
                m_callingClassName + "." + m_callingMethodName);
        log.info("Sites: " + siteCount + " hosts: " + hostCount + " replication factor: " + kfactor);

        m_cluster.ensureCapacity(hostCount);

        m_siteCount = siteCount;
        m_hostCount = hostCount;
        if (kfactor > 0 && !MiscUtils.isPro()) {
            m_kfactor = 0;
        } else {
            m_kfactor = kfactor;
        }
        m_debug = debug;
        m_jarFileName = jarFileName;
        m_failureState = m_kfactor < 1 ? FailureState.ALL_RUNNING : failureState;
        m_pipes = new ArrayList<PipeToFile>();
        m_cmdLines = new ArrayList<CommandLine>();

        
        
        if (isMemcheckDefined() && (target == BackendTarget.NATIVE_EE_JNI) && m_hostCount == 1) {
            m_target = BackendTarget.NATIVE_EE_VALGRIND_IPC;
        }
        else {
            m_target = target;
        }

        String buildDir = System.getenv("VOLTDB_BUILD_DIR");  
        if (buildDir == null) {
            buildDir = System.getProperty("user.dir") + "/obj/release";
        }

        
        String java_library_path = buildDir + "/nativelibs";
        java_library_path = System.getProperty("java.library.path", java_library_path);

        String classPath = System.getProperty("java.class.path") + ":" + buildDir
            + File.separator + m_jarFileName + ":" + buildDir + File.separator + "prod";

        
        
        classPath = classPath.replace(buildDir + File.separator + "testprocs:", "");

        
        String log4j = System.getProperty("log4j.configuration");
        if (log4j == null) {
            log4j = "file:
        }

        m_procBuilder = new ProcessBuilder();

        
        
        m_procBuilder.redirectErrorStream(true);

        Thread shutdownThread = new Thread(new ShutDownHookThread());
        java.lang.Runtime.getRuntime().addShutdownHook(shutdownThread);

        
        this.templateCmdLine.
            addTestOptions(true).
            leader("").
            target(m_target).
            startCommand("create").
            jarFileName(VoltDB.Configuration.getPathToCatalogForTest(m_jarFileName)).
            buildDir(buildDir).
            javaLibraryPath(java_library_path).
            classPath(classPath).
            pathToLicense(ServerThread.getTestLicensePath()).
            log4j(log4j);
        this.templateCmdLine.m_noLoadLibVOLTDB = m_target == BackendTarget.HSQLDB_BACKEND;
        
        this.templateCmdLine.m_tag = m_callingClassName + ":" + m_callingMethodName;
    }

    
    public void overrideAnyRequestForValgrind() {
        if (templateCmdLine.m_backend == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
            m_target = BackendTarget.NATIVE_EE_JNI;
            templateCmdLine.m_backend = BackendTarget.NATIVE_EE_JNI;
        }
    }

    public void overrideStartCommandVerb(String verb) {
        if (verb == null || verb.trim().isEmpty()) return;
        this.templateCmdLine.startCommand(verb);
    }

    public void setCustomCmdLn(String customCmdLn) {
        templateCmdLine.customCmdLn(customCmdLn);
    }

    public void setJavaProperty(String property, String value) {
        templateCmdLine.setJavaProperty(property, value);
    }

    @Override
    public void setCallingMethodName(String name) {
        m_callingMethodName = name;
    }

    @Override
    public boolean compile(VoltProjectBuilder builder) {
        if (!m_compiled) {
            m_compiled = builder.compile(templateCmdLine.jarFileName(), m_siteCount, m_hostCount, m_kfactor);
            templateCmdLine.pathToDeployment(builder.getPathToDeployment());
            m_voltdbroot = builder.getPathToVoltRoot().getAbsolutePath();
        }
        return m_compiled;
    }

    @Override
    public boolean compileWithPartitionDetection(VoltProjectBuilder builder, String snapshotPath, String ppdPrefix) {
        if (!m_compiled) {
            m_compiled = builder.compile(templateCmdLine.jarFileName(), m_siteCount, m_hostCount, m_kfactor,
                    null, true, snapshotPath, ppdPrefix);
            templateCmdLine.pathToDeployment(builder.getPathToDeployment());
            m_voltdbroot = builder.getPathToVoltRoot().getAbsolutePath();
        }
        return m_compiled;
    }

    @Override
    public boolean compileWithAdminMode(VoltProjectBuilder builder, int adminPort, boolean adminOnStartup)
    {
        
        
        
        if (adminPort != VoltDB.DEFAULT_ADMIN_PORT) {
            return false;
        }

        if (!m_compiled) {
            m_compiled = builder.compile(templateCmdLine.jarFileName(), m_siteCount, m_hostCount, m_kfactor,
                    adminPort, adminOnStartup);
            templateCmdLine.pathToDeployment(builder.getPathToDeployment());
            m_voltdbroot = builder.getPathToVoltRoot().getAbsolutePath();
        }
        return m_compiled;
    }

    @Override
    public void startUp() {
        startUp(true);
    }

    @Override
    public void startUp(boolean clearLocalDataDirectories) {
        startUp(clearLocalDataDirectories, ReplicationRole.NONE);
    }

    public void setDeploymentAndVoltDBRoot(String pathToDeployment, String pathToVoltDBRoot) {
        templateCmdLine.pathToDeployment(pathToDeployment);
        m_voltdbroot = pathToVoltDBRoot;
        m_compiled = true;
    }

    public void setHostCount(int hostCount)
    {
        m_hostCount = hostCount;
        
        m_compiled = false;
    }

    void startLocalServer(int hostId, boolean clearLocalDataDirectories) {
        startLocalServer(hostId, clearLocalDataDirectories, templateCmdLine.m_startAction);
    }

    void startLocalServer(int hostId, boolean clearLocalDataDirectories, StartAction action) {
        
        File subroot = null;
        try {
        if (clearLocalDataDirectories) {
                subroot = VoltFile.initNewSubrootForThisProcess();
                m_subRoots.add(subroot);
        } else {
            if (m_subRoots.size() <= hostId) {
                m_subRoots.add(VoltFile.initNewSubrootForThisProcess());
            }
            subroot = m_subRoots.get(hostId);
        }
        } catch (IOException e) {
            throw new RuntimeException(e);
        }

        
        CommandLine cmdln = (templateCmdLine.makeCopy());
        cmdln.startCommand(action);
        cmdln.setJavaProperty(clusterHostIdProperty, String.valueOf(hostId));
        if (this.m_additionalProcessEnv != null) {
            for (String name : this.m_additionalProcessEnv.keySet()) {
                cmdln.setJavaProperty(name, this.m_additionalProcessEnv.get(name));
            }
        }

        cmdln.internalPort(portGenerator.nextInternalPort());
        cmdln.voltFilePrefix(subroot.getPath());
        cmdln.internalPort(portGenerator.nextInternalPort());
        cmdln.port(portGenerator.nextClient());
        cmdln.adminPort(portGenerator.nextAdmin());
        cmdln.zkport(portGenerator.nextZkPort());
        cmdln.httpPort(portGenerator.nextHttp());
        
        cmdln.drAgentStartPort(portGenerator.nextReplicationPort());
        portGenerator.nextReplicationPort();
        portGenerator.nextReplicationPort();
        if (m_target == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
            EEProcess proc = m_eeProcs.get(hostId);
            assert(proc != null);
            cmdln.m_ipcPort = proc.port();
        }
        if (m_target == BackendTarget.NATIVE_EE_IPC) {
            cmdln.m_ipcPort = portGenerator.next();
        }
        if ((m_versionOverrides != null) && (m_versionOverrides.length > hostId)) {
            assert(m_versionOverrides[hostId] != null);
            assert(m_versionCheckRegexOverrides[hostId] != null);
            cmdln.m_versionStringOverrideForTest = m_versionOverrides[hostId];
            cmdln.m_versionCompatibilityRegexOverrideForTest = m_versionCheckRegexOverrides[hostId];
            if ((m_buildStringOverrides != null) && (m_buildStringOverrides.length > hostId)) {
                assert(m_buildStringOverrides[hostId] != null);
                cmdln.m_buildStringOverrideForTest = m_buildStringOverrides[hostId];
            }
        }

        
        

        m_cluster.add(null);
        m_pipes.add(null);
        m_cmdLines.add(cmdln);
        m_localServer = new ServerThread(cmdln);
        m_localServer.start();
    }

    private boolean waitForAllReady()
    {
        if (!m_expectedToInitialize) {
            return true;
        }
        long startOfPipeWait = System.currentTimeMillis();
        boolean allReady = false;
        do {
            if ((System.currentTimeMillis() - startOfPipeWait) > PIPE_WAIT_MAX_TIMEOUT) {
                break;
            }

            allReady = true;
            for (PipeToFile pipeToFile : m_pipes) {
                if (pipeToFile == null) {
                    continue;
                }
                synchronized(pipeToFile) {
                    
                    if (isProcessDead(pipeToFile.getProcess())) {
                        
                        
                        return false;
                    }

                    
                    if (pipeToFile.m_eof.get()) {
                        continue;
                    }

                    
                    if (pipeToFile.m_witnessedReady.get() != true) {
                        try {
                            
                            pipeToFile.wait(250);
                        }
                        catch (InterruptedException ex) {
                            log.error(ex.toString(), ex);
                        }
                        allReady = false;
                    }
                }
            }
        } while (allReady == false);
        return allReady;
    }

    private void printTiming(boolean logtime, String msg) {
        if (logtime) {
            System.out.println("************ " + msg);
        }
    }

    public void startUp(boolean clearLocalDataDirectories, ReplicationRole role) {
        assert (!m_running);
        if (m_running) {
            return;
        }

        
        VoltDB.setDefaultTimezone();

        
        templateCmdLine.replicaMode(role);

        
        boolean logtime = false;
        long startTime = 0;
        printTiming(logtime, "Starting cluster at: " + System.currentTimeMillis());

        
        if (clearLocalDataDirectories) {
            try {
                m_subRoots.clear();
                VoltFile.deleteAllSubRoots();
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
        }

        
        
        portGenerator.reset();
        templateCmdLine.leaderPort(portGenerator.nextInternalPort());

        m_eeProcs.clear();
        for (int ii = 0; ii < m_hostCount; ii++) {
            String logfile = "LocalCluster_host_" + ii + ".log";
            m_eeProcs.add(new EEProcess(templateCmdLine.target(), m_siteCount, logfile));
        }

        m_pipes.clear();
        m_cluster.clear();
        m_cmdLines.clear();
        int oopStartIndex = 0;

        
        if (m_hasLocalServer) {
            startLocalServer(oopStartIndex, clearLocalDataDirectories);
            ++oopStartIndex;
        }

        
        for (int i = oopStartIndex; i < m_hostCount; i++) {
            startOne(i, clearLocalDataDirectories, role, StartAction.CREATE);
        }

        printTiming(logtime, "Pre-witness: " + (System.currentTimeMillis() - startTime) + "ms");
        boolean allReady = waitForAllReady();
        printTiming(logtime, "Post-witness: " + (System.currentTimeMillis() - startTime) + "ms");

        
        int downProcesses = 0;
        for (Process proc : m_cluster) {
            if ((proc != null) && (isProcessDead(proc))) {
                downProcesses++;
            }
        }

        
        if ((downProcesses > 0) || (allReady == false)) {
            
            for (Process proc : m_cluster) {
                if (proc != null) {
                    try { proc.destroy(); } catch (Exception e) {}
                }
            }

            if (downProcesses > 0) {
                int expectedProcesses = m_hostCount - (m_hasLocalServer ? 1 : 0);
                if (!m_expectedToCrash) {
                    throw new RuntimeException(
                            String.format("%d/%d external processes failed to start",
                            downProcesses, expectedProcesses));
                }
            }
            
            else if (!allReady) {
                throw new RuntimeException(
                        "One or more external processes failed to complete initialization.");
            }
        }

        
        if (m_hasLocalServer) {
            m_localServer.waitForInitialization();
        }

        printTiming(logtime, "DONE: " + (System.currentTimeMillis() - startTime) + " ms");
        m_running = true;

        
        if (m_failureState != FailureState.ALL_RUNNING) {
            killOne();
        }

        
        if (m_failureState == FailureState.ONE_RECOVERING) {
            int hostId = m_hasLocalServer ? 1 : 0;
            recoverOne(logtime, startTime, hostId);
        }
    }

    private void killOne()
    {
        log.info("Killing one cluster member.");
        int procIndex = 0;
        if (m_hasLocalServer) {
            procIndex = 1;
        }

        Process proc = m_cluster.get(procIndex);
        proc.destroy();
        int retval = 0;
        try {
            retval = proc.waitFor();
            EEProcess eeProc = m_eeProcs.get(procIndex);
            eeProc.waitForShutdown();
        } catch (InterruptedException e) {
            log.info("External VoltDB process is acting crazy.");
        } finally {
            m_cluster.set(procIndex, null);
        }
        
        if (retval != 0 && retval != 143) {
            log.info("killOne: External VoltDB process terminated abnormally with return: " + retval);
        }
    }

    private void startOne(int hostId, boolean clearLocalDataDirectories, ReplicationRole replicaMode, StartAction startAction)
    {
        PipeToFile ptf = null;
        CommandLine cmdln = (templateCmdLine.makeCopy());
        cmdln.setJavaProperty(clusterHostIdProperty, String.valueOf(hostId));
        if (this.m_additionalProcessEnv != null) {
            for (String name : this.m_additionalProcessEnv.keySet()) {
                cmdln.setJavaProperty(name, this.m_additionalProcessEnv.get(name));
            }
        }
        try {
            cmdln.internalPort(portGenerator.nextInternalPort());
            
            
            cmdln.drAgentStartPort(portGenerator.nextReplicationPort());
            portGenerator.next();
            portGenerator.next();

            
            if (m_target == BackendTarget.NATIVE_EE_IPC) {
                
                cmdln.ipcPort(portGenerator.next());
            }
            if (m_target == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
                EEProcess proc = m_eeProcs.get(hostId);
                assert(proc != null);
                cmdln.m_ipcPort = proc.port();
            }

            cmdln.port(portGenerator.nextClient());
            cmdln.adminPort(portGenerator.nextAdmin());
            cmdln.httpPort(portGenerator.nextHttp());
            cmdln.replicaMode(replicaMode);
            cmdln.timestampSalt(getRandomTimestampSalt());

            if (m_debug) {
                cmdln.debugPort(portGenerator.next());
            }

            cmdln.zkport(portGenerator.nextZkPort());

            if (startAction == StartAction.JOIN) {
                cmdln.startCommand(startAction);
                int portNoToRejoin = m_cmdLines.get(0).internalPort();
                cmdln.leader(":" + portNoToRejoin);
            }

            
            
            File subroot = null;
            if (clearLocalDataDirectories) {
                subroot = VoltFile.getNewSubroot();
                m_subRoots.add(subroot);
            } else {
                if (m_subRoots.size() <= hostId) {
                    m_subRoots.add(VoltFile.getNewSubroot());
                }
                subroot = m_subRoots.get(hostId);
            }
            cmdln.voltFilePrefix(subroot.getPath());
            cmdln.voltRoot(subroot.getPath() + "/" + m_voltdbroot);

            if ((m_versionOverrides != null) && (m_versionOverrides.length > hostId)) {
                assert(m_versionOverrides[hostId] != null);
                assert(m_versionCheckRegexOverrides[hostId] != null);
                cmdln.m_versionStringOverrideForTest = m_versionOverrides[hostId];
                cmdln.m_versionCompatibilityRegexOverrideForTest = m_versionCheckRegexOverrides[hostId];
                if ((m_buildStringOverrides != null) && (m_buildStringOverrides.length > hostId)) {
                    assert(m_buildStringOverrides[hostId] != null);
                    cmdln.m_buildStringOverrideForTest = m_buildStringOverrides[hostId];
                }
            }

            m_cmdLines.add(cmdln);
            m_procBuilder.command().clear();
            List<String> cmdlnList = cmdln.createCommandLine();
            String cmdLineFull = "Start cmd host=" + String.valueOf(hostId) + " :";
            for (String element : cmdlnList) {
                assert(element != null);
                cmdLineFull += " " + element;
            }
            log.info(cmdLineFull);
            m_procBuilder.command().addAll(cmdlnList);

            
            
            
            String testoutputdir = cmdln.buildDir() + File.separator + "testoutput";
            System.out.println("Process output will be redirected to: " + testoutputdir);
            
            File dir = new File(testoutputdir);
            if (dir.exists()) {
                assert (dir.isDirectory());
            } else {
                boolean status = dir.mkdirs();
                assert (status);
            }

            File dirFile = new VoltFile(testoutputdir);
            if (dirFile.listFiles() != null) {
                for (File f : dirFile.listFiles()) {
                    if (f.getName().startsWith(getName() + "-" + hostId)) {
                        f.delete();
                    }
                }
            }

            Process proc = m_procBuilder.start();
            m_cluster.add(proc);
            String fileName = testoutputdir
                    + File.separator
                    + "LC-"
                    + getFileName() + "-"
                    + hostId + "-"
                    + "idx" + String.valueOf(perLocalClusterExtProcessIndex++)
                    + ".txt";
            System.out.println("Process output can be found in: " + fileName);
            ptf = new PipeToFile(
                    fileName,
                    proc.getInputStream(),
                    startAction == StartAction.JOIN ? PipeToFile.m_joinToken : PipeToFile.m_initToken,
                    false,
                    proc);
            m_pipes.add(ptf);
            ptf.setName("ClusterPipe:" + String.valueOf(hostId));
            ptf.start();
        }
        catch (IOException ex) {
            log.error("Failed to start cluster process:" + ex.getMessage(), ex);
            assert (false);
        }

        if (startAction == StartAction.JOIN) {
            waitOnPTFReady(ptf, true, System.currentTimeMillis(), System.currentTimeMillis(), hostId);
        }

        if (hostId > (m_hostCount - 1)) {
            m_hostCount++;
            this.m_compiled = false; 
        }
    }

    
    private boolean isProcessDead(Process p) {
        try {
            p.exitValue();
            return true; 
        }
        catch (IllegalThreadStateException e) {
            return false; 
        }
    }

    public boolean recoverOne(int hostId, Integer portOffset, String rejoinHost, boolean liveRejoin) {
        return recoverOne(
                false,
                0,
                hostId,
                portOffset,
                rejoinHost,
                liveRejoin ? StartAction.LIVE_REJOIN : StartAction.REJOIN);
    }

    public void joinOne(int hostId) {
        startOne(hostId, true, ReplicationRole.NONE, StartAction.JOIN);
    }

    public boolean recoverOne(int hostId, Integer portOffset, String rejoinHost) {
        return recoverOne(false, 0, hostId, portOffset, rejoinHost, StartAction.REJOIN);
    }

    private boolean recoverOne(boolean logtime, long startTime, int hostId) {
        return recoverOne( logtime, startTime, hostId, null, "", StartAction.REJOIN);
    }

    
    
    private boolean recoverOne(boolean logtime, long startTime, int hostId, Integer rejoinHostId,
                               String rejoinHost, StartAction startAction) {
        
        
        
        
        if (rejoinHostId == null || m_hasLocalServer) {
            rejoinHostId = 0;
        }

        int portNoToRejoin = m_cmdLines.get(rejoinHostId).internalPort();

        if (hostId == 0 && m_hasLocalServer) {
            templateCmdLine.leaderPort(portNoToRejoin);
            startLocalServer(rejoinHostId, false, StartAction.REJOIN);
            return true;
        }

        log.info("Rejoining " + hostId + " to hostID: " + rejoinHostId);

        
        EEProcess eeProc = m_eeProcs.get(hostId);
        try {
            eeProc.waitForShutdown();
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
        if (templateCmdLine.target().isIPC) {
            String logfile = "LocalCluster_host_" + hostId + ".log";
            m_eeProcs.set(hostId, new EEProcess(templateCmdLine.target(), m_siteCount, logfile));
        }

        PipeToFile ptf = null;
        long start = 0;
        try {
            CommandLine rejoinCmdLn = m_cmdLines.get(hostId);
            
            rejoinCmdLn.javaProperties = templateCmdLine.javaProperties;
            rejoinCmdLn.startCommand(startAction);

            
            
            if (m_debug) {
                rejoinCmdLn.debugPort(portGenerator.next());
            }
            rejoinCmdLn.leader(rejoinHost + ":" + String.valueOf(portNoToRejoin));

            rejoinCmdLn.m_port = portGenerator.nextClient();
            rejoinCmdLn.m_adminPort = portGenerator.nextAdmin();
            rejoinCmdLn.m_httpPort = portGenerator.nextHttp();
            rejoinCmdLn.m_zkInterface = "127.0.0.1:" + portGenerator.next();
            rejoinCmdLn.m_internalPort = portGenerator.nextInternalPort();
            setPortsFromConfig(hostId, rejoinCmdLn);

            if ((m_versionOverrides != null) && (m_versionOverrides.length > hostId)) {
                assert(m_versionOverrides[hostId] != null);
                assert(m_versionCheckRegexOverrides[hostId] != null);
                rejoinCmdLn.m_versionStringOverrideForTest = m_versionOverrides[hostId];
                rejoinCmdLn.m_versionCompatibilityRegexOverrideForTest = m_versionCheckRegexOverrides[hostId];
                if ((m_buildStringOverrides != null) && (m_buildStringOverrides.length > hostId)) {
                    assert(m_buildStringOverrides[hostId] != null);
                    rejoinCmdLn.m_buildStringOverrideForTest = m_buildStringOverrides[hostId];
                }
            }

            List<String> rejoinCmdLnStr = rejoinCmdLn.createCommandLine();
            String cmdLineFull = "Rejoin cmd line:";
            for (String element : rejoinCmdLnStr) {
                cmdLineFull += " " + element;
            }
            log.info(cmdLineFull);

            m_procBuilder.command().clear();
            m_procBuilder.command().addAll(rejoinCmdLnStr);
            Process proc = m_procBuilder.start();
            start = System.currentTimeMillis();

            
            
            
            String testoutputdir = rejoinCmdLn.buildDir() + File.separator + "testoutput";
            
            File dir = new File(testoutputdir);
            if (dir.exists()) {
                assert(dir.isDirectory());
            }
            else {
                boolean status = dir.mkdirs();
                assert(status);
            }

            ptf = new PipeToFile(
                    testoutputdir +
                    File.separator +
                    "LC-" +
                    getFileName() + "-" +
                    hostId + "-" +
                    "idx" + String.valueOf(perLocalClusterExtProcessIndex++) +
                    ".rejoined.txt",
                    proc.getInputStream(),
                    PipeToFile.m_rejoinToken, true, proc);
            synchronized (this) {
                m_pipes.set(hostId, ptf);
                
                m_cluster.set(hostId, proc);
                m_cmdLines.set(hostId, rejoinCmdLn);
            }
            Thread t = new Thread(ptf);
            t.setName("ClusterPipe:" + String.valueOf(hostId));
            t.start();
        }
        catch (IOException ex) {
            log.error("Failed to start recovering cluster process:" + ex.getMessage(), ex);
            assert (false);
        }

        return waitOnPTFReady(ptf, logtime, startTime, start, hostId);
    }

    
    private boolean waitOnPTFReady(PipeToFile ptf, boolean logtime, long startTime, long start, int hostId) {
        
        synchronized (ptf) {
            if (logtime) System.out.println("********** pre witness: " + (System.currentTimeMillis() - startTime) + " ms");
            while (ptf.m_witnessedReady.get() != true) {
                
                if (ptf.m_eof.get()) {
                    System.out.println("PipeToFile: Reported EOF");
                    break;
                }
                
                if (isProcessDead(ptf.getProcess())) {
                    System.out.println("PipeToFile: Reported Dead Process");
                    break;
                }
                try {
                    
                    ptf.wait(1000);
                }
                catch (InterruptedException ex) {
                    log.error(ex.toString(), ex);
                }
            }
        }
        if (ptf.m_witnessedReady.get()) {
            long finish = System.currentTimeMillis();
            log.info("Took " + (finish - start) +
                     " milliseconds, time from init was " + (finish - ptf.m_initTime));
            return true;
        } else {
            log.info("Recovering process exited before recovery completed");
            try {
                silentKillSingleHost(hostId, true);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return false;
        }
    }

    @Override
    synchronized public void shutDown() throws InterruptedException {
        
        
        

        try {
            if (m_localServer != null) {
                m_localServer.shutdown();
            }
        }
        catch (Exception e) {
            log.error("Failure to shutdown LocalCluster's in-process VoltDB server.", e);
        }
        finally {
            m_running = false;
        }
        shutDownExternal();
    }

    public void killSingleHost(int hostNum) throws InterruptedException
    {
        log.info("Killing " + hostNum);
        if (hostNum == 0 && m_localServer != null) {
            m_localServer.shutdown();
        }
        else {
            silentKillSingleHost(hostNum, false);
        }
    }

    private void silentKillSingleHost(int hostNum, boolean forceKillEEProcs) throws InterruptedException {
        Process proc = null;
        
        EEProcess eeProc = null;
        PipeToFile ptf;
        synchronized (this) {
           proc = m_cluster.get(hostNum);
           
           m_cluster.set(hostNum, null);
           ptf = m_pipes.get(hostNum);
           m_pipes.set(hostNum, null);
           if (m_eeProcs.size() > hostNum) {
               eeProc = m_eeProcs.get(hostNum);
           }
        }

        if (ptf != null && ptf.m_filename != null) {
            
        }
        if (proc != null) {
            proc.destroy();
            proc.waitFor();
        }

        
        
        

        if (eeProc != null) {
            if (forceKillEEProcs) {
                eeProc.destroy();
            }
            eeProc.waitForShutdown();
        }
    }

    public void shutDownExternal() throws InterruptedException {
        shutDownExternal(false);
    }

    public synchronized void shutDownExternal(boolean forceKillEEProcs)
    {
        if (m_cluster != null) {
            
            for (Process proc : m_cluster) {
                if (proc == null)
                    continue;
                proc.destroy();
            }

            
            for (Process proc : m_cluster) {
                if (proc == null)
                    continue;
                int retval = 0;
                try {
                    retval = proc.waitFor();
                }
                catch (InterruptedException e) {
                    log.error("Unable to wait for Localcluster process to die: " + proc.toString(), e);
                }
                
                if (retval != 0 && retval != 143)
                {
                    log.error("External VoltDB process terminated abnormally with return: " + retval);
                }
            }
        }

        if (m_cluster != null) m_cluster.clear();

        for (EEProcess proc : m_eeProcs) {
            try {
                proc.waitForShutdown();
            } catch (InterruptedException e) {
                log.error("Unable to wait for EEProcess to die: " + proc.toString(), e);
            }
        }

        if (templateCmdLine.target() == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
            if (!EEProcess.m_valgrindErrors.isEmpty()) {
                String failString = "";
                for (final String error : EEProcess.m_valgrindErrors) {
                    failString = failString + "\n" + error;
                }
                org.junit.Assert.fail(failString);
            }
        }

        m_eeProcs.clear();
    }

    @Override
    public String getListenerAddress(int hostId) {
        return getListenerAddress(hostId, false);
    }

    @Override
    public String getAdminAddress(int hostId) {
        return getListenerAddress(hostId, true);
    }

    private String getListenerAddress(int hostId, boolean useAdmin) {
        if (!m_running) {
            return null;
        }
        for (int i = 0; i < m_cmdLines.size(); i++) {
            CommandLine cl = m_cmdLines.get(i);
            String hostIdStr = cl.getJavaProperty(clusterHostIdProperty);

            if (hostIdStr.equals(String.valueOf(hostId))) {
                Process p = m_cluster.get(i);
                
                if ((p != null) || (i == 0 && m_hasLocalServer)) {
                    return "localhost:" + (useAdmin ? cl.m_adminPort : cl.m_port);
                }
            }
        }
        return null;
    }

    @Override
    public int getListenerCount() {
        return m_cmdLines.size();
    }

    @Override
    public List<String> getListenerAddresses() {
        if (!m_running) {
            return null;
        }
        ArrayList<String> listeners = new ArrayList<String>();
        for (int i = 0; i < m_cmdLines.size(); i++) {
            CommandLine cl = m_cmdLines.get(i);
            Process p = m_cluster.get(i);
            
            if ((p != null) || (i == 0 && m_hasLocalServer)) {
                listeners.add("localhost:" + cl.m_port);
            }
        }
        return listeners;
    }

    @Override
    public String getName() {
        String prefix = "localCluster";
        if (m_failureState == FailureState.ONE_FAILURE)
            prefix += "OneFail";
        if (m_failureState == FailureState.ONE_RECOVERING)
            prefix += "OneRecov";
        return prefix +
            "-" + String.valueOf(m_siteCount) +
            "-" + String.valueOf(m_hostCount) +
            "-" + templateCmdLine.target().display.toUpperCase();
    }

    String getFileName() {
        String prefix = m_callingClassName + "-" + m_callingMethodName;
        if (m_failureState == FailureState.ONE_FAILURE)
            prefix += "-OneFail";
        if (m_failureState == FailureState.ONE_RECOVERING)
            prefix += "-OneRecov";
        return prefix +
            "-" + String.valueOf(m_siteCount) +
            "-" + String.valueOf(m_hostCount) +
            "-" + templateCmdLine.target().display.toUpperCase();
    }

    @Override
    public int getNodeCount()
    {
        return m_hostCount;
    }

    public boolean areAllNonLocalProcessesDead() {
        for (Process proc : m_cluster){
            try {
                if (proc != null) {
                    proc.exitValue();
                }
            }
            catch (IllegalThreadStateException ex) {
                return false;
            }
        }
        return true;
    }

    public int getLiveNodeCount()
    {
        int count = 0;
        if (m_hasLocalServer)
        {
            count++;
        }

        if (m_cluster != null)
        {
            for (Process proc : m_cluster)
            {
                try
                {
                    if (proc != null)
                    {
                        proc.exitValue();
                    }
                }
                catch (IllegalThreadStateException ex)
                {
                    
                    count++;
                }
            }
        }

        return count;
    }

    public int getBlessedPartitionDetectionProcId() {
        int currMin = Integer.MAX_VALUE;
        int currMinIdx = 0;
        for (int i = 0; i < m_pipes.size(); i++) {
            PipeToFile p = m_pipes.get(i);
            System.out.println("Index " + i + " had hostid: " + p.getHostId());
            if (p.getHostId() < currMin) {
                currMin = p.getHostId();
                currMinIdx = i;
                System.out.println("Setting index: " + i + " to blessed.");
            }
        }
        return currMinIdx;
    }

    @Override
    public void finalize() throws Throwable {
        try {
            shutDownExternal();
        }
        finally {
            super.finalize();
        }
    }

    class ShutDownHookThread implements Runnable {
        @Override
        public void run() {
            shutDownExternal(true);
        }
    }

    @Override
    public boolean isHSQL() {
        return templateCmdLine.target() == BackendTarget.HSQLDB_BACKEND;
    }

    public void setOverridesForHotfix(String[] versions, String[] regexOverrides, String[] buildStrings) {
        assert(buildStrings != null);

        m_buildStringOverrides = buildStrings;
        setOverridesForHotfix(versions, regexOverrides);
    }

    public void setOverridesForHotfix(String[] versions, String[] regexOverrides) {
        assert(versions != null);
        assert(regexOverrides != null);
        assert(versions.length == regexOverrides.length);

        m_versionOverrides = versions;
        m_versionCheckRegexOverrides = regexOverrides;
    }

    @Override
    public void setMaxHeap(int heap) {
        templateCmdLine.setMaxHeap(heap);
    }

    public String getPathToDeployment() {
        return templateCmdLine.pathToDeployment();
    }

    public String zkinterface(int hostId) {
        return m_cmdLines.get(hostId).zkinterface();
    }

    public int drAgentStartPort(int hostId) {
        return m_cmdLines.get(hostId).drAgentStartPort();
    }

    public int internalPort(int hostId) {
        return m_cmdLines.get(hostId).internalPort();
    }

    public int port(int hostId) {
        return m_cmdLines.get(hostId).port();
    }

    public int adminPort(int hostId) {
        return m_cmdLines.get(hostId).adminPort();
    }

    public void setPortsFromConfig(int hostId, VoltDB.Configuration config) {
        CommandLine cl = m_cmdLines.get(hostId);
        assert(cl != null);
        cl.m_port = config.m_port;
        cl.m_adminPort = config.m_adminPort;
        cl.m_zkInterface = config.m_zkInterface;
        cl.m_internalPort = config.m_internalPort;
        cl.m_leader = config.m_leader;
    }

    public static boolean isMemcheckDefined() {
        final String buildType = System.getenv().get("BUILD");
        if (buildType == null) {
            return false;
        }
        return buildType.toLowerCase().startsWith("memcheck");
    }

    @Override
    public boolean isValgrind() {
        return templateCmdLine.m_backend == BackendTarget.NATIVE_EE_VALGRIND_IPC;
    }

    @Override
    public void createDirectory(File path) throws IOException {
        for (File root : m_subRoots) {
            File actualPath = new File(root, path.getPath());
            if (!actualPath.mkdirs()) {
                throw new IOException();
            }
        }
    }

    @Override
    public void deleteDirectory(File path) throws IOException {
        for (File root : m_subRoots) {
            File actualPath = new File(root, path.getPath());
            VoltFile.recursivelyDelete(actualPath);
        }
    }

    @Override
    public ArrayList<File> listFiles(File path) throws IOException {
        ArrayList<File> files = new ArrayList<File>();
        for (File root : m_subRoots) {
            File actualPath = new File(root, path.getPath());
            for (File f : actualPath.listFiles()) {
                files.add(f);
            }
        }
        return files;
    }

    @Override
    public File[] getPathInSubroots(File path) throws IOException {
        File retval[] = new File[m_subRoots.size()];
        for (int ii = 0; ii < m_subRoots.size(); ii++) {
            retval[ii] = new File(m_subRoots.get(ii), path.getPath());
        }
        return retval;
    }

    
    public boolean isExpectedToCrash() {
        return m_expectedToCrash;
    }

    
    public void setExpectedToCrash(boolean expectedToCrash) {
        this.m_expectedToCrash = expectedToCrash;
    }

    
    public boolean isExpectedToInitialize() {
        return m_expectedToInitialize;
    }

    
    public void setExpectedToInitialize(boolean expectedToInitialize) {
        this.m_expectedToInitialize = expectedToInitialize;
    }

    
    public void setOutputWatcher(OutputWatcher watcher) {
        for (PipeToFile pipe : m_pipes) {
            if (pipe != null) {
                pipe.setWatcher(watcher);
            }
        }
    }

    @Override
    public int getLogicalPartitionCount() {
        return (m_siteCount * m_hostCount) / (m_kfactor + 1);
    }
}

<code block>


package org.voltdb.regressionsuites;

import java.io.IOException;
import java.net.ConnectException;
import java.nio.channels.SocketChannel;
import java.util.ArrayList;
import java.util.List;
import java.util.Random;
import java.util.regex.Pattern;

import junit.framework.TestCase;

import org.voltdb.VoltDB;
import org.voltdb.VoltTable;
import org.voltdb.VoltType;
import org.voltdb.client.Client;
import org.voltdb.client.ClientAuthHashScheme;
import org.voltdb.client.ClientConfig;
import org.voltdb.client.ClientConfigForTest;
import org.voltdb.client.ClientFactory;
import org.voltdb.client.ConnectionUtil;
import org.voltdb.client.ProcCallException;
import org.voltdb.common.Constants;

import com.google_voltpatches.common.net.HostAndPort;


public class RegressionSuite extends TestCase {

    protected VoltServerConfig m_config;
    protected String m_username = "default";
    protected String m_password = "password";
    private final ArrayList<Client> m_clients = new ArrayList<Client>();
    private final ArrayList<SocketChannel> m_clientChannels = new ArrayList<SocketChannel>();
    protected final String m_methodName;

    
    public RegressionSuite(final String name) {
        super(name);
        m_methodName = name;
    }

    
    @Override
    public void setUp() throws Exception {
        
        m_config.setCallingMethodName(m_methodName);
        m_config.startUp(true);
    }

    
    @Override
    public void tearDown() throws Exception {
        m_config.shutDown();
        for (final Client c : m_clients) {
            c.close();
        }
        synchronized (m_clientChannels) {
            for (final SocketChannel sc : m_clientChannels) {
                try {
                    ConnectionUtil.closeConnection(sc);
                } catch (final IOException e) {
                    e.printStackTrace();
                }
            }
            m_clientChannels.clear();
        }
        m_clients.clear();
    }

    
    public boolean isHSQL() {
        return m_config.isHSQL();
    }

    
    public int getLogicalPartitionCount() {
        return m_config.getLogicalPartitionCount();
    }

    
    public boolean isValgrind() {
        return m_config.isValgrind();
    }

    public boolean isLocalCluster() {
        return m_config instanceof LocalCluster;
    }

    
    public final VoltServerConfig getServerConfig() {
        return m_config;
    }

    public Client getAdminClient() throws IOException {
        return getClient(1000 * 60 * 10, ClientAuthHashScheme.HASH_SHA256, true); 
    }

    public Client getClient() throws IOException {
        return getClient(1000 * 60 * 10, ClientAuthHashScheme.HASH_SHA256); 
    }

    public Client getClient(ClientAuthHashScheme scheme) throws IOException {
        return getClient(1000 * 60 * 10, scheme); 
    }

    public Client getClientToHostId(int hostId) throws IOException {
        return getClientToHostId(hostId, 1000 * 60 * 10); 
    }

    public Client getFullyConnectedClient() throws IOException {
        return getFullyConnectedClient(1000 * 60 * 10); 
    }

    
    public Client getClient(long timeout) throws IOException {
        return getClient(timeout, ClientAuthHashScheme.HASH_SHA256);
    }

    
    public Client getClient(long timeout, ClientAuthHashScheme scheme) throws IOException {
        return getClient(timeout, scheme, false);
    }

    public Client getClient(long timeout, ClientAuthHashScheme scheme, boolean useAdmin) throws IOException {
        final Random r = new Random();
        String listener = null;
        if (useAdmin) {
            listener = m_config.getAdminAddress(r.nextInt(m_config.getListenerCount()));
        } else {
            listener = m_config.getListenerAddress(r.nextInt(m_config.getListenerCount()));
        }
        ClientConfig config = new ClientConfigForTest(m_username, m_password, scheme);
        config.setConnectionResponseTimeout(timeout);
        config.setProcedureCallTimeout(timeout);
        final Client client = ClientFactory.createClient(config);
        
        try {
            client.createConnection(listener);
        }
        
        catch (ConnectException e) {
            if (useAdmin) {
                listener = m_config.getAdminAddress(r.nextInt(m_config.getListenerCount()));
            } else {
                listener = m_config.getListenerAddress(r.nextInt(m_config.getListenerCount()));
            }
            client.createConnection(listener);
        }
        m_clients.add(client);
        return client;
    }

    
    public Client getClientSha1(long timeout) throws IOException {
        final List<String> listeners = m_config.getListenerAddresses();
        final Random r = new Random();
        String listener = listeners.get(r.nextInt(listeners.size()));
        ClientConfig config = new ClientConfigForTest(m_username, m_password, ClientAuthHashScheme.HASH_SHA1);
        config.setConnectionResponseTimeout(timeout);
        config.setProcedureCallTimeout(timeout);
        final Client client = ClientFactory.createClient(config);
        
        try {
            client.createConnection(listener);
        }
        
        catch (ConnectException e) {
            listener = listeners.get(r.nextInt(listeners.size()));
            client.createConnection(listener);
        }
        m_clients.add(client);
        return client;
    }

    
    public Client getClientToHostId(int hostId, long timeout) throws IOException {
        final String listener = m_config.getListenerAddress(hostId);
        ClientConfig config = new ClientConfigForTest(m_username, m_password);
        config.setConnectionResponseTimeout(timeout);
        config.setProcedureCallTimeout(timeout);
        final Client client = ClientFactory.createClient(config);
        try {
            client.createConnection(listener);
        }
        
        catch (ConnectException e) {
            client.createConnection(listener);
        }
        m_clients.add(client);
        return client;
    }

    public Client getFullyConnectedClient(long timeout) throws IOException {
        final List<String> listeners = m_config.getListenerAddresses();
        final Random r = new Random();
        ClientConfig config = new ClientConfigForTest(m_username, m_password);
        config.setConnectionResponseTimeout(timeout);
        config.setProcedureCallTimeout(timeout);
        final Client client = ClientFactory.createClient(config);
        for (String listener : listeners) {
            
            try {
                client.createConnection(listener);
            }
            
            catch (ConnectException e) {
                listener = listeners.get(r.nextInt(listeners.size()));
                client.createConnection(listener);
            }
        }
        m_clients.add(client);
        return client;
    }

    
    public void releaseClient(Client c) throws IOException, InterruptedException {
        boolean removed = m_clients.remove(c);
        assert(removed);
        c.close();
    }

    
    public SocketChannel getClientChannel() throws IOException {
        return getClientChannel(false);
    }
    public SocketChannel getClientChannel(final boolean noTearDown) throws IOException {
        final List<String> listeners = m_config.getListenerAddresses();
        final Random r = new Random();
        final String listener = listeners.get(r.nextInt(listeners.size()));
        byte[] hashedPassword = ConnectionUtil.getHashedPassword(m_password);
        HostAndPort hNp = HostAndPort.fromString(listener);
        int port = Constants.DEFAULT_PORT;
        if (hNp.hasPort()) {
            port = hNp.getPort();
        }
        final SocketChannel channel = (SocketChannel)
            ConnectionUtil.getAuthenticatedConnection(
                    hNp.getHostText(), m_username, hashedPassword, port, null, ClientAuthHashScheme.getByUnencodedLength(hashedPassword.length))[0];
        channel.configureBlocking(true);
        if (!noTearDown) {
            synchronized (m_clientChannels) {
                m_clientChannels.add(channel);
            }
        }
        return channel;
    }

    
    void setConfig(final VoltServerConfig config) {
        m_config = config;
    }


    @Override
    public String getName() {
        
        return super.getName() + "-" + m_config.getName();
    }

    
    public int port(int hostId) {
        return isLocalCluster() ? ((LocalCluster)m_config).port(hostId) : VoltDB.DEFAULT_PORT+hostId;
    }

    
    public int adminPort(int hostId) {
        return isLocalCluster() ? ((LocalCluster)m_config).adminPort(hostId) : VoltDB.DEFAULT_ADMIN_PORT+hostId;
    }

    
    public int internalPort(int hostId) {
        return isLocalCluster() ? ((LocalCluster)m_config).internalPort(hostId) : VoltDB.DEFAULT_INTERNAL_PORT+hostId;
    }

    static public void validateTableOfLongs(Client c, String sql, long[][] expected)
            throws Exception, IOException, ProcCallException {
        assertNotNull(expected);
        VoltTable vt = c.callProcedure("@AdHoc", sql).getResults()[0];
        validateTableOfLongs(vt, expected);
    }

    static public void validateTableOfScalarLongs(VoltTable vt, long[] expected) {
        assertNotNull(expected);
        assertEquals("Different number of rows! ", expected.length, vt.getRowCount());
        int len = expected.length;
        for (int i=0; i < len; i++) {
            validateRowOfLongs(vt, new long[] {expected[i]});
        }
    }

    static public void validateTableOfScalarLongs(Client client, String sql, long[] expected) throws Exception {
        assertNotNull(expected);
        VoltTable vt = client.callProcedure("@AdHoc", sql).getResults()[0];
        validateTableOfScalarLongs(vt, expected);
    }

    static public void validateTableOfLongs(VoltTable vt, long[][] expected) {
        assertNotNull(expected);
        assertEquals("Wrong number of rows in table.  ",
                        expected.length, vt.getRowCount());
        int len = expected.length;
        for (int i=0; i < len; i++) {
            validateRowOfLongs("at row " + i + ", ", vt, expected[i]);
        }
    }

    static public void validateRowOfLongs(String messagePrefix, VoltTable vt, long [] expected) {
        int len = expected.length;
        assertTrue(vt.advanceRow());
        for (int i=0; i < len; i++) {
            long actual = -10000000;
            
            try {
                actual = vt.getLong(i);
            } catch (IllegalArgumentException ex) {
                try {
                    actual = (long) vt.getDouble(i);
                } catch (IllegalArgumentException newEx) {
                    try {
                        actual = vt.getTimestampAsLong(i);
                    } catch (IllegalArgumentException exTm) {
                        try {
                            actual = vt.getDecimalAsBigDecimal(i).longValueExact();
                        } catch (IllegalArgumentException newerEx) {
                            newerEx.printStackTrace();
                            fail();
                        }
                    } catch (ArithmeticException newestEx) {
                        newestEx.printStackTrace();
                        fail();
                    }
                }
            }

            String message = "at column " + i +", ";
            if (messagePrefix != null) {
                message = messagePrefix + message;
            }

            
            if (expected[i] != Long.MIN_VALUE) {
                assertEquals(message, expected[i], actual);
            } else {
                VoltType type = vt.getColumnType(i);
                assertEquals(message + "expected null: ", Long.parseLong(type.getNullValue().toString()), actual);
            }
        }
    }

    static public void validateRowOfLongs(VoltTable vt, long [] expected) {
        validateRowOfLongs(null, vt, expected);
    }

    static public void validateTableColumnOfScalarVarchar(VoltTable vt, String[] expected) {
        validateTableColumnOfScalarVarchar(vt, 0, expected);
    }

    static public void validateTableColumnOfScalarVarchar(VoltTable vt, int col, String[] expected) {
        assertNotNull(expected);
        assertEquals(expected.length, vt.getRowCount());
        int len = expected.length;
        for (int i=0; i < len; i++) {
            assertTrue(vt.advanceRow());
            if (expected[i] == null) {
                String actual = vt.getString(col);
                assertTrue(vt.wasNull());
                assertEquals(null, actual);
            } else {
                assertEquals(expected[i], vt.getString(col));
            }
        }
    }

    public void assertTablesAreEqual(String prefix, VoltTable expectedRows, VoltTable actualRows) {
        assertEquals(prefix + "column count mismatch.  Expected: " + expectedRows.getColumnCount() + " actual: " + actualRows.getColumnCount(),
                expectedRows.getColumnCount(), actualRows.getColumnCount());

        int i = 0;
        while(expectedRows.advanceRow()) {
            assertTrue(prefix + "too few actual rows; expected more than " + (i + 1), actualRows.advanceRow());

            for (int j = 0; j < actualRows.getColumnCount(); j++) {
                String columnName = actualRows.getColumnName(j);
                String colPrefix = prefix + "row " + i + ": column: " + columnName + ": ";
                VoltType actualTy = actualRows.getColumnType(j);
                VoltType expectedTy = expectedRows.getColumnType(j);
                assertEquals(colPrefix + "type mismatch", expectedTy, actualTy);

                Object expectedObj = expectedRows.get(j,  expectedTy);
                Object actualObj = expectedRows.get(j,  actualTy);
                assertEquals(colPrefix + "values not equal: expected: " + expectedObj + ", actual: " + actualObj,
                        expectedObj, actualObj);
            }

            i++;
        }
        assertFalse(prefix + "too many actual rows; expected only " + i, actualRows.advanceRow());
    }

    static public void verifyStmtFails(Client client, String stmt, String expectedPattern) throws IOException {
        verifyProcFails(client, expectedPattern, "@AdHoc", stmt);
    }

    static public void verifyAdHocFails(Client client, String expectedPattern, Object... args) throws IOException {
        verifyProcFails(client, expectedPattern, "@AdHoc", args);
    }

    static public void verifyProcFails(Client client, String expectedPattern, String storedProc, Object... args) throws IOException {

        String what;
        if (storedProc.compareTo("@AdHoc") == 0) {
            what = "the statement \"" + args[0] + "\"";
        }
        else {
            what = "the stored procedure \"" + storedProc + "\"";
        }

        try {
            client.callProcedure(storedProc, args);
        }
        catch (ProcCallException pce) {
            String msg = pce.getMessage();
            String diagnostic = "Expected " + what + " to throw an exception matching the pattern \"" +
                    expectedPattern + "\", but instead it threw an exception containing \"" + msg + "\".";
            Pattern pattern = Pattern.compile(expectedPattern, Pattern.MULTILINE);
            assertTrue(diagnostic, pattern.matcher(msg).find());
            return;
        }

        String diagnostic = "Expected " + what + " to throw an exception matching the pattern \"" +
                expectedPattern + "\", but instead it threw nothing.";
        fail(diagnostic);
    }


    
    
    
    
    static public void validateSchema(VoltTable result, VoltTable expected)
    {
        assertEquals(expected.getColumnCount(), result.getColumnCount());
        for (int i = 0; i < result.getColumnCount(); i++) {
            assertEquals("Failed name column: " + i, expected.getColumnName(i), result.getColumnName(i));
            assertEquals("Failed type column: " + i, expected.getColumnType(i), result.getColumnType(i));
        }
    }

    static public void validStatisticsForTableLimit(Client client, String tableName, long limit) throws Exception {
        validStatisticsForTableLimitAndPercentage(client, tableName, limit, -1);
    }

    static public void validStatisticsForTableLimitAndPercentage(Client client, String tableName, long limit, long percentage) throws Exception {
        long start = System.currentTimeMillis();
        while (true) {
            long lastLimit =-1, lastPercentage = -1;
            Thread.sleep(1000);
            if (System.currentTimeMillis() - start > 10000) {
                String percentageStr = "";
                if (percentage >= 0) {
                    percentageStr = ", last seen percentage: " + lastPercentage;
                }
                fail("Took too long or have wrong answers: last seen limit: " + lastLimit + percentageStr);
            }

            VoltTable[] results = client.callProcedure("@Statistics", "TABLE", 0).getResults();
            for (VoltTable t: results) { System.out.println(t.toString()); }
            if (results[0].getRowCount() == 0) continue;

            boolean foundTargetTuple = false;
            boolean limitExpected = false;
            boolean percentageExpected = percentage < 0 ? true: false;

            for (VoltTable vt: results) {
                while(vt.advanceRow()) {
                    String name = vt.getString("TABLE_NAME");
                    if (tableName.equals(name)) {
                        foundTargetTuple = true;
                        lastLimit = vt.getLong("TUPLE_LIMIT");
                        if (limit == lastLimit) {
                            limitExpected = true;
                        }
                        if (percentageExpected || percentage == (lastPercentage = vt.getLong("PERCENT_FULL")) ) {
                            percentageExpected = true;
                        }

                        if (limitExpected && percentageExpected) return;
                        break;
                    }
                }
                if (foundTargetTuple) break;
            }
        }
    }

    static public void checkDeploymentPropertyValue(Client client, String key, String value)
            throws IOException, ProcCallException, InterruptedException {
        boolean found = false;

        VoltTable result = client.callProcedure("@SystemInformation", "DEPLOYMENT").getResults()[0];
        while (result.advanceRow()) {
            if (result.getString("PROPERTY").equalsIgnoreCase(key)) {
                found = true;
                assertEquals(value, result.getString("VALUE"));
                break;
            }
        }
        assertTrue(found);
    }

    static public void checkQueryPlan(Client client, String query, String...patterns) throws Exception {
        VoltTable vt;
        assert(patterns.length >= 1);

        vt = client.callProcedure("@Explain", query).getResults()[0];
        String vtStr = vt.toString();

        for (String pattern : patterns) {
            assertTrue(vtStr.contains(pattern));
        }
    }
}

<code block>


package org.voltdb;

import java.io.IOException;
import java.io.PrintWriter;
import java.io.StringWriter;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.AsynchronousCloseException;
import java.nio.channels.SelectionKey;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.concurrent.Callable;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.FutureTask;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;

import org.HdrHistogram_voltpatches.AbstractHistogram;
import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.json_voltpatches.JSONObject;
import org.voltcore.logging.Level;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.BinaryPayloadMessage;
import org.voltcore.messaging.ForeignHost;
import org.voltcore.messaging.HostMessenger;
import org.voltcore.messaging.LocalObjectMessage;
import org.voltcore.messaging.Mailbox;
import org.voltcore.messaging.VoltMessage;
import org.voltcore.network.Connection;
import org.voltcore.network.InputHandler;
import org.voltcore.network.NIOReadStream;
import org.voltcore.network.QueueMonitor;
import org.voltcore.network.ReverseDNSPolicy;
import org.voltcore.network.VoltNetworkPool;
import org.voltcore.network.VoltPort;
import org.voltcore.network.VoltProtocolHandler;
import org.voltcore.network.WriteStream;
import org.voltcore.utils.CoreUtils;
import org.voltcore.utils.DeferredSerialization;
import org.voltcore.utils.EstTime;
import org.voltcore.utils.Pair;
import org.voltcore.utils.RateLimitedLogger;
import org.voltdb.AuthSystem.AuthProvider;
import org.voltdb.AuthSystem.AuthUser;
import org.voltdb.CatalogContext.ProcedurePartitionInfo;
import org.voltdb.ClientInterfaceHandleManager.Iv2InFlight;
import org.voltdb.SystemProcedureCatalog.Config;
import org.voltdb.VoltTable.ColumnInfo;
import org.voltdb.catalog.CatalogMap;
import org.voltdb.catalog.Column;
import org.voltdb.catalog.Database;
import org.voltdb.catalog.Procedure;
import org.voltdb.catalog.SnapshotSchedule;
import org.voltdb.catalog.Statement;
import org.voltdb.catalog.Table;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureInvocationType;
import org.voltdb.common.Constants;
import org.voltdb.compiler.AdHocPlannedStatement;
import org.voltdb.compiler.AdHocPlannedStmtBatch;
import org.voltdb.compiler.AdHocPlannerWork;
import org.voltdb.compiler.AsyncCompilerResult;
import org.voltdb.compiler.AsyncCompilerWork.AsyncCompilerWorkCompletionHandler;
import org.voltdb.compiler.CatalogChangeResult;
import org.voltdb.compiler.CatalogChangeWork;
import org.voltdb.dtxn.InitiatorStats.InvocationInfo;
import org.voltdb.iv2.Cartographer;
import org.voltdb.iv2.Iv2Trace;
import org.voltdb.iv2.MpInitiator;
import org.voltdb.messaging.FastDeserializer;
import org.voltdb.messaging.InitiateResponseMessage;
import org.voltdb.messaging.Iv2EndOfLogMessage;
import org.voltdb.messaging.Iv2InitiateTaskMessage;
import org.voltdb.messaging.LocalMailbox;
import org.voltdb.messaging.MultiPartitionParticipantMessage;
import org.voltdb.parser.SQLLexer;
import org.voltdb.security.AuthenticationRequest;
import org.voltdb.sysprocs.saverestore.SnapshotUtil;
import org.voltdb.utils.Encoder;
import org.voltdb.utils.MiscUtils;

import com.google_voltpatches.common.base.Charsets;
import com.google_voltpatches.common.base.Predicate;
import com.google_voltpatches.common.base.Supplier;
import com.google_voltpatches.common.base.Throwables;
import com.google_voltpatches.common.collect.ImmutableMap;
import com.google_voltpatches.common.util.concurrent.ListenableFuture;
import com.google_voltpatches.common.util.concurrent.ListenableFutureTask;
import org.voltdb.client.ClientAuthHashScheme;


public class ClientInterface implements SnapshotDaemon.DaemonInitiator {

    static long TOPOLOGY_CHANGE_CHECK_MS = Long.getLong("TOPOLOGY_CHANGE_CHECK_MS", 5000);
    static long AUTH_TIMEOUT_MS = Long.getLong("AUTH_TIMEOUT_MS", 30000);

    
    public static final long ASYNC_TOPO_HANDLE = Long.MAX_VALUE - 1;

    
    public static final byte AUTHENTICATION_FAILURE = Constants.AUTHENTICATION_FAILURE;
    public static final byte MAX_CONNECTIONS_LIMIT_ERROR = Constants.MAX_CONNECTIONS_LIMIT_ERROR;
    public static final byte WIRE_PROTOCOL_TIMEOUT_ERROR = Constants.WIRE_PROTOCOL_TIMEOUT_ERROR;
    public static final byte WIRE_PROTOCOL_FORMAT_ERROR = Constants.WIRE_PROTOCOL_FORMAT_ERROR;
    public static final byte AUTHENTICATION_FAILURE_DUE_TO_REJOIN = Constants.AUTHENTICATION_FAILURE_DUE_TO_REJOIN;
    public static final byte EXPORT_DISABLED_REJECTION = Constants.EXPORT_DISABLED_REJECTION;

    
    public static final byte AUTH_HANDSHAKE_VERSION = Constants.AUTH_HANDSHAKE_VERSION;
    public static final byte AUTH_SERVICE_NAME = Constants.AUTH_SERVICE_NAME;
    public static final byte AUTH_HANDSHAKE = Constants.AUTH_HANDSHAKE;

    
    public static final long RESTORE_AGENT_CID          = Long.MIN_VALUE + 1;
    public static final long SNAPSHOT_UTIL_CID          = Long.MIN_VALUE + 2;
    public static final long ELASTIC_JOIN_CID           = Long.MIN_VALUE + 3;
    public static final long DR_REPLICATION_CID         = Long.MIN_VALUE + 4;
    public static final long IMPORTER_CID               = Long.MIN_VALUE + 5;
    
    public static final long CL_REPLAY_BASE_CID         = Long.MIN_VALUE + 100;

    private static final VoltLogger log = new VoltLogger(ClientInterface.class.getName());
    private static final VoltLogger authLog = new VoltLogger("AUTH");
    private static final VoltLogger hostLog = new VoltLogger("HOST");
    private static final VoltLogger networkLog = new VoltLogger("NETWORK");

    
    public enum ExplainMode {
        NONE, EXPLAIN_ADHOC, EXPLAIN_DEFAULT_PROC;
    }

    private final ClientAcceptor m_acceptor;
    private ClientAcceptor m_adminAcceptor;

    private final SnapshotDaemon m_snapshotDaemon = new SnapshotDaemon();
    private final SnapshotDaemonAdapter m_snapshotDaemonAdapter = new SnapshotDaemonAdapter();

    
    private final AtomicReference<CatalogContext> m_catalogContext = new AtomicReference<CatalogContext>(null);

    
    private final AtomicInteger m_numConnections = new AtomicInteger(0);

    
    ZooKeeper m_zk;

    
    private final ConcurrentHashMap<Long, ClientInterfaceHandleManager> m_cihm =
            new ConcurrentHashMap<Long, ClientInterfaceHandleManager>(2048, .75f, 128);

    private final RateLimitedClientNotifier m_notifier = new RateLimitedClientNotifier();

    private final Cartographer m_cartographer;


    
    private final PermissionValidator m_permissionValidator = new PermissionValidator();
    
    private final InvocationValidator m_invocationValidator;

    
    private final  AsyncCompilerWorkCompletionHandler m_adhocCompletionHandler = new AsyncCompilerWorkCompletionHandler() {
        @Override
        public void onCompletion(AsyncCompilerResult result) {
            processFinishedCompilerWork(result);
        }
    };

    
    private final CopyOnWriteArrayList<AdmissionControlGroup> m_allACGs =
            new CopyOnWriteArrayList<AdmissionControlGroup>();

    
    private final ThreadLocal<AdmissionControlGroup> m_acg = new ThreadLocal<AdmissionControlGroup>() {
        @Override
        public AdmissionControlGroup initialValue() {
            AdmissionControlGroup acg = new AdmissionControlGroup( 1024 * 1024 * 8, 1000);
            m_allACGs.add(acg);
            return acg;
        }
    };

    
    private final int m_allPartitions[];
    private ImmutableMap<Integer, Long> m_localReplicas = ImmutableMap.<Integer, Long>builder().build();
    final long m_siteId;
    final long m_plannerSiteId;

    final Mailbox m_mailbox;

    
    private final boolean m_hasDTXNBackPressure = false;

    
    private final AtomicInteger MAX_CONNECTIONS = new AtomicInteger(800);
    private ScheduledFuture<?> m_maxConnectionUpdater;

    private final boolean m_isConfiguredForHSQL;

    
    public class ClientAcceptor implements Runnable {
        private final int m_port;
        private final ServerSocketChannel m_serverSocket;
        private final VoltNetworkPool m_network;
        private volatile boolean m_running = true;
        private Thread m_thread = null;
        private final boolean m_isAdmin;
        private final InetAddress m_interface;

        
        private final ExecutorService m_executor = CoreUtils.getBoundedThreadPoolExecutor(128, 10L, TimeUnit.SECONDS,
                        CoreUtils.getThreadFactory("Client authentication threads", "Client authenticator"));

        ClientAcceptor(InetAddress intf, int port, VoltNetworkPool network, boolean isAdmin)
        {
            m_interface = intf;
            m_network = network;
            m_port = port;
            m_isAdmin = isAdmin;
            ServerSocketChannel socket;
            try {
                socket = ServerSocketChannel.open();
            } catch (IOException e) {
                if (m_isAdmin) {
                    hostLog.fatal("Failed to open admin wire protocol listener on port "
                            + m_port + "(" + e.getMessage() + ")");
                }
                else {
                    hostLog.fatal("Failed to open native wire protocol listener on port "
                            + m_port + "(" + e.getMessage() + ")");
                }
                throw new RuntimeException(e);
            }
            m_serverSocket = socket;
        }

        public void start() throws IOException {
            if (m_thread != null) {
                throw new IllegalStateException("A thread for this ClientAcceptor is already running");
            }
            if (!m_serverSocket.socket().isBound()) {
                try {
                    if (m_interface != null) {
                        m_serverSocket.socket().bind(new InetSocketAddress(m_interface, m_port));
                    } else {
                        m_serverSocket.socket().bind(new InetSocketAddress(m_port));
                    }
                }
                catch (IOException e) {
                    String msg = "Client interface failed to bind to"
                            + (m_isAdmin ? " Admin " : " ") + "port: " + m_port;
                    MiscUtils.printPortsInUse(hostLog);
                    VoltDB.crashLocalVoltDB(msg, false, e);
                }
            }
            m_running = true;
            String threadName = m_isAdmin ? "AdminPort connection acceptor" : "ClientPort connection acceptor";
            m_thread = new Thread( null, this, threadName, 262144);
            m_thread.setDaemon(true);
            m_thread.start();
        }

        public void shutdown() throws InterruptedException {
            
            if (m_thread != null) {
                synchronized (this) {
                    m_running = false;
                    m_thread.interrupt();
                }
                m_thread.join();
            }
        }

        
        class AuthRunnable implements Runnable {
            final SocketChannel m_socket;

            AuthRunnable(SocketChannel socket) {
                this.m_socket = socket;
            }

            @Override
            public void run() {
                if (m_socket != null) {
                    boolean success = false;
                    
                    AtomicReference<String> timeoutRef = new AtomicReference<String>();
                    try {
                        final InputHandler handler = authenticate(m_socket, timeoutRef);
                        if (handler != null) {
                            m_socket.configureBlocking(false);
                            if (handler instanceof ClientInputHandler) {
                                m_socket.socket().setTcpNoDelay(true);
                            }
                            m_socket.socket().setKeepAlive(true);

                            if (handler instanceof ClientInputHandler) {
                                m_network.registerChannel(
                                                m_socket,
                                                handler,
                                                0,
                                                ReverseDNSPolicy.ASYNCHRONOUS);
                                
                            } else {
                                m_network.registerChannel(
                                        m_socket,
                                        handler,
                                        SelectionKey.OP_READ,
                                        ReverseDNSPolicy.ASYNCHRONOUS);
                            }
                            success = true;
                        }
                    } catch (Exception e) {
                        try {
                            m_socket.close();
                        } catch (IOException e1) {
                            
                        }
                        if (m_running) {
                            if (timeoutRef.get() != null) {
                                hostLog.warn(timeoutRef.get());
                            } else {
                                hostLog.warn("Exception authenticating and "
                                        + "registering user in ClientAcceptor", e);
                            }
                        }
                    } finally {
                        if (!success) {
                            m_numConnections.decrementAndGet();
                        }
                    }
                }
            }
        }

        @Override
        public void run() {
            try {
                do {
                    final SocketChannel socket;
                    try
                    {
                        socket = m_serverSocket.accept();
                    }
                    catch (IOException ioe)
                    {
                        if (ioe.getMessage() != null &&
                            ioe.getMessage().contains("Too many open files"))
                        {
                            networkLog.warn("Rejected accepting new connection due to too many open files");
                            continue;
                        }
                        else
                        {
                            throw ioe;
                        }
                    }

                    
                    if (m_numConnections.get() >= MAX_CONNECTIONS.get()) {
                        networkLog.warn("Rejected connection from " +
                                socket.socket().getRemoteSocketAddress() +
                                " because the connection limit of " + MAX_CONNECTIONS + " has been reached");
                        try {
                            
                            final ByteBuffer b = ByteBuffer.allocate(1);
                            b.put(MAX_CONNECTIONS_LIMIT_ERROR);
                            b.flip();
                            socket.configureBlocking(true);
                            for (int ii = 0; ii < 4 && b.hasRemaining(); ii++) {
                                socket.write(b);
                            }
                            socket.close();
                        } catch (IOException e) {}
                        continue;
                    }

                    
                    m_numConnections.incrementAndGet();

                    final AuthRunnable authRunnable = new AuthRunnable(socket);
                    while (true) {
                        try {
                            m_executor.execute(authRunnable);
                            break;
                        } catch (RejectedExecutionException e) {
                            Thread.sleep(1);
                        }
                    }
                } while (m_running);
            } catch (Exception e) {
                if (m_running) {
                    hostLog.error("Exception in ClientAcceptor. The acceptor has died", e);
                }
            } finally {
                try {
                    m_serverSocket.close();
                } catch (IOException e) {
                    hostLog.fatal(null, e);
                }
                
                synchronized (this) {
                    Thread.interrupted();
                    m_executor.shutdownNow();
                    try {
                        m_executor.awaitTermination(5, TimeUnit.MINUTES);
                    } catch (InterruptedException e) {
                        String msg = "Client Listener Interrupted while shutting down "
                                + (m_isAdmin ? " Admin " : " ") + "port: " + m_port;
                        VoltDB.crashLocalVoltDB(msg, false, e);
                    }
                }
            }
        }

        
        private InputHandler
        authenticate(final SocketChannel socket, final AtomicReference<String> timeoutRef) throws IOException
        {
            ByteBuffer responseBuffer = ByteBuffer.allocate(6);
            byte version = (byte)0;
            responseBuffer.putInt(2);
            responseBuffer.put(version);

            
            socket.configureBlocking(true);
            socket.socket().setTcpNoDelay(true);
            final ByteBuffer lengthBuffer = ByteBuffer.allocate(4);

            
            final long start = System.currentTimeMillis();
            ScheduledFuture<?> timeoutFuture =
                    VoltDB.instance().schedulePriorityWork(new Runnable() {
                        @Override
                        public void run() {
                            long delta = System.currentTimeMillis() - start;
                            double seconds = delta / 1000.0;
                            StringBuilder sb = new StringBuilder();
                            sb.append("Timed out authenticating client from ");
                            sb.append(socket.socket().getRemoteSocketAddress().toString());
                            sb.append(String.format(" after %.2f seconds (timeout target is %.2f seconds)", seconds, AUTH_TIMEOUT_MS / 1000.0));
                            timeoutRef.set(sb.toString());
                            try {
                                socket.close();
                            } catch (IOException e) {
                                
                            }
                        }
                    }, AUTH_TIMEOUT_MS, 0, TimeUnit.MILLISECONDS);

            try {
                while (lengthBuffer.hasRemaining()) {
                    int read = socket.read(lengthBuffer);
                    if (read == -1) {
                        socket.close();
                        timeoutFuture.cancel(false);
                        return null;
                    }
                }
            } catch (AsynchronousCloseException e) {}

            
            if (lengthBuffer.hasRemaining()) {
                timeoutFuture.cancel(false);
                authLog.debug("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                              "): wire protocol violation (timeout reading message length).");
                
                responseBuffer.put(WIRE_PROTOCOL_TIMEOUT_ERROR).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }
            lengthBuffer.flip();

            final int messageLength = lengthBuffer.getInt();
            if (messageLength < 0) {
                timeoutFuture.cancel(false);
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                             "): wire protocol violation (message length " + messageLength + " is negative).");
                
                responseBuffer.put(WIRE_PROTOCOL_FORMAT_ERROR).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }
            if (messageLength > ((1024 * 1024) * 2)) {
                timeoutFuture.cancel(false);
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                             "): wire protocol violation (message length " + messageLength + " is too large).");
                
                responseBuffer.put(WIRE_PROTOCOL_FORMAT_ERROR).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
              }

            final ByteBuffer message = ByteBuffer.allocate(messageLength);

            try {
                while (message.hasRemaining()) {
                    int read = socket.read(message);
                    if (read == -1) {
                        socket.close();
                        timeoutFuture.cancel(false);
                        return null;
                    }
                }
            } catch (AsynchronousCloseException e) {}

            
            if (message.hasRemaining()) {
                timeoutFuture.cancel(false);
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                             "): wire protocol violation (timeout reading authentication strings).");
                
                responseBuffer.put(WIRE_PROTOCOL_TIMEOUT_ERROR).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }

            
            if (!timeoutFuture.cancel(false)) {
                return null;
            }

            message.flip();
            int aversion = message.get(); 
            ClientAuthHashScheme hashScheme = ClientAuthHashScheme.HASH_SHA1;
            
            if (aversion > 0) {
                try {
                    hashScheme = ClientAuthHashScheme.get(message.get());
                } catch (IllegalArgumentException ex) {
                    authLog.warn("Failure to authenticate connection Invalid Hash Scheme presented.");
                    
                    responseBuffer.put(WIRE_PROTOCOL_FORMAT_ERROR).flip();
                    socket.write(responseBuffer);
                    socket.close();
                    return null;
                }
            }
            FastDeserializer fds = new FastDeserializer(message);
            final String service = fds.readString();
            final String username = fds.readString();
            final int digestLen = ClientAuthHashScheme.getDigestLength(hashScheme);
            final byte password[] = new byte[digestLen];
            
            if (message.remaining() != digestLen) {
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress()
                        + "): user " + username + " failed authentication.");
                
                responseBuffer.put(AUTHENTICATION_FAILURE).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }
            message.get(password);

            CatalogContext context = m_catalogContext.get();

            AuthProvider ap = null;
            try {
                ap = AuthProvider.fromService(service);
            } catch (IllegalArgumentException unkownProvider) {
                
            }

            if (ap == null) {
                
                responseBuffer.put(EXPORT_DISABLED_REJECTION).flip();
                socket.write(responseBuffer);
                socket.close();
                authLog.warn("Rejected user " + username +
                        " attempting to use disabled or unconfigured service " +
                        service + ".");
                authLog.warn("VoltDB Export services are no longer available through clients.");
                return null;
            }

            
            if (!VoltDB.instance().rejoining()) {
                AuthenticationRequest arq;
                if (ap == AuthProvider.KERBEROS) {
                    arq = context.authSystem.new KerberosAuthenticationRequest(socket);
                } else {
                    arq = context.authSystem.new HashAuthenticationRequest(username, password, hashScheme);
                }
                
                boolean authenticated = arq.authenticate(hashScheme);

                if (!authenticated) {
                    Exception faex = arq.getAuthenticationFailureException();

                    boolean isItIo = false;
                    for (Throwable cause = faex; faex != null && !isItIo; cause = cause.getCause()) {
                        isItIo = cause instanceof IOException;
                    }

                    if (faex != null) {
                        authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                                 "):", faex);
                    } else {
                        authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                                     "): user " + username + " failed authentication.");
                    }
                    
                    if (!isItIo) {
                        responseBuffer.put(AUTHENTICATION_FAILURE).flip();
                        socket.write(responseBuffer);
                    }
                    socket.close();
                    return null;
                }
            } else {
                authLog.warn("Failure to authenticate connection(" + socket.socket().getRemoteSocketAddress() +
                        "): user " + username + " because this node is rejoining.");
                
                responseBuffer.put(AUTHENTICATION_FAILURE_DUE_TO_REJOIN).flip();
                socket.write(responseBuffer);
                socket.close();
                return null;
            }

            
            InputHandler handler = new ClientInputHandler(username, m_isAdmin);

            byte buildString[] = VoltDB.instance().getBuildString().getBytes(Charsets.UTF_8);
            responseBuffer = ByteBuffer.allocate(34 + buildString.length);
            responseBuffer.putInt(30 + buildString.length);
            responseBuffer.put((byte)0);

            
            responseBuffer.put((byte)0);
            responseBuffer.putInt(VoltDB.instance().getHostMessenger().getHostId());
            responseBuffer.putLong(handler.connectionId());
            responseBuffer.putLong(VoltDB.instance().getHostMessenger().getInstanceId().getTimestamp());
            responseBuffer.putInt(VoltDB.instance().getHostMessenger().getInstanceId().getCoord());
            responseBuffer.putInt(buildString.length);
            responseBuffer.put(buildString).flip();
            socket.write(responseBuffer);
            return handler;
        }
    }

    
    public class ClientInputHandler extends VoltProtocolHandler implements AdmissionControlGroup.ACGMember {
        public static final int MAX_READ = 8192 * 4;

        private Connection m_connection;
        private final boolean m_isAdmin;

        
        private final String m_username;

        public ClientInputHandler(String username,
                                  boolean isAdmin)
        {
            m_username = username.intern();
            m_isAdmin = isAdmin;
        }

        public boolean isAdmin()
        {
            return m_isAdmin;
        }

        @Override
        public int getMaxRead() {
            if (m_hasDTXNBackPressure) {
                return 0;
            } else {
                return Math.max( MAX_READ, getNextMessageLength());
            }
        }

        @Override
        public void handleMessage(ByteBuffer message, Connection c) {
            try {
                final ClientResponseImpl error = handleRead(message, this, c);
                if (error != null) {
                    ByteBuffer buf = ByteBuffer.allocate(error.getSerializedSize() + 4);
                    buf.putInt(buf.capacity() - 4);
                    error.flattenToBuffer(buf).flip();
                    c.writeStream().enqueue(buf);
                }
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }

        @Override
        public void started(final Connection c) {
            m_connection = c;
            m_cihm.put(c.connectionId(),
                       new ClientInterfaceHandleManager( m_isAdmin, c, null, m_acg.get()));
            m_acg.get().addMember(this);
            if (!m_acg.get().hasBackPressure()) {
                c.enableReadSelection();
            }
        }

        @Override
        public void stopped(Connection c) {
            m_numConnections.decrementAndGet();
            
            ClientInterfaceHandleManager cihm = m_cihm.remove(connectionId());
            cihm.freeOutstandingTxns();
            cihm.m_acg.removeMember(this);
            m_notifier.removeConnection(c);
        }

        
        @Override
        public Runnable offBackPressure() {
            return new Runnable() {
                @Override
                public void run() {
                    if (!m_acg.get().hasBackPressure()) {
                        m_connection.enableReadSelection();
                    }
                }
            };
        }

        @Override
        public Runnable onBackPressure() {
            return new Runnable() {
                @Override
                public void run() {
                    m_connection.disableReadSelection();
                }
            };
        }

        
        @Override
        public QueueMonitor writestreamMonitor() {
            return new QueueMonitor() {
                @Override
                public boolean queue(int bytes) {
                    return m_acg.get().queue(bytes);
                }
            };
        }

        
        @Override
        public void onBackpressure() {
            m_connection.disableReadSelection();
        }

        @Override
        public void offBackpressure() {
            m_connection.enableReadSelection();
        }
    }

    
    public class ClientResponseWork implements DeferredSerialization {
        private final ClientInterfaceHandleManager cihm;
        private final InitiateResponseMessage response;
        private final Procedure catProc;
        private ClientResponseImpl clientResponse;

        private ClientResponseWork(InitiateResponseMessage response,
                                   ClientInterfaceHandleManager cihm,
                                   Procedure catProc)
        {
            this.response = response;
            this.clientResponse = response.getClientResponseData();
            this.cihm = cihm;
            this.catProc = catProc;
        }

        @Override
        public void serialize(ByteBuffer buf) throws IOException
        {
            buf.putInt(buf.capacity() - 4);
            clientResponse.flattenToBuffer(buf);
        }

        @Override
        public void cancel() {
        }

        @Override
        public int getSerializedSize() throws IOException {
            
            
            
            
            ClientInterfaceHandleManager.Iv2InFlight clientData;
            if (clientResponse != null &&
                    clientResponse.getStatusString() != null &&
                    clientResponse.getStatusString().equals(ClientResponseImpl.IGNORED_TRANSACTION)) {
                clientData = cihm.removeHandle(response.getClientInterfaceHandle());
            }
            else {
                clientData = cihm.findHandle(response.getClientInterfaceHandle());
            }
            if (clientData == null) {
                return DeferredSerialization.EMPTY_MESSAGE_LENGTH;
            }

            
            if (restartTransaction(clientData.m_messageSize, clientData.m_creationTimeNanos)) {
                
                
                return DeferredSerialization.EMPTY_MESSAGE_LENGTH;
            }

            final long now = System.nanoTime();
            final long delta = now - clientData.m_creationTimeNanos;

            
            cihm.m_acg.logTransactionCompleted(
                    cihm.connection.connectionId(),
                    cihm.connection.getHostnameOrIP(),
                    clientData.m_procName,
                    delta,
                    clientResponse.getStatus());

            clientResponse.setClientHandle(clientData.m_clientHandle);
            clientResponse.setClusterRoundtrip((int)TimeUnit.NANOSECONDS.toMillis(delta));
            clientResponse.setHash(null); 

            return clientResponse.getSerializedSize() + 4;
        }

        @Override
        public String toString() {
            return clientResponse.getClass().getName();
        }

        
        private boolean restartTransaction(int messageSize, long nowNanos)
        {
            if (response.isMispartitioned()) {
                
                assert response.getInvocation() != null;
                assert response.getCurrentHashinatorConfig() != null;
                assert(catProc != null);

                
                TheHashinator.updateHashinator(
                        TheHashinator.getConfiguredHashinatorClass(),
                        response.getCurrentHashinatorConfig().getFirst(), 
                        response.getCurrentHashinatorConfig().getSecond(), 
                        false); 

                
                
                if (VoltDB.instance().getMode() == OperationMode.INITIALIZING) {
                    return false;
                }

                boolean isReadonly = catProc.getReadonly();

                try {
                    ProcedurePartitionInfo ppi = (ProcedurePartitionInfo)catProc.getAttachment();
                    int partition = getPartitionForProcedure(ppi.index,
                            ppi.type, response.getInvocation());
                    createTransaction(cihm.connection.connectionId(),
                            response.getInvocation(),
                            isReadonly,
                            true, 
                            false, 
                            partition,
                            messageSize,
                            nowNanos);
                    return true;
                } catch (Exception e) {
                    
                    assert(clientResponse == null);
                    clientResponse = getMispartitionedErrorResponse(response.getInvocation(), catProc, e);
                }
            }

            return false;
        }
    }

    
    public boolean createTransaction(
            final long connectionId,
            final StoredProcedureInvocation invocation,
            final boolean isReadOnly,
            final boolean isSinglePartition,
            final boolean isEveryPartition,
            final int partition,
            final int messageSize,
            final long nowNanos)
    {
        return createTransaction(
                connectionId,
                Iv2InitiateTaskMessage.UNUSED_MP_TXNID,
                0, 
                invocation,
                isReadOnly,
                isSinglePartition,
                isEveryPartition,
                partition,
                messageSize,
                nowNanos,
                false);  
    }

    
    public  boolean createTransaction(
            final long connectionId,
            final long txnId,
            final long uniqueId,
            final StoredProcedureInvocation invocation,
            final boolean isReadOnly,
            final boolean isSinglePartition,
            final boolean isEveryPartition,
            final int partition,
            final int messageSize,
            long nowNanos,
            final boolean isForReplay)
    {
        assert(!isSinglePartition || (partition >= 0));
        final ClientInterfaceHandleManager cihm = m_cihm.get(connectionId);

        Long initiatorHSId = null;
        boolean isShortCircuitRead = false;

        
        if (isSinglePartition && !isEveryPartition) {
            if (isReadOnly) {
                initiatorHSId = m_localReplicas.get(partition);
            }
            if (initiatorHSId != null) {
                isShortCircuitRead = true;
            } else {
                initiatorHSId = m_cartographer.getHSIdForSinglePartitionMaster(partition);
            }
        }
        else {
            
            initiatorHSId = m_cartographer.getHSIdForMultiPartitionInitiator();
            
            
            if (isReadOnly) {
                isShortCircuitRead = true;
            }
        }

        if (initiatorHSId == null) {
            hostLog.error("Failed to find master initiator for partition: "
                    + Integer.toString(partition) + ". Transaction not initiated.");
            return false;
        }

        long handle = cihm.getHandle(isSinglePartition, partition, invocation.getClientHandle(),
                messageSize, nowNanos, invocation.getProcName(), initiatorHSId, isReadOnly, isShortCircuitRead);

        Iv2InitiateTaskMessage workRequest =
            new Iv2InitiateTaskMessage(m_siteId,
                    initiatorHSId,
                    Iv2InitiateTaskMessage.UNUSED_TRUNC_HANDLE,
                    txnId,
                    uniqueId,
                    isReadOnly,
                    isSinglePartition,
                    invocation,
                    handle,
                    connectionId,
                    isForReplay);

        Iv2Trace.logCreateTransaction(workRequest);
        m_mailbox.send(initiatorHSId, workRequest);
        return true;
    }



    
    public static ClientInterface create(
            HostMessenger messenger,
            CatalogContext context,
            ReplicationRole replicationRole,
            Cartographer cartographer,
            int partitionCount,
            InetAddress clientIntf,
            int clientPort,
            InetAddress adminIntf,
            int adminPort,
            long timestampTestingSalt) throws Exception {

        
        int[] allPartitions = new int[partitionCount];
        int index = 0;
        for (Integer partition : cartographer.getPartitions()) {
            if (partition != MpInitiator.MP_INIT_PID) {
                allPartitions[index++] = partition;
            }
        }

        
        final ClientInterface ci = new ClientInterface(
                clientIntf, clientPort, adminIntf, adminPort, context, messenger, replicationRole, cartographer, allPartitions);

        return ci;
    }

    ClientInterface(InetAddress clientIntf, int clientPort, InetAddress adminIntf, int adminPort,
            CatalogContext context, HostMessenger messenger, ReplicationRole replicationRole,
            Cartographer cartographer, int[] allPartitions) throws Exception {
        m_catalogContext.set(context);
        m_cartographer = cartographer;

        
        m_allPartitions = allPartitions;
        m_acceptor = new ClientAcceptor(clientIntf, clientPort, messenger.getNetwork(), false);
        m_adminAcceptor = null;
        m_adminAcceptor = new ClientAcceptor(adminIntf, adminPort, messenger.getNetwork(), true);
        m_invocationValidator = new InvocationValidator(replicationRole);

        m_mailbox = new LocalMailbox(messenger,  messenger.getHSIdForLocalSite(HostMessenger.CLIENT_INTERFACE_SITE_ID)) {
            LinkedBlockingQueue<VoltMessage> m_d = new LinkedBlockingQueue<VoltMessage>();
            @Override
            public void deliver(final VoltMessage message) {
                if (message instanceof InitiateResponseMessage) {
                    final CatalogContext catalogContext = m_catalogContext.get();
                    
                    InitiateResponseMessage response = (InitiateResponseMessage)message;
                    StoredProcedureInvocation invocation = response.getInvocation();
                    Iv2Trace.logFinishTransaction(response, m_mailbox.getHSId());
                    ClientInterfaceHandleManager cihm = m_cihm.get(response.getClientConnectionId());
                    Procedure procedure = null;

                    if (invocation != null) {
                        procedure = catalogContext.procedures.get(invocation.getProcName());
                        if (procedure == null) {
                            procedure = SystemProcedureCatalog.listing.get(invocation.getProcName())
                                                              .asCatalogProcedure();
                        }
                    }

                    
                    if (cihm != null) {
                        
                        
                        cihm.connection.writeStream().fastEnqueue(new ClientResponseWork(response, cihm, procedure));
                    }
                } else if (message instanceof BinaryPayloadMessage) {
                    handlePartitionFailOver((BinaryPayloadMessage)message);
                } else {
                    m_d.offer(message);
                }
            }

            @Override
            public VoltMessage recv() {
                return m_d.poll();
            }
        };
        messenger.createMailbox(m_mailbox.getHSId(), m_mailbox);
        m_plannerSiteId = messenger.getHSIdForLocalSite(HostMessenger.ASYNC_COMPILER_SITE_ID);
        m_zk = messenger.getZK();
        m_siteId = m_mailbox.getHSId();
        m_isConfiguredForHSQL = (VoltDB.instance().getBackendTargetType() == BackendTarget.HSQLDB_BACKEND);
    }

    private void handlePartitionFailOver(BinaryPayloadMessage message) {
        try {
            JSONObject jsObj = new JSONObject(new String(message.m_payload, "UTF-8"));
            final int partitionId = jsObj.getInt(Cartographer.JSON_PARTITION_ID);
            final long initiatorHSId = jsObj.getLong(Cartographer.JSON_INITIATOR_HSID);
            for (final ClientInterfaceHandleManager cihm : m_cihm.values()) {
                try {
                    cihm.connection.queueTask(new Runnable() {
                        @Override
                        public void run() {
                            failOverConnection(partitionId, initiatorHSId, cihm.connection);
                        }
                    });
                } catch (UnsupportedOperationException ignore) {
                    
                    failOverConnection(partitionId, initiatorHSId, cihm.connection);
                }
            }
        } catch (Exception e) {
            hostLog.warn("Error handling partition fail over at ClientInterface, continuing anyways", e);
        }
    }

    
    private void failOverConnection(Integer partitionId, Long initiatorHSId, Connection c) {
        ClientInterfaceHandleManager cihm = m_cihm.get(c.connectionId());
        if (cihm == null) {
            return;
        }

        List<Iv2InFlight> transactions =
                cihm.removeHandlesForPartitionAndInitiator( partitionId, initiatorHSId);

        for (Iv2InFlight inFlight : transactions) {
            ClientResponseImpl response =
                    new ClientResponseImpl(
                            ClientResponseImpl.RESPONSE_UNKNOWN,
                            ClientResponse.UNINITIALIZED_APP_STATUS_CODE,
                            null,
                            new VoltTable[0],
                            "Transaction dropped due to change in mastership. " +
                            "It is possible the transaction was committed");
            response.setClientHandle( inFlight.m_clientHandle );
            ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
            buf.putInt(buf.capacity() - 4);
            response.flattenToBuffer(buf);
            buf.flip();
            c.writeStream().enqueue(buf);
        }

        if (cihm.repairCallback != null) {
            cihm.repairCallback.repairCompleted(partitionId, initiatorHSId);
        }
    }

    
    public void setReplicationRole(ReplicationRole role) {
        m_invocationValidator.setReplicationRole(role);
    }

    
    public void initializeSnapshotDaemon(HostMessenger messenger, GlobalServiceElector gse) {
        m_snapshotDaemon.init(this, messenger, new Runnable() {
            @Override
            public void run() {
                bindAdapter(m_snapshotDaemonAdapter, null);
            }
        },
        gse);
    }

    
    public ClientInterfaceHandleManager bindAdapter(final Connection adapter, final ClientInterfaceRepairCallback repairCallback) {
        if (m_cihm.get(adapter.connectionId()) == null) {
            ClientInterfaceHandleManager cihm = ClientInterfaceHandleManager.makeThreadSafeCIHM(true, adapter, repairCallback,
                        AdmissionControlGroup.getDummy());
            m_cihm.put(adapter.connectionId(), cihm);
        }
        return m_cihm.get(adapter.connectionId());
    }

    
    
    public void mayActivateSnapshotDaemon() {
        SnapshotSchedule schedule = m_catalogContext.get().database.getSnapshotschedule().get("default");
        if (schedule != null)
        {
            final ListenableFuture<Void> future = m_snapshotDaemon.mayGoActiveOrInactive(schedule);
            future.addListener(new Runnable() {
                @Override
                public void run() {
                    try {
                        future.get();
                    } catch (InterruptedException e) {
                        VoltDB.crashLocalVoltDB("Failed to make SnapshotDaemon active", false, e);
                    } catch (ExecutionException e) {
                        VoltDB.crashLocalVoltDB("Failed to make SnapshotDaemon active", false, e);
                    }
                }
            }, CoreUtils.SAMETHREADEXECUTOR);
        }
    }

    
    public void notifyOfCatalogUpdate() {
        m_catalogContext.set(VoltDB.instance().getCatalogContext());
        
        if (VoltDB.instance().getMode() != OperationMode.INITIALIZING) {
            mayActivateSnapshotDaemon();
        }
    }

    private ClientResponseImpl errorResponse(Connection c, long handle, byte status, String reason, Exception e, boolean log) {
        String realReason = reason;
        if (e != null) {
            StringWriter sw = new StringWriter();
            PrintWriter pw = new PrintWriter(sw);
            e.printStackTrace(pw);
            realReason = sw.toString();
        }
        if (log) {
            hostLog.warn(realReason);
        }
        return new ClientResponseImpl(status,
                new VoltTable[0], realReason, handle);
    }

    
    private void processExplainPlannedStmtBatch(  AdHocPlannedStmtBatch planBatch ) {
        final Connection c = (Connection)planBatch.clientData;
        Database db = m_catalogContext.get().database;
        int size = planBatch.getPlannedStatementCount();

        VoltTable[] vt = new VoltTable[ size ];
        for (int i = 0; i < size; ++i) {
            vt[i] = new VoltTable(new VoltTable.ColumnInfo("EXECUTION_PLAN", VoltType.STRING));
            String str = planBatch.explainStatement(i, db);
            vt[i].addRow(str);
        }

        ClientResponseImpl response =
                new ClientResponseImpl(
                        ClientResponseImpl.SUCCESS,
                        ClientResponse.UNINITIALIZED_APP_STATUS_CODE,
                        null,
                        vt,
                        null);
        response.setClientHandle( planBatch.clientHandle );
        ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
        buf.putInt(buf.capacity() - 4);
        response.flattenToBuffer(buf);
        buf.flip();
        c.writeStream().enqueue(buf);
    }

    
    private void processExplainDefaultProc(AdHocPlannedStmtBatch planBatch) {
        final Connection c = (Connection)planBatch.clientData;
        Database db = m_catalogContext.get().database;

        
        
        assert(planBatch.getPlannedStatementCount() == 1);
        AdHocPlannedStatement ahps = planBatch.getPlannedStatement(0);
        String sql = new String(ahps.sql, Charsets.UTF_8);
        String explain = planBatch.explainStatement(0, db);

        VoltTable vt = new VoltTable(new VoltTable.ColumnInfo( "SQL_STATEMENT", VoltType.STRING),
                new VoltTable.ColumnInfo( "EXECUTION_PLAN", VoltType.STRING));
        vt.addRow(sql, explain);

        ClientResponseImpl response =
                new ClientResponseImpl(
                        ClientResponseImpl.SUCCESS,
                        ClientResponse.UNINITIALIZED_APP_STATUS_CODE,
                        null,
                        new VoltTable[] { vt },
                        null);
        response.setClientHandle( planBatch.clientHandle );
        ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
        buf.putInt(buf.capacity() - 4);
        response.flattenToBuffer(buf);
        buf.flip();
        c.writeStream().enqueue(buf);
    }

    
    ClientResponseImpl dispatchExplainProcedure(StoredProcedureInvocation task, ClientInputHandler handler, Connection ccxn, AuthUser user) {
        ParameterSet params = task.getParams();
        
        
        List<String> procNames = SQLLexer.splitStatements( (String)params.toArray()[0]);
        int size = procNames.size();
        VoltTable[] vt = new VoltTable[ size ];
        for( int i=0; i<size; i++ ) {
            String procName = procNames.get(i);

            
            Procedure proc = m_catalogContext.get().procedures.get(procName);
            if (proc == null) {
                
                
                proc = m_catalogContext.get().m_defaultProcs.checkForDefaultProcedure(procName);
                if (proc != null) {
                    String sql = m_catalogContext.get().m_defaultProcs.sqlForDefaultProc(proc);
                    dispatchAdHocCommon(task, handler, ccxn, ExplainMode.EXPLAIN_DEFAULT_PROC, sql, new Object[0], null, user);
                    return null;
                }

                ClientResponseImpl errorResponse =
                        new ClientResponseImpl(
                                ClientResponseImpl.UNEXPECTED_FAILURE,
                                new VoltTable[0], "Procedure "+procName+" not in catalog",
                                task.clientHandle);
                return errorResponse;
            }

            vt[i] = new VoltTable(new VoltTable.ColumnInfo( "SQL_STATEMENT", VoltType.STRING),
                                  new VoltTable.ColumnInfo( "EXECUTION_PLAN", VoltType.STRING));

            for( Statement stmt : proc.getStatements() ) {
                vt[i].addRow( stmt.getSqltext(), Encoder.hexDecodeToString( stmt.getExplainplan() ) );
            }
        }

        ClientResponseImpl response =
                new ClientResponseImpl(
                        ClientResponseImpl.SUCCESS,
                        ClientResponse.UNINITIALIZED_APP_STATUS_CODE,
                        null,
                        vt,
                        null);
        response.setClientHandle( task.clientHandle );
        ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
        buf.putInt(buf.capacity() - 4);
        response.flattenToBuffer(buf);
        buf.flip();
        ccxn.writeStream().enqueue(buf);
        return null;
    }

    private final ClientResponseImpl dispatchAdHoc(StoredProcedureInvocation task,
            ClientInputHandler handler, Connection ccxn, boolean isExplain, AuthSystem.AuthUser user) {
        ParameterSet params = task.getParams();
        Object[] paramArray = params.toArray();
        String sql = (String) paramArray[0];
        Object[] userParams = null;
        if (params.size() > 1) {
            userParams = Arrays.copyOfRange(paramArray, 1, paramArray.length);
        }
        ExplainMode explainMode = isExplain ? ExplainMode.EXPLAIN_ADHOC : ExplainMode.NONE;
        dispatchAdHocCommon(task, handler, ccxn, explainMode, sql, userParams, null, user);
        return null;
    }

    private final ClientResponseImpl dispatchAdHocSpForTest(StoredProcedureInvocation task,
            ClientInputHandler handler, Connection ccxn, boolean isExplain, AuthSystem.AuthUser user) {
        ParameterSet params = task.getParams();
        assert(params.size() > 1);
        Object[] paramArray = params.toArray();
        String sql = (String) paramArray[0];
        
        Object[] userPartitionKey = Arrays.copyOfRange(paramArray, 1, 2);
        Object[] userParams = null;
        
        
        if (params.size() > 2) {
            userParams = Arrays.copyOfRange(paramArray, 2, paramArray.length);
        }
        ExplainMode explainMode = isExplain ? ExplainMode.EXPLAIN_ADHOC : ExplainMode.NONE;
        dispatchAdHocCommon(task, handler, ccxn, explainMode, sql, userParams, userPartitionKey, user);
        return null;
    }

    private final void dispatchAdHocCommon(StoredProcedureInvocation task,
            ClientInputHandler handler, Connection ccxn, ExplainMode explainMode,
            String sql, Object[] userParams, Object[] userPartitionKey, AuthSystem.AuthUser user) {
        List<String> sqlStatements = SQLLexer.splitStatements(sql);
        String[] stmtsArray = sqlStatements.toArray(new String[sqlStatements.size()]);

        AdHocPlannerWork ahpw = new AdHocPlannerWork(
                m_siteId,
                task.clientHandle, handler.connectionId(),
                handler.isAdmin(), ccxn,
                sql, stmtsArray, userParams, null, explainMode,
                userPartitionKey == null, userPartitionKey,
                task.procName, task.type, task.originalTxnId, task.originalUniqueId,
                VoltDB.instance().getReplicationRole() == ReplicationRole.REPLICA,
                VoltDB.instance().getCatalogContext().cluster.getUseddlschema(),
                m_adhocCompletionHandler, user);
        LocalObjectMessage work = new LocalObjectMessage( ahpw );

        m_mailbox.send(m_plannerSiteId, work);
    }

    ClientResponseImpl dispatchUpdateApplicationCatalog(StoredProcedureInvocation task,
            ClientInputHandler handler, Connection ccxn, AuthSystem.AuthUser user)
    {
        ParameterSet params = task.getParams();
        
        
        byte[] catalogBytes = null;
        Object catalogObj = params.toArray()[0];
        if (catalogObj != null) {
            if (catalogObj instanceof String) {
                
                String catalogString = (String) catalogObj;
                if (!catalogString.isEmpty()) {
                    catalogBytes = Encoder.hexDecode(catalogString);
                }
            } else if (catalogObj instanceof byte[]) {
                
                byte[] catalogArr = (byte[]) catalogObj;
                if (catalogArr.length != 0) {
                    catalogBytes = catalogArr;
                }
            }
        }
        String deploymentString = (String) params.toArray()[1];
        LocalObjectMessage work = new LocalObjectMessage(
                new CatalogChangeWork(
                    m_siteId,
                    task.clientHandle, handler.connectionId(), ccxn.getHostnameAndIPAndPort(),
                    handler.isAdmin(), ccxn, catalogBytes, deploymentString,
                    task.procName, task.type, task.originalTxnId, task.originalUniqueId,
                    VoltDB.instance().getReplicationRole() == ReplicationRole.REPLICA,
                    VoltDB.instance().getCatalogContext().cluster.getUseddlschema(),
                    m_adhocCompletionHandler, user));

        m_mailbox.send(m_plannerSiteId, work);
        return null;
    }

    
    ClientResponseImpl dispatchLoadSinglepartitionTable(ByteBuffer buf,
                                                        Procedure catProc,
                                                        StoredProcedureInvocation task,
                                                        ClientInputHandler handler,
                                                        Connection ccxn)
    {
        int partition = -1;
        try {
            CatalogMap<Table> tables = m_catalogContext.get().database.getTables();
            int partitionParamType = getLoadSinglePartitionTablePartitionParamType(tables, task);
            byte[] valueToHash = (byte[])task.getParameterAtIndex(0);
            partition = TheHashinator.getPartitionForParameter(partitionParamType, valueToHash);
        }
        catch (Exception e) {
            authLog.warn(e.getMessage());
            return new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                                          new VoltTable[0], e.getMessage(), task.clientHandle);
        }
        assert(partition != -1);
        createTransaction(handler.connectionId(),
                          task,
                          catProc.getReadonly(),
                          catProc.getSinglepartition(),
                          catProc.getEverysite(),
                          partition,
                          buf.capacity(),
                          System.nanoTime());
        return null;
    }

    
    private static int getLoadSinglePartitionTablePartitionParamType(CatalogMap<Table> tables,
                                                                     StoredProcedureInvocation spi)
        throws Exception
    {
        String tableName = (String) spi.getParameterAtIndex(1);

        
        Table catTable = tables.getIgnoreCase(tableName);
        if (catTable == null) {
            throw new Exception(String .format("Unable to find target table \"%s\" for LoadSinglepartitionTable.",
                                               tableName));
        }

        Column pCol = catTable.getPartitioncolumn();
        return pCol.getType();
    }

    
    void sendSentinelsToAllPartitions(long txnId)
    {
        for (int partition : m_allPartitions) {
            final long initiatorHSId = m_cartographer.getHSIdForSinglePartitionMaster(partition);
            
            sendSentinel(txnId, initiatorHSId, -1, -1, true);
        }
    }

    
    void dispatchSendSentinel(long connectionId, long nowNanos, int size,
                              StoredProcedureInvocation invocation)
    {
        ClientInterfaceHandleManager cihm = m_cihm.get(connectionId);
        
        int pid = (Integer) invocation.getParameterAtIndex(0);
        final long initiatorHSId = m_cartographer.getHSIdForSinglePartitionMaster(pid);
        long handle = cihm.getHandle(true, pid, invocation.getClientHandle(), size, nowNanos,
                invocation.getProcName(), initiatorHSId, true, false);

        
        sendSentinel(invocation.getOriginalTxnId(), initiatorHSId, handle, connectionId, false);
    }

    ClientResponseImpl dispatchStatistics(OpsSelector selector, StoredProcedureInvocation task, Connection ccxn)
    {
        try {
            OpsAgent agent = VoltDB.instance().getOpsAgent(selector);
            if (agent != null) {
                agent.performOpsAction(ccxn, task.clientHandle, selector, task.getParams());
            }
            else {
                return errorResponse(ccxn, task.clientHandle, ClientResponse.GRACEFUL_FAILURE,
                        "Unknown OPS selector", null, true);
            }

            return null;
        } catch (Exception e) {
            return errorResponse( ccxn, task.clientHandle, ClientResponse.UNEXPECTED_FAILURE, null, e, true);
        }
    }

    ClientResponseImpl dispatchPromote(Procedure sysProc,
                                       ByteBuffer buf,
                                       StoredProcedureInvocation task,
                                       ClientInputHandler handler,
                                       Connection ccxn)
    {
        if (VoltDB.instance().getReplicationRole() == ReplicationRole.NONE)
        {
            return new ClientResponseImpl(ClientResponseImpl.GRACEFUL_FAILURE,
                    new VoltTable[0], "@Promote issued on master cluster." +
                    " No action taken.",
                    task.clientHandle);
        }

        
        createTransaction(
                handler.connectionId(),
                task,
                sysProc.getReadonly(),
                sysProc.getSinglepartition(),
                sysProc.getEverysite(),
                0,
                buf.capacity(),
                System.nanoTime());

        return null;
    }

    
    final ClientResponseImpl handleRead(ByteBuffer buf, ClientInputHandler handler, Connection ccxn) throws IOException {
        final long nowNanos = System.nanoTime();
        StoredProcedureInvocation task = new StoredProcedureInvocation();
        try {
            task.initFromBuffer(buf);
        } catch (Exception ex) {
            return new ClientResponseImpl(
                    ClientResponseImpl.UNEXPECTED_FAILURE,
                    new VoltTable[0], ex.getMessage(), ccxn.connectionId());
        }
        ClientResponseImpl error = null;

        
        VoltDBInterface instance = VoltDB.instance();
        if (instance.getMode() == OperationMode.PAUSED && !handler.isAdmin())
        {
            return new ClientResponseImpl(ClientResponseImpl.SERVER_UNAVAILABLE,
                    new VoltTable[0], "Server is paused and is currently unavailable - please try again later.",
                    task.clientHandle);
        }

        
        final CatalogContext catalogContext = m_catalogContext.get();
        final AuthSystem.AuthUser user = catalogContext.authSystem.getUser(handler.m_username);

        Procedure catProc = catalogContext.procedures.get(task.procName);
        if (catProc == null) {
            catProc = catalogContext.m_defaultProcs.checkForDefaultProcedure(task.procName);
        }

        if (catProc == null) {
            String proc = task.procName;
            if (task.procName.equals("@AdHoc") || task.procName.equals("@AdHocSpForTest")) {
                
                
                
                
                proc = "@AdHoc_RW_MP";
            }
            else if (task.procName.equals("@UpdateClasses")) {
                
                
                
                
                proc = "@UpdateApplicationCatalog";
            }
            Config sysProc = SystemProcedureCatalog.listing.get(proc);
            if (sysProc != null) {
                catProc = sysProc.asCatalogProcedure();
            }
        }

        if (user == null) {
            authLog.info("User " + handler.m_username + " has been removed from the system via a catalog update");
            return new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                    new VoltTable[0], "User " + handler.m_username +
                    " has been removed from the system via a catalog update",
                    task.clientHandle);
        }

        if (catProc == null) {
            String errorMessage = "Procedure " + task.procName + " was not found";
            RateLimitedLogger.tryLogForMessage(System.currentTimeMillis(),
                            60, TimeUnit.SECONDS,
                            authLog,
                            Level.WARN, errorMessage + ". This message is rate limited to once every 60 seconds.");
            return new ClientResponseImpl(
                    ClientResponseImpl.UNEXPECTED_FAILURE,
                    new VoltTable[0], errorMessage, task.clientHandle);
        }

        final ProcedurePartitionInfo ppi = (ProcedurePartitionInfo)catProc.getAttachment();

        
        if ((error = m_permissionValidator.shouldAccept(task.procName, user, task, catProc)) != null) {
            return error;
        }

        
        if ((error = m_invocationValidator.shouldAccept(task.procName, user, task, catProc)) != null) {
            return error;
        }

        if (catProc.getSystemproc()) {
            

            
            
            if (task.procName.equals("@Ping")) {
                return new ClientResponseImpl(ClientResponseImpl.SUCCESS, new VoltTable[0], "", task.clientHandle);
            }
            else if (task.procName.equals("@GetPartitionKeys")) {
                return dispatchGetPartitionKeys(task);
            }
            else if (task.procName.equals("@Subscribe")) {
                return dispatchSubscribe( handler, task);
            }
            else if (task.procName.equals("@Statistics")) {
                return dispatchStatistics(OpsSelector.STATISTICS, task, ccxn);
            }
            else if (task.procName.equals("@SystemCatalog")) {
                return dispatchStatistics(OpsSelector.SYSTEMCATALOG, task, ccxn);
            }
            else if (task.procName.equals("@SystemInformation")) {
                return dispatchStatistics(OpsSelector.SYSTEMINFORMATION, task, ccxn);
            }
            else if (task.procName.equals("@GC")) {
                return dispatchSystemGC(handler, task);
            }
            else if (task.procName.equals("@StopNode")) {
                return dispatchStopNode(task);
            }

            else if (task.procName.equals("@Explain")) {
                return dispatchAdHoc(task, handler, ccxn, true, user);
            }
            else if (task.procName.equals("@ExplainProc")) {
                return dispatchExplainProcedure(task, handler, ccxn, user);
            }
            else if (task.procName.equals("@SendSentinel")) {
                dispatchSendSentinel(handler.connectionId(), nowNanos, buf.capacity(), task);
                return null;
            }

            else if (task.procName.equals("@AdHoc")) {
                return dispatchAdHoc(task, handler, ccxn, false, user);
            }
            else if (task.procName.equals("@AdHocSpForTest")) {
                return dispatchAdHocSpForTest(task, handler, ccxn, false, user);
            }
            else if (task.procName.equals("@LoadMultipartitionTable")) {
                
                if (task.getType() == ProcedureInvocationType.REPLICATED) {
                    sendSentinelsToAllPartitions(task.getOriginalTxnId());
                }
            }
            else if (task.procName.equals("@LoadSinglepartitionTable")) {
                
                return dispatchLoadSinglepartitionTable(buf, catProc, task, handler, ccxn);
            }

            

            if (!MiscUtils.isPro()) {
                SystemProcedureCatalog.Config sysProcConfig = SystemProcedureCatalog.listing.get(task.procName);
                if ((sysProcConfig != null) && (sysProcConfig.commercial)) {
                    return new ClientResponseImpl(ClientResponseImpl.GRACEFUL_FAILURE,
                            new VoltTable[0],
                            task.procName + " is available in the Enterprise Edition of VoltDB only.",
                            task.clientHandle);
                }
            }

            

            if (task.procName.equals("@UpdateApplicationCatalog")) {
                return dispatchUpdateApplicationCatalog(task, handler, ccxn, user);
            }
            else if (task.procName.equals("@UpdateClasses")) {
                return dispatchUpdateApplicationCatalog(task, handler, ccxn, user);
            }
            else if (task.procName.equals("@SnapshotSave")) {
                m_snapshotDaemon.requestUserSnapshot(task, ccxn);
                return null;
            }
            else if (task.procName.equals("@Promote")) {
                return dispatchPromote(catProc, buf, task, handler, ccxn);
            }
            else if (task.procName.equals("@SnapshotStatus")) {
                
                
                Object[] params = new Object[1];
                params[0] = "SNAPSHOTSTATUS";
                task.setParams(params);
                return dispatchStatistics(OpsSelector.STATISTICS, task, ccxn);
            }
            else if (task.procName.equals("@SnapshotScan")) {
                return dispatchStatistics(OpsSelector.SNAPSHOTSCAN, task, ccxn);
            }
            else if (task.procName.equals("@SnapshotDelete")) {
                return dispatchStatistics(OpsSelector.SNAPSHOTDELETE, task, ccxn);
            }
            else if (task.procName.equals("@SnapshotRestore")) {
                ClientResponseImpl retval = SnapshotUtil.transformRestoreParamsToJSON(task);
                if (retval != null) {
                    return retval;
                }
            }

            
            

            
            
            if (task.procName.equals("@Pause") || task.procName.equals("@Resume")) {
                if (!handler.isAdmin()) {
                    return new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                            new VoltTable[0],
                            "" + task.procName + " is not available to this client",
                            task.clientHandle);
                }
            }
        }

        int partition = -1;
        if (catProc.getSinglepartition()) {
            
            try {
                partition =
                        getPartitionForProcedure(
                                ppi.index,
                                ppi.type,
                                task);
            } catch (Exception e) {
                
                return getMispartitionedErrorResponse(task, catProc, e);
            }
        }
        boolean success =
                createTransaction(handler.connectionId(),
                        task,
                        catProc.getReadonly(),
                        catProc.getSinglepartition(),
                        catProc.getEverysite(),
                        partition,
                        buf.capacity(),
                        nowNanos);
        if (!success) {
            
            
            
            
            return new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                    new VoltTable[0],
                    ClientResponseImpl.IGNORED_TRANSACTION,
                    task.clientHandle);
        }
        return null;
    }

    
    
    
    private final ExecutorService m_systemGCThread =
            CoreUtils.getCachedSingleThreadExecutor("System.gc() invocation thread", 1000);

    
    private ClientResponseImpl dispatchSystemGC(final ClientInputHandler handler,
                                                final StoredProcedureInvocation task) {
        m_systemGCThread.execute(new Runnable() {
            @Override
            public void run() {
                final long start = System.nanoTime();
                System.gc();
                final long duration = System.nanoTime() - start;
                VoltTable vt = new VoltTable(
                        new ColumnInfo[] { new ColumnInfo("SYSTEM_GC_DURATION_NANOS", VoltType.BIGINT) });
                vt.addRow(duration);
                final ClientResponseImpl response = new ClientResponseImpl(
                        ClientResponseImpl.SUCCESS,
                        new VoltTable[] { vt },
                        null,
                        task.clientHandle);
                ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
                buf.putInt(buf.capacity() - 4);
                response.flattenToBuffer(buf).flip();

                ClientInterfaceHandleManager cihm = m_cihm.get(handler.connectionId());
                if (cihm == null) {
                    return;
                }
                cihm.connection.writeStream().enqueue(buf);
            }
        });
        return null;
    }

    private ClientResponseImpl dispatchSubscribe(ClientInputHandler c, StoredProcedureInvocation task) {
        final ParameterSet ps = task.getParams();
        final Object params[] = ps.toArray();
        String err = null;
        final ClientInterfaceHandleManager cihm = m_cihm.get(c.connectionId());
        
        if (cihm == null) {
            return null;
        }
        for (int ii = 0; ii < params.length; ii++) {
            final Object param = params[ii];
            if (param == null) {
                err = "Parameter index " + ii + " was null"; break;
            }
            if (!(param instanceof String)) {
                err = "Parameter index " + ii + " was not a String"; break;
            }

            if (param.equals("TOPOLOGY")) {
                cihm.setWantsTopologyUpdates(true);
            } else {
                err = "Parameter \"" + param + "\" is not recognized/supported"; break;
            }
        }
        return new ClientResponseImpl(
                       err == null ? ClientResponse.SUCCESS : ClientResponse.GRACEFUL_FAILURE,
                       new VoltTable[] { },
                       err,
                       task.clientHandle);
    }

    private ClientResponseImpl dispatchGetPartitionKeys(StoredProcedureInvocation task) {
        Object params[] = task.getParams().toArray();
        String typeString = "the type of partition key to return and can be one of " +
                            "INTEGER, STRING or VARCHAR (equivalent), or VARBINARY";
        if (params.length != 1 || params[0] == null) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "GetPartitionKeys must have one string parameter specifying " + typeString,
                    task.clientHandle);
        }
        if (!(params[0] instanceof String)) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "GetPartitionKeys must have one string parameter specifying " + typeString +
                    " provided type was " + params[0].getClass().getName(),
                    task.clientHandle);
        }
        VoltType voltType = null;
        String typeStr = ((String)params[0]).trim().toUpperCase();
        if (typeStr.equals("INTEGER")) {
            voltType = VoltType.INTEGER;
        } else if (typeStr.equals("STRING") || typeStr.equals("VARCHAR")) {
            voltType = VoltType.STRING;
        } else if (typeStr.equals("VARBINARY")) {
            voltType = VoltType.VARBINARY;
        } else {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "Type " + typeStr + " is not a supported type of partition key, " + typeString,
                    task.clientHandle);
        }
        VoltTable partitionKeys = TheHashinator.getPartitionKeys(voltType);
        if (partitionKeys == null) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "Type " + typeStr + " is not a supported type of partition key, " + typeString,
                    task.clientHandle);
        }
        return new ClientResponseImpl(ClientResponse.SUCCESS, new VoltTable[] { partitionKeys }, null, task.clientHandle);
    }

    private ClientResponseImpl dispatchStopNode(StoredProcedureInvocation task) {
        Object params[] = task.getParams().toArray();
        if (params.length != 1 || params[0] == null) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "@StopNode must provide hostId",
                    task.clientHandle);
        }
        if (!(params[0] instanceof Integer)) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "@StopNode must have one Integer parameter specified. Provided type was " + params[0].getClass().getName(),
                    task.clientHandle);
        }
        int ihid = (Integer) params[0];
        List<Integer> liveHids = VoltDB.instance().getHostMessenger().getLiveHostIds();
        if (!liveHids.contains(ihid)) {
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "Invalid Host Id or Host Id not member of cluster: " + ihid,
                    task.clientHandle);
        }
        if (!m_cartographer.isClusterSafeIfNodeDies(liveHids, ihid)) {
            hostLog.info("Its unsafe to shutdown node with hostId: " + ihid
                    + " Cannot stop the requested node. Stopping individual nodes is only allowed on a K-safe cluster."
                    + " Use shutdown to stop the cluster.");
            return new ClientResponseImpl(
                    ClientResponse.GRACEFUL_FAILURE,
                    new VoltTable[0],
                    "Cannot stop the requested node. Stopping individual nodes is only allowed on a K-safe cluster."
                            + " Use shutdown to stop the cluster.", task.clientHandle);
        }

        int hid = VoltDB.instance().getHostMessenger().getHostId();
        if (hid == ihid) {
            
            VoltDB.instance().halt();
        } else {
            
            VoltDB.instance().getHostMessenger().sendPoisonPill("@StopNode", ihid, ForeignHost.CRASH_ME);
        }
        return new ClientResponseImpl(ClientResponse.SUCCESS, new VoltTable[0], "SUCCESS", task.clientHandle);
    }

    void createAdHocTransaction(final AdHocPlannedStmtBatch plannedStmtBatch, Connection c)
            throws VoltTypeException
    {
        ByteBuffer buf = null;
        try {
            buf = plannedStmtBatch.flattenPlanArrayToBuffer();
        }
        catch (IOException e) {
            VoltDB.crashLocalVoltDB(e.getMessage(), true, e);
        }
        assert(buf.hasArray());

        
        StoredProcedureInvocation task = new StoredProcedureInvocation();
        
        task.type = plannedStmtBatch.work.invocationType;
        task.originalTxnId = plannedStmtBatch.work.originalTxnId;
        task.originalUniqueId = plannedStmtBatch.work.originalUniqueId;
        
        
        boolean isSinglePartition = plannedStmtBatch.isSinglePartitionCompatible() || m_isConfiguredForHSQL;
        int partition = -1;

        if (isSinglePartition) {
            if (plannedStmtBatch.isReadOnly()) {
                task.procName = "@AdHoc_RO_SP";
            }
            else {
                task.procName = "@AdHoc_RW_SP";
            }
            int type = VoltType.NULL.getValue();
            
            
            
            
            Object partitionParam = plannedStmtBatch.partitionParam();
            byte[] param = null;
            if (partitionParam != null) {
                type = VoltType.typeFromClass(partitionParam.getClass()).getValue();
                param = TheHashinator.valueToBytes(partitionParam);
            }
            partition = TheHashinator.getPartitionForParameter(type, partitionParam);

            
            
            task.setParams(param, (byte)type, buf.array());
        }
        else {
            if (plannedStmtBatch.isReadOnly()) {
                task.procName = "@AdHoc_RO_MP";
            }
            else {
                task.procName = "@AdHoc_RW_MP";
            }
            task.setParams(buf.array());
        }
        task.clientHandle = plannedStmtBatch.clientHandle;

        ClientResponseImpl error = null;
        if ((error = m_permissionValidator.shouldAccept(task.procName, plannedStmtBatch.work.user, task,
                SystemProcedureCatalog.listing.get(task.procName).asCatalogProcedure())) != null) {
            ByteBuffer buffer = ByteBuffer.allocate(error.getSerializedSize() + 4);
            buffer.putInt(buffer.capacity() - 4);
            error.flattenToBuffer(buffer).flip();
            c.writeStream().enqueue(buffer);
        }
        else
        if ((error = m_invocationValidator.shouldAccept(task.procName, plannedStmtBatch.work.user, task,
                SystemProcedureCatalog.listing.get(task.procName).asCatalogProcedure())) != null) {
            ByteBuffer buffer = ByteBuffer.allocate(error.getSerializedSize() + 4);
            buffer.putInt(buffer.capacity() - 4);
            error.flattenToBuffer(buffer).flip();
            c.writeStream().enqueue(buffer);
        }
        else {
            
            try {
                task = MiscUtils.roundTripForCL(task);
            } catch (Exception e) {
                VoltDB.crashLocalVoltDB(e.getMessage(), true, e);
            }

            
            createTransaction(plannedStmtBatch.connectionId, task,
                    plannedStmtBatch.isReadOnly(), isSinglePartition, false,
                    partition,
                    task.getSerializedSize(), System.nanoTime());
        }
    }

    
    public ListenableFutureTask<?> processFinishedCompilerWork(final AsyncCompilerResult result) {
        
        final Connection c = (Connection)result.clientData;
        final ListenableFutureTask<?> ft = ListenableFutureTask.create(new Runnable() {
            @Override
            public void run() {
                if (result.errorMsg == null) {
                    if (result instanceof AdHocPlannedStmtBatch) {
                        final AdHocPlannedStmtBatch plannedStmtBatch = (AdHocPlannedStmtBatch) result;
                        ExplainMode explainMode = plannedStmtBatch.getExplainMode();

                        
                        if ((plannedStmtBatch.getPlannedStatementCount() > 0) &&
                            (!plannedStmtBatch.getPlannedStatement(0).core.wasPlannedAgainstHash(m_catalogContext.get().getCatalogHash())))
                        {

                            
                            LocalObjectMessage work = new LocalObjectMessage(
                                    AdHocPlannerWork.rework(plannedStmtBatch.work, m_adhocCompletionHandler));

                            m_mailbox.send(m_plannerSiteId, work);
                        }
                        else if (explainMode == ExplainMode.EXPLAIN_ADHOC) {
                            processExplainPlannedStmtBatch(plannedStmtBatch);
                        }
                        else if (explainMode == ExplainMode.EXPLAIN_DEFAULT_PROC) {
                            processExplainDefaultProc(plannedStmtBatch);
                        }
                        else {
                            try {
                                createAdHocTransaction(plannedStmtBatch, c);
                            }
                            catch (VoltTypeException vte) {
                                String msg = "Unable to execute adhoc sql statement(s): " +
                                        vte.getMessage();
                                ClientResponseImpl errorResponse =
                                    new ClientResponseImpl(
                                            ClientResponseImpl.GRACEFUL_FAILURE,
                                            new VoltTable[0], msg,
                                            result.clientHandle);
                                ByteBuffer buf = ByteBuffer.allocate(errorResponse.getSerializedSize() + 4);
                                buf.putInt(buf.capacity() - 4);
                                errorResponse.flattenToBuffer(buf);
                                buf.flip();
                                c.writeStream().enqueue(buf);
                            }
                        }
                    }
                    else if (result instanceof CatalogChangeResult) {
                        final CatalogChangeResult changeResult = (CatalogChangeResult) result;

                        
                        if (changeResult.encodedDiffCommands.trim().length() == 0) {
                            ClientResponseImpl shortcutResponse =
                                    new ClientResponseImpl(
                                            ClientResponseImpl.SUCCESS,
                                            new VoltTable[0], "Catalog update with no changes was skipped.",
                                            result.clientHandle);
                            ByteBuffer buf = ByteBuffer.allocate(shortcutResponse.getSerializedSize() + 4);
                            buf.putInt(buf.capacity() - 4);
                            shortcutResponse.flattenToBuffer(buf);
                            buf.flip();
                            c.writeStream().enqueue(buf);
                        }
                        else {
                            
                            StoredProcedureInvocation task = new StoredProcedureInvocation();
                            task.procName = "@UpdateApplicationCatalog";
                            task.setParams(changeResult.encodedDiffCommands,
                                           changeResult.catalogHash,
                                           changeResult.catalogBytes,
                                           changeResult.expectedCatalogVersion,
                                           changeResult.deploymentString,
                                           changeResult.tablesThatMustBeEmpty,
                                           changeResult.reasonsForEmptyTables,
                                           changeResult.requiresSnapshotIsolation ? 1 : 0,
                                           changeResult.worksWithElastic ? 1 : 0,
                                           changeResult.deploymentHash);
                            task.clientHandle = changeResult.clientHandle;
                            
                            task.type = changeResult.invocationType;
                            task.originalTxnId = changeResult.originalTxnId;
                            task.originalUniqueId = changeResult.originalUniqueId;

                            ClientResponseImpl error = null;
                            if ((error = m_permissionValidator.shouldAccept(task.procName, result.user, task,
                                    SystemProcedureCatalog.listing.get(task.procName).asCatalogProcedure())) != null) {
                                ByteBuffer buffer = ByteBuffer.allocate(error.getSerializedSize() + 4);
                                buffer.putInt(buffer.capacity() - 4);
                                error.flattenToBuffer(buffer).flip();
                                c.writeStream().enqueue(buffer);
                            }
                            else {
                                
                                try {
                                    task = MiscUtils.roundTripForCL(task);
                                } catch (Exception e) {
                                    hostLog.fatal(e);
                                    VoltDB.crashLocalVoltDB(e.getMessage(), true, e);
                                }

                                
                                
                                createTransaction(changeResult.connectionId,
                                        task, false, false, false, 0, task.getSerializedSize(),
                                        System.nanoTime());
                            }
                        }
                    }
                    else {
                        throw new RuntimeException(
                                "Should not be able to get here (ClientInterface.checkForFinishedCompilerWork())");
                    }
                }
                else {
                    ClientResponseImpl errorResponse =
                        new ClientResponseImpl(
                                ClientResponseImpl.GRACEFUL_FAILURE,
                                new VoltTable[0], result.errorMsg,
                                result.clientHandle);
                    ByteBuffer buf = ByteBuffer.allocate(errorResponse.getSerializedSize() + 4);
                    buf.putInt(buf.capacity() - 4);
                    errorResponse.flattenToBuffer(buf);
                    buf.flip();
                    c.writeStream().enqueue(buf);
                }
            }
        }, null);
        if (c != null) {
            c.queueTask(ft);
        }

        
        ft.addListener(new Runnable() {
            @Override
            public void run() {
                try {
                     ft.get();
                } catch (Exception e) {
                    String realReason = result.errorMsg;
                    
                    
                    
                    
                    
                    if (realReason == null) {
                        StringWriter sw = new StringWriter();
                        PrintWriter pw = new PrintWriter(sw);
                        e.printStackTrace(pw);
                        Throwable cause = e.getCause();
                        if (cause != null) {
                            cause.printStackTrace(pw);
                        }
                        pw.flush();
                        realReason = sw.toString();
                    }
                    ClientResponseImpl errorResponse =
                            new ClientResponseImpl(
                                    ClientResponseImpl.UNEXPECTED_FAILURE,
                                    new VoltTable[0], realReason,
                                    result.clientHandle);
                    ByteBuffer buf = ByteBuffer.allocate(errorResponse.getSerializedSize() + 4);
                    buf.putInt(buf.capacity() - 4);
                    errorResponse.flattenToBuffer(buf);
                    buf.flip();
                    c.writeStream().enqueue(buf);
                }
            }
        }, CoreUtils.SAMETHREADEXECUTOR);

        
        return ft;
    }

    private ScheduledFuture<?> m_deadConnectionFuture;
    private ScheduledFuture<?> m_topologyCheckFuture;
    public void schedulePeriodicWorks() {
        m_deadConnectionFuture = VoltDB.instance().scheduleWork(new Runnable() {
            @Override
            public void run() {
                try {
                    
                    checkForDeadConnections(EstTime.currentTimeMillis());
                } catch (Exception ex) {
                    log.warn("Exception while checking for dead connections", ex);
                }
            }
        }, 200, 200, TimeUnit.MILLISECONDS);
        
        m_topologyCheckFuture = VoltDB.instance().scheduleWork(new Runnable() {
            @Override
            public void run() {
                checkForTopologyChanges();
            }
        }, 0, TOPOLOGY_CHANGE_CHECK_MS, TimeUnit.MILLISECONDS);
    }

    
    private final AtomicReference<DeferredSerialization> m_currentTopologyValues =
            new AtomicReference<>(null);
    private final Supplier<DeferredSerialization> m_currentTopologySupplier = new Supplier<DeferredSerialization>() {
        @Override
        public DeferredSerialization get() {
            return m_currentTopologyValues.get();
        }
    };

    
    private final Predicate<ClientInterfaceHandleManager> m_wantsTopologyUpdatesPredicate =
            new Predicate<ClientInterfaceHandleManager>() {
                @Override
                public boolean apply(ClientInterfaceHandleManager input) {
                    return input.wantsTopologyUpdates();
                }};

    
    private void checkForTopologyChanges() {
        final Pair<SimpleClientResponseAdapter, ListenableFuture<ClientResponseImpl>> p =
                SimpleClientResponseAdapter.getAsListenableFuture();
        final ListenableFuture<ClientResponseImpl> fut = p.getSecond();
        fut.addListener(new Runnable() {
            @Override
            public void run() {
                try {
                    final ClientResponseImpl r = fut.get();
                    if (r.getStatus() != ClientResponse.SUCCESS) {
                        hostLog.warn("Received error response retrieving topology: " + r.getStatusString());
                        return;
                    }

                    final int size = r.getSerializedSize();
                    final ByteBuffer buf = ByteBuffer.allocate(size + 4);
                    buf.putInt(size);
                    r.flattenToBuffer(buf);
                    buf.flip();

                    
                    ByteBuffer oldValue = null;
                    DeferredSerialization ds = m_currentTopologyValues.get();
                    if (ds != null) {
                        oldValue = ByteBuffer.allocate(ds.getSerializedSize());
                        ds.serialize(oldValue);
                        oldValue.flip();
                    }

                    if (buf.equals(oldValue)) {
                        return;
                    }

                    m_currentTopologyValues.set(new DeferredSerialization() {
                        @Override
                        public void serialize(ByteBuffer outbuf) throws IOException {
                            outbuf.put(buf.duplicate());
                        }
                        @Override
                        public void cancel() {}

                        @Override
                        public int getSerializedSize() {
                            return buf.remaining();
                        }
                    });
                    if (oldValue != null) {
                        m_notifier.queueNotification(
                                m_cihm.values(),
                                m_currentTopologySupplier,
                                m_wantsTopologyUpdatesPredicate);
                    }

                } catch (Throwable t) {
                    hostLog.error("Error checking for topology updates", Throwables.getRootCause(t));
                }
            }
        }, CoreUtils.SAMETHREADEXECUTOR);
        final StoredProcedureInvocation spi = new StoredProcedureInvocation();
        spi.setProcName("@Statistics");
        spi.setParams("TOPO", 0);
        spi.setClientHandle(ASYNC_TOPO_HANDLE);
        dispatchStatistics(OpsSelector.STATISTICS, spi, p.getFirst());
    }

    private static final long CLIENT_HANGUP_TIMEOUT = Long.getLong("CLIENT_HANGUP_TIMEOUT", 30000);

    
    private final void checkForDeadConnections(final long now) {
        final ArrayList<Pair<Connection, Integer>> connectionsToRemove = new ArrayList<Pair<Connection, Integer>>();
        for (final ClientInterfaceHandleManager cihm : m_cihm.values()) {
            
            if (VoltPort.class == cihm.connection.getClass()) {
                final int delta = cihm.connection.writeStream().calculatePendingWriteDelta(now);
                if (delta > CLIENT_HANGUP_TIMEOUT) {
                    connectionsToRemove.add(Pair.of(cihm.connection, delta));
                }
            }
        }

        for (final Pair<Connection, Integer> p : connectionsToRemove) {
            Connection c = p.getFirst();
            networkLog.warn("Closing connection to " + c +
                    " because it hasn't read a response that was pending for " +  p.getSecond() + " milliseconds");
            c.unregister();
        }
    }

    
    
    
    
    protected void shutdown() throws InterruptedException {
        if (m_deadConnectionFuture != null) {
            m_deadConnectionFuture.cancel(false);
            try {m_deadConnectionFuture.get();} catch (Throwable t) {}
        }
        if (m_topologyCheckFuture != null) {
            m_topologyCheckFuture.cancel(false);
            try {m_topologyCheckFuture.get();} catch (Throwable t) {}
        }
        if (m_maxConnectionUpdater != null) {
            m_maxConnectionUpdater.cancel(false);
        }
        if (m_acceptor != null) {
            m_acceptor.shutdown();
        }
        if (m_adminAcceptor != null)
        {
            m_adminAcceptor.shutdown();
        }
        if (m_snapshotDaemon != null) {
            m_snapshotDaemon.shutdown();
        }
        if (m_localReplicasBuilder != null) {
            m_localReplicasBuilder.join(10000);
            if (m_localReplicasBuilder.isAlive()) {
                hostLog.error("Local replica map builder took more than ten seconds, probably hung");
            }
            m_localReplicasBuilder.join();
        }
        m_notifier.shutdown();
    }

    private volatile Thread m_localReplicasBuilder = null;
    public void startAcceptingConnections() throws IOException {
        
        m_localReplicasBuilder = new Thread() {
            @Override
            public void run() {
                    
                final int thisHostId = CoreUtils.getHostIdFromHSId(m_mailbox.getHSId());
                ImmutableMap.Builder<Integer, Long> localReplicas = ImmutableMap.builder();
                for (int partition : m_cartographer.getPartitions()) {
                    for (Long replica : m_cartographer.getReplicasForPartition(partition)) {
                        if (CoreUtils.getHostIdFromHSId(replica) == thisHostId) {
                            localReplicas.put(partition, replica);
                        }
                    }
                }
                m_localReplicas = localReplicas.build();
            }
        };
        m_localReplicasBuilder.start();

        
        m_maxConnectionUpdater = VoltDB.instance().scheduleWork(new Runnable() {
            @Override
            public void run() {
                Integer limit = org.voltdb.utils.CLibrary.getOpenFileLimit();
                if (limit != null) {
                    
                    MAX_CONNECTIONS.set(limit - 300);
                }
            }
        }, 0, 10, TimeUnit.MINUTES);
        m_acceptor.start();
        if (m_adminAcceptor != null)
        {
            m_adminAcceptor.start();
        }
        mayActivateSnapshotDaemon();
        m_notifier.start();
    }

    
    static int getPartitionForProcedure(int partitionIndex, VoltType partitionType,
                                        StoredProcedureInvocation task)
            throws Exception
    {
        Object invocationParameter = task.getParameterAtIndex(partitionIndex);
        return TheHashinator.getPartitionForParameter(partitionType, invocationParameter);
    }

    @Override
    public void initiateSnapshotDaemonWork(final String procedureName, long clientData, final Object params[]) {
        final Config sysProc = SystemProcedureCatalog.listing.get(procedureName);
        if (sysProc == null) {
            throw new RuntimeException("SnapshotDaemon attempted to invoke " + procedureName +
            " which is not a known procedure");
        }
        Procedure catProc = sysProc.asCatalogProcedure();
        StoredProcedureInvocation spi = new StoredProcedureInvocation();
        spi.procName = procedureName;
        spi.params = new FutureTask<ParameterSet>(new Callable<ParameterSet>() {
            @Override
            public ParameterSet call() {
                ParameterSet paramSet = ParameterSet.fromArrayWithCopy(params);
                return paramSet;
            }
        });
        spi.clientHandle = clientData;
        
        if (procedureName.equals("@SnapshotScan")) {
            dispatchStatistics(OpsSelector.SNAPSHOTSCAN, spi, m_snapshotDaemonAdapter);
            return;
        }
        else if (procedureName.equals("@SnapshotDelete")) {
            dispatchStatistics(OpsSelector.SNAPSHOTDELETE, spi, m_snapshotDaemonAdapter);
            return;
        }
        
        createTransaction(m_snapshotDaemonAdapter.connectionId(),
                spi, catProc.getReadonly(),
                catProc.getSinglepartition(), catProc.getEverysite(),
                0,
                0, System.nanoTime());
    }

    
    private class SnapshotDaemonAdapter implements Connection, WriteStream {

        @Override
        public void disableReadSelection() {
            throw new UnsupportedOperationException();
        }

        @Override
        public void enableReadSelection() {
            throw new UnsupportedOperationException();
        }

        @Override
        public NIOReadStream readStream() {
            throw new UnsupportedOperationException();
        }

        @Override
        public WriteStream writeStream() {
            return this;
        }

        @Override
        public int calculatePendingWriteDelta(long now) {
            throw new UnsupportedOperationException();
        }

        @Override
        public boolean hadBackPressure() {
            throw new UnsupportedOperationException();
        }

        @Override
        public boolean isEmpty() {
            throw new UnsupportedOperationException();
        }

        @Override
        public String getHostnameAndIPAndPort() {
            return "SnapshotDaemon";
        }

        @Override
        public String getHostnameOrIP() {
            return "SnapshotDaemon";
        }

        @Override
        public int getRemotePort() {
            return -1;
        }

        @Override
        public InetSocketAddress getRemoteSocketAddress() {
            return null;
        }

        @Override
        public Future<?> unregister() {
            return null;
        }

        @Override
        public long connectionId()
        {
            return Long.MIN_VALUE;
        }

        @Override
        public int getOutstandingMessageCount()
        {
            throw new UnsupportedOperationException();
        }

        @Override
        public void fastEnqueue(final org.voltcore.utils.DeferredSerialization ds) {
            enqueue(ds);
        }

        @Override
        public void enqueue(final org.voltcore.utils.DeferredSerialization ds)
        {

            m_snapshotDaemon.processClientResponse(new Callable<ClientResponseImpl>() {
                @Override
                public ClientResponseImpl call() throws Exception {
                    ClientResponseImpl resp = new ClientResponseImpl();
                    ByteBuffer b = ByteBuffer.allocate(ds.getSerializedSize());
                    ds.serialize(b);
                    b.position(4);
                    resp.initFromBuffer(b);
                    return resp;
                }
            });
        }

        @Override
        public void enqueue(final ByteBuffer b)
        {
            m_snapshotDaemon.processClientResponse(new Callable<ClientResponseImpl>() {
                @Override
                public ClientResponseImpl call() throws Exception {
                    ClientResponseImpl resp = new ClientResponseImpl();
                    b.position(4);
                    resp.initFromBuffer(b);
                    return resp;
                }
            });
        }

        @Override
        public void enqueue(ByteBuffer[] b)
        {
            if (b.length == 1)
            {
                
                
                enqueue(b[0]);
            }
            else
            {
                log.error("Something is using buffer chains with enqueue");
            }
        }

        @Override
        public void queueTask(Runnable r) {
            
            r.run();
        }
    }

    public Map<Long, Pair<String, long[]>> getLiveClientStats()
    {
        final Map<Long, Pair<String, long[]>> client_stats =
            new HashMap<Long, Pair<String, long[]>>();

        
        
        for (Map.Entry<Long, ClientInterfaceHandleManager> e : m_cihm.entrySet()) {
            
            
            if (e.getKey() > 0) {
                long adminMode = e.getValue().isAdmin ? 1 : 0;
                long readWait = e.getValue().connection.readStream().dataAvailable();
                long writeWait = e.getValue().connection.writeStream().getOutstandingMessageCount();
                long outstandingTxns = e.getValue().getOutstandingTxns();
                client_stats.put(
                        e.getKey(), new Pair<String, long[]>(
                            e.getValue().connection.getHostnameOrIP(),
                            new long[] {adminMode, readWait, writeWait, outstandingTxns}));
            }
        }
        return client_stats;
    }

    public SnapshotDaemon getSnapshotDaemon() {
        return m_snapshotDaemon;
    }

    
    public void sendSentinel(long txnId, int partitionId) {
        final long initiatorHSId = m_cartographer.getHSIdForSinglePartitionMaster(partitionId);
        sendSentinel(txnId, initiatorHSId, -1, -1, true);
    }

    private void sendSentinel(long txnId, long initiatorHSId, long ciHandle,
                              long connectionId, boolean forReplay) {
        
        MultiPartitionParticipantMessage mppm =
                new MultiPartitionParticipantMessage(
                        m_siteId,
                        initiatorHSId,
                        txnId,
                        ciHandle,
                        connectionId,
                        false,  
                        forReplay);  
        m_mailbox.send(initiatorHSId, mppm);
    }

    
    public void sendEOLMessage(int partitionId) {
        final long initiatorHSId = m_cartographer.getHSIdForMaster(partitionId);
        Iv2EndOfLogMessage message = new Iv2EndOfLogMessage(partitionId);
        m_mailbox.send(initiatorHSId, message);
    }

    public List<Iterator<Map.Entry<Long, Map<String, InvocationInfo>>>> getIV2InitiatorStats() {
        ArrayList<Iterator<Map.Entry<Long, Map<String, InvocationInfo>>>> statsIterators =
                new ArrayList<Iterator<Map.Entry<Long, Map<String, InvocationInfo>>>>();
        for(AdmissionControlGroup acg : m_allACGs) {
            statsIterators.add(acg.getInitiationStatsIterator());
        }
        return statsIterators;
    }

    public List<AbstractHistogram> getLatencyStats() {
        List<AbstractHistogram> latencyStats = new ArrayList<AbstractHistogram>();
        for (AdmissionControlGroup acg : m_allACGs) {
            latencyStats.add(acg.getLatencyInfo());
        }
        return latencyStats;
    }

    
    private ClientResponseImpl getMispartitionedErrorResponse(StoredProcedureInvocation task,
            Procedure catProc, Exception ex) {
        Object invocationParameter = null;
        try {
            invocationParameter = task.getParameterAtIndex(catProc.getPartitionparameter());
        } catch (Exception ex2) {
        }
        String exMsg = "Unknown";
        if (ex != null) {
            exMsg = ex.getMessage();
        }
        String errorMessage = "Error sending procedure " + task.procName
                + " to the correct partition. Make sure parameter values are correct."
                + " Parameter value " + invocationParameter
                + ", partition column " + catProc.getPartitioncolumn().getName()
                + " type " + catProc.getPartitioncolumn().getType()
                + " Message: " + exMsg;
        authLog.warn(errorMessage);
        ClientResponseImpl clientResponse = new ClientResponseImpl(ClientResponse.UNEXPECTED_FAILURE,
                new VoltTable[0], errorMessage, task.clientHandle);
        return clientResponse;
    }

}

<code block>


package org.voltdb.compiler;

import org.voltcore.network.Connection;
import org.voltdb.AuthSystem;
import org.voltdb.CatalogContext;
import org.voltdb.ClientInterface.ExplainMode;
import org.voltdb.client.ProcedureInvocationType;


public class AdHocPlannerWork extends AsyncCompilerWork {
    private static final long serialVersionUID = -6567283432846270119L;

    final String sqlBatchText;
    final String[] sqlStatements;
    final Object[] userParamSet;
    final CatalogContext catalogContext;
    final boolean inferPartitioning;
    
    
    
    final Object[] userPartitionKey;
    public final ExplainMode explainMode;

    public AdHocPlannerWork(long replySiteId, long clientHandle, long connectionId,
            boolean adminConnection, Connection clientConnection,
            String sqlBatchText, String[] sqlStatements,
            Object[] userParamSet, CatalogContext context, ExplainMode explainMode,
            boolean inferPartitioning, Object[] userPartitionKey,
            String invocationName, ProcedureInvocationType type,
            long originalTxnId, long originalUniqueId,
            boolean onReplica, boolean useAdhocDDL,
            AsyncCompilerWorkCompletionHandler completionHandler, AuthSystem.AuthUser user)
    {
        super(replySiteId, false, clientHandle, connectionId,
              clientConnection == null ? "" : clientConnection.getHostnameAndIPAndPort(),
              adminConnection, clientConnection, invocationName, type,
              originalTxnId, originalUniqueId, onReplica, useAdhocDDL,
              completionHandler, user);
        this.sqlBatchText = sqlBatchText;
        this.sqlStatements = sqlStatements;
        this.userParamSet = userParamSet;
        this.catalogContext = context;
        this.explainMode = explainMode;
        this.inferPartitioning = inferPartitioning;
        this.userPartitionKey = userPartitionKey;
    }

    
    public static AdHocPlannerWork rework(AdHocPlannerWork orig,
            AsyncCompilerWorkCompletionHandler completionHandler) {
        return new AdHocPlannerWork(orig.replySiteId,
                orig.clientHandle,
                orig.connectionId,
                orig.adminConnection,
                (Connection) orig.clientData,
                orig.sqlBatchText,
                orig.sqlStatements,
                orig.userParamSet,
                null ,
                orig.explainMode,
                orig.inferPartitioning,
                orig.userPartitionKey,
                orig.invocationName,
                orig.invocationType,
                orig.originalTxnId,
                orig.originalUniqueId,
                orig.onReplica,
                orig.useAdhocDDL,
                completionHandler,
                orig.user);
        }

    
    public static AdHocPlannerWork makeStoredProcAdHocPlannerWork(long replySiteId,
            String sql, Object[] userParams, boolean singlePartition, CatalogContext context,
            AsyncCompilerWorkCompletionHandler completionHandler)
    {
        return new AdHocPlannerWork(replySiteId, 0, 0, false, null,
            sql, new String[] { sql },
            userParams, context, ExplainMode.NONE,
            
            
            
            
            
            
            
            false, (singlePartition ? new Object[1]  : null),
            "@AdHoc_RW_MP", ProcedureInvocationType.ORIGINAL, 0, 0,
            false, false, 
            completionHandler, new AuthSystem.AuthDisabledUser());
    }

    @Override
    public String toString() {
        String retval = super.toString();
        if (userParamSet == null || (userParamSet.length == 0)) {
            retval += "\n  user params: empty";
        } else {
            int i = 0;
            for (Object param : userParamSet) {
                i++;
                retval += String.format("\n  user param[%d]: %s",
                                        i, (param == null ? "null" : param.toString()));
            }
        }
        if (userPartitionKey == null) {
            retval += "\n  user partitioning: none";
        } else {
            retval += "\n  user partitioning: " +
                      (userPartitionKey[0] == null ? "null" : userPartitionKey[0].toString());
        }
        assert(sqlStatements != null);
        if (sqlStatements.length == 0) {
            retval += "\n  sql: empty";
        } else {
            int i = 0;
            for (String sql : sqlStatements) {
                i++;
                retval += String.format("\n  sql[%d]: %s", i, sql);
            }
        }
        return retval;
    }

    public int getStatementCount()
    {
        return (this.sqlStatements != null ? this.sqlStatements.length : 0);
    }

    public int getParameterCount()
    {
        return (this.userParamSet != null ? this.userParamSet.length : 0);
    }

}

<code block>


package org.voltdb.compiler;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.List;

import org.json_voltpatches.JSONException;
import org.json_voltpatches.JSONObject;
import org.voltcore.network.Connection;
import org.voltdb.ClientInterface.ExplainMode;
import org.voltdb.ParameterConverter;
import org.voltdb.ParameterSet;
import org.voltdb.VoltType;
import org.voltdb.VoltTypeException;
import org.voltdb.catalog.Database;
import org.voltdb.common.Constants;
import org.voltdb.compiler.AsyncCompilerWork.AsyncCompilerWorkCompletionHandler;
import org.voltdb.planner.CorePlan;
import org.voltdb.plannodes.PlanNodeTree;
import org.voltdb.plannodes.SendPlanNode;


public class AdHocPlannedStmtBatch extends AsyncCompilerResult implements Cloneable {
    private static final long serialVersionUID = -8627490621430290801L;

    
    
    public final int partitionParamIndex;
    public final VoltType partitionParamType;
    public final Object partitionParamValue;

    
    public final List<AdHocPlannedStatement> plannedStatements;

    
    public final boolean readOnly;

    
    public final AdHocPlannerWork work;

    
    public AdHocPlannedStmtBatch(
            AdHocPlannerWork work,
            List<AdHocPlannedStatement> stmts,
            int partitionParamIndex,
            VoltType partitionParamType,
            Object partitionParamValue,
            String errors) {
        this.work = work;

        this.clientHandle = work.clientHandle;
        this.connectionId = work.connectionId;
        this.hostname =
            (work.clientData == null) ? "" : ((Connection)work.clientData).getHostnameAndIPAndPort();
        this.adminConnection = work.adminConnection;
        this.clientData = work.clientData;

        this.plannedStatements = stmts;
        boolean allReadOnly = true;
        for (AdHocPlannedStatement plannedStmt : stmts) {
            
            if (!plannedStmt.core.readOnly) {
                allReadOnly = false;
                break;
            }
        }
        this.readOnly = allReadOnly;
        this.partitionParamIndex = partitionParamIndex;
        this.partitionParamType = partitionParamType;
        this.partitionParamValue = partitionParamValue;
        this.errorMsg = errors;
    }

    public static AdHocPlannedStmtBatch mockStatementBatch(long replySiteId, String sql,
            Object[] extractedValues, VoltType[] paramTypes,
            Object[] userParams, int partitionParamIndex, byte[] catalogHash)
    {
        
        AsyncCompilerWorkCompletionHandler dummyHandler = new AsyncCompilerWorkCompletionHandler() {

            @Override
            public void onCompletion(AsyncCompilerResult result) {
                System.out.println("Hmm. Never expected to call this dummy handler.");
            }
        };
        
        AdHocPlannerWork work = AdHocPlannerWork.makeStoredProcAdHocPlannerWork(replySiteId,
                                                                                sql,
                                                                                userParams,
                                                                                false, 
                                                                                null, dummyHandler);
        
        CorePlan core = new CorePlan(new byte[0],
                partitionParamIndex == -1 ? new byte[20] : null,
                new byte[20],
                partitionParamIndex == -1 ? new byte[20] : null,
                false,
                true,
                paramTypes,
                catalogHash);
        AdHocPlannedStatement s = new AdHocPlannedStatement(sql.getBytes(Constants.UTF8ENCODING),
                core,
                extractedValues == null ? ParameterSet.emptyParameterSet() :
                                          ParameterSet.fromArrayNoCopy(extractedValues),
                null);
        List<AdHocPlannedStatement> stmts = new ArrayList<AdHocPlannedStatement>();
        stmts.add(s);
        VoltType partitionParamType = null;
        Object partitionParamValue = null;
        if (work.userPartitionKey != null) {
            partitionParamValue = work.userPartitionKey[0];
        }
        else if (partitionParamIndex > -1) {
            partitionParamValue = userParams[partitionParamIndex];
        }
        if (partitionParamValue != null) {
            partitionParamType = VoltType.typeFromObject(partitionParamValue);
        }
        
        AdHocPlannedStmtBatch plannedStmtBatch = new AdHocPlannedStmtBatch(work,
                                                                           stmts,
                                                                           partitionParamIndex,
                                                                           partitionParamType,
                                                                           partitionParamValue,
                                                                           null);
        return plannedStmtBatch;
    }

    @Override
    public String toString() {
        String retval = super.toString();
        retval += "\n  partition param: " + ((partitionParamValue != null) ? partitionParamValue.toString() : "null");
        retval += "\n  partition param index: " + partitionParamIndex;
        retval += "\n  sql: " + work.sqlBatchText;
        return retval;
    }

    @Override
    public Object clone() {
        try {
            return super.clone();
        } catch (CloneNotSupportedException e) {
            throw new RuntimeException(e);
        }
    }

    
    public List<String> getSQLStatements() {
        List<String> sqlStatements = new ArrayList<String>(plannedStatements.size());
        for (AdHocPlannedStatement plannedStatement : plannedStatements) {
            sqlStatements.add(new String(plannedStatement.sql, Constants.UTF8ENCODING));
        }
        return sqlStatements;
    }

    
    public boolean isSinglePartitionCompatible() {
        for (AdHocPlannedStatement plannedStmt : plannedStatements) {
            if (plannedStmt.core.collectorFragment != null) {
                return false;
            }
        }
        return true;
    }

    
    public int getPlannedStatementCount() {
        return plannedStatements.size();
    }

    
    public AdHocPlannedStatement getPlannedStatement(int index) {
        return plannedStatements.get(index);
    }

    
    public boolean isReadOnly() {
        return readOnly;
    }

    
    public ByteBuffer flattenPlanArrayToBuffer() throws IOException {
        int size = 0; 

        ParameterSet userParamCache = null;
        if (work.userParamSet == null) {
            userParamCache = ParameterSet.emptyParameterSet();
        } else {
            Object[] typedUserParams = new Object[work.userParamSet.length];
            int ii = 0;
            for (AdHocPlannedStatement cs : plannedStatements) {
                for (VoltType paramType : cs.core.parameterTypes) {
                    if (ii >= typedUserParams.length) {
                        String errorMsg =
                            "Too few actual arguments were passed for the parameters in the sql statement(s): (" +
                            typedUserParams.length + " vs. " + ii + ")";
                        
                        throw new VoltTypeException(errorMsg);
                    }
                    typedUserParams[ii] =
                            ParameterConverter.tryToMakeCompatible(paramType.classFromType(),
                                                                   work.userParamSet[ii]);
                    
                    
                    ii++;
                }
            }
            
            
            if (ii < typedUserParams.length) {
                
                String errorMsg =
                        "Too many actual arguments were passed for the parameters in the sql statement(s): (" +
                        typedUserParams.length + " vs. " + ii + ")";
                        throw new VoltTypeException(errorMsg);
            }
            userParamCache = ParameterSet.fromArrayNoCopy(typedUserParams);
        }
        size += userParamCache.getSerializedSize();

        size += 2; 
        for (AdHocPlannedStatement cs : plannedStatements) {
            size += cs.getSerializedSize();
        }

        ByteBuffer buf = ByteBuffer.allocate(size);
        userParamCache.flattenToBuffer(buf);
        buf.putShort((short) plannedStatements.size());
        for (AdHocPlannedStatement cs : plannedStatements) {
            cs.flattenToBuffer(buf);
        }
        return buf;
    }

    
    public static Object[] userParamsFromBuffer(ByteBuffer buf) throws IOException {
        return ParameterSet.fromByteBuffer(buf).toArray();
    }

    
    public static AdHocPlannedStatement[] planArrayFromBuffer(ByteBuffer buf) throws IOException {
        short csCount = buf.getShort();
        AdHocPlannedStatement[] statements = new AdHocPlannedStatement[csCount];
        for (int i = 0; i < csCount; ++i) {
            AdHocPlannedStatement cs = AdHocPlannedStatement.fromBuffer(buf);
            statements[i] = cs;
        }
        return statements;
    }

    public ExplainMode getExplainMode() {
        return work.explainMode;
    }

    
    public Object partitionParam() {
        if (work.userPartitionKey != null) {
            return work.userPartitionKey[0];
        }
        if (partitionParamIndex > -1 && work.userParamSet != null &&
                work.userParamSet.length > partitionParamIndex) {
            Object userParamValue = work.userParamSet[partitionParamIndex];
            if (partitionParamType == null) {
                return userParamValue;
            } else {
                return ParameterConverter.tryToMakeCompatible(partitionParamType.classFromType(), userParamValue);
            }
        }
        return partitionParamValue;
    }

    
    public String explainStatement(int i, Database db) {
        String str = "";
        AdHocPlannedStatement plannedStatement = plannedStatements.get(i);
        String aggplan = new String(plannedStatement.core.aggregatorFragment, Constants.UTF8ENCODING);
        PlanNodeTree pnt = new PlanNodeTree();
        try {
            JSONObject jobj = new JSONObject( aggplan );
            pnt.loadFromJSONPlan(jobj, db);

            if( plannedStatement.core.collectorFragment != null ) {
                
                String collplan = new String(plannedStatement.core.collectorFragment, Constants.UTF8ENCODING);
                PlanNodeTree collpnt = new PlanNodeTree();
                
                JSONObject jobMP = new JSONObject( collplan );
                collpnt.loadFromJSONPlan(jobMP, db);
                assert( collpnt.getRootPlanNode() instanceof SendPlanNode);
                pnt.getRootPlanNode().reattachFragment( (SendPlanNode) collpnt.getRootPlanNode() );
            }
            str = pnt.getRootPlanNode().toExplainPlanString();
        } catch (JSONException e) {
            System.out.println(e.getMessage());
        }
        return str;
    }

}

<code block>


package org.voltdb;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import static org.mockito.Matchers.any;
import static org.mockito.Matchers.anyInt;
import static org.mockito.Matchers.anyLong;
import static org.mockito.Matchers.anyObject;
import static org.mockito.Matchers.eq;
import static org.mockito.Mockito.doAnswer;
import static org.mockito.Mockito.doReturn;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.never;
import static org.mockito.Mockito.reset;
import static org.mockito.Mockito.spy;
import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.when;

import java.io.File;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayDeque;
import java.util.Arrays;
import java.util.HashSet;
import java.util.Queue;
import java.util.Set;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.Executors;
import java.util.concurrent.LinkedTransferQueue;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;

import org.apache.zookeeper_voltpatches.CreateMode;
import org.apache.zookeeper_voltpatches.ZooDefs.Ids;
import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.junit.After;
import org.junit.Before;
import org.junit.BeforeClass;
import org.junit.Test;
import org.mockito.ArgumentCaptor;
import org.mockito.invocation.InvocationOnMock;
import org.mockito.stubbing.Answer;
import org.voltcore.messaging.HostMessenger;
import org.voltcore.messaging.LocalObjectMessage;
import org.voltcore.messaging.VoltMessage;
import org.voltcore.network.Connection;
import org.voltcore.network.VoltNetworkPool;
import org.voltcore.utils.DeferredSerialization;
import org.voltcore.utils.Pair;
import org.voltdb.ClientInterface.ClientInputHandler;
import org.voltdb.VoltDB.Configuration;
import org.voltdb.VoltTable.ColumnInfo;
import org.voltdb.catalog.Catalog;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureInvocationType;
import org.voltdb.common.Constants;
import org.voltdb.compiler.AdHocPlannedStatement;
import org.voltdb.compiler.AdHocPlannedStmtBatch;
import org.voltdb.compiler.AdHocPlannerWork;
import org.voltdb.compiler.CatalogChangeResult;
import org.voltdb.compiler.CatalogChangeWork;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.iv2.Cartographer;
import org.voltdb.messaging.InitiateResponseMessage;
import org.voltdb.messaging.Iv2InitiateTaskMessage;
import org.voltdb.utils.CatalogUtil;
import org.voltdb.utils.Encoder;
import org.voltdb.utils.MiscUtils;

public class TestClientInterface {
    
    private VoltDBInterface m_volt;
    private Queue<DeferredSerialization> statsAnswers = new ArrayDeque<DeferredSerialization>();
    private int drStatsInvoked = 0;
    private StatsAgent m_statsAgent = new StatsAgent() {
        @Override
        public void performOpsAction(final Connection c, final long clientHandle, final OpsSelector selector,
                                     final ParameterSet params) throws Exception {
            final String stat = (String)params.toArray()[0];
            if (stat.equals("TOPO") && !statsAnswers.isEmpty()) {
                c.writeStream().enqueue(statsAnswers.poll());
            } else if (stat.equals("DR")) {
                drStatsInvoked++;
            }
        }
    };
    private SystemInformationAgent m_sysinfoAgent;
    private HostMessenger m_messenger;
    private ClientInputHandler m_handler;
    private Cartographer m_cartographer;
    private SimpleClientResponseAdapter m_cxn;
    private ZooKeeper m_zk;

    
    private static CatalogContext m_context = null;

    
    private static ClientInterface m_ci = null;
    
    

    private static int[] m_allPartitions = new int[] {0, 1, 2};

    @BeforeClass
    public static void setUpOnce() throws Exception {
        buildCatalog();

    }

    BlockingQueue<ByteBuffer> responses = new LinkedTransferQueue<ByteBuffer>();
    BlockingQueue<DeferredSerialization> responsesDS = new LinkedTransferQueue<DeferredSerialization>();
    private static final ScheduledExecutorService ses = Executors.newScheduledThreadPool(1);

    @Before
    public void setUp() throws Exception {
        
        m_volt = mock(VoltDBInterface.class);
        m_sysinfoAgent = mock(SystemInformationAgent.class);
        m_messenger = mock(HostMessenger.class);
        m_handler = mock(ClientInputHandler.class);
        m_cartographer = mock(Cartographer.class);
        m_zk = mock(ZooKeeper.class);
        responses = new LinkedTransferQueue<ByteBuffer>();
        responsesDS = new LinkedTransferQueue<DeferredSerialization>();
        
        drStatsInvoked = 0;
        m_cxn = new SimpleClientResponseAdapter(0, "foo") {
            @Override
            public void enqueue(ByteBuffer buf) {responses.offer(buf);}
            @Override
            public void enqueue(ByteBuffer bufs[]) {responses.offer(bufs[0]);}
            @Override
            public void enqueue(DeferredSerialization ds) {responsesDS.offer(ds);}
            @Override
            public void queueTask(Runnable r) {}
        };


        
        VoltDB.replaceVoltDBInstanceForTest(m_volt);
        doReturn(m_cxn.connectionId()).when(m_handler).connectionId();
        doReturn(m_statsAgent).when(m_volt).getStatsAgent();
        doReturn(m_statsAgent).when(m_volt).getOpsAgent(OpsSelector.STATISTICS);
        doReturn(m_sysinfoAgent).when(m_volt).getOpsAgent(OpsSelector.SYSTEMINFORMATION);
        doReturn(mock(SnapshotCompletionMonitor.class)).when(m_volt).getSnapshotCompletionMonitor();
        doReturn(m_messenger).when(m_volt).getHostMessenger();
        doReturn(mock(VoltNetworkPool.class)).when(m_messenger).getNetwork();
        doReturn(m_zk).when(m_messenger).getZK();
        doReturn(mock(Configuration.class)).when(m_volt).getConfig();
        doReturn(32L).when(m_messenger).getHSIdForLocalSite(HostMessenger.ASYNC_COMPILER_SITE_ID);
        doReturn(ReplicationRole.NONE).when(m_volt).getReplicationRole();
        doReturn(m_context).when(m_volt).getCatalogContext();
        doAnswer(new Answer<Object>() {
            @Override
            public Object answer(InvocationOnMock invocation)
            {
                Object args[] = invocation.getArguments();
                return ses.scheduleAtFixedRate((Runnable) args[0], (long) args[1], (long) args[2], (TimeUnit) args[3]);
            }
        }).when(m_volt).scheduleWork(any(Runnable.class), anyLong(), anyLong(), (TimeUnit)anyObject());

        m_ci = spy(new ClientInterface(null, VoltDB.DEFAULT_PORT, null, VoltDB.DEFAULT_ADMIN_PORT,
                m_context, m_messenger, ReplicationRole.NONE,
                m_cartographer, m_allPartitions));
        m_ci.bindAdapter(m_cxn, null);

        
    }

    private static void buildCatalog() throws IOException {
        
        File cat = File.createTempFile("temp-log-reinitiator", "catalog");
        cat.deleteOnExit();

        VoltProjectBuilder builder = new VoltProjectBuilder();
        String schema = "create table A (i integer not null, primary key (i));";
        builder.addLiteralSchema(schema);
        builder.addPartitionInfo("A", "i");
        builder.addStmtProcedure("hello", "select * from A where i = ?", "A.i: 0");

        if (!builder.compile(cat.getAbsolutePath())) {
            throw new IOException();
        }

        byte[] bytes = MiscUtils.fileToBytes(cat);
        String serializedCat =
            CatalogUtil.getSerializedCatalogStringFromJar(CatalogUtil.loadAndUpgradeCatalogFromJar(bytes).getFirst());
        assertNotNull(serializedCat);
        Catalog catalog = new Catalog();
        catalog.execute(serializedCat);

        String deploymentPath = builder.getPathToDeployment();
        CatalogUtil.compileDeployment(catalog, deploymentPath, false);

        m_context = new CatalogContext(0, 0, catalog, bytes, new byte[] {}, 0);
        TheHashinator.initialize(TheHashinator.getConfiguredHashinatorClass(), TheHashinator.getConfigureBytes(3));
    }

    @After
    public void tearDown() {
        reset(m_messenger);
        reset(m_handler);
    }

    private static ByteBuffer createMsg(String name, final Object...params) throws IOException {
        return createMsg(null, name, params);
    }

    
    private static ByteBuffer createMsg(Long origTxnId, String name,
                                        final Object...params) throws IOException
    {
        StoredProcedureInvocation proc = new StoredProcedureInvocation();
        proc.setProcName(name);
        if (origTxnId != null) {
            proc.setOriginalTxnId(origTxnId);
        }
        proc.setParams(params);
        ByteBuffer buf = ByteBuffer.allocate(proc.getSerializedSize());
        proc.flattenToBuffer(buf);
        buf.flip();
        return buf;
    }

    
    private Iv2InitiateTaskMessage readAndCheck(ByteBuffer msg, String procName, Object partitionParam,
                                                boolean isReadonly, boolean isSinglePart) throws Exception {
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);

        return checkInitMsgSent(procName, partitionParam, isReadonly, isSinglePart);
    }

    private Iv2InitiateTaskMessage checkInitMsgSent(String procName, Object partitionParam,
                                                    boolean isReadonly, boolean isSinglePart)
    {

        ArgumentCaptor<Long> destinationCaptor =
            ArgumentCaptor.forClass(Long.class);
        ArgumentCaptor<Iv2InitiateTaskMessage> messageCaptor =
            ArgumentCaptor.forClass(Iv2InitiateTaskMessage.class);
        verify(m_messenger).send(destinationCaptor.capture(), messageCaptor.capture());

        Iv2InitiateTaskMessage message = messageCaptor.getValue();
        assertEquals(isReadonly, message.isReadOnly()); 
        assertEquals(isSinglePart, message.isSinglePartition()); 
        assertEquals(procName, message.getStoredProcedureName());
        if (isSinglePart) {
            int expected = TheHashinator.getPartitionForParameter(VoltType.typeFromObject(partitionParam).getValue(),
                                                                  partitionParam);
            assertEquals(new Long(m_cartographer.getHSIdForMaster(expected)), destinationCaptor.getValue());
        } else {
            assertEquals(new Long(m_cartographer.getHSIdForMultiPartitionInitiator()), destinationCaptor.getValue());
        }
        return message;
    }

    @Test
    public void testExplain() throws IOException {
        ByteBuffer msg = createMsg("@Explain", "select * from a");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        ArgumentCaptor<LocalObjectMessage> captor = ArgumentCaptor.forClass(LocalObjectMessage.class);
        verify(m_messenger).send(eq(32L), captor.capture());
        assertTrue(captor.getValue().payload instanceof AdHocPlannerWork );
        System.out.println( captor.getValue().payload.toString() );
        String payloadString = captor.getValue().payload.toString();
        assertTrue(payloadString.contains("user partitioning: none"));
    }

    @Test
    public void testAdHoc() throws IOException {
        ByteBuffer msg = createMsg("@AdHoc", "select * from a");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        ArgumentCaptor<LocalObjectMessage> captor = ArgumentCaptor.forClass(LocalObjectMessage.class);
        verify(m_messenger).send(eq(32L), captor.capture());
        assertTrue(captor.getValue().payload instanceof AdHocPlannerWork);
        String payloadString = captor.getValue().payload.toString();
        assertTrue(payloadString.contains("user partitioning: none"));

        
        reset(m_messenger);
        msg = createMsg("@AdHocSpForTest", "select * from a where i = 3", 3);
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        verify(m_messenger).send(eq(32L), captor.capture());
        assertTrue(captor.getValue().payload instanceof AdHocPlannerWork);
        payloadString = captor.getValue().payload.toString();
        assertTrue(payloadString.contains("user params: empty"));
        assertTrue(payloadString.contains("user partitioning: 3"));
    }

    @Test
    public void testFinishedSPAdHocPlanning() throws Exception {
        
        String query = "select * from a where i = ?";
        int partitionParamIndex = 0;
        Object[] extractedValues =  new Object[0];
        VoltType[] paramTypes =  new VoltType[]{VoltType.INTEGER};
        AdHocPlannedStmtBatch plannedStmtBatch =
                AdHocPlannedStmtBatch.mockStatementBatch(3, query, extractedValues, paramTypes,
                                                         new Object[]{3}, partitionParamIndex,
                                                         m_context.getCatalogHash());
        m_ci.processFinishedCompilerWork(plannedStmtBatch).run();

        ArgumentCaptor<Long> destinationCaptor =
                ArgumentCaptor.forClass(Long.class);
        ArgumentCaptor<Iv2InitiateTaskMessage> messageCaptor =
                ArgumentCaptor.forClass(Iv2InitiateTaskMessage.class);
        verify(m_messenger).send(destinationCaptor.capture(), messageCaptor.capture());
        Iv2InitiateTaskMessage message = messageCaptor.getValue();

        assertTrue(message.isReadOnly());  
        assertTrue(message.isSinglePartition()); 
        assertEquals("@AdHoc_RO_SP", message.getStoredProcedureName());

        
        Object partitionParam = message.getStoredProcedureInvocation().getParameterAtIndex(0);
        assertTrue(partitionParam instanceof byte[]);
        VoltType type = VoltType.get((Byte) message.getStoredProcedureInvocation().getParameterAtIndex(1));
        assertTrue(type.isInteger());
        byte[] serializedData = (byte[]) message.getStoredProcedureInvocation().getParameterAtIndex(2);
        ByteBuffer buf = ByteBuffer.wrap(serializedData);
        Object[] parameters = AdHocPlannedStmtBatch.userParamsFromBuffer(buf);
        assertEquals(1, parameters.length);
        assertEquals(3, parameters[0]);
        AdHocPlannedStatement[] statements = AdHocPlannedStmtBatch.planArrayFromBuffer(buf);
        assertTrue(Arrays.equals(TheHashinator.valueToBytes(3), (byte[]) partitionParam));
        assertEquals(1, statements.length);
        String sql = new String(statements[0].sql, Constants.UTF8ENCODING);
        assertEquals(query, sql);
    }

    
    @Test
    public void testFinishedMPAdHocPlanning() throws Exception {
        
        String query = "select * from a";
        Object[] extractedValues =  new Object[0];
        VoltType[] paramTypes =  new VoltType[0];
        AdHocPlannedStmtBatch plannedStmtBatch =
            AdHocPlannedStmtBatch.mockStatementBatch(3, query, extractedValues, paramTypes, null, -1,
                    m_context.getCatalogHash());
        m_ci.processFinishedCompilerWork(plannedStmtBatch).run();

        ArgumentCaptor<Long> destinationCaptor =
                ArgumentCaptor.forClass(Long.class);
        ArgumentCaptor<Iv2InitiateTaskMessage> messageCaptor =
                ArgumentCaptor.forClass(Iv2InitiateTaskMessage.class);
        verify(m_messenger).send(destinationCaptor.capture(), messageCaptor.capture());
        Iv2InitiateTaskMessage message = messageCaptor.getValue();

        
        assertTrue(message.isReadOnly());  
        assertFalse(message.isSinglePartition()); 
        
        assertEquals("@AdHoc_RO_MP", message.getStoredProcedureName());

        byte[] serializedData = (byte[]) message.getStoredProcedureInvocation().getParameterAtIndex(0);
        ByteBuffer buf = ByteBuffer.wrap(serializedData);
        Object[] parameters = AdHocPlannedStmtBatch.userParamsFromBuffer(buf);
        assertEquals(0, parameters.length);
        AdHocPlannedStatement[] statements = AdHocPlannedStmtBatch.planArrayFromBuffer(buf);
        assertEquals(1, statements.length);
        String sql = new String(statements[0].sql, Constants.UTF8ENCODING);
        assertEquals(query, sql);
    }

    @Test
    public void testUpdateCatalog() throws IOException {
        
        if (VoltDB.instance().getConfig().m_isEnterprise) {
            String catalogHex = Encoder.hexEncode("blah");
            ByteBuffer msg = createMsg("@UpdateApplicationCatalog", catalogHex, "blah");
            ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
            assertNull(resp);
            ArgumentCaptor<LocalObjectMessage> captor = ArgumentCaptor.forClass(LocalObjectMessage.class);
            verify(m_messenger).send(eq(32L), 
                                     captor.capture());
            assertTrue(captor.getValue().payload instanceof CatalogChangeWork);
        }
    }

    @Test
    public void testNegativeUpdateCatalog() throws IOException {
        ByteBuffer msg = createMsg("@UpdateApplicationCatalog", new Integer(1), new Long(0));
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        
        assertNotNull(resp);
        assertTrue(resp.getStatus() != 0);
    }


    
    @Test
    public void testFinishedCatalogDiffing() {
        CatalogChangeResult catalogResult = new CatalogChangeResult();
        catalogResult.clientData = null;
        catalogResult.clientHandle = 0;
        catalogResult.connectionId = 0;
        catalogResult.adminConnection = false;
        
        catalogResult.catalogHash = "blah".getBytes();
        catalogResult.catalogBytes = "blah".getBytes();
        catalogResult.deploymentString = "blah";
        catalogResult.expectedCatalogVersion = 3;
        catalogResult.encodedDiffCommands = "diff";
        catalogResult.invocationType = ProcedureInvocationType.REPLICATED;
        catalogResult.originalTxnId = 12345678l;
        catalogResult.originalUniqueId = 87654321l;
        catalogResult.user = new AuthSystem.AuthDisabledUser();
        m_ci.processFinishedCompilerWork(catalogResult).run();

        ArgumentCaptor<Long> destinationCaptor =
                ArgumentCaptor.forClass(Long.class);
        ArgumentCaptor<Iv2InitiateTaskMessage> messageCaptor =
                ArgumentCaptor.forClass(Iv2InitiateTaskMessage.class);
        verify(m_messenger).send(destinationCaptor.capture(), messageCaptor.capture());
        Iv2InitiateTaskMessage message = messageCaptor.getValue();
        
        assertFalse(message.isReadOnly()); 
        assertFalse(message.isSinglePartition()); 
        
        assertEquals("@UpdateApplicationCatalog", message.getStoredProcedureName());
        assertEquals("diff", message.getStoredProcedureInvocation().getParameterAtIndex(0));
        assertTrue(Arrays.equals("blah".getBytes(), (byte[]) message.getStoredProcedureInvocation().getParameterAtIndex(2)));
        assertEquals(3, message.getStoredProcedureInvocation().getParameterAtIndex(3));
        assertEquals("blah", message.getStoredProcedureInvocation().getParameterAtIndex(4));
        assertEquals(ProcedureInvocationType.REPLICATED, message.getStoredProcedureInvocation().getType());
        assertEquals(12345678l, message.getStoredProcedureInvocation().getOriginalTxnId());
        assertEquals(87654321l, message.getStoredProcedureInvocation().getOriginalUniqueId());
    }

    @Test
    public void testUserProc() throws Exception {
        ByteBuffer msg = createMsg("hello", 1);
        StoredProcedureInvocation invocation =
                readAndCheck(msg, "hello", 1, true, true).getStoredProcedureInvocation();
        assertEquals(1, invocation.getParameterAtIndex(0));
    }

    @Test
    public void testGC() throws Exception {
        ByteBuffer msg = createMsg("@GC");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);

        ByteBuffer b = responses.take();
        resp = new ClientResponseImpl();
        b.position(4);
        resp.initFromBuffer(b);
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        VoltTable vt = resp.getResults()[0];
        assertTrue(vt.advanceRow());
        
        assertTrue(resp.getResults()[0].getLong(0) > 10000);
    }

    @Test
    public void testSystemInformation() throws Exception {
        ByteBuffer msg = createMsg("@SystemInformation");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        verify(m_sysinfoAgent).performOpsAction(any(Connection.class), anyInt(), eq(OpsSelector.SYSTEMINFORMATION),
                any(ParameterSet.class));
    }

    
    @Test
    public void testDRStats() throws Exception {
        ByteBuffer msg = createMsg("@Statistics", "DR", 0);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNull(resp);
        assertEquals(drStatsInvoked, 1);
    }

    @Test
    public void testLoadSinglePartTable() throws Exception {
        VoltTable table = new VoltTable(new ColumnInfo("i", VoltType.INTEGER));
        table.addRow(1);

        byte[] partitionParam = {0, 0, 0, 0, 0, 0, 0, 4};
        ByteBuffer msg = createMsg("@LoadSinglepartitionTable", partitionParam, "a", table);
        readAndCheck(msg, "@LoadSinglepartitionTable", partitionParam, false, true);
    }

    @Test
    public void testPausedMode() throws IOException {
        
        when(m_volt.getMode()).thenReturn(OperationMode.PAUSED);
        ByteBuffer msg = createMsg("hello", 1);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.SERVER_UNAVAILABLE, resp.getStatus());
        assert(resp.getStatusString().startsWith("Server is paused"));
        when(m_volt.getMode()).thenReturn(OperationMode.RUNNING);
    }

    @Test
    public void testInvalidProcedure() throws IOException {
        ByteBuffer msg = createMsg("hellooooo", 1);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.UNEXPECTED_FAILURE, resp.getStatus());
    }

    @Test
    public void testAdminProcsOnNonAdminPort() throws IOException {
        ByteBuffer msg = createMsg("@Pause");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.UNEXPECTED_FAILURE, resp.getStatus());

        msg = createMsg("@Resume");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.UNEXPECTED_FAILURE, resp.getStatus());
    }

    @Test
    public void testRejectDupInvocation() throws IOException {
        
        ByteBuffer msg = createMsg(12345l, "hello", 1);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.UNEXPECTED_FAILURE, resp.getStatus());
    }

    @Test
    public void testPolicyRejection() throws IOException {
        
        ByteBuffer msg = createMsg("@AdHoc", 1, 3, 3);
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());
    }

    @Test
    public void testPromoteWithoutCommandLogging() throws Exception {
        final ByteBuffer msg = createMsg("@Promote");
        m_ci.handleRead(msg, m_handler, m_cxn);
        
        verify(m_zk, never()).create(eq(VoltZK.request_truncation_snapshot_node), any(byte[].class),
                                     eq(Ids.OPEN_ACL_UNSAFE), eq(CreateMode.PERSISTENT));
    }

    @Test
    public void testPromoteWithCommandLogging() throws Exception {
        org.voltdb.catalog.CommandLog logConfig = m_context.cluster.getLogconfig().get("log");
        boolean wasEnabled = logConfig.getEnabled();
        logConfig.setEnabled(true);
        try {
            final ByteBuffer msg = createMsg("@Promote");
            m_ci.handleRead(msg, m_handler, m_cxn);
            
            verify(m_zk, never()).create(eq(VoltZK.request_truncation_snapshot_node), any(byte[].class),
                                eq(Ids.OPEN_ACL_UNSAFE), eq(CreateMode.PERSISTENT_SEQUENTIAL));
        }
        finally {
            logConfig.setEnabled(wasEnabled);
        }
    }

    @Test
    public void testTransactionRestart() throws Exception {
        initMsgAndSendRestartResp(true);
    }

    @Test
    public void testTransactionRestartIgnored() throws Exception {
        
        doReturn(OperationMode.INITIALIZING).when(m_volt).getMode();
        initMsgAndSendRestartResp(false);


    }

    private void initMsgAndSendRestartResp(boolean shouldRestart) throws Exception
    {
        
        TheHashinator.constructHashinator(TheHashinator.getConfiguredHashinatorClass(),
                                          TheHashinator.getConfigureBytes(3),
                                          false);
        Pair<Long, byte[]> hashinatorConfig = TheHashinator.getCurrentVersionedConfig();
        long newHashinatorVersion = hashinatorConfig.getFirst() + 1;

        ByteBuffer msg = createMsg("hello", 1);
        Iv2InitiateTaskMessage initMsg = readAndCheck(msg, "hello", 1, true, true);
        assertEquals(1, initMsg.getStoredProcedureInvocation().getParameterAtIndex(0));

        
        InitiateResponseMessage respMsg = new InitiateResponseMessage(initMsg);
        respMsg.setMispartitioned(true, initMsg.getStoredProcedureInvocation(),
                                  Pair.of(newHashinatorVersion, hashinatorConfig.getSecond()));

        
        reset(m_messenger);

        
        m_ci.m_mailbox.deliver(respMsg);

        
        DeferredSerialization resp = responsesDS.take();

        if (shouldRestart) {
            assertEquals(-1, resp.getSerializedSize());
            checkInitMsgSent("hello", 1, true, true);
        } else {
            assertTrue(-1 != resp.getSerializedSize());
            verify(m_messenger, never()).send(anyLong(), any(VoltMessage.class));
        }

        
        assertEquals(newHashinatorVersion, TheHashinator.getCurrentVersionedConfig().getFirst().longValue());
    }

    @Test
    public void testGetPartitionKeys() throws IOException {
        
        ByteBuffer msg = createMsg("@GetPartitionKeys", "BIGINT");
        ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", new Object[] { null });
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", "");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", "ryanlikestheyankees");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", "INTEGER", 99);
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.GRACEFUL_FAILURE, resp.getStatus());

        
        msg = createMsg("@GetPartitionKeys", "InTeGeR");
        resp = m_ci.handleRead(msg, m_handler, m_cxn);
        assertNotNull(resp);
        assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        VoltTable vt = resp.getResults()[0];
        assertEquals(3, vt.getRowCount());
        assertEquals(VoltType.INTEGER, vt.getColumnType(1));

        Set<Integer> partitions = new HashSet<Integer>(Arrays.asList( 0, 1, 2));
        while (vt.advanceRow()) {
            int partition = TheHashinator.getPartitionForParameter(VoltType.INTEGER.getValue(), vt.getLong(1));
            assertTrue(partitions.remove(partition));
        }
        assertTrue(partitions.isEmpty());
    }

    @Test
    public void testSubscribe() throws Exception {
        RateLimitedClientNotifier.WARMUP_MS = 0;
        ClientInterface.TOPOLOGY_CHANGE_CHECK_MS = 1;
        try {
            m_ci.startAcceptingConnections();
            ByteBuffer msg = createMsg("@Subscribe", "TOPOLOGY");
            ClientResponseImpl resp = m_ci.handleRead(msg, m_handler, m_cxn);
            assertNotNull(resp);
            assertEquals(ClientResponse.SUCCESS, resp.getStatus());
            statsAnswers.offer(dsOf(getClientResponse("foo")));
            m_ci.schedulePeriodicWorks();

            
            assertNull(responsesDS.poll(50, TimeUnit.MILLISECONDS));

            statsAnswers.offer(dsOf(getClientResponse("foo")));
            assertNull(responsesDS.poll(50, TimeUnit.MILLISECONDS));

            
            
            ByteBuffer expectedBuf = getClientResponse("bar");
            statsAnswers.offer(dsOf(expectedBuf));
            DeferredSerialization ds = responsesDS.take();
            ByteBuffer actualBuf = ByteBuffer.allocate(ds.getSerializedSize());
            ds.serialize(actualBuf);
            assertEquals(expectedBuf, actualBuf);
        } finally {
            RateLimitedClientNotifier.WARMUP_MS = 1000;
            ClientInterface.TOPOLOGY_CHANGE_CHECK_MS = 5000;
            m_ci.shutdown();
        }
    }

    private DeferredSerialization dsOf(final ByteBuffer buf) {
        return new DeferredSerialization() {
            @Override
            public void serialize(final ByteBuffer outbuf) throws IOException {
                outbuf.put(buf);
            }
            @Override
            public void cancel() {}
            @Override
            public int getSerializedSize() {
                return buf.remaining();
            }
        };
    }

    public ByteBuffer getClientResponse(String str) {
        ClientResponseImpl response = new ClientResponseImpl(ClientResponse.SUCCESS,
                new VoltTable[0], str, ClientInterface.ASYNC_TOPO_HANDLE);
        ByteBuffer buf = ByteBuffer.allocate(response.getSerializedSize() + 4);
        buf.putInt(buf.capacity() - 4);
        response.flattenToBuffer(buf);
        buf.flip();
        return buf;
    }
}

<code block>



package org.voltdb;

import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import java.io.UnsupportedEncodingException;
import java.math.BigDecimal;
import java.net.HttpURLConnection;
import java.net.URL;
import java.net.URLEncoder;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;

import junit.framework.TestCase;

import org.codehaus.jackson.map.ObjectMapper;
import org.json_voltpatches.JSONArray;
import org.json_voltpatches.JSONException;
import org.json_voltpatches.JSONObject;
import org.voltcore.utils.CoreUtils;
import org.voltdb.VoltDB.Configuration;
import org.voltdb.client.Client;
import org.voltdb.client.ClientAuthHashScheme;
import org.voltdb.client.ClientConfig;
import org.voltdb.client.ClientFactory;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureCallback;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.compiler.VoltProjectBuilder.ProcedureInfo;
import org.voltdb.compiler.VoltProjectBuilder.RoleInfo;
import org.voltdb.compiler.VoltProjectBuilder.UserInfo;
import org.voltdb.compiler.deploymentfile.DeploymentType;
import org.voltdb.compiler.deploymentfile.HeartbeatType;
import org.voltdb.compiler.deploymentfile.SystemSettingsType;
import org.voltdb.compiler.deploymentfile.SystemSettingsType.Query;
import org.voltdb.compiler.deploymentfile.UsersType;
import org.voltdb.compiler.procedures.CrazyBlahProc;
import org.voltdb.compiler.procedures.DelayProc;
import org.voltdb.compiler.procedures.SelectStarHelloWorld;
import org.voltdb.types.TimestampType;
import org.voltdb.utils.Base64;
import org.voltdb.utils.Encoder;
import org.voltdb.utils.MiscUtils;

public class TestJSONInterface extends TestCase {

    ServerThread server;
    Client client;

    static class Response {

        public byte status = 0;
        public String statusString = null;
        public byte appStatus = Byte.MIN_VALUE;
        public String appStatusString = null;
        public VoltTable[] results = new VoltTable[0];
        public String exception = null;
    }

    static String japaneseTestVarStrings = "Procedure=Insert&Parameters=%5B%22%5Cu3053%5Cu3093%5Cu306b%5Cu3061%5Cu306f%22%2C%22%5Cu4e16%5Cu754c%22%2C%22Japanese%22%5D";

    static String getHTTPVarString(Map<String, String> params) throws UnsupportedEncodingException {
        String s = "";
        for (Entry<String, String> e : params.entrySet()) {
            String encodedValue = URLEncoder.encode(e.getValue(), "UTF-8");
            s += "&" + e.getKey() + "=" + encodedValue;
        }
        s = s.substring(1);
        return s;
    }

    static String getHTTPURL(Integer port, String path) {
        if (port == null) {
            port = VoltDB.DEFAULT_HTTP_PORT;
        }
        return String.format("http:
    }

    public static String callProcOverJSONRaw(String varString, int expectedCode) throws Exception {
        URL jsonAPIURL = new URL("http:

        HttpURLConnection conn = (HttpURLConnection) jsonAPIURL.openConnection();
        conn.setRequestMethod("POST");
        conn.setDoOutput(true);
        conn.connect();

        OutputStreamWriter out = new OutputStreamWriter(conn.getOutputStream());
        out.write(varString);
        out.flush();
        out.close();
        out = null;
        conn.getOutputStream().close();

        BufferedReader in = null;
        try {
            if (conn.getInputStream() != null) {
                in = new BufferedReader(
                        new InputStreamReader(
                                conn.getInputStream(), "UTF-8"));
            }
        } catch (IOException e) {
            if (conn.getErrorStream() != null) {
                in = new BufferedReader(
                        new InputStreamReader(
                                conn.getErrorStream(), "UTF-8"));
            }
        }
        if (in == null) {
            throw new Exception("Unable to read response from server");
        }

        StringBuilder decodedString = new StringBuilder();
        String line;
        while ((line = in.readLine()) != null) {
            decodedString.append(line);
        }
        in.close();
        in = null;
        
        int responseCode = conn.getResponseCode();

        String response = decodedString.toString();

        assertEquals(expectedCode, responseCode);

        try {
            conn.getInputStream().close();
            conn.disconnect();
        } 
        catch (Exception e) {
        }
        conn = null;

        
        return response;
    }

    private static String getUrlOverJSON(String url, String user, String password, String scheme, int expectedCode, String expectedCt) throws Exception {
        return httpUrlOverJSON("GET", url, user, password, scheme, expectedCode, expectedCt, null);
    }

    private static String postUrlOverJSON(String url, String user, String password, String scheme, int expectedCode, String expectedCt, Map<String,String> params) throws Exception {
        return httpUrlOverJSON("POST", url, user, password, scheme, expectedCode, expectedCt, params);
    }

    private static String putUrlOverJSON(String url, String user, String password, String scheme, int expectedCode, String expectedCt, Map<String,String> params) throws Exception {
        return httpUrlOverJSON("PUT", url, user, password, scheme, expectedCode, expectedCt, params);
    }

    private static String deleteUrlOverJSON(String url, String user, String password, String scheme, int expectedCode, String expectedCt) throws Exception {
        return httpUrlOverJSON("DELETE", url, user, password, scheme, expectedCode, expectedCt, null);
    }

    private static String httpUrlOverJSON(String method, String url, String user, String password, String scheme, int expectedCode, String expectedCt, Map<String,String> params) throws Exception {
        URL jsonAPIURL = new URL(url);

        HttpURLConnection conn = (HttpURLConnection) jsonAPIURL.openConnection();
        conn.setRequestMethod(method);
        conn.setDoOutput(true);
        conn.setRequestProperty("Content-Type", "application/x-www-form-urlencoded");
        if (user != null && password != null) {
            if (scheme.equalsIgnoreCase("hashed")) {
                MessageDigest md = MessageDigest.getInstance("SHA-1");
                byte hashedPasswordBytes[] = md.digest(password.getBytes("UTF-8"));
                String h = user + ":" + Encoder.hexEncode(hashedPasswordBytes);
                conn.setRequestProperty("Authorization", "Hashed " + h);
            } else if (scheme.equalsIgnoreCase("hashed256")) {
                MessageDigest md = MessageDigest.getInstance("SHA-256");
                byte hashedPasswordBytes[] = md.digest(password.getBytes("UTF-8"));
                String h = user + ":" + Encoder.hexEncode(hashedPasswordBytes);
                conn.setRequestProperty("Authorization", "Hashed " + h);
            } else if (scheme.equalsIgnoreCase("basic")) {
                conn.setRequestProperty("Authorization", "Basic " + new String(Base64.encodeToString(new String(user + ":" + password).getBytes(), false)));
            }
        }
        conn.connect();
        byte andbyte[] = String.valueOf('&').getBytes();
        if (params != null && params.size() > 0) {
            OutputStream os = conn.getOutputStream();
            for (String key : params.keySet()) {
                os.write(key.getBytes());
                if (params.get(key) != null) {
                    String b = "=" + params.get(key);
                    os.write(b.getBytes());
                }
                os.write(andbyte);
            }
        }

        BufferedReader in = null;
        try {
            if (conn.getInputStream() != null) {
                in = new BufferedReader(
                        new InputStreamReader(
                                conn.getInputStream(), "UTF-8"));
            }
        } catch (IOException e) {
            if (conn.getErrorStream() != null) {
                in = new BufferedReader(
                        new InputStreamReader(
                                conn.getErrorStream(), "UTF-8"));
            }
        }
        if (in == null) {
            throw new Exception("Unable to read response from server");
        }
        String ct = conn.getContentType();
        assertTrue(ct.contains(expectedCt));

        StringBuilder decodedString = new StringBuilder();
        String line;
        try {
            while ((line = in.readLine()) != null) {
                decodedString.append(line);
            }
        } catch (Exception ex) {
            ex.printStackTrace();
        } finally {
            in.close();
            in = null;
        }
        
        int responseCode = conn.getResponseCode();

        String response = decodedString.toString();

        assertEquals(expectedCode, responseCode);

        try {
            conn.getInputStream().close();
            conn.disconnect();
        } 
        catch (Exception e) {
        }
        conn = null;

        
        return response;
    }

    public static String getHashedPasswordForHTTPVar(String password, ClientAuthHashScheme scheme) {
        assert (password != null);

        MessageDigest md = null;
        try {
            md = MessageDigest.getInstance(ClientAuthHashScheme.getDigestScheme(scheme));
        } catch (NoSuchAlgorithmException e) {
            fail();
        }
        byte hashedPassword[] = null;
        try {
            hashedPassword = md.digest(password.getBytes("UTF-8"));
        } catch (UnsupportedEncodingException e) {
            throw new RuntimeException("JVM doesn't support UTF-8. Please use a supported JVM", e);
        }

        String retval = Encoder.hexEncode(hashedPassword);
        assertEquals(ClientAuthHashScheme.getHexencodedDigestLength(scheme), retval.length());
        return retval;
    }

    public static String callProcOverJSON(String procName, ParameterSet pset, String username, String password, boolean preHash) throws Exception {
        return callProcOverJSON(procName, pset, username, password, preHash, false, 200 , ClientAuthHashScheme.HASH_SHA256);
    }

    public static String callProcOverJSON(String procName, ParameterSet pset, String username, String password, boolean preHash, boolean admin) throws Exception {
        return callProcOverJSON(procName, pset, username, password, preHash, admin, 200 , ClientAuthHashScheme.HASH_SHA256);
    }

    public static String callProcOverJSON(String procName, ParameterSet pset, String username, String password, boolean preHash, boolean admin, int expectedCode, ClientAuthHashScheme scheme) throws Exception {
        
        String paramsInJSON = pset.toJSONString();
        
        HashMap<String, String> params = new HashMap<String, String>();
        params.put("Procedure", procName);
        params.put("Parameters", paramsInJSON);
        if (username != null) {
            params.put("User", username);
        }
        if (password != null) {
            if (preHash) {
                params.put("Hashedpassword", getHashedPasswordForHTTPVar(password, scheme));
            } else {
                params.put("Password", password);
            }
        }
        if (admin) {
            params.put("admin", "true");
        }

        String varString = getHTTPVarString(params);

        varString = getHTTPVarString(params);

        String ret = callProcOverJSONRaw(varString, expectedCode);
        if (preHash) {
            
            params.put("Hashedpassword", getHashedPasswordForHTTPVar(password, ClientAuthHashScheme.HASH_SHA1));
            varString = getHTTPVarString(params);

            varString = getHTTPVarString(params);
            String ignret = callProcOverJSONRaw(varString, expectedCode);
        }
        return ret;
    }

    public static Response responseFromJSON(String jsonStr) throws JSONException, IOException {
        Response response = new Response();
        JSONObject jsonObj = new JSONObject(jsonStr);
        JSONArray resultsJson = jsonObj.getJSONArray("results");
        response.results = new VoltTable[resultsJson.length()];
        for (int i = 0; i < response.results.length; i++) {
            JSONObject tableJson = resultsJson.getJSONObject(i);
            response.results[i] = VoltTable.fromJSONObject(tableJson);
        }
        if (jsonObj.isNull("status") == false) {
            response.status = (byte) jsonObj.getInt("status");
        }
        if (jsonObj.isNull("appstatus") == false) {
            response.appStatus = (byte) jsonObj.getInt("appstatus");
        }
        if (jsonObj.isNull("statusstring") == false) {
            response.statusString = jsonObj.getString("statusstring");
        }
        if (jsonObj.isNull("appstatusstring") == false) {
            response.appStatusString = jsonObj.getString("appstatusstring");
        }
        if (jsonObj.isNull("exception") == false) {
            response.exception = jsonObj.getString("exception");
        }

        return response;
    }

    public void testAJAXAndClientTogether() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addLiteralSchema(simpleSchema);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            client = ClientFactory.createClient(new ClientConfig());
            client.createConnection("localhost");

            final AtomicLong fcnt = new AtomicLong(0);
            final AtomicLong scnt = new AtomicLong(0);
            final AtomicLong cfcnt = new AtomicLong(0);
            final AtomicLong cscnt = new AtomicLong(0);
            final int jsonRunnerCount = 50;
            final int clientRunnerCount = 50;
            final ParameterSet pset = ParameterSet.fromArrayNoCopy("select count(*) from foo");
            String responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            Response r = responseFromJSON(responseJSON);
            assertEquals(ClientResponse.SUCCESS, r.status);
            
            class JSONRunner implements Runnable {

                @Override
                public void run() {
                    try {
                        String rresponseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
                        System.out.println("Response: " + rresponseJSON);
                        Response rr = responseFromJSON(rresponseJSON);
                        assertEquals(ClientResponse.SUCCESS, rr.status);
                        scnt.incrementAndGet();
                    } catch (Exception ex) {
                        fcnt.incrementAndGet();
                        ex.printStackTrace();
                    }
                }

            }

            
            class ClientRunner implements Runnable {

                class Callback implements ProcedureCallback {

                    @Override
                    public void clientCallback(ClientResponse clientResponse) throws Exception {
                        if (clientResponse.getStatus() == ClientResponse.SUCCESS) {
                            cscnt.incrementAndGet();
                        } else {
                            System.out.println("Client failed: " + clientResponse.getStatusString());
                            cfcnt.incrementAndGet();
                        }
                    }

                }
                @Override
                public void run() {
                    try {
                        if (!client.callProcedure(new Callback(), "@AdHoc", "SELECT count(*) from foo")) {
                            cfcnt.decrementAndGet();
                        }
                    } catch (Exception ex) {
                        fcnt.incrementAndGet();
                        ex.printStackTrace();
                    }
                }

            }

            
            ExecutorService es = CoreUtils.getBoundedSingleThreadExecutor("runners", jsonRunnerCount);
            for (int i = 0; i < jsonRunnerCount; i++) {
                es.submit(new JSONRunner());
            }
            ExecutorService ces = CoreUtils.getBoundedSingleThreadExecutor("crunners", clientRunnerCount);
            for (int i = 0; i < clientRunnerCount; i++) {
                ces.submit(new ClientRunner());
            }

            es.shutdown();
            es.awaitTermination(1, TimeUnit.DAYS);
            assertEquals(jsonRunnerCount, scnt.get());
            ces.shutdown();
            ces.awaitTermination(1, TimeUnit.DAYS);
            client.drain();
            assertEquals(clientRunnerCount, cscnt.get());
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            r = responseFromJSON(responseJSON);
            assertEquals(ClientResponse.SUCCESS, r.status);
            
            ClientResponse resp = client.callProcedure("@AdHoc", "SELECT count(*) from foo");
            assertEquals(ClientResponse.SUCCESS, resp.getStatus());
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
            if (client != null) {
                client.close();
            }
        }
    }


    public void testAdminMode() throws Exception {
        try {
            String simpleSchema
                    = "create table blah ("
                    + "ival bigint default 23 not null, "
                    + "sval varchar(200) default 'foo', "
                    + "dateval timestamp, "
                    + "fval float, "
                    + "decval decimal, "
                    + "PRIMARY KEY(ival));";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltDB.Configuration config = new VoltDB.Configuration();

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("blah", "ival");
            builder.addStmtProcedure("Insert", "insert into blah values (?,?,?,?,?);");
            builder.addProcedures(CrazyBlahProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"), 1, 1, 0, 21213, true);
            assertTrue(success);

            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();

            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            ParameterSet pset;
            String responseJSON;
            Response response;

            
            pset = ParameterSet.fromArrayNoCopy(1, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(2, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SERVER_UNAVAILABLE);

            
            pset = ParameterSet.emptyParameterSet();
            responseJSON = callProcOverJSON("@Resume", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(2, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(3, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.emptyParameterSet();
            responseJSON = callProcOverJSON("@Pause", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(4, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, true);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(5, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SERVER_UNAVAILABLE);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testSimple() throws Exception {
        try {
            String simpleSchema
                    = "create table blah ("
                    + "ival bigint default 23 not null, "
                    + "sval varchar(200) default 'foo', "
                    + "dateval timestamp, "
                    + "fval float, "
                    + "decval decimal, "
                    + "PRIMARY KEY(ival));";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltDB.Configuration config = new VoltDB.Configuration();

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("blah", "ival");
            builder.addStmtProcedure("Insert", "insert into blah values (?,?,?,?,?);");
            builder.addProcedures(CrazyBlahProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"), 1, 1, 0, 21213, false);
            assertTrue(success);

            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();

            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            ParameterSet pset;
            String responseJSON;
            Response response;

            
            pset = ParameterSet.fromArrayNoCopy(1, "hello", new TimestampType(System.currentTimeMillis()), 5.0, "5.0");
            responseJSON = callProcOverJSON("Insert", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status == ClientResponse.SUCCESS);

            
            responseJSON = callProcOverJSON("Insert", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertTrue(response.status != ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    5,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    new BigDecimal(5),
                    new BigDecimal[]{},
                    new TimestampType(System.currentTimeMillis()));

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertEquals(ClientResponse.SUCCESS, response.status);

            
            JSONObject jsonObj = new JSONObject(responseJSON);
            JSONArray results = jsonObj.getJSONArray("results");
            assertEquals(4, response.results.length);
            JSONObject table = results.getJSONObject(0);
            JSONArray data = table.getJSONArray("data");
            assertEquals(1, data.length());
            JSONArray row = data.getJSONArray(0);
            assertEquals(1, row.length());
            long value = row.getLong(0);
            assertEquals(1, value);

            
            java.sql.Timestamp ts = new java.sql.Timestamp(System.currentTimeMillis());
            ts.setNanos(123456000);
            pset = ParameterSet.fromArrayNoCopy(1,
                    5,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    new BigDecimal(5),
                    new BigDecimal[]{},
                    ts.toString());

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertEquals(ClientResponse.SUCCESS, response.status);
            response.results[3].advanceRow();
            System.out.println(response.results[3].getTimestampAsTimestamp(0).getTime());
            assertEquals(123456, response.results[3].getTimestampAsTimestamp(0).getTime() % 1000000);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    VoltType.NULL_SMALLINT,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    new BigDecimal(5),
                    new BigDecimal[]{},
                    new TimestampType(System.currentTimeMillis()));

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertFalse(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    Long.MAX_VALUE - 100,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    new BigDecimal(5),
                    new BigDecimal[]{},
                    new TimestampType(System.currentTimeMillis()));

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            assertFalse(response.status == ClientResponse.SUCCESS);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    4,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    5,
                    new BigDecimal[]{},
                    new TimestampType(System.currentTimeMillis()));

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

            
            pset = ParameterSet.fromArrayNoCopy(1,
                    4,
                    new double[]{1.5, 6.0, 4},
                    new VoltTable(new VoltTable.ColumnInfo("foo", VoltType.BIGINT)),
                    5,
                    new BigDecimal[]{},
                    null);

            responseJSON = callProcOverJSON("CrazyBlahProc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

            
            responseJSON = callProcOverJSONRaw("Procedure=@Statistics&Parameters=[TABLE]&jsonp=fooBar", 200);
            System.out.println(responseJSON);
            assertTrue(responseJSON.startsWith("fooBar("));

            
            pset = ParameterSet.fromArrayNoCopy("select * from blah");
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

            
            pset = ParameterSet.fromArrayNoCopy("insert into blah values (974599638818488300, NULL, NULL, NULL, NULL);");
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

            pset = ParameterSet.fromArrayNoCopy("select * from blah where ival = 974599638818488300;");
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.out.println(responseJSON);
            response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);
            assertEquals(1, response.results.length);
            assertEquals(1, response.results[0].getRowCount());

            
            pset = ParameterSet.emptyParameterSet();
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            assertTrue(responseJSON.contains("Adhoc system procedure requires at least the query parameter."));

            
            pset = ParameterSet.fromArrayNoCopy("select * from blah", "foo", "bar");
            responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.err.println(responseJSON);
            assertTrue(responseJSON.contains("Too many actual arguments were passed for the parameters in the sql "
                    + "statement(s): (2 vs. 0)"));

        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testJapaneseNastiness() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE HELLOWORLD (\n"
                    + "    HELLO VARCHAR(15),\n"
                    + "    WORLD VARCHAR(15),\n"
                    + "    DIALECT VARCHAR(15) NOT NULL,\n"
                    + "    PRIMARY KEY (DIALECT)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("HELLOWORLD", "DIALECT");
            builder.addStmtProcedure("Insert", "insert into HELLOWORLD values (?,?,?);");
            builder.addStmtProcedure("Select", "select * from HELLOWORLD;");
            builder.addProcedures(SelectStarHelloWorld.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            String response = callProcOverJSONRaw(japaneseTestVarStrings, 200);
            Response r = responseFromJSON(response);
            assertEquals(1, r.status);

        
            
            char[] test1 = {'a'}
                    
            String test2 = new String(test1);

            ParameterSet pset = ParameterSet.emptyParameterSet();
            response = callProcOverJSON("Select", pset, null, null, false);
            System.out.println(response);
            System.out.println(test2);
            r = responseFromJSON(response);
            assertEquals(1, r.status);

            response = callProcOverJSON("SelectStarHelloWorld", pset, null, null, false);
            r = responseFromJSON(response);
            assertEquals(1, r.status);
            assertTrue(response.contains(test2));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testJSONAuth() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE HELLOWORLD (\n"
                    + "    HELLO VARCHAR(15),\n"
                    + "    WORLD VARCHAR(20),\n"
                    + "    DIALECT VARCHAR(15) NOT NULL,\n"
                    + "    PRIMARY KEY (DIALECT)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("HELLOWORLD", "DIALECT");

            RoleInfo gi = new RoleInfo("foo", true, false, true, true, false, false);
            builder.addRoles(new RoleInfo[]{gi});

            
            UserInfo[] ui = new UserInfo[15];
            ui[0] = new UserInfo("ry@nlikesthe", "y@nkees", new String[]{"foo"});
            for (int i = 1; i < ui.length; i++) {
                ui[i] = new UserInfo("USER" + String.valueOf(i), "PASS" + String.valueOf(i), new String[]{"foo"});
            }
            builder.addUsers(ui);

            builder.setSecurityEnabled(true, true);

            ProcedureInfo[] pi = new ProcedureInfo[2];
            pi[0] = new ProcedureInfo(new String[]{"foo"}, "Insert", "insert into HELLOWORLD values (?,?,?);", null);
            pi[1] = new ProcedureInfo(new String[]{"foo"}, "Select", "select * from HELLOWORLD;", null);
            builder.addProcedures(pi);

            builder.setHTTPDPort(8095);

            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            ParameterSet pset;

            
            for (UserInfo u : ui) {
                pset = ParameterSet.fromArrayNoCopy(u.name, u.password, u.name);
                String response = callProcOverJSON("Insert", pset, u.name, u.password, true);
                Response r = responseFromJSON(response);
                assertEquals(ClientResponse.SUCCESS, r.status);
            }
            
            for (UserInfo u : ui) {
                pset = ParameterSet.fromArrayNoCopy(u.name + "-X", u.password + "-X", u.name + "-X");
                String response = callProcOverJSON("Insert", pset, u.name, u.password, false);
                Response r = responseFromJSON(response);
                assertEquals(ClientResponse.SUCCESS, r.status);
            }

            
            UserInfo u = ui[0];
            pset = ParameterSet.fromArrayNoCopy(u.name + "-X1", u.password + "-X1", u.name + "-X1");
            String response = callProcOverJSON("Insert", pset, u.name, "ick", true);
            Response r = responseFromJSON(response);
            assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);
            response = callProcOverJSON("Insert", pset, u.name, "ick", false);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);

            
            pset = ParameterSet.fromArrayNoCopy(u.name + "-X2", u.password + "-X2", u.name + "-X2");
            String paramsInJSON = pset.toJSONString();
            HashMap<String, String> params = new HashMap<String, String>();
            params.put("Procedure", "Insert");
            params.put("Parameters", paramsInJSON);
            params.put("User", u.name);
            params.put("Password", Encoder.hexEncode(new byte[]{1, 2, 3}));
            String varString = getHTTPVarString(params);
            response = callProcOverJSONRaw(varString, 200);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);

            
            pset = ParameterSet.fromArrayNoCopy(u.name + "-X3", u.password + "-X3", u.name + "-X3");
            paramsInJSON = pset.toJSONString();
            params = new HashMap<String, String>();
            params.put("Procedure", "Insert");
            params.put("Parameters", paramsInJSON);
            params.put("User", u.name);
            params.put("Password", "abcdefghiabcdefghiabcdefghiabcdefghi");
            varString = getHTTPVarString(params);
            response = callProcOverJSONRaw(varString, 200);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);

            
            if (VoltDB.instance().getConfig().m_isEnterprise == false) {
                return;
            }

        
            
            VoltProjectBuilder builder2 = new VoltProjectBuilder();
            builder2.addSchema(schemaPath);
            builder2.addPartitionInfo("HELLOWORLD", "DIALECT");

            
            builder2.addRoles(new RoleInfo[]{gi});

            
            ui = new UserInfo[15];
            ui[0] = new UserInfo("ry@nlikesthe", "y@nkees", new String[]{"foo"});
            for (int i = 1; i < ui.length; i++) {
                ui[i] = new UserInfo("USER" + String.valueOf(i),
                        "welcomehackers" + String.valueOf(i),
                        new String[]{"foo"});
            }
            builder2.addUsers(ui);

            builder2.setSecurityEnabled(true, true);
            builder2.addProcedures(pi);
            builder2.setHTTPDPort(8095);

            success = builder2.compile(Configuration.getPathToCatalogForTest("json-update.jar"));
            assertTrue(success);

            pset = ParameterSet.fromArrayNoCopy(Encoder.hexEncode(MiscUtils.fileToBytes(new File(config.m_pathToCatalog))),
                    new String(MiscUtils.fileToBytes(new File(builder2.getPathToDeployment())), "UTF-8"));
            response = callProcOverJSON("@UpdateApplicationCatalog", pset,
                    ui[0].name, ui[0].password, true);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);

            
            for (UserInfo user : ui) {
                ParameterSet ps = ParameterSet.fromArrayNoCopy(user.name + "-X3", user.password + "-X3", user.name + "-X3");
                String respstr = callProcOverJSON("Insert", ps, user.name, user.password, false);
                Response resp = responseFromJSON(respstr);
                assertEquals(ClientResponse.SUCCESS, resp.status);
            }

            VoltProjectBuilder builder3 = new VoltProjectBuilder();
            builder3.addSchema(schemaPath);
            builder3.addPartitionInfo("HELLOWORLD", "DIALECT");

            
            builder3.addRoles(new RoleInfo[]{gi});

            ui = new UserInfo[1];
            ui[0] = new UserInfo("ry@nlikesthe",
                    "D033E22AE348AEB5660FC2140AEC35850C4DA9978C6976E5B5410415BDE908BD4DEE15DFB167A9C873FC4BB8A81F6F2AB448A918",
                    new String[]{"foo"}, false);
            builder3.addUsers(ui);

            builder3.setSecurityEnabled(true, true);
            builder3.addProcedures(pi);
            builder3.setHTTPDPort(8095);

            success = builder3.compile(Configuration.getPathToCatalogForTest("json-update.jar"));
            assertTrue(success);

            pset = ParameterSet.fromArrayNoCopy(Encoder.hexEncode(MiscUtils.fileToBytes(new File(config.m_pathToCatalog))),
                    new String(MiscUtils.fileToBytes(new File(builder3.getPathToDeployment())), "UTF-8"));
            response = callProcOverJSON("@UpdateApplicationCatalog", pset,
                    "ry@nlikesthe", "y@nkees", true);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);

            
            ParameterSet ps = ParameterSet.fromArrayNoCopy(ui[0].name + "-X4", "admin-X4", ui[0].name + "-X4");
            String respstr = callProcOverJSON("Insert", ps, ui[0].name, "admin", false);
            Response resp = responseFromJSON(respstr);
            assertEquals(ClientResponse.SUCCESS, resp.status);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testJSONDisabled() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE HELLOWORLD (\n"
                    + "    HELLO VARCHAR(15),\n"
                    + "    WORLD VARCHAR(15),\n"
                    + "    DIALECT VARCHAR(15) NOT NULL,\n"
                    + "    PRIMARY KEY (DIALECT)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("HELLOWORLD", "DIALECT");

            builder.addStmtProcedure("Insert", "insert into HELLOWORLD values (?,?,?);");

            builder.setHTTPDPort(8095);
            builder.setJSONAPIEnabled(false);

            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            ParameterSet pset = ParameterSet.fromArrayNoCopy("foo", "bar", "foobar");
            try {
                callProcOverJSON("Insert", pset, null, null, false, false, 403, ClientAuthHashScheme.HASH_SHA256); 
            } catch (Exception e) {
                
                assertTrue(e.getMessage().contains("403"));
            }
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testLongProc() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addLiteralSchema(simpleSchema);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            ParameterSet pset = ParameterSet.fromArrayNoCopy(30000);
            String response = callProcOverJSON("DelayProc", pset, null, null, false);
            Response r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testLongQuerySTring() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addLiteralSchema(simpleSchema);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            final StringBuilder b = new StringBuilder();
            b.append("Procedure=@Statistics&Parameters=[TABLE]&jsonpxx=");
            for (int i = 0; i < 450000; i++) {
                b.append(i);
            }
            
            for (int i = 0; i < 500; i++) {
                String response = callProcOverJSONRaw(b.toString(), 200);
                System.out.println(response);
                Response r = responseFromJSON(response);
                assertEquals(ClientResponse.UNEXPECTED_FAILURE, r.status);
                
                ParameterSet pset = ParameterSet.fromArrayNoCopy("select * from foo");
                String responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
                System.out.println(responseJSON);
                r = responseFromJSON(responseJSON);
                System.out.println(r.statusString);
                assertEquals(ClientResponse.SUCCESS, r.status);
            }
            
            ParameterSet pset = ParameterSet.fromArrayNoCopy("select * from foo");
            String responseJSON = callProcOverJSON("@AdHoc", pset, null, null, false);
            System.out.println(responseJSON);
            Response response = responseFromJSON(responseJSON);
            System.out.println(response.statusString);
            assertEquals(ClientResponse.SUCCESS, response.status);

        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testBinaryProc() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    b VARBINARY(256) DEFAULT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addLiteralSchema(simpleSchema);
            builder.addPartitionInfo("foo", "bar");
            builder.addStmtProcedure("Insert", "insert into foo values (?, ?);");
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String varString = "Procedure=Insert&Parameters=[5,\"aa\"]";
            String response = callProcOverJSONRaw(varString, 200);
            System.out.println(response);
            Response r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);

            
            varString = "Procedure=Insert&Parameters=[6,\"aaa\"]";
            response = callProcOverJSONRaw(varString, 200);
            System.out.println(response);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.GRACEFUL_FAILURE, r.status);
            varString = "Procedure=Insert&Parameters=[7,\"aaay\"]";
            response = callProcOverJSONRaw(varString, 200);
            System.out.println(response);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.GRACEFUL_FAILURE, r.status);

            
            varString = "Procedure=Insert&Parameters=[8,NULL]";
            response = callProcOverJSONRaw(varString, 200);
            System.out.println(response);
            r = responseFromJSON(response);
            assertEquals(ClientResponse.SUCCESS, r.status);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testGarbageProcs() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            callProcOverJSONRaw(getHTTPURL(null, "api/1.0/Tim"), 404);
            callProcOverJSONRaw(getHTTPURL(null, "api/1.0/Tim?Procedure=foo&Parameters=[x4{]"), 404);
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testDeployment() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            
            String xdep = getUrlOverJSON("http:
            assertTrue(xdep.contains("<deployment>"));
            assertTrue(xdep.contains("</deployment>"));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testUpdateDeployment() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            
            String pdep = postUrlOverJSON("http:
            assertTrue(pdep.contains("Failed"));
            Map<String,String> params = new HashMap<>();
            params.put("deployment", jdep);
            pdep = postUrlOverJSON("http:
            assertTrue(pdep.contains("Deployment Updated"));

            
            params.put("admin", "true");
            pdep = postUrlOverJSON("http:
            assertTrue(pdep.contains("Deployment Updated"));

            ObjectMapper mapper = new ObjectMapper();
            DeploymentType deptype = mapper.readValue(jdep, DeploymentType.class);

            
            if (deptype.getHeartbeat() == null) {
                HeartbeatType hb = new HeartbeatType();
                hb.setTimeout(99);
                deptype.setHeartbeat(hb);
            } else {
                deptype.getHeartbeat().setTimeout(99);
            }
            String ndeptype = mapper.writeValueAsString(deptype);
            params.put("deployment", ndeptype);
            pdep = postUrlOverJSON("http:
            System.out.println("POST result is: " + pdep);
            assertTrue(pdep.contains("Deployment Updated"));
            jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            deptype = mapper.readValue(jdep, DeploymentType.class);
            int nto = deptype.getHeartbeat().getTimeout();
            assertEquals(99, nto);

            
            SystemSettingsType ss = deptype.getSystemsettings();
            if (ss == null) {
                ss = new SystemSettingsType();
                deptype.setSystemsettings(ss);
            }
            Query qv = ss.getQuery();
            if (qv == null) {
                qv = new Query();
                qv.setTimeout(99);
            } else {
                qv.setTimeout(99);
            }
            ss.setQuery(qv);
            deptype.setSystemsettings(ss);
            ndeptype = mapper.writeValueAsString(deptype);
            params.put("deployment", ndeptype);
            pdep = postUrlOverJSON("http:
            System.out.println("POST result is: " + pdep);
            assertTrue(pdep.contains("Deployment Updated"));
            jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            deptype = mapper.readValue(jdep, DeploymentType.class);
            nto = deptype.getSystemsettings().getQuery().getTimeout();
            assertEquals(99, nto);

            qv.setTimeout(88);
            ss.setQuery(qv);
            deptype.setSystemsettings(ss);
            ndeptype = mapper.writeValueAsString(deptype);
            params.put("deployment", ndeptype);
            pdep = postUrlOverJSON("http:
            System.out.println("POST result is: " + pdep);
            assertTrue(pdep.contains("Deployment Updated"));
            jdep = getUrlOverJSON("http:
            assertTrue(jdep.contains("cluster"));
            deptype = mapper.readValue(jdep, DeploymentType.class);
            nto = deptype.getSystemsettings().getQuery().getTimeout();
            assertEquals(88, nto);

        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testDeploymentSecurity() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            UserInfo users[] = new UserInfo[] {
                    new UserInfo("user1", "admin", new String[] {"user"}),
                    new UserInfo("user2", "admin", new String[] {"administrator"}),
                    new UserInfo("user3", "admin", new String[] {"administrator"}), 
            };
            builder.addUsers(users);

            
            builder.setSecurityEnabled(true, false);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            
            
            
            String dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));

            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            assertTrue(dep.contains("jackson5"));
            assertTrue(dep.matches("^jackson5(.*)"));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testDeploymentSecurityAuthorizationHashed() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            UserInfo users[] = new UserInfo[] {
                    new UserInfo("user1", "admin", new String[] {"user"}),
                    new UserInfo("user2", "admin", new String[] {"administrator"}),
            };
            builder.addUsers(users);

            
            builder.setSecurityEnabled(true, false);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));

        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testDeploymentSecurityAuthorizationBasic() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            UserInfo users[] = new UserInfo[] {
                    new UserInfo("user1", "admin", new String[] {"user"}),
                    new UserInfo("user2", "admin", new String[] {"administrator"}),
            };
            builder.addUsers(users);

            
            builder.setSecurityEnabled(true, false);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("cluster"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("Permission denied"));
            
            dep = getUrlOverJSON("http:
            assertTrue(dep.contains("<deployment>"));
            assertTrue(dep.contains("</deployment>"));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testUsers() throws Exception {
        try {
            String simpleSchema
            = "CREATE TABLE foo (\n"
            + "    bar BIGINT NOT NULL,\n"
            + "    PRIMARY KEY (bar)\n"
            + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            builder.setUseDDLSchema(true);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String json = getUrlOverJSON("http:
            assertEquals(json, "");
            getUrlOverJSON("http:

            
            ObjectMapper mapper = new ObjectMapper();
            UsersType.User user = new UsersType.User();
            user.setName("foo");
            user.setPassword("foo");
            String map = mapper.writeValueAsString(user);
            Map<String,String> params = new HashMap<>();
            params.put("user", map);
            putUrlOverJSON("http:

            
            json = getUrlOverJSON("http:
            JSONArray jarray = new JSONArray(json);
            assertEquals(jarray.length(), 1);
            JSONObject jobj = jarray.getJSONObject(0);
            assertTrue(jobj.getString("id").contains("/deployment/users/foo"));
            assertTrue(jobj.getString("roles").equalsIgnoreCase("null"));

            
            user.setRoles("foo");
            map = mapper.writeValueAsString(user);
            params.put("user", map);
            postUrlOverJSON("http:

            
            json = getUrlOverJSON("http:
            jarray = new JSONArray(json);
            assertEquals(jarray.length(), 1);
            jobj = jarray.getJSONObject(0);
            assertTrue(jobj.getString("roles").equals("foo"));

            
            deleteUrlOverJSON("http:

            
            json = getUrlOverJSON("http:
            assertEquals(json, "");
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }

    public void testProfile() throws Exception {
        try {
            String simpleSchema
                    = "CREATE TABLE foo (\n"
                    + "    bar BIGINT NOT NULL,\n"
                    + "    PRIMARY KEY (bar)\n"
                    + ");";

            File schemaFile = VoltProjectBuilder.writeStringToTempFile(simpleSchema);
            String schemaPath = schemaFile.getPath();
            schemaPath = URLEncoder.encode(schemaPath, "UTF-8");

            VoltProjectBuilder builder = new VoltProjectBuilder();
            builder.addSchema(schemaPath);
            builder.addPartitionInfo("foo", "bar");
            builder.addProcedures(DelayProc.class);
            builder.setHTTPDPort(8095);
            boolean success = builder.compile(Configuration.getPathToCatalogForTest("json.jar"));
            assertTrue(success);

            VoltDB.Configuration config = new VoltDB.Configuration();
            config.m_pathToCatalog = config.setPathToCatalogForTest("json.jar");
            config.m_pathToDeployment = builder.getPathToDeployment();
            server = new ServerThread(config);
            server.start();
            server.waitForInitialization();

            
            String dep = getUrlOverJSON("http:
            assertTrue(dep.contains("\"user\""));
            assertTrue(dep.contains("\"permissions\""));
        } finally {
            if (server != null) {
                server.shutdown();
                server.join();
            }
            server = null;
        }
    }
}

<code block>


package org.voltdb.regressionsuites;

import java.io.File;
import java.io.IOException;
import java.util.List;

import org.voltdb.compiler.VoltProjectBuilder;


public interface VoltServerConfig {

    
    public boolean compile(VoltProjectBuilder builder);

    
    public void startUp();

    
    public void startUp(boolean clearDataDirectories);

    
    public void shutDown() throws InterruptedException;

    
    public String getListenerAddress(int hostId);

    
    public List<String> getListenerAddresses();

    
    public String getName();

    public void setCallingMethodName(String name);

    
    public int getNodeCount();

    
    public boolean isHSQL();

    
    public boolean isValgrind();

    boolean compileWithPartitionDetection(VoltProjectBuilder builder,
            String snapshotPath,
            String ppdPrefix);

    boolean compileWithAdminMode(VoltProjectBuilder builder, int adminPort,
                                 boolean adminOnStartup);

    
    public void createDirectory(File path) throws IOException;

    
    public void deleteDirectory(File path) throws IOException;

    
    public List<File> listFiles(File path) throws IOException;

    public File[] getPathInSubroots(File path) throws IOException;

    public void setMaxHeap(int max);

    
    public int getLogicalPartitionCount();
}

<code block>


package org.voltdb.regressionsuites;

import java.io.IOException;
import java.util.Random;

import junit.framework.Test;

import org.voltdb.BackendTarget;
import org.voltdb.VoltTable;
import org.voltdb.VoltType;
import org.voltdb.client.Client;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.NoConnectionsException;
import org.voltdb.client.NullCallback;
import org.voltdb.client.ProcCallException;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.utils.MiscUtils;
import org.voltdb_testprocs.regressionsuites.malicious.GoSleep;

public class TestSystemProcedureSuite extends RegressionSuite {

    private static int SITES = 3;
    private static int HOSTS = MiscUtils.isPro() ? 2 : 1;
    private static int KFACTOR = MiscUtils.isPro() ? 1 : 0;
    private static boolean hasLocalServer = false;

    static final Class<?>[] PROCEDURES =
    {
     GoSleep.class
    };

    public TestSystemProcedureSuite(String name) {
        super(name);
    }

    public void testPing() throws IOException, ProcCallException {
        Client client = getClient();
        ClientResponse cr = client.callProcedure("@Ping");
        assertEquals(ClientResponse.SUCCESS, cr.getStatus());
    }

    private void checkProSysprocError(Client client, String name, int paramCount)
            throws NoConnectionsException, IOException
    {
        
        Object[] params = new Object[paramCount];
        for (int i = 0; i < paramCount; i++) {
            params[i] = i;
        }

        try {
            client.callProcedure(name, params);
            fail();
        }
        catch (ProcCallException e) {
            assertEquals(ClientResponse.GRACEFUL_FAILURE, e.getClientResponse().getStatus());
            if (!e.getClientResponse().getStatusString().contains("Enterprise Edition")) {
                System.out.println("sup");
                System.out.println("MESSAGE: " + e.getClientResponse().getStatusString());
            }
            assertTrue(e.getClientResponse().getStatusString().contains("Enterprise"));
        }
    }

    public void testProSysprocErrorOnCommunity() throws Exception {
        
        if (MiscUtils.isPro()) {
            return;
        }

        Client client = getClient();

        checkProSysprocError(client, "@SnapshotSave", 3);
        checkProSysprocError(client, "@SnapshotRestore", 2);
        checkProSysprocError(client, "@SnapshotStatus", 0);
        checkProSysprocError(client, "@SnapshotScan", 2);
        checkProSysprocError(client, "@SnapshotDelete", 2);
        
        
    }

    public void testInvalidProcedureName() throws IOException {
        Client client = getClient();
        try {
            client.callProcedure("@SomeInvalidSysProcName", "1", "2");
        }
        catch (Exception e2) {
            assertEquals("Procedure @SomeInvalidSysProcName was not found", e2.getMessage());
            return;
        }
        fail("Expected exception.");
    }

    private final String m_loggingConfig =
        "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>" +
        "<!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\">" +
        "<log4j:configuration xmlns:log4j=\"http:
            "<appender name=\"Console\" class=\"org.apache.log4j.ConsoleAppender\">" +
                "<param name=\"Target\" value=\"System.out\" />" +
                "<layout class=\"org.apache.log4j.TTCCLayout\">" +
                "</layout>" +
            "</appender>" +
            "<appender name=\"Async\" class=\"org.apache.log4j.AsyncAppender\">" +
                "<param name=\"Blocking\" value=\"true\" />" +
                "<appender-ref ref=\"Console\" /> " +
            "</appender>" +
            "<root>" +
               "<priority value=\"info\" />" +
               "<appender-ref ref=\"Async\" />" +
            "</root>" +
        "</log4j:configuration>";

    public void testUpdateLogging() throws Exception {
        Client client = getClient();
        VoltTable results[] = null;
        results = client.callProcedure("@UpdateLogging", m_loggingConfig).getResults();
        for (VoltTable result : results) {
            assertEquals( 0, result.asScalarLong());
        }
    }

    public void testPromoteMaster() throws Exception {
        Client client = getClient();
        try {
            client.callProcedure("@Promote");
            fail();
        }
        catch (ProcCallException pce) {
            assertEquals(ClientResponse.GRACEFUL_FAILURE, pce.getClientResponse().getStatus());
        }
    }

    
    
    public void testQuiesce() throws IOException, ProcCallException {
        Client client = getClient();
        VoltTable results[] = client.callProcedure("@Quiesce").getResults();
        assertEquals(1, results.length);
        results[0].advanceRow();
        assertEquals(results[0].get(0, VoltType.BIGINT), new Long(0));
    }

    public void testLoadMultipartitionTableAndIndexStatsAndValidatePartitioning() throws Exception {
        Client client = getClient();

        
        Random r = new Random(0);
        for (int ii = 0; ii < 50; ii++) {
            client.callProcedure(new NullCallback(), "@AdHoc",
                    "INSERT INTO new_order values (" + (short)(r.nextDouble() * Short.MAX_VALUE) + ");");
        }

        
        try {
            client.callProcedure("@LoadMultipartitionTable", "DOES_NOT_EXIST", null, 1);
            fail();
        } catch (ProcCallException ex) {}

        
        VoltTable partitioned_table = new VoltTable(
                new VoltTable.ColumnInfo("W_ID", org.voltdb.VoltType.SMALLINT),
                new VoltTable.ColumnInfo("W_NAME", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_STREET_1", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_STREET_2", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_CITY", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_STATE", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_ZIP", org.voltdb.VoltType.get((byte)9)),
                new VoltTable.ColumnInfo("W_TAX",org.voltdb.VoltType.get((byte)8)),
                new VoltTable.ColumnInfo("W_YTD", org.voltdb.VoltType.get((byte)8))
        );

        for (int i = 1; i < 21; i++) {
            Object[] row = new Object[] {new Short((short) i),
                                         "name_" + i,
                                         "street1_" + i,
                                         "street2_" + i,
                                         "city_" + i,
                                         "ma",
                                         "zip_"  + i,
                                         new Double(i),
                                         new Double(i)};
            partitioned_table.addRow(row);
        }

        
        VoltTable replicated_table =
            new VoltTable(new VoltTable.ColumnInfo("I_ID", VoltType.INTEGER),
                          new VoltTable.ColumnInfo("I_IM_ID", VoltType.INTEGER),
                          new VoltTable.ColumnInfo("I_NAME", VoltType.STRING),
                          new VoltTable.ColumnInfo("I_PRICE", VoltType.FLOAT),
                          new VoltTable.ColumnInfo("I_DATA", VoltType.STRING));

        for (int i = 1; i < 21; i++) {
            Object[] row = new Object[] {i,
                                         i,
                                         "name_" + i,
                                         new Double(i),
                                         "data_"  + i};

            replicated_table.addRow(row);
        }

        try {
            try {
                client.callProcedure("@LoadMultipartitionTable", "WAREHOUSE",
                                 partitioned_table);
                fail();
            } catch (ProcCallException e) {}
            client.callProcedure("@LoadMultipartitionTable", "ITEM",
                                 replicated_table);

            
            int rowcount = 0;
            VoltTable results[] = client.callProcedure("@Statistics", "table", 0).getResults();
            while (rowcount != (20 * SITES * HOSTS)) {
                rowcount = 0;
                results = client.callProcedure("@Statistics", "table", 0).getResults();
                
                while(results[0].advanceRow()) {
                    if (results[0].getString("TABLE_NAME").equals("ITEM"))
                    {
                        rowcount += results[0].getLong("TUPLE_COUNT");
                    }
                }
            }

            System.out.println(results[0]);

            
            int foundItem = 0;
            results = client.callProcedure("@Statistics", "table", 0).getResults();
            while(results[0].advanceRow()) {
                if (results[0].getString("TABLE_NAME").equals("ITEM"))
                {
                    ++foundItem;
                    
                    assertEquals(20, results[0].getLong("TUPLE_COUNT"));
                }
            }
            assertEquals(MiscUtils.isPro() ? 6 : 3, foundItem);

            
            VoltTable indexStats =
                    client.callProcedure("@Statistics", "INDEX", 0).getResults()[0];
            System.out.println(indexStats);
            long memorySum = 0;
            while (indexStats.advanceRow()) {
                memorySum += indexStats.getLong("MEMORY_ESTIMATE");
            }

            
            long indexMemorySum = 0;
            for (int ii = 0; ii < 1000; ii++) {
                indexMemorySum = 0;
                indexStats = client.callProcedure("@Statistics", "MEMORY", 0).getResults()[0];
                System.out.println(indexStats);
                while (indexStats.advanceRow()) {
                    indexMemorySum += indexStats.getLong("INDEXMEMORY");
                }
                boolean success = indexMemorySum != 120;
                if (success) {
                    success = memorySum == indexMemorySum;
                    if (success) {
                        break;
                    }
                }
                Thread.sleep(1);
            }
            assertTrue(indexMemorySum != 120);
            assertEquals(memorySum, indexMemorySum);

            
            ClientResponse cr = client.callProcedure("@ValidatePartitioning", 0, null);

            VoltTable hashinatorMatches = cr.getResults()[1];
            while (hashinatorMatches.advanceRow()) {
                assertEquals(1L, hashinatorMatches.getLong("HASHINATOR_MATCHES"));
            }

            VoltTable validateResult = cr.getResults()[0];
            System.out.println(validateResult);
            while (validateResult.advanceRow()) {
                assertEquals(0L, validateResult.getLong("MISPARTITIONED_ROWS"));
            }

            
            cr = client.callProcedure("@ValidatePartitioning", 0, new byte[] { 0, 0, 0, 9 });

            hashinatorMatches = cr.getResults()[1];
            while (hashinatorMatches.advanceRow()) {
                assertEquals(0L, hashinatorMatches.getLong("HASHINATOR_MATCHES"));
            }

            validateResult = cr.getResults()[0];
            System.out.println(validateResult);
            while (validateResult.advanceRow()) {
                if (validateResult.getString("TABLE").equals("NEW_ORDER")) {
                    assertTrue(validateResult.getLong("MISPARTITIONED_ROWS") > 0);
                }
            }
        }
        catch (Exception e) {
            e.printStackTrace();
            fail();
        }
    }

    
    public void testProfCtl() throws Exception {
        Client client = getClient();

        
        
        
        ClientResponse resp = client.callProcedure("@ProfCtl", "SAMPLER_START");
        VoltTable vt = resp.getResults()[0];
        boolean foundResponse = false;
        while (vt.advanceRow()) {
            if (!vt.getString("Result").equalsIgnoreCase("sampler_start")) {
                fail();
            }
            foundResponse = true;
        }
        assertTrue(foundResponse);

        
        
        
        resp = client.callProcedure("@ProfCtl", "GPERF_ENABLE");
        vt = resp.getResults()[0];
        foundResponse = false;
        while (vt.advanceRow()) {
            if (vt.getString("Result").equalsIgnoreCase("GPERF_ENABLE")) {
                foundResponse = true;
            }
            else {
                assertTrue(vt.getString("Result").equalsIgnoreCase("GPERF_NOOP"));
            }
        }
        assertTrue(foundResponse);

        
        
        
        resp = client.callProcedure("@ProfCtl", "GPERF_DISABLE");
        vt = resp.getResults()[0];
        foundResponse = false;
        while (vt.advanceRow()) {
            if (vt.getString("Result").equalsIgnoreCase("gperf_disable")) {
                foundResponse = true;
            }
            else {
                assertTrue(vt.getString("Result").equalsIgnoreCase("GPERF_NOOP"));
            }
        }
        assertTrue(foundResponse);

        
        
        
        resp = client.callProcedure("@ProfCtl", "MakeAPony");
        vt = resp.getResults()[0];
        assertTrue(true);
    }

    
    
    
    
    
    static public Test suite() throws IOException {
        VoltServerConfig config = null;

        MultiConfigSuiteBuilder builder =
            new MultiConfigSuiteBuilder(TestSystemProcedureSuite.class);

        
        
        
        VoltProjectBuilder project = new VoltProjectBuilder();
        project.addLiteralSchema(
                        "CREATE TABLE WAREHOUSE (\n" +
                        "  W_ID SMALLINT DEFAULT '0' NOT NULL,\n" +
                        "  W_NAME VARCHAR(16) DEFAULT NULL,\n" +
                        "  W_STREET_1 VARCHAR(32) DEFAULT NULL,\n" +
                        "  W_STREET_2 VARCHAR(32) DEFAULT NULL,\n" +
                        "  W_CITY VARCHAR(32) DEFAULT NULL,\n" +
                        "  W_STATE VARCHAR(2) DEFAULT NULL,\n" +
                        "  W_ZIP VARCHAR(9) DEFAULT NULL,\n" +
                        "  W_TAX FLOAT DEFAULT NULL,\n" +
                        "  W_YTD FLOAT DEFAULT NULL,\n" +
                        "  CONSTRAINT W_PK_TREE PRIMARY KEY (W_ID)\n" +
                        ");\n" +
                        "CREATE TABLE ITEM (\n" +
                        "  I_ID INTEGER DEFAULT '0' NOT NULL,\n" +
                        "  I_IM_ID INTEGER DEFAULT NULL,\n" +
                        "  I_NAME VARCHAR(32) DEFAULT NULL,\n" +
                        "  I_PRICE FLOAT DEFAULT NULL,\n" +
                        "  I_DATA VARCHAR(64) DEFAULT NULL,\n" +
                        "  CONSTRAINT I_PK_TREE PRIMARY KEY (I_ID)\n" +
                        ");\n" +
                        "CREATE TABLE NEW_ORDER (\n" +
                        "  NO_W_ID SMALLINT DEFAULT '0' NOT NULL\n" +
                        ");\n");

        project.addPartitionInfo("WAREHOUSE", "W_ID");
        project.addPartitionInfo("NEW_ORDER", "NO_W_ID");
        project.addProcedures(PROCEDURES);

        

        
        config = new LocalCluster("sysproc-cluster.jar", TestSystemProcedureSuite.SITES, TestSystemProcedureSuite.HOSTS, TestSystemProcedureSuite.KFACTOR,
                                  BackendTarget.NATIVE_EE_JNI);
        ((LocalCluster) config).setHasLocalServer(hasLocalServer);
        boolean success = config.compile(project);
        assertTrue(success);
        builder.addServerConfig(config);

        return builder;
    }
}



<code block>


package org.voltdb.regressionsuites;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import org.voltdb.BackendTarget;
import org.voltdb.ServerThread;
import org.voltdb.StartAction;
import org.voltdb.VoltDB.Configuration;
import org.voltdb.compiler.VoltProjectBuilder;


@Deprecated
public abstract class LocalSingleProcessServer implements VoltServerConfig {

    public final String m_jarFileName;
    public int m_siteCount;
    public final BackendTarget m_target;

    ServerThread m_server = null;
    boolean m_compiled = false;
    protected String m_pathToDeployment;
    private File m_pathToVoltRoot = null;
    private EEProcess m_siteProcess = null;

    public LocalSingleProcessServer(String jarFileName, int siteCount,
                                    BackendTarget target)
    {
        assert(jarFileName != null);
        assert(siteCount > 0);
        m_jarFileName = Configuration.getPathToCatalogForTest(jarFileName);
        m_siteCount = siteCount;
        if (LocalCluster.isMemcheckDefined() && target.equals(BackendTarget.NATIVE_EE_JNI)) {
            m_target = BackendTarget.NATIVE_EE_VALGRIND_IPC;
        } else {
            m_target = target;
        }
    }

    @Override
    public void setCallingMethodName(String name) {
        
    }

    @Override
    public boolean compile(VoltProjectBuilder builder) {
        if (m_compiled == true) {
            return true;
        }

        m_compiled = builder.compile(m_jarFileName, m_siteCount, 1, 0);
        m_pathToDeployment = builder.getPathToDeployment();
        m_pathToVoltRoot = builder.getPathToVoltRoot();

        return m_compiled;
    }

    @Override
    public boolean compileWithPartitionDetection(VoltProjectBuilder builder, String snapshotPath, String ppdPrefix) {
        
        
        int hostCount = 1;
        int replication = 0;

        if (m_compiled) {
            return true;
        }
        m_compiled = builder.compile(m_jarFileName, m_siteCount, hostCount, replication,
                                     null, true, snapshotPath, ppdPrefix);
        m_pathToDeployment = builder.getPathToDeployment();
        m_pathToVoltRoot = builder.getPathToVoltRoot();

        return m_compiled;
    }

    @Override
    public boolean compileWithAdminMode(VoltProjectBuilder builder,
                                        int adminPort, boolean adminOnStartup)
    {
        int hostCount = 1;
        int replication = 0;

        if (m_compiled) {
            return true;
        }
        m_compiled = builder.compile(m_jarFileName, m_siteCount, hostCount, replication,
                                     adminPort, adminOnStartup);
        m_pathToDeployment = builder.getPathToDeployment();
        return m_compiled;

    }

    @Override
    public List<String> getListenerAddresses() {
        
        if (m_server == null)
            return null;
        ArrayList<String> listeners = new ArrayList<String>();
        listeners.add("localhost");
        return listeners;
    }

    @Override
    public String getListenerAddress(int hostId) {
        if (m_server == null)
            return null;
        return "localhost";
    }

    @Override
    public String getName() {
        

        String retval = "localSingleProcess-";
        retval += String.valueOf(m_siteCount);
        if (m_target == BackendTarget.HSQLDB_BACKEND)
            retval += "-HSQL";
        else if (m_target == BackendTarget.NATIVE_EE_IPC)
            retval += "-IPC";
        else
            retval += "-JNI";
        return retval;
    }

    @Override
    public int getNodeCount()
    {
        return 1;
    }

    @Override
    public void shutDown() throws InterruptedException {
        m_server.shutdown();
        m_siteProcess.waitForShutdown();
        if (m_target == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
            if (!EEProcess.m_valgrindErrors.isEmpty()) {
                String failString = "";
                for (final String error : EEProcess.m_valgrindErrors) {
                    failString = failString + "\n" +  error;
                }
                org.junit.Assert.fail(failString);
            }
        }
    }

    @Override
    public void startUp(boolean clearLocalDataDirectories) {
        if (clearLocalDataDirectories) {
            File exportOverflow = new File( m_pathToVoltRoot, "export_overflow");
            if (exportOverflow.exists()) {
                assert(exportOverflow.isDirectory());
                for (File f : exportOverflow.listFiles()) {
                    if (f.isFile() && f.getName().endsWith(".pbd") || f.getName().endsWith(".ad")) {
                        f.delete();
                    }
                }
            }
        }

        Configuration config = new Configuration();
        config.m_backend = m_target;
        config.m_noLoadLibVOLTDB = (m_target == BackendTarget.HSQLDB_BACKEND);
        
        config.m_pathToCatalog = m_jarFileName;
        config.m_pathToDeployment = m_pathToDeployment;
        config.m_startAction = StartAction.CREATE;

        m_siteProcess = new EEProcess(m_target, m_siteCount, "LocalSingleProcessServer.log");
        config.m_ipcPort = m_siteProcess.port();

        m_server = new ServerThread(config);
        m_server.start();
        m_server.waitForInitialization();
    }

    @Override
    public boolean isHSQL() {
        return m_target == BackendTarget.HSQLDB_BACKEND;
    }

    @Override
    public boolean isValgrind() {
        return m_target == BackendTarget.NATIVE_EE_VALGRIND_IPC;
    }
    @Override
    public void startUp() {
        startUp(true);
    }
    @Override
    public void createDirectory(File path) throws IOException {
        throw new UnsupportedOperationException();
    }
    @Override
    public void deleteDirectory(File path) throws IOException {
        throw new UnsupportedOperationException();
    }
    @Override
    public List<File> listFiles(File path) throws IOException {
        throw new UnsupportedOperationException();
    }
    @Override
    public File[] getPathInSubroots(File path) throws IOException {
        throw new UnsupportedOperationException();
    }

    @Override
    public int getLogicalPartitionCount() {
        return 1;
    }
}

<code block>

package org.voltdb.regressionsuites;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.Random;

import org.voltcore.logging.VoltLogger;
import org.voltdb.BackendTarget;
import org.voltdb.ReplicationRole;
import org.voltdb.ServerThread;
import org.voltdb.StartAction;
import org.voltdb.VoltDB;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.utils.CommandLine;
import org.voltdb.utils.MiscUtils;
import org.voltdb.utils.VoltFile;


public class LocalCluster implements VoltServerConfig {

    public enum FailureState {
        ALL_RUNNING,
        ONE_FAILURE,
        ONE_RECOVERING
    }

    
    
    public static final String clusterHostIdProperty = "__VOLTDB_CLUSTER_HOSTID__";

    private VoltLogger log = new VoltLogger("HOST");

    
    
    static final int TIMESTAMP_SALT_VARIANCE = 3;

    int getRandomTimestampSalt() {
        Random r = new Random();
        
        int retval = r.nextInt(TIMESTAMP_SALT_VARIANCE * 2 + 1);
        
        retval -= TIMESTAMP_SALT_VARIANCE;
        return retval;
    }

    
    static final long PIPE_WAIT_MAX_TIMEOUT = 60 * 1000 *2; 

    String m_callingClassName = "";
    String m_callingMethodName = "";
    boolean m_compiled = false;
    protected int m_siteCount;
    int m_hostCount;
    int m_kfactor = 0;
    protected BackendTarget m_target;
    protected String m_jarFileName;
    boolean m_running = false;
    private final boolean m_debug;
    FailureState m_failureState;
    int m_nextIPCPort = 10000;
    ArrayList<Process> m_cluster = new ArrayList<Process>();
    int perLocalClusterExtProcessIndex = 0;
    VoltProjectBuilder m_builder;
    private boolean m_expectedToCrash = false;
    private boolean m_expectedToInitialize = true;

    
    ArrayList<File> m_subRoots = new ArrayList<File>();
    public ArrayList<File> getSubRoots() {
        return m_subRoots;
    }

    boolean m_hasLocalServer = true;
    public void setHasLocalServer(boolean hasLocalServer) {
        m_hasLocalServer = hasLocalServer;
    }

    ArrayList<PipeToFile> m_pipes = null;
    ArrayList<CommandLine> m_cmdLines = null;
    ServerThread m_localServer = null;
    ProcessBuilder m_procBuilder;
    private final ArrayList<EEProcess> m_eeProcs = new ArrayList<EEProcess>();
    
    
    private Map<String, String> m_additionalProcessEnv = null;
    
    public final PortGeneratorForTest portGenerator = new PortGeneratorForTest();
    private String m_voltdbroot = "";

    private String[] m_versionOverrides = null;
    private String[] m_versionCheckRegexOverrides = null;
    private String[] m_buildStringOverrides = null;

    
    
    
    
    private final CommandLine templateCmdLine = new CommandLine(StartAction.CREATE);

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target)
    {
        this(jarFileName, siteCount, hostCount, kfactor, target, null);
    }

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target,
                        Map<String, String> env)
    {
        this(jarFileName, siteCount, hostCount, kfactor, target,
                FailureState.ALL_RUNNING, false, false, env);

    }

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target,
                        boolean isRejoinTest)
    {
        this(jarFileName, siteCount, hostCount, kfactor, target,
                FailureState.ALL_RUNNING, false, isRejoinTest, null);
    }

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target,
                        FailureState failureState,
                        boolean debug)
    {
        this(jarFileName, siteCount, hostCount, kfactor, target,
                failureState, debug, false, null);
    }

    public LocalCluster(String jarFileName,
                        int siteCount,
                        int hostCount,
                        int kfactor,
                        BackendTarget target,
                        FailureState failureState,
                        boolean debug,
                        boolean isRejoinTest,
                        Map<String, String> env)
    {
        assert (jarFileName != null);
        assert (siteCount > 0);
        assert (hostCount > 0);

        m_additionalProcessEnv = env;
        
        StackTraceElement[] traces = Thread.currentThread().getStackTrace();
        m_callingClassName = "UnknownClass";
        m_callingMethodName = "unknownMethod";
        
        int i;
        
        for (i = 0; traces[i].getClassName().equals(getClass().getName()) == false; i++);
        
        for (;      traces[i].getClassName().equals(getClass().getName()); i++);
        
        int dot = traces[i].getClassName().lastIndexOf('.');
        m_callingClassName = traces[i].getClassName().substring(dot + 1);
        m_callingMethodName = traces[i].getMethodName();

        log.info("Instantiating LocalCluster for " + jarFileName + " with class.method: " +
                m_callingClassName + "." + m_callingMethodName);
        log.info("Sites: " + siteCount + " hosts: " + hostCount + " replication factor: " + kfactor);

        m_cluster.ensureCapacity(hostCount);

        m_siteCount = siteCount;
        m_hostCount = hostCount;
        if (kfactor > 0 && !MiscUtils.isPro()) {
            m_kfactor = 0;
        } else {
            m_kfactor = kfactor;
        }
        m_debug = debug;
        m_jarFileName = jarFileName;
        m_failureState = m_kfactor < 1 ? FailureState.ALL_RUNNING : failureState;
        m_pipes = new ArrayList<PipeToFile>();
        m_cmdLines = new ArrayList<CommandLine>();

        
        
        if (isMemcheckDefined() && (target == BackendTarget.NATIVE_EE_JNI) && m_hostCount == 1) {
            m_target = BackendTarget.NATIVE_EE_VALGRIND_IPC;
        }
        else {
            m_target = target;
        }

        String buildDir = System.getenv("VOLTDB_BUILD_DIR");  
        if (buildDir == null) {
            buildDir = System.getProperty("user.dir") + "/obj/release";
        }

        
        String java_library_path = buildDir + "/nativelibs";
        java_library_path = System.getProperty("java.library.path", java_library_path);

        String classPath = System.getProperty("java.class.path") + ":" + buildDir
            + File.separator + m_jarFileName + ":" + buildDir + File.separator + "prod";

        
        
        classPath = classPath.replace(buildDir + File.separator + "testprocs:", "");

        
        String log4j = System.getProperty("log4j.configuration");
        if (log4j == null) {
            log4j = "file:
        }

        m_procBuilder = new ProcessBuilder();

        
        
        m_procBuilder.redirectErrorStream(true);

        Thread shutdownThread = new Thread(new ShutDownHookThread());
        java.lang.Runtime.getRuntime().addShutdownHook(shutdownThread);

        
        this.templateCmdLine.
            addTestOptions(true).
            leader("").
            target(m_target).
            startCommand("create").
            jarFileName(VoltDB.Configuration.getPathToCatalogForTest(m_jarFileName)).
            buildDir(buildDir).
            javaLibraryPath(java_library_path).
            classPath(classPath).
            pathToLicense(ServerThread.getTestLicensePath()).
            log4j(log4j);
        this.templateCmdLine.m_noLoadLibVOLTDB = m_target == BackendTarget.HSQLDB_BACKEND;
        
        this.templateCmdLine.m_tag = m_callingClassName + ":" + m_callingMethodName;
    }

    
    public void overrideAnyRequestForValgrind() {
        if (templateCmdLine.m_backend == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
            m_target = BackendTarget.NATIVE_EE_JNI;
            templateCmdLine.m_backend = BackendTarget.NATIVE_EE_JNI;
        }
    }

    public void overrideStartCommandVerb(String verb) {
        if (verb == null || verb.trim().isEmpty()) return;
        this.templateCmdLine.startCommand(verb);
    }

    public void setCustomCmdLn(String customCmdLn) {
        templateCmdLine.customCmdLn(customCmdLn);
    }

    public void setJavaProperty(String property, String value) {
        templateCmdLine.setJavaProperty(property, value);
    }

    @Override
    public void setCallingMethodName(String name) {
        m_callingMethodName = name;
    }

    @Override
    public boolean compile(VoltProjectBuilder builder) {
        if (!m_compiled) {
            m_compiled = builder.compile(templateCmdLine.jarFileName(), m_siteCount, m_hostCount, m_kfactor);
            templateCmdLine.pathToDeployment(builder.getPathToDeployment());
            m_voltdbroot = builder.getPathToVoltRoot().getAbsolutePath();
        }
        return m_compiled;
    }

    @Override
    public boolean compileWithPartitionDetection(VoltProjectBuilder builder, String snapshotPath, String ppdPrefix) {
        if (!m_compiled) {
            m_compiled = builder.compile(templateCmdLine.jarFileName(), m_siteCount, m_hostCount, m_kfactor,
                    null, true, snapshotPath, ppdPrefix);
            templateCmdLine.pathToDeployment(builder.getPathToDeployment());
            m_voltdbroot = builder.getPathToVoltRoot().getAbsolutePath();
        }
        return m_compiled;
    }

    @Override
    public boolean compileWithAdminMode(VoltProjectBuilder builder, int adminPort, boolean adminOnStartup)
    {
        
        
        
        if (adminPort != VoltDB.DEFAULT_ADMIN_PORT) {
            return false;
        }

        if (!m_compiled) {
            m_compiled = builder.compile(templateCmdLine.jarFileName(), m_siteCount, m_hostCount, m_kfactor,
                    adminPort, adminOnStartup);
            templateCmdLine.pathToDeployment(builder.getPathToDeployment());
            m_voltdbroot = builder.getPathToVoltRoot().getAbsolutePath();
        }
        return m_compiled;
    }

    @Override
    public void startUp() {
        startUp(true);
    }

    @Override
    public void startUp(boolean clearLocalDataDirectories) {
        startUp(clearLocalDataDirectories, ReplicationRole.NONE);
    }

    public void setDeploymentAndVoltDBRoot(String pathToDeployment, String pathToVoltDBRoot) {
        templateCmdLine.pathToDeployment(pathToDeployment);
        m_voltdbroot = pathToVoltDBRoot;
        m_compiled = true;
    }

    public void setHostCount(int hostCount)
    {
        m_hostCount = hostCount;
        
        m_compiled = false;
    }

    void startLocalServer(int hostId, boolean clearLocalDataDirectories) {
        startLocalServer(hostId, clearLocalDataDirectories, templateCmdLine.m_startAction);
    }

    void startLocalServer(int hostId, boolean clearLocalDataDirectories, StartAction action) {
        
        File subroot = null;
        try {
        if (clearLocalDataDirectories) {
                subroot = VoltFile.initNewSubrootForThisProcess();
                m_subRoots.add(subroot);
        } else {
            if (m_subRoots.size() <= hostId) {
                m_subRoots.add(VoltFile.initNewSubrootForThisProcess());
            }
            subroot = m_subRoots.get(hostId);
        }
        } catch (IOException e) {
            throw new RuntimeException(e);
        }

        
        CommandLine cmdln = (templateCmdLine.makeCopy());
        cmdln.startCommand(action);
        cmdln.setJavaProperty(clusterHostIdProperty, String.valueOf(hostId));
        if (this.m_additionalProcessEnv != null) {
            for (String name : this.m_additionalProcessEnv.keySet()) {
                cmdln.setJavaProperty(name, this.m_additionalProcessEnv.get(name));
            }
        }

        cmdln.internalPort(portGenerator.nextInternalPort());
        cmdln.voltFilePrefix(subroot.getPath());
        cmdln.internalPort(portGenerator.nextInternalPort());
        cmdln.port(portGenerator.nextClient());
        cmdln.adminPort(portGenerator.nextAdmin());
        cmdln.zkport(portGenerator.nextZkPort());
        cmdln.httpPort(portGenerator.nextHttp());
        
        cmdln.drAgentStartPort(portGenerator.nextReplicationPort());
        portGenerator.nextReplicationPort();
        portGenerator.nextReplicationPort();
        if (m_target == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
            EEProcess proc = m_eeProcs.get(hostId);
            assert(proc != null);
            cmdln.m_ipcPort = proc.port();
        }
        if (m_target == BackendTarget.NATIVE_EE_IPC) {
            cmdln.m_ipcPort = portGenerator.next();
        }
        if ((m_versionOverrides != null) && (m_versionOverrides.length > hostId)) {
            assert(m_versionOverrides[hostId] != null);
            assert(m_versionCheckRegexOverrides[hostId] != null);
            cmdln.m_versionStringOverrideForTest = m_versionOverrides[hostId];
            cmdln.m_versionCompatibilityRegexOverrideForTest = m_versionCheckRegexOverrides[hostId];
            if ((m_buildStringOverrides != null) && (m_buildStringOverrides.length > hostId)) {
                assert(m_buildStringOverrides[hostId] != null);
                cmdln.m_buildStringOverrideForTest = m_buildStringOverrides[hostId];
            }
        }

        
        

        m_cluster.add(null);
        m_pipes.add(null);
        m_cmdLines.add(cmdln);
        m_localServer = new ServerThread(cmdln);
        m_localServer.start();
    }

    private boolean waitForAllReady()
    {
        if (!m_expectedToInitialize) {
            return true;
        }
        long startOfPipeWait = System.currentTimeMillis();
        boolean allReady = false;
        do {
            if ((System.currentTimeMillis() - startOfPipeWait) > PIPE_WAIT_MAX_TIMEOUT) {
                break;
            }

            allReady = true;
            for (PipeToFile pipeToFile : m_pipes) {
                if (pipeToFile == null) {
                    continue;
                }
                synchronized(pipeToFile) {
                    
                    if (isProcessDead(pipeToFile.getProcess())) {
                        
                        
                        return false;
                    }

                    
                    if (pipeToFile.m_eof.get()) {
                        continue;
                    }

                    
                    if (pipeToFile.m_witnessedReady.get() != true) {
                        try {
                            
                            pipeToFile.wait(250);
                        }
                        catch (InterruptedException ex) {
                            log.error(ex.toString(), ex);
                        }
                        allReady = false;
                    }
                }
            }
        } while (allReady == false);
        return allReady;
    }

    private void printTiming(boolean logtime, String msg) {
        if (logtime) {
            System.out.println("************ " + msg);
        }
    }

    public void startUp(boolean clearLocalDataDirectories, ReplicationRole role) {
        assert (!m_running);
        if (m_running) {
            return;
        }

        
        VoltDB.setDefaultTimezone();

        
        templateCmdLine.replicaMode(role);

        
        boolean logtime = false;
        long startTime = 0;
        printTiming(logtime, "Starting cluster at: " + System.currentTimeMillis());

        
        if (clearLocalDataDirectories) {
            try {
                m_subRoots.clear();
                VoltFile.deleteAllSubRoots();
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
        }

        
        
        portGenerator.reset();
        templateCmdLine.leaderPort(portGenerator.nextInternalPort());

        m_eeProcs.clear();
        for (int ii = 0; ii < m_hostCount; ii++) {
            String logfile = "LocalCluster_host_" + ii + ".log";
            m_eeProcs.add(new EEProcess(templateCmdLine.target(), m_siteCount, logfile));
        }

        m_pipes.clear();
        m_cluster.clear();
        m_cmdLines.clear();
        int oopStartIndex = 0;

        
        if (m_hasLocalServer) {
            startLocalServer(oopStartIndex, clearLocalDataDirectories);
            ++oopStartIndex;
        }

        
        for (int i = oopStartIndex; i < m_hostCount; i++) {
            startOne(i, clearLocalDataDirectories, role, StartAction.CREATE);
        }

        printTiming(logtime, "Pre-witness: " + (System.currentTimeMillis() - startTime) + "ms");
        boolean allReady = waitForAllReady();
        printTiming(logtime, "Post-witness: " + (System.currentTimeMillis() - startTime) + "ms");

        
        int downProcesses = 0;
        for (Process proc : m_cluster) {
            if ((proc != null) && (isProcessDead(proc))) {
                downProcesses++;
            }
        }

        
        if ((downProcesses > 0) || (allReady == false)) {
            
            for (Process proc : m_cluster) {
                if (proc != null) {
                    try { proc.destroy(); } catch (Exception e) {}
                }
            }

            if (downProcesses > 0) {
                int expectedProcesses = m_hostCount - (m_hasLocalServer ? 1 : 0);
                if (!m_expectedToCrash) {
                    throw new RuntimeException(
                            String.format("%d/%d external processes failed to start",
                            downProcesses, expectedProcesses));
                }
            }
            
            else if (!allReady) {
                throw new RuntimeException(
                        "One or more external processes failed to complete initialization.");
            }
        }

        
        if (m_hasLocalServer) {
            m_localServer.waitForInitialization();
        }

        printTiming(logtime, "DONE: " + (System.currentTimeMillis() - startTime) + " ms");
        m_running = true;

        
        if (m_failureState != FailureState.ALL_RUNNING) {
            killOne();
        }

        
        if (m_failureState == FailureState.ONE_RECOVERING) {
            int hostId = m_hasLocalServer ? 1 : 0;
            recoverOne(logtime, startTime, hostId);
        }
    }

    private void killOne()
    {
        log.info("Killing one cluster member.");
        int procIndex = 0;
        if (m_hasLocalServer) {
            procIndex = 1;
        }

        Process proc = m_cluster.get(procIndex);
        proc.destroy();
        int retval = 0;
        try {
            retval = proc.waitFor();
            EEProcess eeProc = m_eeProcs.get(procIndex);
            eeProc.waitForShutdown();
        } catch (InterruptedException e) {
            log.info("External VoltDB process is acting crazy.");
        } finally {
            m_cluster.set(procIndex, null);
        }
        
        if (retval != 0 && retval != 143) {
            log.info("killOne: External VoltDB process terminated abnormally with return: " + retval);
        }
    }

    private void startOne(int hostId, boolean clearLocalDataDirectories, ReplicationRole replicaMode, StartAction startAction)
    {
        PipeToFile ptf = null;
        CommandLine cmdln = (templateCmdLine.makeCopy());
        cmdln.setJavaProperty(clusterHostIdProperty, String.valueOf(hostId));
        if (this.m_additionalProcessEnv != null) {
            for (String name : this.m_additionalProcessEnv.keySet()) {
                cmdln.setJavaProperty(name, this.m_additionalProcessEnv.get(name));
            }
        }
        try {
            cmdln.internalPort(portGenerator.nextInternalPort());
            
            
            cmdln.drAgentStartPort(portGenerator.nextReplicationPort());
            portGenerator.next();
            portGenerator.next();

            
            if (m_target == BackendTarget.NATIVE_EE_IPC) {
                
                cmdln.ipcPort(portGenerator.next());
            }
            if (m_target == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
                EEProcess proc = m_eeProcs.get(hostId);
                assert(proc != null);
                cmdln.m_ipcPort = proc.port();
            }

            cmdln.port(portGenerator.nextClient());
            cmdln.adminPort(portGenerator.nextAdmin());
            cmdln.httpPort(portGenerator.nextHttp());
            cmdln.replicaMode(replicaMode);
            cmdln.timestampSalt(getRandomTimestampSalt());

            if (m_debug) {
                cmdln.debugPort(portGenerator.next());
            }

            cmdln.zkport(portGenerator.nextZkPort());

            if (startAction == StartAction.JOIN) {
                cmdln.startCommand(startAction);
                int portNoToRejoin = m_cmdLines.get(0).internalPort();
                cmdln.leader(":" + portNoToRejoin);
            }

            
            
            File subroot = null;
            if (clearLocalDataDirectories) {
                subroot = VoltFile.getNewSubroot();
                m_subRoots.add(subroot);
            } else {
                if (m_subRoots.size() <= hostId) {
                    m_subRoots.add(VoltFile.getNewSubroot());
                }
                subroot = m_subRoots.get(hostId);
            }
            cmdln.voltFilePrefix(subroot.getPath());
            cmdln.voltRoot(subroot.getPath() + "/" + m_voltdbroot);

            if ((m_versionOverrides != null) && (m_versionOverrides.length > hostId)) {
                assert(m_versionOverrides[hostId] != null);
                assert(m_versionCheckRegexOverrides[hostId] != null);
                cmdln.m_versionStringOverrideForTest = m_versionOverrides[hostId];
                cmdln.m_versionCompatibilityRegexOverrideForTest = m_versionCheckRegexOverrides[hostId];
                if ((m_buildStringOverrides != null) && (m_buildStringOverrides.length > hostId)) {
                    assert(m_buildStringOverrides[hostId] != null);
                    cmdln.m_buildStringOverrideForTest = m_buildStringOverrides[hostId];
                }
            }

            m_cmdLines.add(cmdln);
            m_procBuilder.command().clear();
            List<String> cmdlnList = cmdln.createCommandLine();
            String cmdLineFull = "Start cmd host=" + String.valueOf(hostId) + " :";
            for (String element : cmdlnList) {
                assert(element != null);
                cmdLineFull += " " + element;
            }
            log.info(cmdLineFull);
            m_procBuilder.command().addAll(cmdlnList);

            
            
            
            String testoutputdir = cmdln.buildDir() + File.separator + "testoutput";
            System.out.println("Process output will be redirected to: " + testoutputdir);
            
            File dir = new File(testoutputdir);
            if (dir.exists()) {
                assert (dir.isDirectory());
            } else {
                boolean status = dir.mkdirs();
                assert (status);
            }

            File dirFile = new VoltFile(testoutputdir);
            if (dirFile.listFiles() != null) {
                for (File f : dirFile.listFiles()) {
                    if (f.getName().startsWith(getName() + "-" + hostId)) {
                        f.delete();
                    }
                }
            }

            Process proc = m_procBuilder.start();
            m_cluster.add(proc);
            String fileName = testoutputdir
                    + File.separator
                    + "LC-"
                    + getFileName() + "-"
                    + hostId + "-"
                    + "idx" + String.valueOf(perLocalClusterExtProcessIndex++)
                    + ".txt";
            System.out.println("Process output can be found in: " + fileName);
            ptf = new PipeToFile(
                    fileName,
                    proc.getInputStream(),
                    startAction == StartAction.JOIN ? PipeToFile.m_joinToken : PipeToFile.m_initToken,
                    false,
                    proc);
            m_pipes.add(ptf);
            ptf.setName("ClusterPipe:" + String.valueOf(hostId));
            ptf.start();
        }
        catch (IOException ex) {
            log.error("Failed to start cluster process:" + ex.getMessage(), ex);
            assert (false);
        }

        if (startAction == StartAction.JOIN) {
            waitOnPTFReady(ptf, true, System.currentTimeMillis(), System.currentTimeMillis(), hostId);
        }

        if (hostId > (m_hostCount - 1)) {
            m_hostCount++;
            this.m_compiled = false; 
        }
    }

    
    private boolean isProcessDead(Process p) {
        try {
            p.exitValue();
            return true; 
        }
        catch (IllegalThreadStateException e) {
            return false; 
        }
    }

    public boolean recoverOne(int hostId, Integer portOffset, String rejoinHost, boolean liveRejoin) {
        return recoverOne(
                false,
                0,
                hostId,
                portOffset,
                rejoinHost,
                liveRejoin ? StartAction.LIVE_REJOIN : StartAction.REJOIN);
    }

    public void joinOne(int hostId) {
        startOne(hostId, true, ReplicationRole.NONE, StartAction.JOIN);
    }

    public boolean recoverOne(int hostId, Integer portOffset, String rejoinHost) {
        return recoverOne(false, 0, hostId, portOffset, rejoinHost, StartAction.REJOIN);
    }

    private boolean recoverOne(boolean logtime, long startTime, int hostId) {
        return recoverOne( logtime, startTime, hostId, null, "", StartAction.REJOIN);
    }

    
    
    private boolean recoverOne(boolean logtime, long startTime, int hostId, Integer rejoinHostId,
                               String rejoinHost, StartAction startAction) {
        
        
        
        
        if (rejoinHostId == null || m_hasLocalServer) {
            rejoinHostId = 0;
        }

        int portNoToRejoin = m_cmdLines.get(rejoinHostId).internalPort();

        if (hostId == 0 && m_hasLocalServer) {
            templateCmdLine.leaderPort(portNoToRejoin);
            startLocalServer(rejoinHostId, false, StartAction.REJOIN);
            return true;
        }

        log.info("Rejoining " + hostId + " to hostID: " + rejoinHostId);

        
        EEProcess eeProc = m_eeProcs.get(hostId);
        try {
            eeProc.waitForShutdown();
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
        if (templateCmdLine.target().isIPC) {
            String logfile = "LocalCluster_host_" + hostId + ".log";
            m_eeProcs.set(hostId, new EEProcess(templateCmdLine.target(), m_siteCount, logfile));
        }

        PipeToFile ptf = null;
        long start = 0;
        try {
            CommandLine rejoinCmdLn = m_cmdLines.get(hostId);
            
            rejoinCmdLn.javaProperties = templateCmdLine.javaProperties;
            rejoinCmdLn.startCommand(startAction);

            
            
            if (m_debug) {
                rejoinCmdLn.debugPort(portGenerator.next());
            }
            rejoinCmdLn.leader(rejoinHost + ":" + String.valueOf(portNoToRejoin));

            rejoinCmdLn.m_port = portGenerator.nextClient();
            rejoinCmdLn.m_adminPort = portGenerator.nextAdmin();
            rejoinCmdLn.m_httpPort = portGenerator.nextHttp();
            rejoinCmdLn.m_zkInterface = "127.0.0.1:" + portGenerator.next();
            rejoinCmdLn.m_internalPort = portGenerator.nextInternalPort();
            setPortsFromConfig(hostId, rejoinCmdLn);

            if ((m_versionOverrides != null) && (m_versionOverrides.length > hostId)) {
                assert(m_versionOverrides[hostId] != null);
                assert(m_versionCheckRegexOverrides[hostId] != null);
                rejoinCmdLn.m_versionStringOverrideForTest = m_versionOverrides[hostId];
                rejoinCmdLn.m_versionCompatibilityRegexOverrideForTest = m_versionCheckRegexOverrides[hostId];
                if ((m_buildStringOverrides != null) && (m_buildStringOverrides.length > hostId)) {
                    assert(m_buildStringOverrides[hostId] != null);
                    rejoinCmdLn.m_buildStringOverrideForTest = m_buildStringOverrides[hostId];
                }
            }

            List<String> rejoinCmdLnStr = rejoinCmdLn.createCommandLine();
            String cmdLineFull = "Rejoin cmd line:";
            for (String element : rejoinCmdLnStr) {
                cmdLineFull += " " + element;
            }
            log.info(cmdLineFull);

            m_procBuilder.command().clear();
            m_procBuilder.command().addAll(rejoinCmdLnStr);
            Process proc = m_procBuilder.start();
            start = System.currentTimeMillis();

            
            
            
            String testoutputdir = rejoinCmdLn.buildDir() + File.separator + "testoutput";
            
            File dir = new File(testoutputdir);
            if (dir.exists()) {
                assert(dir.isDirectory());
            }
            else {
                boolean status = dir.mkdirs();
                assert(status);
            }

            ptf = new PipeToFile(
                    testoutputdir +
                    File.separator +
                    "LC-" +
                    getFileName() + "-" +
                    hostId + "-" +
                    "idx" + String.valueOf(perLocalClusterExtProcessIndex++) +
                    ".rejoined.txt",
                    proc.getInputStream(),
                    PipeToFile.m_rejoinToken, true, proc);
            synchronized (this) {
                m_pipes.set(hostId, ptf);
                
                m_cluster.set(hostId, proc);
                m_cmdLines.set(hostId, rejoinCmdLn);
            }
            Thread t = new Thread(ptf);
            t.setName("ClusterPipe:" + String.valueOf(hostId));
            t.start();
        }
        catch (IOException ex) {
            log.error("Failed to start recovering cluster process:" + ex.getMessage(), ex);
            assert (false);
        }

        return waitOnPTFReady(ptf, logtime, startTime, start, hostId);
    }

    
    private boolean waitOnPTFReady(PipeToFile ptf, boolean logtime, long startTime, long start, int hostId) {
        
        synchronized (ptf) {
            if (logtime) System.out.println("********** pre witness: " + (System.currentTimeMillis() - startTime) + " ms");
            while (ptf.m_witnessedReady.get() != true) {
                
                if (ptf.m_eof.get()) {
                    System.out.println("PipeToFile: Reported EOF");
                    break;
                }
                
                if (isProcessDead(ptf.getProcess())) {
                    System.out.println("PipeToFile: Reported Dead Process");
                    break;
                }
                try {
                    
                    ptf.wait(1000);
                }
                catch (InterruptedException ex) {
                    log.error(ex.toString(), ex);
                }
            }
        }
        if (ptf.m_witnessedReady.get()) {
            long finish = System.currentTimeMillis();
            log.info("Took " + (finish - start) +
                     " milliseconds, time from init was " + (finish - ptf.m_initTime));
            return true;
        } else {
            log.info("Recovering process exited before recovery completed");
            try {
                silentKillSingleHost(hostId, true);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return false;
        }
    }

    @Override
    synchronized public void shutDown() throws InterruptedException {
        
        
        

        try {
            if (m_localServer != null) {
                m_localServer.shutdown();
            }
        }
        catch (Exception e) {
            log.error("Failure to shutdown LocalCluster's in-process VoltDB server.", e);
        }
        finally {
            m_running = false;
        }
        shutDownExternal();
    }

    public void killSingleHost(int hostNum) throws InterruptedException
    {
        log.info("Killing " + hostNum);
        if (hostNum == 0 && m_localServer != null) {
            m_localServer.shutdown();
        }
        else {
            silentKillSingleHost(hostNum, false);
        }
    }

    private void silentKillSingleHost(int hostNum, boolean forceKillEEProcs) throws InterruptedException {
        Process proc = null;
        
        EEProcess eeProc = null;
        PipeToFile ptf;
        synchronized (this) {
           proc = m_cluster.get(hostNum);
           
           m_cluster.set(hostNum, null);
           ptf = m_pipes.get(hostNum);
           m_pipes.set(hostNum, null);
           if (m_eeProcs.size() > hostNum) {
               eeProc = m_eeProcs.get(hostNum);
           }
        }

        if (ptf != null && ptf.m_filename != null) {
            
        }
        if (proc != null) {
            proc.destroy();
            proc.waitFor();
        }

        
        
        

        if (eeProc != null) {
            if (forceKillEEProcs) {
                eeProc.destroy();
            }
            eeProc.waitForShutdown();
        }
    }

    public void shutDownExternal() throws InterruptedException {
        shutDownExternal(false);
    }

    public synchronized void shutDownExternal(boolean forceKillEEProcs)
    {
        if (m_cluster != null) {
            
            for (Process proc : m_cluster) {
                if (proc == null)
                    continue;
                proc.destroy();
            }

            
            for (Process proc : m_cluster) {
                if (proc == null)
                    continue;
                int retval = 0;
                try {
                    retval = proc.waitFor();
                }
                catch (InterruptedException e) {
                    log.error("Unable to wait for Localcluster process to die: " + proc.toString(), e);
                }
                
                if (retval != 0 && retval != 143)
                {
                    log.error("External VoltDB process terminated abnormally with return: " + retval);
                }
            }
        }

        if (m_cluster != null) m_cluster.clear();

        for (EEProcess proc : m_eeProcs) {
            try {
                proc.waitForShutdown();
            } catch (InterruptedException e) {
                log.error("Unable to wait for EEProcess to die: " + proc.toString(), e);
            }
        }

        if (templateCmdLine.target() == BackendTarget.NATIVE_EE_VALGRIND_IPC) {
            if (!EEProcess.m_valgrindErrors.isEmpty()) {
                String failString = "";
                for (final String error : EEProcess.m_valgrindErrors) {
                    failString = failString + "\n" + error;
                }
                org.junit.Assert.fail(failString);
            }
        }

        m_eeProcs.clear();
    }

    @Override
    public String getListenerAddress(int hostId) {
        if (!m_running) {
            return null;
        }
        for (int i = 0; i < m_cmdLines.size(); i++) {
            CommandLine cl = m_cmdLines.get(i);
            String hostIdStr = cl.getJavaProperty(clusterHostIdProperty);

            if (hostIdStr.equals(String.valueOf(hostId))) {
                Process p = m_cluster.get(i);
                
                if ((p != null) || (i == 0 && m_hasLocalServer)) {
                    return "localhost:" + cl.m_port;
                }
            }
        }
        return null;
    }

    @Override
    public List<String> getListenerAddresses() {
        if (!m_running) {
            return null;
        }
        ArrayList<String> listeners = new ArrayList<String>();
        for (int i = 0; i < m_cmdLines.size(); i++) {
            CommandLine cl = m_cmdLines.get(i);
            Process p = m_cluster.get(i);
            
            if ((p != null) || (i == 0 && m_hasLocalServer)) {
                listeners.add("localhost:" + cl.m_port);
            }
        }
        return listeners;
    }

    @Override
    public String getName() {
        String prefix = "localCluster";
        if (m_failureState == FailureState.ONE_FAILURE)
            prefix += "OneFail";
        if (m_failureState == FailureState.ONE_RECOVERING)
            prefix += "OneRecov";
        return prefix +
            "-" + String.valueOf(m_siteCount) +
            "-" + String.valueOf(m_hostCount) +
            "-" + templateCmdLine.target().display.toUpperCase();
    }

    String getFileName() {
        String prefix = m_callingClassName + "-" + m_callingMethodName;
        if (m_failureState == FailureState.ONE_FAILURE)
            prefix += "-OneFail";
        if (m_failureState == FailureState.ONE_RECOVERING)
            prefix += "-OneRecov";
        return prefix +
            "-" + String.valueOf(m_siteCount) +
            "-" + String.valueOf(m_hostCount) +
            "-" + templateCmdLine.target().display.toUpperCase();
    }

    @Override
    public int getNodeCount()
    {
        return m_hostCount;
    }

    public boolean areAllNonLocalProcessesDead() {
        for (Process proc : m_cluster){
            try {
                if (proc != null) {
                    proc.exitValue();
                }
            }
            catch (IllegalThreadStateException ex) {
                return false;
            }
        }
        return true;
    }

    public int getLiveNodeCount()
    {
        int count = 0;
        if (m_hasLocalServer)
        {
            count++;
        }

        if (m_cluster != null)
        {
            for (Process proc : m_cluster)
            {
                try
                {
                    if (proc != null)
                    {
                        proc.exitValue();
                    }
                }
                catch (IllegalThreadStateException ex)
                {
                    
                    count++;
                }
            }
        }

        return count;
    }

    public int getBlessedPartitionDetectionProcId() {
        int currMin = Integer.MAX_VALUE;
        int currMinIdx = 0;
        for (int i = 0; i < m_pipes.size(); i++) {
            PipeToFile p = m_pipes.get(i);
            System.out.println("Index " + i + " had hostid: " + p.getHostId());
            if (p.getHostId() < currMin) {
                currMin = p.getHostId();
                currMinIdx = i;
                System.out.println("Setting index: " + i + " to blessed.");
            }
        }
        return currMinIdx;
    }

    @Override
    public void finalize() throws Throwable {
        try {
            shutDownExternal();
        }
        finally {
            super.finalize();
        }
    }

    class ShutDownHookThread implements Runnable {
        @Override
        public void run() {
            shutDownExternal(true);
        }
    }

    @Override
    public boolean isHSQL() {
        return templateCmdLine.target() == BackendTarget.HSQLDB_BACKEND;
    }

    public void setOverridesForHotfix(String[] versions, String[] regexOverrides, String[] buildStrings) {
        assert(buildStrings != null);

        m_buildStringOverrides = buildStrings;
        setOverridesForHotfix(versions, regexOverrides);
    }

    public void setOverridesForHotfix(String[] versions, String[] regexOverrides) {
        assert(versions != null);
        assert(regexOverrides != null);
        assert(versions.length == regexOverrides.length);

        m_versionOverrides = versions;
        m_versionCheckRegexOverrides = regexOverrides;
    }

    @Override
    public void setMaxHeap(int heap) {
        templateCmdLine.setMaxHeap(heap);
    }

    public String getPathToDeployment() {
        return templateCmdLine.pathToDeployment();
    }

    public String zkinterface(int hostId) {
        return m_cmdLines.get(hostId).zkinterface();
    }

    public int drAgentStartPort(int hostId) {
        return m_cmdLines.get(hostId).drAgentStartPort();
    }

    public int internalPort(int hostId) {
        return m_cmdLines.get(hostId).internalPort();
    }

    public int port(int hostId) {
        return m_cmdLines.get(hostId).port();
    }

    public int adminPort(int hostId) {
        return m_cmdLines.get(hostId).adminPort();
    }

    public void setPortsFromConfig(int hostId, VoltDB.Configuration config) {
        CommandLine cl = m_cmdLines.get(hostId);
        assert(cl != null);
        cl.m_port = config.m_port;
        cl.m_adminPort = config.m_adminPort;
        cl.m_zkInterface = config.m_zkInterface;
        cl.m_internalPort = config.m_internalPort;
        cl.m_leader = config.m_leader;
    }

    public static boolean isMemcheckDefined() {
        final String buildType = System.getenv().get("BUILD");
        if (buildType == null) {
            return false;
        }
        return buildType.toLowerCase().startsWith("memcheck");
    }

    @Override
    public boolean isValgrind() {
        return templateCmdLine.m_backend == BackendTarget.NATIVE_EE_VALGRIND_IPC;
    }

    @Override
    public void createDirectory(File path) throws IOException {
        for (File root : m_subRoots) {
            File actualPath = new File(root, path.getPath());
            if (!actualPath.mkdirs()) {
                throw new IOException();
            }
        }
    }

    @Override
    public void deleteDirectory(File path) throws IOException {
        for (File root : m_subRoots) {
            File actualPath = new File(root, path.getPath());
            VoltFile.recursivelyDelete(actualPath);
        }
    }

    @Override
    public ArrayList<File> listFiles(File path) throws IOException {
        ArrayList<File> files = new ArrayList<File>();
        for (File root : m_subRoots) {
            File actualPath = new File(root, path.getPath());
            for (File f : actualPath.listFiles()) {
                files.add(f);
            }
        }
        return files;
    }

    @Override
    public File[] getPathInSubroots(File path) throws IOException {
        File retval[] = new File[m_subRoots.size()];
        for (int ii = 0; ii < m_subRoots.size(); ii++) {
            retval[ii] = new File(m_subRoots.get(ii), path.getPath());
        }
        return retval;
    }

    
    public boolean isExpectedToCrash() {
        return m_expectedToCrash;
    }

    
    public void setExpectedToCrash(boolean expectedToCrash) {
        this.m_expectedToCrash = expectedToCrash;
    }

    
    public boolean isExpectedToInitialize() {
        return m_expectedToInitialize;
    }

    
    public void setExpectedToInitialize(boolean expectedToInitialize) {
        this.m_expectedToInitialize = expectedToInitialize;
    }

    
    public void setOutputWatcher(OutputWatcher watcher) {
        for (PipeToFile pipe : m_pipes) {
            if (pipe != null) {
                pipe.setWatcher(watcher);
            }
        }
    }

    @Override
    public int getLogicalPartitionCount() {
        return (m_siteCount * m_hostCount) / (m_kfactor + 1);
    }
}

<code block>


package org.voltdb.regressionsuites;

import java.io.IOException;
import java.net.ConnectException;
import java.nio.channels.SocketChannel;
import java.util.ArrayList;
import java.util.List;
import java.util.Random;
import java.util.regex.Pattern;

import junit.framework.TestCase;

import org.voltdb.VoltDB;
import org.voltdb.VoltTable;
import org.voltdb.VoltType;
import org.voltdb.client.Client;
import org.voltdb.client.ClientAuthHashScheme;
import org.voltdb.client.ClientConfig;
import org.voltdb.client.ClientConfigForTest;
import org.voltdb.client.ClientFactory;
import org.voltdb.client.ConnectionUtil;
import org.voltdb.client.ProcCallException;
import org.voltdb.common.Constants;

import com.google_voltpatches.common.net.HostAndPort;


public class RegressionSuite extends TestCase {

    protected VoltServerConfig m_config;
    protected String m_username = "default";
    protected String m_password = "password";
    private final ArrayList<Client> m_clients = new ArrayList<Client>();
    private final ArrayList<SocketChannel> m_clientChannels = new ArrayList<SocketChannel>();
    protected final String m_methodName;

    
    public RegressionSuite(final String name) {
        super(name);
        m_methodName = name;
    }

    
    @Override
    public void setUp() throws Exception {
        
        m_config.setCallingMethodName(m_methodName);
        m_config.startUp(true);
    }

    
    @Override
    public void tearDown() throws Exception {
        m_config.shutDown();
        for (final Client c : m_clients) {
            c.close();
        }
        synchronized (m_clientChannels) {
            for (final SocketChannel sc : m_clientChannels) {
                try {
                    ConnectionUtil.closeConnection(sc);
                } catch (final IOException e) {
                    e.printStackTrace();
                }
            }
            m_clientChannels.clear();
        }
        m_clients.clear();
    }

    
    public boolean isHSQL() {
        return m_config.isHSQL();
    }

    
    public int getLogicalPartitionCount() {
        return m_config.getLogicalPartitionCount();
    }

    
    public boolean isValgrind() {
        return m_config.isValgrind();
    }

    public boolean isLocalCluster() {
        return m_config instanceof LocalCluster;
    }

    
    public final VoltServerConfig getServerConfig() {
        return m_config;
    }

    public Client getClient() throws IOException {
        return getClient(1000 * 60 * 10, ClientAuthHashScheme.HASH_SHA256); 
    }

    public Client getClient(ClientAuthHashScheme scheme) throws IOException {
        return getClient(1000 * 60 * 10, scheme); 
    }

    public Client getClientToHostId(int hostId) throws IOException {
        return getClientToHostId(hostId, 1000 * 60 * 10); 
    }

    public Client getFullyConnectedClient() throws IOException {
        return getFullyConnectedClient(1000 * 60 * 10); 
    }

    
    public Client getClient(long timeout) throws IOException {
        return getClient(timeout, ClientAuthHashScheme.HASH_SHA256);
    }

    
    public Client getClient(long timeout, ClientAuthHashScheme scheme) throws IOException {
        final List<String> listeners = m_config.getListenerAddresses();
        final Random r = new Random();
        String listener = listeners.get(r.nextInt(listeners.size()));
        ClientConfig config = new ClientConfigForTest(m_username, m_password, scheme);
        config.setConnectionResponseTimeout(timeout);
        config.setProcedureCallTimeout(timeout);
        final Client client = ClientFactory.createClient(config);
        
        try {
            client.createConnection(listener);
        }
        
        catch (ConnectException e) {
            listener = listeners.get(r.nextInt(listeners.size()));
            client.createConnection(listener);
        }
        m_clients.add(client);
        return client;
    }

    
    public Client getClientSha1(long timeout) throws IOException {
        final List<String> listeners = m_config.getListenerAddresses();
        final Random r = new Random();
        String listener = listeners.get(r.nextInt(listeners.size()));
        ClientConfig config = new ClientConfigForTest(m_username, m_password, ClientAuthHashScheme.HASH_SHA1);
        config.setConnectionResponseTimeout(timeout);
        config.setProcedureCallTimeout(timeout);
        final Client client = ClientFactory.createClient(config);
        
        try {
            client.createConnection(listener);
        }
        
        catch (ConnectException e) {
            listener = listeners.get(r.nextInt(listeners.size()));
            client.createConnection(listener);
        }
        m_clients.add(client);
        return client;
    }

    
    public Client getClientToHostId(int hostId, long timeout) throws IOException {
        final String listener = m_config.getListenerAddress(hostId);
        ClientConfig config = new ClientConfigForTest(m_username, m_password);
        config.setConnectionResponseTimeout(timeout);
        config.setProcedureCallTimeout(timeout);
        final Client client = ClientFactory.createClient(config);
        try {
            client.createConnection(listener);
        }
        
        catch (ConnectException e) {
            client.createConnection(listener);
        }
        m_clients.add(client);
        return client;
    }

    public Client getFullyConnectedClient(long timeout) throws IOException {
        final List<String> listeners = m_config.getListenerAddresses();
        final Random r = new Random();
        ClientConfig config = new ClientConfigForTest(m_username, m_password);
        config.setConnectionResponseTimeout(timeout);
        config.setProcedureCallTimeout(timeout);
        final Client client = ClientFactory.createClient(config);
        for (String listener : listeners) {
            
            try {
                client.createConnection(listener);
            }
            
            catch (ConnectException e) {
                listener = listeners.get(r.nextInt(listeners.size()));
                client.createConnection(listener);
            }
        }
        m_clients.add(client);
        return client;
    }

    
    public void releaseClient(Client c) throws IOException, InterruptedException {
        boolean removed = m_clients.remove(c);
        assert(removed);
        c.close();
    }

    
    public SocketChannel getClientChannel() throws IOException {
        return getClientChannel(false);
    }
    public SocketChannel getClientChannel(final boolean noTearDown) throws IOException {
        final List<String> listeners = m_config.getListenerAddresses();
        final Random r = new Random();
        final String listener = listeners.get(r.nextInt(listeners.size()));
        byte[] hashedPassword = ConnectionUtil.getHashedPassword(m_password);
        HostAndPort hNp = HostAndPort.fromString(listener);
        int port = Constants.DEFAULT_PORT;
        if (hNp.hasPort()) {
            port = hNp.getPort();
        }
        final SocketChannel channel = (SocketChannel)
            ConnectionUtil.getAuthenticatedConnection(
                    hNp.getHostText(), m_username, hashedPassword, port, null, ClientAuthHashScheme.getByUnencodedLength(hashedPassword.length))[0];
        channel.configureBlocking(true);
        if (!noTearDown) {
            synchronized (m_clientChannels) {
                m_clientChannels.add(channel);
            }
        }
        return channel;
    }

    
    void setConfig(final VoltServerConfig config) {
        m_config = config;
    }


    @Override
    public String getName() {
        
        return super.getName() + "-" + m_config.getName();
    }

    
    public int port(int hostId) {
        return isLocalCluster() ? ((LocalCluster)m_config).port(hostId) : VoltDB.DEFAULT_PORT+hostId;
    }

    
    public int adminPort(int hostId) {
        return isLocalCluster() ? ((LocalCluster)m_config).adminPort(hostId) : VoltDB.DEFAULT_ADMIN_PORT+hostId;
    }

    
    public int internalPort(int hostId) {
        return isLocalCluster() ? ((LocalCluster)m_config).internalPort(hostId) : VoltDB.DEFAULT_INTERNAL_PORT+hostId;
    }

    static public void validateTableOfLongs(Client c, String sql, long[][] expected)
            throws Exception, IOException, ProcCallException {
        assertNotNull(expected);
        VoltTable vt = c.callProcedure("@AdHoc", sql).getResults()[0];
        validateTableOfLongs(vt, expected);
    }

    static public void validateTableOfScalarLongs(VoltTable vt, long[] expected) {
        assertNotNull(expected);
        assertEquals("Different number of rows! ", expected.length, vt.getRowCount());
        int len = expected.length;
        for (int i=0; i < len; i++) {
            validateRowOfLongs(vt, new long[] {expected[i]});
        }
    }

    static public void validateTableOfScalarLongs(Client client, String sql, long[] expected) throws Exception {
        assertNotNull(expected);
        VoltTable vt = client.callProcedure("@AdHoc", sql).getResults()[0];
        validateTableOfScalarLongs(vt, expected);
    }

    static public void validateTableOfLongs(VoltTable vt, long[][] expected) {
        assertNotNull(expected);
        assertEquals("Wrong number of rows in table.  ",
                        expected.length, vt.getRowCount());
        int len = expected.length;
        for (int i=0; i < len; i++) {
            validateRowOfLongs("at row " + i + ", ", vt, expected[i]);
        }
    }

    static public void validateRowOfLongs(String messagePrefix, VoltTable vt, long [] expected) {
        int len = expected.length;
        assertTrue(vt.advanceRow());
        for (int i=0; i < len; i++) {
            long actual = -10000000;
            
            try {
                actual = vt.getLong(i);
            } catch (IllegalArgumentException ex) {
                try {
                    actual = (long) vt.getDouble(i);
                } catch (IllegalArgumentException newEx) {
                    try {
                        actual = vt.getTimestampAsLong(i);
                    } catch (IllegalArgumentException exTm) {
                        try {
                            actual = vt.getDecimalAsBigDecimal(i).longValueExact();
                        } catch (IllegalArgumentException newerEx) {
                            newerEx.printStackTrace();
                            fail();
                        }
                    } catch (ArithmeticException newestEx) {
                        newestEx.printStackTrace();
                        fail();
                    }
                }
            }

            String message = "at column " + i +", ";
            if (messagePrefix != null) {
                message = messagePrefix + message;
            }

            
            if (expected[i] != Long.MIN_VALUE) {
                assertEquals(message, expected[i], actual);
            } else {
                VoltType type = vt.getColumnType(i);
                assertEquals(message + "expected null: ", Long.parseLong(type.getNullValue().toString()), actual);
            }
        }
    }

    static public void validateRowOfLongs(VoltTable vt, long [] expected) {
        validateRowOfLongs(null, vt, expected);
    }

    static public void validateTableColumnOfScalarVarchar(VoltTable vt, String[] expected) {
        validateTableColumnOfScalarVarchar(vt, 0, expected);
    }

    static public void validateTableColumnOfScalarVarchar(VoltTable vt, int col, String[] expected) {
        assertNotNull(expected);
        assertEquals(expected.length, vt.getRowCount());
        int len = expected.length;
        for (int i=0; i < len; i++) {
            assertTrue(vt.advanceRow());
            if (expected[i] == null) {
                String actual = vt.getString(col);
                assertTrue(vt.wasNull());
                assertEquals(null, actual);
            } else {
                assertEquals(expected[i], vt.getString(col));
            }
        }
    }

    public void assertTablesAreEqual(String prefix, VoltTable expectedRows, VoltTable actualRows) {
        assertEquals(prefix + "column count mismatch.  Expected: " + expectedRows.getColumnCount() + " actual: " + actualRows.getColumnCount(),
                expectedRows.getColumnCount(), actualRows.getColumnCount());

        int i = 0;
        while(expectedRows.advanceRow()) {
            assertTrue(prefix + "too few actual rows; expected more than " + (i + 1), actualRows.advanceRow());

            for (int j = 0; j < actualRows.getColumnCount(); j++) {
                String columnName = actualRows.getColumnName(j);
                String colPrefix = prefix + "row " + i + ": column: " + columnName + ": ";
                VoltType actualTy = actualRows.getColumnType(j);
                VoltType expectedTy = expectedRows.getColumnType(j);
                assertEquals(colPrefix + "type mismatch", expectedTy, actualTy);

                Object expectedObj = expectedRows.get(j,  expectedTy);
                Object actualObj = expectedRows.get(j,  actualTy);
                assertEquals(colPrefix + "values not equal: expected: " + expectedObj + ", actual: " + actualObj,
                        expectedObj, actualObj);
            }

            i++;
        }
        assertFalse(prefix + "too many actual rows; expected only " + i, actualRows.advanceRow());
    }

    static public void verifyStmtFails(Client client, String stmt, String expectedPattern) throws IOException {
        verifyProcFails(client, expectedPattern, "@AdHoc", stmt);
    }

    static public void verifyAdHocFails(Client client, String expectedPattern, Object... args) throws IOException {
        verifyProcFails(client, expectedPattern, "@AdHoc", args);
    }

    static public void verifyProcFails(Client client, String expectedPattern, String storedProc, Object... args) throws IOException {

        String what;
        if (storedProc.compareTo("@AdHoc") == 0) {
            what = "the statement \"" + args[0] + "\"";
        }
        else {
            what = "the stored procedure \"" + storedProc + "\"";
        }

        try {
            client.callProcedure(storedProc, args);
        }
        catch (ProcCallException pce) {
            String msg = pce.getMessage();
            String diagnostic = "Expected " + what + " to throw an exception matching the pattern \"" +
                    expectedPattern + "\", but instead it threw an exception containing \"" + msg + "\".";
            Pattern pattern = Pattern.compile(expectedPattern, Pattern.MULTILINE);
            assertTrue(diagnostic, pattern.matcher(msg).find());
            return;
        }

        String diagnostic = "Expected " + what + " to throw an exception matching the pattern \"" +
                expectedPattern + "\", but instead it threw nothing.";
        fail(diagnostic);
    }


    
    
    
    
    static public void validateSchema(VoltTable result, VoltTable expected)
    {
        assertEquals(expected.getColumnCount(), result.getColumnCount());
        for (int i = 0; i < result.getColumnCount(); i++) {
            assertEquals("Failed name column: " + i, expected.getColumnName(i), result.getColumnName(i));
            assertEquals("Failed type column: " + i, expected.getColumnType(i), result.getColumnType(i));
        }
    }

    static public void validStatisticsForTableLimit(Client client, String tableName, long limit) throws Exception {
        validStatisticsForTableLimitAndPercentage(client, tableName, limit, -1);
    }

    static public void validStatisticsForTableLimitAndPercentage(Client client, String tableName, long limit, long percentage) throws Exception {
        long start = System.currentTimeMillis();
        while (true) {
            long lastLimit =-1, lastPercentage = -1;
            Thread.sleep(1000);
            if (System.currentTimeMillis() - start > 10000) {
                String percentageStr = "";
                if (percentage >= 0) {
                    percentageStr = ", last seen percentage: " + lastPercentage;
                }
                fail("Took too long or have wrong answers: last seen limit: " + lastLimit + percentageStr);
            }

            VoltTable[] results = client.callProcedure("@Statistics", "TABLE", 0).getResults();
            for (VoltTable t: results) { System.out.println(t.toString()); }
            if (results[0].getRowCount() == 0) continue;

            boolean foundTargetTuple = false;
            boolean limitExpected = false;
            boolean percentageExpected = percentage < 0 ? true: false;

            for (VoltTable vt: results) {
                while(vt.advanceRow()) {
                    String name = vt.getString("TABLE_NAME");
                    if (tableName.equals(name)) {
                        foundTargetTuple = true;
                        lastLimit = vt.getLong("TUPLE_LIMIT");
                        if (limit == lastLimit) {
                            limitExpected = true;
                        }
                        if (percentageExpected || percentage == (lastPercentage = vt.getLong("PERCENT_FULL")) ) {
                            percentageExpected = true;
                        }

                        if (limitExpected && percentageExpected) return;
                        break;
                    }
                }
                if (foundTargetTuple) break;
            }
        }
    }

    static public void checkDeploymentPropertyValue(Client client, String key, String value)
            throws IOException, ProcCallException, InterruptedException {
        boolean found = false;

        VoltTable result = client.callProcedure("@SystemInformation", "DEPLOYMENT").getResults()[0];
        while (result.advanceRow()) {
            if (result.getString("PROPERTY").equalsIgnoreCase(key)) {
                found = true;
                assertEquals(value, result.getString("VALUE"));
                break;
            }
        }
        assertTrue(found);
    }

    static public void checkQueryPlan(Client client, String query, String...patterns) throws Exception {
        VoltTable vt;
        assert(patterns.length >= 1);

        vt = client.callProcedure("@Explain", query).getResults()[0];
        String vtStr = vt.toString();

        for (String pattern : patterns) {
            assertTrue(vtStr.contains(pattern));
        }
    }
}

<code block>



package org.hsqldb_voltpatches;

import java.math.BigDecimal;
import java.math.BigInteger;

import org.hsqldb_voltpatches.lib.HashSet;
import org.hsqldb_voltpatches.store.ValuePool;
import org.hsqldb_voltpatches.types.DTIType;
import org.hsqldb_voltpatches.types.IntervalMonthData;
import org.hsqldb_voltpatches.types.IntervalSecondData;
import org.hsqldb_voltpatches.types.IntervalType;
import org.hsqldb_voltpatches.types.NumberType;
import org.hsqldb_voltpatches.types.Type;

import java.io.Serializable;


public class SetFunction implements Serializable {

    private HashSet distinctValues;
    private boolean isDistinct;

    
    private int  setType;
    private int  dataType;
    private Type type;

    
    private int count;

    
    private boolean    hasNull;
    private boolean    every = true;
    private boolean    some  = false;
    private long       currentLong;
    private double     currentDouble;
    private BigDecimal currentBigDecimal;
    private Object     currentValue;

    SetFunction(int setType, Type type, boolean isDistinct) {

        this.setType = setType;
        this.type    = type;

        if (isDistinct) {
            this.isDistinct = true;
            distinctValues  = new HashSet();
        }

        if (setType == OpTypes.VAR_SAMP || setType == OpTypes.STDDEV_SAMP) {
            this.sample = true;
        }

        if (type != null) {
            dataType = type.typeCode;

            if (type.isIntervalType()) {
                dataType = Types.SQL_INTERVAL;
            }
        }
    }

    void add(Session session, Object item) {

        if (item == null) {
            hasNull = true;

            session.addWarning(Error.error(ErrorCode.W_01003));

            return;
        }

        if (isDistinct && !distinctValues.add(item)) {
            return;
        }

        count++;

        switch (setType) {

            case OpTypes.COUNT :
                return;
            
            case OpTypes.APPROX_COUNT_DISTINCT:
                
                throw Error.error(ErrorCode.X_42581, Tokens.T_APPROX_COUNT_DISTINCT);
            
            case OpTypes.AVG :
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        currentLong += ((Number) item).intValue();

                        return;

                    case Types.SQL_INTERVAL :
                        if (item instanceof IntervalSecondData) {
                            addLong(((IntervalSecondData) item).units);

                            currentLong += ((IntervalSecondData) item).nanos;

                            if (Math.abs(currentLong)
                                    >= DTIType.nanoScaleFactors[0]) {
                                addLong(currentLong
                                        / DTIType.nanoScaleFactors[0]);

                                currentLong %= DTIType.nanoScaleFactors[0];
                            }
                        } else if (item instanceof IntervalMonthData) {
                            addLong(((IntervalMonthData) item).units);
                        }

                        return;

                    case Types.SQL_BIGINT :
                        addLong(((Number) item).longValue());

                        return;

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        currentDouble += ((Number) item).doubleValue();

                        return;

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        if (currentBigDecimal == null) {
                            currentBigDecimal = (BigDecimal) item;
                        } else {
                            currentBigDecimal =
                                currentBigDecimal.add((BigDecimal) item);
                        }

                        return;

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.MIN : {
                if (currentValue == null) {
                    currentValue = item;

                    return;
                }

                if (type.compare(currentValue, item) > 0) {
                    currentValue = item;
                }

                return;
            }
            case OpTypes.MAX : {
                if (currentValue == null) {
                    currentValue = item;

                    return;
                }

                if (type.compare(currentValue, item) < 0) {
                    currentValue = item;
                }

                return;
            }
            case OpTypes.EVERY :
                if (!(item instanceof Boolean)) {
                    throw Error.error(ErrorCode.X_42565);
                }

                every = every && ((Boolean) item).booleanValue();

                return;

            case OpTypes.SOME :
                if (!(item instanceof Boolean)) {
                    throw Error.error(ErrorCode.X_42565);
                }

                some = some || ((Boolean) item).booleanValue();

                return;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                addDataPoint((Number) item);

                return;

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }
    }

    Object getValue() {

        if (setType == OpTypes.COUNT) {
            return ValuePool.getInt(count);
        }

        
        if (setType == OpTypes.APPROX_COUNT_DISTINCT) {
            throw Error.error(ErrorCode.X_42581, Tokens.T_APPROX_COUNT_DISTINCT);
        }
        
        if (count == 0) {
            return null;
        }

        switch (setType) {

            case OpTypes.AVG : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return new Long(currentLong / count);

                    case Types.SQL_BIGINT : {
                        long value = getLongSum().divide(
                            BigInteger.valueOf(count)).longValue();

                        return new Long(value);
                    }
                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return new Double(currentDouble / count);

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return currentBigDecimal.divide(new BigDecimal(count),
                                                        BigDecimal.ROUND_DOWN);

                    case Types.SQL_INTERVAL : {
                        BigInteger bi =
                            getLongSum().divide(BigInteger.valueOf(count));

                        if (!NumberType.isInLongLimits(bi)) {
                            throw Error.error(ErrorCode.X_22015);
                        }

                        if (((IntervalType) type).isDaySecondIntervalType()) {
                            return new IntervalSecondData(bi.longValue(),
                                                          currentLong,
                                                          (IntervalType) type,
                                                          true);
                        } else {
                            return IntervalMonthData.newIntervalMonth(
                                bi.longValue(), (IntervalType) type);
                        }
                    }
                    default :
                        throw Error.runtimeError(ErrorCode.U_S0500,
                                                 "SetFunction");
                }
            }
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return new Long(currentLong);

                    case Types.SQL_BIGINT :
                        return new BigDecimal(getLongSum());

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return new Double(currentDouble);

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return currentBigDecimal;

                    case Types.SQL_INTERVAL : {
                        BigInteger bi = getLongSum();

                        if (!NumberType.isInLongLimits(bi)) {
                            throw Error.error(ErrorCode.X_22015);
                        }

                        if (((IntervalType) type).isDaySecondIntervalType()) {
                            return new IntervalSecondData(bi.longValue(),
                                                          currentLong,
                                                          (IntervalType) type,
                                                          true);
                        } else {
                            return IntervalMonthData.newIntervalMonth(
                                bi.longValue(), (IntervalType) type);
                        }
                    }
                    default :
                        throw Error.runtimeError(ErrorCode.U_S0500,
                                                 "SetFunction");
                }
            }
            case OpTypes.MIN :
            case OpTypes.MAX :
                return currentValue;

            case OpTypes.EVERY :
                return every ? Boolean.TRUE
                             : Boolean.FALSE;

            case OpTypes.SOME :
                return some ? Boolean.TRUE
                            : Boolean.FALSE;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
                return getStdDev();

            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                return getVariance();

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }
    }

    
    static Type getType(int setType, Type type) {

        if (setType == OpTypes.COUNT) {
            return Type.SQL_INTEGER;
        }

        
        
        
        
        
        
        if (type == null) {
            throw Error.error(ErrorCode.U_S0500);
        }
        
        int dataType = type.isIntervalType() ? Types.SQL_INTERVAL
                                             : type.typeCode;

        switch (setType) {

            case OpTypes.AVG : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                    case Types.SQL_BIGINT :
                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                    case Types.SQL_INTERVAL :
                        return type;

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return Type.SQL_BIGINT;

                    case Types.SQL_BIGINT :
                        return Type.SQL_DECIMAL_BIGINT_SQR;

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return Type.SQL_DOUBLE;

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return Type.getType(type.typeCode, 0,
                                            type.precision * 2, type.scale);

                    case Types.SQL_INTERVAL :
                        return IntervalType.newIntervalType(
                            type.typeCode, DTIType.maxIntervalPrecision,
                            type.scale);

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.MIN :
            case OpTypes.MAX :
                return type;

            case OpTypes.EVERY :
            case OpTypes.SOME :
                if (type.isBooleanType()) {
                    return Type.SQL_BOOLEAN;
                }
                break;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                if (type.isNumberType()) {
                    return Type.SQL_DOUBLE;
                }
                break;

            
            case OpTypes.APPROX_COUNT_DISTINCT :
                switch (dataType) {
                case Types.TINYINT :
                case Types.SQL_SMALLINT :
                case Types.SQL_INTEGER :
                case Types.SQL_BIGINT :
                case Types.SQL_DOUBLE :
                case Types.SQL_DECIMAL :
                case Types.SQL_TIMESTAMP :
                    return Type.SQL_DOUBLE;
                default:
                    throw Error.error(ErrorCode.X_42565);
                }
            
            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }

        throw Error.error(ErrorCode.X_42565);
    }

    

    
    static final BigInteger multiplier =
        BigInteger.valueOf(0x0000000100000000L);


    long hi;
    long lo;

    void addLong(long value) {

        if (value == 0) {}
        else if (value > 0) {
            hi += value >> 32;
            lo += value & 0x00000000ffffffffL;
        } else {
            if (value == Long.MIN_VALUE) {
                hi -= 0x000000080000000L;
            } else {
                long temp = ~value + 1;

                hi -= temp >> 32;
                lo -= temp & 0x00000000ffffffffL;
            }
        }


    }

    BigInteger getLongSum() {

        BigInteger biglo  = BigInteger.valueOf(lo);
        BigInteger bighi  = BigInteger.valueOf(hi);
        BigInteger result = (bighi.multiply(multiplier)).add(biglo);


        return result;
    }

    
    
    
    private double  sk;
    private double  vk;
    private long    n;
    private boolean initialized;
    private boolean sample;

    private void addDataPoint(Number x) {    

        double xi;
        double xsi;
        long   nm1;

        if (x == null) {
            return;
        }

        xi = x.doubleValue();

        if (!initialized) {
            n           = 1;
            sk          = xi;
            vk          = 0.0;
            initialized = true;

            return;
        }

        n++;

        nm1 = (n - 1);
        xsi = (sk - (xi * nm1));
        vk  += ((xsi * xsi) / n) / nm1;
        sk  += xi;
    }

    private Number getVariance() {

        if (!initialized) {
            return null;
        }

        return sample ? (n == 1) ? null    
                                 : new Double(vk / (double) (n - 1))
                      : new Double(vk / (double) (n));
    }

    private Number getStdDev() {

        if (!initialized) {
            return null;
        }

        return sample ? (n == 1) ? null    
                                 : new Double(Math.sqrt(vk / (double) (n - 1)))
                      : new Double(Math.sqrt(vk / (double) (n)));
    }

    
}

<code block>


package org.voltdb.regressionsuites;

import java.io.IOException;
import java.math.BigDecimal;
import java.util.Random;

import org.voltdb.BackendTarget;
import org.voltdb.VoltTable;
import org.voltdb.client.Client;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.types.TimestampType;

public class TestApproxCountDistinctSuite extends RegressionSuite {

    private static final double ALLOWED_PERCENT_ERROR = 1.5;

    private static final String COLUMN_NAMES[] = {
            "bi",
            "ii",
            "si",
            "ti",
            "ff",
            "dd",
            "ts"
    };

    private static final String TABLE_NAMES[] = {"r", "p"};

    private static long getNormalValue(Random r, double magnitude, long min, long max) {
        double d;
        do {
            d = r.nextGaussian() * magnitude;
        } while (d > max || d <= min);

        return (long) d;
    }

    private static BigDecimal getNormalDecimalValue(Random r, double magnitude) {
        double d;
        do {
            d = r.nextGaussian() * magnitude;
        } while (d > (magnitude * 2) || d <= (-magnitude * 2));

        return new BigDecimal(String.format("%.12f", d));
    }

    private static void fillTable(Client client, String tbl) throws Exception {
        Random r = new Random(777);

        
        for (int i = 0; i < 1084; ++i) {

            
            
            if (i % 13 == 0) {
                client.callProcedure(tbl + ".Insert", i,
                        null, null, null, null, null, null, null);
            }
            else {
                
                final long baseTs = 1437589323966000L; 
                client.callProcedure(tbl + ".Insert",
                        i,    
                        getNormalValue(r, 1000, Long.MIN_VALUE, Long.MAX_VALUE),
                        getNormalValue(r, 1000, Integer.MIN_VALUE, Integer.MAX_VALUE),
                        getNormalValue(r, 1000, Short.MIN_VALUE, Short.MAX_VALUE),
                        getNormalValue(r, 100, Byte.MIN_VALUE, Byte.MAX_VALUE),
                        r.nextGaussian(), 
                        getNormalDecimalValue(r, 1000000000), 
                        new TimestampType(baseTs + getNormalValue(r, 10000, Short.MIN_VALUE, Short.MAX_VALUE)));
            }
        }
    }

    private static void assertEstimateWithin(String col, long exact, double estimate, double maxError) {
        double percentError = Math.abs(((exact - estimate) / exact) * 100.0);

        

        assertTrue("Estimate for distinct values in " + col,
                percentError < maxError);
    }

    
    private static void assertEstimatesAreWithin(String col, VoltTable exactTable, VoltTable estimateTable, double maxError) {
        final int whichCol = exactTable.getColumnCount() - 1;

        while(estimateTable.advanceRow()) {
            assertTrue(exactTable.advanceRow());

            assertEstimateWithin(col, exactTable.getLong(whichCol), estimateTable.getDouble(whichCol), maxError);
        }

        assertFalse(exactTable.advanceRow());
    }

    public void testAsTableAgg() throws Exception
    {
        Client client = getClient();

        
        
        
        
        
        
        double expectedEstimates[] = {
                859.613,
                862.6527,
                870.759,
                247.4666,
                997.5537,
                1001.615,
                983.3405
        };

        
        for (int colIdx = 0; colIdx < COLUMN_NAMES.length; ++colIdx) {
            for (int tblIdx = 0; tblIdx < TABLE_NAMES.length; ++tblIdx) {
                String tbl = TABLE_NAMES[tblIdx];
                String col = COLUMN_NAMES[colIdx];

                String approxStmt = String.format("select approx_count_distinct(%s) from %s", col, tbl);
                VoltTable vt = client.callProcedure("@AdHoc", approxStmt).getResults()[0];
                assertTrue(vt.advanceRow());
                assertEquals(0.0, vt.getDouble(0));
                assertFalse(vt.advanceRow());
            }
        }

        fillTable(client, "p");
        fillTable(client, "r");

        for (int tblIdx = 0; tblIdx < TABLE_NAMES.length; ++tblIdx) {
            for (int colIdx = 0; colIdx < COLUMN_NAMES.length; ++colIdx) {

                String tbl = TABLE_NAMES[tblIdx];
                String col = COLUMN_NAMES[colIdx];

                String approxStmt = String.format("select approx_count_distinct(%s) from %s", col, tbl);

                VoltTable vt = client.callProcedure("@AdHoc", approxStmt).getResults()[0];
                assertTrue(vt.advanceRow());
                double actualEstimate = vt.getDouble(0);
                assertEquals("Actual estimate not expected for column " + col,
                        expectedEstimates[colIdx], actualEstimate, 0.01);
                assertFalse(vt.advanceRow());

                
                String approxStmtNoNulls = String.format(
                        "select approx_count_distinct(%s) "
                        + "from %s "
                        + "where %s is not null", col, tbl, col);
                vt = client.callProcedure("@AdHoc", approxStmtNoNulls).getResults()[0];
                assertTrue(vt.advanceRow());
                double actualEstimateNoNulls = vt.getDouble(0);
                assertEquals(actualEstimate, actualEstimateNoNulls, 0.0);
                assertFalse(vt.advanceRow());

                
                String exactStmt = String.format("select count(distinct %s) from %s", col, tbl);

                vt = client.callProcedure("@AdHoc", exactStmt).getResults()[0];
                assertTrue(vt.advanceRow());
                long exact = vt.getLong(0);

                assertEstimateWithin(col, exact, actualEstimate, ALLOWED_PERCENT_ERROR);

                assertFalse(vt.advanceRow());
            }
        }
    }

    
    public void compareEstimateAndExact(Client client, String tables[], String columns[], String queryFormat) throws Exception
    {
        for (int tblIdx = 0; tblIdx < tables.length; ++tblIdx) {
            for (int colIdx = 0; colIdx < columns.length; ++colIdx) {
                String tbl = tables[tblIdx];
                String col = columns[colIdx];

                String approxStmt = String.format(queryFormat,
                        "approx_count_distinct(",
                        col, tbl);
                String exactStmt = String.format(queryFormat,
                        "count( distinct ",
                        col, tbl);

                VoltTable estimateTable = client.callProcedure("@AdHoc", approxStmt).getResults()[0];
                VoltTable exactTable = client.callProcedure("@AdHoc", exactStmt).getResults()[0];

                assertEstimatesAreWithin(col, exactTable, estimateTable, ALLOWED_PERCENT_ERROR);
            }
        }
    }

    public void testAsGroupByAgg() throws Exception
    {
        Client client = getClient();

        fillTable(client, "p");
        fillTable(client, "r");

        
        compareEstimateAndExact(client, TABLE_NAMES, COLUMN_NAMES,
                "select bitand(cast(pk as bigint), x'03') as pk_lobits, %s %s ) "
                + "from %s "
                + "group by pk_lobits "
                + "order by pk_lobits");

        
        
        
        compareEstimateAndExact(client, TABLE_NAMES, COLUMN_NAMES,
                "select "
                + "  bitand(cast(pk as bigint), x'03') as pk_lobits, "
                + "  count(distinct bi), "
                + "  %s %s ) "
                + "from %s "
                + "group by pk_lobits "
                + "order by pk_lobits");

        
        
        compareEstimateAndExact(client, TABLE_NAMES, COLUMN_NAMES,
                "select "
                + "  bitand(cast(pk as bigint), x'03') as pk_lobits, "
                + "  count(dd), "
                + "  %s %s ) "
                + "from %s "
                + "group by pk_lobits "
                + "order by pk_lobits");
    }

    public void testWithPartitionKey() throws Exception {
        Client client = getClient();

        fillTable(client, "p");

        compareEstimateAndExact(client, new String[] {"p"}, new String[] {"pk"},
                "select %s %s ) from %s;");

        compareEstimateAndExact(client, new String[] {"p"}, new String[] {"pk"},
                "select %s %s ) from %s where mod(pk, 3) = 0;");

        compareEstimateAndExact(client, new String[] {"p"}, new String[] {"pk"},
                "select bitand(bi, x'05') as gbk, %s %s ) "
                + "from %s "
                + "group by gbk order by gbk;");

        compareEstimateAndExact(client, new String[] {"p"}, new String[] {"pk"},
                "select bitand(bi, x'05') as gbk, %s %s ) "
                + "from %s "
                + "where mod(pk, 3) = 0 "
                + "group by gbk order by gbk;");
    }

    public void testWithSubqueries() throws Exception {
        Client client = getClient();

        fillTable(client, "p");
        fillTable(client, "r");

        
        
        compareEstimateAndExact(client, TABLE_NAMES, COLUMN_NAMES,
                "select %s %s ) "
                + "from (select approx_count_distinct(ii) from r) as repl_subquery,"
                + "  %s");

        
        compareEstimateAndExact(client, TABLE_NAMES, COLUMN_NAMES,
                "select %s %s ) "
                + "from %s, "
                + "(select approx_count_distinct(ii) from r) as repl_subquery");

        
        compareEstimateAndExact(client, TABLE_NAMES, COLUMN_NAMES,
                "select count(distinct bi), %s %s ) "
                + "from (select sum(dd), approx_count_distinct(ii) from r) as repl_subquery,"
                + "  %s");

        
        compareEstimateAndExact(client, TABLE_NAMES, COLUMN_NAMES,
                "select count(bi), %s %s ) "
                + "from (select sum(distinct dd), approx_count_distinct(ii) from r) as repl_subquery,"
                + "  %s");

        
        compareEstimateAndExact(client, TABLE_NAMES, COLUMN_NAMES,
                "select approx_count_distinct(bi), subq.a_count "
                + "from (select %s %s ) as a_count from %s) as subq,"
                + "  r "
                + "group by subq.a_count");

        
        compareEstimateAndExact(client, TABLE_NAMES, COLUMN_NAMES,
                "select approx_count_distinct(bi), subq.a_count "
                + "from (select %s %s ) as a_count, sum(distinct ii) from %s) as subq,"
                + "  r "
                + "group by subq.a_count");
    }

    public void testNegative() throws Exception {
        Client client = getClient();

        

        verifyStmtFails(client,
                "select approx_count_distinct(vc) from unsupported_column_types;",
                "incompatible data type in operation");

        verifyStmtFails(client,
                "select approx_count_distinct(vb) from unsupported_column_types;",
                "incompatible data type in operation");

        verifyStmtFails(client,
                "select approx_count_distinct(vc_inline) from unsupported_column_types;",
                "incompatible data type in operation");

        verifyStmtFails(client,
                "select approx_count_distinct(vb_inline) from unsupported_column_types;",
                "incompatible data type in operation");
    }

    public TestApproxCountDistinctSuite(String name) {
        super(name);
    }

    static public junit.framework.Test suite() {

        VoltServerConfig config = null;
        MultiConfigSuiteBuilder builder = new MultiConfigSuiteBuilder(TestApproxCountDistinctSuite.class);
        VoltProjectBuilder project = new VoltProjectBuilder();
        final String literalSchema =
                "CREATE TABLE r ( " +
                "pk integer primary key not null, " +
                "bi bigint, " +
                "ii integer, " +
                "si smallint, " +
                "ti tinyint, " +
                "ff float, " +
                "dd decimal, " +
                "ts timestamp " +
                ");" +
                "CREATE TABLE p ( " +
                "pk integer primary key not null, " +
                "bi bigint, " +
                "ii integer, " +
                "si smallint, " +
                "ti tinyint, " +
                "ff float, " +
                "dd decimal, " +
                "ts timestamp " +
                "); " +
                "partition table p on column pk;" +
                "CREATE TABLE unsupported_column_types ( "
                + "vb varbinary(256), "
                + "vc varchar(256),"
                + "vb_inline varbinary(4), "
                + "vc_inline varchar(4), "
                + ");";
        try {
            project.addLiteralSchema(literalSchema);
        } catch (IOException e) {
            assertFalse(true);
        }
        boolean success;

        config = new LocalCluster("testApproxCountDistinctSuite-onesite.jar", 3, 1, 0, BackendTarget.NATIVE_EE_JNI);
        success = config.compile(project);
        assert(success);
        builder.addServerConfig(config);

        config = new LocalCluster("testApproxCountDistinctSuite-onesite.jar", 1, 1, 0, BackendTarget.NATIVE_EE_JNI);
        success = config.compile(project);
        assert(success);
        builder.addServerConfig(config);

        return builder;
    }
}

<code block>



package org.hsqldb_voltpatches;

import java.math.BigDecimal;
import java.math.BigInteger;

import org.hsqldb_voltpatches.lib.HashSet;
import org.hsqldb_voltpatches.store.ValuePool;
import org.hsqldb_voltpatches.types.DTIType;
import org.hsqldb_voltpatches.types.IntervalMonthData;
import org.hsqldb_voltpatches.types.IntervalSecondData;
import org.hsqldb_voltpatches.types.IntervalType;
import org.hsqldb_voltpatches.types.NumberType;
import org.hsqldb_voltpatches.types.Type;

import java.io.Serializable;


public class SetFunction implements Serializable {

    private HashSet distinctValues;
    private boolean isDistinct;

    
    private int  setType;
    private int  dataType;
    private Type type;

    
    private int count;

    
    private boolean    hasNull;
    private boolean    every = true;
    private boolean    some  = false;
    private long       currentLong;
    private double     currentDouble;
    private BigDecimal currentBigDecimal;
    private Object     currentValue;

    SetFunction(int setType, Type type, boolean isDistinct) {

        this.setType = setType;
        this.type    = type;

        if (isDistinct) {
            this.isDistinct = true;
            distinctValues  = new HashSet();
        }

        if (setType == OpTypes.VAR_SAMP || setType == OpTypes.STDDEV_SAMP) {
            this.sample = true;
        }

        if (type != null) {
            dataType = type.typeCode;

            if (type.isIntervalType()) {
                dataType = Types.SQL_INTERVAL;
            }
        }
    }

    void add(Session session, Object item) {

        if (item == null) {
            hasNull = true;

            session.addWarning(Error.error(ErrorCode.W_01003));

            return;
        }

        if (isDistinct && !distinctValues.add(item)) {
            return;
        }

        count++;

        switch (setType) {

            case OpTypes.COUNT :
                return;
            
            case OpTypes.APPROX_COUNT_DISTINCT:
                
                throw Error.error(ErrorCode.X_42581, Tokens.T_APPROX_COUNT_DISTINCT);
            
            case OpTypes.AVG :
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        currentLong += ((Number) item).intValue();

                        return;

                    case Types.SQL_INTERVAL :
                        if (item instanceof IntervalSecondData) {
                            addLong(((IntervalSecondData) item).units);

                            currentLong += ((IntervalSecondData) item).nanos;

                            if (Math.abs(currentLong)
                                    >= DTIType.nanoScaleFactors[0]) {
                                addLong(currentLong
                                        / DTIType.nanoScaleFactors[0]);

                                currentLong %= DTIType.nanoScaleFactors[0];
                            }
                        } else if (item instanceof IntervalMonthData) {
                            addLong(((IntervalMonthData) item).units);
                        }

                        return;

                    case Types.SQL_BIGINT :
                        addLong(((Number) item).longValue());

                        return;

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        currentDouble += ((Number) item).doubleValue();

                        return;

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        if (currentBigDecimal == null) {
                            currentBigDecimal = (BigDecimal) item;
                        } else {
                            currentBigDecimal =
                                currentBigDecimal.add((BigDecimal) item);
                        }

                        return;

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.MIN : {
                if (currentValue == null) {
                    currentValue = item;

                    return;
                }

                if (type.compare(currentValue, item) > 0) {
                    currentValue = item;
                }

                return;
            }
            case OpTypes.MAX : {
                if (currentValue == null) {
                    currentValue = item;

                    return;
                }

                if (type.compare(currentValue, item) < 0) {
                    currentValue = item;
                }

                return;
            }
            case OpTypes.EVERY :
                if (!(item instanceof Boolean)) {
                    throw Error.error(ErrorCode.X_42565);
                }

                every = every && ((Boolean) item).booleanValue();

                return;

            case OpTypes.SOME :
                if (!(item instanceof Boolean)) {
                    throw Error.error(ErrorCode.X_42565);
                }

                some = some || ((Boolean) item).booleanValue();

                return;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                addDataPoint((Number) item);

                return;

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }
    }

    Object getValue() {

        if (setType == OpTypes.COUNT) {
            return ValuePool.getInt(count);
        }

        
        if (setType == OpTypes.APPROX_COUNT_DISTINCT) {
            throw Error.error(ErrorCode.X_42581, Tokens.T_APPROX_COUNT_DISTINCT);
        }
        
        if (count == 0) {
            return null;
        }

        switch (setType) {

            case OpTypes.AVG : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return new Long(currentLong / count);

                    case Types.SQL_BIGINT : {
                        long value = getLongSum().divide(
                            BigInteger.valueOf(count)).longValue();

                        return new Long(value);
                    }
                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return new Double(currentDouble / count);

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return currentBigDecimal.divide(new BigDecimal(count),
                                                        BigDecimal.ROUND_DOWN);

                    case Types.SQL_INTERVAL : {
                        BigInteger bi =
                            getLongSum().divide(BigInteger.valueOf(count));

                        if (!NumberType.isInLongLimits(bi)) {
                            throw Error.error(ErrorCode.X_22015);
                        }

                        if (((IntervalType) type).isDaySecondIntervalType()) {
                            return new IntervalSecondData(bi.longValue(),
                                                          currentLong,
                                                          (IntervalType) type,
                                                          true);
                        } else {
                            return IntervalMonthData.newIntervalMonth(
                                bi.longValue(), (IntervalType) type);
                        }
                    }
                    default :
                        throw Error.runtimeError(ErrorCode.U_S0500,
                                                 "SetFunction");
                }
            }
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return new Long(currentLong);

                    case Types.SQL_BIGINT :
                        return new BigDecimal(getLongSum());

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return new Double(currentDouble);

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return currentBigDecimal;

                    case Types.SQL_INTERVAL : {
                        BigInteger bi = getLongSum();

                        if (!NumberType.isInLongLimits(bi)) {
                            throw Error.error(ErrorCode.X_22015);
                        }

                        if (((IntervalType) type).isDaySecondIntervalType()) {
                            return new IntervalSecondData(bi.longValue(),
                                                          currentLong,
                                                          (IntervalType) type,
                                                          true);
                        } else {
                            return IntervalMonthData.newIntervalMonth(
                                bi.longValue(), (IntervalType) type);
                        }
                    }
                    default :
                        throw Error.runtimeError(ErrorCode.U_S0500,
                                                 "SetFunction");
                }
            }
            case OpTypes.MIN :
            case OpTypes.MAX :
                return currentValue;

            case OpTypes.EVERY :
                return every ? Boolean.TRUE
                             : Boolean.FALSE;

            case OpTypes.SOME :
                return some ? Boolean.TRUE
                            : Boolean.FALSE;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
                return getStdDev();

            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                return getVariance();

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }
    }

    
    static Type getType(int setType, Type type) {

        if (setType == OpTypes.COUNT) {
            return Type.SQL_INTEGER;
        }

        
        if (setType == OpTypes.APPROX_COUNT_DISTINCT) {
            return Type.SQL_DOUBLE;
        }
        
        
        
        
        
        
        
        if (type == null) {
            throw Error.error(ErrorCode.U_S0500);
        }
        
        int dataType = type.isIntervalType() ? Types.SQL_INTERVAL
                                             : type.typeCode;

        switch (setType) {

            case OpTypes.AVG : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                    case Types.SQL_BIGINT :
                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                    case Types.SQL_INTERVAL :
                        return type;

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return Type.SQL_BIGINT;

                    case Types.SQL_BIGINT :
                        return Type.SQL_DECIMAL_BIGINT_SQR;

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return Type.SQL_DOUBLE;

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return Type.getType(type.typeCode, 0,
                                            type.precision * 2, type.scale);

                    case Types.SQL_INTERVAL :
                        return IntervalType.newIntervalType(
                            type.typeCode, DTIType.maxIntervalPrecision,
                            type.scale);

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.MIN :
            case OpTypes.MAX :
                return type;

            case OpTypes.EVERY :
            case OpTypes.SOME :
                if (type.isBooleanType()) {
                    return Type.SQL_BOOLEAN;
                }
                break;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                if (type.isNumberType()) {
                    return Type.SQL_DOUBLE;
                }
                break;

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }

        throw Error.error(ErrorCode.X_42565);
    }

    

    
    static final BigInteger multiplier =
        BigInteger.valueOf(0x0000000100000000L);


    long hi;
    long lo;

    void addLong(long value) {

        if (value == 0) {}
        else if (value > 0) {
            hi += value >> 32;
            lo += value & 0x00000000ffffffffL;
        } else {
            if (value == Long.MIN_VALUE) {
                hi -= 0x000000080000000L;
            } else {
                long temp = ~value + 1;

                hi -= temp >> 32;
                lo -= temp & 0x00000000ffffffffL;
            }
        }


    }

    BigInteger getLongSum() {

        BigInteger biglo  = BigInteger.valueOf(lo);
        BigInteger bighi  = BigInteger.valueOf(hi);
        BigInteger result = (bighi.multiply(multiplier)).add(biglo);


        return result;
    }

    
    
    
    private double  sk;
    private double  vk;
    private long    n;
    private boolean initialized;
    private boolean sample;

    private void addDataPoint(Number x) {    

        double xi;
        double xsi;
        long   nm1;

        if (x == null) {
            return;
        }

        xi = x.doubleValue();

        if (!initialized) {
            n           = 1;
            sk          = xi;
            vk          = 0.0;
            initialized = true;

            return;
        }

        n++;

        nm1 = (n - 1);
        xsi = (sk - (xi * nm1));
        vk  += ((xsi * xsi) / n) / nm1;
        sk  += xi;
    }

    private Number getVariance() {

        if (!initialized) {
            return null;
        }

        return sample ? (n == 1) ? null    
                                 : new Double(vk / (double) (n - 1))
                      : new Double(vk / (double) (n));
    }

    private Number getStdDev() {

        if (!initialized) {
            return null;
        }

        return sample ? (n == 1) ? null    
                                 : new Double(Math.sqrt(vk / (double) (n - 1)))
                      : new Double(Math.sqrt(vk / (double) (n)));
    }

    
}

<code block>


package org.voltdb.regressionsuites;

import java.io.IOException;
import java.util.Random;

import org.voltdb.BackendTarget;
import org.voltdb.VoltTable;
import org.voltdb.client.Client;
import org.voltdb.client.NoConnectionsException;
import org.voltdb.client.ProcCallException;
import org.voltdb.compiler.VoltProjectBuilder;

public class TestApproxCountDistinctSuite extends RegressionSuite {

    private static void fillTable(Client client, String tbl) throws Exception {
        Random r = new Random(777);
        for (int i = 0; i < 1000; ++i) {

            double d;
            do {
                d = r.nextGaussian() * 1000;
            } while (d > Long.MAX_VALUE || d <= Long.MIN_VALUE);

            long val = (long) d;
            client.callProcedure(tbl + ".Insert", i, val);
        }
    }

    public void testSimple() throws Exception
    {
        Client client = getClient();

        VoltTable vt = client.callProcedure("@AdHoc", "select approx_count_distinct(bi) from r;")
                .getResults()[0];
        assertTrue(vt.advanceRow());
        assertEquals(0.0, vt.getDouble(0));
        assertFalse(vt.advanceRow());

        fillTable(client, "r");

        vt = client.callProcedure("@AdHoc",
                "select approx_count_distinct(bi), count(distinct bi)  from r;")
                .getResults()[0];
        assertTrue(vt.advanceRow());
        assertEquals(820.529, vt.getDouble(0), 0.01);
        assertEquals(867, vt.getLong(1));
        
        
        
        
        assertFalse(vt.advanceRow());
    }

    public void testDistributed() throws Exception {
        Client client = getClient();

        VoltTable vt = client.callProcedure("@Explain", "select approx_count_distinct(bi) from p;")
                .getResults()[0];

        vt = client.callProcedure("@AdHoc", "select approx_count_distinct(bi) from p;")
                .getResults()[0];
        assertTrue(vt.advanceRow());
        assertEquals(0.0, vt.getDouble(0));
        assertFalse(vt.advanceRow());

        fillTable(client, "p");

        vt = client.callProcedure("@AdHoc",
                "select approx_count_distinct(bi) from p;")
                .getResults()[0];
        assertTrue(vt.advanceRow());
        assertEquals(820.529, vt.getDouble(0), 0.01);
        assertFalse(vt.advanceRow());
    }

    public TestApproxCountDistinctSuite(String name) {
        super(name);
    }

    static public junit.framework.Test suite() {

        VoltServerConfig config = null;
        MultiConfigSuiteBuilder builder = new MultiConfigSuiteBuilder(TestApproxCountDistinctSuite.class);
        VoltProjectBuilder project = new VoltProjectBuilder();
        final String literalSchema =
                "CREATE TABLE r ( " +
                "pk integer primary key not null, " +
                "bi bigint " +
                ");" +
                "CREATE TABLE p ( " +
                "pk integer primary key not null, " +
                "bi bigint " +
                ");" +
                "partition table p on column pk;" +
                "";
        try {
            project.addLiteralSchema(literalSchema);
        } catch (IOException e) {
            assertFalse(true);
        }
        boolean success;

        config = new LocalCluster("testApproxCountDistinctSuite-onesite.jar", 2, 1, 0, BackendTarget.NATIVE_EE_JNI);
        success = config.compile(project);
        assert(success);
        builder.addServerConfig(config);

        config = new LocalCluster("testApproxCountDistinctSuite-onesite.jar", 1, 1, 0, BackendTarget.NATIVE_EE_JNI);
        success = config.compile(project);
        assert(success);
        builder.addServerConfig(config);

        return builder;
    }
}

<code block>

package org.voltdb;

import java.util.Map;
import java.util.Set;

import org.voltdb.iv2.SpScheduler.DurableMpUniqueIdListener;
import org.voltdb.iv2.SpScheduler.DurableSpUniqueIdListener;
import org.voltdb.iv2.TransactionTask;
import org.voltdb.messaging.Iv2InitiateTaskMessage;

import com.google_voltpatches.common.util.concurrent.ListenableFuture;

public interface CommandLog {
    
    public abstract void init(
                                 CatalogContext context,
                                 long txnId,
                                 int partitionCount, String coreBinding,
                                 Map<Integer, Long> perPartitionTxnId);

    
    public abstract void initForRejoin(
                                          CatalogContext context,
                                          long txnId,
                                          int partitionCount, boolean isRejoin,
                                          String coreBinding, Map<Integer, Long> perPartitionTxnId);

    public abstract boolean needsInitialization();

    
    public abstract ListenableFuture<Object> log(
            Iv2InitiateTaskMessage message,
            long spHandle,
            int[] involvedPartitions,
            DurabilityListener listener,
            TransactionTask durabilityHandle);

    public abstract void shutdown() throws InterruptedException;

    
    public abstract void logIv2Fault(long writerHSId, Set<Long> survivorHSId,
            int partitionId, long spHandle);

    public interface DurabilityListener {
        
        public void setSpUniqueIdListener(DurableSpUniqueIdListener listener);

        
        public void setMpUniqueIdListener(DurableMpUniqueIdListener listener);

        
        public void createFirstCompletionCheck(boolean isSyncLogging, boolean haveMpGateway);

        
        public boolean completionCheckInitialized(boolean supportsMp);

        
        public void onDurability();
        
        public void addTransaction(TransactionTask pendingTask);
        
        public int getNumberOfTasks();
        
        public void startNewTaskList(int nextMaxRowCnt);
    }

    
    public abstract boolean isEnabled();

    
    public void requestTruncationSnapshot(final boolean queueIfPending);

    
    public void populateCommandLogStats(Map<String, Integer> columnNameToIndex, Object[] rowValues);

    
    public abstract boolean isSynchronous();

    
    public abstract void registerDurabilityListener(DurabilityListener durabilityListener);
}

<code block>


package org.voltdb;

import java.io.IOException;
import java.lang.reflect.Constructor;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.util.Map;
import java.util.concurrent.atomic.AtomicLong;

import org.cliffc_voltpatches.high_scale_lib.NonBlockingHashMap;
import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.DBBPool;
import org.voltcore.utils.DBBPool.BBContainer;
import org.voltdb.iv2.MpInitiator;
import org.voltdb.iv2.SpScheduler.DurableMpUniqueIdListener;
import org.voltdb.iv2.SpScheduler.DurableSpUniqueIdListener;
import org.voltdb.licensetool.LicenseApi;

import com.google_voltpatches.common.base.Charsets;
import com.google_voltpatches.common.collect.ImmutableMap;


public class PartitionDRGateway implements DurableSpUniqueIdListener, DurableMpUniqueIdListener {
    private static final VoltLogger log = new VoltLogger("DR");

    public enum DRRecordType {
        INSERT, DELETE, UPDATE, BEGIN_TXN, END_TXN, TRUNCATE_TABLE, DELETE_BY_INDEX;

        public static final ImmutableMap<Integer, DRRecordType> conversion;
        static {
            ImmutableMap.Builder<Integer, DRRecordType> b = ImmutableMap.builder();
            for (DRRecordType t : DRRecordType.values()) {
                b.put(t.ordinal(), t);
            }
            conversion = b.build();
        }

        public static DRRecordType valueOf(int ordinal) {
            return conversion.get(ordinal);
        }
    }

    public static final Map<Integer, PartitionDRGateway> m_partitionDRGateways = new NonBlockingHashMap<>();

    
    public static PartitionDRGateway getInstance(int partitionId,
                                                 ProducerDRGateway producerGateway,
                                                 StartAction startAction)
    {
        final VoltDBInterface vdb = VoltDB.instance();
        LicenseApi api = vdb.getLicenseApi();
        final boolean licensedToDR = api.isDrReplicationAllowed();

        
        
        PartitionDRGateway pdrg = null;
        if (licensedToDR && producerGateway != null) {
            pdrg = tryToLoadProVersion();
        }
        if (pdrg == null) {
            pdrg = new PartitionDRGateway();
        }

        
        try {
            pdrg.init(partitionId, producerGateway, startAction);
        } catch (IOException e) {
            VoltDB.crashLocalVoltDB(e.getMessage(), false, e);
        }
        m_partitionDRGateways.put(partitionId,  pdrg);

        return pdrg;
    }

    private static PartitionDRGateway tryToLoadProVersion()
    {
        try {
            Class<?> pdrgiClass = null;
            pdrgiClass = Class.forName("org.voltdb.dr2.PartitionDRGatewayImpl");
            Constructor<?> constructor = pdrgiClass.getConstructor();
            Object obj = constructor.newInstance();
            return (PartitionDRGateway) obj;
        } catch (Exception e) {
        }
        return null;
    }

    
    protected void init(int partitionId,
                        ProducerDRGateway producerGateway,
                        StartAction startAction) throws IOException {}
    public void onSuccessfulProcedureCall(long txnId, long uniqueId, int hash,
                                          StoredProcedureInvocation spi,
                                          ClientResponseImpl response) {}
    public void onSuccessfulMPCall(long spHandle, long txnId, long uniqueId, int hash,
                                   StoredProcedureInvocation spi,
                                   ClientResponseImpl response) {}
    public void onBinaryDR(int partitionId, long startSequenceNumber, long lastSequenceNumber, long lastUniqueId, ByteBuffer buf) {
        final BBContainer cont = DBBPool.wrapBB(buf);
        DBBPool.registerUnsafeMemory(cont.address());
        cont.discard();
    }

    @Override
    public void lastSpUniqueIdMadeDurable(long uniqueId) {}

    @Override
    public void lastMpUniqueIdMadeDurable(long uniqueId) {}

    private static final ThreadLocal<AtomicLong> haveOpenTransactionLocal = new ThreadLocal<AtomicLong>() {
        @Override
        protected AtomicLong initialValue() {
            return new AtomicLong(-1);
        }
    };

    private static final ThreadLocal<AtomicLong> lastCommittedSpHandleTL = new ThreadLocal<AtomicLong>() {
        @Override
        protected AtomicLong initialValue() {
            return new AtomicLong(0);
        }
    };

    public static synchronized void pushDRBuffer(
            int partitionId,
            long startSequenceNumber,
            long lastSequenceNumber,
            long lastUniqueId,
            ByteBuffer buf) {
        if (startSequenceNumber == lastUniqueId) {
            log.trace("Received DR buffer size " + buf.remaining());
            AtomicLong haveOpenTransaction = haveOpenTransactionLocal.get();
            buf.order(ByteOrder.LITTLE_ENDIAN);
            
            buf.position(8 + 65 + (partitionId == MpInitiator.MP_INIT_PID ? 0 : 4));
            while (buf.hasRemaining()) {
                int startPosition = buf.position();
                byte version = buf.get();
                int type = buf.get();

                int checksum = 0;
                if (version != 0) log.trace("Remaining is " + buf.remaining());

                DRRecordType recordType = DRRecordType.valueOf(type);
                switch (recordType) {
                case INSERT:
                case DELETE:
                case DELETE_BY_INDEX: {
                    
                    if (haveOpenTransaction.get() == -1) {
                        log.error("Have insert/delete but no open transaction");
                        break;
                    }
                    final long tableHandle = buf.getLong();
                    final int lengthPrefix = buf.getInt();
                    final int indexCrc;
                    if (recordType == DRRecordType.DELETE_BY_INDEX) {
                        indexCrc = buf.getInt();
                    } else {
                        indexCrc = 0;
                    }
                    buf.position(buf.position() + lengthPrefix);
                    checksum = buf.getInt();
                    log.trace("Version " + version + " type " + recordType + "table handle " + tableHandle + " length " + lengthPrefix + " checksum " + checksum +
                              (recordType == DRRecordType.DELETE_BY_INDEX ? (" index checksum " + indexCrc) : ""));
                    break;
                }
                case BEGIN_TXN: {
                    
                    final long txnId = buf.getLong();
                    final long spHandle = buf.getLong();
                    if (haveOpenTransaction.get() != -1) {
                        log.error("Have open transaction txnid " + txnId + " spHandle " + spHandle + " but already open transaction");
                        break;
                    }
                    haveOpenTransaction.set(spHandle);
                    checksum = buf.getInt();
                    log.trace("Version " + version + " type BEGIN_TXN " + " txnid " + txnId + " spHandle " + spHandle + " checksum " + checksum);
                    break;
                }
                case END_TXN: {
                    
                    final long spHandle = buf.getLong();
                    if (haveOpenTransaction.get() == -1 ) {
                        log.error("Have end transaction spHandle " + spHandle + " but no open transaction and its less then last committed " + lastCommittedSpHandleTL.get().get());
                        break;
                    }
                    haveOpenTransaction.set(-1);
                    lastCommittedSpHandleTL.get().set(spHandle);
                    checksum = buf.getInt();
                    log.trace("Version " + version + " type END_TXN " + " spHandle " + spHandle + " checksum " + checksum);
                    break;
                }
                case TRUNCATE_TABLE: {
                    final long tableHandle = buf.getLong();
                    final byte tableNameBytes[] = new byte[buf.getInt()];
                    buf.get(tableNameBytes);
                    final String tableName = new String(tableNameBytes, Charsets.UTF_8);
                    checksum = buf.getInt();
                    log.trace("Version " + version + " type TRUNCATE_TABLE table handle " + tableHandle + " table name " + tableName);
                    break;
                }
                }
                int calculatedChecksum = DBBPool.getBufferCRC32C(buf, startPosition, buf.position() - startPosition - 4);
                if (calculatedChecksum != checksum) {
                    log.error("Checksum " + calculatedChecksum + " didn't match " + checksum);
                    break;
                }

            }
        }

        final PartitionDRGateway pdrg = m_partitionDRGateways.get(partitionId);
        if (pdrg == null) {
            VoltDB.crashLocalVoltDB("No PRDG when there should be", true, null);
        }
        pdrg.onBinaryDR(partitionId, startSequenceNumber, lastSequenceNumber, lastUniqueId, buf);
    }

    public void forceAllDRNodeBuffersToDisk(final boolean nofsync) {}
}

<code block>


package org.voltdb.iv2;

import java.util.ArrayDeque;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Queue;
import java.util.concurrent.CountDownLatch;

import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltcore.messaging.TransactionInfoBaseMessage;
import org.voltcore.messaging.VoltMessage;
import org.voltcore.utils.CoreUtils;
import org.voltdb.ClientResponseImpl;
import org.voltdb.CommandLog;
import org.voltdb.CommandLog.DurabilityListener;
import org.voltdb.PartitionDRGateway;
import org.voltdb.SnapshotCompletionInterest;
import org.voltdb.SnapshotCompletionMonitor;
import org.voltdb.SystemProcedureCatalog;
import org.voltdb.VoltDB;
import org.voltdb.VoltTable;
import org.voltdb.client.ClientResponse;
import org.voltdb.dtxn.TransactionState;
import org.voltdb.messaging.BorrowTaskMessage;
import org.voltdb.messaging.CompleteTransactionMessage;
import org.voltdb.messaging.DumpMessage;
import org.voltdb.messaging.FragmentResponseMessage;
import org.voltdb.messaging.FragmentTaskMessage;
import org.voltdb.messaging.InitiateResponseMessage;
import org.voltdb.messaging.Iv2InitiateTaskMessage;
import org.voltdb.messaging.Iv2LogFaultMessage;
import org.voltdb.messaging.MultiPartitionParticipantMessage;

import com.google_voltpatches.common.primitives.Ints;
import com.google_voltpatches.common.primitives.Longs;
import com.google_voltpatches.common.util.concurrent.ListenableFuture;

public class SpScheduler extends Scheduler implements SnapshotCompletionInterest
{
    static final VoltLogger tmLog = new VoltLogger("TM");

    static class DuplicateCounterKey implements Comparable<DuplicateCounterKey>
    {
        private final long m_txnId;
        private final long m_spHandle;
        transient final int m_hash;

        DuplicateCounterKey(long txnId, long spHandle)
        {
            m_txnId = txnId;
            m_spHandle = spHandle;
            m_hash = (37 * (int)(m_txnId ^ (m_txnId >>> 32))) +
                ((int)(m_spHandle ^ (m_spHandle >>> 32)));
        }

        @Override
        public boolean equals(Object o)
        {
            if (this == o) {
                return true;
            }
            if (o == null || !(getClass().isInstance(o))) {
                return false;
            }

            DuplicateCounterKey other = (DuplicateCounterKey)o;

            return (m_txnId == other.m_txnId && m_spHandle == other.m_spHandle);
        }

        
        @Override
        public int compareTo(DuplicateCounterKey o)
        {
            if (m_txnId < o.m_txnId) {
                return -1;
            } else if (m_txnId > o.m_txnId) {
                return 1;
            } else {
                if (m_spHandle < o.m_spHandle) {
                    return -1;
                }
                else if (m_spHandle > o.m_spHandle) {
                    return 1;
                }
                else {
                    return 0;
                }
            }
        }

        @Override
        public int hashCode()
        {
            return m_hash;
        }

        @Override
        public String toString()
        {
            return "<" + m_txnId + ", " + m_spHandle + ">";
        }
    };

    public interface DurableSpUniqueIdListener {
        
        public void lastSpUniqueIdMadeDurable(long uniqueId);
    }

    public interface DurableMpUniqueIdListener {
        
        public void lastMpUniqueIdMadeDurable(long uniqueId);
    }


    List<Long> m_replicaHSIds = new ArrayList<Long>();
    long m_sendToHSIds[] = new long[0];

    private final TransactionTaskQueue m_pendingTasks;
    private final Map<Long, TransactionState> m_outstandingTxns =
        new HashMap<Long, TransactionState>();
    private final Map<DuplicateCounterKey, DuplicateCounter> m_duplicateCounters =
        new HashMap<DuplicateCounterKey, DuplicateCounter>();
    
    private final Map<Long, Queue<TransactionTask>> m_mpsPendingDurability =
        new HashMap<Long, Queue<TransactionTask>>();
    private CommandLog m_cl;
    private PartitionDRGateway m_drGateway = new PartitionDRGateway();
    private PartitionDRGateway m_drGatewayMP = null;
    private final SnapshotCompletionMonitor m_snapMonitor;
    
    
    boolean m_replayComplete = false;
    private final DurabilityListener m_durabilityListener;
    
    private final UniqueIdGenerator m_uniqueIdGenerator;

    
    long m_repairLogTruncationHandle = Long.MIN_VALUE;

    SpScheduler(int partitionId, SiteTaskerQueue taskQueue, SnapshotCompletionMonitor snapMonitor)
    {
        super(partitionId, taskQueue);
        m_pendingTasks = new TransactionTaskQueue(m_tasks,getCurrentTxnId());
        m_snapMonitor = snapMonitor;
        m_durabilityListener = new SpDurabilityListener(this, m_pendingTasks, taskQueue, m_lock);
        m_uniqueIdGenerator = new UniqueIdGenerator(partitionId, 0);
    }

    @Override
    public void setLeaderState(boolean isLeader)
    {
        super.setLeaderState(isLeader);
        m_snapMonitor.addInterest(this);
    }

    @Override
    public void setMaxSeenTxnId(long maxSeenTxnId)
    {
        super.setMaxSeenTxnId(maxSeenTxnId);
        writeIv2ViableReplayEntry();
    }

    public void setSpUniqueIdListener(DurableSpUniqueIdListener listener) {
        m_durabilityListener.setSpUniqueIdListener(listener);
        if (m_cl != null && !m_durabilityListener.completionCheckInitialized(false)) {
            m_durabilityListener.createFirstCompletionCheck(m_cl.isSynchronous(), false);
        }
    }

    public void setMpUniqueIdListener(DurableMpUniqueIdListener listener) {
        m_durabilityListener.setMpUniqueIdListener(listener);
        if (m_cl != null && !m_durabilityListener.completionCheckInitialized(true)) {
            m_durabilityListener.createFirstCompletionCheck(m_cl.isSynchronous(), true);
        }
    }

    public void setDRGateway(PartitionDRGateway gateway)
    {
        m_drGateway = gateway;
        setSpUniqueIdListener(gateway);
    }

    public void setMpDRGateway(final PartitionDRGateway mpGateway)
    {
        m_drGatewayMP = mpGateway;
        m_durabilityListener.setMpUniqueIdListener(mpGateway);
    }

    @Override
    public void shutdown()
    {
        m_tasks.offer(m_nullTask);
    }

    
    
    
    
    @Override
    public void updateReplicas(List<Long> replicas, Map<Integer, Long> partitionMasters)
    {
        
        m_replicaHSIds = replicas;
        
        List<Long> sendToHSIds = new ArrayList<Long>(m_replicaHSIds);
        sendToHSIds.remove(m_mailbox.getHSId());
        m_sendToHSIds = Longs.toArray(sendToHSIds);

        
        
        List<DuplicateCounterKey> doneCounters = new LinkedList<DuplicateCounterKey>();
        for (Entry<DuplicateCounterKey, DuplicateCounter> entry : m_duplicateCounters.entrySet()) {
            DuplicateCounter counter = entry.getValue();
            int result = counter.updateReplicas(m_replicaHSIds);
            if (result == DuplicateCounter.DONE) {
                doneCounters.add(entry.getKey());
            }
        }

        
        Collections.sort(doneCounters);
        for (DuplicateCounterKey key : doneCounters) {
            DuplicateCounter counter = m_duplicateCounters.remove(key);
            VoltMessage resp = counter.getLastResponse();
            if (resp != null) {
                
                
                if (resp instanceof FragmentResponseMessage) {
                    FragmentResponseMessage fresp = (FragmentResponseMessage)resp;
                    fresp.setExecutorSiteId(m_mailbox.getHSId());
                }
                m_mailbox.send(counter.m_destinationId, resp);
            }
            else {
                hostLog.warn("TXN " + counter.getTxnId() + " lost all replicas and " +
                        "had no responses.  This should be impossible?");
            }
        }
        writeIv2ViableReplayEntry();
    }

    
    private void deliverReadyTxns() {
        
        VoltMessage m = m_replaySequencer.poll();
        while(m != null) {
            deliver(m);
            m = m_replaySequencer.poll();
        }
        
        m = m_replaySequencer.drain();
        while (m != null) {
            if (m instanceof Iv2InitiateTaskMessage) {
                
                Iv2InitiateTaskMessage task = (Iv2InitiateTaskMessage) m;
                final InitiateResponseMessage response = new InitiateResponseMessage(task);
                response.setResults(new ClientResponseImpl(ClientResponse.UNEXPECTED_FAILURE,
                            new VoltTable[0],
                            ClientResponseImpl.IGNORED_TRANSACTION));
                m_mailbox.send(response.getInitiatorHSId(), response);
            }
            m = m_replaySequencer.drain();
        }
    }

    
    @Override
    public boolean sequenceForReplay(VoltMessage message)
    {
        boolean canDeliver = false;
        long sequenceWithTxnId = Long.MIN_VALUE;

        boolean commandLog = (message instanceof TransactionInfoBaseMessage &&
                (((TransactionInfoBaseMessage)message).isForReplay()));

        boolean dr = ((message instanceof TransactionInfoBaseMessage &&
                ((TransactionInfoBaseMessage)message).isForDR()));

        boolean sentinel = message instanceof MultiPartitionParticipantMessage;

        boolean replay = commandLog || sentinel || dr;
        boolean sequenceForReplay = m_isLeader && replay;

        assert(!(commandLog && dr));

        if (commandLog || sentinel) {
            sequenceWithTxnId = ((TransactionInfoBaseMessage)message).getTxnId();
        }
        else if (dr) {
            sequenceWithTxnId = ((TransactionInfoBaseMessage)message).getOriginalTxnId();
        }

        if (sequenceForReplay) {
            InitiateResponseMessage dupe = m_replaySequencer.dedupe(sequenceWithTxnId,
                    (TransactionInfoBaseMessage) message);
            if (dupe != null) {
                
                m_mailbox.send(dupe.getInitiatorHSId(), dupe);
            }
            else if (!m_replaySequencer.offer(sequenceWithTxnId, (TransactionInfoBaseMessage) message)) {
                canDeliver = true;
            }
            else {
                deliverReadyTxns();
            }

            
            if (sentinel && !commandLog) {
                MultiPartitionParticipantMessage mppm = (MultiPartitionParticipantMessage) message;
                final InitiateResponseMessage response = new InitiateResponseMessage(mppm);
                ClientResponseImpl clientResponse =
                        new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                                new VoltTable[0], ClientResponseImpl.IGNORED_TRANSACTION);
                response.setResults(clientResponse);
                m_mailbox.send(response.getInitiatorHSId(), response);
            }
        }
        else {
            if (replay) {
                
                m_replaySequencer.updateLastSeenTxnId(sequenceWithTxnId,
                        (TransactionInfoBaseMessage) message);
                m_replaySequencer.updateLastPolledTxnId(sequenceWithTxnId,
                        (TransactionInfoBaseMessage) message);
            }

            canDeliver = true;
        }

        return canDeliver;
    }

    
    
    
    @Override
    public void deliver(VoltMessage message)
    {
        if (message instanceof Iv2InitiateTaskMessage) {
            handleIv2InitiateTaskMessage((Iv2InitiateTaskMessage)message);
        }
        else if (message instanceof InitiateResponseMessage) {
            handleInitiateResponseMessage((InitiateResponseMessage)message);
        }
        else if (message instanceof FragmentTaskMessage) {
            handleFragmentTaskMessage((FragmentTaskMessage)message);
        }
        else if (message instanceof FragmentResponseMessage) {
            handleFragmentResponseMessage((FragmentResponseMessage)message);
        }
        else if (message instanceof CompleteTransactionMessage) {
            handleCompleteTransactionMessage((CompleteTransactionMessage)message);
        }
        else if (message instanceof BorrowTaskMessage) {
            handleBorrowTaskMessage((BorrowTaskMessage)message);
        }
        else if (message instanceof Iv2LogFaultMessage) {
            handleIv2LogFaultMessage((Iv2LogFaultMessage)message);
        }
        else if (message instanceof DumpMessage) {
            handleDumpMessage();
        }
        else {
            throw new RuntimeException("UNKNOWN MESSAGE TYPE, BOOM!");
        }
    }

    private long getMaxTaskedSpHandle() {
        return m_pendingTasks.getMaxTaskedSpHandle();
    }

    
    
    public void handleIv2InitiateTaskMessage(Iv2InitiateTaskMessage message)
    {
        if (!message.isSinglePartition()) {
            throw new RuntimeException("SpScheduler.handleIv2InitiateTaskMessage " +
                    "should never receive multi-partition initiations.");
        }

        final String procedureName = message.getStoredProcedureName();
        long newSpHandle;
        long uniqueId = Long.MIN_VALUE;
        Iv2InitiateTaskMessage msg = message;
        if (m_isLeader || message.isReadOnly()) {
            
            if (!m_isLeader &&
                    CoreUtils.getHostIdFromHSId(msg.getInitiatorHSId()) !=
                    CoreUtils.getHostIdFromHSId(m_mailbox.getHSId())) {
                VoltDB.crashLocalVoltDB("Only allowed to do short circuit reads locally", true, null);
                    }

            
            if (message.isForReplay()) {
                uniqueId = message.getUniqueId();
                try {
                    m_uniqueIdGenerator.updateMostRecentlyGeneratedUniqueId(uniqueId);
                }
                catch (Exception e) {
                    hostLog.fatal(e.getMessage());
                    hostLog.fatal("Invocation: " + message);
                    VoltDB.crashLocalVoltDB(e.getMessage(), true, e);
                }
            } else if (message.isForDR()) {
                uniqueId = message.getStoredProcedureInvocation().getOriginalUniqueId();
                
                if (UniqueIdGenerator.getPartitionIdFromUniqueId(uniqueId) == m_partitionId) {
                    m_uniqueIdGenerator.updateMostRecentlyGeneratedUniqueId(uniqueId);
                }
            }

            
            if (message.isForReplay()) {
                newSpHandle = message.getTxnId();
                setMaxSeenTxnId(newSpHandle);
            } else if (m_isLeader && !message.isReadOnly()) {
                TxnEgo ego = advanceTxnEgo();
                newSpHandle = ego.getTxnId();
                uniqueId = m_uniqueIdGenerator.getNextUniqueId();
            } else {
                
                uniqueId = UniqueIdGenerator.makeIdFromComponents(
                        Math.max(System.currentTimeMillis(), m_uniqueIdGenerator.lastUsedTime),
                        0,
                        m_uniqueIdGenerator.partitionId);
                
                newSpHandle = getMaxTaskedSpHandle();
            }

            
            
            
            
            
            msg = new Iv2InitiateTaskMessage(
                    message.getInitiatorHSId(),
                    message.getCoordinatorHSId(),
                    m_repairLogTruncationHandle,
                    message.getTxnId(),
                    message.getUniqueId(),
                    message.isReadOnly(),
                    message.isSinglePartition(),
                    message.getStoredProcedureInvocation(),
                    message.getClientInterfaceHandle(),
                    message.getConnectionId(),
                    message.isForReplay());

            msg.setSpHandle(newSpHandle);

            
            
            
            if (SystemProcedureCatalog.listing.get(procedureName) == null ||
                    !SystemProcedureCatalog.listing.get(procedureName).getEverysite()) {
                msg.setTxnId(newSpHandle);
                msg.setUniqueId(uniqueId);
                    }

            
            
            if (m_isLeader && !msg.isReadOnly() && m_sendToHSIds.length > 0) {
                Iv2InitiateTaskMessage replmsg =
                    new Iv2InitiateTaskMessage(m_mailbox.getHSId(),
                            m_mailbox.getHSId(),
                            m_repairLogTruncationHandle,
                            msg.getTxnId(),
                            msg.getUniqueId(),
                            msg.isReadOnly(),
                            msg.isSinglePartition(),
                            msg.getStoredProcedureInvocation(),
                            msg.getClientInterfaceHandle(),
                            msg.getConnectionId(),
                            msg.isForReplay());
                
                replmsg.setSpHandle(newSpHandle);
                m_mailbox.send(m_sendToHSIds, replmsg);
                DuplicateCounter counter = new DuplicateCounter(
                        msg.getInitiatorHSId(),
                        msg.getTxnId(), m_replicaHSIds, msg.getStoredProcedureName());
                m_duplicateCounters.put(new DuplicateCounterKey(msg.getTxnId(), newSpHandle), counter);
            }
        }
        else {
            setMaxSeenTxnId(msg.getSpHandle());
            newSpHandle = msg.getSpHandle();
            uniqueId = msg.getUniqueId();
        }
        Iv2Trace.logIv2InitiateTaskMessage(message, m_mailbox.getHSId(), msg.getTxnId(), newSpHandle);
        doLocalInitiateOffer(msg);
        return;
    }

    
    private void doLocalInitiateOffer(Iv2InitiateTaskMessage msg)
    {
        final String procedureName = msg.getStoredProcedureName();
        final SpProcedureTask task =
            new SpProcedureTask(m_mailbox, procedureName, m_pendingTasks, msg, m_drGateway);
        if (!msg.isReadOnly()) {
            ListenableFuture<Object> durabilityBackpressureFuture =
                    m_cl.log(msg, msg.getSpHandle(), null, m_durabilityListener, task);
            
            
            
            if (durabilityBackpressureFuture != null) {
                m_pendingTasks.offer(task.setDurabilityBackpressureFuture(durabilityBackpressureFuture));
            }
        } else {
            m_pendingTasks.offer(task);
        }
    }

    @Override
    public void handleMessageRepair(List<Long> needsRepair, VoltMessage message)
    {
        if (message instanceof Iv2InitiateTaskMessage) {
            handleIv2InitiateTaskMessageRepair(needsRepair, (Iv2InitiateTaskMessage)message);
        }
        else if (message instanceof FragmentTaskMessage) {
            handleFragmentTaskMessageRepair(needsRepair, (FragmentTaskMessage)message);
        }
        else if (message instanceof CompleteTransactionMessage) {
            
            handleCompleteTransactionMessage((CompleteTransactionMessage)message);
        }
        else {
            throw new RuntimeException("SpScheduler.handleMessageRepair received unexpected message type: " +
                    message);
        }
    }

    private void handleIv2InitiateTaskMessageRepair(List<Long> needsRepair, Iv2InitiateTaskMessage message)
    {
        if (!message.isSinglePartition()) {
            throw new RuntimeException("SpScheduler.handleIv2InitiateTaskMessageRepair " +
                    "should never receive multi-partition initiations.");
        }

        
        

        
        
        

        List<Long> expectedHSIds = new ArrayList<Long>(needsRepair);
        DuplicateCounter counter = new DuplicateCounter(
                HostMessenger.VALHALLA,
                message.getTxnId(), expectedHSIds, message.getStoredProcedureName());
        m_duplicateCounters.put(new DuplicateCounterKey(message.getTxnId(), message.getSpHandle()), counter);

        m_uniqueIdGenerator.updateMostRecentlyGeneratedUniqueId(message.getUniqueId());
        
        if (needsRepair.contains(m_mailbox.getHSId())) {
            needsRepair.remove(m_mailbox.getHSId());
            
            Iv2InitiateTaskMessage localWork =
                new Iv2InitiateTaskMessage(message.getInitiatorHSId(),
                    message.getCoordinatorHSId(), message);
            doLocalInitiateOffer(localWork);
        }

        
        if (!needsRepair.isEmpty()) {
            Iv2InitiateTaskMessage replmsg =
                new Iv2InitiateTaskMessage(m_mailbox.getHSId(), m_mailbox.getHSId(), message);
            m_mailbox.send(com.google_voltpatches.common.primitives.Longs.toArray(needsRepair), replmsg);
        }
    }

    private void handleFragmentTaskMessageRepair(List<Long> needsRepair, FragmentTaskMessage message)
    {
        
        

        List<Long> expectedHSIds = new ArrayList<Long>(needsRepair);
        DuplicateCounter counter = new DuplicateCounter(
                message.getCoordinatorHSId(), 
                message.getTxnId(), expectedHSIds, "MP_DETERMINISM_ERROR");
        m_duplicateCounters.put(new DuplicateCounterKey(message.getTxnId(), message.getSpHandle()), counter);

        
        if (needsRepair.contains(m_mailbox.getHSId())) {
            
            if (m_outstandingTxns.get(message.getTxnId()) != null) {
                hostLog.warn("SPI repair attempted to repair a fragment which it has already seen. " +
                        "This shouldn't be possible.");
                
                throw new RuntimeException("Attempted to repair with a fragment we've already seen.");
            }
            needsRepair.remove(m_mailbox.getHSId());
            
            FragmentTaskMessage localWork =
                new FragmentTaskMessage(message.getInitiatorHSId(),
                    message.getCoordinatorHSId(), message);
            doLocalFragmentOffer(localWork);
        }

        
        if (!needsRepair.isEmpty()) {
            FragmentTaskMessage replmsg =
                new FragmentTaskMessage(m_mailbox.getHSId(), m_mailbox.getHSId(), message);
            m_mailbox.send(com.google_voltpatches.common.primitives.Longs.toArray(needsRepair), replmsg);
        }
    }

    
    public void handleInitiateResponseMessage(InitiateResponseMessage message)
    {
        
        
        
        
        if (message.isReadOnly()) {
            
            m_mailbox.send(message.getInitiatorHSId(), message);
            return;
        }

        final long spHandle = message.getSpHandle();
        final DuplicateCounterKey dcKey = new DuplicateCounterKey(message.getTxnId(), spHandle);
        DuplicateCounter counter = m_duplicateCounters.get(dcKey);
        if (counter != null) {
            int result = counter.offer(message);
            if (result == DuplicateCounter.DONE) {
                m_duplicateCounters.remove(dcKey);
                m_repairLogTruncationHandle = spHandle;
                m_mailbox.send(counter.m_destinationId, counter.getLastResponse());
            }
            else if (result == DuplicateCounter.MISMATCH) {
                VoltDB.crashGlobalVoltDB("HASH MISMATCH: replicas produced different results.", true, null);
            }
        }
        else {
            
            m_repairLogTruncationHandle = spHandle;
            m_mailbox.send(message.getInitiatorHSId(), message);
        }
    }

    
    
    
    private void handleBorrowTaskMessage(BorrowTaskMessage message) {
        
        
        
        long newSpHandle = getMaxTaskedSpHandle();
        Iv2Trace.logFragmentTaskMessage(message.getFragmentTaskMessage(),
                m_mailbox.getHSId(), newSpHandle, true);
        TransactionState txn = m_outstandingTxns.get(message.getTxnId());

        if (txn == null) {
            
            
            
            
            
            
            txn = new BorrowTransactionState(newSpHandle, message);
        }


        if (message.getFragmentTaskMessage().isSysProcTask()) {
            final SysprocFragmentTask task =
                new SysprocFragmentTask(m_mailbox, (ParticipantTransactionState)txn,
                                        m_pendingTasks, message.getFragmentTaskMessage(),
                                        message.getInputDepMap());
            m_pendingTasks.offer(task);
        }
        else {
            final FragmentTask task =
                new FragmentTask(m_mailbox, (ParticipantTransactionState)txn,
                        m_pendingTasks, message.getFragmentTaskMessage(),
                        message.getInputDepMap());
            m_pendingTasks.offer(task);
        }
    }

    
    
    
    
    
    
    
    
    
    void handleFragmentTaskMessage(FragmentTaskMessage message)
    {
        FragmentTaskMessage msg = message;
        long newSpHandle;
        if (m_isLeader) {
            
            
            
            msg = new FragmentTaskMessage(message.getInitiatorHSId(),
                    message.getCoordinatorHSId(), message);
            
            if (!message.isReadOnly()) {
                TxnEgo ego = advanceTxnEgo();
                newSpHandle = ego.getTxnId();
            } else {
                newSpHandle = getMaxTaskedSpHandle();
            }

            msg.setSpHandle(newSpHandle);
            if (msg.getInitiateTask() != null) {
                msg.getInitiateTask().setSpHandle(newSpHandle);
                
                msg.setStateForDurability(msg.getInitiateTask(), msg.getInvolvedPartitions());
            }

            
            if (m_sendToHSIds.length > 0 && (!msg.isReadOnly() || msg.isSysProcTask())) {
                FragmentTaskMessage replmsg =
                    new FragmentTaskMessage(m_mailbox.getHSId(),
                            m_mailbox.getHSId(), msg);
                m_mailbox.send(m_sendToHSIds,
                        replmsg);
                DuplicateCounter counter;
                
                if (message.getFragmentTaskType() != FragmentTaskMessage.SYS_PROC_PER_SITE) {
                    counter = new DuplicateCounter(
                            msg.getCoordinatorHSId(),
                            msg.getTxnId(), m_replicaHSIds, "MP_DETERMINISM_ERROR");
                }
                else {
                    counter = new SysProcDuplicateCounter(
                            msg.getCoordinatorHSId(),
                            msg.getTxnId(), m_replicaHSIds, "MP_DETERMINISM_ERROR");
                }
                m_duplicateCounters.put(new DuplicateCounterKey(msg.getTxnId(), newSpHandle), counter);
            }
        }
        else {
            newSpHandle = msg.getSpHandle();
            setMaxSeenTxnId(newSpHandle);
        }
        Iv2Trace.logFragmentTaskMessage(message, m_mailbox.getHSId(), newSpHandle, false);
        doLocalFragmentOffer(msg);
    }

    
    private void doLocalFragmentOffer(FragmentTaskMessage msg)
    {
        TransactionState txn = m_outstandingTxns.get(msg.getTxnId());
        boolean logThis = false;
        
        
        
        if (txn == null) {
            txn = new ParticipantTransactionState(msg.getSpHandle(), msg);
            m_outstandingTxns.put(msg.getTxnId(), txn);
            
            
            
            
            logThis = (msg.getInitiateTask() != null && !msg.getInitiateTask().isReadOnly());
        }

        
        
        
        
        if (msg.isFinalTask() && txn.isReadOnly()) {
            m_outstandingTxns.remove(msg.getTxnId());
        }

        TransactionTask task;
        if (msg.isSysProcTask()) {
            task =
                new SysprocFragmentTask(m_mailbox, (ParticipantTransactionState)txn,
                                        m_pendingTasks, msg, null);
        }
        else {
            task =
                new FragmentTask(m_mailbox, (ParticipantTransactionState)txn,
                                 m_pendingTasks, msg, null);
        }
        if (logThis) {
            ListenableFuture<Object> durabilityBackpressureFuture =
                    m_cl.log(msg.getInitiateTask(), msg.getSpHandle(), Ints.toArray(msg.getInvolvedPartitions()),
                             m_durabilityListener, task);
            
            
            
            if (durabilityBackpressureFuture != null) {
                m_pendingTasks.offer(task.setDurabilityBackpressureFuture(durabilityBackpressureFuture));
            } else {
                
                assert !m_mpsPendingDurability.containsKey(task.getTxnId());
                m_mpsPendingDurability.put(task.getTxnId(), new ArrayDeque<TransactionTask>());
            }
        } else {
            queueOrOfferMPTask(task);
        }
    }

    
    public void offerPendingMPTasks(long txnId)
    {
        Queue<TransactionTask> pendingTasks = m_mpsPendingDurability.get(txnId);
        if (pendingTasks != null) {
            for (TransactionTask task : pendingTasks) {
                m_pendingTasks.offer(task);
            }
            m_mpsPendingDurability.remove(txnId);
        }
    }

    
    private void queueOrOfferMPTask(TransactionTask task)
    {
        
        
        Queue<TransactionTask> pendingTasks = m_mpsPendingDurability.get(task.getTxnId());
        if (pendingTasks != null) {
            pendingTasks.offer(task);
        } else {
            m_pendingTasks.offer(task);
        }
    }

    
    
    public void handleFragmentResponseMessage(FragmentResponseMessage message)
    {
        
        DuplicateCounter counter =
            m_duplicateCounters.get(new DuplicateCounterKey(message.getTxnId(), message.getSpHandle()));
        if (counter != null) {
            int result = counter.offer(message);
            if (result == DuplicateCounter.DONE) {
                m_duplicateCounters.remove(new DuplicateCounterKey(message.getTxnId(), message.getSpHandle()));
                m_repairLogTruncationHandle = message.getSpHandle();
                FragmentResponseMessage resp = (FragmentResponseMessage)counter.getLastResponse();
                
                
                resp.setExecutorSiteId(m_mailbox.getHSId());
                m_mailbox.send(counter.m_destinationId, resp);
            }
            else if (result == DuplicateCounter.MISMATCH) {
                VoltDB.crashGlobalVoltDB("HASH MISMATCH running multi-part procedure.", true, null);
            }
            
            return;
        }

        m_mailbox.send(message.getDestinationSiteId(), message);
    }

    public void handleCompleteTransactionMessage(CompleteTransactionMessage message)
    {
        CompleteTransactionMessage msg = message;
        if (m_isLeader) {
            msg = new CompleteTransactionMessage(message);
            
            
            if (!msg.isForReplay()) advanceTxnEgo();
            msg.setSpHandle(getCurrentTxnId());
            if (m_sendToHSIds.length > 0) {
                m_mailbox.send(m_sendToHSIds, msg);
            }
        } else {
            setMaxSeenTxnId(msg.getSpHandle());
        }
        TransactionState txn = m_outstandingTxns.get(msg.getTxnId());
        
        
        
        if (txn != null)
        {
            Iv2Trace.logCompleteTransactionMessage(msg, m_mailbox.getHSId());
            final CompleteTransactionTask task =
                new CompleteTransactionTask(txn, m_pendingTasks, msg, m_drGateway);
            queueOrOfferMPTask(task);
            
            if (!msg.isRestart()) {
                m_outstandingTxns.remove(msg.getTxnId());
            }
        }
    }

    public void handleIv2LogFaultMessage(Iv2LogFaultMessage message)
    {
        
        
        writeIv2ViableReplayEntryInternal(message.getSpHandle());
        setMaxSeenTxnId(message.getSpHandle());
    }

    public void handleDumpMessage()
    {
        String who = CoreUtils.hsIdToString(m_mailbox.getHSId());
        hostLog.warn("State dump for site: " + who);
        hostLog.warn("" + who + ": partition: " + m_partitionId + ", isLeader: " + m_isLeader);
        if (m_isLeader) {
            hostLog.warn("" + who + ": replicas: " + CoreUtils.hsIdCollectionToString(m_replicaHSIds));
            if (m_sendToHSIds.length > 0) {
                m_mailbox.send(m_sendToHSIds, new DumpMessage());
            }
        }
        hostLog.warn("" + who + ": most recent SP handle: " + getCurrentTxnId() + " " +
                TxnEgo.txnIdToString(getCurrentTxnId()));
        hostLog.warn("" + who + ": outstanding txns: " + m_outstandingTxns.keySet() + " " +
                TxnEgo.txnIdCollectionToString(m_outstandingTxns.keySet()));
        hostLog.warn("" + who + ": TransactionTaskQueue: " + m_pendingTasks.toString());
        if (m_duplicateCounters.size() > 0) {
            hostLog.warn("" + who + ": duplicate counters: ");
            for (Entry<DuplicateCounterKey, DuplicateCounter> e : m_duplicateCounters.entrySet()) {
                hostLog.warn("\t" + who + ": " + e.getKey().toString() + ": " + e.getValue().toString());
            }
        }
    }

    @Override
    public void setCommandLog(CommandLog cl) {
        m_cl = cl;
        m_durabilityListener.createFirstCompletionCheck(cl.isSynchronous(), m_drGatewayMP != null);
        m_cl.registerDurabilityListener(m_durabilityListener);
    }

    @Override
    public void enableWritingIv2FaultLog()
    {
        m_replayComplete = true;
        writeIv2ViableReplayEntry();
    }

    
    void writeIv2ViableReplayEntry()
    {
        if (m_replayComplete) {
            if (m_isLeader) {
                
                long faultSpHandle = advanceTxnEgo().getTxnId();
                writeIv2ViableReplayEntryInternal(faultSpHandle);
                
                Iv2LogFaultMessage faultMsg = new Iv2LogFaultMessage(faultSpHandle);
                m_mailbox.send(m_sendToHSIds,
                        faultMsg);
            }
        }
    }

    
    void writeIv2ViableReplayEntryInternal(long spHandle)
    {
        if (m_replayComplete) {
            m_cl.logIv2Fault(m_mailbox.getHSId(), new HashSet<Long>(m_replicaHSIds), m_partitionId,
                    spHandle);
        }
    }

    @Override
    public CountDownLatch snapshotCompleted(SnapshotCompletionEvent event)
    {
        if (event.truncationSnapshot && event.didSucceed) {
            synchronized(m_lock) {
                writeIv2ViableReplayEntry();
            }
        }
        return new CountDownLatch(0);
    }

    @Override
    public void dump()
    {
        m_replaySequencer.dump(m_mailbox.getHSId());
        tmLog.info(String.format("%s: %s", CoreUtils.hsIdToString(m_mailbox.getHSId()), m_pendingTasks));
    }
}

<code block>

package org.voltdb;

import java.util.Map;
import java.util.Set;

import org.voltdb.iv2.TransactionTask;
import org.voltdb.messaging.Iv2InitiateTaskMessage;

import com.google_voltpatches.common.util.concurrent.ListenableFuture;

public interface CommandLog {
    
    public abstract void init(
                                 CatalogContext context,
                                 long txnId,
                                 int partitionCount, String coreBinding,
                                 Map<Integer, Long> perPartitionTxnId);

    
    public abstract void initForRejoin(
                                          CatalogContext context,
                                          long txnId,
                                          int partitionCount, boolean isRejoin,
                                          String coreBinding, Map<Integer, Long> perPartitionTxnId);

    public abstract boolean needsInitialization();

    
    public abstract ListenableFuture<Object> log(
            Iv2InitiateTaskMessage message,
            long spHandle,
            int[] involvedPartitions,
            DurabilityListener listener,
            TransactionTask durabilityHandle);

    public abstract void shutdown() throws InterruptedException;

    
    public abstract void logIv2Fault(long writerHSId, Set<Long> survivorHSId,
            int partitionId, long spHandle);

    public interface DurabilityListener {
        
        public void createFirstCompletionCheck(boolean isSyncLogging, boolean haveMpGateway);
        
        public void onDurability();
        
        public void addTransaction(TransactionTask pendingTask);
        
        public int getNumberOfTasks();
        
        public void startNewTaskList(int nextMaxRowCnt);
    }

    
    public abstract boolean isEnabled();

    
    public void requestTruncationSnapshot(final boolean queueIfPending);

    
    public void populateCommandLogStats(Map<String, Integer> columnNameToIndex, Object[] rowValues);

    
    public abstract boolean isSynchronous();

    
    public abstract void registerDurabilityListener(DurabilityListener durabilityListener);
}

<code block>


package org.voltdb;

import java.io.IOException;
import java.lang.reflect.Constructor;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.util.Map;
import java.util.concurrent.atomic.AtomicLong;

import org.cliffc_voltpatches.high_scale_lib.NonBlockingHashMap;
import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.DBBPool;
import org.voltcore.utils.DBBPool.BBContainer;
import org.voltdb.iv2.MpInitiator;
import org.voltdb.licensetool.LicenseApi;

import com.google_voltpatches.common.base.Charsets;
import com.google_voltpatches.common.collect.ImmutableMap;


public class PartitionDRGateway {
    private static final VoltLogger log = new VoltLogger("DR");

    public enum DRRecordType {
        INSERT, DELETE, UPDATE, BEGIN_TXN, END_TXN, TRUNCATE_TABLE, DELETE_BY_INDEX;

        public static final ImmutableMap<Integer, DRRecordType> conversion;
        static {
            ImmutableMap.Builder<Integer, DRRecordType> b = ImmutableMap.builder();
            for (DRRecordType t : DRRecordType.values()) {
                b.put(t.ordinal(), t);
            }
            conversion = b.build();
        }

        public static DRRecordType valueOf(int ordinal) {
            return conversion.get(ordinal);
        }
    }

    public static final Map<Integer, PartitionDRGateway> m_partitionDRGateways = new NonBlockingHashMap<>();

    
    public static PartitionDRGateway getInstance(int partitionId,
                                                 ProducerDRGateway producerGateway,
                                                 StartAction startAction)
    {
        final VoltDBInterface vdb = VoltDB.instance();
        LicenseApi api = vdb.getLicenseApi();
        final boolean licensedToDR = api.isDrReplicationAllowed();

        
        
        PartitionDRGateway pdrg = null;
        if (licensedToDR && producerGateway != null) {
            pdrg = tryToLoadProVersion();
        }
        if (pdrg == null) {
            pdrg = new PartitionDRGateway();
        }

        
        try {
            pdrg.init(partitionId, producerGateway, startAction);
        } catch (IOException e) {
            VoltDB.crashLocalVoltDB(e.getMessage(), false, e);
        }
        m_partitionDRGateways.put(partitionId,  pdrg);

        return pdrg;
    }

    private static PartitionDRGateway tryToLoadProVersion()
    {
        try {
            Class<?> pdrgiClass = null;
            pdrgiClass = Class.forName("org.voltdb.dr2.PartitionDRGatewayImpl");
            Constructor<?> constructor = pdrgiClass.getConstructor();
            Object obj = constructor.newInstance();
            return (PartitionDRGateway) obj;
        } catch (Exception e) {
        }
        return null;
    }

    
    protected void init(int partitionId,
                        ProducerDRGateway producerGateway,
                        StartAction startAction) throws IOException {}
    public void onSuccessfulProcedureCall(long txnId, long uniqueId, int hash,
                                          StoredProcedureInvocation spi,
                                          ClientResponseImpl response) {}
    public void onSuccessfulMPCall(long spHandle, long txnId, long uniqueId, int hash,
                                   StoredProcedureInvocation spi,
                                   ClientResponseImpl response) {}
    public void onBinaryDR(int partitionId, long startSequenceNumber, long lastSequenceNumber, long lastUniqueId, ByteBuffer buf) {
        final BBContainer cont = DBBPool.wrapBB(buf);
        DBBPool.registerUnsafeMemory(cont.address());
        cont.discard();
    }

    public void uniqueIdDurable(long uniqueId) {}

    private static final ThreadLocal<AtomicLong> haveOpenTransactionLocal = new ThreadLocal<AtomicLong>() {
        @Override
        protected AtomicLong initialValue() {
            return new AtomicLong(-1);
        }
    };

    private static final ThreadLocal<AtomicLong> lastCommittedSpHandleTL = new ThreadLocal<AtomicLong>() {
        @Override
        protected AtomicLong initialValue() {
            return new AtomicLong(0);
        }
    };

    public static synchronized void pushDRBuffer(
            int partitionId,
            long startSequenceNumber,
            long lastSequenceNumber,
            long lastUniqueId,
            ByteBuffer buf) {
        if (startSequenceNumber == lastUniqueId) {
            log.trace("Received DR buffer size " + buf.remaining());
            AtomicLong haveOpenTransaction = haveOpenTransactionLocal.get();
            buf.order(ByteOrder.LITTLE_ENDIAN);
            
            buf.position(8 + 65 + (partitionId == MpInitiator.MP_INIT_PID ? 0 : 4));
            while (buf.hasRemaining()) {
                int startPosition = buf.position();
                byte version = buf.get();
                int type = buf.get();

                int checksum = 0;
                if (version != 0) log.trace("Remaining is " + buf.remaining());

                DRRecordType recordType = DRRecordType.valueOf(type);
                switch (recordType) {
                case INSERT:
                case DELETE:
                case DELETE_BY_INDEX: {
                    
                    if (haveOpenTransaction.get() == -1) {
                        log.error("Have insert/delete but no open transaction");
                        break;
                    }
                    final long tableHandle = buf.getLong();
                    final int lengthPrefix = buf.getInt();
                    final int indexCrc;
                    if (recordType == DRRecordType.DELETE_BY_INDEX) {
                        indexCrc = buf.getInt();
                    } else {
                        indexCrc = 0;
                    }
                    buf.position(buf.position() + lengthPrefix);
                    checksum = buf.getInt();
                    log.trace("Version " + version + " type " + recordType + "table handle " + tableHandle + " length " + lengthPrefix + " checksum " + checksum +
                              (recordType == DRRecordType.DELETE_BY_INDEX ? (" index checksum " + indexCrc) : ""));
                    break;
                }
                case BEGIN_TXN: {
                    
                    final long txnId = buf.getLong();
                    final long spHandle = buf.getLong();
                    if (haveOpenTransaction.get() != -1) {
                        log.error("Have open transaction txnid " + txnId + " spHandle " + spHandle + " but already open transaction");
                        break;
                    }
                    haveOpenTransaction.set(spHandle);
                    checksum = buf.getInt();
                    log.trace("Version " + version + " type BEGIN_TXN " + " txnid " + txnId + " spHandle " + spHandle + " checksum " + checksum);
                    break;
                }
                case END_TXN: {
                    
                    final long spHandle = buf.getLong();
                    if (haveOpenTransaction.get() == -1 ) {
                        log.error("Have end transaction spHandle " + spHandle + " but no open transaction and its less then last committed " + lastCommittedSpHandleTL.get().get());
                        break;
                    }
                    haveOpenTransaction.set(-1);
                    lastCommittedSpHandleTL.get().set(spHandle);
                    checksum = buf.getInt();
                    log.trace("Version " + version + " type END_TXN " + " spHandle " + spHandle + " checksum " + checksum);
                    break;
                }
                case TRUNCATE_TABLE: {
                    final long tableHandle = buf.getLong();
                    final byte tableNameBytes[] = new byte[buf.getInt()];
                    buf.get(tableNameBytes);
                    final String tableName = new String(tableNameBytes, Charsets.UTF_8);
                    checksum = buf.getInt();
                    log.trace("Version " + version + " type TRUNCATE_TABLE table handle " + tableHandle + " table name " + tableName);
                    break;
                }
                }
                int calculatedChecksum = DBBPool.getBufferCRC32C(buf, startPosition, buf.position() - startPosition - 4);
                if (calculatedChecksum != checksum) {
                    log.error("Checksum " + calculatedChecksum + " didn't match " + checksum);
                    break;
                }

            }
        }

        final PartitionDRGateway pdrg = m_partitionDRGateways.get(partitionId);
        if (pdrg == null) {
            VoltDB.crashLocalVoltDB("No PRDG when there should be", true, null);
        }
        pdrg.onBinaryDR(partitionId, startSequenceNumber, lastSequenceNumber, lastUniqueId, buf);
    }

    public void forceAllDRNodeBuffersToDisk(final boolean nofsync) {}
}

<code block>


package org.voltdb.iv2;

import java.util.ArrayDeque;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Queue;
import java.util.concurrent.CountDownLatch;

import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltcore.messaging.TransactionInfoBaseMessage;
import org.voltcore.messaging.VoltMessage;
import org.voltcore.utils.CoreUtils;
import org.voltdb.ClientResponseImpl;
import org.voltdb.CommandLog;
import org.voltdb.CommandLog.DurabilityListener;
import org.voltdb.PartitionDRGateway;
import org.voltdb.SnapshotCompletionInterest;
import org.voltdb.SnapshotCompletionMonitor;
import org.voltdb.SystemProcedureCatalog;
import org.voltdb.VoltDB;
import org.voltdb.VoltTable;
import org.voltdb.client.ClientResponse;
import org.voltdb.dtxn.TransactionState;
import org.voltdb.iv2.SiteTasker.SiteTaskerRunnable;
import org.voltdb.messaging.BorrowTaskMessage;
import org.voltdb.messaging.CompleteTransactionMessage;
import org.voltdb.messaging.DumpMessage;
import org.voltdb.messaging.FragmentResponseMessage;
import org.voltdb.messaging.FragmentTaskMessage;
import org.voltdb.messaging.InitiateResponseMessage;
import org.voltdb.messaging.Iv2InitiateTaskMessage;
import org.voltdb.messaging.Iv2LogFaultMessage;
import org.voltdb.messaging.MultiPartitionParticipantMessage;

import com.google_voltpatches.common.primitives.Ints;
import com.google_voltpatches.common.primitives.Longs;
import com.google_voltpatches.common.util.concurrent.ListenableFuture;

public class SpScheduler extends Scheduler implements SnapshotCompletionInterest
{
    static final VoltLogger tmLog = new VoltLogger("TM");

    static class DuplicateCounterKey implements Comparable<DuplicateCounterKey>
    {
        private final long m_txnId;
        private final long m_spHandle;
        transient final int m_hash;

        DuplicateCounterKey(long txnId, long spHandle)
        {
            m_txnId = txnId;
            m_spHandle = spHandle;
            m_hash = (37 * (int)(m_txnId ^ (m_txnId >>> 32))) +
                ((int)(m_spHandle ^ (m_spHandle >>> 32)));
        }

        @Override
        public boolean equals(Object o)
        {
            if (this == o) {
                return true;
            }
            if (o == null || !(getClass().isInstance(o))) {
                return false;
            }

            DuplicateCounterKey other = (DuplicateCounterKey)o;

            return (m_txnId == other.m_txnId && m_spHandle == other.m_spHandle);
        }

        
        @Override
        public int compareTo(DuplicateCounterKey o)
        {
            if (m_txnId < o.m_txnId) {
                return -1;
            } else if (m_txnId > o.m_txnId) {
                return 1;
            } else {
                if (m_spHandle < o.m_spHandle) {
                    return -1;
                }
                else if (m_spHandle > o.m_spHandle) {
                    return 1;
                }
                else {
                    return 0;
                }
            }
        }

        @Override
        public int hashCode()
        {
            return m_hash;
        }

        @Override
        public String toString()
        {
            return "<" + m_txnId + ", " + m_spHandle + ">";
        }
    };

    class SpDurabilityListener implements DurabilityListener {

        
        class CompletionChecks {
            long m_lastSpUniqueId;

            CompletionChecks(long lastSpUniqueId) {
                m_lastSpUniqueId = lastSpUniqueId;
            }

            CompletionChecks startNewCheckList(int startSize) {
                return new CompletionChecks(m_lastSpUniqueId);
            }

            void addTask(TransactionTask task) {
                m_lastSpUniqueId = task.m_txnState.uniqueId;
            }

            int getTaskListSize() {
                return 0;
            }

            void processChecks() {
                m_drGateway.uniqueIdDurable(m_lastSpUniqueId);
            }
        };

        class AsyncMpCompletionChecks extends CompletionChecks {
            long m_lastMpUniqueId;

            AsyncMpCompletionChecks(long lastSpUniqueId, long lastMpUniqueId) {
                super(lastSpUniqueId);
                m_lastMpUniqueId = lastMpUniqueId;
            }

            @Override
            CompletionChecks startNewCheckList(int startSize) {
                return new AsyncMpCompletionChecks(m_lastSpUniqueId, m_lastMpUniqueId);
            }

            @Override
            void addTask(TransactionTask task) {
                m_lastSpUniqueId = task.m_txnState.uniqueId;
                if (!task.m_txnState.isSinglePartition()) {
                    m_lastMpUniqueId = m_lastSpUniqueId;
                }
            }

            @Override
            void processChecks() {
                super.processChecks();
                m_drGatewayMP.uniqueIdDurable(m_lastMpUniqueId);
            }
        };

        class SyncSpCompletionChecks extends CompletionChecks {
            ArrayList<TransactionTask> m_pendingTransactions;

            public SyncSpCompletionChecks(long lastSpUniqueId, int startSize) {
                super(lastSpUniqueId);
                m_pendingTransactions = new ArrayList<TransactionTask>(startSize);
            }

            @Override
            CompletionChecks startNewCheckList(int startSize) {
                return new SyncSpCompletionChecks(m_lastSpUniqueId, startSize);
            }

            @Override
            void addTask(TransactionTask task) {
                m_pendingTransactions.add(task);
                m_lastSpUniqueId = task.m_txnState.uniqueId;
            }

            @Override
            public int getTaskListSize() {
                return m_pendingTransactions.size();
            }

            @Override
            void processChecks() {
                for (TransactionTask o : m_pendingTransactions) {
                    m_pendingTasks.offer(o);
                    
                    if (!o.getTransactionState().isSinglePartition()) {
                        offerPendingMPTasks(o.getTxnId());
                    }
                }
                super.processChecks();
            }
        }

        class SyncMpCompletionChecks extends SyncSpCompletionChecks {
            long m_lastMpUniqueId;

            public SyncMpCompletionChecks(long lastSpUniqueId, long lastMpUniqueId, int startSize) {
                super(lastSpUniqueId, startSize);
                m_lastMpUniqueId = lastMpUniqueId;
            }

            @Override
            CompletionChecks startNewCheckList(int startSize) {
                return new SyncMpCompletionChecks(m_lastSpUniqueId, m_lastMpUniqueId, startSize);
            }

            @Override
            void addTask(TransactionTask task) {
                m_pendingTransactions.add(task);
                m_lastSpUniqueId = task.m_txnState.uniqueId;
                if (!task.m_txnState.isSinglePartition()) {
                    m_lastMpUniqueId = m_lastSpUniqueId;
                }
            }

            @Override
            public int getTaskListSize() {
                return m_pendingTransactions.size();
            }

            @Override
            void processChecks() {
                super.processChecks();
                m_drGatewayMP.uniqueIdDurable(m_lastMpUniqueId);
            }
        }

        final ArrayDeque<CompletionChecks> m_writingTransactionLists =
                new ArrayDeque<CompletionChecks>(4);

        CompletionChecks m_currentCompletionChecks = null;

        @Override
        public void onDurability() {
            final CompletionChecks m_currentChecks = m_writingTransactionLists.poll();
            final SiteTaskerRunnable r = new SiteTasker.SiteTaskerRunnable() {
                @Override
                void run() {
                    assert(m_currentChecks != null);
                    synchronized (m_lock) {
                        m_currentChecks.processChecks();
                    }
                }
            };
            if (InitiatorMailbox.SCHEDULE_IN_SITE_THREAD) {
                m_tasks.offer(r);
            } else {
                r.run();
            }
        }

        @Override
        public void addTransaction(TransactionTask pendingTask) {
            m_currentCompletionChecks.addTask(pendingTask);
        }

        @Override
        public void startNewTaskList(int nextStartTaskListSize) {
            m_writingTransactionLists.offer(m_currentCompletionChecks);
            m_currentCompletionChecks = m_currentCompletionChecks.startNewCheckList(nextStartTaskListSize);
        }

        @Override
        public int getNumberOfTasks() {
            return m_currentCompletionChecks.getTaskListSize();
        }

        @Override
        public void createFirstCompletionCheck(boolean isSyncLogging, boolean haveMpGateway) {
            if (isSyncLogging) {
                if (haveMpGateway) {
                    m_currentCompletionChecks = new SyncMpCompletionChecks(Long.MIN_VALUE, Long.MIN_VALUE, 16);
                }
                else {
                    m_currentCompletionChecks = new SyncSpCompletionChecks(Long.MIN_VALUE, 16);
                }
            }
            else {
                if (haveMpGateway) {
                    m_currentCompletionChecks = new AsyncMpCompletionChecks(Long.MIN_VALUE, Long.MIN_VALUE);
                }
                else {
                    m_currentCompletionChecks = new CompletionChecks(Long.MIN_VALUE);
                }
            }
        }
    }


    List<Long> m_replicaHSIds = new ArrayList<Long>();
    long m_sendToHSIds[] = new long[0];

    private final TransactionTaskQueue m_pendingTasks;
    private final Map<Long, TransactionState> m_outstandingTxns =
        new HashMap<Long, TransactionState>();
    private final Map<DuplicateCounterKey, DuplicateCounter> m_duplicateCounters =
        new HashMap<DuplicateCounterKey, DuplicateCounter>();
    
    private final Map<Long, Queue<TransactionTask>> m_mpsPendingDurability =
        new HashMap<Long, Queue<TransactionTask>>();
    private CommandLog m_cl;
    private PartitionDRGateway m_drGateway = new PartitionDRGateway();
    private PartitionDRGateway m_drGatewayMP = null;
    private final SnapshotCompletionMonitor m_snapMonitor;
    
    
    boolean m_replayComplete = false;
    private final DurabilityListener m_durabilityListener;
    
    private final UniqueIdGenerator m_uniqueIdGenerator;


    
    long m_repairLogTruncationHandle = Long.MIN_VALUE;

    SpScheduler(int partitionId, SiteTaskerQueue taskQueue, SnapshotCompletionMonitor snapMonitor)
    {
        super(partitionId, taskQueue);
        m_pendingTasks = new TransactionTaskQueue(m_tasks,getCurrentTxnId());
        m_snapMonitor = snapMonitor;
        m_durabilityListener = new SpDurabilityListener();
        m_uniqueIdGenerator = new UniqueIdGenerator(partitionId, 0);
    }

    @Override
    public void setLeaderState(boolean isLeader)
    {
        super.setLeaderState(isLeader);
        m_snapMonitor.addInterest(this);
    }

    @Override
    public void setMaxSeenTxnId(long maxSeenTxnId)
    {
        super.setMaxSeenTxnId(maxSeenTxnId);
        writeIv2ViableReplayEntry();
    }

    public void setDRGateway(PartitionDRGateway gateway)
    {
        m_drGateway = gateway;
    }

    public void setMpDRGateway(final PartitionDRGateway mpGateway)
    {
        m_drGatewayMP = mpGateway;
        if (m_cl != null) {
            m_durabilityListener.createFirstCompletionCheck(m_cl.isSynchronous(), m_drGatewayMP != null);
        }
    }

    @Override
    public void shutdown()
    {
        m_tasks.offer(m_nullTask);
    }

    
    
    
    
    @Override
    public void updateReplicas(List<Long> replicas, Map<Integer, Long> partitionMasters)
    {
        
        m_replicaHSIds = replicas;
        
        List<Long> sendToHSIds = new ArrayList<Long>(m_replicaHSIds);
        sendToHSIds.remove(m_mailbox.getHSId());
        m_sendToHSIds = Longs.toArray(sendToHSIds);

        
        
        List<DuplicateCounterKey> doneCounters = new LinkedList<DuplicateCounterKey>();
        for (Entry<DuplicateCounterKey, DuplicateCounter> entry : m_duplicateCounters.entrySet()) {
            DuplicateCounter counter = entry.getValue();
            int result = counter.updateReplicas(m_replicaHSIds);
            if (result == DuplicateCounter.DONE) {
                doneCounters.add(entry.getKey());
            }
        }

        
        Collections.sort(doneCounters);
        for (DuplicateCounterKey key : doneCounters) {
            DuplicateCounter counter = m_duplicateCounters.remove(key);
            VoltMessage resp = counter.getLastResponse();
            if (resp != null) {
                
                
                if (resp instanceof FragmentResponseMessage) {
                    FragmentResponseMessage fresp = (FragmentResponseMessage)resp;
                    fresp.setExecutorSiteId(m_mailbox.getHSId());
                }
                m_mailbox.send(counter.m_destinationId, resp);
            }
            else {
                hostLog.warn("TXN " + counter.getTxnId() + " lost all replicas and " +
                        "had no responses.  This should be impossible?");
            }
        }
        writeIv2ViableReplayEntry();
    }

    
    private void deliverReadyTxns() {
        
        VoltMessage m = m_replaySequencer.poll();
        while(m != null) {
            deliver(m);
            m = m_replaySequencer.poll();
        }
        
        m = m_replaySequencer.drain();
        while (m != null) {
            if (m instanceof Iv2InitiateTaskMessage) {
                
                Iv2InitiateTaskMessage task = (Iv2InitiateTaskMessage) m;
                final InitiateResponseMessage response = new InitiateResponseMessage(task);
                response.setResults(new ClientResponseImpl(ClientResponse.UNEXPECTED_FAILURE,
                            new VoltTable[0],
                            ClientResponseImpl.IGNORED_TRANSACTION));
                m_mailbox.send(response.getInitiatorHSId(), response);
            }
            m = m_replaySequencer.drain();
        }
    }

    
    @Override
    public boolean sequenceForReplay(VoltMessage message)
    {
        boolean canDeliver = false;
        long sequenceWithTxnId = Long.MIN_VALUE;

        boolean commandLog = (message instanceof TransactionInfoBaseMessage &&
                (((TransactionInfoBaseMessage)message).isForReplay()));

        boolean dr = ((message instanceof TransactionInfoBaseMessage &&
                ((TransactionInfoBaseMessage)message).isForDR()));

        boolean sentinel = message instanceof MultiPartitionParticipantMessage;

        boolean replay = commandLog || sentinel || dr;
        boolean sequenceForReplay = m_isLeader && replay;

        assert(!(commandLog && dr));

        if (commandLog || sentinel) {
            sequenceWithTxnId = ((TransactionInfoBaseMessage)message).getTxnId();
        }
        else if (dr) {
            sequenceWithTxnId = ((TransactionInfoBaseMessage)message).getOriginalTxnId();
        }

        if (sequenceForReplay) {
            InitiateResponseMessage dupe = m_replaySequencer.dedupe(sequenceWithTxnId,
                    (TransactionInfoBaseMessage) message);
            if (dupe != null) {
                
                m_mailbox.send(dupe.getInitiatorHSId(), dupe);
            }
            else if (!m_replaySequencer.offer(sequenceWithTxnId, (TransactionInfoBaseMessage) message)) {
                canDeliver = true;
            }
            else {
                deliverReadyTxns();
            }

            
            if (sentinel && !commandLog) {
                MultiPartitionParticipantMessage mppm = (MultiPartitionParticipantMessage) message;
                final InitiateResponseMessage response = new InitiateResponseMessage(mppm);
                ClientResponseImpl clientResponse =
                        new ClientResponseImpl(ClientResponseImpl.UNEXPECTED_FAILURE,
                                new VoltTable[0], ClientResponseImpl.IGNORED_TRANSACTION);
                response.setResults(clientResponse);
                m_mailbox.send(response.getInitiatorHSId(), response);
            }
        }
        else {
            if (replay) {
                
                m_replaySequencer.updateLastSeenTxnId(sequenceWithTxnId,
                        (TransactionInfoBaseMessage) message);
                m_replaySequencer.updateLastPolledTxnId(sequenceWithTxnId,
                        (TransactionInfoBaseMessage) message);
            }

            canDeliver = true;
        }

        return canDeliver;
    }

    
    
    
    @Override
    public void deliver(VoltMessage message)
    {
        if (message instanceof Iv2InitiateTaskMessage) {
            handleIv2InitiateTaskMessage((Iv2InitiateTaskMessage)message);
        }
        else if (message instanceof InitiateResponseMessage) {
            handleInitiateResponseMessage((InitiateResponseMessage)message);
        }
        else if (message instanceof FragmentTaskMessage) {
            handleFragmentTaskMessage((FragmentTaskMessage)message);
        }
        else if (message instanceof FragmentResponseMessage) {
            handleFragmentResponseMessage((FragmentResponseMessage)message);
        }
        else if (message instanceof CompleteTransactionMessage) {
            handleCompleteTransactionMessage((CompleteTransactionMessage)message);
        }
        else if (message instanceof BorrowTaskMessage) {
            handleBorrowTaskMessage((BorrowTaskMessage)message);
        }
        else if (message instanceof Iv2LogFaultMessage) {
            handleIv2LogFaultMessage((Iv2LogFaultMessage)message);
        }
        else if (message instanceof DumpMessage) {
            handleDumpMessage();
        }
        else {
            throw new RuntimeException("UNKNOWN MESSAGE TYPE, BOOM!");
        }
    }

    private long getMaxTaskedSpHandle() {
        return m_pendingTasks.getMaxTaskedSpHandle();
    }

    
    
    public void handleIv2InitiateTaskMessage(Iv2InitiateTaskMessage message)
    {
        if (!message.isSinglePartition()) {
            throw new RuntimeException("SpScheduler.handleIv2InitiateTaskMessage " +
                    "should never receive multi-partition initiations.");
        }

        final String procedureName = message.getStoredProcedureName();
        long newSpHandle;
        long uniqueId = Long.MIN_VALUE;
        Iv2InitiateTaskMessage msg = message;
        if (m_isLeader || message.isReadOnly()) {
            
            if (!m_isLeader &&
                    CoreUtils.getHostIdFromHSId(msg.getInitiatorHSId()) !=
                    CoreUtils.getHostIdFromHSId(m_mailbox.getHSId())) {
                VoltDB.crashLocalVoltDB("Only allowed to do short circuit reads locally", true, null);
                    }

            
            if (message.isForReplay()) {
                uniqueId = message.getUniqueId();
                try {
                    m_uniqueIdGenerator.updateMostRecentlyGeneratedUniqueId(uniqueId);
                }
                catch (Exception e) {
                    hostLog.fatal(e.getMessage());
                    hostLog.fatal("Invocation: " + message);
                    VoltDB.crashLocalVoltDB(e.getMessage(), true, e);
                }
            } else if (message.isForDR()) {
                uniqueId = message.getStoredProcedureInvocation().getOriginalUniqueId();
                
                if (UniqueIdGenerator.getPartitionIdFromUniqueId(uniqueId) == m_partitionId) {
                    m_uniqueIdGenerator.updateMostRecentlyGeneratedUniqueId(uniqueId);
                }
            }

            
            if (message.isForReplay()) {
                newSpHandle = message.getTxnId();
                setMaxSeenTxnId(newSpHandle);
            } else if (m_isLeader && !message.isReadOnly()) {
                TxnEgo ego = advanceTxnEgo();
                newSpHandle = ego.getTxnId();
                uniqueId = m_uniqueIdGenerator.getNextUniqueId();
            } else {
                
                uniqueId = UniqueIdGenerator.makeIdFromComponents(
                        Math.max(System.currentTimeMillis(), m_uniqueIdGenerator.lastUsedTime),
                        0,
                        m_uniqueIdGenerator.partitionId);
                
                newSpHandle = getMaxTaskedSpHandle();
            }

            
            
            
            
            
            msg = new Iv2InitiateTaskMessage(
                    message.getInitiatorHSId(),
                    message.getCoordinatorHSId(),
                    m_repairLogTruncationHandle,
                    message.getTxnId(),
                    message.getUniqueId(),
                    message.isReadOnly(),
                    message.isSinglePartition(),
                    message.getStoredProcedureInvocation(),
                    message.getClientInterfaceHandle(),
                    message.getConnectionId(),
                    message.isForReplay());

            msg.setSpHandle(newSpHandle);

            
            
            
            if (SystemProcedureCatalog.listing.get(procedureName) == null ||
                    !SystemProcedureCatalog.listing.get(procedureName).getEverysite()) {
                msg.setTxnId(newSpHandle);
                msg.setUniqueId(uniqueId);
                    }

            
            
            if (m_isLeader && !msg.isReadOnly() && m_sendToHSIds.length > 0) {
                Iv2InitiateTaskMessage replmsg =
                    new Iv2InitiateTaskMessage(m_mailbox.getHSId(),
                            m_mailbox.getHSId(),
                            m_repairLogTruncationHandle,
                            msg.getTxnId(),
                            msg.getUniqueId(),
                            msg.isReadOnly(),
                            msg.isSinglePartition(),
                            msg.getStoredProcedureInvocation(),
                            msg.getClientInterfaceHandle(),
                            msg.getConnectionId(),
                            msg.isForReplay());
                
                replmsg.setSpHandle(newSpHandle);
                m_mailbox.send(m_sendToHSIds, replmsg);
                DuplicateCounter counter = new DuplicateCounter(
                        msg.getInitiatorHSId(),
                        msg.getTxnId(), m_replicaHSIds, msg.getStoredProcedureName());
                m_duplicateCounters.put(new DuplicateCounterKey(msg.getTxnId(), newSpHandle), counter);
            }
        }
        else {
            setMaxSeenTxnId(msg.getSpHandle());
            newSpHandle = msg.getSpHandle();
            uniqueId = msg.getUniqueId();
        }
        Iv2Trace.logIv2InitiateTaskMessage(message, m_mailbox.getHSId(), msg.getTxnId(), newSpHandle);
        doLocalInitiateOffer(msg);
        return;
    }

    
    private void doLocalInitiateOffer(Iv2InitiateTaskMessage msg)
    {
        final String procedureName = msg.getStoredProcedureName();
        final SpProcedureTask task =
            new SpProcedureTask(m_mailbox, procedureName, m_pendingTasks, msg, m_drGateway);
        if (!msg.isReadOnly()) {
            ListenableFuture<Object> durabilityBackpressureFuture =
                    m_cl.log(msg, msg.getSpHandle(), null, m_durabilityListener, task);
            
            
            
            if (durabilityBackpressureFuture != null) {
                m_pendingTasks.offer(task.setDurabilityBackpressureFuture(durabilityBackpressureFuture));
            }
        } else {
            m_pendingTasks.offer(task);
        }
    }

    @Override
    public void handleMessageRepair(List<Long> needsRepair, VoltMessage message)
    {
        if (message instanceof Iv2InitiateTaskMessage) {
            handleIv2InitiateTaskMessageRepair(needsRepair, (Iv2InitiateTaskMessage)message);
        }
        else if (message instanceof FragmentTaskMessage) {
            handleFragmentTaskMessageRepair(needsRepair, (FragmentTaskMessage)message);
        }
        else if (message instanceof CompleteTransactionMessage) {
            
            handleCompleteTransactionMessage((CompleteTransactionMessage)message);
        }
        else {
            throw new RuntimeException("SpScheduler.handleMessageRepair received unexpected message type: " +
                    message);
        }
    }

    private void handleIv2InitiateTaskMessageRepair(List<Long> needsRepair, Iv2InitiateTaskMessage message)
    {
        if (!message.isSinglePartition()) {
            throw new RuntimeException("SpScheduler.handleIv2InitiateTaskMessageRepair " +
                    "should never receive multi-partition initiations.");
        }

        
        

        
        
        

        List<Long> expectedHSIds = new ArrayList<Long>(needsRepair);
        DuplicateCounter counter = new DuplicateCounter(
                HostMessenger.VALHALLA,
                message.getTxnId(), expectedHSIds, message.getStoredProcedureName());
        m_duplicateCounters.put(new DuplicateCounterKey(message.getTxnId(), message.getSpHandle()), counter);

        m_uniqueIdGenerator.updateMostRecentlyGeneratedUniqueId(message.getUniqueId());
        
        if (needsRepair.contains(m_mailbox.getHSId())) {
            needsRepair.remove(m_mailbox.getHSId());
            
            Iv2InitiateTaskMessage localWork =
                new Iv2InitiateTaskMessage(message.getInitiatorHSId(),
                    message.getCoordinatorHSId(), message);
            doLocalInitiateOffer(localWork);
        }

        
        if (!needsRepair.isEmpty()) {
            Iv2InitiateTaskMessage replmsg =
                new Iv2InitiateTaskMessage(m_mailbox.getHSId(), m_mailbox.getHSId(), message);
            m_mailbox.send(com.google_voltpatches.common.primitives.Longs.toArray(needsRepair), replmsg);
        }
    }

    private void handleFragmentTaskMessageRepair(List<Long> needsRepair, FragmentTaskMessage message)
    {
        
        

        List<Long> expectedHSIds = new ArrayList<Long>(needsRepair);
        DuplicateCounter counter = new DuplicateCounter(
                message.getCoordinatorHSId(), 
                message.getTxnId(), expectedHSIds, "MP_DETERMINISM_ERROR");
        m_duplicateCounters.put(new DuplicateCounterKey(message.getTxnId(), message.getSpHandle()), counter);

        
        if (needsRepair.contains(m_mailbox.getHSId())) {
            
            if (m_outstandingTxns.get(message.getTxnId()) != null) {
                hostLog.warn("SPI repair attempted to repair a fragment which it has already seen. " +
                        "This shouldn't be possible.");
                
                throw new RuntimeException("Attempted to repair with a fragment we've already seen.");
            }
            needsRepair.remove(m_mailbox.getHSId());
            
            FragmentTaskMessage localWork =
                new FragmentTaskMessage(message.getInitiatorHSId(),
                    message.getCoordinatorHSId(), message);
            doLocalFragmentOffer(localWork);
        }

        
        if (!needsRepair.isEmpty()) {
            FragmentTaskMessage replmsg =
                new FragmentTaskMessage(m_mailbox.getHSId(), m_mailbox.getHSId(), message);
            m_mailbox.send(com.google_voltpatches.common.primitives.Longs.toArray(needsRepair), replmsg);
        }
    }

    
    public void handleInitiateResponseMessage(InitiateResponseMessage message)
    {
        
        
        
        
        if (message.isReadOnly()) {
            
            m_mailbox.send(message.getInitiatorHSId(), message);
            return;
        }

        final long spHandle = message.getSpHandle();
        final DuplicateCounterKey dcKey = new DuplicateCounterKey(message.getTxnId(), spHandle);
        DuplicateCounter counter = m_duplicateCounters.get(dcKey);
        if (counter != null) {
            int result = counter.offer(message);
            if (result == DuplicateCounter.DONE) {
                m_duplicateCounters.remove(dcKey);
                m_repairLogTruncationHandle = spHandle;
                m_mailbox.send(counter.m_destinationId, counter.getLastResponse());
            }
            else if (result == DuplicateCounter.MISMATCH) {
                VoltDB.crashGlobalVoltDB("HASH MISMATCH: replicas produced different results.", true, null);
            }
        }
        else {
            
            m_repairLogTruncationHandle = spHandle;
            m_mailbox.send(message.getInitiatorHSId(), message);
        }
    }

    
    
    
    private void handleBorrowTaskMessage(BorrowTaskMessage message) {
        
        
        
        long newSpHandle = getMaxTaskedSpHandle();
        Iv2Trace.logFragmentTaskMessage(message.getFragmentTaskMessage(),
                m_mailbox.getHSId(), newSpHandle, true);
        TransactionState txn = m_outstandingTxns.get(message.getTxnId());

        if (txn == null) {
            
            
            
            
            
            
            txn = new BorrowTransactionState(newSpHandle, message);
        }


        if (message.getFragmentTaskMessage().isSysProcTask()) {
            final SysprocFragmentTask task =
                new SysprocFragmentTask(m_mailbox, (ParticipantTransactionState)txn,
                                        m_pendingTasks, message.getFragmentTaskMessage(),
                                        message.getInputDepMap());
            m_pendingTasks.offer(task);
        }
        else {
            final FragmentTask task =
                new FragmentTask(m_mailbox, (ParticipantTransactionState)txn,
                        m_pendingTasks, message.getFragmentTaskMessage(),
                        message.getInputDepMap());
            m_pendingTasks.offer(task);
        }
    }

    
    
    
    
    
    
    
    
    
    void handleFragmentTaskMessage(FragmentTaskMessage message)
    {
        FragmentTaskMessage msg = message;
        long newSpHandle;
        if (m_isLeader) {
            
            
            
            msg = new FragmentTaskMessage(message.getInitiatorHSId(),
                    message.getCoordinatorHSId(), message);
            
            if (!message.isReadOnly()) {
                TxnEgo ego = advanceTxnEgo();
                newSpHandle = ego.getTxnId();
            } else {
                newSpHandle = getMaxTaskedSpHandle();
            }

            msg.setSpHandle(newSpHandle);
            if (msg.getInitiateTask() != null) {
                msg.getInitiateTask().setSpHandle(newSpHandle);
                
                msg.setStateForDurability(msg.getInitiateTask(), msg.getInvolvedPartitions());
            }

            
            if (m_sendToHSIds.length > 0 && (!msg.isReadOnly() || msg.isSysProcTask())) {
                FragmentTaskMessage replmsg =
                    new FragmentTaskMessage(m_mailbox.getHSId(),
                            m_mailbox.getHSId(), msg);
                m_mailbox.send(m_sendToHSIds,
                        replmsg);
                DuplicateCounter counter;
                
                if (message.getFragmentTaskType() != FragmentTaskMessage.SYS_PROC_PER_SITE) {
                    counter = new DuplicateCounter(
                            msg.getCoordinatorHSId(),
                            msg.getTxnId(), m_replicaHSIds, "MP_DETERMINISM_ERROR");
                }
                else {
                    counter = new SysProcDuplicateCounter(
                            msg.getCoordinatorHSId(),
                            msg.getTxnId(), m_replicaHSIds, "MP_DETERMINISM_ERROR");
                }
                m_duplicateCounters.put(new DuplicateCounterKey(msg.getTxnId(), newSpHandle), counter);
            }
        }
        else {
            newSpHandle = msg.getSpHandle();
            setMaxSeenTxnId(newSpHandle);
        }
        Iv2Trace.logFragmentTaskMessage(message, m_mailbox.getHSId(), newSpHandle, false);
        doLocalFragmentOffer(msg);
    }

    
    private void doLocalFragmentOffer(FragmentTaskMessage msg)
    {
        TransactionState txn = m_outstandingTxns.get(msg.getTxnId());
        boolean logThis = false;
        
        
        
        if (txn == null) {
            txn = new ParticipantTransactionState(msg.getSpHandle(), msg);
            m_outstandingTxns.put(msg.getTxnId(), txn);
            
            
            
            
            logThis = (msg.getInitiateTask() != null && !msg.getInitiateTask().isReadOnly());
        }

        
        
        
        
        if (msg.isFinalTask() && txn.isReadOnly()) {
            m_outstandingTxns.remove(msg.getTxnId());
        }

        TransactionTask task;
        if (msg.isSysProcTask()) {
            task =
                new SysprocFragmentTask(m_mailbox, (ParticipantTransactionState)txn,
                                        m_pendingTasks, msg, null);
        }
        else {
            task =
                new FragmentTask(m_mailbox, (ParticipantTransactionState)txn,
                                 m_pendingTasks, msg, null);
        }
        if (logThis) {
            ListenableFuture<Object> durabilityBackpressureFuture =
                    m_cl.log(msg.getInitiateTask(), msg.getSpHandle(), Ints.toArray(msg.getInvolvedPartitions()),
                             m_durabilityListener, task);
            
            
            
            if (durabilityBackpressureFuture != null) {
                m_pendingTasks.offer(task.setDurabilityBackpressureFuture(durabilityBackpressureFuture));
            } else {
                
                assert !m_mpsPendingDurability.containsKey(task.getTxnId());
                m_mpsPendingDurability.put(task.getTxnId(), new ArrayDeque<TransactionTask>());
            }
        } else {
            queueOrOfferMPTask(task);
        }
    }

    
    private void offerPendingMPTasks(long txnId)
    {
        Queue<TransactionTask> pendingTasks = m_mpsPendingDurability.get(txnId);
        if (pendingTasks != null) {
            for (TransactionTask task : pendingTasks) {
                m_pendingTasks.offer(task);
            }
            m_mpsPendingDurability.remove(txnId);
        }
    }

    
    private void queueOrOfferMPTask(TransactionTask task)
    {
        
        
        Queue<TransactionTask> pendingTasks = m_mpsPendingDurability.get(task.getTxnId());
        if (pendingTasks != null) {
            pendingTasks.offer(task);
        } else {
            m_pendingTasks.offer(task);
        }
    }

    
    
    public void handleFragmentResponseMessage(FragmentResponseMessage message)
    {
        
        DuplicateCounter counter =
            m_duplicateCounters.get(new DuplicateCounterKey(message.getTxnId(), message.getSpHandle()));
        if (counter != null) {
            int result = counter.offer(message);
            if (result == DuplicateCounter.DONE) {
                m_duplicateCounters.remove(new DuplicateCounterKey(message.getTxnId(), message.getSpHandle()));
                m_repairLogTruncationHandle = message.getSpHandle();
                FragmentResponseMessage resp = (FragmentResponseMessage)counter.getLastResponse();
                
                
                resp.setExecutorSiteId(m_mailbox.getHSId());
                m_mailbox.send(counter.m_destinationId, resp);
            }
            else if (result == DuplicateCounter.MISMATCH) {
                VoltDB.crashGlobalVoltDB("HASH MISMATCH running multi-part procedure.", true, null);
            }
            
            return;
        }

        m_mailbox.send(message.getDestinationSiteId(), message);
    }

    public void handleCompleteTransactionMessage(CompleteTransactionMessage message)
    {
        CompleteTransactionMessage msg = message;
        if (m_isLeader) {
            msg = new CompleteTransactionMessage(message);
            
            
            if (!msg.isForReplay()) advanceTxnEgo();
            msg.setSpHandle(getCurrentTxnId());
            if (m_sendToHSIds.length > 0) {
                m_mailbox.send(m_sendToHSIds, msg);
            }
        } else {
            setMaxSeenTxnId(msg.getSpHandle());
        }
        TransactionState txn = m_outstandingTxns.get(msg.getTxnId());
        
        
        
        if (txn != null)
        {
            Iv2Trace.logCompleteTransactionMessage(msg, m_mailbox.getHSId());
            final CompleteTransactionTask task =
                new CompleteTransactionTask(txn, m_pendingTasks, msg, m_drGateway);
            queueOrOfferMPTask(task);
            
            if (!msg.isRestart()) {
                m_outstandingTxns.remove(msg.getTxnId());
            }
        }
    }

    public void handleIv2LogFaultMessage(Iv2LogFaultMessage message)
    {
        
        
        writeIv2ViableReplayEntryInternal(message.getSpHandle());
        setMaxSeenTxnId(message.getSpHandle());
    }

    public void handleDumpMessage()
    {
        String who = CoreUtils.hsIdToString(m_mailbox.getHSId());
        hostLog.warn("State dump for site: " + who);
        hostLog.warn("" + who + ": partition: " + m_partitionId + ", isLeader: " + m_isLeader);
        if (m_isLeader) {
            hostLog.warn("" + who + ": replicas: " + CoreUtils.hsIdCollectionToString(m_replicaHSIds));
            if (m_sendToHSIds.length > 0) {
                m_mailbox.send(m_sendToHSIds, new DumpMessage());
            }
        }
        hostLog.warn("" + who + ": most recent SP handle: " + getCurrentTxnId() + " " +
                TxnEgo.txnIdToString(getCurrentTxnId()));
        hostLog.warn("" + who + ": outstanding txns: " + m_outstandingTxns.keySet() + " " +
                TxnEgo.txnIdCollectionToString(m_outstandingTxns.keySet()));
        hostLog.warn("" + who + ": TransactionTaskQueue: " + m_pendingTasks.toString());
        if (m_duplicateCounters.size() > 0) {
            hostLog.warn("" + who + ": duplicate counters: ");
            for (Entry<DuplicateCounterKey, DuplicateCounter> e : m_duplicateCounters.entrySet()) {
                hostLog.warn("\t" + who + ": " + e.getKey().toString() + ": " + e.getValue().toString());
            }
        }
    }

    @Override
    public void setCommandLog(CommandLog cl) {
        m_cl = cl;
        m_durabilityListener.createFirstCompletionCheck(cl.isSynchronous(), m_drGatewayMP != null);
        m_cl.registerDurabilityListener(m_durabilityListener);
    }

    @Override
    public void enableWritingIv2FaultLog()
    {
        m_replayComplete = true;
        writeIv2ViableReplayEntry();
    }

    
    void writeIv2ViableReplayEntry()
    {
        if (m_replayComplete) {
            if (m_isLeader) {
                
                long faultSpHandle = advanceTxnEgo().getTxnId();
                writeIv2ViableReplayEntryInternal(faultSpHandle);
                
                Iv2LogFaultMessage faultMsg = new Iv2LogFaultMessage(faultSpHandle);
                m_mailbox.send(m_sendToHSIds,
                        faultMsg);
            }
        }
    }

    
    void writeIv2ViableReplayEntryInternal(long spHandle)
    {
        if (m_replayComplete) {
            m_cl.logIv2Fault(m_mailbox.getHSId(), new HashSet<Long>(m_replicaHSIds), m_partitionId,
                    spHandle);
        }
    }

    @Override
    public CountDownLatch snapshotCompleted(SnapshotCompletionEvent event)
    {
        if (event.truncationSnapshot && event.didSucceed) {
            synchronized(m_lock) {
                writeIv2ViableReplayEntry();
            }
        }
        return new CountDownLatch(0);
    }

    @Override
    public void dump()
    {
        m_replaySequencer.dump(m_mailbox.getHSId());
        tmLog.info(String.format("%s: %s", CoreUtils.hsIdToString(m_mailbox.getHSId()), m_pendingTasks));
    }
}

<code block>

package exportbenchmark2.db.exportbenchmark.procedures;

import java.math.BigDecimal;
import java.math.RoundingMode;
import java.util.Random;

import org.voltdb.VoltType;
import org.voltdb.types.TimestampType;

public class SampleRecord
{
    public final long rowid;
    public final Object rowid_group;
    public final Object type_null_tinyint;
    public final Object type_not_null_tinyint;
    public final Object type_null_smallint;
    public final Object type_not_null_smallint;
    public final Object type_null_integer;
    public final Object type_not_null_integer;
    public final Object type_null_bigint;
    public final Object type_not_null_bigint;
    public final Object type_null_timestamp;
    public final Object type_not_null_timestamp;
    public final Object type_null_float;
    public final Object type_not_null_float;
    public final Object type_null_decimal;
    public final Object type_not_null_decimal;
    public final Object type_null_varchar25;
    public final Object type_not_null_varchar25;
    public final Object type_null_varchar128;
    public final Object type_not_null_varchar128;
    public final Object type_null_varchar1024;
    public final Object type_not_null_varchar1024;
    public SampleRecord(long rowid, Random rand)
    {
        this.rowid = rowid;
        this.rowid_group = (byte)((rowid % 255) - 127);
        this.type_null_tinyint          = nextTinyint(rand, true);
        this.type_not_null_tinyint      = nextTinyint(rand);
        this.type_null_smallint         = nextSmallint(rand, true);
        this.type_not_null_smallint     = nextSmallint(rand);
        this.type_null_integer          = nextInteger(rand, true);
        this.type_not_null_integer      = nextInteger(rand);
        this.type_null_bigint           = nextBigint(rand, true);
        this.type_not_null_bigint       = nextBigint(rand);
        this.type_null_timestamp        = nextTimestamp(rand, true);
        this.type_not_null_timestamp    = nextTimestamp(rand);
        this.type_null_float            = nextFloat(rand, true);
        this.type_not_null_float        = nextFloat(rand);
        this.type_null_decimal          = nextDecimal(rand, true);
        this.type_not_null_decimal      = nextDecimal(rand);
        this.type_null_varchar25        = nextVarchar(rand, true, 1, 25);
        this.type_not_null_varchar25    = nextVarchar(rand, 1, 25);
        this.type_null_varchar128       = nextVarchar(rand, true, 25, 128);
        this.type_not_null_varchar128   = nextVarchar(rand, 25, 128);
        this.type_null_varchar1024      = nextVarchar(rand, true, 128, 1024);
        this.type_not_null_varchar1024  = nextVarchar(rand, 128, 1024);
    }

    @Override
    public String toString() {
        String s = "\"" + rowid + "\",\"" + rowid_group + "\",\"" + type_null_tinyint + "\",\"" + type_not_null_tinyint +
                "\",\"" + type_null_smallint + "\",\"" + type_not_null_smallint + "\",\"" + type_null_integer +
                "\",\"" + type_not_null_integer + "\",\"" + type_null_bigint + "\",\"" + type_not_null_bigint +
                "\",\"" + type_null_timestamp + "\",\"" + type_not_null_timestamp + "\",\"" + type_null_float +
                "\",\"" + type_not_null_float + "\",\"" + type_null_decimal + "\",\"" + type_not_null_decimal +
                "\",\"" + type_null_varchar25 + "\",\"" + type_not_null_varchar25 + "\",\"" + type_null_varchar128 +
                "\",\"" + type_not_null_varchar128 + "\",\"" + type_null_varchar1024 + "\",\"" + type_not_null_varchar1024 + "\"";
        return s.replace("\"null\"", "null");   
    }

    private static Object nextTinyint(Random rand)
    {
        return nextTinyint(rand, false);
    }
    private static Object nextTinyint(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        byte result;
        do { result = (new Integer(rand.nextInt())).byteValue(); } while(result == VoltType.NULL_TINYINT);
        return result;
    }

    private static Object nextSmallint(Random rand)
    {
        return nextSmallint(rand, false);
    }
    private static Object nextSmallint(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        short result;
        do { result = (new Integer(rand.nextInt())).shortValue(); } while(result == VoltType.NULL_SMALLINT);
        return result;
    }

    private static Object nextInteger(Random rand)
    {
        return nextInteger(rand, false);
    }
    private static Object nextInteger(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        int result;
        do { result = rand.nextInt(); } while(result == VoltType.NULL_INTEGER);
        return result;
    }

    private static Object nextBigint(Random rand)
    {
        return nextBigint(rand, false);
    }
    private static Object nextBigint(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        long result;
        do { result = rand.nextLong(); } while(result == VoltType.NULL_BIGINT);
        return result;
    }

    private static Object nextTimestamp(Random rand)
    {
        return nextTimestamp(rand, false);
    }
    private static Object nextTimestamp(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        return new TimestampType(Math.abs(rand.nextInt())*1000l);
    }

    private static Object nextFloat(Random rand)
    {
        return nextFloat(rand, false);
    }
    private static Object nextFloat(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        double result; 
        do { result = rand.nextDouble(); } while(result == VoltType.NULL_FLOAT);
        return result;
    }

    private static Object nextDecimal(Random rand)
    {
        return nextDecimal(rand, false);
    }
    private static Object nextDecimal(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        return (new BigDecimal(rand.nextDouble()*rand.nextLong())).setScale(12, RoundingMode.HALF_EVEN);
    }

    private static Object nextVarchar(Random rand, int minLength, int maxLength)
    {
        return nextVarchar(rand, false, minLength, maxLength);
    }
    private static Object nextVarchar(Random rand, boolean isNullable, int minLength, int maxLength)
    {
        if (isNullable && rand.nextBoolean()) return null;
        int length = (maxLength==minLength)?maxLength:rand.nextInt(maxLength-minLength)+minLength;
        StringBuilder result = new StringBuilder(length);
        while(result.length() < length)
            result.append(Long.toBinaryString(rand.nextLong()));
        return result.toString().substring(0,Math.min(result.length(), length)-1);
    }
}

<code block>

package exportbenchmark2.db.exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES.rowid:0",
        singlePartition = true
    )

public class InsertExport0 extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT " + sqlBase);
    public final SQLStmt dbInsert = new SQLStmt("INSERT INTO ALL_VALUES " + sqlBase);

    public long run(long rowid, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();
        
        int dbInserts = 1;
        int exportInserts = 0;

        
        Random rand = new Random(txid);

        
        for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    dbInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    exportInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>

package exportbenchmark2.db.exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES.rowid:0",
        singlePartition = true
    )

public class InsertExport10 extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT " + sqlBase);
    public final SQLStmt dbInsert = new SQLStmt("INSERT INTO ALL_VALUES " + sqlBase);

    public long run(long rowid, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();
        int dbInserts = 1;
        int exportInserts = 10;

        
        Random rand = new Random(txid);

        
        for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    dbInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    exportInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>

package exportbenchmark2.db.exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES.rowid:0",
        singlePartition = true
    )

public class InsertExport1 extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT " + sqlBase);
    public final SQLStmt dbInsert = new SQLStmt("INSERT INTO ALL_VALUES " + sqlBase);

    public long run(long rowid, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();
        
        int dbInserts = 1;
        int exportInserts = 1;

        
        Random rand = new Random(txid);

        
        for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    dbInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    exportInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>




package exportbenchmark2.db.exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES1.rowid:0",
        singlePartition = true
    )

public class InsertExport extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert1 = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT1 " + sqlBase);
    public final SQLStmt exportInsert2 = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT2 " + sqlBase);
    public final SQLStmt dbInsert1 = new SQLStmt("INSERT INTO ALL_VALUES1 " + sqlBase);
    public final SQLStmt dbInsert2 = new SQLStmt("INSERT INTO ALL_VALUES2 " + sqlBase);

    public long run(long rowid, int dbInserts, int exportInserts, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();

        
        Random rand = new Random(txid);

        
       for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(dbInsert1, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);

            record = new SampleRecord(rowid, rand);
            voltQueueSQL(dbInsert2, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(exportInsert1, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);

            record = new SampleRecord(rowid, rand);
            voltQueueSQL(exportInsert2, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>

package exportbenchmark2.db.exportbenchmark.procedures;

import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

public class TruncateTables extends VoltProcedure {
    public final SQLStmt truncTable1 = new SQLStmt("TRUNCATE TABLE ALL_VALUES1");
    public final SQLStmt truncTable2 = new SQLStmt("TRUNCATE TABLE ALL_VALUES2");

    public long run()
    {
            voltQueueSQL(truncTable1);
            voltQueueSQL(truncTable2);

        
        voltExecuteSQL(true);
        return 0;
    }
}

<code block>

package exportbenchmark2.db.exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES1.rowid:0",
        singlePartition = true
    )

public class InsertExport5 extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert1 = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT1 " + sqlBase);
    public final SQLStmt exportInsert2 = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT2 " + sqlBase);
    public final SQLStmt dbInsert1 = new SQLStmt("INSERT INTO ALL_VALUES1 " + sqlBase);
    public final SQLStmt dbInsert2 = new SQLStmt("INSERT INTO ALL_VALUES2 " + sqlBase);

    public long run(long rowid, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();
        
        int dbInserts = 5;
        int exportInserts = 5;

        
        Random rand = new Random(txid);

        
        for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(dbInsert1, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);

            record = new SampleRecord(rowid, rand);
            voltQueueSQL(dbInsert2, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(exportInsert1, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128,
                record.type_not_null_varchar128,
                record.type_null_varchar1024,
                record.type_not_null_varchar1024);

            record = new SampleRecord(rowid, rand);
            voltQueueSQL(exportInsert2, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128,
                record.type_not_null_varchar128,
                record.type_null_varchar1024,
                record.type_not_null_varchar1024);
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>



package exportbenchmark2.exporter.exportbenchmark;

import java.util.Properties;

import org.voltdb.export.AdvertisedDataSource;
import org.voltdb.exportclient.ExportClientBase;
import org.voltdb.exportclient.ExportDecoderBase;

public class NoOpExporter extends ExportClientBase {

    @Override
    public void configure(Properties config) throws Exception {
        
    }

    static class NoOpExportDecoder extends ExportDecoderBase {
        NoOpExportDecoder(AdvertisedDataSource source) {
            super(source);
        }

        @Override
        public void sourceNoLongerAdvertised(AdvertisedDataSource source) {
            
            
        }

        @Override
        public boolean processRow(int rowSize, byte[] rowData) throws RestartBlockException {
            
            return true;
        }
    }

    @Override
    public ExportDecoderBase constructExportDecoder(AdvertisedDataSource source) {
        return new NoOpExportDecoder(source);
    }
}

<code block>



package exportbenchmark2.exporter.exportbenchmark;

import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.DatagramChannel;
import java.util.Properties;

import org.json_voltpatches.JSONException;
import org.json_voltpatches.JSONObject;
import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.CoreUtils;
import org.voltdb.export.AdvertisedDataSource;
import org.voltdb.exportclient.ExportClientBase;
import org.voltdb.exportclient.ExportDecoderBase;


public class SocketExporter extends ExportClientBase {

    private static final VoltLogger m_logger = new VoltLogger("ExportClient");

    String host;
    int port;
    int statsDuration;
    InetSocketAddress address;
    DatagramChannel channel;

    @Override
    public void configure(Properties config) throws Exception {
        host = config.getProperty("socket.dest", "localhost");
        port = Integer.parseInt(config.getProperty("socket.port", "5001"));
        statsDuration = Integer.parseInt(config.getProperty("stats.duration", "5"));

        if ("localhost".equals(host)) {
            address = new InetSocketAddress(CoreUtils.getLocalAddress(), port);
        } else {
            address = new InetSocketAddress(host, port);
        }
        channel = DatagramChannel.open();
    }

    class SocketExportDecoder extends ExportDecoderBase {
        long transactions = 0;
        long totalDecodeTime = 0;
        long timerStart = 0;

        SocketExportDecoder(AdvertisedDataSource source) {
            super(source);
        }

        
        public void sendStatistics() {
            if (timerStart > 0) {
                ByteBuffer buffer = ByteBuffer.allocate(1024);
                Long endTime = System.currentTimeMillis();

                
                JSONObject message = new JSONObject();
                try {
                    message.put("transactions", transactions);
                    message.put("decodeTime", totalDecodeTime);
                    message.put("startTime", timerStart);
                    message.put("endTime", endTime);
                    message.put("partitionId", m_source.partitionId);
                } catch (JSONException e) {
                    m_logger.error("Couldn't create JSON object: " + e.getLocalizedMessage());
                }

                String messageString = message.toString();
                buffer.clear();
                buffer.put((byte)messageString.length());
                buffer.put(messageString.getBytes());
                buffer.flip();

                
                try {
                    int sent = channel.send(buffer, address);
                    if (sent != messageString.getBytes().length+1) {
                        
                        m_logger.error("Error sending entire stats message");
                    }
                } catch (IOException e) {
                    m_logger.error("Couldn't send stats to socket");
                }
                transactions = 0;
                totalDecodeTime = 0;
            }
            timerStart = System.currentTimeMillis();
        }

        @Override
        public void sourceNoLongerAdvertised(AdvertisedDataSource source) {
            try {
                channel.close();
            } catch (IOException ignore) {}
        }

        @Override
        
        public boolean processRow(int rowSize, byte[] rowData) throws RestartBlockException {
            
            transactions++;

            
            try {
                long startTime = System.nanoTime();
                decodeRow(rowData);
                long endTime = System.nanoTime();

                totalDecodeTime += endTime - startTime;
            } catch (IOException e) {
                m_logger.error(e.getLocalizedMessage());
            }

            return true;
        }

        @Override
        public void onBlockCompletion() {
            if (transactions > 0)
                sendStatistics();
        }
    }

    @Override
    public ExportDecoderBase constructExportDecoder(AdvertisedDataSource source) {
        return new SocketExportDecoder(source);
    }
}
<code block>


package exportbenchmark2.client.exportbenchmark;

import java.io.IOException;
import java.util.concurrent.CountDownLatch;

import org.voltdb.client.Client;

public class Connect2Server {
    final static Client client = null;
    

    static void connectToOneServerWithRetry(String server) {
        int sleep = 1000;
        while (true) {
            try {
                client.createConnection(server);
                break;
            }
            catch (IOException e) {
                System.err.printf("Connection failed - retrying in %d second(s).\n", sleep / 1000);
                try { Thread.sleep(sleep); } catch (InterruptedException interruted) {}
                if (sleep < 8000) sleep += sleep;
            }
        }
        System.out.printf("Connected to VoltDB node at: %s.\n", server);
    }

    
    static Client connect(String servers) throws InterruptedException {
        System.out.println("Connecting to VoltDB...");

        String[] serverArray = servers.split(",");
        final CountDownLatch connections = new CountDownLatch(serverArray.length);

        
        for (final String server : serverArray) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    connectToOneServerWithRetry(server);
                    connections.countDown();
                }
            }).start();
        }
        
        connections.await();
        return client;
    }
}


<code block>



package exportbenchmark2.client.exportbenchmark;

import java.io.FileWriter;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.Selector;
import java.text.SimpleDateFormat;
import java.util.Timer;
import java.util.TimerTask;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;

import org.voltdb.CLIConfig;
import org.voltdb.VoltTable;
import org.voltdb.client.Client;
import org.voltdb.client.ClientConfig;
import org.voltdb.client.ClientFactory;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ClientStats;
import org.voltdb.client.ClientStatsContext;
import org.voltdb.client.NoConnectionsException;
import org.voltdb.client.NullCallback;
import org.voltdb.client.ProcCallException;
import org.voltdb.client.ProcedureCallback;


public class ExportBenchmark {

    
    static final String HORIZONTAL_RULE =
            "----------" + "----------" + "----------" + "----------" +
            "----------" + "----------" + "----------" + "----------" + "\n";

    
    static Client client;
    
    final ExportBenchConfig config;
    
    int ratio;
    
    Selector statsSocketSelector;
    Thread statsThread;
    ByteBuffer buffer = ByteBuffer.allocate(1024);
    
    static ClientStatsContext periodicStatsContext;
    static ClientStatsContext fullStatsContext;
    
    Timer periodicStatsTimer;
    
    long totalInserts = 0;
    AtomicLong successfulInserts = new AtomicLong(0);
    AtomicLong failedInserts = new AtomicLong(0);
    AtomicBoolean testFinished = new AtomicBoolean(false);

    
    double min = -1;
    double max = 0;
    double start = 0;
    double end = 0;

    int dbInserts;
    int exportInserts;

    
    long benchmarkStartTS, benchmarkWarmupEndTS, benchmarkEndTS, serverStartTS, serverEndTS, decodeTime, partCount;

    static long samples = 0;
    static long sampleSum = 0;

    static final SimpleDateFormat LOG_DF = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss,SSS");

    
    static class ExportBenchConfig extends CLIConfig {
        @Option(desc = "Interval for performance feedback, in seconds.")
        long displayinterval = 1;

        @Option(desc = "Benchmark duration, in seconds.")
        int duration = 30;

        @Option(desc = "Warmup duration in seconds.")
        int warmup = 10;

        @Option(desc = "Comma separated list of the form server[:port] to connect to.")
        String servers = "localhost";

        @Option (desc = "Port on which to listen for statistics info from export clients")
        int statsPort = 5001;

        @Option(desc = "Filename to write raw summary statistics to.")
        String statsfile = "";

        @Option(desc = "Filename to write periodic stat infomation in CSV format")
        String csvfile = "";

        @Override
        public void validate() {
            if (duration <= 0) exitWithMessageAndUsage("duration must be > 0");
            if (warmup < 0) exitWithMessageAndUsage("warmup must be >= 0");
            if (displayinterval <= 0) exitWithMessageAndUsage("displayinterval must be > 0");
        }
    }

    
    class ExportCallback implements ProcedureCallback {
        @Override
        public void clientCallback(ClientResponse response) {
            if (response.getStatus() == ClientResponse.SUCCESS) {
                successfulInserts.incrementAndGet();
            } else {
                failedInserts.incrementAndGet();
            }
        }
    }

    
    private void exitWithException(String message, Exception e) {
        System.err.println(message);
        System.err.println(e.getLocalizedMessage());
        System.exit(1);
    }

    
    public ExportBenchmark(ExportBenchConfig config, int dbInserts, int exportInserts) {
        this.config = config;
        this.dbInserts = dbInserts;
        this.exportInserts = exportInserts;
        samples = 0;
        sampleSum = 0;
        serverStartTS = serverEndTS = decodeTime = partCount = 0;
    }

    
    public synchronized void printStatistics() {
        ClientStats stats = periodicStatsContext.fetchAndResetBaseline().getStats();
        long time = Math.round((stats.getEndTimestamp() - benchmarkStartTS) / 1000.0);
        long thrup;

        System.out.printf("%02d:%02d:%02d ", time / 3600, (time / 60) % 60, time % 60);
        thrup = stats.getTxnThroughput();
        System.out.printf("Throughput %d/s, ", thrup);
        System.out.printf("Aborts/Failures %d/%d, ",
                stats.getInvocationAborts(), stats.getInvocationErrors());
        System.out.printf("Avg/95%% Latency %.2f/%.2fms\n", stats.getAverageLatency(),
                stats.kPercentileLatencyAsDouble(0.95));
        samples++;
        if (samples > 3) {
            sampleSum += thrup;
        }

        
        if (min == -1 || thrup < min) min = thrup;
        if (start == 0) start = thrup;
        if (thrup > max) max = thrup;
        end = thrup;
    }

    
    public void schedulePeriodicStats() {
        periodicStatsTimer = new Timer();
        TimerTask statsPrinting = new TimerTask() {
            @Override
            public void run() { printStatistics(); }
        };
        periodicStatsTimer.scheduleAtFixedRate(statsPrinting,
                                    config.displayinterval * 1000,
                                    config.displayinterval * 1000);
    }

    
    public void doInserts(Client client, int ratio) {
        
        System.out.println("Truncating DB tables");
        try {
            client.callProcedure("TruncateTables");
        } catch (IOException | ProcCallException e1) {
            e1.printStackTrace();
        }

        
        System.out.println("Warming up...");
        long now = System.currentTimeMillis();
        AtomicLong rowId = new AtomicLong(0);
        while (benchmarkWarmupEndTS > now) {
            try {
                client.callProcedure(
                        new NullCallback(),
                        "InsertExport",
                        rowId.getAndIncrement(),
                        dbInserts,
                        exportInserts,
                        0);
                
                if (++totalInserts % 50 == 0) {
                    now = System.currentTimeMillis();
                }
            } catch (Exception ignore) {}
        }
        System.out.println("Warmup complete");
        rowId.set(0);

        
        fullStatsContext.fetchAndResetBaseline();
        periodicStatsContext.fetchAndResetBaseline();

        schedulePeriodicStats();

        
        System.out.println("Running benchmark...");
        now = System.currentTimeMillis();
        while (benchmarkEndTS > now) {
            try {

                client.callProcedure(
                        new ExportCallback(),
                        "InsertExport",
                        rowId.getAndIncrement(),
                        dbInserts,
                        exportInserts,
                        0);
                
                if (++totalInserts % 50 == 0) {
                    now = System.currentTimeMillis();
                }
            } catch (Exception e) {
                System.err.println("Couldn't insert into VoltDB\n");
                e.printStackTrace();
                System.exit(1);
            }
        }

        try {
            client.drain();
        } catch (Exception e) {
            e.printStackTrace();
        }

        System.out.println("Benchmark complete: wrote " + successfulInserts.get() + " objects");
        System.out.println("Failed to insert " + failedInserts.get() + " objects");

        testFinished.set(true);
        
    }

    
    public boolean waitForStreamedAllocatedMemoryZero() throws ProcCallException,IOException,InterruptedException {
        boolean passed = false;

        VoltTable stats = null;
        long ftime = 0;
        long st = System.currentTimeMillis();
        
        long end = st + (10 * 60 * 1000);
        while (true) {
            stats = client.callProcedure("@Statistics", "table", 0).getResults()[0];
            boolean passedThisTime = true;
            long ctime = System.currentTimeMillis();
            if (ctime > end) {
                System.out.println("Waited too long...");
                System.out.println(stats);
                break;
            }
            if (ctime - st > (3 * 60 * 1000)) {
                System.out.println(stats);
                st = System.currentTimeMillis();
            }
            long ts = 0;
            while (stats.advanceRow()) {
                String ttype = stats.getString("TABLE_TYPE");
                Long tts = stats.getLong("TIMESTAMP");
                
                if (tts > ts) {
                    ts = tts;
                }
                if ("StreamedTable".equals(ttype)) {
                    if (0 != stats.getLong("TUPLE_ALLOCATED_MEMORY")) {
                        passedThisTime = false;
                        System.out.println("Partition Not Zero.");
                        break;
                    }
                }
            }
            if (passedThisTime) {
                if (ftime == 0) {
                    ftime = ts;
                    continue;
                }
                
                if (ftime != ts) {
                    passed = true;
                    break;
                }
                System.out.println("Passed but not ready to declare victory.");
            }
            Thread.sleep(5000);
        }
        System.out.println("Passed is: " + passed);
        System.out.println(stats);
        return passed;
    }

    
    private void runTest() throws InterruptedException {
        
        benchmarkStartTS = System.currentTimeMillis();
        benchmarkWarmupEndTS = benchmarkStartTS + (config.warmup * 1000);
        benchmarkEndTS = benchmarkWarmupEndTS + (config.duration * 1000);

        
        Thread writes = new Thread(new Runnable() {
            @Override
            public void run() {
                doInserts(client, ratio);
            }
        });
        writes.start();

        
        Thread.sleep(config.warmup * 1000);
        
        

        writes.join();
        periodicStatsTimer.cancel();
        System.out.println("Client flushed; waiting for export to finish");


        
        boolean success = false;
        try {
            success = waitForStreamedAllocatedMemoryZero();
        } catch (IOException e) {
            System.err.println("Error while waiting for export: ");
            e.getLocalizedMessage();
        } catch (ProcCallException e) {
            System.err.println("Error while calling procedures: ");
            e.getLocalizedMessage();
        }
        finalStats();

        
        System.out.println("Finished benchmark");
        System.out.println("Throughput");
        System.out.format("Start %6.0f, End %6.0f. Delta %6.2f%%%n" , start, end, (end-start)/start*100.0);
        System.out.format("Min %6.0f, Max %6.0f. Delta %6.2f%%%n", min, max, (max-min)/min*100.0);

        try {
            client.drain();
        } catch (NoConnectionsException e) {
            e.printStackTrace();
        }
    }

	void finalStats() {
		
		try {
			if ((config.statsfile != null) && (config.statsfile.length() != 0)) {
				FileWriter fw = new FileWriter(config.statsfile);
				fw.append(String.format("%d,%f,%f,%f,%f\n",	benchmarkStartTS, min, max, (end-start)/start*100.0, (max-min)/min*100.0));
				fw.close();
			}
		} catch (IOException e) {
			System.err.println("Error writing stats file");
			e.printStackTrace();
		}
	}

    static void connectToOneServerWithRetry(String server) {
        int sleep = 1000;
        while (true) {
            try {
                client.createConnection(server);
                break;
            }
            catch (IOException e) {
                System.err.printf("Connection failed - retrying in %d second(s).\n", sleep / 1000);
                try { Thread.sleep(sleep); } catch (InterruptedException interruted) {}
                if (sleep < 8000) sleep += sleep;
            }
        }
        System.out.printf("Connected to VoltDB node at: %s.\n", server);
    }

    
    static void connect(String servers) throws InterruptedException {
        ClientConfig clientConfig = new ClientConfig();
        clientConfig.setReconnectOnConnectionLoss(true);
        clientConfig.setClientAffinity(true);
        client = ClientFactory.createClient(clientConfig);
        fullStatsContext = client.createStatsContext();
        periodicStatsContext = client.createStatsContext();

        System.out.println("Connecting to VoltDB...");

        String[] serverArray = servers.split(",");
        final CountDownLatch connections = new CountDownLatch(serverArray.length);

        
        for (final String server : serverArray) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    connectToOneServerWithRetry(server);
                    connections.countDown();
                }
            }).start();
        }
        
        connections.await();
    }
    

    public static void main(String[] args) {
        ExportBenchConfig config = new ExportBenchConfig();
        config.parse(ExportBenchmark.class.getName(), args);
        
        final int DBINSERTS = 0;
        final int EXPORTINSERTS = 1;
        int[][] tests = {{5,5}};

        
        try {
            System.out.println("Test initialization. Servers: " + config.servers);
            connect(config.servers);
        } catch (InterruptedException e) {
            System.err.println("Error connecting to VoltDB");
            e.printStackTrace();
            System.exit(1);
        }

        for (int test = 0; test < tests.length; test++) {
            try {
                 ExportBenchmark bench = new ExportBenchmark(config, tests[test][DBINSERTS], tests[test][EXPORTINSERTS]);
                 System.out.println("Running trial " + test + " -- DB Inserts: " + tests[test][DBINSERTS] + ", Export Inserts: " + tests[test][EXPORTINSERTS]);
                 bench.runTest();
            } catch (InterruptedException e) {
                 e.printStackTrace();
            }

        }
    }
}

<code block>

package exportbenchmark.procedures;

import java.math.BigDecimal;
import java.math.RoundingMode;
import java.util.Random;

import org.voltdb.VoltType;
import org.voltdb.types.TimestampType;

public class SampleRecord
{
    public final long rowid;
    public final Object rowid_group;
    public final Object type_null_tinyint;
    public final Object type_not_null_tinyint;
    public final Object type_null_smallint;
    public final Object type_not_null_smallint;
    public final Object type_null_integer;
    public final Object type_not_null_integer;
    public final Object type_null_bigint;
    public final Object type_not_null_bigint;
    public final Object type_null_timestamp;
    public final Object type_not_null_timestamp;
    public final Object type_null_float;
    public final Object type_not_null_float;
    public final Object type_null_decimal;
    public final Object type_not_null_decimal;
    public final Object type_null_varchar25;
    public final Object type_not_null_varchar25;
    public final Object type_null_varchar128;
    public final Object type_not_null_varchar128;
    public final Object type_null_varchar1024;
    public final Object type_not_null_varchar1024;
    public SampleRecord(long rowid, Random rand)
    {
        this.rowid = rowid;
        this.rowid_group = (byte)((rowid % 255) - 127);
        this.type_null_tinyint          = nextTinyint(rand, true);
        this.type_not_null_tinyint      = nextTinyint(rand);
        this.type_null_smallint         = nextSmallint(rand, true);
        this.type_not_null_smallint     = nextSmallint(rand);
        this.type_null_integer          = nextInteger(rand, true);
        this.type_not_null_integer      = nextInteger(rand);
        this.type_null_bigint           = nextBigint(rand, true);
        this.type_not_null_bigint       = nextBigint(rand);
        this.type_null_timestamp        = nextTimestamp(rand, true);
        this.type_not_null_timestamp    = nextTimestamp(rand);
        this.type_null_float            = nextFloat(rand, true);
        this.type_not_null_float        = nextFloat(rand);
        this.type_null_decimal          = nextDecimal(rand, true);
        this.type_not_null_decimal      = nextDecimal(rand);
        this.type_null_varchar25        = nextVarchar(rand, true, 1, 25);
        this.type_not_null_varchar25    = nextVarchar(rand, 1, 25);
        this.type_null_varchar128       = nextVarchar(rand, true, 25, 128);
        this.type_not_null_varchar128   = nextVarchar(rand, 25, 128);
        this.type_null_varchar1024      = nextVarchar(rand, true, 128, 1024);
        this.type_not_null_varchar1024  = nextVarchar(rand, 128, 1024);
    }

    @Override
    public String toString() {
        String s = "\"" + rowid + "\",\"" + rowid_group + "\",\"" + type_null_tinyint + "\",\"" + type_not_null_tinyint +
                "\",\"" + type_null_smallint + "\",\"" + type_not_null_smallint + "\",\"" + type_null_integer +
                "\",\"" + type_not_null_integer + "\",\"" + type_null_bigint + "\",\"" + type_not_null_bigint +
                "\",\"" + type_null_timestamp + "\",\"" + type_not_null_timestamp + "\",\"" + type_null_float +
                "\",\"" + type_not_null_float + "\",\"" + type_null_decimal + "\",\"" + type_not_null_decimal +
                "\",\"" + type_null_varchar25 + "\",\"" + type_not_null_varchar25 + "\",\"" + type_null_varchar128 +
                "\",\"" + type_not_null_varchar128 + "\",\"" + type_null_varchar1024 + "\",\"" + type_not_null_varchar1024 + "\"";
        return s.replace("\"null\"", "null");   
    }

    private static Object nextTinyint(Random rand)
    {
        return nextTinyint(rand, false);
    }
    private static Object nextTinyint(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        byte result;
        do { result = (new Integer(rand.nextInt())).byteValue(); } while(result == VoltType.NULL_TINYINT);
        return result;
    }

    private static Object nextSmallint(Random rand)
    {
        return nextSmallint(rand, false);
    }
    private static Object nextSmallint(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        short result;
        do { result = (new Integer(rand.nextInt())).shortValue(); } while(result == VoltType.NULL_SMALLINT);
        return result;
    }

    private static Object nextInteger(Random rand)
    {
        return nextInteger(rand, false);
    }
    private static Object nextInteger(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        int result;
        do { result = rand.nextInt(); } while(result == VoltType.NULL_INTEGER);
        return result;
    }

    private static Object nextBigint(Random rand)
    {
        return nextBigint(rand, false);
    }
    private static Object nextBigint(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        long result;
        do { result = rand.nextLong(); } while(result == VoltType.NULL_BIGINT);
        return result;
    }

    private static Object nextTimestamp(Random rand)
    {
        return nextTimestamp(rand, false);
    }
    private static Object nextTimestamp(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        return new TimestampType(Math.abs(rand.nextInt())*1000l);
    }

    private static Object nextFloat(Random rand)
    {
        return nextFloat(rand, false);
    }
    private static Object nextFloat(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        double result; 
        do { result = rand.nextDouble(); } while(result == VoltType.NULL_FLOAT);
        return result;
    }

    private static Object nextDecimal(Random rand)
    {
        return nextDecimal(rand, false);
    }
    private static Object nextDecimal(Random rand, boolean isNullable)
    {
        if (isNullable && rand.nextBoolean()) return null;
        return (new BigDecimal(rand.nextDouble()*rand.nextLong())).setScale(12, RoundingMode.HALF_EVEN);
    }

    private static Object nextVarchar(Random rand, int minLength, int maxLength)
    {
        return nextVarchar(rand, false, minLength, maxLength);
    }
    private static Object nextVarchar(Random rand, boolean isNullable, int minLength, int maxLength)
    {
        if (isNullable && rand.nextBoolean()) return null;
        int length = (maxLength==minLength)?maxLength:rand.nextInt(maxLength-minLength)+minLength;
        StringBuilder result = new StringBuilder(length);
        while(result.length() < length)
            result.append(Long.toBinaryString(rand.nextLong()));
        return result.toString().substring(0,Math.min(result.length(), length)-1);
    }
}

<code block>

package exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES.rowid:0",
        singlePartition = true
    )

public class InsertExport0 extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT " + sqlBase);
    public final SQLStmt dbInsert = new SQLStmt("INSERT INTO ALL_VALUES " + sqlBase);

    public long run(long rowid, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();
        
        int dbInserts = 1;
        int exportInserts = 0;

        
        Random rand = new Random(txid);

        
        for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    dbInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    exportInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>

package exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES.rowid:0",
        singlePartition = true
    )

public class InsertExport10 extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT " + sqlBase);
    public final SQLStmt dbInsert = new SQLStmt("INSERT INTO ALL_VALUES " + sqlBase);

    public long run(long rowid, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();
        int dbInserts = 1;
        int exportInserts = 10;

        
        Random rand = new Random(txid);

        
        for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    dbInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    exportInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>

package exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES.rowid:0",
        singlePartition = true
    )

public class InsertExport1 extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT " + sqlBase);
    public final SQLStmt dbInsert = new SQLStmt("INSERT INTO ALL_VALUES " + sqlBase);

    public long run(long rowid, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();
        
        int dbInserts = 1;
        int exportInserts = 1;

        
        Random rand = new Random(txid);

        
        for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    dbInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(
                    exportInsert
                    , txid
                    , rowid
                    , record.rowid_group
                    , record.type_null_tinyint
                    , record.type_not_null_tinyint
                    , record.type_null_smallint
                    , record.type_not_null_smallint
                    , record.type_null_integer
                    , record.type_not_null_integer
                    , record.type_null_bigint
                    , record.type_not_null_bigint
                    , record.type_null_timestamp
                    , record.type_not_null_timestamp
                    , record.type_null_float
                    , record.type_not_null_float
                    , record.type_null_decimal
                    , record.type_not_null_decimal
                    , record.type_null_varchar25
                    , record.type_not_null_varchar25
                    , record.type_null_varchar128
                    , record.type_not_null_varchar128
                    , record.type_null_varchar1024
                    , record.type_not_null_varchar1024
                    );
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>

package exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES1.rowid:0",
        singlePartition = true
    )

public class InsertExport extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert1 = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT1 " + sqlBase);
    public final SQLStmt exportInsert2 = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT2 " + sqlBase);
    public final SQLStmt dbInsert1 = new SQLStmt("INSERT INTO ALL_VALUES1 " + sqlBase);
    public final SQLStmt dbInsert2 = new SQLStmt("INSERT INTO ALL_VALUES2 " + sqlBase);

    public long run(long rowid, int dbInserts, int exportInserts, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();
        
        
        

        
        Random rand = new Random(txid);

        
       for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(dbInsert1, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);

            record = new SampleRecord(rowid, rand);
            voltQueueSQL(dbInsert2, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(exportInsert1, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128,
                record.type_not_null_varchar128,
                record.type_null_varchar1024,
                record.type_not_null_varchar1024);

            record = new SampleRecord(rowid, rand);
            voltQueueSQL(exportInsert2, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128,
                record.type_not_null_varchar128,
                record.type_null_varchar1024,
                record.type_not_null_varchar1024);
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>

package exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

public class TruncateTables extends VoltProcedure {
    public final SQLStmt truncTable1 = new SQLStmt("TRUNCATE TABLE ALL_VALUES1");
    public final SQLStmt truncTable2 = new SQLStmt("TRUNCATE TABLE ALL_VALUES2");

    public long run()
    {
            voltQueueSQL(truncTable1);
            voltQueueSQL(truncTable2);

        
        voltExecuteSQL(true);
        return 0;
    }
}

<code block>

package exportbenchmark.procedures;

import java.util.Random;

import org.voltdb.ProcInfo;
import org.voltdb.SQLStmt;
import org.voltdb.VoltProcedure;

@ProcInfo(
        partitionInfo = "ALL_VALUES1.rowid:0",
        singlePartition = true
    )

public class InsertExport5 extends VoltProcedure {
    public final String sqlBase = "(txnid, rowid, rowid_group, type_null_tinyint, type_not_null_tinyint, type_null_smallint, type_not_null_smallint, "
            + "type_null_integer, type_not_null_integer, type_null_bigint, type_not_null_bigint, type_null_timestamp, type_not_null_timestamp, type_null_float, type_not_null_float, "
            + "type_null_decimal, type_not_null_decimal, type_null_varchar25, type_not_null_varchar25, type_null_varchar128, type_not_null_varchar128, type_null_varchar1024, "
            + "type_not_null_varchar1024) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    public final SQLStmt exportInsert1 = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT1 " + sqlBase);
    public final SQLStmt exportInsert2 = new SQLStmt("INSERT INTO ALL_VALUES_EXPORT2 " + sqlBase);
    public final SQLStmt dbInsert1 = new SQLStmt("INSERT INTO ALL_VALUES1 " + sqlBase);
    public final SQLStmt dbInsert2 = new SQLStmt("INSERT INTO ALL_VALUES2 " + sqlBase);

    public long run(long rowid, int reversed)
    {
        @SuppressWarnings("deprecation")
        long txid = getVoltPrivateRealTransactionIdDontUseMe();
        
        int dbInserts = 5;
        int exportInserts = 5;

        
        Random rand = new Random(txid);

        
        for (int row = 0; row < dbInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(dbInsert1, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);

            record = new SampleRecord(rowid, rand);
            voltQueueSQL(dbInsert2, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128, record.type_not_null_varchar128,
                record.type_null_varchar1024, record.type_not_null_varchar1024);
            }

        
        for (int row = 0; row < exportInserts; row++) {
            SampleRecord record = new SampleRecord(rowid, rand);
            voltQueueSQL(exportInsert1, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128,
                record.type_not_null_varchar128,
                record.type_null_varchar1024,
                record.type_not_null_varchar1024);

            record = new SampleRecord(rowid, rand);
            voltQueueSQL(exportInsert2, txid, rowid, record.rowid_group,
                record.type_null_tinyint, record.type_not_null_tinyint,
                record.type_null_smallint, record.type_not_null_smallint,
                record.type_null_integer, record.type_not_null_integer,
                record.type_null_bigint, record.type_not_null_bigint,
                record.type_null_timestamp, record.type_not_null_timestamp,
                record.type_null_float, record.type_not_null_float,
                record.type_null_decimal, record.type_not_null_decimal,
                record.type_null_varchar25, record.type_not_null_varchar25,
                record.type_null_varchar128,
                record.type_not_null_varchar128,
                record.type_null_varchar1024,
                record.type_not_null_varchar1024);
        }

        
        voltExecuteSQL(true);

        
        return txid;
    }
}

<code block>



package exportbenchmark;

import java.util.Properties;

import org.voltdb.export.AdvertisedDataSource;
import org.voltdb.exportclient.ExportClientBase;
import org.voltdb.exportclient.ExportDecoderBase;

public class NoOpExporter extends ExportClientBase {

    @Override
    public void configure(Properties config) throws Exception {
        
    }

    static class NoOpExportDecoder extends ExportDecoderBase {
        NoOpExportDecoder(AdvertisedDataSource source) {
            super(source);
        }

        @Override
        public void sourceNoLongerAdvertised(AdvertisedDataSource source) {
            
            
        }

        @Override
        public boolean processRow(int rowSize, byte[] rowData) throws RestartBlockException {
            
            return true;
        }
    }

    @Override
    public ExportDecoderBase constructExportDecoder(AdvertisedDataSource source) {
        return new NoOpExportDecoder(source);
    }
}

<code block>



package exportbenchmark;

import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.DatagramChannel;
import java.util.Properties;
import java.util.Timer;
import java.util.TimerTask;
import java.util.concurrent.atomic.AtomicLong;

import org.json_voltpatches.JSONException;
import org.json_voltpatches.JSONObject;
import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.CoreUtils;
import org.voltdb.export.AdvertisedDataSource;
import org.voltdb.exportclient.ExportClientBase;
import org.voltdb.exportclient.ExportDecoderBase;


public class SocketExporter extends ExportClientBase {

    private static final VoltLogger m_logger = new VoltLogger("ExportClient");

    String host;
    int port;
    int statsDuration;
    InetSocketAddress address;
    DatagramChannel channel;

    @Override
    public void configure(Properties config) throws Exception {
        host = config.getProperty("socket.dest", "localhost");
        port = Integer.parseInt(config.getProperty("socket.port", "5001"));
        statsDuration = Integer.parseInt(config.getProperty("stats.duration", "5"));

        if ("localhost".equals(host)) {
            address = new InetSocketAddress(CoreUtils.getLocalAddress(), port);
        } else {
            address = new InetSocketAddress(host, port);
        }
        channel = DatagramChannel.open();
    }

    class SocketExportDecoder extends ExportDecoderBase {
        long transactions = 0;
        long totalDecodeTime = 0;
        long timerStart = 0;

        SocketExportDecoder(AdvertisedDataSource source) {
            super(source);
        }

        
        public void sendStatistics() {
            if (timerStart > 0) {
                ByteBuffer buffer = ByteBuffer.allocate(1024);
                Long endTime = System.currentTimeMillis();

                
                JSONObject message = new JSONObject();
                try {
                    message.put("transactions", transactions);
                    message.put("decodeTime", totalDecodeTime);
                    message.put("startTime", timerStart);
                    message.put("endTime", endTime);
                    message.put("partitionId", m_source.partitionId);
                } catch (JSONException e) {
                    m_logger.error("Couldn't create JSON object: " + e.getLocalizedMessage());
                }

                String messageString = message.toString();
                buffer.clear();
                buffer.put((byte)messageString.length());
                buffer.put(messageString.getBytes());
                buffer.flip();

                
                try {
                    int sent = channel.send(buffer, address);
                    if (sent != messageString.getBytes().length+1) {
                        
                        m_logger.error("Error sending entire stats message");
                    }
                } catch (IOException e) {
                    m_logger.error("Couldn't send stats to socket");
                }
                transactions = 0;
                totalDecodeTime = 0;
            }
            timerStart = System.currentTimeMillis();
        }

        @Override
        public void sourceNoLongerAdvertised(AdvertisedDataSource source) {
            try {
                channel.close();
            } catch (IOException ignore) {}
        }

        @Override
        
        public boolean processRow(int rowSize, byte[] rowData) throws RestartBlockException {
            
            transactions++;

            
            try {
                long startTime = System.nanoTime();
                decodeRow(rowData);
                long endTime = System.nanoTime();

                totalDecodeTime += endTime - startTime;
            } catch (IOException e) {
                m_logger.error(e.getLocalizedMessage());
            }

            return true;
        }

        @Override
        public void onBlockCompletion() {
            if (transactions > 0)
                sendStatistics();
        }
    }

    @Override
    public ExportDecoderBase constructExportDecoder(AdvertisedDataSource source) {
        return new SocketExportDecoder(source);
    }
}
<code block>


package exportbenchmark;

import java.io.IOException;
import java.util.concurrent.CountDownLatch;

import org.voltdb.client.Client;

public class Connect2Server {
    final static Client client = null;
    

    static void connectToOneServerWithRetry(String server) {
        int sleep = 1000;
        while (true) {
            try {
                client.createConnection(server);
                break;
            }
            catch (IOException e) {
                System.err.printf("Connection failed - retrying in %d second(s).\n", sleep / 1000);
                try { Thread.sleep(sleep); } catch (InterruptedException interruted) {}
                if (sleep < 8000) sleep += sleep;
            }
        }
        System.out.printf("Connected to VoltDB node at: %s.\n", server);
    }

    
    static Client connect(String servers) throws InterruptedException {
        System.out.println("Connecting to VoltDB...");

        String[] serverArray = servers.split(",");
        final CountDownLatch connections = new CountDownLatch(serverArray.length);

        
        for (final String server : serverArray) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    connectToOneServerWithRetry(server);
                    connections.countDown();
                }
            }).start();
        }
        
        connections.await();
        return client;
    }
}


<code block>



package exportbenchmark;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.Selector;
import java.text.SimpleDateFormat;
import java.util.Timer;
import java.util.TimerTask;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;

import org.voltdb.CLIConfig;
import org.voltdb.client.Client;
import org.voltdb.client.ClientConfig;
import org.voltdb.client.ClientFactory;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ClientStats;
import org.voltdb.client.ClientStatsContext;
import org.voltdb.client.NoConnectionsException;
import org.voltdb.client.NullCallback;
import org.voltdb.client.ProcCallException;
import org.voltdb.client.ProcedureCallback;


public class ExportBenchmark {

    
    static final String HORIZONTAL_RULE =
            "----------" + "----------" + "----------" + "----------" +
            "----------" + "----------" + "----------" + "----------" + "\n";

    
    static Client client;
    
    final ExportBenchConfig config;
    
    int ratio;
    
    Selector statsSocketSelector;
    Thread statsThread;
    ByteBuffer buffer = ByteBuffer.allocate(1024);
    
    static ClientStatsContext periodicStatsContext;
    static ClientStatsContext fullStatsContext;
    
    Timer periodicStatsTimer;
    
    long totalInserts = 0;
    AtomicLong successfulInserts = new AtomicLong(0);
    AtomicLong failedInserts = new AtomicLong(0);
    AtomicBoolean testFinished = new AtomicBoolean(false);

    
    double min = -1;
    double max = 0;
    double start = 0;
    double end = 0;

    int dbInserts;
    int exportInserts;

    
    long benchmarkStartTS, benchmarkWarmupEndTS, benchmarkEndTS, serverStartTS, serverEndTS, decodeTime, partCount;

    static long samples = 0;
    static long sampleSum = 0;

    static final SimpleDateFormat LOG_DF = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss,SSS");

    
    static class ExportBenchConfig extends CLIConfig {
        @Option(desc = "Interval for performance feedback, in seconds.")
        long displayinterval = 1;

        @Option(desc = "Benchmark duration, in seconds.")
        int duration = 30;

        @Option(desc = "Warmup duration in seconds.")
        int warmup = 10;

        @Option(desc = "Comma separated list of the form server[:port] to connect to.")
        String servers = "localhost";

        @Option (desc = "Port on which to listen for statistics info from export clients")
        int statsPort = 5001;

        @Option(desc = "Filename to write raw summary statistics to.")
        String statsfile = "";

        @Option(desc = "Filename to write periodic stat infomation in CSV format")
        String csvfile = "";

        @Override
        public void validate() {
            if (duration <= 0) exitWithMessageAndUsage("duration must be > 0");
            if (warmup < 0) exitWithMessageAndUsage("warmup must be >= 0");
            if (displayinterval <= 0) exitWithMessageAndUsage("displayinterval must be > 0");
        }
    }

    
    class ExportCallback implements ProcedureCallback {
        @Override
        public void clientCallback(ClientResponse response) {
            if (response.getStatus() == ClientResponse.SUCCESS) {
                successfulInserts.incrementAndGet();
            } else {
                failedInserts.incrementAndGet();
            }
        }
    }

    
    private void exitWithException(String message, Exception e) {
        System.err.println(message);
        System.err.println(e.getLocalizedMessage());
        System.exit(1);
    }

    
    public ExportBenchmark(ExportBenchConfig config, int dbInserts, int exportInserts) {
        this.config = config;
        this.dbInserts = dbInserts;
        this.exportInserts = exportInserts;
        samples = 0;
        sampleSum = 0;
        serverStartTS = serverEndTS = decodeTime = partCount = 0;
    }

    
    public synchronized void printStatistics() {
        ClientStats stats = periodicStatsContext.fetchAndResetBaseline().getStats();
        long time = Math.round((stats.getEndTimestamp() - benchmarkStartTS) / 1000.0);
        long thrup;

        System.out.printf("%02d:%02d:%02d ", time / 3600, (time / 60) % 60, time % 60);
        thrup = stats.getTxnThroughput();
        System.out.printf("Throughput %d/s, ", thrup);
        System.out.printf("Aborts/Failures %d/%d, ",
                stats.getInvocationAborts(), stats.getInvocationErrors());
        System.out.printf("Avg/95%% Latency %.2f/%.2fms\n", stats.getAverageLatency(),
                stats.kPercentileLatencyAsDouble(0.95));
        samples++;
        if (samples > 3) {
            sampleSum += thrup;
        }

        
        if (min == -1 || thrup < min) min = thrup;
        if (start == 0) start = thrup;
        if (thrup > max) max = thrup;
        end = thrup;
    }

    
    public void schedulePeriodicStats() {
        periodicStatsTimer = new Timer();
        TimerTask statsPrinting = new TimerTask() {
            @Override
            public void run() { printStatistics(); }
        };
        periodicStatsTimer.scheduleAtFixedRate(statsPrinting,
                                    config.displayinterval * 1000,
                                    config.displayinterval * 1000);
    }

    
    public void doInserts(Client client, int ratio) {

        
        System.out.println("Truncating DB tables");
        try {
            client.callProcedure("TruncateTables");
        } catch (IOException | ProcCallException e1) {
            
            e1.printStackTrace();
        }

        
        System.out.println("Warming up...");
        long now = System.currentTimeMillis();
        AtomicLong rowId = new AtomicLong(0);
        while (benchmarkWarmupEndTS > now) {
            try {
                client.callProcedure(
                        new NullCallback(),
                        "InsertExport",
                        rowId.getAndIncrement(),
                        dbInserts,
                        exportInserts,
                        0);
                
                if (++totalInserts % 50 == 0) {
                    now = System.currentTimeMillis();
                }
            } catch (Exception ignore) {}
        }
        System.out.println("Warmup complete");
        rowId.set(0);

        
        fullStatsContext.fetchAndResetBaseline();
        periodicStatsContext.fetchAndResetBaseline();

        schedulePeriodicStats();

        
        System.out.println("Running benchmark...");
        System.out.println("Calling SP " + "InsertExport");
        now = System.currentTimeMillis();
        while (benchmarkEndTS > now) {
            try {

                client.callProcedure(
                        new ExportCallback(),
                        "InsertExport",
                        rowId.getAndIncrement(),
                        dbInserts,
                        exportInserts,
                        0);
                
                if (++totalInserts % 50 == 0) {
                    now = System.currentTimeMillis();
                }
            } catch (Exception e) {
                System.err.println("Couldn't insert into VoltDB\n");
                e.printStackTrace();
                System.exit(1);
            }
        }

        try {
            client.drain();
        } catch (Exception e) {
            e.printStackTrace();
        }

        System.out.println("Benchmark complete: wrote " + successfulInserts.get() + " objects");
        System.out.println("Failed to insert " + failedInserts.get() + " objects");

        testFinished.set(true);
        
    }

    
    private void runTest() throws InterruptedException {
        
        benchmarkStartTS = System.currentTimeMillis();
        benchmarkWarmupEndTS = benchmarkStartTS + (config.warmup * 1000);
        benchmarkEndTS = benchmarkWarmupEndTS + (config.duration * 1000);

        
        Thread writes = new Thread(new Runnable() {
            @Override
            public void run() {
                doInserts(client, ratio);
            }
        });
        writes.start();

        
        Thread.sleep(config.warmup * 1000);
        
        

        writes.join();
        periodicStatsTimer.cancel();
        System.out.println("Client flushed; waiting for export to finish");

        boolean success = false;
        
        
        System.out.println("Finished benchmark");
        System.out.println("Throughput");
        System.out.format("Start %6.0f, End %6.0f. Delta %6.2f%%%n" , start, end, (end-start)/start*100.0);
        System.out.format("Min %6.0f, Max %6.0f. Delta %6.2f%%%n", min, max, (max-min)/min*100.0);

        try {
            client.drain();
        } catch (NoConnectionsException e) {
            
            e.printStackTrace();
        }
    }

    static void connectToOneServerWithRetry(String server) {
        int sleep = 1000;
        while (true) {
            try {
                client.createConnection(server);
                break;
            }
            catch (IOException e) {
                System.err.printf("Connection failed - retrying in %d second(s).\n", sleep / 1000);
                try { Thread.sleep(sleep); } catch (InterruptedException interruted) {}
                if (sleep < 8000) sleep += sleep;
            }
        }
        System.out.printf("Connected to VoltDB node at: %s.\n", server);
    }

    
    static void connect(String servers) throws InterruptedException {
        ClientConfig clientConfig = new ClientConfig();
        clientConfig.setReconnectOnConnectionLoss(true);
        clientConfig.setClientAffinity(true);
        client = ClientFactory.createClient(clientConfig);
        fullStatsContext = client.createStatsContext();
        periodicStatsContext = client.createStatsContext();

        System.out.println("Connecting to VoltDB...");

        String[] serverArray = servers.split(",");
        final CountDownLatch connections = new CountDownLatch(serverArray.length);

        
        for (final String server : serverArray) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    connectToOneServerWithRetry(server);
                    connections.countDown();
                }
            }).start();
        }
        
        connections.await();
    }
    

    public static void main(String[] args) {
        ExportBenchConfig config = new ExportBenchConfig();
        config.parse(ExportBenchmark.class.getName(), args);
        
        final int DBINSERTS = 0;
        final int EXPORTINSERTS = 1;
        int[][] tests = {{5,5}};

     
        try {
            System.out.println("Test initialization. Servers: " + config.servers);
            connect(config.servers);
        } catch (InterruptedException e) {
            System.err.println("Error connecting to VoltDB");
            e.printStackTrace();
            System.exit(1);
        }

        for (int test = 0; test < tests.length; test++) {
            try {
                 ExportBenchmark bench = new ExportBenchmark(config,tests[test][DBINSERTS], tests[test][EXPORTINSERTS]);
                 System.out.println("Running trial " + test + " -- DB Inserts: " + tests[test][DBINSERTS] + ", Export Inserts: " + tests[test][EXPORTINSERTS]);
                 bench.runTest();
            } catch (InterruptedException e) {
                 e.printStackTrace();
            }

        }
    }
}

<code block>
package org.voltdb.sqlparser.semantics.symtab;

import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.TreeMap;

import org.voltdb.sqlparser.syntax.symtab.ISymbolTable;
import org.voltdb.sqlparser.syntax.symtab.ITop;


public class SymbolTable implements ISymbolTable {
    ISymbolTable m_parent;
    Type         m_integerType = null;
    public class TablePair {
        Table m_table;
        String m_alias;
        public TablePair(Table aTable, String aAlias) {
            m_table = aTable;
            m_alias = aAlias;
        }
        public final Table getTable() {
            return m_table;
        }
        public final String getAlias() {
            return m_alias;
        }
    }
    List<TablePair> m_tables = new ArrayList<TablePair>();
    Map<String, Top> m_lookup = new TreeMap<String, Top>(String.CASE_INSENSITIVE_ORDER);

    public SymbolTable(SymbolTable aParent) {
        m_parent = aParent;
    }

    
    @Override
    public void define(ITop aEntity) {
        if (aEntity.getName() != null) {
            m_lookup.put(aEntity.getName(), (Top) aEntity);
        }
        if (aEntity instanceof Table) {
            m_tables.add(new TablePair((Table)aEntity, aEntity.getName()));
        }
    }

    public String toString() {
    	return m_lookup.toString();
    }

    public void addTable(Table aTable,String aAlias) {
    	m_lookup.put(aAlias, aTable);
    	m_tables.add(new TablePair(aTable, aAlias));
    }

    
    @Override
    public int size() {
        return m_lookup.size();
    }

    
    public void buildLookup(String[] args) {

    }

    
    @Override
    public boolean isEmpty() {
        return m_lookup.size() == 0;
    }
    
    @Override
    public final Top get(String aName) {
        Top ret = m_lookup.get(aName);
        if (ret == null) {
        	if (m_parent != null)
        		ret = (Top) m_parent.get(aName);
        }
        return ret;
    }

    
    @Override
    public final Type getType(String aName) { 
        Top answer = get(aName);
        if (answer != null && answer instanceof Type) {
            return (Type)answer;
        } else if (m_parent != null) {
            return (Type) m_parent.getType(aName);
        } else {
            return null;
        }
    }

    
    @Override
    public final Value getValue(String aName) {
        Top answer = get(aName);
        if (answer != null && answer instanceof Value) {
            return (Value)answer;
        }
        return null;
    }

    public final Table getTable(String aName) {
    	Top table = get(aName);
    	if (table != null && table instanceof Table)
    		return (Table)table;
    	return null;
    }

    public static ISymbolTable newStandardPrelude() {
        ISymbolTable answer = new SymbolTable(null);
        answer.define(new IntegerType("bigint", 8, 8));
        answer.define(new IntegerType("integer", 4, 4));
        answer.define(new IntegerType("tinyint", 1, 1));
        answer.define(new IntegerType("smallint", 2, 2));
        return answer;
    }

    public String getTableAliasByColumn(String aColName) {
        for (TablePair tp : m_tables) {
            Column col = tp.getTable().getColumnByName(aColName);
            if (col != null) {
                if (tp.getAlias() == null) {
                    return tp.getTable().getName();
                }
                return tp.getAlias();
            }
        }
        return null;
    }

    public String getTableNameByColumn(String aColName) {
        for (TablePair tp : m_tables) {
            Column col = tp.getTable().getColumnByName(aColName);
            if (col != null) {
                return tp.getTable().getName();
            }
        }
        return null;
    }

    public final List<TablePair> getTables() {
        return m_tables;
    }

    public final int getSize() {
    	return m_lookup.size();
    }
}

<code block>
package org.voltdb.sqlparser.semantics.grammar;

import java.util.ArrayList;
import java.util.List;

import org.antlr.v4.runtime.ANTLRErrorListener;
import org.antlr.v4.runtime.Parser;
import org.antlr.v4.runtime.RecognitionException;
import org.antlr.v4.runtime.Recognizer;
import org.antlr.v4.runtime.atn.ATNConfigSet;
import org.antlr.v4.runtime.dfa.DFA;
import org.antlr.v4.runtime.misc.NotNull;
import org.voltdb.sqlparser.semantics.symtab.CatalogAdapter;
import org.voltdb.sqlparser.semantics.symtab.Neutrino;
import org.voltdb.sqlparser.semantics.symtab.Type;
import org.voltdb.sqlparser.syntax.grammar.ErrorMessage;
import org.voltdb.sqlparser.syntax.grammar.ICatalog;
import org.voltdb.sqlparser.syntax.grammar.IInsertStatement;
import org.voltdb.sqlparser.syntax.grammar.IOperator;
import org.voltdb.sqlparser.syntax.grammar.ISelectQuery;
import org.voltdb.sqlparser.syntax.grammar.SQLParserBaseListener;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser;
import org.voltdb.sqlparser.syntax.grammar.ErrorMessage.Severity;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Column_definitionContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Column_nameContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Column_refContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Create_table_statementContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.ExpressionContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Insert_statementContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.ProjectionContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Select_statementContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Table_clauseContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Table_refContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.ValueContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Where_clauseContext;
import org.voltdb.sqlparser.syntax.symtab.IColumn;
import org.voltdb.sqlparser.syntax.symtab.IParserFactory;
import org.voltdb.sqlparser.syntax.symtab.ISymbolTable;
import org.voltdb.sqlparser.syntax.symtab.ITable;
import org.voltdb.sqlparser.syntax.symtab.IType;

public class DDLListener extends SQLParserBaseListener implements ANTLRErrorListener {
	private ITable m_currentlyCreatedTable = null;
    private ISymbolTable m_symbolTable;
    private IParserFactory m_factory;
    private ICatalog m_catalog;
    private List<ErrorMessage> m_errorMessages = new ArrayList<ErrorMessage>();
    private ISelectQuery m_selectQuery = null;
    private IInsertStatement m_insertStatement = null;

    public DDLListener(IParserFactory aFactory) {
        m_factory = aFactory;
        m_symbolTable = aFactory.getStandardPrelude();
        m_catalog = aFactory.getCatalog();
        m_selectQuery = null;
        m_insertStatement = null;
    }

    public boolean hasErrors() {
        return m_errorMessages.size() > 0;
    }

    private final void addError(int line, int col, String errorMessageFormat, Object ... args) {
        String msg = String.format(errorMessageFormat, args);
        m_errorMessages.add(new ErrorMessage(line,
                                             col,
                                             Severity.Error,
                                             msg));
    }

    public final List<ErrorMessage> getErrorMessages() {
        return m_errorMessages;
    }

    public String getErrorMessagesAsString() {
        StringBuffer sb = new StringBuffer();
        int nerrs = getErrorMessages().size();
        sb.append(String.format("\nOh, dear, there seem%s to be %serror%s here.\n",
                                nerrs > 1 ? "" : "s",
                                nerrs > 1 ? "" : "an ",
                                nerrs > 1 ? "s" : ""));
        for (ErrorMessage em : getErrorMessages()) {
            sb.append(String.format("line %d, column %d: %s\n", em.getLine(), em.getCol(), em.getMsg()));
        }
        return sb.toString();
    }

	
	@Override public void exitColumn_definition(SQLParserParser.Column_definitionContext ctx) {
	    String colName = ctx.column_name().IDENTIFIER().getText();
	    String type = ctx.type_expression().type_name().IDENTIFIER().getText();
	    Type colType = (Type) m_symbolTable.getType(type);
	    if (colType == null) {
	        addError(ctx.start.getLine(), ctx.start.getCharPositionInLine(), "Type expected");
	    } else {
	        m_currentlyCreatedTable.addColumn(colName, m_factory.newColumn(colName, colType));
	    }
	}

	
	@Override public void enterCreate_table_statement(SQLParserParser.Create_table_statementContext ctx) {
	    String tableName = ctx.table_name().IDENTIFIER().getText();
	    m_currentlyCreatedTable = m_factory.newTable(tableName);
	}
	
	@Override public void exitCreate_table_statement(SQLParserParser.Create_table_statementContext ctx) {
	    m_catalog.addTable(m_currentlyCreatedTable);
	    m_currentlyCreatedTable = null;
	}

	@Override public void enterSelect_statement(SQLParserParser.Select_statementContext ctx) {
	    m_selectQuery = m_factory.newSelectQuery(m_symbolTable);
	}
	
	@Override public void exitSelect_statement(SQLParserParser.Select_statementContext ctx) {
	    m_factory.processQuery(m_selectQuery);
	}

	
	@Override public void exitProjection(SQLParserParser.ProjectionContext ctx) {
	    String tableName = null;
	    String columnName = ctx.projection_ref().column_name().IDENTIFIER().getText();
	    String alias = null;
	    if (ctx.projection_ref().table_name() != null) {
	        tableName = ctx.projection_ref().table_name().IDENTIFIER().getText();
	    }
	    if (ctx.column_name() != null) {
	        alias = ctx.column_name().IDENTIFIER().getText();
	    }
	    m_selectQuery.addProjection(tableName, columnName, alias);
	}
	
	@Override public void exitTable_clause(SQLParserParser.Table_clauseContext ctx) {
        for (SQLParserParser.Table_refContext tr : ctx.table_ref()) {
            String tableName = tr.table_name().get(0).IDENTIFIER().getText();
            String alias = null;
            if (tr.table_name().size() > 1) {
                alias = tr.table_name().get(1).IDENTIFIER().getText();
            }
            ITable table = m_catalog.getTableByName(tableName);
            if (table == null) {
                addError(tr.start.getLine(),
                         tr.start.getCharPositionInLine(),
                         "Cannot find table %s",
                         tableName);
            }
	        m_selectQuery.addTable(table, alias);
	    }
        while(m_selectQuery.hasNeutrinos()) {
        	m_selectQuery.popNeutrino();
        }
	}
	
	@Override public void exitColumn_ref(@NotNull SQLParserParser.Column_refContext ctx) {
		String columnName = ctx.column_name().IDENTIFIER().getText();
		String tableName = null;
	    if (ctx.table_name() != null) {
	        tableName = ctx.table_name().IDENTIFIER().getText();
	    }
	    m_selectQuery.pushNeutrino(m_selectQuery.getColumnNeutrino(columnName,tableName));
	}

	
	@Override public void exitWhere_clause(SQLParserParser.Where_clauseContext ctx) {
		Neutrino ret = (Neutrino) m_selectQuery.popNeutrino();
		if (!(ret != null && ret.isBooleanExpression())) { 
			addError(ctx.start.getLine(),
			        ctx.start.getCharPositionInLine(),
			        "Boolean expression expected");
		} else {
			
			m_selectQuery.setWhereCondition(ret);
		}
	}

	
	@Override public void exitExpression(@NotNull SQLParserParser.ExpressionContext ctx) {
		List<ExpressionContext> exprs = ctx.expression();
		
		
		
		if (exprs.size() == 2) { 
		    
		    String opString;
		    IOperator op;
		    if (ctx.timesop() != null) {
		        opString = ctx.timesop().getText();
		    } else if (ctx.addop() != null) {
		        opString = ctx.addop().getText();
		    } else if (ctx.relop() != null) {
		        opString = ctx.relop().getText();
		    } else {
		        addError(ctx.start.getLine(),
		                 ctx.start.getCharPositionInLine(),
		                 "Unknown operator");
		        return;
		    }
		    op = m_factory.getExpressionOperator(opString);
		    
		    
		    
		    Neutrino rightoperand = (Neutrino) m_selectQuery.popNeutrino();
		    Neutrino leftoperand = (Neutrino) m_selectQuery.popNeutrino();
		    Neutrino answer;
		    if (op.isArithmetic()) {
    		    answer = (Neutrino) m_selectQuery.getNeutrinoMath(op,
    		                                           leftoperand,
    		                                           rightoperand);
		    } else if (op.isRelational()) {
		        answer = (Neutrino) m_selectQuery.getNeutrinoCompare(op,
		                                                  leftoperand,
		                                                  rightoperand);
		    } else if (op.isBoolean()) {
		        answer = (Neutrino) m_selectQuery.getNeutrinoBoolean(op,
		                                                  leftoperand,
		                                                  rightoperand);
		    } else {
		        addError(ctx.start.getLine(),
		                 ctx.start.getCharPositionInLine(),
		                 "Internal Error: Unknown operation kind for operator \"%s\"",
		                 opString);
		        return;
		    }
		    if (answer == null) {
		        addError(ctx.start.getLine(),
		                ctx.start.getCharPositionInLine(),
		                "Incompatible argument types %s and %s",
		                leftoperand.getType().getName(),
		                rightoperand.getType().getName());
		        return;
		    }
		    m_selectQuery.pushNeutrino(answer);
		} else { 
			Column_refContext cref = ctx.column_ref();
			if (cref != null) {
			    String tableName = (cref.table_name() != null) ? cref.table_name().IDENTIFIER().getText() : null;
			    String columnName = cref.column_name().IDENTIFIER().getText();
			    Neutrino crefNeutrino = (Neutrino) m_selectQuery.getColumnNeutrino(columnName, tableName);
			    m_selectQuery.pushNeutrino(crefNeutrino);
			} else {
			    
				if (ctx.FALSE() != null) { 
				    Type boolType = (Type) m_factory.makeBooleanType();
					m_selectQuery.pushNeutrino(
							new Neutrino(boolType,
									     m_factory.makeUnaryAST(boolType, false)));
				} else if (ctx.TRUE() != null ) { 
				    Type boolType = (Type) m_factory.makeBooleanType();
					m_selectQuery.pushNeutrino(
							new Neutrino(boolType,
									    m_factory.makeUnaryAST(boolType, true)));
				} else { 
				    Type intType = (Type) m_factory.makeIntegerType();
					m_selectQuery.pushNeutrino(
							new Neutrino(intType,
							             m_factory.makeUnaryAST(intType, Integer.valueOf(ctx.NUMBER().getText()))));
				}
			}
		}
	}

	
	@Override public void exitInsert_statement(SQLParserParser.Insert_statementContext ctx) {
	    String tableName = ctx.table_name().IDENTIFIER().getText();
	    ITable table = m_catalog.getTableByName(tableName);
	    if (table == null) {
	        addError(ctx.table_name().start.getLine(),
	                 ctx.table_name().start.getCharPositionInLine(),
	                 "Undefined table name %s",
	                 tableName);
	        return;
	    }
	    if (ctx.column_name_list().column_name().size() != ctx.values().value().size()) {
	        addError(ctx.column_name_list().start.getLine(),
	                 ctx.column_name_list().start.getCharPositionInLine(),
	                 (ctx.column_name_list().column_name().size() > ctx.values().value().size())
	                   ? "Too few values in insert statement."
	                   : "Too many values in insert statement.");
	        return;
	    }
	    m_insertStatement = m_factory.newInsertStatement();
	    m_insertStatement.addTable(table);
	    List<String> colNames = new ArrayList<String>();
	    List<IType>  colTypes = new ArrayList<IType>();
	    List<String> colVals  = new ArrayList<String>();
	    for (Column_nameContext colCtx : ctx.column_name_list().column_name()) {
	        String colName = colCtx.IDENTIFIER().getText();
	        IColumn col = table.getColumnByName(colName);
	        if (col == null) {
	            addError(colCtx.start.getLine(),
	                     colCtx.start.getCharPositionInLine(),
	                     "Undefined column name %s in table %s",
	                     colName,
	                     tableName);
	            return;
	        }
	        IType colType = col.getType();
	        colNames.add(colName);
	        colTypes.add(colType);
	    }
	    for (ValueContext val : ctx.values().value()) {
	        String valStr = val.NUMBER().getText();
	        colVals.add(valStr);
	    }
	    for (int idx = 0; idx < colNames.size(); idx += 1) {
	        m_insertStatement.addColumn(colNames.get(idx),
	                                    colTypes.get(idx),
	                                    colVals.get(idx));
	    }
	}

    @Override
    public void reportAmbiguity(Parser aArg0, DFA aArg1, int aArg2, int aArg3,
            boolean aArg4, java.util.BitSet aArg5, ATNConfigSet aArg6) {
        

    }

    @Override
    public void reportAttemptingFullContext(Parser aArg0, DFA aArg1, int aArg2,
            int aArg3, java.util.BitSet aArg4, ATNConfigSet aArg5) {
        

    }

    @Override
    public void reportContextSensitivity(Parser aArg0, DFA aArg1, int aArg2,
            int aArg3, int aArg4, ATNConfigSet aArg5) {
    }

    @Override
    public void syntaxError(Recognizer<?, ?> aArg0, Object aTokObj, int aLine,
            int aCol, String msg, RecognitionException aArg5) {
        addError(aLine, aCol, msg);
    }

    public final ISelectQuery getSelectQuery() {
        return m_selectQuery;
    }

    public final IInsertStatement getInsertStatement() {
        return m_insertStatement;
    }

    public CatalogAdapter getCatalogAdapter() {
        assert(m_catalog instanceof CatalogAdapter);
        return (CatalogAdapter)m_catalog;
    }

    protected final IParserFactory getFactory() {
        return m_factory;
    }

}

<code block>
package org.hsqldb_voltpatches;

import static java.lang.String.format;

import org.assertj.core.api.AbstractAssert;
import org.assertj.core.api.Assertions;
import org.assertj.core.api.Condition;

import java.util.Map;
import org.hsqldb_voltpatches.VoltXMLElement.VoltXMLDiff;


public class VoltXMLElementAssert extends AbstractAssert<VoltXMLElementAssert, VoltXMLElement> {

	
	public VoltXMLElementAssert(VoltXMLElement actual) {
		super(actual, VoltXMLElementAssert.class);
	}

	
	public static VoltXMLElementAssert assertThat(VoltXMLElement actual) {
		return new VoltXMLElementAssert(actual);
	}

	public VoltXMLElementAssert hasName(String name) {
		isNotNull();
		if (name == null) {
			failWithMessage("Expected null name");
		}
		if (!name.equals(actual.getUniqueName())) {
			failWithMessage("Expected name to be:\n    <%s>\nnot:\n    <%s>",
						    name, actual.getUniqueName());
		}
		return this;
	}
	
	public VoltXMLElementAssert hasAttribute(String attributeName,
			                                 String attributeValue) {
		
		isNotNull();

		
		String errorMessage = format("\nExpected attribute named <%s> to be:\n  <%s>\n but was:\n  <%s>", actual,
								     attributeValue,
								     actual.attributes.get(attributeName));
		if (!actual.attributes.get(attributeName).equals(attributeValue)) {
			throw new AssertionError(errorMessage);
		}

		
		return this;
	}

	public VoltXMLElementAssert hasChildNamed(String childName,
											  Condition<VoltXMLElement> ... conditions) {
		isNotNull();
		VoltXMLElement child = actual.findChild(childName);
		if (child == null) {
			failWithMessage(String.format("Can't find child named: <%s>", childName));
		}
		for (Condition<VoltXMLElement> cond : conditions) {
			assertThat(actual).has(cond);
		}
		return this;
	}
}

<code block>
package org.voltdb.sqlparser.symtab;

import org.assertj.core.api.AbstractAssert;
import org.assertj.core.api.Condition;
import org.assertj.core.api.Fail;
import org.voltdb.sqlparser.semantics.symtab.Column;
import org.voltdb.sqlparser.semantics.symtab.Table;


public class TableAssert extends AbstractAssert<TableAssert, Table> {

    
    public TableAssert(Table actual) {
        super(actual, TableAssert.class);
    }

    
    public static TableAssert assertThat(Table actual) {
        return new TableAssert(actual);
    }

    @SafeVarargs
	public static final Condition<Table> withColumnNamed(final String aColumnName,
                                                         final Condition<Column> ...conditions) {
        return new Condition<Table>() {
            @Override
            public boolean matches(Table aValue) {
                Column col = aValue.getColumnByName(aColumnName);
                if (col == null) {
                    Fail.fail(String.format("Expected column named <%s>", aColumnName));
                }
                for (Condition<Column> cond : conditions) {
                    org.voltdb.sqlparser.symtab.ColumnAssert.assertThat(col).has(cond);
                }
                return true;
            }
        };
    }
}

<code block>
package org.voltdb.sqlparser.symtab;

import org.assertj.core.api.AbstractAssert;
import org.assertj.core.api.Condition;
import org.voltdb.sqlparser.semantics.symtab.CatalogAdapter;
import org.voltdb.sqlparser.semantics.symtab.Table;


public class CatalogAdapterAssert extends
        AbstractAssert<CatalogAdapterAssert, CatalogAdapter> {

    
    public CatalogAdapterAssert(CatalogAdapter actual) {
        super(actual, CatalogAdapterAssert.class);
    }

    
    public static CatalogAdapterAssert assertThat(CatalogAdapter actual) {
        return new CatalogAdapterAssert(actual);
    }

    @SafeVarargs
	public final CatalogAdapterAssert hasTableNamed(String aTableName,
			 									    Condition<Table> ...conditions) {
        isNotNull();
        Table tbl = actual.getTableByName(aTableName);
        if (tbl == null) {
            failWithMessage("Expected to find a table named <%s>", aTableName);
        }
        for (Condition<Table> cond : conditions) {
            org.voltdb.sqlparser.symtab.TableAssert.assertThat(tbl).has(cond);
        }
        return this;
    }

}

<code block>
package org.voltdb.sqlparser.symtab;

import static java.lang.String.format;

import org.assertj.core.api.AbstractAssert;
import org.voltdb.sqlparser.semantics.symtab.SymbolTable;
import org.voltdb.sqlparser.semantics.symtab.Type;


public class SymbolTableAssert extends
        AbstractAssert<SymbolTableAssert, SymbolTable> {

    
    public SymbolTableAssert(SymbolTable actual) {
        super(actual, SymbolTableAssert.class);
    }

    
    public static SymbolTableAssert assertThat(SymbolTable actual) {
        return new SymbolTableAssert(actual);
    }

    
    public SymbolTableAssert isEmpty() {
    	return hasSize(0);
    }
    
    public SymbolTableAssert hasSize(int size) {
        
        isNotNull();

        
        String errorMessage = format(
                "Expected actual SymbolTable to be have size %d, but was %d.",
                size, actual.getSize());

        
        if (actual.getSize() != size) {
            throw new AssertionError(errorMessage);
        }
        
        return this;
    }

    
    public SymbolTableAssert isNotEmpty() {
        
        isNotNull();

        
        String errorMessage = format(
                "Expected actual SymbolTable not to be empty but was.", actual);

        
        if (actual.isEmpty())
            throw new AssertionError(errorMessage);

        
        return this;
    }
    
    public TypeAssert definesType(String aTypeName) {
        isNotNull();
        Type t = actual.getType(aTypeName);
        if (t == null) {
            failWithMessage("Expected type <%s> to be defined", aTypeName);
        }
        return new TypeAssert(t);
    }
}

<code block>
package org.voltdb.sqlparser.symtab;

import org.assertj.core.api.AbstractAssert;
import org.voltdb.sqlparser.semantics.symtab.Type;


public class TypeAssert extends AbstractAssert<TypeAssert, Type> {
    protected TypeAssert(Type aActual) {
        super(aActual, TypeAssert.class);
        
    }

    public TypeAssert hasName(String aTypeName) {
        isNotNull();
        if (actual.getName().equalsIgnoreCase(aTypeName)) {
            failWithMessage("Expected type named <%s>.", aTypeName);
        }
        return this;
    }

    public TypeAssert hasMaxSize(int aMaxSize) {
        isNotNull();
        if (actual.getMaxSize() != aMaxSize) {
            failWithMessage("Expected type name <%s> to have max size %d not %d",
                            actual.getName(), aMaxSize, actual.getMaxSize());
        }
        return this;
    }

    public TypeAssert hasNominalSize(int aNominalSize) {
        isNotNull();
        if (actual.getNominalSize() != aNominalSize) {
            failWithMessage("Expected type name <%s> to have nominal size %d not %d",
                            actual.getName(), aNominalSize, actual.getNominalSize());
        }
        return this;
    }
}

<code block>
package org.voltdb.sqlparser;

import org.junit.Test;
import org.voltdb.sqlparser.semantics.symtab.IntegerType;
import org.voltdb.sqlparser.semantics.symtab.SymbolTable;
import static org.voltdb.sqlparser.symtab.SymbolTableAssert.assertThat;
public class TestSymbolTable {
    @Test
    public void test() {
        SymbolTable s = new SymbolTable(null);
        assertThat(s).isEmpty();
        IntegerType bigint = new IntegerType("bigint", 8, 8);
        s.define(bigint);
        assertThat(s).hasSize(1)
                     .definesType("bigint")
                     .hasMaxSize(8)
                     .hasNominalSize(8);
    }
}

<code block>
package org.voltdb.sqlparser;

import static org.voltdb.sqlparser.symtab.CatalogAdapterAssert.assertThat;

import java.io.IOException;

import org.junit.Test;
import org.voltdb.sqlparser.semantics.grammar.DDLListener;
import org.voltdb.sqlparser.semantics.symtab.CatalogAdapter;
import org.voltdb.sqlparser.semantics.symtab.ParserFactory;
import org.voltdb.sqlparser.syntax.SQLParserDriver;
import static org.voltdb.sqlparser.symtab.CatalogAdapterAssert.assertThat;
import static org.voltdb.sqlparser.symtab.SymbolTableAssert.assertThat;
import static org.voltdb.sqlparser.symtab.ColumnAssert.withColumnTypeNamed;
import static org.voltdb.sqlparser.symtab.TableAssert.withColumnNamed;

public class TestCreateTable {

    @Test
    public void testMultiTableCreation() throws IOException {
        testDDL1("create table alpha ( id bigint );");
        testDDL2("create table beta ( id bigint not null, local tinyint not null );");
    }

    private void testDDL1(String ddl) throws IOException {
        CatalogAdapter catalog = new CatalogAdapter();
        ParserFactory factory = new ParserFactory(catalog);
        DDLListener listener = new DDLListener(factory);
        SQLParserDriver driver = new SQLParserDriver(ddl, null);
        driver.walk(listener);
        assertThat(catalog)
            .hasTableNamed("alpha",
                      withColumnNamed("id",
                                      withColumnTypeNamed("bigint")));
    }

    private void testDDL2(String ddl) throws IOException {
        CatalogAdapter catalog = new CatalogAdapter();
        ParserFactory factory = new ParserFactory(catalog);
        DDLListener listener = new DDLListener(factory);
        SQLParserDriver driver = new SQLParserDriver(ddl, null);
        driver.walk(listener);

        assertThat(catalog)
            .hasTableNamed("beta",
                      withColumnNamed("id",
                                      withColumnTypeNamed("bigint")),
                      withColumnNamed("local",
                                     withColumnTypeNamed("tinyint")));
    }
}

<code block>
package org.voltdb.sqlparser.syntax.grammar;

import java.util.ArrayList;
import java.util.List;

import org.antlr.v4.runtime.ANTLRErrorListener;
import org.antlr.v4.runtime.Parser;
import org.antlr.v4.runtime.RecognitionException;
import org.antlr.v4.runtime.Recognizer;
import org.antlr.v4.runtime.atn.ATNConfigSet;
import org.antlr.v4.runtime.dfa.DFA;
import org.antlr.v4.runtime.misc.NotNull;
import org.voltdb.sqlparser.semantics.grammar.ErrorMessage;
import org.voltdb.sqlparser.semantics.grammar.ErrorMessage.Severity;
import org.voltdb.sqlparser.semantics.symtab.CatalogAdapter;
import org.voltdb.sqlparser.semantics.symtab.Neutrino;
import org.voltdb.sqlparser.semantics.symtab.Type;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Column_nameContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Column_refContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.ExpressionContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.ValueContext;
import org.voltdb.sqlparser.syntax.symtab.IColumn;
import org.voltdb.sqlparser.syntax.symtab.IParserFactory;
import org.voltdb.sqlparser.syntax.symtab.ISymbolTable;
import org.voltdb.sqlparser.syntax.symtab.ITable;
import org.voltdb.sqlparser.syntax.symtab.IType;

public class DDLListener extends SQLParserBaseListener implements ANTLRErrorListener {
	private ITable m_currentlyCreatedTable = null;
    private ISymbolTable m_symbolTable;
    private IParserFactory m_factory;
    private ICatalog m_catalog;
    private List<ErrorMessage> m_errorMessages = new ArrayList<ErrorMessage>();
    private ISelectQuery m_selectQuery = null;
    private IInsertStatement m_insertStatement = null;

    public DDLListener(IParserFactory aFactory) {
        m_factory = aFactory;
        m_symbolTable = aFactory.getStandardPrelude();
        m_catalog = aFactory.getCatalog();
        m_selectQuery = null;
        m_insertStatement = null;
    }

    public boolean hasErrors() {
        return m_errorMessages.size() > 0;
    }

    private final void addError(int line, int col, String errorMessageFormat, Object ... args) {
        String msg = String.format(errorMessageFormat, args);
        m_errorMessages.add(new ErrorMessage(line,
                                             col,
                                             Severity.Error,
                                             msg));
    }

    public final List<ErrorMessage> getErrorMessages() {
        return m_errorMessages;
    }

    public String getErrorMessagesAsString() {
        StringBuffer sb = new StringBuffer();
        int nerrs = getErrorMessages().size();
        sb.append(String.format("\nOh, dear, there seem%s to be %serror%s here.\n",
                                nerrs > 1 ? "" : "s",
                                nerrs > 1 ? "" : "an ",
                                nerrs > 1 ? "s" : ""));
        for (ErrorMessage em : getErrorMessages()) {
            sb.append(String.format("line %d, column %d: %s\n", em.getLine(), em.getCol(), em.getMsg()));
        }
        return sb.toString();
    }

	
	@Override public void exitColumn_definition(SQLParserParser.Column_definitionContext ctx) {
	    String colName = ctx.column_name().IDENTIFIER().getText();
	    String type = ctx.type_expression().type_name().IDENTIFIER().getText();
	    Type colType = (Type) m_symbolTable.getType(type);
	    if (colType == null) {
	        addError(ctx.start.getLine(), ctx.start.getCharPositionInLine(), "Type expected");
	    } else {
	        m_currentlyCreatedTable.addColumn(colName, m_factory.newColumn(colName, colType));
	    }
	}

	
	@Override public void enterCreate_table_statement(SQLParserParser.Create_table_statementContext ctx) {
	    String tableName = ctx.table_name().IDENTIFIER().getText();
	    m_currentlyCreatedTable = m_factory.newTable(tableName);
	}
	
	@Override public void exitCreate_table_statement(SQLParserParser.Create_table_statementContext ctx) {
	    m_catalog.addTable(m_currentlyCreatedTable);
	    m_currentlyCreatedTable = null;
	}

	@Override public void enterSelect_statement(SQLParserParser.Select_statementContext ctx) {
	    m_selectQuery = m_factory.newSelectQuery(m_symbolTable);
	}
	
	@Override public void exitSelect_statement(SQLParserParser.Select_statementContext ctx) {
	    m_factory.processQuery(m_selectQuery);
	}

	
	@Override public void exitProjection(SQLParserParser.ProjectionContext ctx) {
	    String tableName = null;
	    String columnName = ctx.projection_ref().column_name().IDENTIFIER().getText();
	    String alias = null;
	    if (ctx.projection_ref().table_name() != null) {
	        tableName = ctx.projection_ref().table_name().IDENTIFIER().getText();
	    }
	    if (ctx.column_name() != null) {
	        alias = ctx.column_name().IDENTIFIER().getText();
	    }
	    m_selectQuery.addProjection(tableName, columnName, alias);
	}
	
	@Override public void exitTable_clause(SQLParserParser.Table_clauseContext ctx) {
        for (SQLParserParser.Table_refContext tr : ctx.table_ref()) {
            String tableName = tr.table_name().get(0).IDENTIFIER().getText();
            String alias = null;
            if (tr.table_name().size() > 1) {
                alias = tr.table_name().get(1).IDENTIFIER().getText();
            }
            ITable table = m_catalog.getTableByName(tableName);
            if (table == null) {
                addError(tr.start.getLine(),
                         tr.start.getCharPositionInLine(),
                         "Cannot find table %s",
                         tableName);
            }
	        m_selectQuery.addTable(table, alias);
	    }
        while(m_selectQuery.hasNeutrinos()) {
        	m_selectQuery.popNeutrino();
        }
	}
	
	@Override public void exitColumn_ref(@NotNull SQLParserParser.Column_refContext ctx) {
		String columnName = ctx.column_name().IDENTIFIER().getText();
		String tableName = null;
	    if (ctx.table_name() != null) {
	        tableName = ctx.table_name().IDENTIFIER().getText();
	    }
	    m_selectQuery.pushNeutrino(m_selectQuery.getColumnNeutrino(columnName,tableName));
	}

	
	@Override public void exitWhere_clause(SQLParserParser.Where_clauseContext ctx) {
		Neutrino ret = (Neutrino)m_selectQuery.popNeutrino();
		if (!(ret != null && ret.isBooleanExpression())) { 
			addError(ctx.start.getLine(),
			        ctx.start.getCharPositionInLine(),
			        "Boolean expression expected");
		} else {
			
			m_selectQuery.setWhereCondition(ret);
		}
	}

	
	@Override public void exitExpression(@NotNull SQLParserParser.ExpressionContext ctx) {
		List<ExpressionContext> exprs = ctx.expression();
		
		
		
		if (exprs.size() == 2) { 
		    
		    String opString;
		    IOperator op;
		    if (ctx.timesop() != null) {
		        opString = ctx.timesop().getText();
		    } else if (ctx.addop() != null) {
		        opString = ctx.addop().getText();
		    } else if (ctx.relop() != null) {
		        opString = ctx.relop().getText();
		    } else {
		        addError(ctx.start.getLine(),
		                 ctx.start.getCharPositionInLine(),
		                 "Unknown operator");
		        return;
		    }
		    op = m_factory.getExpressionOperator(opString);
		    
		    
		    
		    Neutrino rightoperand = (Neutrino)m_selectQuery.popNeutrino();
		    Neutrino leftoperand = (Neutrino)m_selectQuery.popNeutrino();
		    Neutrino answer;
		    if (op.isArithmetic()) {
    		    answer = (Neutrino)m_selectQuery.getNeutrinoMath(op,
    		                                           leftoperand,
    		                                           rightoperand);
		    } else if (op.isRelational()) {
		        answer = (Neutrino)m_selectQuery.getNeutrinoCompare(op,
		                                                  leftoperand,
		                                                  rightoperand);
		    } else if (op.isBoolean()) {
		        answer = (Neutrino)m_selectQuery.getNeutrinoBoolean(op,
		                                                  leftoperand,
		                                                  rightoperand);
		    } else {
		        addError(ctx.start.getLine(),
		                 ctx.start.getCharPositionInLine(),
		                 "Internal Error: Unknown operation kind for operator \"%s\"",
		                 opString);
		        return;
		    }
		    if (answer == null) {
		        addError(ctx.start.getLine(),
		                ctx.start.getCharPositionInLine(),
		                "Incompatible argument types %s and %s",
		                leftoperand.getType().getName(),
		                rightoperand.getType().getName());
		        return;
		    }
		    m_selectQuery.pushNeutrino(answer);
		} else { 
			Column_refContext cref = ctx.column_ref();
			if (cref != null) {
			    String tableName = (cref.table_name() != null) ? cref.table_name().IDENTIFIER().getText() : null;
			    String columnName = cref.column_name().IDENTIFIER().getText();
			    Neutrino crefNeutrino = (Neutrino)m_selectQuery.getColumnNeutrino(columnName, tableName);
			    m_selectQuery.pushNeutrino(crefNeutrino);
			} else {
			    
				if (ctx.FALSE() != null) { 
				    Type boolType = (Type) m_factory.makeBooleanType();
					m_selectQuery.pushNeutrino(
							new Neutrino(boolType,
									     m_factory.makeUnaryAST(boolType, false)));
				} else if (ctx.TRUE() != null ) { 
				    Type boolType = (Type) m_factory.makeBooleanType();
					m_selectQuery.pushNeutrino(
							new Neutrino(boolType,
									    m_factory.makeUnaryAST(boolType, true)));
				} else { 
				    Type intType = (Type) m_factory.makeIntegerType();
					m_selectQuery.pushNeutrino(
							new Neutrino(intType,
							             m_factory.makeUnaryAST(intType, Integer.valueOf(ctx.NUMBER().getText()))));
				}
			}
		}
	}

	
	@Override public void exitInsert_statement(SQLParserParser.Insert_statementContext ctx) {
	    String tableName = ctx.table_name().IDENTIFIER().getText();
	    ITable table = m_catalog.getTableByName(tableName);
	    if (table == null) {
	        addError(ctx.table_name().start.getLine(),
	                 ctx.table_name().start.getCharPositionInLine(),
	                 "Undefined table name %s",
	                 tableName);
	        return;
	    }
	    if (ctx.column_name().size() != ctx.values().value().size()) {
	        addError(ctx.column_name().get(0).start.getLine(),
	                 ctx.column_name().get(0).start.getCharPositionInLine(),
	                 (ctx.column_name().size() > ctx.values().value().size())
	                   ? "Too few values in insert statement."
	                   : "Too many values in insert statement.");
	        return;
	    }
	    m_insertStatement = m_factory.newInsertStatement();
	    m_insertStatement.addTable(table);
	    List<String> colNames = new ArrayList<String>();
	    List<IType>  colTypes = new ArrayList<IType>();
	    List<String> colVals  = new ArrayList<String>();
	    for (Column_nameContext colCtx : ctx.column_name()) {
	        String colName = colCtx.IDENTIFIER().getText();
	        IColumn col = table.getColumnByName(colName);
	        if (col == null) {
	            addError(colCtx.start.getLine(),
	                     colCtx.start.getCharPositionInLine(),
	                     "Undefined column name %s in table %s",
	                     colName,
	                     tableName);
	            return;
	        }
	        IType colType = col.getType();
	        colNames.add(colName);
	        colTypes.add(colType);
	    }
	    for (ValueContext val : ctx.values().value()) {
	        String valStr = val.NUMBER().getText();
	        colVals.add(valStr);
	    }
	    for (int idx = 0; idx < colNames.size(); idx += 1) {
	        m_insertStatement.addColumn(colNames.get(idx),
	                                    colTypes.get(idx),
	                                    colVals.get(idx));
	    }
	}

    @Override
    public void reportAmbiguity(Parser aArg0, DFA aArg1, int aArg2, int aArg3,
            boolean aArg4, java.util.BitSet aArg5, ATNConfigSet aArg6) {
        

    }

    @Override
    public void reportAttemptingFullContext(Parser aArg0, DFA aArg1, int aArg2,
            int aArg3, java.util.BitSet aArg4, ATNConfigSet aArg5) {
        

    }

    @Override
    public void reportContextSensitivity(Parser aArg0, DFA aArg1, int aArg2,
            int aArg3, int aArg4, ATNConfigSet aArg5) {
    }

    @Override
    public void syntaxError(Recognizer<?, ?> aArg0, Object aTokObj, int aLine,
            int aCol, String msg, RecognitionException aArg5) {
        addError(aLine, aCol, msg);
    }

    public final ISelectQuery getSelectQuery() {
        return m_selectQuery;
    }

    public final IInsertStatement getInsertStatement() {
        return m_insertStatement;
    }

    public CatalogAdapter getCatalogAdapter() {
        assert(m_catalog instanceof CatalogAdapter);
        return (CatalogAdapter)m_catalog;
    }

    protected final IParserFactory getFactory() {
        return m_factory;
    }

}

<code block>
package org.voltdb.sqlparser.semantics.symtab;

import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.TreeMap;

import org.voltdb.sqlparser.syntax.symtab.ISymbolTable;
import org.voltdb.sqlparser.syntax.symtab.ITop;


public class SymbolTable implements ISymbolTable {
    ISymbolTable m_parent;
    Type         m_integerType = null;
    public class TablePair {
        Table m_table;
        String m_alias;
        public TablePair(Table aTable, String aAlias) {
            m_table = aTable;
            m_alias = aAlias;
        }
        public final Table getTable() {
            return m_table;
        }
        public final String getAlias() {
            return m_alias;
        }
    }
    List<TablePair> m_tables = new ArrayList<TablePair>();
    Map<String, Top> m_lookup = new TreeMap<String, Top>(String.CASE_INSENSITIVE_ORDER);

    public SymbolTable(SymbolTable aParent) {
        m_parent = aParent;
    }

    
    @Override
    public void define(ITop aEntity) {
        if (aEntity.getName() != null) {
            m_lookup.put(aEntity.getName(), (Top) aEntity);
        }
        if (aEntity instanceof Table) {
            m_tables.add(new TablePair((Table)aEntity, aEntity.getName()));
        }
    }

    public String toString() {
    	return m_lookup.toString();
    }

    public void addTable(Table aTable,String aAlias) {
    	m_lookup.put(aAlias, aTable);
    	m_tables.add(new TablePair(aTable, aAlias));
    }

    
    @Override
    public int size() {
        return m_lookup.size();
    }

    
    public void buildLookup(String[] args) {

    }

    
    @Override
    public boolean isEmpty() {
        return m_lookup.size() == 0;
    }
    
    @Override
    public final Top get(String aName) {
        Top ret = m_lookup.get(aName);
        if (ret == null) {
        	if (m_parent != null)
        		ret = (Top) m_parent.get(aName);
        }
        return ret;
    }

    
    @Override
    public final Type getType(String aName) { 
        Top answer = get(aName);
        if (answer != null && answer instanceof Type) {
            return (Type)answer;
        } else if (m_parent != null) {
            return (Type) m_parent.getType(aName);
        } else {
            return null;
        }
    }

    
    @Override
    public final Value getValue(String aName) {
        Top answer = get(aName);
        if (answer != null && answer instanceof Value) {
            return (Value)answer;
        }
        return null;
    }

    public final Table getTable(String aName) {
    	Top table = get(aName);
    	if (table != null && table instanceof Table)
    		return (Table)table;
    	return null;
    }

    public static ISymbolTable newStandardPrelude() {
        ISymbolTable answer = new SymbolTable(null);
        answer.define(new IntegerType("bigint", 8, 8));
        answer.define(new IntegerType("integer", 4, 4));
        answer.define(new IntegerType("tinyint", 1, 1));
        answer.define(new IntegerType("smallint", 2, 2));
        return answer;
    }

    public String getTableAliasByColumn(String aColName) {
        for (TablePair tp : m_tables) {
            Column col = tp.getTable().getColumnByName(aColName);
            if (col != null) {
                if (tp.getAlias() == null) {
                    return tp.getTable().getName();
                }
                return tp.getAlias();
            }
        }
        return null;
    }

    public String getTableNameByColumn(String aColName) {
        for (TablePair tp : m_tables) {
            Column col = tp.getTable().getColumnByName(aColName);
            if (col != null) {
                return tp.getTable().getName();
            }
        }
        return null;
    }

    public final List<TablePair> getTables() {
        return m_tables;
    }
}

<code block>
package org.voltdb.sqlparser.semantics.grammar;

import java.util.ArrayList;
import java.util.List;

import org.antlr.v4.runtime.ANTLRErrorListener;
import org.antlr.v4.runtime.Parser;
import org.antlr.v4.runtime.RecognitionException;
import org.antlr.v4.runtime.Recognizer;
import org.antlr.v4.runtime.atn.ATNConfigSet;
import org.antlr.v4.runtime.dfa.DFA;
import org.antlr.v4.runtime.misc.NotNull;
import org.voltdb.sqlparser.semantics.symtab.CatalogAdapter;
import org.voltdb.sqlparser.semantics.symtab.Neutrino;
import org.voltdb.sqlparser.semantics.symtab.Type;
import org.voltdb.sqlparser.syntax.grammar.ErrorMessage;
import org.voltdb.sqlparser.syntax.grammar.ICatalog;
import org.voltdb.sqlparser.syntax.grammar.IInsertStatement;
import org.voltdb.sqlparser.syntax.grammar.IOperator;
import org.voltdb.sqlparser.syntax.grammar.ISelectQuery;
import org.voltdb.sqlparser.syntax.grammar.SQLParserBaseListener;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser;
import org.voltdb.sqlparser.syntax.grammar.ErrorMessage.Severity;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Column_definitionContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Column_nameContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Column_refContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Create_table_statementContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.ExpressionContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Insert_statementContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.ProjectionContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Select_statementContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Table_clauseContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Table_refContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.ValueContext;
import org.voltdb.sqlparser.syntax.grammar.SQLParserParser.Where_clauseContext;
import org.voltdb.sqlparser.syntax.symtab.IColumn;
import org.voltdb.sqlparser.syntax.symtab.IParserFactory;
import org.voltdb.sqlparser.syntax.symtab.ISymbolTable;
import org.voltdb.sqlparser.syntax.symtab.ITable;
import org.voltdb.sqlparser.syntax.symtab.IType;

public class DDLListener extends SQLParserBaseListener implements ANTLRErrorListener {
	private ITable m_currentlyCreatedTable = null;
    private ISymbolTable m_symbolTable;
    private IParserFactory m_factory;
    private ICatalog m_catalog;
    private List<ErrorMessage> m_errorMessages = new ArrayList<ErrorMessage>();
    private ISelectQuery m_selectQuery = null;
    private IInsertStatement m_insertStatement = null;

    public DDLListener(IParserFactory aFactory) {
        m_factory = aFactory;
        m_symbolTable = aFactory.getStandardPrelude();
        m_catalog = aFactory.getCatalog();
        m_selectQuery = null;
        m_insertStatement = null;
    }

    public boolean hasErrors() {
        return m_errorMessages.size() > 0;
    }

    private final void addError(int line, int col, String errorMessageFormat, Object ... args) {
        String msg = String.format(errorMessageFormat, args);
        m_errorMessages.add(new ErrorMessage(line,
                                             col,
                                             Severity.Error,
                                             msg));
    }

    public final List<ErrorMessage> getErrorMessages() {
        return m_errorMessages;
    }

    public String getErrorMessagesAsString() {
        StringBuffer sb = new StringBuffer();
        int nerrs = getErrorMessages().size();
        sb.append(String.format("\nOh, dear, there seem%s to be %serror%s here.\n",
                                nerrs > 1 ? "" : "s",
                                nerrs > 1 ? "" : "an ",
                                nerrs > 1 ? "s" : ""));
        for (ErrorMessage em : getErrorMessages()) {
            sb.append(String.format("line %d, column %d: %s\n", em.getLine(), em.getCol(), em.getMsg()));
        }
        return sb.toString();
    }

	
	@Override public void exitColumn_definition(SQLParserParser.Column_definitionContext ctx) {
	    String colName = ctx.column_name().IDENTIFIER().getText();
	    String type = ctx.type_expression().type_name().IDENTIFIER().getText();
	    Type colType = (Type) m_symbolTable.getType(type);
	    if (colType == null) {
	        addError(ctx.start.getLine(), ctx.start.getCharPositionInLine(), "Type expected");
	    } else {
	        m_currentlyCreatedTable.addColumn(colName, m_factory.newColumn(colName, colType));
	    }
	}

	
	@Override public void enterCreate_table_statement(SQLParserParser.Create_table_statementContext ctx) {
	    String tableName = ctx.table_name().IDENTIFIER().getText();
	    m_currentlyCreatedTable = m_factory.newTable(tableName);
	}
	
	@Override public void exitCreate_table_statement(SQLParserParser.Create_table_statementContext ctx) {
	    m_catalog.addTable(m_currentlyCreatedTable);
	    m_currentlyCreatedTable = null;
	}

	@Override public void enterSelect_statement(SQLParserParser.Select_statementContext ctx) {
	    m_selectQuery = m_factory.newSelectQuery(m_symbolTable);
	}
	
	@Override public void exitSelect_statement(SQLParserParser.Select_statementContext ctx) {
	    m_factory.processQuery(m_selectQuery);
	}

	
	@Override public void exitProjection(SQLParserParser.ProjectionContext ctx) {
	    String tableName = null;
	    String columnName = ctx.projection_ref().column_name().IDENTIFIER().getText();
	    String alias = null;
	    if (ctx.projection_ref().table_name() != null) {
	        tableName = ctx.projection_ref().table_name().IDENTIFIER().getText();
	    }
	    if (ctx.column_name() != null) {
	        alias = ctx.column_name().IDENTIFIER().getText();
	    }
	    m_selectQuery.addProjection(tableName, columnName, alias);
	}
	
	@Override public void exitTable_clause(SQLParserParser.Table_clauseContext ctx) {
        for (SQLParserParser.Table_refContext tr : ctx.table_ref()) {
            String tableName = tr.table_name().get(0).IDENTIFIER().getText();
            String alias = null;
            if (tr.table_name().size() > 1) {
                alias = tr.table_name().get(1).IDENTIFIER().getText();
            }
            ITable table = m_catalog.getTableByName(tableName);
            if (table == null) {
                addError(tr.start.getLine(),
                         tr.start.getCharPositionInLine(),
                         "Cannot find table %s",
                         tableName);
            }
	        m_selectQuery.addTable(table, alias);
	    }
        while(m_selectQuery.hasNeutrinos()) {
        	m_selectQuery.popNeutrino();
        }
	}
	
	@Override public void exitColumn_ref(@NotNull SQLParserParser.Column_refContext ctx) {
		String columnName = ctx.column_name().IDENTIFIER().getText();
		String tableName = null;
	    if (ctx.table_name() != null) {
	        tableName = ctx.table_name().IDENTIFIER().getText();
	    }
	    m_selectQuery.pushNeutrino(m_selectQuery.getColumnNeutrino(columnName,tableName));
	}

	
	@Override public void exitWhere_clause(SQLParserParser.Where_clauseContext ctx) {
		Neutrino ret = (Neutrino) m_selectQuery.popNeutrino();
		if (!(ret != null && ret.isBooleanExpression())) { 
			addError(ctx.start.getLine(),
			        ctx.start.getCharPositionInLine(),
			        "Boolean expression expected");
		} else {
			
			m_selectQuery.setWhereCondition(ret);
		}
	}

	
	@Override public void exitExpression(@NotNull SQLParserParser.ExpressionContext ctx) {
		List<ExpressionContext> exprs = ctx.expression();
		
		
		
		if (exprs.size() == 2) { 
		    
		    String opString;
		    IOperator op;
		    if (ctx.timesop() != null) {
		        opString = ctx.timesop().getText();
		    } else if (ctx.addop() != null) {
		        opString = ctx.addop().getText();
		    } else if (ctx.relop() != null) {
		        opString = ctx.relop().getText();
		    } else {
		        addError(ctx.start.getLine(),
		                 ctx.start.getCharPositionInLine(),
		                 "Unknown operator");
		        return;
		    }
		    op = m_factory.getExpressionOperator(opString);
		    
		    
		    
		    Neutrino rightoperand = (Neutrino) m_selectQuery.popNeutrino();
		    Neutrino leftoperand = (Neutrino) m_selectQuery.popNeutrino();
		    Neutrino answer;
		    if (op.isArithmetic()) {
    		    answer = (Neutrino) m_selectQuery.getNeutrinoMath(op,
    		                                           leftoperand,
    		                                           rightoperand);
		    } else if (op.isRelational()) {
		        answer = (Neutrino) m_selectQuery.getNeutrinoCompare(op,
		                                                  leftoperand,
		                                                  rightoperand);
		    } else if (op.isBoolean()) {
		        answer = (Neutrino) m_selectQuery.getNeutrinoBoolean(op,
		                                                  leftoperand,
		                                                  rightoperand);
		    } else {
		        addError(ctx.start.getLine(),
		                 ctx.start.getCharPositionInLine(),
		                 "Internal Error: Unknown operation kind for operator \"%s\"",
		                 opString);
		        return;
		    }
		    if (answer == null) {
		        addError(ctx.start.getLine(),
		                ctx.start.getCharPositionInLine(),
		                "Incompatible argument types %s and %s",
		                leftoperand.getType().getName(),
		                rightoperand.getType().getName());
		        return;
		    }
		    m_selectQuery.pushNeutrino(answer);
		} else { 
			Column_refContext cref = ctx.column_ref();
			if (cref != null) {
			    String tableName = (cref.table_name() != null) ? cref.table_name().IDENTIFIER().getText() : null;
			    String columnName = cref.column_name().IDENTIFIER().getText();
			    Neutrino crefNeutrino = (Neutrino) m_selectQuery.getColumnNeutrino(columnName, tableName);
			    m_selectQuery.pushNeutrino(crefNeutrino);
			} else {
			    
				if (ctx.FALSE() != null) { 
				    Type boolType = (Type) m_factory.makeBooleanType();
					m_selectQuery.pushNeutrino(
							new Neutrino(boolType,
									     m_factory.makeUnaryAST(boolType, false)));
				} else if (ctx.TRUE() != null ) { 
				    Type boolType = (Type) m_factory.makeBooleanType();
					m_selectQuery.pushNeutrino(
							new Neutrino(boolType,
									    m_factory.makeUnaryAST(boolType, true)));
				} else { 
				    Type intType = (Type) m_factory.makeIntegerType();
					m_selectQuery.pushNeutrino(
							new Neutrino(intType,
							             m_factory.makeUnaryAST(intType, Integer.valueOf(ctx.NUMBER().getText()))));
				}
			}
		}
	}

	
	@Override public void exitInsert_statement(SQLParserParser.Insert_statementContext ctx) {
	    String tableName = ctx.table_name().IDENTIFIER().getText();
	    ITable table = m_catalog.getTableByName(tableName);
	    if (table == null) {
	        addError(ctx.table_name().start.getLine(),
	                 ctx.table_name().start.getCharPositionInLine(),
	                 "Undefined table name %s",
	                 tableName);
	        return;
	    }
	    if (ctx.column_name().size() != ctx.values().value().size()) {
	        addError(ctx.column_name().get(0).start.getLine(),
	                 ctx.column_name().get(0).start.getCharPositionInLine(),
	                 (ctx.column_name().size() > ctx.values().value().size())
	                   ? "Too few values in insert statement."
	                   : "Too many values in insert statement.");
	        return;
	    }
	    m_insertStatement = m_factory.newInsertStatement();
	    m_insertStatement.addTable(table);
	    List<String> colNames = new ArrayList<String>();
	    List<IType>  colTypes = new ArrayList<IType>();
	    List<String> colVals  = new ArrayList<String>();
	    for (Column_nameContext colCtx : ctx.column_name()) {
	        String colName = colCtx.IDENTIFIER().getText();
	        IColumn col = table.getColumnByName(colName);
	        if (col == null) {
	            addError(colCtx.start.getLine(),
	                     colCtx.start.getCharPositionInLine(),
	                     "Undefined column name %s in table %s",
	                     colName,
	                     tableName);
	            return;
	        }
	        IType colType = col.getType();
	        colNames.add(colName);
	        colTypes.add(colType);
	    }
	    for (ValueContext val : ctx.values().value()) {
	        String valStr = val.NUMBER().getText();
	        colVals.add(valStr);
	    }
	    for (int idx = 0; idx < colNames.size(); idx += 1) {
	        m_insertStatement.addColumn(colNames.get(idx),
	                                    colTypes.get(idx),
	                                    colVals.get(idx));
	    }
	}

    @Override
    public void reportAmbiguity(Parser aArg0, DFA aArg1, int aArg2, int aArg3,
            boolean aArg4, java.util.BitSet aArg5, ATNConfigSet aArg6) {
        

    }

    @Override
    public void reportAttemptingFullContext(Parser aArg0, DFA aArg1, int aArg2,
            int aArg3, java.util.BitSet aArg4, ATNConfigSet aArg5) {
        

    }

    @Override
    public void reportContextSensitivity(Parser aArg0, DFA aArg1, int aArg2,
            int aArg3, int aArg4, ATNConfigSet aArg5) {
    }

    @Override
    public void syntaxError(Recognizer<?, ?> aArg0, Object aTokObj, int aLine,
            int aCol, String msg, RecognitionException aArg5) {
        addError(aLine, aCol, msg);
    }

    public final ISelectQuery getSelectQuery() {
        return m_selectQuery;
    }

    public final IInsertStatement getInsertStatement() {
        return m_insertStatement;
    }

    public CatalogAdapter getCatalogAdapter() {
        assert(m_catalog instanceof CatalogAdapter);
        return (CatalogAdapter)m_catalog;
    }

    protected final IParserFactory getFactory() {
        return m_factory;
    }

}

<code block>
package org.voltdb.sqlparser.matchers;

import org.assertj.core.api.AbstractAssert;
import org.voltdb.sqlparser.semantics.symtab.SymbolTable;
import org.voltdb.sqlparser.semantics.symtab.Type;

public class SymbolTableAssert extends AbstractAssert<SymbolTableAssert, SymbolTable> {
    public SymbolTableAssert(SymbolTable aSymTab) {
        super(aSymTab, SymbolTableAssert.class);
    }

    public static SymbolTableAssert assertThat(SymbolTable aSymTab) {
        return new SymbolTableAssert(aSymTab);
    }
    
    public SymbolTableAssert isEmpty() {
        isNotNull();
        if (!actual.isEmpty()) {
            failWithMessage("Expected empty symbol table");
        }
        return this;
    };

    public SymbolTableAssert hasSize(int aSize) {
        isNotNull();
        if (actual.size() != aSize) {
            failWithMessage("Expected %d elements, not %d", aSize, actual.size());
        }
        return this;
    }

    public TypeAssert definesType(String aTypeName) {
        isNotNull();
        Type t = actual.getType(aTypeName);
        if (t == null) {
            failWithMessage("Expected type <%s> to be defined", aTypeName);
        }
        return new TypeAssert(t);
    }
}

<code block>
package org.voltdb.sqlparser.matchers;

import org.assertj.core.api.AbstractAssert;
import org.voltdb.sqlparser.semantics.symtab.Type;

public class TypeAssert extends AbstractAssert<TypeAssert, Type> {

    protected TypeAssert(Type aActual) {
        super(aActual, TypeAssert.class);
        
    }

    public TypeAssert hasName(String aTypeName) {
        isNotNull();
        if (actual.getName().equalsIgnoreCase(aTypeName)) {
            failWithMessage("Expected type named <%s>.", aTypeName);
        }
        return this;
    }

    public TypeAssert hasMaxSize(int aMaxSize) {
        isNotNull();
        if (actual.getMaxSize() != aMaxSize) {
            failWithMessage("Expected type name <%s> to have max size %d not %d",
                            actual.getName(), aMaxSize, actual.getMaxSize());
        }
        return this;
    }

    public TypeAssert hasNominalSize(int aNominalSize) {
        isNotNull();
        if (actual.getNominalSize() != aNominalSize) {
            failWithMessage("Expected type name <%s> to have nominal size %d not %d",
                            actual.getName(), aNominalSize, actual.getNominalSize());
        }
        return this;
    }

}

<code block>
package org.voltdb.sqlparser.symtab;

import org.assertj.core.api.AbstractAssert;
import org.assertj.core.api.Condition;
import org.assertj.core.api.Fail;
import org.voltdb.sqlparser.semantics.symtab.Column;
import org.voltdb.sqlparser.semantics.symtab.Table;


public class TableAssert extends AbstractAssert<TableAssert, Table> {

    
    public TableAssert(Table actual) {
        super(actual, TableAssert.class);
    }

    
    public static TableAssert assertThat(Table actual) {
        return new TableAssert(actual);
    }

    public static Condition<Table> withColumnNamed(final String aColumnName,
                                                    final Condition<Column> ...conditions) {
        return new Condition<Table>() {
            @Override
            public boolean matches(Table aValue) {
                Column col = aValue.getColumnByName(aColumnName);
                if (col == null) {
                    Fail.fail(String.format("Expected column named <%s>", aColumnName));
                }
                for (Condition<Column> cond : conditions) {
                    org.voltdb.sqlparser.symtab.ColumnAssert.assertThat(col).has(cond);
                }
                return true;
            }
        };
    }
}

<code block>
package org.voltdb.sqlparser.symtab;

import org.assertj.core.api.AbstractAssert;
import org.assertj.core.api.Condition;
import org.voltdb.sqlparser.semantics.symtab.CatalogAdapter;
import org.voltdb.sqlparser.semantics.symtab.Table;


public class CatalogAdapterAssert extends
        AbstractAssert<CatalogAdapterAssert, CatalogAdapter> {

    
    public CatalogAdapterAssert(CatalogAdapter actual) {
        super(actual, CatalogAdapterAssert.class);
    }

    
    public static CatalogAdapterAssert assertThat(CatalogAdapter actual) {
        return new CatalogAdapterAssert(actual);
    }

    public CatalogAdapterAssert hasTableNamed(String aTableName,
                                              Condition<Table> ...conditions) {
        isNotNull();
        Table tbl = actual.getTableByName(aTableName);
        if (tbl == null) {
            failWithMessage("Expected to find a table named <%s>", aTableName);
        }
        for (Condition<Table> cond : conditions) {
            org.voltdb.sqlparser.symtab.TableAssert.assertThat(tbl).has(cond);
        }
        return this;
    }

}

<code block>
package org.voltdb.sqlparser.symtab;

import static java.lang.String.format;

import org.assertj.core.api.AbstractAssert;
import org.voltdb.sqlparser.semantics.symtab.SymbolTable;


public class SymbolTableAssert extends
        AbstractAssert<SymbolTableAssert, SymbolTable> {

    
    public SymbolTableAssert(SymbolTable actual) {
        super(actual, SymbolTableAssert.class);
    }

    
    public static SymbolTableAssert assertThat(SymbolTable actual) {
        return new SymbolTableAssert(actual);
    }

    
    public SymbolTableAssert isEmpty() {
        
        isNotNull();

        
        String errorMessage = format(
                "Expected actual SymbolTable to be empty but was not.", actual);

        
        if (!actual.isEmpty())
            throw new AssertionError(errorMessage);

        
        return this;
    }

    
    public SymbolTableAssert isNotEmpty() {
        
        isNotNull();

        
        String errorMessage = format(
                "Expected actual SymbolTable not to be empty but was.", actual);

        
        if (actual.isEmpty())
            throw new AssertionError(errorMessage);

        
        return this;
    }

}

<code block>
package org.voltdb.sqlparser.symtab;

import org.assertj.core.api.AbstractAssert;
import org.voltdb.sqlparser.semantics.symtab.Type;


public class TypeAssert extends AbstractAssert<TypeAssert, Type> {

    
    public TypeAssert(Type actual) {
        super(actual, TypeAssert.class);
    }

    
    public static TypeAssert assertThat(Type actual) {
        return new TypeAssert(actual);
    }

}

<code block>
package org.voltdb.sqlparser;

import static org.voltdb.sqlparser.matchers.SymbolTableAssert.assertThat;

import org.junit.Test;
import org.voltdb.sqlparser.semantics.symtab.IntegerType;
import org.voltdb.sqlparser.semantics.symtab.SymbolTable;

public class TestSymbolTable {
    @Test
    public void test() {
        SymbolTable s = new SymbolTable(null);
        assertThat(s).isEmpty();
        assertThat(s).hasSize(0);
        IntegerType bigint = new IntegerType("bigint", 8, 8);
        s.define(bigint);
        assertThat(s).hasSize(1)
                     .definesType("bigint")
                     .hasMaxSize(8)
                     .hasNominalSize(8);
    }
}

<code block>
package org.voltdb.sqlparser;

import static org.voltdb.sqlparser.symtab.CatalogAdapterAssert.assertThat;
import static org.voltdb.sqlparser.symtab.ColumnAssert.withColumnTypeNamed;
import static org.voltdb.sqlparser.symtab.TableAssert.withColumnNamed;

import java.io.IOException;

import org.junit.Test;
import org.voltdb.sqlparser.semantics.grammar.DDLListener;
import org.voltdb.sqlparser.semantics.symtab.CatalogAdapter;
import org.voltdb.sqlparser.semantics.symtab.ParserFactory;
import org.voltdb.sqlparser.syntax.SQLParserDriver;

public class TestCreateTable {

    @Test
    public void testMultiTableCreation() throws IOException {
        testDDL1("create table alpha ( id bigint );");
        testDDL2("create table beta ( id bigint not null, local tinyint not null );");
    }

    private void testDDL1(String ddl) throws IOException {
        CatalogAdapter catalog = new CatalogAdapter();
        ParserFactory factory = new ParserFactory(catalog);
        DDLListener listener = new DDLListener(factory);
        SQLParserDriver driver = new SQLParserDriver(ddl, null);
        driver.walk(listener);
        assertThat(catalog)
            .hasTableNamed("alpha",
                      withColumnNamed("id",
                                      withColumnTypeNamed("bigint")));
    }

    private void testDDL2(String ddl) throws IOException {
        CatalogAdapter catalog = new CatalogAdapter();
        ParserFactory factory = new ParserFactory(catalog);
        DDLListener listener = new DDLListener(factory);
        SQLParserDriver driver = new SQLParserDriver(ddl, null);
        driver.walk(listener);

        assertThat(catalog)
            .hasTableNamed("beta",
                      withColumnNamed("id",
                                      withColumnTypeNamed("bigint")),
                      withColumnNamed("local",
                                     withColumnTypeNamed("tinyint")));
    }
}

<code block>

package org.voltdb.utils;

import java.io.File;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.channels.FileChannel.MapMode;

import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.Bits;
import org.voltcore.utils.DBBPool;
import org.voltcore.utils.DBBPool.BBContainer;
import org.voltcore.utils.DBBPool.MBBContainer;
import org.voltcore.utils.DeferredSerialization;
import org.voltdb.utils.BinaryDeque.OutputContainerFactory;
import org.xerial.snappy.Snappy;


class PBDMMapSegment implements PBDSegment {
    private static final VoltLogger LOG = new VoltLogger("HOST");

    
    private boolean m_syncedSinceLastEdit;
    final File m_file;
    private RandomAccessFile m_ras;
    private FileChannel m_fc;
    private MBBContainer m_buf;
    private ByteBuffer m_readBuf;

    
    
    private boolean m_haveMAdvised;

    
    
    int m_objectReadIndex;
    private int m_bytesRead;

    
    private final Long m_index;

    private boolean m_closed = true;

    
    
    private int m_discardCount;

    public PBDMMapSegment(Long index, File file) {
        m_index = index;
        m_file = file;
        reset();
        if (LOG.isDebugEnabled()) {
            LOG.debug("Creating Segment: " + file.getName() + " At Index: " + m_index);
        }
    }

    @Override
    public long segmentId() {
        return m_index;
    }

    @Override
    public File file() {
        return m_file;
    }

    @Override
    public void reset() {
        m_syncedSinceLastEdit = true;
        m_haveMAdvised = false;
        m_objectReadIndex = 0;
        m_bytesRead = 0;
        m_discardCount = 0;
    }

    @Override
    public int getNumEntries() throws IOException {
        if (m_closed) {
            open(false);
        }
        if (m_fc.size() > SEGMENT_HEADER_BYTES) {
            return m_buf.b().getInt(COUNT_OFFSET);
        } else {
            return 0;
        }
    }

    @Override
    public boolean isBeingPolled() {
        return m_objectReadIndex != 0;
    }

    @Override
    public int readIndex() {
        return m_objectReadIndex;
    }

    private void initNumEntries(int count, int size) throws IOException {
        final ByteBuffer buf = m_buf.b();
        buf.putInt(0, count);
        buf.putInt(4, size);
        m_syncedSinceLastEdit = false;
    }

    private void incrementNumEntries(int size) throws IOException {
        final ByteBuffer buf = m_buf.b();
        
        buf.putInt(COUNT_OFFSET, buf.getInt(COUNT_OFFSET) + 1);
        buf.putInt(SIZE_OFFSET, buf.getInt(SIZE_OFFSET) + size);
        m_syncedSinceLastEdit = false;
    }

    @Override
    public void open(boolean forWrite) throws IOException {
        open(forWrite, forWrite);
    }

    
    private void open(boolean forWrite, boolean truncate) throws IOException {
        if (!m_closed) {
            throw new IOException("Segment is already opened");
        }

        if (!m_file.exists()) {
            m_syncedSinceLastEdit = false;
        }
        assert(m_ras == null);
        m_ras = new RandomAccessFile(m_file, "rw");
        m_fc = m_ras.getChannel();

        if (forWrite) {
            
            m_buf = DBBPool.wrapMBB(m_fc.map(MapMode.READ_WRITE, 0, CHUNK_SIZE));
            m_buf.b().position(SIZE_OFFSET + 4);
            m_readBuf = m_buf.b().duplicate();
            if (truncate) {
                initNumEntries(0, 0);
            }
        } else {
            
            
            final long size = m_fc.size();
            m_buf = DBBPool.wrapMBB(m_fc.map(MapMode.READ_ONLY, 0, size));
            m_readBuf = m_buf.b().duplicate();
            m_buf.b().position((int) size);
            m_readBuf.position(SIZE_OFFSET + 4);
        }

        m_closed = false;
    }

    @Override
    public void closeAndDelete() throws IOException {
        close();
        if (LOG.isDebugEnabled()) {
            LOG.debug("Deleting segment at Index " + m_index + " File: " + m_file.getAbsolutePath());
        }
        m_file.delete();
    }

    @Override
    public boolean isClosed() {
        return m_closed;
    }

    @Override
    public void close() throws IOException {
        try {
            if (m_fc != null) {
                m_fc.close();
                m_ras = null;
                m_fc = null;
                m_buf.discard();
                m_buf = null;
                m_readBuf = null;
            }
        } finally {
            m_closed = true;
            reset();
        }
    }

    @Override
    public void sync() throws IOException {
        if (m_closed) throw new IOException("closed");
        if (!m_syncedSinceLastEdit) {
            m_buf.b().force();
        }
        m_syncedSinceLastEdit = true;
    }

    @Override
    public boolean hasMoreEntries() throws IOException {
        if (m_closed) throw new IOException("closed");
        return m_objectReadIndex < m_buf.b().getInt(COUNT_OFFSET);
    }

    @Override
    public boolean isEmpty() throws IOException {
        if (m_closed) throw new IOException("closed");
        return m_discardCount == getNumEntries();
    }

    @Override
    public boolean offer(BBContainer cont, boolean compress) throws IOException {
        if (m_closed) throw new IOException("closed");
        final ByteBuffer buf = cont.b();
        final int remaining = buf.remaining();
        if (remaining < 32 || !buf.isDirect()) compress = false;
        final int maxCompressedSize = compress ? Snappy.maxCompressedLength(remaining) : remaining;
        final ByteBuffer mbuf = m_buf.b();
        if (mbuf.remaining() < maxCompressedSize + OBJECT_HEADER_BYTES) return false;


        m_syncedSinceLastEdit = false;
        try {
            
            final int objSizePosition = mbuf.position();
            mbuf.position(mbuf.position() + OBJECT_HEADER_BYTES);

            int written = maxCompressedSize;
            if (compress) {
                
                final long destAddr = m_buf.address() + mbuf.position();
                written = (int)Snappy.rawCompress(cont.address() + buf.position(), remaining, destAddr);
                mbuf.position(mbuf.position() + written);
            } else {
                mbuf.put(buf);
            }

            
            
            mbuf.putInt(objSizePosition, written);
            mbuf.putInt(objSizePosition + 4, compress ? FLAG_COMPRESSED: NO_FLAGS);
            buf.position(buf.limit());
            incrementNumEntries(remaining);
        } finally {
            cont.discard();
        }

        return true;
    }

    @Override
    public int offer(DeferredSerialization ds) throws IOException {
        if (m_closed) throw new IOException("closed");
        final ByteBuffer mbuf = m_buf.b();
        if (mbuf.remaining() < ds.getSerializedSize() + OBJECT_HEADER_BYTES) return -1;

        m_syncedSinceLastEdit = false;
        int written = PBDUtils.writeDeferredSerialization(mbuf, ds);
        incrementNumEntries(written);
        return written;
    }

    @Override
    public BBContainer poll(OutputContainerFactory factory) throws IOException {
        if (m_closed) throw new IOException("closed");
        final long mBufAddr = m_buf.address();
        if (!m_haveMAdvised) {
            final ByteBuffer mbuf = m_buf.b();
            m_haveMAdvised = true;
            final long retval = PosixAdvise.madvise(
                    m_buf.address(),
                    mbuf.position(),
                    PosixAdvise.POSIX_MADV_WILLNEED);
            if (retval != 0) {
                LOG.warn("madvise will need failed: " + retval);
            }
        }

        
        if (!hasMoreEntries()) {
            return null;
        }

        m_objectReadIndex++;

        
        final int nextCompressedLength = m_readBuf.getInt();
        final int nextFlags = m_readBuf.getInt();

        
        final boolean compressed = (nextFlags & FLAG_COMPRESSED) != 0;
        
        final int nextUncompressedLength = compressed ? (int)Snappy.uncompressedLength(mBufAddr + m_readBuf.position(), nextCompressedLength) : nextCompressedLength;
        m_bytesRead += nextUncompressedLength;

        final BBContainer retcont;
        if (compressed) {
            
            retcont = factory.getContainer(nextUncompressedLength);
            final ByteBuffer retbuf = retcont.b();

            
            retbuf.limit(nextUncompressedLength);

            
            final long sourceAddr = mBufAddr + m_readBuf.position();
            final long destAddr = retcont.address();
            Snappy.rawUncompress(sourceAddr, nextCompressedLength, destAddr);
            m_readBuf.position(m_readBuf.position() + nextCompressedLength);
        } else {
            
            final int oldLimit = m_readBuf.limit();
            m_readBuf.limit(m_readBuf.position() + nextUncompressedLength);
            ByteBuffer retbuf = m_readBuf.slice();
            m_readBuf.position(m_readBuf.limit());
            m_readBuf.limit(oldLimit);

            
            retcont = DBBPool.dummyWrapBB(retbuf);
            Bits.readEveryPage(retcont);
        }

        return new BBContainer(retcont.b()) {
            private boolean m_discarded = false;

            @Override
            public void discard()
            {
                checkDoubleFree();
                if (m_discarded) {
                    LOG.error("PBD Container discarded more than once");
                    return;
                }
                m_discarded = true;
                retcont.discard();
                m_discardCount++;
            }
        };
    }

    
    @Override
    public int uncompressedBytesToRead() {
        if (m_closed) throw new RuntimeException("closed");
        return Math.max(0, m_buf.b().getInt(SIZE_OFFSET) - m_bytesRead);
    }
}

<code block>


package org.voltdb.utils;

import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.DBBPool;
import org.voltcore.utils.DeferredSerialization;

import java.io.EOFException;
import java.io.File;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;


public class PBDRegularSegment implements PBDSegment {
    private static final VoltLogger LOG = new VoltLogger("HOST");

    
    private boolean m_syncedSinceLastEdit = true;
    private final File m_file;
    private RandomAccessFile m_ras;
    private FileChannel m_fc;
    private boolean m_closed = true;

    
    private int m_objectReadIndex = 0;
    private int m_bytesRead = 0;
    
    private long m_readOffset = SEGMENT_HEADER_BYTES;

    
    private final Long m_index;

    private int m_discardCount;
    private int m_numOfEntries = -1;
    private int m_size = -1;

    private DBBPool.BBContainer m_tmpHeaderBuf = null;

    public PBDRegularSegment(Long index, File file) {
        m_index = index;
        m_file = file;
        reset();
    }

    @Override
    public long segmentId()
    {
        return m_index;
    }

    @Override
    public File file()
    {
        return m_file;
    }

    @Override
    public void reset()
    {
        m_syncedSinceLastEdit = false;
        m_objectReadIndex = 0;
        m_bytesRead = 0;
        m_readOffset = SEGMENT_HEADER_BYTES;
        m_discardCount = 0;
        if (m_tmpHeaderBuf != null) {
            m_tmpHeaderBuf.discard();
            m_tmpHeaderBuf = null;
        }
    }

    @Override
    public int getNumEntries() throws IOException
    {
        if (m_closed) {
            open(false);
        }
        if (m_fc.size() > 0) {
            m_tmpHeaderBuf.b().clear();
            PBDUtils.readBufferFully(m_fc, m_tmpHeaderBuf.b(), COUNT_OFFSET);
            m_numOfEntries = m_tmpHeaderBuf.b().getInt();
            m_size = m_tmpHeaderBuf.b().getInt();
            return m_numOfEntries;
        } else {
            m_numOfEntries = 0;
            m_size = 0;
            return 0;
        }
    }

    @Override
    public boolean isBeingPolled()
    {
        return m_objectReadIndex != 0;
    }

    @Override
    public int readIndex()
    {
        return m_objectReadIndex;
    }

    @Override
    public void open(boolean forWrite) throws IOException
    {
        open(forWrite, forWrite);
    }

    
    private void open(boolean forWrite, boolean truncate) throws IOException
    {
        if (!m_closed) {
            throw new IOException("Segment is already opened");
        }

        if (!m_file.exists()) {
            if (!forWrite) {
                throw new IOException("File " + m_file + " does not exist");
            }
            m_syncedSinceLastEdit = false;
        }
        assert(m_ras == null);
        m_ras = new RandomAccessFile( m_file, forWrite ? "rw" : "r");
        m_fc = m_ras.getChannel();
        m_tmpHeaderBuf = DBBPool.allocateDirect(SEGMENT_HEADER_BYTES);

        if (truncate) {
            initNumEntries(0, 0);
        }
        m_fc.position(SEGMENT_HEADER_BYTES);

        m_closed = false;
    }

    private void initNumEntries(int count, int size) throws IOException {
        m_numOfEntries = count;
        m_size = size;

        m_tmpHeaderBuf.b().clear();
        m_tmpHeaderBuf.b().putInt(m_numOfEntries);
        m_tmpHeaderBuf.b().putInt(m_size);
        m_tmpHeaderBuf.b().flip();
        PBDUtils.writeBuffer(m_fc, m_tmpHeaderBuf.bDR(), COUNT_OFFSET);
        m_syncedSinceLastEdit = false;
    }

    private void incrementNumEntries(int size) throws IOException
    {
        m_numOfEntries++;
        m_size += size;

        m_tmpHeaderBuf.b().clear();
        m_tmpHeaderBuf.b().putInt(m_numOfEntries);
        m_tmpHeaderBuf.b().putInt(m_size);
        m_tmpHeaderBuf.b().flip();
        PBDUtils.writeBuffer(m_fc, m_tmpHeaderBuf.bDR(), COUNT_OFFSET);
        m_syncedSinceLastEdit = false;
    }

    
    private int remaining() throws IOException {
        
        return (int)(PBDSegment.CHUNK_SIZE - m_fc.position()) - SEGMENT_HEADER_BYTES;
    }

    @Override
    public void closeAndDelete() throws IOException {
        close();
        m_file.delete();

        m_numOfEntries = -1;
        m_size = -1;
    }

    @Override
    public boolean isClosed()
    {
        return m_closed;
    }

    @Override
    public void close() throws IOException {
        try {
            if (m_fc != null) {
                m_fc.close();
            }
        } finally {
            m_ras = null;
            m_fc = null;
            m_closed = true;
            reset();
        }
    }

    @Override
    public void sync() throws IOException {
        if (m_closed) throw new IOException("Segment closed");
        if (!m_syncedSinceLastEdit) {
            m_fc.force(true);
        }
        m_syncedSinceLastEdit = true;
    }

    @Override
    public boolean hasMoreEntries() throws IOException
    {
        if (m_closed) throw new IOException("Segment closed");
        return m_objectReadIndex < m_numOfEntries;
    }

    @Override
    public boolean isEmpty() throws IOException
    {
        if (m_closed) throw new IOException("Segment closed");
        return m_discardCount == m_numOfEntries;
    }

    @Override
    public boolean offer(DBBPool.BBContainer cont, boolean compress) throws IOException
    {
        if (m_closed) throw new IOException("Segment closed");
        final ByteBuffer buf = cont.b();
        final int remaining = buf.remaining();
        if (remaining < 32 || !buf.isDirect()) compress = false;
        final int maxCompressedSize = (compress ? CompressionService.maxCompressedLength(remaining) : remaining) + OBJECT_HEADER_BYTES;
        if (remaining() < maxCompressedSize) return false;

        m_syncedSinceLastEdit = false;
        DBBPool.BBContainer destBuf = cont;

        try {
            m_tmpHeaderBuf.b().clear();

            if (compress) {
                destBuf = DBBPool.allocateDirectAndPool(maxCompressedSize);
                final int compressedSize = CompressionService.compressBuffer(buf, destBuf.b());
                destBuf.b().limit(compressedSize);

                m_tmpHeaderBuf.b().putInt(compressedSize);
                m_tmpHeaderBuf.b().putInt(FLAG_COMPRESSED);
            } else {
                destBuf = cont;
                m_tmpHeaderBuf.b().putInt(remaining);
                m_tmpHeaderBuf.b().putInt(NO_FLAGS);
            }

            m_tmpHeaderBuf.b().flip();
            while (m_tmpHeaderBuf.b().hasRemaining()) {
                m_fc.write(m_tmpHeaderBuf.b());
            }

            while (destBuf.b().hasRemaining()) {
                m_fc.write(destBuf.b());
            }

            incrementNumEntries(remaining);
        } finally {
            destBuf.discard();
            if (compress) {
                cont.discard();
            }
        }

        return true;
    }

    @Override
    public int offer(DeferredSerialization ds) throws IOException
    {
        if (m_closed) throw new IOException("closed");
        final int fullSize = ds.getSerializedSize() + OBJECT_HEADER_BYTES;
        if (remaining() < fullSize) return -1;

        m_syncedSinceLastEdit = false;
        DBBPool.BBContainer destBuf = DBBPool.allocateDirectAndPool(fullSize);

        try {
            final int written = PBDUtils.writeDeferredSerialization(destBuf.b(), ds);
            destBuf.b().flip();

            while (destBuf.b().hasRemaining()) {
                m_fc.write(destBuf.b());
            }

            incrementNumEntries(written);
            return written;
        } finally {
            destBuf.discard();
        }
    }

    @Override
    public DBBPool.BBContainer poll(BinaryDeque.OutputContainerFactory factory) throws IOException
    {
        if (m_closed) throw new IOException("closed");

        if (!hasMoreEntries()) {
            return null;
        }

        final long writePos = m_fc.position();
        m_fc.position(m_readOffset);
        m_objectReadIndex++;

        try {
            
            m_tmpHeaderBuf.b().clear();
            while (m_tmpHeaderBuf.b().hasRemaining()) {
                int read = m_fc.read(m_tmpHeaderBuf.b());
                if (read == -1) {
                    throw new EOFException();
                }
            }
            m_tmpHeaderBuf.b().flip();
            final int length = m_tmpHeaderBuf.b().getInt();
            final int flags = m_tmpHeaderBuf.b().getInt();
            final boolean compressed = (flags & FLAG_COMPRESSED) != 0;
            final int uncompressedLen;

            if (length < 1) {
                throw new IOException("Read an invalid length");
            }

            final DBBPool.BBContainer retcont;
            if (compressed) {
                final DBBPool.BBContainer compressedBuf = DBBPool.allocateDirectAndPool(length);
                try {
                    while (compressedBuf.b().hasRemaining()) {
                        int read = m_fc.read(compressedBuf.b());
                        if (read == -1) {
                            throw new EOFException();
                        }
                    }
                    compressedBuf.b().flip();

                    uncompressedLen = CompressionService.uncompressedLength(compressedBuf.bDR());
                    retcont = factory.getContainer(uncompressedLen);
                    retcont.b().limit(uncompressedLen);
                    CompressionService.decompressBuffer(compressedBuf.bDR(), retcont.b());
                } finally {
                    compressedBuf.discard();
                }
            } else {
                uncompressedLen = length;
                retcont = factory.getContainer(length);
                retcont.b().limit(length);
                while (retcont.b().hasRemaining()) {
                    int read = m_fc.read(retcont.b());
                    if (read == -1) {
                        throw new EOFException();
                    }
                }
                retcont.b().flip();
            }

            m_bytesRead += uncompressedLen;

            return new DBBPool.BBContainer(retcont.b()) {
                private boolean m_discarded = false;

                @Override
                public void discard() {
                    checkDoubleFree();
                    if (m_discarded) {
                        LOG.error("PBD Container discarded more than once");
                        return;
                    }

                    m_discarded = true;
                    retcont.discard();
                    m_discardCount++;
                }
            };
        } finally {
            m_readOffset = m_fc.position();
            m_fc.position(writePos);
        }
    }

    @Override
    public int uncompressedBytesToRead() {
        if (m_closed) throw new RuntimeException("Segment closed");
        return m_size - m_bytesRead;
    }
}

<code block>

package org.voltdb.utils;

import java.io.File;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.channels.FileChannel.MapMode;

import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.Bits;
import org.voltcore.utils.DBBPool;
import org.voltcore.utils.DBBPool.BBContainer;
import org.voltcore.utils.DBBPool.MBBContainer;
import org.voltcore.utils.DeferredSerialization;
import org.voltdb.utils.BinaryDeque.OutputContainerFactory;
import org.xerial.snappy.Snappy;


class PBDMMapSegment implements PBDSegment {
    private static final VoltLogger LOG = new VoltLogger("HOST");

    
    private boolean m_syncedSinceLastEdit;
    final File m_file;
    private RandomAccessFile m_ras;
    private FileChannel m_fc;
    private MBBContainer m_buf;
    private ByteBuffer m_readBuf;

    
    
    private boolean m_haveMAdvised;

    
    
    int m_objectReadIndex;
    private int m_bytesRead;

    
    private final Long m_index;

    private boolean m_closed = true;

    
    
    private int m_discardCount;

    public PBDMMapSegment(Long index, File file) {
        m_index = index;
        m_file = file;
        reset();
        if (LOG.isDebugEnabled()) {
            LOG.debug("Creating Segment: " + file.getName() + " At Index: " + m_index);
        }
    }

    @Override
    public long segmentId() {
        return m_index;
    }

    @Override
    public File file() {
        return m_file;
    }

    @Override
    public void reset() {
        m_syncedSinceLastEdit = true;
        m_haveMAdvised = false;
        m_objectReadIndex = 0;
        m_bytesRead = 0;
        m_discardCount = 0;
    }

    @Override
    public int getNumEntries() throws IOException {
        if (m_closed) {
            open(false);
        }
        if (m_fc.size() > SEGMENT_HEADER_BYTES) {
            final int numEntries = m_buf.b().getInt(0);
            return numEntries;
        } else {
            return 0;
        }
    }

    @Override
    public boolean isBeingPolled() {
        return m_objectReadIndex != 0;
    }

    @Override
    public int readIndex() {
        return m_objectReadIndex;
    }

    private void initNumEntries() throws IOException {
        final ByteBuffer buf = m_buf.b();
        buf.putInt(0, 0);
        buf.putInt(4, 0);
        m_syncedSinceLastEdit = false;
    }

    private void incrementNumEntries(int size) throws IOException {
        final ByteBuffer buf = m_buf.b();
        
        buf.putInt(COUNT_OFFSET, buf.getInt(COUNT_OFFSET) + 1);
        buf.putInt(SIZE_OFFSET, buf.getInt(SIZE_OFFSET) + size);
        m_syncedSinceLastEdit = false;
    }

    @Override
    public void open(boolean forWrite) throws IOException {
        if (!m_closed) {
            throw new IOException("Segment is already opened");
        }

        if (!m_file.exists()) {
            m_syncedSinceLastEdit = false;
        }
        assert(m_ras == null);
        m_ras = new RandomAccessFile(m_file, "rw");
        m_fc = m_ras.getChannel();

        if (forWrite) {
            
            m_buf = DBBPool.wrapMBB(m_fc.map(MapMode.READ_WRITE, 0, CHUNK_SIZE));
            m_buf.b().position(SIZE_OFFSET + 4);
            m_readBuf = m_buf.b().duplicate();
            initNumEntries();
        } else {
            
            
            final long size = m_fc.size();
            m_buf = DBBPool.wrapMBB(m_fc.map(MapMode.READ_ONLY, 0, size));
            m_readBuf = m_buf.b().duplicate();
            m_buf.b().position((int) size);
            m_readBuf.position(SIZE_OFFSET + 4);
        }

        m_closed = false;
    }

    @Override
    public void closeAndDelete() throws IOException {
        close();
        if (LOG.isDebugEnabled()) {
            LOG.debug("Deleting segment at Index " + m_index + " File: " + m_file.getAbsolutePath());
        }
        m_file.delete();
    }

    @Override
    public boolean isClosed() {
        return m_closed;
    }

    @Override
    public void close() throws IOException {
        try {
            if (m_fc != null) {
                m_fc.close();
                m_ras = null;
                m_fc = null;
                m_buf.discard();
                m_buf = null;
                m_readBuf = null;
            }
        } finally {
            m_closed = true;
            reset();
        }
    }

    @Override
    public void sync() throws IOException {
        if (m_closed) throw new IOException("closed");
        if (!m_syncedSinceLastEdit) {
            m_buf.b().force();
        }
        m_syncedSinceLastEdit = true;
    }

    @Override
    public boolean hasMoreEntries() throws IOException {
        if (m_closed) throw new IOException("closed");
        return m_objectReadIndex < m_buf.b().getInt(COUNT_OFFSET);
    }

    @Override
    public boolean isEmpty() throws IOException {
        if (m_closed) throw new IOException("closed");
        return m_discardCount == getNumEntries();
    }

    @Override
    public boolean offer(BBContainer cont, boolean compress) throws IOException {
        if (m_closed) throw new IOException("closed");
        final ByteBuffer buf = cont.b();
        final int remaining = buf.remaining();
        if (remaining < 32 || !buf.isDirect()) compress = false;
        final int maxCompressedSize = compress ? Snappy.maxCompressedLength(remaining) : remaining;
        final ByteBuffer mbuf = m_buf.b();
        if (mbuf.remaining() < maxCompressedSize + OBJECT_HEADER_BYTES) return false;


        m_syncedSinceLastEdit = false;
        try {
            
            final int objSizePosition = mbuf.position();
            mbuf.position(mbuf.position() + OBJECT_HEADER_BYTES);

            int written = maxCompressedSize;
            if (compress) {
                
                final long destAddr = m_buf.address() + mbuf.position();
                written = (int)Snappy.rawCompress(cont.address() + buf.position(), remaining, destAddr);
                mbuf.position(mbuf.position() + written);
            } else {
                mbuf.put(buf);
            }

            
            
            mbuf.putInt(objSizePosition, written);
            mbuf.putInt(objSizePosition + 4, compress ? FLAG_COMPRESSED: NO_FLAGS);
            buf.position(buf.limit());
            incrementNumEntries(remaining);
        } finally {
            cont.discard();
        }

        return true;
    }

    @Override
    public int offer(DeferredSerialization ds) throws IOException {
        if (m_closed) throw new IOException("closed");
        final ByteBuffer mbuf = m_buf.b();
        if (mbuf.remaining() < ds.getSerializedSize() + OBJECT_HEADER_BYTES) return -1;

        m_syncedSinceLastEdit = false;
        int written = PBDUtils.writeDeferredSerialization(mbuf, ds);
        incrementNumEntries(written);
        return written;
    }

    @Override
    public BBContainer poll(OutputContainerFactory factory) throws IOException {
        if (m_closed) throw new IOException("closed");
        final long mBufAddr = m_buf.address();
        if (!m_haveMAdvised) {
            final ByteBuffer mbuf = m_buf.b();
            m_haveMAdvised = true;
            final long retval = PosixAdvise.madvise(
                    m_buf.address(),
                    mbuf.position(),
                    PosixAdvise.POSIX_MADV_WILLNEED);
            if (retval != 0) {
                LOG.warn("madvise will need failed: " + retval);
            }
        }

        
        if (!hasMoreEntries()) {
            return null;
        }

        m_objectReadIndex++;

        
        final int nextCompressedLength = m_readBuf.getInt();
        final int nextFlags = m_readBuf.getInt();

        
        final boolean compressed = (nextFlags & FLAG_COMPRESSED) != 0;
        
        final int nextUncompressedLength = compressed ? (int)Snappy.uncompressedLength(mBufAddr + m_readBuf.position(), nextCompressedLength) : nextCompressedLength;
        m_bytesRead += nextUncompressedLength;

        final BBContainer retcont;
        if (compressed) {
            
            retcont = factory.getContainer(nextUncompressedLength);
            final ByteBuffer retbuf = retcont.b();

            
            retbuf.limit(nextUncompressedLength);

            
            final long sourceAddr = mBufAddr + m_readBuf.position();
            final long destAddr = retcont.address();
            Snappy.rawUncompress(sourceAddr, nextCompressedLength, destAddr);
            m_readBuf.position(m_readBuf.position() + nextCompressedLength);
        } else {
            
            final int oldLimit = m_readBuf.limit();
            m_readBuf.limit(m_readBuf.position() + nextUncompressedLength);
            ByteBuffer retbuf = m_readBuf.slice();
            m_readBuf.position(m_readBuf.limit());
            m_readBuf.limit(oldLimit);

            
            retcont = DBBPool.dummyWrapBB(retbuf);
            Bits.readEveryPage(retcont);
        }

        return new BBContainer(retcont.b()) {
            private boolean m_discarded = false;

            @Override
            public void discard()
            {
                checkDoubleFree();
                if (m_discarded) {
                    LOG.error("PBD Container discarded more than once");
                    return;
                }
                m_discarded = true;
                retcont.discard();
                m_discardCount++;
            }
        };
    }

    
    @Override
    public int uncompressedBytesToRead() {
        if (m_closed) throw new RuntimeException("closed");
        return Math.max(0, m_buf.b().getInt(SIZE_OFFSET) - m_bytesRead);
    }
}

<code block>


package org.voltdb.utils;

import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.DBBPool;
import org.voltcore.utils.DeferredSerialization;

import java.io.EOFException;
import java.io.File;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;


public class PBDRegularSegment implements PBDSegment {
    private static final VoltLogger LOG = new VoltLogger("HOST");

    
    private boolean m_syncedSinceLastEdit = true;
    private final File m_file;
    private RandomAccessFile m_ras;
    private FileChannel m_fc;
    private boolean m_closed = true;

    
    private int m_objectReadIndex = 0;
    private int m_bytesRead = 0;
    
    private long m_readOffset = SEGMENT_HEADER_BYTES;

    
    private final Long m_index;

    private int m_discardCount;
    private int m_numOfEntries = -1;
    private int m_size = -1;

    private DBBPool.BBContainer m_tmpHeaderBuf = null;

    public PBDRegularSegment(Long index, File file) {
        m_index = index;
        m_file = file;
        reset();
    }

    @Override
    public long segmentId()
    {
        return m_index;
    }

    @Override
    public File file()
    {
        return m_file;
    }

    @Override
    public void reset()
    {
        m_syncedSinceLastEdit = false;
        m_objectReadIndex = 0;
        m_bytesRead = 0;
        m_readOffset = SEGMENT_HEADER_BYTES;
        m_discardCount = 0;
        if (m_tmpHeaderBuf != null) {
            m_tmpHeaderBuf.discard();
            m_tmpHeaderBuf = null;
        }
    }

    @Override
    public int getNumEntries() throws IOException
    {
        if (m_closed) {
            open(false);
        }
        if (m_fc.size() > 0) {
            m_tmpHeaderBuf.b().clear();
            PBDUtils.readBufferFully(m_fc, m_tmpHeaderBuf.b(), COUNT_OFFSET);
            m_numOfEntries = m_tmpHeaderBuf.b().getInt();
            m_size = m_tmpHeaderBuf.b().getInt();
            return m_numOfEntries;
        } else {
            m_numOfEntries = 0;
            m_size = 0;
            return 0;
        }
    }

    @Override
    public boolean isBeingPolled()
    {
        return m_objectReadIndex != 0;
    }

    @Override
    public int readIndex()
    {
        return m_objectReadIndex;
    }

    @Override
    public void open(boolean forWrite) throws IOException
    {
        if (!m_closed) {
            throw new IOException("Segment is already opened");
        }

        if (!m_file.exists()) {
            if (!forWrite) {
                throw new IOException("File " + m_file + " does not exist");
            }
            m_syncedSinceLastEdit = false;
        }
        assert(m_ras == null);
        m_ras = new RandomAccessFile( m_file, forWrite ? "rw" : "r");
        m_fc = m_ras.getChannel();
        m_tmpHeaderBuf = DBBPool.allocateDirect(SEGMENT_HEADER_BYTES);

        if (forWrite) {
            initNumEntries();
        }
        m_fc.position(SEGMENT_HEADER_BYTES);

        m_closed = false;
    }

    private void initNumEntries() throws IOException {
        m_numOfEntries = 0;
        m_size = 0;

        m_tmpHeaderBuf.b().clear();
        m_tmpHeaderBuf.b().putInt(m_numOfEntries);
        m_tmpHeaderBuf.b().putInt(m_size);
        m_tmpHeaderBuf.b().flip();
        PBDUtils.writeBuffer(m_fc, m_tmpHeaderBuf.bDR(), COUNT_OFFSET);
        m_syncedSinceLastEdit = false;
    }

    private void incrementNumEntries(int size) throws IOException
    {
        m_numOfEntries++;
        m_size += size;

        m_tmpHeaderBuf.b().clear();
        m_tmpHeaderBuf.b().putInt(m_numOfEntries);
        m_tmpHeaderBuf.b().putInt(m_size);
        m_tmpHeaderBuf.b().flip();
        PBDUtils.writeBuffer(m_fc, m_tmpHeaderBuf.bDR(), COUNT_OFFSET);
        m_syncedSinceLastEdit = false;
    }

    
    private int remaining() throws IOException {
        
        return (int)(PBDSegment.CHUNK_SIZE - m_fc.position()) - SEGMENT_HEADER_BYTES;
    }

    @Override
    public void closeAndDelete() throws IOException {
        close();
        m_file.delete();

        m_numOfEntries = -1;
        m_size = -1;
    }

    @Override
    public boolean isClosed()
    {
        return m_closed;
    }

    @Override
    public void close() throws IOException {
        try {
            if (m_fc != null) {
                m_fc.close();
            }
        } finally {
            m_ras = null;
            m_fc = null;
            m_closed = true;
            reset();
        }
    }

    @Override
    public void sync() throws IOException {
        if (m_closed) throw new IOException("Segment closed");
        if (!m_syncedSinceLastEdit) {
            m_fc.force(true);
        }
        m_syncedSinceLastEdit = true;
    }

    @Override
    public boolean hasMoreEntries() throws IOException
    {
        if (m_closed) throw new IOException("Segment closed");
        return m_objectReadIndex < m_numOfEntries;
    }

    @Override
    public boolean isEmpty() throws IOException
    {
        if (m_closed) throw new IOException("Segment closed");
        return m_discardCount == m_numOfEntries;
    }

    @Override
    public boolean offer(DBBPool.BBContainer cont, boolean compress) throws IOException
    {
        if (m_closed) throw new IOException("Segment closed");
        final ByteBuffer buf = cont.b();
        final int remaining = buf.remaining();
        if (remaining < 32 || !buf.isDirect()) compress = false;
        final int maxCompressedSize = (compress ? CompressionService.maxCompressedLength(remaining) : remaining) + OBJECT_HEADER_BYTES;
        if (remaining() < maxCompressedSize) return false;

        m_syncedSinceLastEdit = false;
        DBBPool.BBContainer destBuf = cont;

        try {
            m_tmpHeaderBuf.b().clear();

            if (compress) {
                destBuf = DBBPool.allocateDirectAndPool(maxCompressedSize);
                final int compressedSize = CompressionService.compressBuffer(buf, destBuf.b());
                destBuf.b().limit(compressedSize);

                m_tmpHeaderBuf.b().putInt(compressedSize);
                m_tmpHeaderBuf.b().putInt(FLAG_COMPRESSED);
            } else {
                destBuf = cont;
                m_tmpHeaderBuf.b().putInt(remaining);
                m_tmpHeaderBuf.b().putInt(NO_FLAGS);
            }

            m_tmpHeaderBuf.b().flip();
            while (m_tmpHeaderBuf.b().hasRemaining()) {
                m_fc.write(m_tmpHeaderBuf.b());
            }

            while (destBuf.b().hasRemaining()) {
                m_fc.write(destBuf.b());
            }

            incrementNumEntries(remaining);
        } finally {
            destBuf.discard();
            if (compress) {
                cont.discard();
            }
        }

        return true;
    }

    @Override
    public int offer(DeferredSerialization ds) throws IOException
    {
        if (m_closed) throw new IOException("closed");
        final int fullSize = ds.getSerializedSize() + OBJECT_HEADER_BYTES;
        if (remaining() < fullSize) return -1;

        m_syncedSinceLastEdit = false;
        DBBPool.BBContainer destBuf = DBBPool.allocateDirectAndPool(fullSize);

        try {
            final int written = PBDUtils.writeDeferredSerialization(destBuf.b(), ds);
            destBuf.b().flip();

            while (destBuf.b().hasRemaining()) {
                m_fc.write(destBuf.b());
            }

            incrementNumEntries(written);
            return written;
        } finally {
            destBuf.discard();
        }
    }

    @Override
    public DBBPool.BBContainer poll(BinaryDeque.OutputContainerFactory factory) throws IOException
    {
        if (m_closed) throw new IOException("closed");

        if (!hasMoreEntries()) {
            return null;
        }

        final long writePos = m_fc.position();
        m_fc.position(m_readOffset);
        m_objectReadIndex++;

        try {
            
            m_tmpHeaderBuf.b().clear();
            while (m_tmpHeaderBuf.b().hasRemaining()) {
                int read = m_fc.read(m_tmpHeaderBuf.b());
                if (read == -1) {
                    throw new EOFException();
                }
            }
            m_tmpHeaderBuf.b().flip();
            final int length = m_tmpHeaderBuf.b().getInt();
            final int flags = m_tmpHeaderBuf.b().getInt();
            final boolean compressed = (flags & FLAG_COMPRESSED) != 0;
            final int uncompressedLen;

            if (length < 1) {
                throw new IOException("Read an invalid length");
            }

            final DBBPool.BBContainer retcont;
            if (compressed) {
                final DBBPool.BBContainer compressedBuf = DBBPool.allocateDirectAndPool(length);
                try {
                    while (compressedBuf.b().hasRemaining()) {
                        int read = m_fc.read(compressedBuf.b());
                        if (read == -1) {
                            throw new EOFException();
                        }
                    }
                    compressedBuf.b().flip();

                    uncompressedLen = CompressionService.uncompressedLength(compressedBuf.bDR());
                    retcont = factory.getContainer(uncompressedLen);
                    retcont.b().limit(uncompressedLen);
                    CompressionService.decompressBuffer(compressedBuf.bDR(), retcont.b());
                } finally {
                    compressedBuf.discard();
                }
            } else {
                uncompressedLen = length;
                retcont = factory.getContainer(length);
                retcont.b().limit(length);
                while (retcont.b().hasRemaining()) {
                    int read = m_fc.read(retcont.b());
                    if (read == -1) {
                        throw new EOFException();
                    }
                }
                retcont.b().flip();
            }

            m_bytesRead += uncompressedLen;

            return new DBBPool.BBContainer(retcont.b()) {
                private boolean m_discarded = false;

                @Override
                public void discard() {
                    checkDoubleFree();
                    if (m_discarded) {
                        LOG.error("PBD Container discarded more than once");
                        return;
                    }

                    m_discarded = true;
                    retcont.discard();
                    m_discardCount++;
                }
            };
        } finally {
            m_readOffset = m_fc.position();
            m_fc.position(writePos);
        }
    }

    @Override
    public int uncompressedBytesToRead() {
        if (m_closed) throw new RuntimeException("Segment closed");
        return m_size - m_bytesRead;
    }
}

<code block>


package org.voltdb.importclient;

import java.io.BufferedInputStream;
import java.io.EOFException;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.ArrayList;
import java.util.Properties;

import org.apache.log4j.spi.LoggingEvent;
import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltcore.network.ReverseDNSCache;
import org.voltdb.importer.ImportHandlerProxy;
import org.voltdb.importer.Invocation;


public class Log4jSocketHandlerImporter extends ImportHandlerProxy implements BundleActivator
{

    private static final String PORT_CONFIG = "port";
    private static final String EVENT_TABLE_CONFIG = "log-event-table";

    private int m_port;
    private String m_tableName;
    private ServerSocket m_serverSocket;
    private final ArrayList<SocketReader> m_connections = new ArrayList<SocketReader>();

    @Override
    public void start(BundleContext context)
    {
        context.registerService(Log4jSocketHandlerImporter.class.getName(), this, null);
    }

    @Override
    public void stop(BundleContext context)
    {
        stop();
    }

    @Override
    public void stop()
    {
        closeServerSocket();

        for (SocketReader conn : m_connections) {
            conn.stop();
        }
        m_connections.clear();
    }

    private void closeServerSocket()
    {
        try {
            if (m_serverSocket!=null) {
                m_serverSocket.close();
            }
        } catch(IOException e) { 
            info("Unexpected error closing log4j socket appender listener on " + m_port);
        }
    }

    
    @Override
    public String getName()
    {
        return "Log4jSocketHandlerImporter";
    }

    
    @Override
    public void configure(Properties p)
    {
        Properties properties = (Properties) p.clone();
        String str = properties.getProperty(PORT_CONFIG);
        if (str == null || str.trim().length() == 0) {
            throw new RuntimeException(PORT_CONFIG + " must be specified as a log4j socket importer property");
        }
        m_port = Integer.parseInt(str);

        closeServerSocket(); 
        try {
            m_serverSocket = new ServerSocket(m_port);
            info("Log4j socket appender listener listening on port: " + m_port);
        } catch(IOException e) {
            error("IOException opening server socket on port " + m_port + " - " + e.getMessage());
            throw new RuntimeException(e);
        }

        m_tableName = properties.getProperty(EVENT_TABLE_CONFIG);
        if (m_tableName==null || m_tableName.trim().length()==0) {
            throw new RuntimeException(EVENT_TABLE_CONFIG + " must be specified as a log4j socket importer property");
        }

        
        
        
    }


    
    @Override
    public void readyForData()
    {
        if (!hasTable(m_tableName)) {
            printCreateTableError();
            return;
        }

        try {
            while (true) {
                Socket socket = m_serverSocket.accept();
                SocketReader reader = new SocketReader(socket);
                m_connections.add(reader);
                new Thread(reader).start();
            }
        } catch (IOException e) {
            
            error(String.format("Unexpected error [%s] accepting connections on port [%d]", e.getMessage(), m_serverSocket.getLocalPort()));
        } finally {
            closeServerSocket();
        }
    }

    private void printCreateTableError()
    {
            System.err.println("Log event table must exist before Log4j socket importer can be used");
            System.err.println("Please create the table using the following ddl and use appropriate partition:");
            System.err.println("CREATE TABLE " + m_tableName + "\n" +
            "(\n" +
            "  log_event_host    varchar(256) NOT NULL\n" +
            ", logger_name       varchar(256) NOT NULL\n" +
            ", log_level         varchar(25)  NOT NULL\n" +
            ", logging_thread    varchar(25)  NOT NULL\n" +
            ", log_timestamp     timestamp    NOT NULL\n" +
            ", log_message       varchar(1024)\n" +
            ", throwable_str_rep varchar(4096)\n" +
            ");\n" +
            "PARTITION TABLE " + m_tableName + " ON COLUMN log_event_host;");
    }

    
    private class SocketReader implements Runnable
    {
        private final Socket m_socket;

        public SocketReader(Socket socket)
        {
            m_socket = socket;
            Log4jSocketHandlerImporter.this.info("Connected to socket appender at " + socket.getRemoteSocketAddress());
        }

        @Override
        public void run()
        {
            try {
                String hostname = ReverseDNSCache.hostnameOrAddress(m_socket.getInetAddress());
                ObjectInputStream ois = new ObjectInputStream(new BufferedInputStream(m_socket.getInputStream()));
                while (true) {
                    LoggingEvent event = (LoggingEvent) ois.readObject();
                    if (!Log4jSocketHandlerImporter.this.callProcedure(new SaveLog4jEventInvocation(hostname, event, m_tableName))) {
                        Log4jSocketHandlerImporter.this.error("Failed to insert log4j event");
                    }
                }
            } catch(EOFException e) { 
                Log4jSocketHandlerImporter.this.info("Client disconnected from " + m_socket.getRemoteSocketAddress());
            } catch (ClassNotFoundException | IOException e) { 
                                                               
                Log4jSocketHandlerImporter.this.error(String.format("Unexpected error [%s] reading from %s", e.getMessage(), m_socket.getRemoteSocketAddress()));
                e.printStackTrace();
            } finally {
                closeSocket();
            }
        }

        public void stop()
        {
            closeSocket();
        }

        private void closeSocket()
        {
            try {
                m_socket.close();
            } catch(IOException e) {
                Log4jSocketHandlerImporter.this.error("Could not close log4j event reader socket on " + m_socket.getLocalPort());
                e.printStackTrace();
            }
        }
    }

    
    private class SaveLog4jEventInvocation implements Invocation {

        private final String m_hostName;
        private final LoggingEvent m_event;
        private final String m_procName;

        public SaveLog4jEventInvocation(String hostName, LoggingEvent loggingEvent, String tableName) {
            m_hostName = hostName;
            m_event = loggingEvent;
            m_procName = tableName + ".insert";
        }
        @Override
        public String getProcedure()
        {
            return m_procName;
        }

        @Override
        public Object[] getParams() throws IOException
        {
            return new Object[] {
                    m_hostName,
                    m_event.getLoggerName(),
                    m_event.getLevel().toString(),
                    m_event.getThreadName(),
                    m_event.getTimeStamp()*1000,
                    m_event.getRenderedMessage(),
                    getThrowableRep(m_event)
           };
        }

        
        
        
        private String getThrowableRep(LoggingEvent event)
        {
            if (event.getThrowableStrRep() == null || event.getThrowableStrRep().length==0) {
                return null;
            }

            StringBuffer sb = new StringBuffer();
            for (String line : event.getThrowableStrRep()) {
                sb.append(line + "\n");
            }

            
            return sb.deleteCharAt(sb.length() - 1).toString();
        }
    }
}

<code block>


package org.voltdb.importclient;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.ArrayList;
import java.util.Properties;

import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltdb.importer.CSVInvocation;
import org.voltdb.importer.ImportHandlerProxy;


public class SocketStreamImporter extends ImportHandlerProxy implements BundleActivator {

    private Properties m_properties;
    private ServerSocket m_serverSocket;
    private String m_procedure;
    private final ArrayList<ClientConnectionHandler> m_clients = new ArrayList<ClientConnectionHandler>();

    
    @Override
    public void start(BundleContext context) throws Exception {
        context.registerService(SocketStreamImporter.class.getName(), this, null);
    }

    @Override
    public void stop(BundleContext context) throws Exception {
        
    }

    @Override
    public void stop() {
        try {
            for (ClientConnectionHandler s : m_clients) {
                s.stopClient();
            }
            m_clients.clear();
            m_serverSocket.close();
            m_serverSocket = null;
        } catch (IOException ex) {
            ex.printStackTrace();
        }
    }

    
    @Override
    public String getName() {
        return "SocketImporter";
    }

    
    @Override
    public void configure(Properties p) {
        m_properties = (Properties) p.clone();
        String s = (String )m_properties.get("port");
        m_procedure = (String )m_properties.get("procedure");
        if (m_procedure == null || m_procedure.trim().length() == 0) {
            throw new RuntimeException("Missing procedure.");
        }
        try {
            if (m_serverSocket != null) {
                m_serverSocket.close();
            }
            m_serverSocket = new ServerSocket(Integer.parseInt(s));
        } catch (IOException ex) {
           ex.printStackTrace();
           throw new RuntimeException(ex.getCause());
        }
    }

    
    private class ClientConnectionHandler extends Thread {
        private final Socket m_clientSocket;
        private final String m_procedure;
        private final ImportHandlerProxy m_importHandlerProxy;

        public ClientConnectionHandler(ImportHandlerProxy ic, Socket clientSocket, String procedure) {
            m_importHandlerProxy = ic;
            m_clientSocket = clientSocket;
            m_procedure = procedure;
        }

        @Override
        public void run() {
            try {
                while (true) {
                    BufferedReader in = new BufferedReader(
                            new InputStreamReader(m_clientSocket.getInputStream()));
                    while (true) {
                        String line = in.readLine();
                        
                        if (line == null) break;
                        CSVInvocation invocation = new CSVInvocation(m_procedure, line);
                        if (!callProcedure(invocation)) {
                            System.out.println("Inserted failed: " + line);
                        }
                    }
                    m_clientSocket.close();
                    System.out.println("Client Closed.");
                }
            } catch (IOException ioe) {
                ioe.printStackTrace();
            }
        }

        public void stopClient() {
            try {
                m_clientSocket.close();
            } catch (IOException ex) {
                ex.printStackTrace();
            }
        }
    }

    
    @Override
    public void readyForData() {
        try {
            info("Configured and ready with properties: " + m_properties);
            String procedure = m_properties.getProperty("procedure");
            while (true) {
                Socket clientSocket = m_serverSocket.accept();
                ClientConnectionHandler ch = new ClientConnectionHandler(this, clientSocket, procedure);
                m_clients.add(ch);
                ch.start();
            }
        } catch (Exception ex) {
            ex.printStackTrace();
        }
    }

}

<code block>


package org.voltdb.importclient;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;
import kafka.message.MessageAndMetadata;
import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltdb.importer.CSVInvocation;
import org.voltdb.importer.ImportHandlerProxy;


public class KafkaStreamImporter extends ImportHandlerProxy implements BundleActivator {

    private Properties m_properties;
    private String m_procedure;
    private String[] m_topic;
    private String m_zookeeper;

    private KafkaStreamConsumerConnector m_connector;
    private ExecutorService m_es;

    
    @Override
    public void start(BundleContext context) throws Exception {
        context.registerService(KafkaStreamImporter.class.getName(), this, null);
    }

    @Override
    public void stop(BundleContext context) throws Exception {
        
    }

    @Override
    public synchronized void stop() {
        synchronized (this) {
            try {
                if (m_connector != null) {
                    info("Stopping Kafka connector.");
                    m_connector.stop();
                    info("Stopped Kafka connector.");
                }
            } catch (Exception ex) {
                ex.printStackTrace();
            } finally {
                m_connector = null;
            }
            try {
                if (m_es != null) {
                    info("Stopping Kafka consumer executor.");
                    m_es.shutdown();
                    m_es.awaitTermination(1, TimeUnit.DAYS);
                    info("Stopped Kafka consumer executor.");
                }
            } catch (Exception ex) {
                ex.printStackTrace();
            } finally {
                m_es = null;
            }
        }
    }

    
    @Override
    public String getName() {
        return "KafkaImporter";
    }

    
    @Override
    public void configure(Properties p) {
        m_properties = (Properties) p.clone();
        m_procedure = (String )m_properties.get("procedure");
        if (m_procedure == null || m_procedure.trim().length() == 0) {
            throw new RuntimeException("Missing procedure.");
        }
        String topics = (String )m_properties.getProperty("topic");
        if (topics == null || topics.trim().length() == 0) {
            throw new RuntimeException("Missing topic(s).");
        }
        m_topic = topics.split(",");
        if (m_topic == null || m_topic.length == 0) {
            throw new RuntimeException("Missing topic(s).");
        }
        m_zookeeper = (String )m_properties.getProperty("zookeeper");
        if (m_zookeeper == null || m_zookeeper.trim().length() == 0) {
            throw new RuntimeException("Missing kafka zookeeper");
        }
    }

    private class KafkaStreamConsumerConnector {

        private ConsumerConnector m_consumer;

        public KafkaStreamConsumerConnector(String zk, String groupName) {
            
            String groupId = "voltdbimporter-" + groupName;
            
            Properties props = new Properties();
            props.put("zookeeper.connect", zk);
            props.put("group.id", groupId);
            props.put("zookeeper.session.timeout.ms", "400");
            props.put("zookeeper.sync.time.ms", "200");
            props.put("auto.commit.interval.ms", "1000");
            props.put("auto.commit.enable", "true");
            props.put("auto.offset.reset", "smallest");
            props.put("rebalance.backoff.ms", "10000");

            m_consumer = kafka.consumer.Consumer.createJavaConsumerConnector(new ConsumerConfig(props));
        }

        public void stop() {
            try {
                m_consumer.commitOffsets();
            } catch (Exception ex) {
                ex.printStackTrace();
            }
            try {
                m_consumer.shutdown();
            } catch (Exception ex) {
                ex.printStackTrace();
            } finally {
                m_consumer = null;
            }
        }
    }

    private class KafkaConsumer implements Runnable {

        private final KafkaStream m_stream;
        private final String m_procedure;

        public KafkaConsumer(KafkaStream a_stream, String proc) {
            m_stream = a_stream;
            m_procedure = proc;
        }

        @Override
        public void run() {
            try {
                ConsumerIterator<byte[], byte[]> it = m_stream.iterator();
                while (it.hasNext()) {
                    MessageAndMetadata<byte[], byte[]> md = it.next();
                    byte msg[] = md.message();
                    String line = new String(msg);
                    CSVInvocation invocation = new CSVInvocation(m_procedure, line);
                    callProcedure(invocation);
                }
            } catch (Exception ex) {
                ex.printStackTrace();
            }
        }

    }

    private ExecutorService getConsumerExecutor(KafkaStreamConsumerConnector consumer) throws Exception {

        Map<String, Integer> topicCountMap = new HashMap<>();
        
        ExecutorService executor = Executors.newFixedThreadPool(3 * m_topic.length);
        for (int i = 0; i < m_topic.length; i++) {
            topicCountMap.put(m_topic[i], 1);
        }
        Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumer.m_consumer.createMessageStreams(topicCountMap);

        for (int i = 0; i < m_topic.length; i++) {
            List<KafkaStream<byte[], byte[]>> streams = consumerMap.get(m_topic[i]);

            
            for (final KafkaStream stream : streams) {
                KafkaConsumer bconsumer = new KafkaConsumer(stream, m_procedure);
                executor.submit(bconsumer);
            }
        }

        return executor;
    }

    
    @Override
    public void readyForData() {
        try {
            info("Configured and ready with properties: " + m_properties);
            synchronized (this) {
                
                m_connector = new KafkaStreamConsumerConnector(m_zookeeper, "voltdb-importer");
                m_es = getConsumerExecutor(m_connector);
            }
            
            m_es.awaitTermination(365, TimeUnit.DAYS);
        } catch (Exception ex) {
            ex.printStackTrace();
        }
    }

}

<code block>


package org.voltdb.importer;

import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import java.util.ServiceLoader;

import org.osgi.framework.Bundle;
import org.osgi.framework.Constants;
import org.osgi.framework.ServiceReference;
import org.osgi.framework.launch.Framework;
import org.osgi.framework.launch.FrameworkFactory;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltdb.CatalogContext;
import org.voltdb.ImportHandler;
import org.voltdb.VoltDB;

import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.base.Throwables;
import org.osgi.framework.BundleException;

public class ImportProcessor implements ImportDataProcessor {

    private static final VoltLogger m_logger = new VoltLogger("IMPORT");
    private final FrameworkFactory m_frameworkFactory;
    private final Map<String, String> m_frameworkProps;
    private final Map<String, BundleWrapper> m_bundles = new HashMap<String, BundleWrapper>();
    private final Map<String, BundleWrapper> m_bundlesByName = new HashMap<String, BundleWrapper>();
    private final Framework m_framework;

    public ImportProcessor() throws BundleException {
        
        m_frameworkProps = new HashMap<String, String>();
        
        m_frameworkProps.put(Constants.FRAMEWORK_SYSTEMPACKAGES_EXTRA, "org.voltcore.network;version=1.0.0"
                + ",org.voltdb.importer;version=1.0.0,org.apache.log4j;version=1.0.0,org.voltdb.client;version=1.0.0,org.slf4j;version=1.0.0");
        
        m_frameworkProps.put("org.osgi.framework.storage.clean", "onFirstInit");
        m_frameworkFactory = ServiceLoader.load(FrameworkFactory.class).iterator().next();
        m_framework = m_frameworkFactory.newFramework(m_frameworkProps);
        m_framework.start();
    }

    
    public class BundleWrapper {
        public final Bundle m_bundle;
        public final Properties m_properties;
        public final ImportHandlerProxy m_handlerProxy;
        private ImportHandler m_handler;

        public BundleWrapper(ImportHandlerProxy handler, Properties properties, Bundle bundle) {
            m_bundle = bundle;
            m_handlerProxy = handler;
            m_properties = properties;
        }

        public void setHandler(ImportHandler handler) throws Exception {
            Preconditions.checkState((m_handler == null), "ImportHandler can only be set once.");
            m_handler = handler;
            m_handlerProxy.setHandler(handler);
        }

        public ImportHandler getHandler() {
            return m_handler;
        }

        public void stop() {
            try {
                m_handler.stop();
                if (m_bundle != null) {
                    m_bundle.stop();
                }
            } catch (Exception ex) {
                m_logger.error("Failed to stop the import bundles.", ex);
            }
        }
    }

    public void addProcessorConfig(Properties properties) {
        String module = properties.getProperty(ImportDataProcessor.IMPORT_MODULE);
        String moduleAttrs[] = module.split("\\|");
        String bundleJar = moduleAttrs[1];
        String moduleType = moduleAttrs[0];

        Preconditions.checkState(!m_bundles.containsKey(bundleJar), "Import to source is already defined.");
        try {
            BundleWrapper wrapper = null;
            ImportHandlerProxy importHandlerProxy = null;
            if (moduleType.equalsIgnoreCase("osgi")) {

                Bundle bundle = m_framework.getBundleContext().installBundle(bundleJar);
                bundle.start();
                ServiceReference refs[] = bundle.getRegisteredServices();
                
                ServiceReference reference = refs[0];
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    bundle.stop();
                    return;
                }
                Object o = bundle.getBundleContext().getService(reference);
                importHandlerProxy = (ImportHandlerProxy )o;
                wrapper = new BundleWrapper(importHandlerProxy, properties, bundle);
            } else {
                
                Class reference = this.getClass().getClassLoader().loadClass(bundleJar);
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    return;
                }

                importHandlerProxy = (ImportHandlerProxy )reference.newInstance();
                 wrapper = new BundleWrapper(importHandlerProxy, properties, null);
            }
            importHandlerProxy.configure(properties);
            String name = importHandlerProxy.getName();
            if (name == null || name.trim().length() == 0) {
                throw new RuntimeException("Importer must implement and return a valid unique name.");
            }
            Preconditions.checkState(!m_bundlesByName.containsKey(name), "Importer must implement and return a valid unique name: " + name);
            m_bundlesByName.put(name, wrapper);
            m_bundles.put(bundleJar, wrapper);
        } catch(Throwable t) {
            m_logger.error("Failed to configure import handler for " + bundleJar, t);
            Throwables.propagate(t);
        }
    }

    @Override
    public synchronized void readyForData(CatalogContext catContext, HostMessenger messenger) {

        for (BundleWrapper bw : m_bundles.values()) {
            try {
                ImportHandler importHandler = new ImportHandler(bw.m_handlerProxy, catContext);
                
                bw.setHandler(importHandler);
                importHandler.readyForData();
                m_logger.info("Importer started: " + bw.m_handlerProxy.getName());
            } catch (Exception ex) {
                
                VoltDB.crashLocalVoltDB("Import failed to set Handler", true, ex);
                m_logger.error("Failed to start the import handler: " + bw.m_handlerProxy.getName(), ex);
            }
        }
    }

    @Override
    public synchronized void shutdown() {
        try {
            
            for (BundleWrapper bw : m_bundles.values()) {
                try {
                    bw.stop();
                } catch (Exception ex) {
                    m_logger.error("Failed to stop the import handler: " + bw.m_handlerProxy.getName(), ex);
                }
            }
            m_bundles.clear();
            if (m_framework != null) {
                m_framework.stop();
                m_framework.uninstall();
            }
        } catch (Exception ex) {
            m_logger.error("Failed to stop the import bundles.", ex);
        }
    }

    @Override
    public void setProcessorConfig(Map<String, Properties> config) {
        for (String cname : config.keySet()) {
            Properties properties = config.get(cname);

            String importBundleJar = properties.getProperty(IMPORT_MODULE);
            Preconditions.checkNotNull(importBundleJar, "Import source is undefined or custom export plugin class missing.");
            addProcessorConfig(properties);
        }
    }

}

<code block>



package org.voltdb;

import java.io.File;
import java.io.IOException;
import java.io.OutputStream;
import java.net.Socket;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import java.util.Random;
import java.util.concurrent.CountDownLatch;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.log4j.net.SocketAppender;
import org.voltdb.client.Client;
import org.voltdb.client.ClientImpl;
import org.voltdb.client.ClientResponse;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.regressionsuites.LocalCluster;
import org.voltdb.regressionsuites.MultiConfigSuiteBuilder;
import org.voltdb.regressionsuites.RegressionSuite;
import org.voltdb.regressionsuites.TestSQLTypesSuite;
import org.voltdb.utils.VoltFile;

import com.google_voltpatches.common.collect.ImmutableMap;



public class TestImportSuite extends RegressionSuite {
    private static final Logger s_testSocketLogger = Logger.getLogger("testSocketLogger");
    private static final Level[] s_levels =
        { Level.DEBUG, Level.ERROR, Level.FATAL, Level.INFO, Level.TRACE, Level.WARN };

    private Boolean m_socketHandlerInitialized = false;

    @Override
    public void setUp() throws Exception
    {
        VoltFile.recursivelyDelete(new File("/tmp/" + System.getProperty("user.name")));
        File f = new File("/tmp/" + System.getProperty("user.name"));
        f.mkdirs();

        super.setUp();
    }

    private void setupLog4jSocketHandler() {
        synchronized(m_socketHandlerInitialized) {
            if (m_socketHandlerInitialized) return;

            SocketAppender appender = new SocketAppender("localhost", 6060);
            appender.setReconnectionDelay(50);
            s_testSocketLogger.setAdditivity(false);
            s_testSocketLogger.removeAllAppenders();
            s_testSocketLogger.setLevel(Level.ALL);
            s_testSocketLogger.addAppender(appender);
            m_socketHandlerInitialized = true;
        }
    }

    @Override
    public void tearDown() throws Exception {
        super.tearDown();
    }

    abstract class DataPusher extends Thread {
        private final int m_count;
        private final CountDownLatch m_latch;

        public DataPusher(int count, CountDownLatch latch) {
            m_count = count;
            m_latch = latch;
        }

        protected abstract void initialize();
        protected abstract void close();
        protected abstract void pushData(String str) throws Exception;

        @Override
        public void run() {
            initialize();

            try {
                for (int icnt = 0; icnt < m_count; icnt++) {
                    String s = String.valueOf(System.nanoTime() + icnt) + "," + System.currentTimeMillis() + "\n";
                    pushData(s);
                    Thread.sleep(0, 1);
                }
            } catch (Exception ex) {
                ex.printStackTrace();
            } finally {
                close();
                m_latch.countDown();
            }
        }

    }

    class SocketDataPusher extends DataPusher {
        private final String m_server;
        private final int m_port;
        private OutputStream m_sout;

        public SocketDataPusher(String server, int port, int count, CountDownLatch latch) {
            super(count, latch);
            m_server = server;
            m_port = port;
        }

        @Override
        protected void initialize() {
            m_sout = connectToOneServerWithRetry(m_server, m_port);
            System.out.printf("Connected to VoltDB socket importer at: %s.\n", m_server + ":" + m_port);
        }

        @Override
        protected void pushData(String str) throws Exception {
            m_sout.write(str.getBytes());
        }

        @Override
        protected void close() {
            try {
                m_sout.flush();
                m_sout.close();
            } catch (IOException ex) {
            }
        }
    }

    class Log4jDataPusher extends DataPusher {

        private final Random random = new Random();

        public Log4jDataPusher(int count, CountDownLatch latch) {
            super(count, latch);
        }

        @Override
        protected void initialize() {
            TestImportSuite.this.setupLog4jSocketHandler();
        }

        @Override
        protected void pushData(String str) throws Exception {
            s_testSocketLogger.log(s_levels[random.nextInt(s_levels.length)], str);
        }

        @Override
        protected void close() {
        }
    }

    private void pushDataToImporters(int count, int loops) throws Exception {
        CountDownLatch latch = new CountDownLatch(2*loops);
        for (int i=0; i<loops; i++) {
            (new SocketDataPusher("localhost", 7001, count, latch)).start();
            (new Log4jDataPusher(count, latch)).start();
        }
        latch.await();
    }

    private void verifyData(Client client, int count) throws Exception {
        verifyData(client, count, -1);
    }

    private void verifyData(Client client, int count, int min) throws Exception {
        ClientResponse response = client.callProcedure("@AdHoc", "select count(*) from importTable");
        assertEquals(ClientResponse.SUCCESS, response.getStatus());
            assertEquals(count, response.getResults()[0].asScalarLong());

        response = client.callProcedure("@AdHoc", "select count(*) from log_events");
        assertEquals(ClientResponse.SUCCESS, response.getStatus());
        if (min<0) {
            assertEquals(count, response.getResults()[0].asScalarLong());
        } else {
            long result = response.getResults()[0].asScalarLong();
            assertTrue(result + " not between " + min + " and " + count, result>=min && result<=count);
        }
    }

    public void testImportSimpleData() throws Exception {
        System.out.println("testImportSimpleData");
        Client client = getClient();
        while (!((ClientImpl) client).isHashinatorInitialized()) {
            Thread.sleep(1000);
            System.out.println("Waiting for hashinator to be initialized...");
        }

        pushDataToImporters(100, 1);
        verifyData(client, 100);
        client.close();
    }

    public void testImportMultipleTimes() throws Exception {
        System.out.println("testImportUpdateApplicationCatalog");
        Client client = getClient();
        while (!((ClientImpl) client).isHashinatorInitialized()) {
            Thread.sleep(1000);
            System.out.println("Waiting for hashinator to be initialized...");
        }

        pushDataToImporters(100, 1);
        verifyData(client, 100);

        Thread.sleep(0, 1);

        pushDataToImporters(100, 1);
        verifyData(client, 200);

        client.close();
    }

    public void testImportMultipleClientsInParallel() throws Exception {
        System.out.println("testImportMultipleClientsInParallel");
        Client client = getClient();
        while (!((ClientImpl) client).isHashinatorInitialized()) {
            Thread.sleep(1000);
            System.out.println("Waiting for hashinator to be initialized...");
        }

        pushDataToImporters(100, 2);
        verifyData(client, 100*2);
        client.close();
    }

    public void testImportMultipleClientsUpdateApplicationCatalogWhenNotPushing() throws Exception {
        System.out.println("testImportMultipleClientsUpdateApplicationCatalogWhenNotPushing");
        Client client = getClient();
        while (!((ClientImpl) client).isHashinatorInitialized()) {
            Thread.sleep(1000);
            System.out.println("Waiting for hashinator to be initialized...");
        }

        pushDataToImporters(1000, 3);
        verifyData(client, 3000);

        ClientResponse response = client.callProcedure("@AdHoc", "create table nudge(id integer);");
        assertEquals(ClientResponse.SUCCESS, response.getStatus());

        pushDataToImporters(1000, 4);
        
        verifyData(client, 7000, 3001);

        client.close();
    }

    
    static OutputStream connectToOneServerWithRetry(String server, int port) {
        int sleep = 1000;
        while (true) {
            try {
                Socket pushSocket = new Socket(server, port);
                OutputStream out = pushSocket.getOutputStream();
                System.out.printf("Connected to VoltDB node at: %s.\n", server);
                return out;
            }
            catch (Exception e) {
                System.err.printf("Connection failed - retrying in %d second(s).\n", sleep / 1000);
                try { Thread.sleep(sleep); } catch (Exception interruted) {}
                if (sleep < 8000) sleep += sleep;
            }
        }
    }

    public TestImportSuite(final String name) {
        super(name);
    }

    static public junit.framework.Test suite() throws Exception
    {

        LocalCluster config;
        Map<String, String> additionalEnv = new HashMap<String, String>();
        
        String bundleLocation = System.getProperty("user.dir") + "/bundles";
        System.out.println("Bundle location is: " + bundleLocation);
        additionalEnv.put("voltdbbundlelocation", bundleLocation);

        final MultiConfigSuiteBuilder builder =
            new MultiConfigSuiteBuilder(TestImportSuite.class);

        VoltProjectBuilder project = new VoltProjectBuilder();
        project.setUseDDLSchema(true);
        project.addSchema(TestSQLTypesSuite.class.getResource("sqltypessuite-import-ddl.sql"));

        
        Properties props = new Properties();
        props.putAll(ImmutableMap.<String, String>of(
                "port", "7001",
                "decode", "true",
                "procedure", "importTable.insert"));
        project.addImport(true, "custom", "csv", "socketstream.jar", props);
        project.addPartitionInfo("importTable", "PKEY");

        
        props = new Properties();
        props.putAll(ImmutableMap.<String, String>of(
                "port", "6060",
                "procedure", "importTable.insert",
                "log-event-table", "log_events"));
        project.addImport(true, "custom", null, "log4jsocketimporter.jar", props);

        

        config = new LocalCluster("import-ddl-cluster-rep.jar", 4, 1, 0,
                BackendTarget.NATIVE_EE_JNI, LocalCluster.FailureState.ALL_RUNNING, true, false, additionalEnv);
        config.setHasLocalServer(false);
        boolean compile = config.compile(project);
        assertTrue(compile);
        builder.addServerConfig(config);

        return builder;
    }
}

<code block>


package org.voltdb.importclient;

import java.io.BufferedInputStream;
import java.io.EOFException;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.ArrayList;
import java.util.Properties;

import org.apache.log4j.spi.LoggingEvent;
import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltcore.network.ReverseDNSCache;
import org.voltdb.importer.ImportHandlerProxy;
import org.voltdb.importer.Invocation;


public class Log4jSocketHandlerImporter extends ImportHandlerProxy implements BundleActivator
{

    private static final String PORT_CONFIG = "port";
    private static final String EVENT_TABLE_CONFIG = "log-event-table";

    private int m_port;
    private String m_tableName;
    private ServerSocket m_serverSocket;
    private final ArrayList<SocketReader> m_connections = new ArrayList<SocketReader>();

    @Override
    public void start(BundleContext context)
    {
        context.registerService(ImportHandlerProxy.class.getName(), this, null);
    }

    @Override
    public void stop(BundleContext context)
    {
        stop();
    }

    @Override
    public void stop()
    {
        closeServerSocket();

        for (SocketReader conn : m_connections) {
            conn.stop();
        }
        m_connections.clear();
    }

    private void closeServerSocket()
    {
        try {
            if (m_serverSocket!=null) {
                m_serverSocket.close();
            }
        } catch(IOException e) { 
            info("Unexpected error closing log4j socket appender listener on " + m_port);
        }
    }

    
    @Override
    public String getName()
    {
        return "Log4jSocketHandlerImporter";
    }

    
    @Override
    public void configure(Properties p)
    {
        Properties properties = (Properties) p.clone();
        String str = properties.getProperty(PORT_CONFIG);
        if (str == null || str.trim().length() == 0) {
            throw new RuntimeException(PORT_CONFIG + " must be specified as a log4j socket importer property");
        }
        m_port = Integer.parseInt(str);

        closeServerSocket(); 
        try {
            m_serverSocket = new ServerSocket(m_port);
            info("Log4j socket appender listener listening on port: " + m_port);
        } catch(IOException e) {
            error("IOException opening server socket on port " + m_port + " - " + e.getMessage());
            throw new RuntimeException(e);
        }

        m_tableName = properties.getProperty(EVENT_TABLE_CONFIG);
        if (m_tableName==null || m_tableName.trim().length()==0) {
            throw new RuntimeException(EVENT_TABLE_CONFIG + " must be specified as a log4j socket importer property");
        }

        
        
        
    }


    
    @Override
    public void readyForData()
    {
        if (!hasTable(m_tableName)) {
            printCreateTableError();
            return;
        }

        try {
            while (true) {
                Socket socket = m_serverSocket.accept();
                SocketReader reader = new SocketReader(socket);
                m_connections.add(reader);
                new Thread(reader).start();
            }
        } catch (IOException e) {
            
            error(String.format("Unexpected error [%s] accepting connections on port [%d]", e.getMessage(), m_serverSocket.getLocalPort()));
        } finally {
            closeServerSocket();
        }
    }

    private void printCreateTableError()
    {
            System.err.println("Log event table must exist before Log4j socket importer can be used");
            System.err.println("Please create the table using the following ddl and use appropriate partition:");
            System.err.println("CREATE TABLE " + m_tableName + "\n" +
            "(\n" +
            "  log_event_host    varchar(256) NOT NULL\n" +
            ", logger_name       varchar(256) NOT NULL\n" +
            ", log_level         varchar(25)  NOT NULL\n" +
            ", logging_thread    varchar(25)  NOT NULL\n" +
            ", log_timestamp     timestamp    NOT NULL\n" +
            ", log_message       varchar(1024)\n" +
            ", throwable_str_rep varchar(4096)\n" +
            ");\n" +
            "PARTITION TABLE " + m_tableName + " ON COLUMN log_event_host;");
    }

    
    private class SocketReader implements Runnable
    {
        private final Socket m_socket;

        public SocketReader(Socket socket)
        {
            m_socket = socket;
            Log4jSocketHandlerImporter.this.info("Connected to socket appender at " + socket.getRemoteSocketAddress());
        }

        @Override
        public void run()
        {
            try {
                String hostname = ReverseDNSCache.hostnameOrAddress(m_socket.getInetAddress());
                ObjectInputStream ois = new ObjectInputStream(new BufferedInputStream(m_socket.getInputStream()));
                while (true) {
                    LoggingEvent event = (LoggingEvent) ois.readObject();
                    if (!Log4jSocketHandlerImporter.this.callProcedure(new SaveLog4jEventInvocation(hostname, event, m_tableName))) {
                        Log4jSocketHandlerImporter.this.error("Failed to insert log4j event");
                    }
                }
            } catch(EOFException e) { 
                Log4jSocketHandlerImporter.this.info("Client disconnected from " + m_socket.getRemoteSocketAddress());
            } catch (ClassNotFoundException | IOException e) { 
                                                               
                Log4jSocketHandlerImporter.this.error(String.format("Unexpected error [%s] reading from %s", e.getMessage(), m_socket.getRemoteSocketAddress()));
                e.printStackTrace();
            } finally {
                closeSocket();
            }
        }

        public void stop()
        {
            closeSocket();
        }

        private void closeSocket()
        {
            try {
                m_socket.close();
            } catch(IOException e) {
                Log4jSocketHandlerImporter.this.error("Could not close log4j event reader socket on " + m_socket.getLocalPort());
                e.printStackTrace();
            }
        }
    }

    
    private class SaveLog4jEventInvocation implements Invocation {

        private final String m_hostName;
        private final LoggingEvent m_event;
        private final String m_procName;

        public SaveLog4jEventInvocation(String hostName, LoggingEvent loggingEvent, String tableName) {
            m_hostName = hostName;
            m_event = loggingEvent;
            m_procName = tableName + ".insert";
        }
        @Override
        public String getProcedure()
        {
            return m_procName;
        }

        @Override
        public Object[] getParams() throws IOException
        {
            return new Object[] {
                    m_hostName,
                    m_event.getLoggerName(),
                    m_event.getLevel().toString(),
                    m_event.getThreadName(),
                    m_event.getTimeStamp()*1000,
                    m_event.getRenderedMessage(),
                    getThrowableRep(m_event)
           };
        }

        
        
        
        private String getThrowableRep(LoggingEvent event)
        {
            if (event.getThrowableStrRep() == null || event.getThrowableStrRep().length==0) {
                return null;
            }

            StringBuffer sb = new StringBuffer();
            for (String line : event.getThrowableStrRep()) {
                sb.append(line + "\n");
            }

            
            return sb.deleteCharAt(sb.length() - 1).toString();
        }
    }
}

<code block>


package org.voltdb.importclient;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.ArrayList;
import java.util.Properties;

import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltdb.importer.CSVInvocation;
import org.voltdb.importer.ImportHandlerProxy;


public class SocketStreamImporter extends ImportHandlerProxy implements BundleActivator {

    private Properties m_properties;
    private ServerSocket m_serverSocket;
    private String m_procedure;
    private final ArrayList<ClientConnectionHandler> m_clients = new ArrayList<ClientConnectionHandler>();

    
    @Override
    public void start(BundleContext context) throws Exception {
        context.registerService(ImportHandlerProxy.class.getName(), this, null);
    }

    @Override
    public void stop(BundleContext context) throws Exception {
        
    }

    @Override
    public void stop() {
        try {
            for (ClientConnectionHandler s : m_clients) {
                s.stopClient();
            }
            m_clients.clear();
            m_serverSocket.close();
            m_serverSocket = null;
        } catch (IOException ex) {
            ex.printStackTrace();
        }
    }

    
    @Override
    public String getName() {
        return "SocketImporter";
    }

    
    @Override
    public void configure(Properties p) {
        m_properties = (Properties) p.clone();
        String s = (String )m_properties.get("port");
        m_procedure = (String )m_properties.get("procedure");
        if (m_procedure == null || m_procedure.trim().length() == 0) {
            throw new RuntimeException("Missing procedure.");
        }
        try {
            if (m_serverSocket != null) {
                m_serverSocket.close();
            }
            m_serverSocket = new ServerSocket(Integer.parseInt(s));
        } catch (IOException ex) {
           ex.printStackTrace();
           throw new RuntimeException(ex.getCause());
        }
    }

    
    private class ClientConnectionHandler extends Thread {
        private final Socket m_clientSocket;
        private final String m_procedure;
        private final ImportHandlerProxy m_importHandlerProxy;

        public ClientConnectionHandler(ImportHandlerProxy ic, Socket clientSocket, String procedure) {
            m_importHandlerProxy = ic;
            m_clientSocket = clientSocket;
            m_procedure = procedure;
        }

        @Override
        public void run() {
            try {
                while (true) {
                    BufferedReader in = new BufferedReader(
                            new InputStreamReader(m_clientSocket.getInputStream()));
                    while (true) {
                        String line = in.readLine();
                        
                        if (line == null) break;
                        CSVInvocation invocation = new CSVInvocation(m_procedure, line);
                        if (!callProcedure(invocation)) {
                            System.out.println("Inserted failed: " + line);
                        }
                    }
                    m_clientSocket.close();
                    System.out.println("Client Closed.");
                }
            } catch (IOException ioe) {
                ioe.printStackTrace();
            }
        }

        public void stopClient() {
            try {
                m_clientSocket.close();
            } catch (IOException ex) {
                ex.printStackTrace();
            }
        }
    }

    
    @Override
    public void readyForData() {
        try {
            info("Configured and ready with properties: " + m_properties);
            String procedure = m_properties.getProperty("procedure");
            while (true) {
                Socket clientSocket = m_serverSocket.accept();
                ClientConnectionHandler ch = new ClientConnectionHandler(this, clientSocket, procedure);
                m_clients.add(ch);
                ch.start();
            }
        } catch (Exception ex) {
            ex.printStackTrace();
        }
    }

}

<code block>


package org.voltdb.importclient;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;
import kafka.message.MessageAndMetadata;
import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltdb.importer.CSVInvocation;
import org.voltdb.importer.ImportHandlerProxy;


public class KafkaStreamImporter extends ImportHandlerProxy implements BundleActivator {

    private Properties m_properties;
    private String m_procedure;
    private String[] m_topic;
    private String m_zookeeper;

    private KafkaStreamConsumerConnector m_connector;
    private ExecutorService m_es;

    
    @Override
    public void start(BundleContext context) throws Exception {
        context.registerService(ImportHandlerProxy.class.getName(), this, null);
    }

    @Override
    public void stop(BundleContext context) throws Exception {
        
    }

    @Override
    public synchronized void stop() {
        synchronized (this) {
            try {
                if (m_connector != null) {
                    info("Stopping Kafka connector.");
                    m_connector.stop();
                    info("Stopped Kafka connector.");
                }
            } catch (Exception ex) {
                ex.printStackTrace();
            } finally {
                m_connector = null;
            }
            try {
                if (m_es != null) {
                    info("Stopping Kafka consumer executor.");
                    m_es.shutdown();
                    m_es.awaitTermination(1, TimeUnit.DAYS);
                    info("Stopped Kafka consumer executor.");
                }
            } catch (Exception ex) {
                ex.printStackTrace();
            } finally {
                m_es = null;
            }
        }
    }

    
    @Override
    public String getName() {
        return "KafkaImporter";
    }

    
    @Override
    public void configure(Properties p) {
        m_properties = (Properties) p.clone();
        m_procedure = (String )m_properties.get("procedure");
        if (m_procedure == null || m_procedure.trim().length() == 0) {
            throw new RuntimeException("Missing procedure.");
        }
        String topics = (String )m_properties.getProperty("topic");
        if (topics == null || topics.trim().length() == 0) {
            throw new RuntimeException("Missing topic(s).");
        }
        m_topic = topics.split(",");
        if (m_topic == null || m_topic.length == 0) {
            throw new RuntimeException("Missing topic(s).");
        }
        m_zookeeper = (String )m_properties.getProperty("zookeeper");
        if (m_zookeeper == null || m_zookeeper.trim().length() == 0) {
            throw new RuntimeException("Missing kafka zookeeper");
        }
    }

    private class KafkaStreamConsumerConnector {

        private ConsumerConnector m_consumer;

        public KafkaStreamConsumerConnector(String zk, String groupName) {
            
            String groupId = "voltdbimporter-" + groupName;
            
            Properties props = new Properties();
            props.put("zookeeper.connect", zk);
            props.put("group.id", groupId);
            props.put("zookeeper.session.timeout.ms", "400");
            props.put("zookeeper.sync.time.ms", "200");
            props.put("auto.commit.interval.ms", "1000");
            props.put("auto.commit.enable", "true");
            props.put("auto.offset.reset", "smallest");
            props.put("rebalance.backoff.ms", "10000");

            m_consumer = kafka.consumer.Consumer.createJavaConsumerConnector(new ConsumerConfig(props));
        }

        public void stop() {
            try {
                m_consumer.commitOffsets();
            } catch (Exception ex) {
                ex.printStackTrace();
            }
            try {
                m_consumer.shutdown();
            } catch (Exception ex) {
                ex.printStackTrace();
            } finally {
                m_consumer = null;
            }
        }
    }

    private class KafkaConsumer implements Runnable {

        private final KafkaStream m_stream;
        private final String m_procedure;

        public KafkaConsumer(KafkaStream a_stream, String proc) {
            m_stream = a_stream;
            m_procedure = proc;
        }

        @Override
        public void run() {
            try {
                ConsumerIterator<byte[], byte[]> it = m_stream.iterator();
                while (it.hasNext()) {
                    MessageAndMetadata<byte[], byte[]> md = it.next();
                    byte msg[] = md.message();
                    String line = new String(msg);
                    CSVInvocation invocation = new CSVInvocation(m_procedure, line);
                    callProcedure(invocation);
                }
            } catch (Exception ex) {
                ex.printStackTrace();
            }
        }

    }

    private ExecutorService getConsumerExecutor(KafkaStreamConsumerConnector consumer) throws Exception {

        Map<String, Integer> topicCountMap = new HashMap<>();
        
        ExecutorService executor = Executors.newFixedThreadPool(3 * m_topic.length);
        for (int i = 0; i < m_topic.length; i++) {
            topicCountMap.put(m_topic[i], 1);
        }
        Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumer.m_consumer.createMessageStreams(topicCountMap);

        for (int i = 0; i < m_topic.length; i++) {
            List<KafkaStream<byte[], byte[]>> streams = consumerMap.get(m_topic[i]);

            
            for (final KafkaStream stream : streams) {
                KafkaConsumer bconsumer = new KafkaConsumer(stream, m_procedure);
                executor.submit(bconsumer);
            }
        }

        return executor;
    }

    
    @Override
    public void readyForData() {
        try {
            info("Configured and ready with properties: " + m_properties);
            synchronized (this) {
                
                m_connector = new KafkaStreamConsumerConnector(m_zookeeper, "voltdb-importer");
                m_es = getConsumerExecutor(m_connector);
            }
            
            m_es.awaitTermination(365, TimeUnit.DAYS);
        } catch (Exception ex) {
            ex.printStackTrace();
        }
    }

}

<code block>


package org.voltdb.importer;

import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import java.util.ServiceLoader;

import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.osgi.framework.Bundle;
import org.osgi.framework.Constants;
import org.osgi.framework.ServiceReference;
import org.osgi.framework.launch.Framework;
import org.osgi.framework.launch.FrameworkFactory;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltdb.CatalogContext;
import org.voltdb.ImportHandler;
import org.voltdb.VoltDB;

import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.base.Throwables;

public class ImportProcessor implements ImportDataProcessor {

    private static final VoltLogger m_logger = new VoltLogger("IMPORT");
    private final FrameworkFactory m_frameworkFactory;
    private final Map<String, String> m_frameworkProps;
    private final Map<String, BundleWrapper> m_bundles = new HashMap<String, BundleWrapper>();
    private final Map<String, BundleWrapper> m_bundlesByName = new HashMap<String, BundleWrapper>();

    public ImportProcessor() {
        
        m_frameworkProps = new HashMap<String, String>();
        
        m_frameworkProps.put(Constants.FRAMEWORK_SYSTEMPACKAGES_EXTRA, "org.voltcore.network;version=1.0.0"
                + ",org.voltdb.importer;version=1.0.0,org.apache.log4j;version=1.0.0,org.voltdb.client;version=1.0.0,org.slf4j;version=1.0.0");
        
        
        m_frameworkFactory = ServiceLoader.load(FrameworkFactory.class).iterator().next();
    }

    
    public class BundleWrapper {
        public final Bundle m_bundle;
        public final Framework m_framework;
        public final Properties m_properties;
        public final ImportHandlerProxy m_handlerProxy;
        private ImportHandler m_handler;

        public BundleWrapper(Bundle bundle, Framework framework, ImportHandlerProxy handler, Properties properties) {
            m_bundle = bundle;
            m_framework = framework;
            m_handlerProxy = handler;
            m_properties = properties;
        }

        public void setHandler(ImportHandler handler) throws Exception {
            Preconditions.checkState((m_handler == null), "ImportHandler can only be set once.");
            m_handler = handler;
            m_handlerProxy.setHandler(handler);
        }

        public ImportHandler getHandler() {
            return m_handler;
        }

        public void stop() {
            try {
                m_handler.stop();
                if (m_bundle != null) {
                    m_bundle.stop();
                }
                if (m_framework != null) {
                    m_framework.stop();
                }
            } catch (Exception ex) {
                m_logger.error("Failed to stop the import bundles.", ex);
            }
        }
    }

    public void addProcessorConfig(Properties properties) {
        String module = properties.getProperty(ImportDataProcessor.IMPORT_MODULE);
        String moduleAttrs[] = module.split("\\|");
        String bundleJar = moduleAttrs[1];
        String moduleType = moduleAttrs[0];

        Preconditions.checkState(!m_bundles.containsKey(bundleJar), "Import to source is already defined.");
        try {
            ImportHandlerProxy importHandlerProxy = null;
            BundleWrapper wrapper = null;
            if (moduleType.equalsIgnoreCase("osgi")) {
                Framework framework = m_frameworkFactory.newFramework(m_frameworkProps);
                framework.start();

                Bundle bundle = framework.getBundleContext().installBundle(bundleJar);
                bundle.start();

                ServiceReference reference = framework.getBundleContext().getServiceReference(ImportDataProcessor.IMPORTER_SERVICE_CLASS);
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    bundle.stop();
                    framework.stop();
                    return;
                }
                Object o = framework.getBundleContext().getService(reference);
                importHandlerProxy = (ImportHandlerProxy )o;
                
                wrapper = new BundleWrapper(bundle, framework, importHandlerProxy, properties);
            } else {
                
                Class reference = this.getClass().getClassLoader().loadClass(bundleJar);
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    return;
                }

                Object o = reference.newInstance();
                importHandlerProxy = (ImportHandlerProxy )o;
                
                 wrapper = new BundleWrapper(null, null, importHandlerProxy, properties);
            }
            importHandlerProxy.configure(properties);
            String name = importHandlerProxy.getName();
            if (name == null || name.trim().length() == 0) {
                throw new RuntimeException("Importer must implement and return a valid unique name.");
            }
            Preconditions.checkState(!m_bundlesByName.containsKey(name), "Importer must implement and return a valid unique name.");
            m_bundlesByName.put(name, wrapper);
            m_bundles.put(bundleJar, wrapper);
        } catch(Throwable t) {
            m_logger.error("Failed to configure import handler for " + bundleJar, t);
            Throwables.propagate(t);
        }
    }

    private void registerImporterMetaData(CatalogContext catContext, HostMessenger messenger) {
        ZooKeeper zk = messenger.getZK();
        
    }

    @Override
    public void readyForData(CatalogContext catContext, HostMessenger messenger) {
        
        registerImporterMetaData(catContext, messenger);

        
        synchronized (this) {
            for (BundleWrapper bw : m_bundles.values()) {
                try {
                    ImportHandler importHandler = new ImportHandler(bw.m_handlerProxy, catContext);
                    
                    bw.setHandler(importHandler);
                    importHandler.readyForData();
                    m_logger.info("Importer started: " + bw.m_handlerProxy.getName());
                } catch (Exception ex) {
                    
                    VoltDB.crashLocalVoltDB("Import failed to set Handler", true, ex);
                    m_logger.error("Failed to start the import handler: " + bw.m_handlerProxy.getName(), ex);
                }
            }
        }
    }

    @Override
    public void shutdown() {
        synchronized (this) {
            try {
                
                for (BundleWrapper bw : m_bundles.values()) {
                    try {
                        bw.stop();
                    } catch (Exception ex) {
                        m_logger.error("Failed to stop the import handler: " + bw.m_handlerProxy.getName(), ex);
                    }
                }
                m_bundles.clear();
            } catch (Exception ex) {
                m_logger.error("Failed to stop the import bundles.", ex);
            }
        }
    }

    @Override
    public void setProcessorConfig(Map<String, Properties> config) {
        for (String cname : config.keySet()) {
            Properties properties = config.get(cname);

            String importBundleJar = properties.getProperty(IMPORT_MODULE);
            Preconditions.checkNotNull(importBundleJar, "Import source is undefined or custom export plugin class missing.");
            addProcessorConfig(properties);
        }
    }

}

<code block>



package org.voltdb;

import java.io.File;
import java.io.IOException;
import java.io.OutputStream;
import java.net.Socket;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import java.util.Random;
import java.util.concurrent.CountDownLatch;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.log4j.net.SocketAppender;
import org.voltdb.client.Client;
import org.voltdb.client.ClientImpl;
import org.voltdb.client.ClientResponse;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.regressionsuites.LocalCluster;
import org.voltdb.regressionsuites.MultiConfigSuiteBuilder;
import org.voltdb.regressionsuites.RegressionSuite;
import org.voltdb.regressionsuites.TestSQLTypesSuite;
import org.voltdb.utils.VoltFile;

import com.google_voltpatches.common.collect.ImmutableMap;



public class TestImportSuite extends RegressionSuite {
    private static final Logger s_testSocketLogger = Logger.getLogger("testSocketLogger");
    private static final Level[] s_levels =
        { Level.DEBUG, Level.ERROR, Level.FATAL, Level.INFO, Level.TRACE, Level.WARN };

    private Boolean m_socketHandlerInitialized = false;

    @Override
    public void setUp() throws Exception
    {
        VoltFile.recursivelyDelete(new File("/tmp/" + System.getProperty("user.name")));
        File f = new File("/tmp/" + System.getProperty("user.name"));
        f.mkdirs();

        super.setUp();
    }

    private void setupLog4jSocketHandler() {
        synchronized(m_socketHandlerInitialized) {
            if (m_socketHandlerInitialized) return;

            SocketAppender appender = new SocketAppender("localhost", 6060);
            appender.setReconnectionDelay(50);
            s_testSocketLogger.setAdditivity(false);
            s_testSocketLogger.removeAllAppenders();
            s_testSocketLogger.setLevel(Level.ALL);
            s_testSocketLogger.addAppender(appender);
            m_socketHandlerInitialized = true;
        }
    }

    @Override
    public void tearDown() throws Exception {
        super.tearDown();
    }

    abstract class DataPusher extends Thread {
        private final int m_count;
        private final CountDownLatch m_latch;

        public DataPusher(int count, CountDownLatch latch) {
            m_count = count;
            m_latch = latch;
        }

        protected abstract void initialize();
        protected abstract void close();
        protected abstract void pushData(String str) throws Exception;

        @Override
        public void run() {
            initialize();

            try {
                for (int icnt = 0; icnt < m_count; icnt++) {
                    String s = String.valueOf(System.nanoTime() + icnt) + "," + System.currentTimeMillis() + "\n";
                    pushData(s);
                    Thread.sleep(0, 1);
                }
            } catch (Exception ex) {
                ex.printStackTrace();
            } finally {
                close();
                m_latch.countDown();
            }
        }

    }

    class SocketDataPusher extends DataPusher {
        private final String m_server;
        private final int m_port;
        private OutputStream m_sout;

        public SocketDataPusher(String server, int port, int count, CountDownLatch latch) {
            super(count, latch);
            m_server = server;
            m_port = port;
        }

        @Override
        protected void initialize() {
            m_sout = connectToOneServerWithRetry(m_server, m_port);
            System.out.printf("Connected to VoltDB socket importer at: %s.\n", m_server + ":" + m_port);
        }

        @Override
        protected void pushData(String str) throws Exception {
            m_sout.write(str.getBytes());
        }

        @Override
        protected void close() {
            try {
                m_sout.flush();
                m_sout.close();
            } catch (IOException ex) {
            }
        }
    }

    class Log4jDataPusher extends DataPusher {

        private final Random random = new Random();

        public Log4jDataPusher(int count, CountDownLatch latch) {
            super(count, latch);
        }

        @Override
        protected void initialize() {
            TestImportSuite.this.setupLog4jSocketHandler();
        }

        @Override
        protected void pushData(String str) throws Exception {
            s_testSocketLogger.log(s_levels[random.nextInt(s_levels.length)], str);
        }

        @Override
        protected void close() {
        }
    }

    private void pushDataToImporters(int count, int loops) throws Exception {
        CountDownLatch latch = new CountDownLatch(2*loops);
        for (int i=0; i<loops; i++) {
            (new SocketDataPusher("localhost", 7001, count, latch)).start();
            (new Log4jDataPusher(count, latch)).start();
        }
        latch.await();
    }

    private void verifyData(Client client, int count) throws Exception {
        verifyData(client, count, -1);
    }

    private void verifyData(Client client, int count, int min) throws Exception {
        ClientResponse response = client.callProcedure("@AdHoc", "select count(*) from importTable");
        assertEquals(ClientResponse.SUCCESS, response.getStatus());
            assertEquals(count, response.getResults()[0].asScalarLong());

        response = client.callProcedure("@AdHoc", "select count(*) from log_events");
        assertEquals(ClientResponse.SUCCESS, response.getStatus());
        if (min<0) {
            assertEquals(count, response.getResults()[0].asScalarLong());
        } else {
            long result = response.getResults()[0].asScalarLong();
            assertTrue(result + " not between " + min + " and " + count, result>=min && result<=count);
        }
    }

    public void testImportSimpleData() throws Exception {
        System.out.println("testImportSimpleData");
        Client client = getClient();
        while (!((ClientImpl) client).isHashinatorInitialized()) {
            Thread.sleep(1000);
            System.out.println("Waiting for hashinator to be initialized...");
        }

        pushDataToImporters(100, 1);
        verifyData(client, 100);
        client.close();
    }

    public void testImportMultipleTimes() throws Exception {
        System.out.println("testImportUpdateApplicationCatalog");
        Client client = getClient();
        while (!((ClientImpl) client).isHashinatorInitialized()) {
            Thread.sleep(1000);
            System.out.println("Waiting for hashinator to be initialized...");
        }

        pushDataToImporters(100, 1);
        verifyData(client, 100);

        Thread.sleep(0, 1);

        pushDataToImporters(100, 1);
        verifyData(client, 200);

        client.close();
    }

    public void testImportMultipleClientsInParallel() throws Exception {
        System.out.println("testImportMultipleClientsInParallel");
        Client client = getClient();
        while (!((ClientImpl) client).isHashinatorInitialized()) {
            Thread.sleep(1000);
            System.out.println("Waiting for hashinator to be initialized...");
        }

        pushDataToImporters(100, 2);
        verifyData(client, 100*2);
        client.close();
    }

    public void testImportMultipleClientsUpdateApplicationCatalogWhenNotPushing() throws Exception {
        System.out.println("testImportMultipleClientsUpdateApplicationCatalogWhenNotPushing");
        Client client = getClient();
        while (!((ClientImpl) client).isHashinatorInitialized()) {
            Thread.sleep(1000);
            System.out.println("Waiting for hashinator to be initialized...");
        }

        pushDataToImporters(1000, 3);
        verifyData(client, 3000);

        ClientResponse response = client.callProcedure("@AdHoc", "create table nudge(id integer);");
        assertEquals(ClientResponse.SUCCESS, response.getStatus());

        pushDataToImporters(1000, 4);
        
        verifyData(client, 7000, 3001);

        client.close();
    }

    
    static OutputStream connectToOneServerWithRetry(String server, int port) {
        int sleep = 1000;
        while (true) {
            try {
                Socket pushSocket = new Socket(server, port);
                OutputStream out = pushSocket.getOutputStream();
                System.out.printf("Connected to VoltDB node at: %s.\n", server);
                return out;
            }
            catch (Exception e) {
                System.err.printf("Connection failed - retrying in %d second(s).\n", sleep / 1000);
                try { Thread.sleep(sleep); } catch (Exception interruted) {}
                if (sleep < 8000) sleep += sleep;
            }
        }
    }

    public TestImportSuite(final String name) {
        super(name);
    }

    static public junit.framework.Test suite() throws Exception
    {

        LocalCluster config;
        Map<String, String> additionalEnv = new HashMap<String, String>();

        final MultiConfigSuiteBuilder builder =
            new MultiConfigSuiteBuilder(TestImportSuite.class);

        VoltProjectBuilder project = new VoltProjectBuilder();
        project.setUseDDLSchema(true);
        project.addSchema(TestSQLTypesSuite.class.getResource("sqltypessuite-import-ddl.sql"));

        
        Properties props = new Properties();
        props.putAll(ImmutableMap.<String, String>of(
                "port", "7001",
                "decode", "true",
                "procedure", "importTable.insert"));
        project.addImport(true, "custom", "csv", "org.voltdb.importclient.SocketStreamImporter", props);
        project.addPartitionInfo("importTable", "PKEY");

        
        props = new Properties();
        props.putAll(ImmutableMap.<String, String>of(
                "port", "6060",
                "log-event-table", "log_events"));
        project.addImport(true, "custom", null, "org.voltdb.importclient.Log4jSocketHandlerImporter", props);

        

        config = new LocalCluster("import-ddl-cluster-rep.jar", 4, 1, 0,
                BackendTarget.NATIVE_EE_JNI, LocalCluster.FailureState.ALL_RUNNING, true, false, additionalEnv);
        config.setHasLocalServer(false);
        boolean compile = config.compile(project);
        assertTrue(compile);
        builder.addServerConfig(config);

        return builder;
    }
}

<code block>



package org.hsqldb_voltpatches;


import java.lang.reflect.Field;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Vector;


import java.math.BigDecimal;
import org.hsqldb_voltpatches.types.BinaryData;
import org.hsqldb_voltpatches.types.TimestampData;
import org.hsqldb_voltpatches.types.NumberType;
import org.hsqldb_voltpatches.HSQLInterface.HSQLParseException;


import org.hsqldb_voltpatches.HsqlNameManager.SimpleName;
import org.hsqldb_voltpatches.ParserDQL.CompileContext;
import org.hsqldb_voltpatches.lib.ArrayListIdentity;
import org.hsqldb_voltpatches.lib.HsqlArrayList;
import org.hsqldb_voltpatches.lib.HsqlList;
import org.hsqldb_voltpatches.lib.OrderedHashSet;
import org.hsqldb_voltpatches.lib.OrderedIntHashSet;
import org.hsqldb_voltpatches.lib.Set;
import org.hsqldb_voltpatches.persist.PersistentStore;
import org.hsqldb_voltpatches.types.CharacterType;
import org.hsqldb_voltpatches.types.NullType;
import org.hsqldb_voltpatches.types.Type;


public class Expression {

    public static final int LEFT   = 0;
    public static final int RIGHT  = 1;
    public static final int UNARY  = 1;
    public static final int BINARY = 2;

    
    
    static final Expression[] emptyExpressionArray = new Expression[]{};

    
    static final Expression EXPR_TRUE  = new ExpressionLogical(true);
    static final Expression EXPR_FALSE = new ExpressionLogical(false);

    
    static final OrderedIntHashSet aggregateFunctionSet =
        new OrderedIntHashSet();

    static {
        aggregateFunctionSet.add(OpTypes.COUNT);
        
        aggregateFunctionSet.add(OpTypes.APPROX_COUNT_DISTINCT);
        
        aggregateFunctionSet.add(OpTypes.SUM);
        aggregateFunctionSet.add(OpTypes.MIN);
        aggregateFunctionSet.add(OpTypes.MAX);
        aggregateFunctionSet.add(OpTypes.AVG);
        aggregateFunctionSet.add(OpTypes.EVERY);
        aggregateFunctionSet.add(OpTypes.SOME);
        aggregateFunctionSet.add(OpTypes.STDDEV_POP);
        aggregateFunctionSet.add(OpTypes.STDDEV_SAMP);
        aggregateFunctionSet.add(OpTypes.VAR_POP);
        aggregateFunctionSet.add(OpTypes.VAR_SAMP);
    }

    static final OrderedIntHashSet columnExpressionSet =
        new OrderedIntHashSet();

    static {
        columnExpressionSet.add(OpTypes.COLUMN);
    }

    static final OrderedIntHashSet subqueryExpressionSet =
        new OrderedIntHashSet();

    static {
        subqueryExpressionSet.add(OpTypes.ROW_SUBQUERY);
        subqueryExpressionSet.add(OpTypes.TABLE_SUBQUERY);
    }

    static final OrderedIntHashSet subqueryAggregateExpressionSet =
        new OrderedIntHashSet();

    static {
        subqueryAggregateExpressionSet.add(OpTypes.COUNT);
        
        subqueryAggregateExpressionSet.add(OpTypes.APPROX_COUNT_DISTINCT);
        
        subqueryAggregateExpressionSet.add(OpTypes.SUM);
        subqueryAggregateExpressionSet.add(OpTypes.MIN);
        subqueryAggregateExpressionSet.add(OpTypes.MAX);
        subqueryAggregateExpressionSet.add(OpTypes.AVG);
        subqueryAggregateExpressionSet.add(OpTypes.EVERY);
        subqueryAggregateExpressionSet.add(OpTypes.SOME);
        subqueryAggregateExpressionSet.add(OpTypes.STDDEV_POP);
        subqueryAggregateExpressionSet.add(OpTypes.STDDEV_SAMP);
        subqueryAggregateExpressionSet.add(OpTypes.VAR_POP);
        subqueryAggregateExpressionSet.add(OpTypes.VAR_SAMP);

        
        subqueryAggregateExpressionSet.add(OpTypes.TABLE_SUBQUERY);
        subqueryAggregateExpressionSet.add(OpTypes.ROW_SUBQUERY);
    }

    static final OrderedIntHashSet emptyExpressionSet =
        new OrderedIntHashSet();

    
    protected int opType;

    
    protected int exprSubType;

    
    SimpleName alias;

    
    protected boolean isAggregate;

    
    protected Object       valueData;
    protected Expression[] nodes;
    Type[]                 nodeDataTypes;

    
    SubQuery subQuery;

    
    boolean isCorrelated;

    
    int columnIndex = -1;

    
    protected Type dataType;

    
    int     queryTableColumnIndex = -1;    
    boolean isParam;

    
    int parameterIndex = -1;

    
    int rangePosition = -1;

    
    boolean isColumnEqual;

    Expression(int type) {
        opType = type;
        nodes  = emptyExpressionArray;
    }

    

    
    Expression(int exprType, SubQuery sq) {

        this(OpTypes.TABLE_SUBQUERY);

        subQuery = sq;
    }

    
    Expression(int type, Expression[] list) {

        this(type);

        this.nodes = list;
    }

    public String describe(Session session) {
        return describe(session, 0);
    }

    static String getContextSQL(Expression expression) {

        if (expression == null) {
            return null;
        }

        String ddl = expression.getSQL();

        switch (expression.opType) {

            case OpTypes.VALUE :
            case OpTypes.COLUMN :
            case OpTypes.ROW :
            case OpTypes.FUNCTION :
            case OpTypes.SQL_FUNCTION :
            case OpTypes.ALTERNATIVE :
            case OpTypes.CASEWHEN :
            case OpTypes.CAST :
                return ddl;
        }

        StringBuffer sb = new StringBuffer();

        ddl = sb.append('(').append(ddl).append(')').toString();

        return ddl;
    }

    
    public String getSQL() {

        StringBuffer sb = new StringBuffer(64);

        switch (opType) {

            case OpTypes.VALUE :
                if (valueData == null) {
                    return Tokens.T_NULL;
                }

                return dataType.convertToSQLString(valueData);

            case OpTypes.ROW :
                sb.append('(');

                for (int i = 0; i < nodes.length; i++) {
                    sb.append(nodes[i].getSQL());

                    if (i < nodes.length - 1) {
                        sb.append(',');
                    }
                }

                sb.append(')');

                return sb.toString();

            
            case OpTypes.TABLE :
                for (int i = 0; i < nodes.length; i++) {
                    sb.append(nodes[i].getSQL());

                    if (i < nodes.length - 1) {
                        sb.append(',');
                    }
                }

                return sb.toString();
        }

        switch (opType) {

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY :

                break;

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "Expression");
        }

        return sb.toString();
    }

    protected String describe(Session session, int blanks) {

        StringBuffer sb = new StringBuffer(64);

        sb.append('\n');

        for (int i = 0; i < blanks; i++) {
            sb.append(' ');
        }

        switch (opType) {

            case OpTypes.VALUE :
                sb.append("VALUE = ").append(valueData);
                sb.append(", TYPE = ").append(dataType.getNameString());

                return sb.toString();

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY :
                sb.append("QUERY ");
                sb.append(subQuery.queryExpression.describe(session));

                return sb.toString();

            case OpTypes.ROW :
                sb.append("ROW = ");

                for (int i = 0; i < nodes.length; i++) {
                    sb.append(nodes[i].describe(session, blanks + 1));
                }

                sb.append("), TYPE = ").append(dataType.getNameString());
                break;

            case OpTypes.TABLE :
                sb.append("VALUELIST ");

                for (int i = 0; i < nodes.length; i++) {
                    sb.append(nodes[i].describe(session, blanks + 1));
                    sb.append(' ');
                }
                break;
        }

        if (nodes[LEFT] != null) {
            sb.append(" arg1=[");
            sb.append(nodes[LEFT].describe(session, blanks + 1));
            sb.append(']');
        }

        if (nodes[RIGHT] != null) {
            sb.append(" arg2=[");
            sb.append(nodes[RIGHT].describe(session, blanks + 1));
            sb.append(']');
        }

        return sb.toString();
    }

    
    void setDataType(Session session, Type type) {

        if (opType == OpTypes.VALUE) {
            valueData = type.convertToType(session, valueData, dataType);
        }

        dataType = type;
    }

    public boolean equals(Expression other) {

        if (other == this) {
            return true;
        }

        if (other == null) {
            return false;
        }

        if (opType != other.opType || exprSubType != other.exprSubType
                || !equals(dataType, other.dataType)) {
            return false;
        }

        switch (opType) {

            case OpTypes.SIMPLE_COLUMN :
                return this.columnIndex == other.columnIndex;

            case OpTypes.VALUE :
                return equals(valueData, other.valueData);

            default :
                return equals(nodes, other.nodes)
                       && equals(subQuery, other.subQuery);
        }
    }

    public boolean equals(Object other) {

        if (other == this) {
            return true;
        }

        if (other instanceof Expression) {
            return equals((Expression) other);
        }

        return false;
    }

    public int hashCode() {

        int val = opType + exprSubType;

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                val += nodes[i].hashCode();
            }
        }

        return val;
    }

    static boolean equals(Object o1, Object o2) {

        if (o1 == o2) {
            return true;
        }

        return (o1 == null) ? o2 == null
                            : o1.equals(o2);
    }

    static boolean equals(Expression[] row1, Expression[] row2) {

        if (row1 == row2) {
            return true;
        }

        if (row1.length != row2.length) {
            return false;
        }

        int len = row1.length;

        for (int i = 0; i < len; i++) {
            Expression e1     = row1[i];
            Expression e2     = row2[i];
            boolean    equals = (e1 == null) ? e2 == null
                                             : e1.equals(e2);

            if (!equals) {
                return false;
            }
        }

        return true;
    }

    boolean isComposedOf(Expression exprList[], int start, int end,
                         OrderedIntHashSet excludeSet) {

        if (opType == OpTypes.VALUE) {
            return true;
        }

        if (excludeSet.contains(opType)) {
            return true;
        }

        for (int i = start; i < end; i++) {
            if (equals(exprList[i])) {
                return true;
            }
        }

        switch (opType) {

            case OpTypes.LIKE :
            case OpTypes.MATCH_SIMPLE :
            case OpTypes.MATCH_PARTIAL :
            case OpTypes.MATCH_FULL :
            case OpTypes.MATCH_UNIQUE_SIMPLE :
            case OpTypes.MATCH_UNIQUE_PARTIAL :
            case OpTypes.MATCH_UNIQUE_FULL :
            case OpTypes.UNIQUE :
            case OpTypes.EXISTS :
            case OpTypes.TABLE_SUBQUERY :
            case OpTypes.ROW_SUBQUERY :

            
            case OpTypes.COUNT :
            
            case OpTypes.APPROX_COUNT_DISTINCT:
            
            case OpTypes.SUM :
            case OpTypes.MIN :
            case OpTypes.MAX :
            case OpTypes.AVG :
            case OpTypes.EVERY :
            case OpTypes.SOME :
            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                return false;
        }

        if (nodes.length == 0) {
            return false;
        }

        boolean result = true;

        for (int i = 0; i < nodes.length; i++) {
            result &= (nodes[i] == null
                       || nodes[i].isComposedOf(exprList, start, end,
                                                excludeSet));
        }

        return result;
    }

    boolean isComposedOf(OrderedHashSet expressions,
                         OrderedIntHashSet excludeSet) {

        
        if (opType == OpTypes.VALUE || opType == OpTypes.DYNAMIC_PARAM
                || opType == OpTypes.PARAMETER || opType == OpTypes.VARIABLE) {
            return true;
        }
        

        if (excludeSet.contains(opType)) {
            return true;
        }

        for (int i = 0; i < expressions.size(); i++) {
            if (equals(expressions.get(i))) {
                return true;
            }
        }

        switch (opType) {

            case OpTypes.COUNT :
            
            case OpTypes.APPROX_COUNT_DISTINCT:
            
            case OpTypes.SUM :
            case OpTypes.MIN :
            case OpTypes.MAX :
            case OpTypes.AVG :
            case OpTypes.EVERY :
            case OpTypes.SOME :
            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                return false;
        }


        if (nodes.length == 0) {
            return false;
        }

        boolean result = true;

        for (int i = 0; i < nodes.length; i++) {
            result &= (nodes[i] == null
                       || nodes[i].isComposedOf(expressions, excludeSet));
        }

        return result;
    }

    Expression replace(OrderedHashSet expressions,
                       OrderedHashSet replacements) {

        if (opType == OpTypes.VALUE) {
            return this;
        }

        int index = expressions.getIndex(this);

        if (index != -1) {
            return (Expression) replacements.get(index);
        }

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            nodes[i] = nodes[i].replace(expressions, replacements);
        }

        return this;
    }

    Expression replaceColumnReferences(RangeVariable range,
                                       Expression[] list) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            nodes[i] = nodes[i].replaceColumnReferences(range, list);
        }

        return this;
    }

    void convertToSimpleColumn(OrderedHashSet expressions,
                               OrderedHashSet replacements) {

        if (opType == OpTypes.VALUE) {
            return;
        }

        int index = expressions.getIndex(this);

        if (index != -1) {
            Expression e = (Expression) replacements.get(index);

            nodes         = emptyExpressionArray;
            opType        = OpTypes.SIMPLE_COLUMN;
            columnIndex   = e.columnIndex;
            rangePosition = e.rangePosition;

            return;
        }

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            nodes[i].convertToSimpleColumn(expressions, replacements);
        }
    }

    boolean isSelfAggregate() {
        return false;
    }

    
    void setAlias(SimpleName name) {
        alias = name;
    }

    
    String getAlias() {

        if (alias != null) {
            return alias.name;
        }

        return "";
    }

    SimpleName getSimpleName() {

        if (alias != null) {
            return alias;
        }

        return null;
    }

    
    public int getType() {
        return opType;
    }

    
    Expression getLeftNode() {
        return nodes.length > 0 ? nodes[LEFT]
                                : null;
    }

    
    Expression getRightNode() {
        return nodes.length > 1 ? nodes[RIGHT]
                                : null;
    }

    void setLeftNode(Expression e) {
        nodes[LEFT] = e;
    }

    void setRightNode(Expression e) {
        nodes[RIGHT] = e;
    }

    
    RangeVariable getRangeVariable() {
        return null;
    }

    
    Expression replaceAliasInOrderBy(Expression[] columns, int length) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            nodes[i] = nodes[i].replaceAliasInOrderBy(columns, length);
        }

        return this;
    }

    
    int findMatchingRangeVariableIndex(RangeVariable[] rangeVarArray) {
        return -1;
    }

    
    void collectRangeVariables(RangeVariable[] rangeVariables, Set set) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                nodes[i].collectRangeVariables(rangeVariables, set);
            }
        }

        if (subQuery != null && subQuery.queryExpression != null) {
            HsqlList unresolvedExpressions =
                subQuery.queryExpression.getUnresolvedExpressions();

            if (unresolvedExpressions != null) {
                for (int i = 0; i < unresolvedExpressions.size(); i++) {
                    Expression e = (Expression) unresolvedExpressions.get(i);

                    e.collectRangeVariables(rangeVariables, set);
                }
            }
        }
    }

    
    void collectObjectNames(Set set) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                nodes[i].collectObjectNames(set);
            }
        }

        if (subQuery != null) {
            if (subQuery.queryExpression != null) {
                subQuery.queryExpression.collectObjectNames(set);
            }
        }
    }

    
    boolean hasReference(RangeVariable range) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                if (nodes[i].hasReference(range)) {
                    return true;
                }
            }
        }

        if (subQuery != null && subQuery.queryExpression != null) {
            if (subQuery.queryExpression.hasReference(range)) {
                return true;
            }
        }

        return false;
    }

    
    public HsqlList resolveColumnReferences(RangeVariable[] rangeVarArray,
            HsqlList unresolvedSet) {
        return resolveColumnReferences(rangeVarArray, rangeVarArray.length,
                                       unresolvedSet, true);
    }

    public HsqlList resolveColumnReferences(RangeVariable[] rangeVarArray,
            int rangeCount, HsqlList unresolvedSet, boolean acceptsSequences) {

        if (opType == OpTypes.VALUE) {
            return unresolvedSet;
        }

        switch (opType) {

            case OpTypes.CASEWHEN :
                acceptsSequences = false;
                break;

            case OpTypes.TABLE : {
                HsqlList localSet = null;

                for (int i = 0; i < nodes.length; i++) {
                    if (nodes[i] == null) {
                        continue;
                    }

                    localSet = nodes[i].resolveColumnReferences(
                        RangeVariable.emptyArray, localSet);
                }

                if (localSet != null) {
                    isCorrelated = true;

                    if (subQuery != null) {
                        subQuery.setCorrelated();
                    }

                    for (int i = 0; i < localSet.size(); i++) {
                        Expression e = (Expression) localSet.get(i);

                        unresolvedSet =
                            e.resolveColumnReferences(rangeVarArray,
                                                      unresolvedSet);
                    }

                    unresolvedSet = Expression.resolveColumnSet(rangeVarArray,
                            localSet, unresolvedSet);
                }

                return unresolvedSet;
            }
        }

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            unresolvedSet = nodes[i].resolveColumnReferences(rangeVarArray,
                    rangeCount, unresolvedSet, acceptsSequences);
        }

        switch (opType) {

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY : {
                QueryExpression queryExpression = subQuery.queryExpression;

                if (!queryExpression.areColumnsResolved()) {
                    isCorrelated = true;

                    subQuery.setCorrelated();

                    
                    if (unresolvedSet == null) {
                        unresolvedSet = new ArrayListIdentity();
                    }

                    unresolvedSet.addAll(
                        queryExpression.getUnresolvedExpressions());
                }

                break;
            }
            default :
        }

        return unresolvedSet;
    }

    public OrderedHashSet getUnkeyedColumns(OrderedHashSet unresolvedSet) {

        if (opType == OpTypes.VALUE) {
            return unresolvedSet;
        }

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            unresolvedSet = nodes[i].getUnkeyedColumns(unresolvedSet);
        }

        switch (opType) {

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY :
                if (subQuery != null) {
                    if (unresolvedSet == null) {
                        unresolvedSet = new OrderedHashSet();
                    }

                    unresolvedSet.add(this);
                }
                break;
        }

        return unresolvedSet;
    }

    public void resolveTypes(Session session, Expression parent) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                nodes[i].resolveTypes(session, this);
            }
        }

        switch (opType) {

            case OpTypes.VALUE :
                break;

            case OpTypes.TABLE :

                
                break;

            case OpTypes.ROW :
                nodeDataTypes = new Type[nodes.length];

                for (int i = 0; i < nodes.length; i++) {
                    if (nodes[i] != null) {
                        nodeDataTypes[i] = nodes[i].dataType;
                    }
                }
                break;

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY : {
                QueryExpression queryExpression = subQuery.queryExpression;

                queryExpression.resolveTypes(session);
                subQuery.prepareTable(session);

                nodeDataTypes = queryExpression.getColumnTypes();
                dataType      = nodeDataTypes[0];

                break;
            }
            default :
                throw Error.runtimeError(ErrorCode.U_S0500,
                                         "Expression.resolveTypes()");
        }
    }

    void setAsConstantValue(Session session) {

        valueData = getConstantValue(session);
        opType    = OpTypes.VALUE;
        nodes     = emptyExpressionArray;
    }

    void setAsConstantValue(Object value) {

        valueData = value;
        opType    = OpTypes.VALUE;
        nodes     = emptyExpressionArray;
    }

    void prepareTable(Session session, Expression row, int degree) {

        if (nodeDataTypes != null) {
            return;
        }

        for (int i = 0; i < nodes.length; i++) {
            Expression e = nodes[i];

            if (e.opType == OpTypes.ROW) {
                if (degree != e.nodes.length) {
                    throw Error.error(ErrorCode.X_42564);
                }
            } else if (degree == 1) {
                nodes[i]       = new Expression(OpTypes.ROW);
                nodes[i].nodes = new Expression[]{ e };
            } else {
                throw Error.error(ErrorCode.X_42564);
            }
        }

        nodeDataTypes = new Type[degree];

        for (int j = 0; j < degree; j++) {
            Type type = row == null ? null
                                    : row.nodes[j].dataType;

            for (int i = 0; i < nodes.length; i++) {
                type = Type.getAggregateType(nodes[i].nodes[j].dataType, type);
            }

            if (type == null) {
                throw Error.error(ErrorCode.X_42567);
            }

            nodeDataTypes[j] = type;

            if (row != null && row.nodes[j].isParam) {
                row.nodes[j].dataType = type;
            }

            for (int i = 0; i < nodes.length; i++) {
                if (nodes[i].nodes[j].isParam) {
                    nodes[i].nodes[j].dataType = nodeDataTypes[j];

                    continue;
                }

                if (nodes[i].nodes[j].opType == OpTypes.VALUE) {
                    if (nodes[i].nodes[j].valueData == null) {
                        nodes[i].nodes[j].dataType = nodeDataTypes[j];
                    }
                }
            }

            if (nodeDataTypes[j].isCharacterType()
                    && !((CharacterType) nodeDataTypes[j])
                        .isEqualIdentical()) {

                
            }
        }
    }

    
    void insertValuesIntoSubqueryTable(Session session,
                                       PersistentStore store) {

        TableDerived table = subQuery.getTable();

        for (int i = 0; i < nodes.length; i++) {
            Object[] data = nodes[i].getRowValue(session);

            for (int j = 0; j < nodeDataTypes.length; j++) {
                data[j] = nodeDataTypes[j].convertToType(session, data[j],
                        nodes[i].nodes[j].dataType);
            }

            Row row = (Row) store.getNewCachedObject(session, data);

            try {
                store.indexRow(session, row);
            } catch (HsqlException e) {}
        }
    }

    
    String getColumnName() {
        return getAlias();
    }

    ColumnSchema getColumn() {
        return null;
    }

    
    int getColumnIndex() {
        return columnIndex;
    }

    
    Type getDataType() {
        return dataType;
    }

    int getDegree() {
        return opType == OpTypes.ROW ? nodes.length
                                     : 1;
    }

    public Object[] getRowValue(Session session) {

        switch (opType) {

            case OpTypes.ROW : {
                Object[] data = new Object[nodes.length];

                for (int i = 0; i < nodes.length; i++) {
                    data[i] = nodes[i].getValue(session);
                }

                return data;
            }
            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY : {
                return subQuery.queryExpression.getValues(session);
            }
            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "Expression");
        }
    }

    Object getValue(Session session, Type type) {

        Object o = getValue(session);

        if (o == null || dataType == type) {
            return o;
        }

        return type.convertToType(session, o, dataType);
    }

    public Object getConstantValue(Session session) {
        return getValue(session);
    }

    public Object getConstantValueNoCheck(Session session) {

        try {
            return getValue(session);
        } catch (HsqlException e) {
            return null;
        }
    }

    public Object getValue(Session session) {

        switch (opType) {

            case OpTypes.VALUE :
                return valueData;

            case OpTypes.SIMPLE_COLUMN : {
                Object[] data =
                    session.sessionContext.rangeIterators[rangePosition]
                        .getCurrent();

                return data[columnIndex];
            }
            case OpTypes.ROW : {
                if (nodes.length == 1) {
                    return nodes[0].getValue(session);
                }

                Object[] row = new Object[nodes.length];

                for (int i = 0; i < nodes.length; i++) {
                    row[i] = nodes[i].getValue(session);
                }

                return row;
            }
            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY : {
                subQuery.materialiseCorrelated(session);

                Object value = subQuery.getValue(session);

                return value;
            }
            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "Expression");
        }
    }

    boolean testCondition(Session session) {
        return Boolean.TRUE.equals(getValue(session));
    }

    static int countNulls(Object[] a) {

        int nulls = 0;

        for (int i = 0; i < a.length; i++) {
            if (a[i] == null) {
                nulls++;
            }
        }

        return nulls;
    }

    static void convertToType(Session session, Object[] data, Type[] dataType,
                              Type[] newType) {

        for (int i = 0; i < data.length; i++) {
            data[i] = newType[i].convertToType(session, data[i], dataType[i]);
        }
    }

    
    static QuerySpecification getCheckSelect(Session session, Table t,
            Expression e) {

        CompileContext     compileContext = new CompileContext(session);
        QuerySpecification s = new QuerySpecification(compileContext);

        s.exprColumns    = new Expression[1];
        s.exprColumns[0] = EXPR_TRUE;

        RangeVariable range = new RangeVariable(t, null, null, null,
            compileContext);

        s.rangeVariables = new RangeVariable[]{ range };

        HsqlList unresolved = e.resolveColumnReferences(s.rangeVariables,
            null);

        ExpressionColumn.checkColumnsResolved(unresolved);
        e.resolveTypes(session, null);

        if (Type.SQL_BOOLEAN != e.getDataType()) {
            throw Error.error(ErrorCode.X_42568);
        }

        Expression condition = new ExpressionLogical(OpTypes.NOT, e);

        s.queryCondition = condition;

        s.resolveReferences(session);
        s.resolveTypes(session);

        return s;
    }

    boolean isParam() {
        return isParam;
    }

    void setAttributesAsColumn(ColumnSchema column, boolean isWritable) {
        throw Error.runtimeError(ErrorCode.U_S0500,
                                 "Expression.setAttributesAsColumn");
    }

    String getValueClassName() {

        Type type = dataType == null ? NullType.getNullType()
                                     : dataType;

        return type.getJDBCClassName();
    }

    public void collectAllFunctionExpressions(HsqlList set) {

        Expression.collectAllExpressions(set, this,
                                         Expression.emptyExpressionSet,
                                         Expression.emptyExpressionSet);
    }

    
    static void collectAllExpressions(HsqlList set, Expression e,
                                      OrderedIntHashSet typeSet,
                                      OrderedIntHashSet stopAtTypeSet) {

        if (e == null) {
            return;
        }

        if (stopAtTypeSet.contains(e.opType)) {
            return;
        }

        for (int i = 0; i < e.nodes.length; i++) {
            collectAllExpressions(set, e.nodes[i], typeSet, stopAtTypeSet);
        }

        if (typeSet.contains(e.opType)) {
            set.add(e);
        }

        if (e.subQuery != null && e.subQuery.queryExpression != null) {
            e.subQuery.queryExpression.collectAllExpressions(set, typeSet,
                    stopAtTypeSet);
        }
    }

    
    public boolean isCorrelated() {

        if (opType == OpTypes.TABLE_SUBQUERY && subQuery != null
                && subQuery.isCorrelated()) {
            return true;
        }

        return false;
    }

    
    public void checkValidCheckConstraint() {

        HsqlArrayList set = new HsqlArrayList();

        Expression.collectAllExpressions(set, this, subqueryExpressionSet,
                                         emptyExpressionSet);

        if (!set.isEmpty()) {
            throw Error.error(ErrorCode.X_0A000,
                              "subquery in check constraint");
        }
    }

    static HsqlList resolveColumnSet(RangeVariable[] rangeVars,
                                     HsqlList sourceSet, HsqlList targetSet) {

        if (sourceSet == null) {
            return targetSet;
        }

        for (int i = 0; i < sourceSet.size(); i++) {
            Expression e = (Expression) sourceSet.get(i);

            targetSet = e.resolveColumnReferences(rangeVars, targetSet);
        }

        return targetSet;
    }

    Expression getIndexableExpression(RangeVariable rangeVar) {
        return null;
    }

    

    
    public void collectAllColumnExpressions(HsqlList set) {

        Expression.collectAllExpressions(set, this,
                                         Expression.columnExpressionSet,
                                         Expression.emptyExpressionSet);
    }

    static Map<Integer, VoltXMLElement> prototypes = new HashMap<Integer, VoltXMLElement>();

    static {
        prototypes.put(OpTypes.VALUE,         new VoltXMLElement("value")); 
        prototypes.put(OpTypes.COLUMN,        new VoltXMLElement("columnref")); 
        prototypes.put(OpTypes.COALESCE,      new VoltXMLElement("columnref")); 
        prototypes.put(OpTypes.DEFAULT,       new VoltXMLElement("columnref")); 
        prototypes.put(OpTypes.SIMPLE_COLUMN, (new VoltXMLElement("simplecolumn")));

        prototypes.put(OpTypes.VARIABLE,      null); 
        prototypes.put(OpTypes.PARAMETER,     null); 
        prototypes.put(OpTypes.DYNAMIC_PARAM, (new VoltXMLElement("value")).withValue("isparam", "true")); 
        prototypes.put(OpTypes.ASTERISK,      new VoltXMLElement("asterisk"));
        prototypes.put(OpTypes.SEQUENCE,      null); 
        prototypes.put(OpTypes.SCALAR_SUBQUERY,null); 
        prototypes.put(OpTypes.ROW_SUBQUERY,  null); 
        prototypes.put(OpTypes.TABLE_SUBQUERY,new VoltXMLElement("tablesubquery"));
        prototypes.put(OpTypes.ROW,           new VoltXMLElement("row")); 
        prototypes.put(OpTypes.TABLE,         new VoltXMLElement("table")); 
        prototypes.put(OpTypes.FUNCTION,      null); 
        prototypes.put(OpTypes.SQL_FUNCTION,  new VoltXMLElement("function"));
        prototypes.put(OpTypes.ROUTINE_FUNCTION, null); 

        
        prototypes.put(OpTypes.NEGATE,        (new VoltXMLElement("operation")).withValue("optype", "negate"));

        prototypes.put(OpTypes.ADD,           (new VoltXMLElement("operation")).withValue("optype", "add"));
        prototypes.put(OpTypes.SUBTRACT,      (new VoltXMLElement("operation")).withValue("optype", "subtract"));
        prototypes.put(OpTypes.MULTIPLY,      (new VoltXMLElement("operation")).withValue("optype", "multiply"));
        prototypes.put(OpTypes.DIVIDE,        (new VoltXMLElement("operation")).withValue("optype", "divide"));

        prototypes.put(OpTypes.CONCAT,        (new VoltXMLElement("function")) 
                                               .withValue("function_id", FunctionCustom.FUNC_CONCAT_ID_STRING)
                                               .withValue("name", Tokens.T_CONCAT_WORD)
                                               .withValue("valuetype", Type.SQL_VARCHAR.getNameString()));

        
        prototypes.put(OpTypes.EQUAL,         (new VoltXMLElement("operation")).withValue("optype", "equal"));
        prototypes.put(OpTypes.GREATER_EQUAL, (new VoltXMLElement("operation")).withValue("optype", "greaterthanorequalto"));
        prototypes.put(OpTypes.GREATER,       (new VoltXMLElement("operation")).withValue("optype", "greaterthan"));
        prototypes.put(OpTypes.SMALLER,       (new VoltXMLElement("operation")).withValue("optype", "lessthan"));
        prototypes.put(OpTypes.SMALLER_EQUAL, (new VoltXMLElement("operation")).withValue("optype", "lessthanorequalto"));
        prototypes.put(OpTypes.NOT_EQUAL,     (new VoltXMLElement("operation")).withValue("optype", "notequal"));
        prototypes.put(OpTypes.IS_NULL,       (new VoltXMLElement("operation")).withValue("optype", "is_null"));

        
        prototypes.put(OpTypes.NOT,           (new VoltXMLElement("operation")).withValue("optype", "not"));
        prototypes.put(OpTypes.AND,           (new VoltXMLElement("operation")).withValue("optype", "and"));
        prototypes.put(OpTypes.OR,            (new VoltXMLElement("operation")).withValue("optype", "or"));

        
        prototypes.put(OpTypes.ALL_QUANTIFIED,null); 
        prototypes.put(OpTypes.ANY_QUANTIFIED,null); 

        
        prototypes.put(OpTypes.LIKE,          (new VoltXMLElement("operation")).withValue("optype", "like"));
        prototypes.put(OpTypes.IN,            null); 
        prototypes.put(OpTypes.EXISTS,        (new VoltXMLElement("operation")).withValue("optype", "exists"));
        prototypes.put(OpTypes.OVERLAPS,      null); 
        prototypes.put(OpTypes.UNIQUE,        null); 
        prototypes.put(OpTypes.NOT_DISTINCT,  null); 
        prototypes.put(OpTypes.MATCH_SIMPLE,  null); 
        prototypes.put(OpTypes.MATCH_PARTIAL, null); 
        prototypes.put(OpTypes.MATCH_FULL,    null); 
        prototypes.put(OpTypes.MATCH_UNIQUE_SIMPLE,  null); 
        prototypes.put(OpTypes.MATCH_UNIQUE_PARTIAL, null); 
        prototypes.put(OpTypes.MATCH_UNIQUE_FULL,    null); 
        
        prototypes.put(OpTypes.COUNT,         (new VoltXMLElement("aggregation")).withValue("optype", "count"));
        prototypes.put(OpTypes.APPROX_COUNT_DISTINCT, (new VoltXMLElement("aggregation")).withValue("optype", "approx_count_distinct"));
        prototypes.put(OpTypes.SUM,           (new VoltXMLElement("aggregation")).withValue("optype", "sum"));
        prototypes.put(OpTypes.MIN,           (new VoltXMLElement("aggregation")).withValue("optype", "min"));
        prototypes.put(OpTypes.MAX,           (new VoltXMLElement("aggregation")).withValue("optype", "max"));
        prototypes.put(OpTypes.AVG,           (new VoltXMLElement("aggregation")).withValue("optype", "avg"));
        prototypes.put(OpTypes.EVERY,         (new VoltXMLElement("aggregation")).withValue("optype", "every"));
        prototypes.put(OpTypes.SOME,          (new VoltXMLElement("aggregation")).withValue("optype", "some"));
        prototypes.put(OpTypes.STDDEV_POP,    (new VoltXMLElement("aggregation")).withValue("optype", "stddevpop"));
        prototypes.put(OpTypes.STDDEV_SAMP,   (new VoltXMLElement("aggregation")).withValue("optype", "stddevsamp"));
        prototypes.put(OpTypes.VAR_POP,       (new VoltXMLElement("aggregation")).withValue("optype", "varpop"));
        prototypes.put(OpTypes.VAR_SAMP,      (new VoltXMLElement("aggregation")).withValue("optype", "varsamp"));
        
        prototypes.put(OpTypes.CAST,          (new VoltXMLElement("operation")).withValue("optype", "cast"));
        prototypes.put(OpTypes.ZONE_MODIFIER, null); 
        prototypes.put(OpTypes.CASEWHEN,      (new VoltXMLElement("operation")).withValue("optype", "operator_case_when"));
        prototypes.put(OpTypes.ORDER_BY,      new VoltXMLElement("orderby"));
        prototypes.put(OpTypes.LIMIT,         new VoltXMLElement("limit"));
        prototypes.put(OpTypes.ALTERNATIVE,   (new VoltXMLElement("operation")).withValue("optype", "operator_alternative"));
        prototypes.put(OpTypes.MULTICOLUMN,   null); 
    }

    
    VoltXMLElement voltGetXML(Session session)
            throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException
    {
        return voltGetXML(session, null, null, -1);
    }

    VoltXMLElement voltGetXML(Session session, List<Expression> displayCols,
            java.util.Set<Integer> ignoredDisplayColIndexes, int startKey)
            throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException
    {
        return voltGetXML(session, displayCols, ignoredDisplayColIndexes, startKey, null);
    }

    
    VoltXMLElement voltGetXML(Session session, List<Expression> displayCols,
            java.util.Set<Integer> ignoredDisplayColIndexes, int startKey, String realAlias)
        throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException
    {
        
        
        int exprOp = getType();

        
        
        
        
        
        
        
        
        
        
        if (exprOp == OpTypes.SIMPLE_COLUMN) {
            if (displayCols == null) {
                if (this instanceof ExpressionColumn == false) {
                    throw new org.hsqldb_voltpatches.HSQLInterface.HSQLParseException(
                            "VoltDB does not support this complex query currently.");
                }
                
                opType = OpTypes.COLUMN;
                exprOp = OpTypes.COLUMN;
            } else {
                
                for (int ii=startKey+1; ii < displayCols.size(); ++ii)
                {
                    Expression otherCol = displayCols.get(ii);
                    
                    
                    
                    if (otherCol != null && (otherCol.opType != OpTypes.SIMPLE_COLUMN) &&
                             (otherCol.columnIndex == this.columnIndex)  &&
                             !(otherCol instanceof ExpressionColumn))
                    {
                        ignoredDisplayColIndexes.add(ii);
                        
                        
                        
                        return otherCol.voltGetXML(session, displayCols, ignoredDisplayColIndexes, startKey, getAlias());
                    }
                }
                assert(false);
            }
        }

        
        
        VoltXMLElement exp = prototypes.get(exprOp);
        if (exp == null) {
            
            throwForUnsupportedExpression(exprOp);
        }

        
        
        exp = exp.duplicate();
        exp.attributes.put("id", this.getUniqueId(session));

        if (realAlias != null) {
            exp.attributes.put("alias", realAlias);
        } else if ((alias != null) && (getAlias().length() > 0)) {
            exp.attributes.put("alias", getAlias());
        }

        
        if (exprSubType == OpTypes.ANY_QUANTIFIED) {
            exp.attributes.put("opsubtype", "any");
        } else if (exprSubType == OpTypes.ALL_QUANTIFIED) {
            exp.attributes.put("opsubtype", "all");
        }

        for (Expression expr : nodes) {
            if (expr != null) {
                VoltXMLElement vxmle = expr.voltGetXML(session, displayCols, ignoredDisplayColIndexes, startKey);
                exp.children.add(vxmle);
                assert(vxmle != null);
            }
        }

        
        
        
        
        
        
        switch (exprOp) {
        case OpTypes.VALUE:
            
            
            
            if (valueData == null) {
                if (dataType == null) {
                    exp.attributes.put("valuetype", "NULL");
                    return exp;
                }
                exp.attributes.put("valuetype", Types.getTypeName(dataType.typeCode));
                return exp;
            }

            if (dataType.isBooleanType()) {
                
                
                
                
                
                
                
                
                
                
                
                
                throw new org.hsqldb_voltpatches.HSQLInterface.HSQLParseException(
                        "VoltDB does not support WHERE clauses containing only constants");
            }

            exp.attributes.put("valuetype", Types.getTypeName(dataType.typeCode));

            if (valueData instanceof TimestampData) {
                
                
                
                
                
                
                TimestampData time = (TimestampData) valueData;
                exp.attributes.put("value", Long.toString(Math.round((time.getSeconds() +
                                                                      time.getZone()) * 1e6) +
                                                          time.getNanos() / 1000));
                return exp;
            }

            
            if (valueData instanceof BinaryData) {
                BinaryData bd = (BinaryData) valueData;
                exp.attributes.put("value", hexEncode(bd.getBytes()));
                return exp;
            }

            
            if (dataType instanceof NumberType && ! dataType.isIntegralType()) {
                
                exp.attributes.put("value", new BigDecimal(valueData.toString()).toPlainString());
                return exp;
            }
            exp.attributes.put("value", valueData.toString());
            return exp;

        case OpTypes.COLUMN:
        case OpTypes.COALESCE:
            ExpressionColumn ec = (ExpressionColumn)this;
            return ec.voltAnnotateColumnXML(exp);

        case OpTypes.SQL_FUNCTION:
            FunctionSQL fn = (FunctionSQL)this;
            return fn.voltAnnotateFunctionXML(exp);

        case OpTypes.COUNT:
        case OpTypes.SUM:
        case OpTypes.AVG:
            if (((ExpressionAggregate)this).isDistinctAggregate) {
                exp.attributes.put("distinct", "true");
            }
            return exp;

        case OpTypes.ORDER_BY:
            if (((ExpressionOrderBy)this).isDescending()) {
                exp.attributes.put("desc", "true");
            }
            return exp;

        case OpTypes.CAST:
            if (dataType == null) {
                throw new org.hsqldb_voltpatches.HSQLInterface.HSQLParseException(
                        "VoltDB could not determine the type in a CAST operation");
            }
            exp.attributes.put("valuetype", dataType.getNameString());
            return exp;

        case OpTypes.TABLE_SUBQUERY:
            if (subQuery == null || subQuery.queryExpression == null) {
                throw new HSQLParseException("VoltDB could not determine the subquery");
            }
            ExpressionColumn parameters[] = new ExpressionColumn[0];
            exp.children.add(StatementQuery.voltGetXMLExpression(subQuery.queryExpression, parameters, session));
            return exp;

        case OpTypes.ALTERNATIVE:
            assert(nodes.length == 2);
            
            if (nodes[RIGHT] instanceof ExpressionValue) {
                ExpressionValue val = (ExpressionValue) nodes[RIGHT];
                if (val.valueData == null && val.dataType == Type.SQL_ALL_TYPES) {
                    exp.children.get(RIGHT).attributes.put("valuetype", dataType.getNameString());
                }
            }
        case OpTypes.CASEWHEN:
            
            assert(dataType != null);
            exp.attributes.put("valuetype", dataType.getNameString());
            return exp;

        default:
            return exp;
        }
    }

    private static final int caseDiff = ('a' - 'A');
    
    public static String hexEncode(byte[] data) {
        if (data == null)
            return null;

        StringBuilder sb = new StringBuilder();
        for (byte b : data) {
            
            char ch = Character.forDigit((b >> 4) & 0xF, 16);
            
            if (Character.isLetter(ch)) {
                ch -= caseDiff;
            }
            sb.append(ch);
            ch = Character.forDigit(b & 0xF, 16);
            if (Character.isLetter(ch)) {
                ch -= caseDiff;
            }
            sb.append(ch);
        }
        return sb.toString();
    }

    private static void throwForUnsupportedExpression(int exprOp)
            throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException
    {
        String opAsString;
        switch (exprOp) {
        
        

        case OpTypes.VARIABLE:
            opAsString = "HSQL session variables"; break; 
        case OpTypes.PARAMETER:
            opAsString = "HSQL session parameters"; break; 

        case OpTypes.SEQUENCE:
            opAsString = "sequence types"; break; 

        case OpTypes.SCALAR_SUBQUERY:
        case OpTypes.ROW_SUBQUERY:
        case OpTypes.TABLE_SUBQUERY:
        case OpTypes.ROW:
        case OpTypes.TABLE:
        case OpTypes.EXISTS:
            throw new HSQLParseException("Unsupported subquery syntax within an expression. Consider using a join or multiple statements instead");

        case OpTypes.FUNCTION:             opAsString = "HSQL-style user-defined Java SQL functions"; break;

        case OpTypes.ROUTINE_FUNCTION:     opAsString = "HSQL routine functions"; break; 

        case OpTypes.ALL_QUANTIFIED:
        case OpTypes.ANY_QUANTIFIED:
            opAsString = "sequences or subqueries"; break; 

        case OpTypes.IN:
            opAsString = "the IN operator. Consider using an OR expression"; break; 

        case OpTypes.OVERLAPS:
        case OpTypes.UNIQUE:
        case OpTypes.NOT_DISTINCT:
            opAsString = "sequences or subqueries"; break; 

        case OpTypes.MATCH_SIMPLE:
        case OpTypes.MATCH_PARTIAL:
        case OpTypes.MATCH_FULL:
        case OpTypes.MATCH_UNIQUE_SIMPLE:
        case OpTypes.MATCH_UNIQUE_PARTIAL:
        case OpTypes.MATCH_UNIQUE_FULL:
            opAsString = "the MATCH operator"; break; 

        case OpTypes.ZONE_MODIFIER:
            opAsString = "ZONE modifier operations"; break; 
        case OpTypes.MULTICOLUMN:
            opAsString = "a MULTICOLUMN operation"; break; 

        default:
            opAsString = " the unknown operator with numeric code (" + String.valueOf(exprOp) + ")";
        }
        throw new org.hsqldb_voltpatches.HSQLInterface.HSQLParseException(
                "VoltDB does not support " + opAsString);
    }

    
    public Expression eliminateDuplicates(final Session session) {
        
        
        Map<String, Expression> subExprMap = new HashMap<String, Expression>();
        extractAndSubExpressions(session, this, subExprMap);
        
        if (!subExprMap.isEmpty()) {
            Iterator<Map.Entry<String, Expression>> itExpr = subExprMap.entrySet().iterator();
            Expression finalExpr = itExpr.next().getValue();
            while (itExpr.hasNext()) {
                finalExpr = new ExpressionLogical(OpTypes.AND, finalExpr, itExpr.next().getValue());
            }
            return finalExpr;
        }
        return this;
    }

    protected void extractAndSubExpressions(final Session session, Expression expr,
            Map<String, Expression> subExprMap) {
        
        if (expr instanceof ExpressionLogical && ((ExpressionLogical) expr).opType == OpTypes.AND) {
            extractAndSubExpressions(session, expr.nodes[LEFT], subExprMap);
            extractAndSubExpressions(session, expr.nodes[RIGHT], subExprMap);
        } else {
            String id = expr.getUniqueId(session);
            subExprMap.put(id, expr);
       }
    }

    protected String cached_id = null;

    
    protected String getUniqueId(final Session session) {
        if (cached_id != null) {
            return cached_id;
        }

        
        
        

        
        
        cached_id = new String();
        int hashCode = 0;
        
        
        
        if (getType() == OpTypes.VALUE || getType() == OpTypes.COLUMN) {
            hashCode = super.hashCode();
        
        
        
        } else {
            
            
            
            final List<String> id_list = new Vector<String>();
            new Object() {
                public void traverse(Expression exp) {
                    for (Expression expr : exp.nodes) {
                        if (expr != null)
                            id_list.add(expr.getUniqueId(session));
                    }
                }
            }.traverse(this);

            if (id_list.size() > 0) {
                
                for (String temp : id_list)
                    this.cached_id += "+" + temp;
                hashCode = this.cached_id.intern().hashCode();
            }
            else
                hashCode = super.hashCode();
        }

        long id = session.getNodeIdForExpression(hashCode);
        cached_id = Long.toString(id);
        return cached_id;
    }

    
    public VoltXMLElement voltGetExpressionXML(Session session, Table table)
            throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException {
        resolveTableColumns(table);
        Expression parent = null; 
        resolveTypes(session, parent);
        return voltGetXML(session);
    }

    
    private void resolveTableColumns(Table table) {
        HsqlList set = new HsqlArrayList();
        collectAllColumnExpressions(set);
        for (int i = 0; i < set.size(); i++) {
            ExpressionColumn array_element = (ExpressionColumn)set.get(i);
            ColumnSchema column = table.getColumn(table.getColumnIndex(array_element.getAlias()));
            array_element.setAttributesAsColumn(column, false);

        }
    }

    
    @Override
    public String toString() {
        String type = null;

        
        
        
        Field[] fields = OpTypes.class.getFields();
        for (Field f : fields) {
            if (f.getType() != int.class) continue;
            int value = 0;
            try {
                value = f.getInt(null);
            } catch (Exception e) {
                
                e.printStackTrace();
            }

            
            if (value == opType) {
                type = f.getName();
                break;
            }
        }
        assert(type != null);

        
        String str = super.toString() + " with opType " + type +
                ", isAggregate: " + isAggregate +
                ", columnIndex: " + columnIndex;
        if (this instanceof ExpressionOrderBy) {
            str += "\n  " + this.nodes[LEFT].toString();
        }
        return str;
    }
    
}

<code block>



package org.hsqldb_voltpatches;

import org.hsqldb_voltpatches.lib.IntValueHashMap;
import org.hsqldb_voltpatches.lib.OrderedIntHashSet;


public class Tokens {

    
    
    static final String        T_ABS              = "ABS";
    public static final String T_ALL              = "ALL";
    static final String        T_ALLOCATE         = "ALLOCATE";
    public static final String T_ALTER            = "ALTER";
    static final String        T_AND              = "AND";
    static final String        T_ANY              = "ANY";
    
    static final String        T_APPROX_COUNT_DISTINCT = "APPROX_COUNT_DISTINCT";
    
    static final String        T_ARE              = "ARE";
    static final String        T_ARRAY            = "ARRAY";
    public static final String T_AS               = "AS";
    static final String        T_ASENSITIVE       = "ASENSITIVE";
    static final String        T_ASYMMETRIC       = "ASYMMETRIC";
    static final String        T_AT               = "AT";
    static final String        T_ATOMIC           = "ATOMIC";
    public static final String T_AUTHORIZATION    = "AUTHORIZATION";
    static final String        T_AVG              = "AVG";
    static final String        T_BEGIN            = "BEGIN";
    static final String        T_BETWEEN          = "BETWEEN";
    public static final String T_BIGINT           = "BIGINT";
    public static final String T_BINARY           = "BINARY";
    static final String        T_BIT_LENGTH       = "BIT_LENGTH";
    
    static final String        T_BYTES            = "BYTES"; 
    
    public static final String T_BLOB             = "BLOB";
    public static final String T_BOOLEAN          = "BOOLEAN";
    static final String        T_BOTH             = "BOTH";
    static final String        T_BY               = "BY";
    static final String        T_CALL             = "CALL";
    static final String        T_CALLED           = "CALLED";
    static final String        T_CARDINALITY      = "CARDINALITY";
    public static final String T_CASCADED         = "CASCADED";
    static final String        T_CASE             = "CASE";
    static final String        T_CAST             = "CAST";
    static final String        T_CEIL             = "CEIL";
    static final String        T_CEILING          = "CEILING";
    static final String        T_CHAR             = "CHAR";
    static final String        T_CHAR_LENGTH      = "CHAR_LENGTH";
    public static final String T_CHARACTER        = "CHARACTER";
    static final String        T_CHARACTER_LENGTH = "CHARACTER_LENGTH";
    public static final String T_CHECK            = "CHECK";
    public static final String T_CLOB             = "CLOB";
    static final String        T_CLOSE            = "CLOSE";
    static final String        T_COALESCE         = "COALESCE";
    static final String        T_COLLATE          = "COLLATE";
    static final String        T_COLLECT          = "COLLECT";
    static final String        T_COLUMN           = "COLUMN";
    public static final String T_COMMIT           = "COMMIT";
    static final String        T_CONDITION        = "CONDIITON";
    public static final String T_CONNECT          = "CONNECT";
    public static final String T_CONSTRAINT       = "CONSTRAINT";
    static final String        T_CONVERT          = "CONVERT";
    static final String        T_CORR             = "CORR";
    static final String        T_CORRESPONDING    = "CORRESPONDING";
    static final String        T_COUNT            = "COUNT";
    static final String        T_COVAR_POP        = "COVAR_POP";
    static final String        T_COVAR_SAMP       = "COVAR_SAMP";
    public static final String T_CREATE           = "CREATE";
    static final String        T_CROSS            = "CROSS";
    static final String        T_CUBE             = "CUBE";
    static final String        T_CUME_DIST        = "CUME_DIST";
    static final String        T_CURRENT          = "CURRENT";
    static final String        T_CURRENT_CATALOG  = "CURRENT_CATALOG";
    static final String        T_CURRENT_DATE     = "CURRENT_DATE";
    static final String T_CURRENT_DEFAULT_TRANSFORM_GROUP =
        "CURRENT_DEFAULT_TRANSFORM_GROUP";
    static final String T_CURRENT_PATH      = "CURRENT_PATH";
    static final String T_CURRENT_ROLE      = "CURRENT_ROLE";
    static final String T_CURRENT_SCHEMA    = "CURRENT_SCHEMA";
    static final String T_CURRENT_TIME      = "CURRENT_TIME";
    static final String T_CURRENT_TIMESTAMP = "CURRENT_TIMESTAMP";
    static final String T_CURRENT_TRANSFORM_GROUP_FOR_TYPE =
        "CURRENT_TRANSFORM_GROUP_FOR_TYPE";
    static final String        T_CURRENT_USER      = "CURRENT_USER";
    static final String        T_CURSOR            = "CURSOR";
    static final String        T_CYCLE             = "CYCLE";
    public static final String T_DATE              = "DATE";
    public static final String T_DAY               = "DAY";
    static final String        T_DEALLOCATE        = "DEALLOCATE";
    static final String        T_DEC               = "DEC";
    public static final String T_DECIMAL           = "DECIMAL";
    static final String        T_DECLARE           = "DECLARE";
    public static final String T_DEFAULT           = "DEFAULT";
    public static final String T_DELETE            = "DELETE";
    static final String        T_DENSE_RANK        = "DENSE_RANK";
    static final String        T_DEREF             = "DEREF";
    static final String        T_DESCRIBE          = "DESCRIBE";
    static final String        T_DETERMINISTIC     = "DETERMINISTIC";
    static final String        T_DISCONNECT        = "DISCONNECT";
    static final String        T_DISTINCT          = "DISTINCT";
    public static final String T_DO                = "DO";
    
    public static final String T_DOUBLE            = "FLOAT";
    
    
    static final String        T_DROP              = "DROP";
    static final String        T_DYNAMIC           = "DYNAMIC";
    static final String        T_EACH              = "EACH";
    static final String        T_ELEMENT           = "ELEMENT";
    static final String        T_ELSE              = "ELSE";
    static final String        T_ELSEIF            = "ELSEIF";
    static final String        T_END               = "END";
    static final String        T_END_EXEC          = "END_EXEC";
    static final String        T_ESCAPE            = "ESCAPE";
    static final String        T_EVERY             = "EVERY";
    static final String        T_EXCEPT            = "EXCEPT";
    static final String        T_EXEC              = "EXEC";
    public static final String T_EXECUTE           = "EXECUTE";
    static final String        T_EXISTS            = "EXISTS";
    static final String        T_EXP               = "EXP";
    static final String        T_EXTERNAL          = "EXTERNAL";
    static final String        T_EXTRACT           = "EXTRACT";
    static final String        T_FALSE             = "FALSE";
    static final String        T_FETCH             = "FETCH";
    static final String        T_FILTER            = "FILTER";
    static final String        T_FIRST_VALUE       = "FIRST_VALUE";
    public static final String T_FLOAT             = "FLOAT";
    static final String        T_FLOOR             = "FLOOR";
    static final String        T_FOR               = "FOR";
    static final String        T_FOREIGN           = "FOREIGN";
    static final String        T_FREE              = "FREE";
    static final String        T_FROM              = "FROM";
    static final String        T_FULL              = "FULL";
    static final String        T_FUNCTION          = "FUNCTION";
    static final String        T_FUSION            = "FUSION";
    public static final String T_GET               = "GET";
    static final String        T_GLOBAL            = "GLOBAL";
    public static final String T_GRANT             = "GRANT";
    static final String        T_GROUP             = "GROUP";
    static final String        T_GROUPING          = "GROUPING";
    static final String        T_HANDLER           = "HANDLER";
    static final String        T_HAVING            = "HAVING";
    static final String        T_HOLD              = "HOLD";
    public static final String T_HOUR              = "HOUR";
    static final String        T_IDENTITY          = "IDENTITY";
    static final String        T_IF                = "IF";
    static final String        T_IN                = "IN";
    static final String        T_INDICATOR         = "INDICATOR";
    static final String        T_INNER             = "INNER";
    static final String        T_INOUT             = "INOUT";
    static final String        T_INSENSITIVE       = "INSENSITIVE";
    public static final String T_INSERT            = "INSERT";
    static final String        T_INT               = "INT";
    public static final String T_INTEGER           = "INTEGER";
    static final String        T_INTERSECT         = "INTERSECT";
    static final String        T_INTERSECTION      = "INTERSECTION";
    public static final String T_INTERVAL          = "INTERVAL";
    static final String        T_INTO              = "INTO";
    static final String        T_ITERATE           = "ITERATE";
    static final String        T_IS                = "IS";
    static final String        T_JAR               = "JAR";             
    static final String        T_JOIN              = "JOIN";
    static final String        T_LAG               = "LAG";
    static final String        T_LANGUAGE          = "LANGUAGE";
    static final String        T_LARGE             = "LARGE";
    static final String        T_LAST_VALUE        = "LAST_VALUE";
    static final String        T_LATERAL           = "LATERAL";
    static final String        T_LEAD              = "LEAD";
    static final String        T_LEADING           = "LEADING";
    static final String        T_LEAVE             = "LEAVE";
    static final String        T_LEFT              = "LEFT";
    static final String        T_LIKE              = "LIKE";
    static final String        T_LIKE_REGX         = "LIKE_REGX";
    static final String        T_LN                = "LN";
    public static final String T_LOCAL             = "LOCAL";
    static final String        T_LOCALTIME         = "LOCALTIME";
    static final String        T_LOCALTIMESTAMP    = "LOCALTIMESTAMP";
    public static final String T_LOOP              = "LOOP";
    static final String        T_LOWER             = "LOWER";
    static final String        T_MATCH             = "MATCH";
    static final String        T_MAX               = "MAX";
    static final String        T_MAX_CARDINALITY   = "MAX_CARDINALITY";
    static final String        T_MEMBER            = "MEMBER";
    static final String        T_MERGE             = "MERGE";
    static final String        T_METHOD            = "METHOD";
    static final String        T_MIN               = "MIN";
    public static final String T_MINUTE            = "MINUTE";
    static final String        T_MOD               = "MOD";
    static final String        T_MODIFIES          = "MODIFIES";
    static final String        T_MODULE            = "MODULE";
    public static final String T_MONTH             = "MONTH";
    static final String        T_MULTISET          = "MULTISET";
    static final String        T_NATIONAL          = "NATIONAL";
    static final String        T_NATURAL           = "NATURAL";
    static final String        T_NCHAR             = "NCHAR";
    static final String        T_NCLOB             = "NCLOB";
    static final String        T_NEW               = "NEW";
    public static final String T_NO                = "NO";
    public static final String T_NONE              = "NONE";
    static final String        T_NORMALIZE         = "NORMALIZE";
    static final String        T_NOT               = "NOT";
    static final String        T_NTH_VALUE         = "NTH_VALUE";
    static final String        T_NTILE             = "NTILE";
    public static final String T_NULL              = "NULL";
    public static final String T_NULLIF            = "NULLIF";
    public static final String T_NUMERIC           = "NUMERIC";
    static final String        T_OCCURRENCES_REGEX = "OCCURRENCES_REGEX";
    static final String        T_OCTET_LENGTH      = "OCTET_LENGTH";
    static final String        T_OF                = "OF";
    static final String        T_OFFSET            = "OFFSET";
    static final String        T_OLD               = "OLD";
    public static final String T_ON                = "ON";
    static final String        T_ONLY              = "ONLY";
    static final String        T_OPEN              = "OPEN";
    static final String        T_OR                = "OR";
    static final String        T_ORDER             = "ORDER";
    static final String        T_OUT               = "OUT";
    static final String        T_OUTER             = "OUTER";
    static final String        T_OVER              = "OVER";
    static final String        T_OVERLAPS          = "OVERLAPS";
    static final String        T_OVERLAY           = "OVERLAY";
    static final String        T_PARAMETER         = "PARAMETER";
    static final String        T_PARTITION         = "PARTITION";
    static final String        T_PERCENT_RANK      = "PERCENT_RANK";
    static final String        T_PERCENTILE_CONT   = "PERCENTILE_CONT";
    static final String        T_PERCENTILE_DISC   = "PERCENTILE_DISC";
    static final String        T_POSITION          = "POSITION";
    static final String        T_POSITION_REGEX    = "POSITION_REGEX";
    static final String        T_POWER             = "POWER";
    static final String        T_PRECISION         = "PRECISION";
    static final String        T_PREPARE           = "PREPARE";
    static final String        T_PRIMARY           = "PRIMARY";
    static final String        T_PROCEDURE         = "PROCEDURE";
    static final String        T_RANGE             = "RANGE";
    static final String        T_RANK              = "RANK";
    static final String        T_READS             = "READS";
    public static final String T_REAL              = "REAL";
    static final String        T_RECURSIVE         = "RECURSIVE";
    static final String        T_REF               = "REF";
    public static final String T_REFERENCES        = "REFERENCES";
    static final String        T_REFERENCING       = "REFERENCING";
    static final String        T_REGR_AVGX         = "REGR_AVGX";
    static final String        T_REGR_AVGY         = "REGR_AVGY";
    static final String        T_REGR_COUNT        = "REGR_COUNT";
    static final String        T_REGR_INTERCEPT    = "REGR_INTERCEPT";
    static final String        T_REGR_R2           = "REGR_R2";
    static final String        T_REGR_SLOPE        = "REGR_SLOPE";
    static final String        T_REGR_SXX          = "REGR_SXX";
    static final String        T_REGR_SXY          = "REGR_SXY";
    static final String        T_REGR_SYY          = "REGR_SYY";
    static final String        T_RELEASE           = "RELEASE";
    static final String        T_REPEAT            = "REPEAT";
    static final String        T_RESIGNAL          = "RESIGNAL";
    static final String        T_RESULT            = "RESULT";
    static final String        T_RETURN            = "RETURN";
    static final String        T_RETURNS           = "RETURNS";
    static final String        T_REVOKE            = "REVOKE";
    static final String        T_RIGHT             = "RIGHT";
    static final String        T_ROLLBACK          = "ROLLBACK";
    static final String        T_ROLLUP            = "ROLLUP";
    static final String        T_ROW               = "ROW";
    static final String        T_ROW_NUMBER        = "ROW_NUMBER";
    static final String        T_ROWS              = "ROWS";
    static final String        T_SAVEPOINT         = "SAVEPOINT";
    static final String        T_SCOPE             = "SCOPE";
    static final String        T_SCROLL            = "SCROLL";
    static final String        T_SEARCH            = "SEARCH";
    public static final String T_SECOND            = "SECOND";
    public static final String T_SELECT            = "SELECT";
    static final String        T_SENSITIVE         = "SENSITIVE";
    static final String        T_SESSION_USER      = "SESSION_USER";
    public static final String T_SET               = "SET";
    static final String        T_SIGNAL            = "SIGNAL";
    static final String        T_SIMILAR           = "SIMILAR";
    public static final String T_SMALLINT          = "SMALLINT";
    static final String        T_SOME              = "SOME";
    static final String        T_SPECIFIC          = "SPECIFIC";
    static final String        T_SPECIFICTYPE      = "SPECIFICTYPE";
    static final String        T_SQL               = "SQL";
    static final String        T_SQLEXCEPTION      = "SQLEXCEPTION";
    static final String        T_SQLSTATE          = "SQLSTATE";
    static final String        T_SQLWARNING        = "SQLWARNING";
    static final String        T_SQRT              = "SQRT";
    static final String        T_START             = "START";
    static final String        T_STATIC            = "STATIC";
    static final String        T_STDDEV_POP        = "STDDEV_POP";
    static final String        T_STDDEV_SAMP       = "STDDEV_SAMP";
    static final String        T_SUBMULTISET       = "SUBMULTISET";
    static final String        T_SUBSTRING         = "SUBSTRING";
    static final String        T_SUBSTRING_REGEX   = "SUBSTRING_REGEX";
    static final String        T_SUM               = "SUM";
    static final String        T_SYMMETRIC         = "SYMMETRIC";
    static final String        T_SYSTEM            = "SYSTEM";
    static final String        T_SYSTEM_USER       = "SYSTEM_USER";
    static final String        T_TABLE             = "TABLE";
    static final String        T_TABLESAMPLE       = "TABLESAMPLE";
    static final String        T_THEN              = "THEN";
    public static final String T_TIME              = "TIME";
    public static final String T_TIMESTAMP         = "TIMESTAMP";
    public static final String T_TIMEZONE_HOUR     = "TIMEZONE_HOUR";
    public static final String T_TIMEZONE_MINUTE   = "TIMEZONE_MINUTE";
    public static final String T_TO                = "TO";
    static final String        T_TRAILING          = "TRAILING";
    static final String        T_TRANSLATE         = "TRANSLATE";
    static final String        T_TRANSLATE_REGEX   = "TRANSLATE_REGEX";
    static final String        T_TRANSLATION       = "TRANSLATION";
    static final String        T_TREAT             = "TREAT";
    public static final String T_TRIGGER           = "TRIGGER";
    static final String        T_TRIM              = "TRIM";
    static final String        T_TRIM_ARRAY        = "TRIM_ARRAY";
    static final String        T_TRUE              = "TRUE";
    static final String        T_TRUNCATE          = "TRUNCATE";
    static final String        T_UESCAPE           = "UESCAPE";
    static final String        T_UNION             = "UNION";
    
    static final String        T_ASSUMEUNIQUE      = "ASSUMEUNIQUE";     
    
    public static final String T_UNIQUE            = "UNIQUE";
    static final String        T_UNKNOWN           = "UNKNOWN";
    static final String        T_UNNEST            = "UNNEST";
    static final String        T_UNTIL             = "UNTIL";
    public static final String T_UPDATE            = "UPDATE";
    static final String        T_UPPER             = "UPPER";
    public static final String T_USER              = "USER";
    static final String        T_USING             = "USING";
    static final String        T_VALUE             = "VALUE";
    static final String        T_VALUES            = "VALUES";
    static final String        T_VAR_POP           = "VAR_POP";
    static final String        T_VAR_SAMP          = "VAR_SAMP";
    public static final String T_VARBINARY         = "VARBINARY";
    public static final String T_VARCHAR           = "VARCHAR";
    static final String        T_VARYING           = "VARYING";
    static final String        T_WHEN              = "WHEN";
    static final String        T_WHENEVER          = "WHENEVER";
    static final String        T_WHERE             = "WHERE";
    public static final String T_WHILE             = "WHILE";
    static final String        T_WIDTH_BUCKET      = "WIDTH_BUCKET";
    static final String        T_WINDOW            = "WINDOW";
    public static final String T_WITH              = "WITH";
    static final String        T_WITHIN            = "WITHIN";
    static final String        T_WITHOUT           = "WITHOUT";
    public static final String T_YEAR              = "YEAR";

    
    static final String        T_ASTERISK       = "*";
    static final String        T_COMMA          = ",";
    static final String        T_CIRCUMFLEX     = "^";
    static final String        T_CLOSEBRACKET   = ")";
    static final String        T_COLON          = ":";
    static final String        T_CONCAT         = "||";
    public static final String T_DIVIDE         = "/";
    static final String        T_EQUALS         = "=";
    static final String        T_GREATER        = ">";
    static final String        T_GREATER_EQUALS = ">=";
    static final String        T_LESS           = "<";
    static final String        T_LESS_EQUALS    = "<=";
    static final String        T_PERCENT        = "%";
    static final String        T_PLUS           = "+";
    static final String        T_MINUS          = "-";
    static final String        T_NOT_EQUALS     = "<>";
    static final String        T_NOT_EQUALS_ALT = "!=";
    static final String        T_OPENBRACKET    = "(";
    static final String        T_QUESTION       = "?";
    static final String        T_SEMICOLON      = ";";
    static final String        T_DOUBLE_COLON   = "::";

    
    static final String T_A                      = "A";
    static final String T_ABSOLUTE               = "ABSOLUTE";
    static final String T_ACTION                 = "ACTION";
    static final String T_ADA                    = "ADA";
    static final String T_ADMIN                  = "ADMIN";
    static final String T_AFTER                  = "AFTER";
    static final String T_ALWAYS                 = "ALWAYS";
    static final String T_ASC                    = "ASC";
    static final String T_ASSERTION              = "ASSERTION";
    static final String T_ASSIGNMENT             = "ASSIGNMENT";
    static final String T_ATTRIBUTE              = "ATTRIBUTE";
    static final String T_ATTRIBUTES             = "ATTRIBUTES";
    static final String T_BEFORE                 = "BEFORE";
    static final String T_BERNOULLI              = "BERNOULLI";
    static final String T_BREADTH                = "BREADTH";
    static final String T_C                      = "C";
    static final String T_CASCADE                = "CASCADE";
    static final String T_CATALOG                = "CATALOG";
    static final String T_CATALOG_NAME           = "CATALOG_NAME";
    static final String T_CHAIN                  = "CHAIN";
    static final String T_CHARACTER_SET_CATALOG  = "CHARACTER_SET_CATALOG";
    static final String T_CHARACTER_SET_NAME     = "CHARACTER_SET_NAME";
    static final String T_CHARACTER_SET_SCHEMA   = "CHARACTER_SET_SCHEMA";
    static final String T_CHARACTERISTICS        = "CHARACTERISTICS";
    static final String T_CHARACTERS             = "CHARACTERS";
    static final String T_CLASS_ORIGIN           = "CLASS_ORIGIN";
    static final String T_COBOL                  = "COBOL";
    static final String T_COLLATION              = "COLLATION";
    static final String T_COLLATION_CATALOG      = "COLLATION_CATALOG";
    static final String T_COLLATION_NAME         = "COLLATION_NAME";
    static final String T_COLLATION_SCHEMA       = "COLLATION_SCHEMA";
    static final String T_COLUMN_NAME            = "COLUMN_NAME";
    static final String T_COMMAND_FUNCTION       = "COMMAND_FUNCTION";
    static final String T_COMMAND_FUNCTION_CODE  = "COMMAND_FUNCTION_CODE";
    static final String T_COMMITTED              = "COMMITTED";
    static final String T_COMPARABLE             = "COMPARABLE";        
    static final String T_CONDITION_IDENTIFIER   = "CONDIITON_IDENTIFIER";
    static final String T_CONDITION_NUMBER       = "CONDITION_NUMBER";
    static final String T_CONNECTION_NAME        = "CONNECTION_NAME";
    static final String T_CONSTRAINT_CATALOG     = "CONSTRAINT_CATALOG";
    static final String T_CONSTRAINT_NAME        = "CONSTRAINT_NAME";
    static final String T_CONSTRAINT_SCHEMA      = "CONSTRAINT_SCHEMA";
    static final String T_CONSTRAINTS            = "CONSTRAINTS";
    static final String T_CONSTRUCTOR            = "CONSTRUCTOR";
    static final String T_CONTAINS               = "CONTAINS";
    static final String T_CONTINUE               = "CONTINUE";
    static final String T_CURRENT_COLLATION      = "CURRENT_COLLATION";
    static final String T_CURSOR_NAME            = "CURSOR_NAME";
    static final String T_DATA                   = "DATA";
    static final String T_DATETIME_INTERVAL_CODE = "DATETIME_INTERVAL_CODE";
    static final String T_DATETIME_INTERVAL_PRECISION =
        "DATETIME_INTERVAL_PRECISION";
    static final String        T_DEFAULTS             = "DEFAULTS";
    static final String        T_DEFERRABLE           = "DEFERRABLE";
    static final String        T_DEFERRED             = "DEFERRED";
    static final String        T_DEFINED              = "DEFINED";
    static final String        T_DEFINER              = "DEFINER";
    static final String        T_DEGREE               = "DEGREE";
    static final String        T_DEPTH                = "DEPTH";
    static final String        T_DERIVED              = "DERIVED";
    static final String        T_DESC                 = "DESC";
    static final String        T_DESCRIPTOR           = "DESCRIPTOR";
    static final String        T_DIAGNOSTICS          = "DIAGNOSTICS";
    static final String        T_DISPATCH             = "DISPATCH";
    public static final String T_DOMAIN               = "DOMAIN";
    static final String        T_DYNAMIC_FUNCTION     = "DYNAMIC_FUNCTION";
    static final String T_DYNAMIC_FUNCTION_CODE = "DYNAMIC_FUNCTION_CODE";
    static final String        T_EXCEPTION            = "EXCEPTION";
    static final String        T_EXCLUDE              = "EXCLUDE";
    static final String        T_EXCLUDING            = "EXCLUDING";
    static final String        T_EXIT                 = "EXIT";
    static final String        T_FINAL                = "FINAL";
    static final String        T_FIRST                = "FIRST";
    static final String        T_FOLLOWING            = "FOLLOWING";
    static final String        T_FORTRAN              = "FORTRAN";
    static final String        T_FOUND                = "FOUND";
    public static final String T_G_FACTOR             = "G";
    static final String        T_GENERAL              = "GENERAL";
    static final String        T_GO                   = "GO";
    static final String        T_GOTO                 = "GOTO";
    static final String        T_GRANTED              = "GRANTED";
    static final String        T_HIERARCHY            = "HIERARCHY";
    static final String        T_IMPLEMENTATION       = "IMPLEMENTATION";
    static final String        T_INCLUDING            = "INCLUDING";
    static final String        T_INCREMENT            = "INCREMENT";
    static final String        T_INITIALLY            = "INITIALLY";
    static final String        T_INPUT                = "INPUT";
    static final String        T_INSTANCE             = "INSTANCE";
    static final String        T_INSTANTIABLE         = "INSTANTIABLE";
    static final String        T_INSTEAD              = "INSTEAD";
    static final String        T_INTERFACE            = "INTERFACE";    
    static final String        T_INVOKER              = "INVOKER";
    static final String        T_ISOLATION            = "ISOLATION";
    static final String        T_JAVA                 = "JAVA";         
    public static final String T_K_FACTOR             = "K";
    static final String        T_KEY                  = "KEY";
    static final String        T_KEY_MEMBER           = "KEY_MEMBER";
    static final String        T_KEY_TYPE             = "KEY_TYPE";
    static final String        T_LAST                 = "LAST";
    static final String        T_LENGTH               = "LENGTH";
    static final String        T_LEVEL                = "LEVEL";
    static final String        T_LOCATOR              = "LOCATOR";
    public static final String T_M_FACTOR             = "M";
    static final String        T_MAP                  = "MAP";
    static final String        T_MATCHED              = "MATCHED";
    static final String        T_MAXVALUE             = "MAXVALUE";
    static final String        T_MESSAGE_LENGTH       = "MESSAGE_LENGTH";
    static final String        T_MESSAGE_OCTET_LENGTH = "MESSAGE_OCTET_LENGTH";
    static final String        T_MESSAGE_TEXT         = "MESSAGE_TEXT";
    static final String        T_MINVALUE             = "MINVALUE";
    static final String        T_MORE                 = "MORE";
    static final String        T_MUMPS                = "MUMPS";
    static final String        T_NAME                 = "NAME";
    static final String        T_NAMES                = "NAMES";
    static final String        T_NESTING              = "NESTING";
    static final String        T_NEXT                 = "NEXT";
    static final String        T_NORMALIZED           = "NORMALIZED";
    static final String        T_NULLABLE             = "NULLABLE";
    static final String        T_NULLS                = "NULLS";
    static final String        T_NUMBER               = "NUMBER";
    public static final String T_OBJECT               = "OBJECT";
    static final String        T_OCTETS               = "OCTETS";
    static final String        T_OPTION               = "OPTION";
    static final String        T_OPTIONS              = "OPTIONS";
    static final String        T_ORDERING             = "ORDERING";
    static final String        T_ORDINALITY           = "ORDINALITY";
    static final String        T_OTHERS               = "OTHERS";
    static final String        T_OVERRIDING           = "OVERRIDING";
    public static final String T_P_FACTOR             = "P";
    static final String        T_PAD                  = "PAD";
    static final String        T_PARAMETER_MODE       = "PARAMETER_MODE";
    static final String        T_PARAMETER_NAME       = "PARAMETER_NAME";
    static final String T_PARAMETER_ORDINAL_POSITION =
        "PARAMETER_ORDINAL_POSITION";
    static final String T_PARAMETER_SPECIFIC_CATALOG =
        "PARAMETER_SPECIFIC_CATALOG";
    static final String T_PARAMETER_SPEC_NAME = "PARAMETER_SPECIFIC_NAME";
    static final String T_PARAMETER_SPEC_SCHEMA = "PARAMETER_SPECIFIC_SCHEMA";
    static final String        T_PARTIAL              = "PARTIAL";
    static final String        T_PASCAL               = "PASCAL";
    static final String        T_PATH                 = "PATH";
    static final String        T_PLACING              = "PLACING";
    static final String        T_PLI                  = "PLI";
    static final String        T_PRECEDING            = "PRECEDING";
    static final String        T_PRESERVE             = "PRESERVE";
    static final String        T_PRIOR                = "PRIOR";
    static final String        T_PRIVILEGES           = "PRIVILEGES";
    static final String        T_PUBLIC               = "PUBLIC";
    static final String        T_READ                 = "READ";
    static final String        T_RELATIVE             = "RELATIVE";
    static final String        T_REPEATABLE           = "REPEATABLE";
    static final String        T_RESTART              = "RESTART";
    static final String        T_RETURNED_CARDINALITY = "RETURNED_CARDINALITY";
    static final String        T_RETURNED_LENGTH      = "RETURNED_LENGTH";
    static final String T_RETURNED_OCTET_LENGTH = "RETURNED_OCTET_LENGTH";
    static final String        T_RETURNED_SQLSTATE    = "RETURNED_SQLSTATE";
    public static final String T_ROLE                 = "ROLE";
    static final String        T_ROUTINE              = "ROUTINE";
    static final String        T_ROUTINE_CATALOG      = "ROUTINE_CATALOG";
    static final String        T_ROUTINE_NAME         = "ROUTINE_NAME";
    static final String        T_ROUTINE_SCHEMA       = "ROUTINE_SCHEMA";
    static final String        T_ROW_COUNT            = "ROW_COUNT";
    static final String        T_SCALE                = "SCALE";
    public static final String T_SCHEMA               = "SCHEMA";
    static final String        T_SCHEMA_NAME          = "SCHEMA_NAME";
    static final String        T_SCOPE_CATALOG        = "SCOPE_CATALOG";
    static final String        T_SCOPE_NAME           = "SCOPE_NAME";
    static final String        T_SCOPE_SCHEMA         = "SCOPE_SCHEMA";
    static final String        T_SECTION              = "SECTION";
    static final String        T_SECURITY             = "SECURITY";
    static final String        T_SELF                 = "SELF";
    static final String        T_SEQUENCE             = "SEQUENCE";
    static final String        T_SERIALIZABLE         = "SERIALIZABLE";
    static final String        T_SERVER_NAME          = "SERVER_NAME";
    public static final String T_SESSION              = "SESSION";
    static final String        T_SETS                 = "SETS";
    static final String        T_SIMPLE               = "SIMPLE";
    static final String        T_SIZE                 = "SIZE";
    static final String        T_SOURCE               = "SOURCE";
    static final String        T_SPACE                = "SPACE";
    static final String        T_SPECIFIC_NAME        = "SPECIFIC_NAME";
    static final String        T_SQLDATA              = "SQLDATA";      
    static final String        T_STACKED              = "STACKED";
    static final String        T_STATE                = "STATE";
    static final String        T_STATEMENT            = "STATEMENT";
    static final String        T_STRUCTURE            = "STRUCTURE";
    static final String        T_STYLE                = "STYLE";
    static final String        T_SUBCLASS_ORIGIN      = "SUBCLASS_ORIGIN";
    public static final String T_T_FACTOR             = "T";
    static final String        T_TABLE_NAME           = "TABLE_NAME";
    static final String        T_TEMPORARY            = "TEMPORARY";
    static final String        T_TIES                 = "TIES";
    static final String        T_TOP_LEVEL_COUNT      = "TOP_LEVEL_COUNT";
    static final String        T_TRANSACTION          = "TRANSACTION";
    static final String        T_TRANSACT_COMMITTED = "TRANSACTIONS_COMMITTED";
    static final String T_TRANSACTION_ROLLED_BACK = "TRANSACTIONS_ROLLED_BACK";
    static final String        T_TRANSACT_ACTIVE      = "TRANSACTION_ACTIVE";
    static final String        T_TRANSFORM            = "TRANSFORM";
    static final String        T_TRANSFORMS           = "TRANSFORMS";
    static final String        T_TRIGGER_CATALOG      = "TRIGGER_CATALOG";
    static final String        T_TRIGGER_NAME         = "TRIGGER_NAME";
    static final String        T_TRIGGER_SCHEMA       = "TRIGGER_SCHEMA";
    public static final String T_TYPE                 = "TYPE";
    static final String        T_UNBOUNDED            = "UNBOUNDED";
    static final String        T_UNCOMMITTED          = "UNCOMMITTED";
    static final String        T_UNDER                = "UNDER";
    static final String        T_UNDO                 = "UNDO";
    static final String        T_UNNAMED              = "UNNAMED";
    public static final String T_USAGE                = "USAGE";
    static final String T_USER_DEFINED_TYPE_CATALOG =
        "USER_DEFINED_TYPE_CATALOG";
    static final String T_USER_DEFINED_TYPE_CODE = "USER_DEFINED_TYPE_CODE";
    static final String T_USER_DEFINED_TYPE_NAME = "USER_DEFINED_TYPE_NAME";
    static final String T_USER_DEFINED_TYPE_SCHEMA =
        "USER_DEFINED_TYPE_SCHEMA";
    static final String        T_VIEW  = "VIEW";
    static final String        T_WORK  = "WORK";
    static final String        T_WRITE = "WRITE";
    public static final String T_ZONE  = "ZONE";

    
    static final String        T_ADD                 = "ADD";
    static final String        T_ALIAS               = "ALIAS";
    static final String        T_AUTOCOMMIT          = "AUTOCOMMIT";
    static final String        T_BACKUP              = "BACKUP";
    public static final String T_BIT                 = "BIT";
    static final String        T_BITLENGTH           = "BITLENGTH";
    static final String        T_CACHE               = "CACHE";
    static final String        T_CACHED              = "CACHED";
    static final String        T_CASEWHEN            = "CASEWHEN";
    static final String        T_CHECKPOINT          = "CHECKPOINT";
    static final String        T_CLASS               = "CLASS";
    static final String        T_COMPACT             = "COMPACT";
    public static final String T_COMPRESSED          = "COMPRESSED";
    static final String        T_CONTROL             = "CONTROL";
    static final String        T_CURDATE             = "CURDATE";
    static final String        T_CURTIME             = "CURTIME";
    static final String        T_DATABASE            = "DATABASE";
    static final String        T_DEFRAG              = "DEFRAG";
    static final String        T_EXPLAIN             = "EXPLAIN";
    static final String        T_EVENT               = "EVENT";
    static final String        T_FILE                = "FILE";
    static final String        T_FILES               = "FILES";
    static final String        T_FOLD                = "FOLD";
    static final String        T_GENERATED           = "GENERATED";
    static final String        T_HEADER              = "HEADER";
    static final String        T_IFNULL              = "IFNULL";
    static final String        T_IGNORECASE          = "IGNORECASE";
    static final String        T_IMMEDIATELY         = "IMMEDIATELY";
    public static final String T_INDEX               = "INDEX";
    public static final String T_INITIAL             = "INITIAL";
    static final String        T_ISAUTOCOMMIT        = "ISAUTOCOMMIT";
    static final String        T_ISREADONLYDATABASE  = "ISREADONLYDATABASE";
    static final String T_ISREADONLYDATABASEFILES = "ISREADONLYDATABASEFILES";
    static final String        T_ISREADONLYSESSION   = "ISREADONLYSESSION";
    static final String        T_LIMIT               = "LIMIT";
    static final String        T_LOCK                = "LOCK";
    static final String        T_LOCKS               = "LOCKS";
    static final String        T_LOGSIZE             = "LOGSIZE";
    static final String        T_MAXROWS             = "MAXROWS";
    static final String        T_MEMORY              = "MEMORY";
    
    static final String        T_MICROS              = "MICROS";         
    static final String        T_MICROSECOND         = "MICROSECOND";    
    
    static final String        T_MILLIS              = "MILLIS";
    
    static final String        T_MILLISECOND         = "MILLISECOND";    
    
    static final String        T_MINUS_EXCEPT        = "MINUS";
    static final String        T_MVCC                = "MVCC";
    static final String        T_NIO                 = "NIO";
    static final String        T_NOW                 = "NOW";
    static final String        T_NOWAIT              = "NOWAIT";
    static final String        T_NVL                 = "NVL";
    static final String        T_OCTETLENGTH         = "OCTETLENGTH";
    static final String        T_OFF                 = "OFF";
    public static final String T_OTHER               = "OTHER";
    public static final String T_PASSWORD            = "PASSWORD";
    static final String        T_PLAN                = "PLAN";
    static final String        T_PROPERTY            = "PROPERTY";
    static final String        T_QUEUE               = "QUEUE";
    static final String        T_READONLY            = "READONLY";
    static final String T_REFERENTIAL_INTEGRITY      = "REFERENTIAL_INTEGRITY";
    static final String        T_RENAME              = "RENAME";
    static final String        T_RESTRICT            = "RESTRICT";
    static final String        T_SCRIPT              = "SCRIPT";
    static final String        T_SCRIPTFORMAT        = "SCRIPTFORMAT";
    static final String        T_BLOCKING            = "BLOCKING";
    static final String        T_SHUTDOWN            = "SHUTDOWN";
    static final String        T_SQL_TSI_DAY         = "SQL_TSI_DAY";
    static final String        T_SQL_TSI_FRAC_SECOND = "SQL_TSI_FRAC_SECOND";
    static final String        T_SQL_TSI_HOUR        = "SQL_TSI_HOUR";
    static final String        T_SQL_TSI_MINUTE      = "SQL_TSI_MINUTE";
    static final String        T_SQL_TSI_MONTH       = "SQL_TSI_MONTH";
    static final String        T_SQL_TSI_QUARTER     = "SQL_TSI_QUARTER";
    static final String        T_SQL_TSI_SECOND      = "SQL_TSI_SECOND";
    static final String        T_SQL_TSI_WEEK        = "SQL_TSI_WEEK";
    static final String        T_SQL_TSI_YEAR        = "SQL_TSI_YEAR";
    static final String        T_SQL_BIGINT          = "SQL_BIGINT";
    static final String        T_SQL_BINARY          = "SQL_BINARY";
    static final String        T_SQL_BIT             = "SQL_BIT";
    static final String        T_SQL_BLOB            = "SQL_BLOB";
    static final String        T_SQL_BOOLEAN         = "SQL_BOOLEAN";
    static final String        T_SQL_CHAR            = "SQL_CHAR";
    static final String        T_SQL_CLOB            = "SQL_CLOB";
    static final String        T_SQL_DATE            = "SQL_DATE";
    static final String        T_SQL_DECIMAL         = "SQL_DECIMAL";
    static final String        T_SQL_DATALINK        = "SQL_DATALINK";
    static final String        T_SQL_DOUBLE          = "SQL_DOUBLE";
    static final String        T_SQL_FLOAT           = "SQL_FLOAT";
    static final String        T_SQL_INTEGER         = "SQL_INTEGER";
    static final String        T_SQL_LONGVARBINARY   = "SQL_LONGVARBINARY";
    static final String        T_SQL_LONGNVARCHAR    = "SQL_LONGNVARCHAR";
    static final String        T_SQL_LONGVARCHAR     = "SQL_LONGVARCHAR";
    static final String        T_SQL_NCHAR           = "SQL_NCHAR";
    static final String        T_SQL_NCLOB           = "SQL_NCLOB";
    static final String        T_SQL_NUMERIC         = "SQL_NUMERIC";
    static final String        T_SQL_NVARCHAR        = "SQL_NVARCHAR";
    static final String        T_SQL_REAL            = "SQL_REAL";
    static final String        T_SQL_ROWID           = "SQL_ROWID";
    static final String        T_SQL_SQLXML          = "SQL_SQLXML";
    static final String        T_SQL_SMALLINT        = "SQL_SMALLINT";
    static final String        T_SQL_TIME            = "SQL_TIME";
    static final String        T_SQL_TIMESTAMP       = "SQL_TIMESTAMP";
    static final String        T_SQL_TINYINT         = "SQL_TINYINT";
    static final String        T_SQL_VARBINARY       = "SQL_VARBINARY";
    static final String        T_SQL_VARCHAR         = "SQL_VARCHAR";
    static final String        T_SYSDATE             = "SYSDATE";
    static final String        T_TEMP                = "TEMP";
    public static final String T_TEXT                = "TEXT";
    static final String        T_TIMESTAMPADD        = "TIMESTAMPADD";
    static final String        T_TIMESTAMPDIFF       = "TIMESTAMPDIFF";
    public static final String T_TINYINT             = "TINYINT";
    static final String        T_TO_CHAR             = "TO_CHAR";
    static final String        T_TODAY               = "TODAY";
    static final String        T_TOP                 = "TOP";
    public static final String T_VARCHAR_IGNORECASE  = "VARCHAR_IGNORECASE";
    static final String        T_WRITE_DELAY         = "WRITE_DELAY";
    public static final String T_YES                 = "YES";
    public static final String T_DAY_NAME            = "DAY_NAME";
    public static final String T_MONTH_NAME          = "MONTH_NAME";
    public static final String T_QUARTER             = "QUARTER";
    public static final String T_DAY_OF_WEEK         = "DAY_OF_WEEK";
    public static final String T_DAY_OF_MONTH        = "DAY_OF_MONTH";
    public static final String T_DAY_OF_YEAR         = "DAY_OF_YEAR";
    public static final String T_WEEK_OF_YEAR        = "WEEK_OF_YEAR";
    static final String        T_DAYNAME             = "DAYNAME";
    static final String        T_NONTHNAME           = "NONTHNAME";
    static final String        T_DAYOFMONTH          = "DAYOFMONTH";
    static final String        T_DAYOFWEEK           = "DAYOFWEEK";
    static final String        T_DAYOFYEAR           = "DAYOFYEAR";
    static final String        T_WEEK                = "WEEK";
    
    static final String        T_WEEKOFYEAR          = "WEEKOFYEAR"; 
    static final String        T_WEEKDAY             = "WEEKDAY";    
    

    
    static final String        T_ACOS             = "ACOS";
    static final String        T_ASIN             = "ASIN";
    static final String        T_ATAN             = "ATAN";
    static final String        T_ATAN2            = "ATAN2";
    static final String        T_COS              = "COS";
    static final String        T_COT              = "COT";
    static final String        T_DEGREES          = "DEGREES";
    static final String        T_DMOD             = "DMOD";
    static final String        T_LOG              = "LOG";
    static final String        T_LOG10            = "LOG10";
    static final String        T_PI               = "PI";
    static final String        T_RADIANS          = "RADIANS";
    static final String        T_RAND             = "RAND";
    static final String        T_ROUND            = "ROUND";
    static final String        T_SIGN             = "SIGN";
    static final String        T_SIN              = "SIN";
    static final String        T_TAN              = "TAN";
    static final String        T_BITAND           = "BITAND";
    static final String        T_BITOR            = "BITOR";
    static final String        T_BITXOR           = "BITXOR";
    
    static final String        T_CONCAT_WORD      = "CONCAT";
    
    static final String        T_ROUNDMAGIC       = "ROUNDMAGIC";
    static final String        T_ASCII            = "ASCII";
    
    
    
    static final String        T_DIFFERENCE       = "DIFFERENCE";
    static final String        T_HEXTORAW         = "HEXTORAW";
    static final String        T_LCASE            = "LCASE";
    static final String        T_LOCATE           = "LOCATE";
    static final String        T_LTRIM            = "LTRIM";
    static final String        T_RAWTOHEX         = "RAWTOHEX";
    static final String        T_REPLACE          = "REPLACE";
    static final String        T_RTRIM            = "RTRIM";
    static final String        T_SOUNDEX          = "SOUNDEX";
    static final String        T_SPACE_WORD       = "SPACE_WORD";
    static final String        T_SUBSTR           = "SUBSTR";
    static final String        T_UCASE            = "UCASE";
    static final String        T_DATEDIFF         = "DATEDIFF";
    public static final String T_SECONDS_MIDNIGHT = "SECONDS_SINCE_MIDNIGHT";

    
    
    
    public static final int ABS                              = 1;
    public static final int ALL                              = 2;
    public static final int ALLOCATE                         = 3;
    public static final int ALTER                            = 4;
    public static final int AND                              = 5;
    public static final int ANY                              = 6;
    public static final int ARE                              = 7;
    public static final int ARRAY                            = 8;
    public static final int AS                               = 9;
    public static final int ASENSITIVE                       = 10;
    public static final int ASYMMETRIC                       = 11;
    public static final int AT                               = 12;
    public static final int ATOMIC                           = 13;
    public static final int AUTHORIZATION                    = 14;
    public static final int AVG                              = 15;
    public static final int BEGIN                            = 16;
    public static final int BETWEEN                          = 17;
    public static final int BIGINT                           = 18;
    public static final int BINARY                           = 19;
    public static final int BLOB                             = 20;
    public static final int BOOLEAN                          = 21;
    public static final int BOTH                             = 22;
    public static final int BY                               = 23;
    public static final int CALL                             = 24;
    public static final int CALLED                           = 25;
    public static final int CARDINALITY                      = 26;
    public static final int CASCADED                         = 27;
    public static final int CASE                             = 28;
    public static final int CAST                             = 29;
    public static final int CEIL                             = 30;
    public static final int CEILING                          = 31;
    public static final int CHAR                             = 32;
    public static final int CHAR_LENGTH                      = 33;
    public static final int CHARACTER                        = 34;
    public static final int CHARACTER_LENGTH                 = 35;
    public static final int CHECK                            = 36;
    public static final int CLOB                             = 37;
    public static final int CLOSE                            = 38;
    public static final int COALESCE                         = 39;
    public static final int COLLATE                          = 40;
    public static final int COLLECT                          = 41;
    public static final int COLUMN                           = 42;
    public static final int COMMIT                           = 43;
    public static final int COMPARABLE                       = 44;
    public static final int CONDITION                        = 45;
    public static final int CONNECT                          = 46;
    public static final int CONSTRAINT                       = 47;
    public static final int CONVERT                          = 48;
    public static final int CORR                             = 49;
    public static final int CORRESPONDING                    = 50;
    public static final int COUNT                            = 51;
    
    public static final int APPROX_COUNT_DISTINCT            = 1304;
    
    public static final int COVAR_POP                        = 52;
    public static final int COVAR_SAMP                       = 53;
    public static final int CREATE                           = 54;
    public static final int CROSS                            = 55;
    public static final int CUBE                             = 56;
    public static final int CUME_DIST                        = 57;
    public static final int CURRENT                          = 58;
    public static final int CURRENT_CATALOG                  = 59;
    public static final int CURRENT_DATE                     = 60;
    public static final int CURRENT_DEFAULT_TRANSFORM_GROUP  = 61;
    public static final int CURRENT_PATH                     = 62;
    public static final int CURRENT_ROLE                     = 63;
    public static final int CURRENT_SCHEMA                   = 64;
    public static final int CURRENT_TIME                     = 65;
    public static final int CURRENT_TIMESTAMP                = 66;
    public static final int CURRENT_TRANSFORM_GROUP_FOR_TYPE = 67;
    public static final int CURRENT_USER                     = 68;
    public static final int CURSOR                           = 69;
    public static final int CYCLE                            = 70;
    public static final int DATE                             = 71;
    public static final int DAY                              = 72;
    public static final int DEALLOCATE                       = 73;
    public static final int DEC                              = 74;
    public static final int DECIMAL                          = 75;
    public static final int DECLARE                          = 76;
    public static final int DEFAULT                          = 77;
    public static final int DELETE                           = 78;
    public static final int DENSE_RANK                       = 79;
    public static final int DEREF                            = 80;
    public static final int DESCRIBE                         = 81;
    public static final int DETERMINISTIC                    = 82;
    public static final int DISCONNECT                       = 83;
    public static final int DISTINCT                         = 84;
    public static final int DO                               = 85;
    public static final int DOUBLE                           = 86;
    public static final int DROP                             = 87;
    public static final int DYNAMIC                          = 88;
    public static final int EACH                             = 89;
    public static final int ELEMENT                          = 90;
    public static final int ELSE                             = 91;
    public static final int ELSEIF                           = 92;
    public static final int END                              = 93;
    public static final int END_EXEC                         = 94;
    public static final int ESCAPE                           = 95;
    public static final int EVERY                            = 96;
    public static final int EXCEPT                           = 97;
    public static final int EXEC                             = 98;
    public static final int EXECUTE                          = 99;
    public static final int EXISTS                           = 100;
    public static final int EXIT                             = 101;
    public static final int EXP                              = 102;
    public static final int EXTERNAL                         = 103;
    public static final int EXTRACT                          = 104;
    public static final int FALSE                            = 105;
    public static final int FETCH                            = 106;
    public static final int FILTER                           = 107;
    public static final int FIRST_VALUE                      = 108;
    public static final int FLOAT                            = 109;
    public static final int FLOOR                            = 110;
    public static final int FOR                              = 111;
    public static final int FOREIGN                          = 112;
    public static final int FREE                             = 113;
    public static final int FROM                             = 114;
    public static final int FULL                             = 115;
    public static final int FUNCTION                         = 116;
    public static final int FUSION                           = 117;
    public static final int GET                              = 118;
    public static final int GLOBAL                           = 119;
    public static final int GRANT                            = 120;
    public static final int GROUP                            = 121;
    public static final int GROUPING                         = 122;
    public static final int HANDLER                          = 123;
    public static final int HAVING                           = 124;
    public static final int HOLD                             = 125;
    public static final int HOUR                             = 126;
    public static final int IDENTITY                         = 127;
    public static final int IN                               = 128;
    public static final int INDICATOR                        = 129;
    public static final int INNER                            = 130;
    public static final int INOUT                            = 131;
    public static final int INSENSITIVE                      = 132;
    public static final int INSERT                           = 133;
    public static final int INT                              = 134;
    public static final int INTEGER                          = 135;
    public static final int INTERSECT                        = 136;
    public static final int INTERSECTION                     = 137;
    public static final int INTERVAL                         = 138;
    public static final int INTO                             = 139;
    public static final int IS                               = 140;
    public static final int ITERATE                          = 141;
    public static final int JOIN                             = 142;
    public static final int LAG                              = 143;
    public static final int LANGUAGE                         = 144;
    public static final int LARGE                            = 145;
    public static final int LAST_VALUE                       = 146;
    public static final int LATERAL                          = 147;
    public static final int LEAD                             = 148;
    public static final int LEADING                          = 149;
    public static final int LEAVE                            = 150;
    public static final int LEFT                             = 151;
    public static final int LIKE                             = 152;
    public static final int LIKE_REGEX                       = 153;
    public static final int LN                               = 154;
    public static final int LOCAL                            = 155;
    public static final int LOCALTIME                        = 156;
    public static final int LOCALTIMESTAMP                   = 157;
    public static final int LOOP                             = 158;
    public static final int LOWER                            = 159;
    public static final int MATCH                            = 160;
    public static final int MAX                              = 161;
    public static final int MAX_CARDINALITY                  = 162;
    public static final int MEMBER                           = 163;
    public static final int MERGE                            = 164;
    public static final int METHOD                           = 165;
    public static final int MIN                              = 166;
    public static final int MINUTE                           = 167;
    public static final int MOD                              = 168;
    public static final int MODIFIES                         = 169;
    public static final int MODULE                           = 170;
    public static final int MONTH                            = 171;
    public static final int MULTISET                         = 172;
    public static final int NATIONAL                         = 173;
    public static final int NATURAL                          = 174;
    public static final int NCHAR                            = 175;
    public static final int NCLOB                            = 176;
    public static final int NEW                              = 177;
    public static final int NO                               = 178;
    public static final int NONE                             = 179;
    public static final int NORMALIZE                        = 180;
    public static final int NOT                              = 181;
    public static final int NTH_VALUE                        = 182;
    public static final int NTILE                            = 183;
    public static final int NULL                             = 184;
    public static final int NULLIF                           = 185;
    public static final int NUMERIC                          = 186;
    public static final int OCCURRENCES_REGEX                = 187;
    public static final int OCTET_LENGTH                     = 188;
    public static final int OF                               = 189;
    public static final int OFFSET                           = 190;
    public static final int OLD                              = 191;
    public static final int ON                               = 192;
    public static final int ONLY                             = 193;
    public static final int OPEN                             = 194;
    public static final int OR                               = 195;
    public static final int ORDER                            = 196;
    public static final int OUT                              = 197;
    public static final int OUTER                            = 198;
    public static final int OVER                             = 199;
    public static final int OVERLAPS                         = 200;
    public static final int OVERLAY                          = 201;
    public static final int PARAMETER                        = 202;
    public static final int PARTITION                        = 203;
    public static final int PERCENT_RANK                     = 204;
    public static final int PERCENTILE_CONT                  = 205;
    public static final int PERCENTILE_DISC                  = 206;
    public static final int POSITION                         = 207;
    public static final int POSITION_REGEX                   = 208;
    public static final int POWER                            = 209;
    public static final int PRECISION                        = 210;
    public static final int PREPARE                          = 211;
    public static final int PRIMARY                          = 212;
    public static final int PROCEDURE                        = 213;
    public static final int RANGE                            = 214;
    public static final int RANK                             = 215;
    public static final int READS                            = 216;
    public static final int REAL                             = 217;
    public static final int RECURSIVE                        = 218;
    public static final int REF                              = 219;
    public static final int REFERENCES                       = 220;
    public static final int REFERENCING                      = 221;
    public static final int REGR_AVGX                        = 222;
    public static final int REGR_AVGY                        = 223;
    public static final int REGR_COUNT                       = 224;
    public static final int REGR_INTERCEPT                   = 225;
    public static final int REGR_R2                          = 226;
    public static final int REGR_SLOPE                       = 227;
    public static final int REGR_SXX                         = 228;
    public static final int REGR_SXY                         = 229;
    public static final int REGR_SYY                         = 230;
    public static final int RELEASE                          = 231;
    public static final int REPEAT                           = 232;
    public static final int RESIGNAL                         = 233;
    public static final int RESULT                           = 234;
    public static final int RETURN                           = 235;
    public static final int RETURNS                          = 236;
    public static final int REVOKE                           = 237;
    public static final int RIGHT                            = 238;
    public static final int ROLLBACK                         = 239;
    public static final int ROLLUP                           = 240;
    public static final int ROW                              = 241;
    public static final int ROW_NUMBER                       = 242;
    public static final int ROWS                             = 243;
    public static final int SAVEPOINT                        = 244;
    public static final int SCOPE                            = 245;
    public static final int SCROLL                           = 246;
    public static final int SEARCH                           = 247;
    public static final int SECOND                           = 248;
    public static final int SELECT                           = 249;
    public static final int SENSITIVE                        = 250;
    public static final int SESSION_USER                     = 251;
    public static final int SET                              = 252;
    public static final int SIGNAL                           = 253;
    public static final int SIMILAR                          = 254;
    public static final int SMALLINT                         = 255;
    public static final int SOME                             = 256;
    public static final int SPECIFIC                         = 257;
    public static final int SPECIFICTYPE                     = 258;
    public static final int SQL                              = 259;
    public static final int SQLEXCEPTION                     = 260;
    public static final int SQLSTATE                         = 261;
    public static final int SQLWARNING                       = 262;
    public static final int SQRT                             = 263;
    public static final int STACKED                          = 264;
    public static final int START                            = 265;
    public static final int STATIC                           = 266;
    public static final int STDDEV_POP                       = 267;
    public static final int STDDEV_SAMP                      = 268;
    public static final int SUBMULTISET                      = 269;
    public static final int SUBSTRING                        = 270;
    public static final int SUBSTRING_REGEX                  = 271;
    public static final int SUM                              = 272;
    public static final int SYMMETRIC                        = 273;
    public static final int SYSTEM                           = 274;
    public static final int SYSTEM_USER                      = 275;
    public static final int TABLE                            = 276;
    public static final int TABLESAMPLE                      = 277;
    public static final int THEN                             = 278;
    public static final int TIME                             = 279;
    public static final int TIMESTAMP                        = 280;
    public static final int TIMEZONE_HOUR                    = 281;
    public static final int TIMEZONE_MINUTE                  = 282;
    public static final int TO                               = 283;
    public static final int TRAILING                         = 284;
    public static final int TRANSLATE                        = 285;
    public static final int TRANSLATE_REGEX                  = 286;
    public static final int TRANSLATION                      = 287;
    public static final int TREAT                            = 288;
    public static final int TRIGGER                          = 289;
    public static final int TRIM                             = 290;
    public static final int TRIM_ARRAY                       = 291;
    public static final int TRUE                             = 292;
    public static final int TRUNCATE                         = 293;
    public static final int UESCAPE                          = 294;
    public static final int UNDO                             = 295;
    public static final int UNION                            = 296;
    public static final int UNIQUE                           = 297;
    
    public static final int ASSUMEUNIQUE                     = 1303;    
    
    public static final int UNKNOWN                          = 298;
    public static final int UNNEST                           = 299;
    public static final int UNTIL                            = 300;
    public static final int UPDATE                           = 301;
    public static final int UPPER                            = 302;
    public static final int USER                             = 303;
    public static final int USING                            = 304;
    public static final int VALUE                            = 305;
    public static final int VALUES                           = 306;
    public static final int VAR_POP                          = 307;
    public static final int VAR_SAMP                         = 308;
    public static final int VARBINARY                        = 309;
    public static final int VARCHAR                          = 310;
    public static final int VARYING                          = 311;
    public static final int WHEN                             = 312;
    public static final int WHENEVER                         = 313;
    public static final int WHERE                            = 314;
    public static final int WIDTH_BUCKET                     = 315;
    public static final int WINDOW                           = 316;
    public static final int WITH                             = 317;
    public static final int WITHIN                           = 318;
    public static final int WITHOUT                          = 319;
    public static final int WHILE                            = 320;
    public static final int YEAR                             = 321;

    
    public static final int A                           = 330;
    public static final int ABSOLUTE                    = 331;
    public static final int ACTION                      = 332;
    public static final int ADA                         = 333;
    public static final int ADD                         = 334;
    public static final int ADMIN                       = 335;
    public static final int AFTER                       = 336;
    public static final int ALWAYS                      = 337;
    public static final int ASC                         = 338;
    public static final int ASSERTION                   = 339;
    public static final int ASSIGNMENT                  = 340;
    public static final int ATTRIBUTE                   = 341;
    public static final int ATTRIBUTES                  = 342;
    public static final int BEFORE                      = 343;
    public static final int BERNOULLI                   = 344;
    public static final int BREADTH                     = 345;
    public static final int C                           = 346;
    public static final int CASCADE                     = 347;
    public static final int CATALOG                     = 348;
    public static final int CATALOG_NAME                = 349;
    public static final int CHAIN                       = 350;
    public static final int CHARACTER_SET_CATALOG       = 351;
    public static final int CHARACTER_SET_NAME          = 352;
    public static final int CHARACTER_SET_SCHEMA        = 353;
    public static final int CHARACTERISTICS             = 354;
    public static final int CHARACTERS                  = 355;
    public static final int CLASS_ORIGIN                = 356;
    public static final int COBOL                       = 357;
    public static final int COLLATION                   = 358;
    public static final int COLLATION_CATALOG           = 359;
    public static final int COLLATION_NAME              = 360;
    public static final int COLLATION_SCHEMA            = 361;
    public static final int COLUMN_NAME                 = 362;
    public static final int COMMAND_FUNCTION            = 363;
    public static final int COMMAND_FUNCTION_CODE       = 364;
    public static final int COMMITTED                   = 365;
    public static final int CONDITION_IDENTIFIER        = 366;
    public static final int CONDITION_NUMBER            = 367;
    public static final int CONNECTION                  = 368;
    public static final int CONNECTION_NAME             = 369;
    public static final int CONSTRAINT_CATALOG          = 370;
    public static final int CONSTRAINT_NAME             = 371;
    public static final int CONSTRAINT_SCHEMA           = 372;
    public static final int CONSTRAINTS                 = 373;
    public static final int CONSTRUCTOR                 = 374;
    public static final int CONTAINS                    = 375;
    public static final int CONTINUE                    = 376;
    public static final int CURSOR_NAME                 = 377;
    public static final int DATA                        = 378;
    public static final int DATETIME_INTERVAL_CODE      = 379;
    public static final int DATETIME_INTERVAL_PRECISION = 380;
    public static final int DEFAULTS                    = 381;
    public static final int DEFERRABLE                  = 382;
    public static final int DEFERRED                    = 383;
    public static final int DEFINED                     = 384;
    public static final int DEFINER                     = 385;
    public static final int DEGREE                      = 386;
    public static final int DEPTH                       = 387;
    public static final int DERIVED                     = 388;
    public static final int DESC                        = 389;
    public static final int DESCRIPTOR                  = 390;
    public static final int DIAGNOSTICS                 = 391;
    public static final int DISPATCH                    = 392;
    public static final int DOMAIN                      = 393;
    public static final int DYNAMIC_FUNCTION            = 394;
    public static final int DYNAMIC_FUNCTION_CODE       = 395;
    public static final int EQUALS                      = 396;
    public static final int EXCEPTION                   = 397;
    public static final int EXCLUDE                     = 398;
    public static final int EXCLUDING                   = 399;
    public static final int FINAL                       = 400;
    public static final int FIRST                       = 401;
    public static final int FOLLOWING                   = 402;
    public static final int FORTRAN                     = 403;
    public static final int FOUND                       = 404;
    public static final int G                           = 405;
    public static final int GENERAL                     = 406;
    public static final int GENERATED                   = 407;
    public static final int GO                          = 408;
    public static final int GOTO                        = 409;
    public static final int GRANTED                     = 410;
    public static final int HIERARCHY                   = 411;
    public static final int IF                          = 412;
    public static final int IGNORE                      = 413;
    public static final int IMMEDIATE                   = 414;
    public static final int IMPLEMENTATION              = 415;
    public static final int INCLUDING                   = 416;
    public static final int INCREMENT                   = 417;
    public static final int INITIALLY                   = 418;
    public static final int INPUT                       = 419;
    public static final int INSTANCE                    = 420;
    public static final int INSTANTIABLE                = 421;
    public static final int INSTEAD                     = 422;
    public static final int INVOKER                     = 423;
    public static final int ISOLATION                   = 424;
    public static final int JAVA                        = 425;
    public static final int K                           = 426;
    public static final int KEY                         = 427;
    public static final int KEY_MEMBER                  = 428;
    public static final int KEY_TYPE                    = 429;
    public static final int LAST                        = 430;
    public static final int LENGTH                      = 431;
    public static final int LEVEL                       = 432;
    public static final int LOCATOR                     = 433;
    public static final int M                           = 434;
    public static final int MAP                         = 435;
    public static final int MATCHED                     = 436;
    public static final int MAXVALUE                    = 437;
    public static final int MESSAGE_LENGTH              = 438;
    public static final int MESSAGE_OCTET_LENGTH        = 439;
    public static final int MESSAGE_TEXT                = 440;
    public static final int MINVALUE                    = 441;
    public static final int MORE                        = 442;
    public static final int MUMPS                       = 443;
    public static final int NAME                        = 444;
    public static final int NAMES                       = 445;
    public static final int NESTING                     = 446;
    public static final int NEXT                        = 447;
    public static final int NORMALIZED                  = 448;
    public static final int NULLABLE                    = 449;
    public static final int NULLS                       = 450;
    public static final int NUMBER                      = 451;
    public static final int OBJECT                      = 452;
    public static final int OCTETS                      = 453;
    public static final int OPTION                      = 454;
    public static final int OPTIONS                     = 455;
    public static final int ORDERING                    = 456;
    public static final int ORDINALITY                  = 457;
    public static final int OTHERS                      = 458;
    public static final int OUTPUT                      = 459;
    public static final int OVERRIDING                  = 460;
    public static final int PAD                         = 461;
    public static final int PARAMETER_MODE              = 462;
    public static final int PARAMETER_NAME              = 463;
    public static final int PARAMETER_ORDINAL_POSITION  = 464;
    public static final int PARAMETER_SPECIFIC_CATALOG  = 465;
    public static final int PARAMETER_SPECIFIC_NAME     = 466;
    public static final int PARAMETER_SPECIFIC_SCHEMA   = 467;
    public static final int PARTIAL                     = 468;
    public static final int PASCAL                      = 469;
    public static final int PATH                        = 470;
    public static final int PLACING                     = 471;
    public static final int PLI                         = 472;
    public static final int PRECEDING                   = 473;
    public static final int PRESERVE                    = 474;
    public static final int PRIOR                       = 475;
    public static final int PRIVILEGES                  = 476;
    public static final int PUBLIC                      = 477;
    public static final int READ                        = 478;
    public static final int RELATIVE                    = 479;
    public static final int REPEATABLE                  = 480;
    public static final int RESPECT                     = 481;
    public static final int RESTART                     = 482;
    public static final int RESTRICT                    = 483;
    public static final int RETURNED_CARDINALITY        = 484;
    public static final int RETURNED_LENGTH             = 485;
    public static final int RETURNED_OCTET_LENGTH       = 486;
    public static final int RETURNED_SQLSTATE           = 487;
    public static final int ROLE                        = 488;
    public static final int ROUTINE                     = 489;
    public static final int ROUTINE_CATALOG             = 490;
    public static final int ROUTINE_NAME                = 491;
    public static final int ROUTINE_SCHEMA              = 492;
    public static final int ROW_COUNT                   = 493;
    public static final int SCALE                       = 494;
    public static final int SCHEMA                      = 495;
    public static final int SCHEMA_NAME                 = 496;
    public static final int SCOPE_CATALOG               = 497;
    public static final int SCOPE_NAME                  = 498;
    public static final int SCOPE_SCHEMA                = 499;
    public static final int SECTION                     = 500;
    public static final int SECURITY                    = 501;
    public static final int SELF                        = 502;
    public static final int SEQUENCE                    = 503;
    public static final int SERIALIZABLE                = 504;
    public static final int SERVER_NAME                 = 505;
    public static final int SESSION                     = 506;
    public static final int SETS                        = 507;
    public static final int SIMPLE                      = 508;
    public static final int SIZE                        = 509;
    public static final int SOURCE                      = 510;
    public static final int SPACE                       = 511;
    public static final int SPECIFIC_NAME               = 512;
    public static final int STATE                       = 513;
    public static final int STATEMENT                   = 514;
    public static final int STRUCTURE                   = 515;
    public static final int STYLE                       = 516;
    public static final int SUBCLASS_ORIGIN             = 517;
    public static final int TABLE_NAME                  = 518;
    public static final int TEMPORARY                   = 519;
    public static final int TIES                        = 520;
    public static final int TOP_LEVEL_COUNT             = 521;
    public static final int TRANSACTION                 = 522;
    public static final int TRANSACTION_ACTIVE          = 523;
    public static final int TRANSACTIONS_COMMITTED      = 524;
    public static final int TRANSACTIONS_ROLLED_BACK    = 525;
    public static final int TRANSFORM                   = 526;
    public static final int TRANSFORMS                  = 527;
    public static final int TRIGGER_CATALOG             = 528;
    public static final int TRIGGER_NAME                = 529;
    public static final int TRIGGER_SCHEMA              = 530;
    public static final int TYPE                        = 531;
    public static final int UNBOUNDED                   = 532;
    public static final int UNCOMMITTED                 = 533;
    public static final int UNDER                       = 534;
    public static final int UNNAMED                     = 535;
    public static final int USAGE                       = 536;
    public static final int USER_DEFINED_TYPE_CATALOG   = 537;
    public static final int USER_DEFINED_TYPE_CODE      = 538;
    public static final int USER_DEFINED_TYPE_NAME      = 539;
    public static final int USER_DEFINED_TYPE_SCHEMA    = 540;
    public static final int VIEW                        = 541;
    public static final int WORK                        = 542;
    public static final int WRITE                       = 543;
    public static final int ZONE                        = 544;

    
    public static final int P = 545;
    public static final int T = 546;

    
    static final int        ALIAS                 = 551;
    static final int        AUTOCOMMIT            = 552;
    static final int        BIT                   = 553;
    static final int        BIT_LENGTH            = 554;
    
    static final int        BYTES                 = 1010; 
    
    static final int        CACHED                = 555;
    static final int        CASEWHEN              = 556;
    static final int        CHECKPOINT            = 557;
    static final int        COMPACT               = 558;
    static final int        DATABASE              = 559;
    public static final int DAY_OF_WEEK           = 560;
    static final int        DEFRAG                = 561;
    static final int        EXPLAIN               = 562;
    static final int        HEADER                = 563;
    static final int        IGNORECASE            = 564;
    static final int        IFNULL                = 565;
    static final int        INDEX                 = 566;
    static final int        IMMEDIATELY           = 567;
    static final int        INITIAL               = 568;
    static final int        LIMIT                 = 569;
    static final int        LOGSIZE               = 570;
    static final int        MAXROWS               = 571;
    static final int        MEMORY                = 572;
    
    static final int        MICROS                = 1000; 
    static final int        MICROSECOND           = 1001; 
    
    static final int        MILLIS                = 573;
    
    static final int        MILLISECOND           = 1002; 
    
    static final int        MINUS_EXCEPT          = 574;
    static final int        NOW                   = 575;
    static final int        OFF                   = 576;
    static final int        PASSWORD              = 577;
    static final int        PLAN                  = 578;
    static final int        PROPERTY              = 579;
    static final int        READONLY              = 580;
    static final int        REFERENTIAL_INTEGRITY = 581;
    static final int        RENAME                = 582;
    static final int        SCRIPT                = 583;
    static final int        SCRIPTFORMAT          = 584;
    static final int        SEMICOLON             = 585;
    static final int        SHUTDOWN              = 586;
    static final int        TEMP                  = 587;
    static final int        TEXT                  = 588;
    static final int        TO_CHAR               = 589;
    static final int        TODAY                 = 590;
    static final int        TOP                   = 591;
    public static final int WEEK_OF_YEAR          = 592;
    static final int        WRITE_DELAY           = 593;
    static final int        COMPRESSED            = 594;
    static final int        EVENT                 = 595;
    static final int        BACKUP                = 596;
    static final int        BLOCKING              = 597;

    
    static final int        CURDATE                 = 598;
    static final int        CURTIME                 = 599;
    static final int        TIMESTAMPADD            = 600;
    static final int        TIMESTAMPDIFF           = 601;
    static final int        SYSDATE                 = 602;
    static final int        ISAUTOCOMMIT            = 603;
    static final int        ISREADONLYSESSION       = 604;
    static final int        ISREADONLYDATABASE      = 605;
    static final int        ISREADONLYDATABASEFILES = 606;
    public static final int DAY_NAME                = 607;
    public static final int MONTH_NAME              = 608;
    public static final int QUARTER                 = 609;
    public static final int DAY_OF_MONTH            = 610;
    public static final int DAY_OF_YEAR             = 611;
    static final int        DAYNAME                 = 612;
    static final int        NONTHNAME               = 613;
    static final int        DAYOFMONTH              = 614;
    static final int        DAYOFWEEK               = 615;
    static final int        DAYOFYEAR               = 616;
    
    public static final int WEEK                    = 617;
    
    
    static final int        OCTETLENGTH             = 618;
    static final int        BITLENGTH               = 619;

    
    static final int        ACOS             = 620;
    static final int        ASIN             = 621;
    static final int        ATAN             = 622;
    static final int        ATAN2            = 623;
    static final int        COS              = 624;
    static final int        COT              = 625;
    static final int        DEGREES          = 626;
    static final int        DMOD             = 627;
    static final int        LOG              = 628;
    static final int        LOG10            = 629;
    static final int        PI               = 630;
    static final int        RADIANS          = 631;
    static final int        RAND             = 632;
    static final int        ROUND            = 633;
    static final int        SIGN             = 634;
    static final int        SIN              = 635;
    static final int        TAN              = 636;
    static final int        BITAND           = 637;
    static final int        BITOR            = 638;
    static final int        BITXOR           = 639;
    static final int        ROUNDMAGIC       = 640;
    static final int        ASCII            = 641;
    static final int        CONCAT_WORD      = 642;
    static final int        DIFFERENCE       = 643;
    static final int        HEXTORAW         = 644;
    static final int        LCASE            = 645;
    static final int        LOCATE           = 646;
    static final int        LTRIM            = 647;
    static final int        RAWTOHEX         = 648;
    static final int        REPLACE          = 649;
    static final int        RTRIM            = 650;
    static final int        SOUNDEX          = 651;
    static final int        SPACE_WORD       = 652;
    static final int        SUBSTR           = 653;
    static final int        UCASE            = 654;
    static final int        DATEDIFF         = 655;
    public static final int SECONDS_MIDNIGHT = 656;

    
    static final int CONTROL = 657;
    static final int LOCK    = 658;
    static final int LOCKS   = 659;
    static final int MVCC    = 660;

    
    static final int        ASTERISK         = 661;
    static final int        CLOSEBRACKET     = 662;
    static final int        COLON            = 663;
    static final int        COMMA            = 664;
    static final int        CONCAT           = 665;
    static final int        DIVIDE           = 666;
    static final int        DOUBLE_COLON_OP  = 667;
    static final int        DOUBLE_PERIOD_OP = 668;
    static final int        DOUBLE_COLUMN_OP = 669;
    static final int        GREATER          = 670;
    static final int        GREATER_EQUALS   = 671;
    static final int        LESS             = 672;
    static final int        LESS_EQUALS      = 673;
    public static final int MINUS            = 674;
    static final int        NOT_EQUALS       = 675;
    static final int        OPENBRACKET      = 676;
    static final int        PLUS             = 677;
    static final int        QUESTION         = 678;
    static final int        RIGHT_ARROW_OP   = 679;
    static final int        DOUBLE_COLON     = 680;

    
    static final int SQL_TSI_FRAC_SECOND = 681;
    static final int SQL_TSI_SECOND      = 682;
    static final int SQL_TSI_MINUTE      = 683;
    static final int SQL_TSI_HOUR        = 684;
    static final int SQL_TSI_DAY         = 685;
    static final int SQL_TSI_WEEK        = 686;
    static final int SQL_TSI_MONTH       = 687;
    static final int SQL_TSI_QUARTER     = 688;
    static final int SQL_TSI_YEAR        = 689;

    
    static final int FILE  = 691;
    static final int FILES = 692;
    static final int CACHE = 693;
    static final int NIO = 694;

    
    static final int SQL_BIGINT        = 701;
    static final int SQL_BINARY        = 702;
    static final int SQL_BIT           = 703;
    static final int SQL_BLOB          = 704;
    static final int SQL_BOOLEAN       = 705;
    static final int SQL_CHAR          = 706;
    static final int SQL_CLOB          = 707;
    static final int SQL_DATE          = 708;
    static final int SQL_DECIMAL       = 709;
    static final int SQL_DATALINK      = 710;
    static final int SQL_DOUBLE        = 711;
    static final int SQL_FLOAT         = 712;
    static final int SQL_INTEGER       = 713;
    static final int SQL_LONGVARBINARY = 714;
    static final int SQL_LONGNVARCHAR  = 715;
    static final int SQL_LONGVARCHAR   = 716;
    static final int SQL_NCHAR         = 717;
    static final int SQL_NCLOB         = 718;
    static final int SQL_NUMERIC       = 719;
    static final int SQL_NVARCHAR      = 720;
    static final int SQL_REAL          = 721;
    static final int SQL_ROWID         = 722;
    static final int SQL_SQLXML        = 723;
    static final int SQL_SMALLINT      = 724;
    static final int SQL_TIME          = 725;
    static final int SQL_TIMESTAMP     = 726;
    static final int SQL_TINYINT       = 727;
    static final int SQL_VARBINARY     = 728;
    static final int SQL_VARCHAR       = 729;

    
    static final int X_KEYSET      = 730;
    static final int X_OPTION      = 731;
    static final int X_REPEAT      = 732;
    static final int X_POS_INTEGER = 733;

    
    public static final int X_VALUE                    = 734;
    public static final int X_IDENTIFIER               = 735;
    public static final int X_DELIMITED_IDENTIFIER     = 736;
    public static final int X_ENDPARSE                 = 737;
    public static final int X_STARTPARSE               = 738;
    public static final int X_REMARK                   = 739;
    public static final int X_NULL                     = 730;
    public static final int X_LOB_SIZE                 = 731;
    public static final int X_MALFORMED_STRING         = 732;
    public static final int X_MALFORMED_NUMERIC        = 733;
    public static final int X_MALFORMED_BIT_STRING     = 734;
    public static final int X_MALFORMED_BINARY_STRING  = 735;
    public static final int X_MALFORMED_UNICODE_STRING = 736;
    public static final int X_MALFORMED_COMMENT        = 737;
    public static final int X_MALFORMED_IDENTIFIER     = 738;
    public static final int X_MALFORMED_UNICODE_ESCAPE = 739;
    
    public static final int WEEKOFYEAR                 = 740; 
    public static final int WEEKDAY                    = 741; 
    

    
    public static final int X_UNKNOWN_TOKEN = -1;
    private static final IntValueHashMap reservedKeys =
        new IntValueHashMap(351);

    static {
        reservedKeys.put(Tokens.T_ABS, ABS);
        reservedKeys.put(Tokens.T_ALL, ALL);
        reservedKeys.put(Tokens.T_ALLOCATE, ALLOCATE);
        reservedKeys.put(Tokens.T_ALTER, ALTER);
        reservedKeys.put(Tokens.T_AND, AND);
        reservedKeys.put(Tokens.T_ANY, ANY);
        reservedKeys.put(Tokens.T_ARE, ARE);
        reservedKeys.put(Tokens.T_ARRAY, ARRAY);
        reservedKeys.put(Tokens.T_AS, AS);
        reservedKeys.put(Tokens.T_ASENSITIVE, ASENSITIVE);
        reservedKeys.put(Tokens.T_ASYMMETRIC, ASYMMETRIC);
        reservedKeys.put(Tokens.T_AT, AT);
        reservedKeys.put(Tokens.T_ATOMIC, ATOMIC);
        reservedKeys.put(Tokens.T_AUTHORIZATION, AUTHORIZATION);
        reservedKeys.put(Tokens.T_AVG, AVG);
        reservedKeys.put(Tokens.T_BEGIN, BEGIN);
        reservedKeys.put(Tokens.T_BETWEEN, BETWEEN);
        reservedKeys.put(Tokens.T_BIGINT, BIGINT);
        reservedKeys.put(Tokens.T_BINARY, BINARY);
        reservedKeys.put(Tokens.T_BIT_LENGTH, BIT_LENGTH);
        
        reservedKeys.put(Tokens.T_BYTES, BYTES); 
        
        reservedKeys.put(Tokens.T_BLOB, BLOB);
        reservedKeys.put(Tokens.T_BOOLEAN, BOOLEAN);
        reservedKeys.put(Tokens.T_BOTH, BOTH);
        reservedKeys.put(Tokens.T_BY, BY);
        reservedKeys.put(Tokens.T_CALL, CALL);
        reservedKeys.put(Tokens.T_CALLED, CALLED);
        reservedKeys.put(Tokens.T_CARDINALITY, CARDINALITY);
        reservedKeys.put(Tokens.T_CASCADED, CASCADED);
        reservedKeys.put(Tokens.T_CASE, CASE);
        reservedKeys.put(Tokens.T_CAST, CAST);
        reservedKeys.put(Tokens.T_CEIL, CEIL);
        reservedKeys.put(Tokens.T_CEILING, CEILING);
        reservedKeys.put(Tokens.T_CHAR, CHAR);
        reservedKeys.put(Tokens.T_CHAR_LENGTH, CHAR_LENGTH);
        reservedKeys.put(Tokens.T_CHARACTER, CHARACTER);
        reservedKeys.put(Tokens.T_CHARACTER_LENGTH, CHARACTER_LENGTH);
        reservedKeys.put(Tokens.T_CHECK, CHECK);
        reservedKeys.put(Tokens.T_CLOB, CLOB);
        reservedKeys.put(Tokens.T_CLOSE, CLOSE);
        reservedKeys.put(Tokens.T_COALESCE, COALESCE);
        reservedKeys.put(Tokens.T_COLLATE, COLLATE);
        reservedKeys.put(Tokens.T_COLLECT, COLLECT);
        reservedKeys.put(Tokens.T_COLUMN, COLUMN);
        reservedKeys.put(Tokens.T_COMMIT, COMMIT);
        reservedKeys.put(Tokens.T_COMPARABLE, COMPARABLE);
        
        reservedKeys.put(Tokens.T_CONCAT, CONCAT);
        
        reservedKeys.put(Tokens.T_CONDITION, CONDITION);
        reservedKeys.put(Tokens.T_CONNECT, CONNECT);
        reservedKeys.put(Tokens.T_CONSTRAINT, CONSTRAINT);
        reservedKeys.put(Tokens.T_CONVERT, CONVERT);
        reservedKeys.put(Tokens.T_CORR, CORR);
        reservedKeys.put(Tokens.T_CORRESPONDING, CORRESPONDING);
        reservedKeys.put(Tokens.T_COUNT, COUNT);
        
        reservedKeys.put(Tokens.T_APPROX_COUNT_DISTINCT, APPROX_COUNT_DISTINCT);
        
        reservedKeys.put(Tokens.T_COVAR_POP, COVAR_POP);
        reservedKeys.put(Tokens.T_COVAR_SAMP, COVAR_SAMP);
        reservedKeys.put(Tokens.T_CREATE, CREATE);
        reservedKeys.put(Tokens.T_CROSS, CROSS);
        reservedKeys.put(Tokens.T_CUBE, CUBE);
        reservedKeys.put(Tokens.T_CUME_DIST, CUME_DIST);
        reservedKeys.put(Tokens.T_CURRENT, CURRENT);
        reservedKeys.put(Tokens.T_CURRENT_CATALOG, CURRENT_CATALOG);
        reservedKeys.put(Tokens.T_CURRENT_DATE, CURRENT_DATE);
        reservedKeys.put(Tokens.T_CURRENT_DEFAULT_TRANSFORM_GROUP,
                         CURRENT_DEFAULT_TRANSFORM_GROUP);
        reservedKeys.put(Tokens.T_CURRENT_PATH, CURRENT_PATH);
        reservedKeys.put(Tokens.T_CURRENT_ROLE, CURRENT_ROLE);
        reservedKeys.put(Tokens.T_CURRENT_SCHEMA, CURRENT_SCHEMA);
        reservedKeys.put(Tokens.T_CURRENT_TIME, CURRENT_TIME);
        reservedKeys.put(Tokens.T_CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
        reservedKeys.put(Tokens.T_DO, DO);
        reservedKeys.put(Tokens.T_CURRENT_TRANSFORM_GROUP_FOR_TYPE,
                         CURRENT_TRANSFORM_GROUP_FOR_TYPE);
        reservedKeys.put(Tokens.T_CURRENT_USER, CURRENT_USER);
        reservedKeys.put(Tokens.T_CURSOR, CURSOR);
        reservedKeys.put(Tokens.T_CYCLE, CYCLE);
        reservedKeys.put(Tokens.T_DATE, DATE);
        reservedKeys.put(Tokens.T_DAY, DAY);
        reservedKeys.put(Tokens.T_DEALLOCATE, DEALLOCATE);
        reservedKeys.put(Tokens.T_DEC, DEC);
        reservedKeys.put(Tokens.T_DECIMAL, DECIMAL);
        reservedKeys.put(Tokens.T_DECLARE, DECLARE);
        reservedKeys.put(Tokens.T_DEFAULT, DEFAULT);
        reservedKeys.put(Tokens.T_DELETE, DELETE);
        reservedKeys.put(Tokens.T_DENSE_RANK, DENSE_RANK);
        reservedKeys.put(Tokens.T_DEREF, DEREF);
        reservedKeys.put(Tokens.T_DESCRIBE, DESCRIBE);
        reservedKeys.put(Tokens.T_DETERMINISTIC, DETERMINISTIC);
        reservedKeys.put(Tokens.T_DISCONNECT, DISCONNECT);
        reservedKeys.put(Tokens.T_DISTINCT, DISTINCT);
        reservedKeys.put(Tokens.T_DOUBLE, DOUBLE);
        reservedKeys.put(Tokens.T_DROP, DROP);
        reservedKeys.put(Tokens.T_DYNAMIC, DYNAMIC);
        reservedKeys.put(Tokens.T_EACH, EACH);
        reservedKeys.put(Tokens.T_ELEMENT, ELEMENT);
        reservedKeys.put(Tokens.T_ELSE, ELSE);
        reservedKeys.put(Tokens.T_ELSEIF, ELSEIF);
        reservedKeys.put(Tokens.T_END, END);
        reservedKeys.put(Tokens.T_END_EXEC, END_EXEC);
        reservedKeys.put(Tokens.T_ESCAPE, ESCAPE);
        reservedKeys.put(Tokens.T_EVERY, EVERY);
        reservedKeys.put(Tokens.T_EXCEPT, EXCEPT);
        reservedKeys.put(Tokens.T_EXEC, EXEC);
        reservedKeys.put(Tokens.T_EXECUTE, EXECUTE);
        reservedKeys.put(Tokens.T_EXISTS, EXISTS);
        reservedKeys.put(Tokens.T_EXIT, EXIT);
        reservedKeys.put(Tokens.T_EXP, EXP);
        reservedKeys.put(Tokens.T_EXTERNAL, EXTERNAL);
        reservedKeys.put(Tokens.T_EXTRACT, EXTRACT);
        reservedKeys.put(Tokens.T_FALSE, FALSE);
        reservedKeys.put(Tokens.T_FETCH, FETCH);
        reservedKeys.put(Tokens.T_FILTER, FILTER);
        reservedKeys.put(Tokens.T_FIRST_VALUE, FIRST_VALUE);
        reservedKeys.put(Tokens.T_FLOAT, FLOAT);
        reservedKeys.put(Tokens.T_FLOOR, FLOOR);
        reservedKeys.put(Tokens.T_FOR, FOR);
        reservedKeys.put(Tokens.T_FOREIGN, FOREIGN);
        reservedKeys.put(Tokens.T_FREE, FREE);
        reservedKeys.put(Tokens.T_FROM, FROM);
        reservedKeys.put(Tokens.T_FULL, FULL);
        reservedKeys.put(Tokens.T_FUNCTION, FUNCTION);
        reservedKeys.put(Tokens.T_FUSION, FUSION);
        reservedKeys.put(Tokens.T_GET, GET);
        reservedKeys.put(Tokens.T_GLOBAL, GLOBAL);
        reservedKeys.put(Tokens.T_GRANT, GRANT);
        reservedKeys.put(Tokens.T_GROUP, GROUP);
        reservedKeys.put(Tokens.T_GROUPING, GROUPING);
        reservedKeys.put(Tokens.T_HANDLER, HANDLER);
        reservedKeys.put(Tokens.T_HAVING, HAVING);
        reservedKeys.put(Tokens.T_HOLD, HOLD);
        reservedKeys.put(Tokens.T_HOUR, HOUR);
        reservedKeys.put(Tokens.T_IDENTITY, IDENTITY);
        reservedKeys.put(Tokens.T_IF, IF);
        reservedKeys.put(Tokens.T_IN, IN);
        reservedKeys.put(Tokens.T_INDICATOR, INDICATOR);
        reservedKeys.put(Tokens.T_INNER, INNER);
        reservedKeys.put(Tokens.T_INOUT, INOUT);
        reservedKeys.put(Tokens.T_INSENSITIVE, INSENSITIVE);
        reservedKeys.put(Tokens.T_INSERT, INSERT);
        reservedKeys.put(Tokens.T_INT, INT);
        reservedKeys.put(Tokens.T_INTEGER, INTEGER);
        reservedKeys.put(Tokens.T_INTERSECT, INTERSECT);
        reservedKeys.put(Tokens.T_INTERSECTION, INTERSECTION);
        reservedKeys.put(Tokens.T_INTERVAL, INTERVAL);
        reservedKeys.put(Tokens.T_INTO, INTO);
        reservedKeys.put(Tokens.T_IS, IS);
        reservedKeys.put(Tokens.T_ITERATE, ITERATE);
        reservedKeys.put(Tokens.T_JOIN, JOIN);
        reservedKeys.put(Tokens.T_LAG, LAG);
        reservedKeys.put(Tokens.T_LANGUAGE, LANGUAGE);
        reservedKeys.put(Tokens.T_LARGE, LARGE);
        reservedKeys.put(Tokens.T_LAST_VALUE, LAST_VALUE);
        reservedKeys.put(Tokens.T_LATERAL, LATERAL);
        reservedKeys.put(Tokens.T_LEAD, LEAD);
        reservedKeys.put(Tokens.T_LEADING, LEADING);
        reservedKeys.put(Tokens.T_LEAVE, LEAVE);
        reservedKeys.put(Tokens.T_LEFT, LEFT);
        reservedKeys.put(Tokens.T_LIKE, LIKE);
        reservedKeys.put(Tokens.T_LIKE_REGX, LIKE_REGEX);
        reservedKeys.put(Tokens.T_LN, LN);
        reservedKeys.put(Tokens.T_LOCAL, LOCAL);
        reservedKeys.put(Tokens.T_LOCALTIME, LOCALTIME);
        reservedKeys.put(Tokens.T_LOCALTIMESTAMP, LOCALTIMESTAMP);
        reservedKeys.put(Tokens.T_LOOP, LOOP);
        reservedKeys.put(Tokens.T_LOWER, LOWER);
        reservedKeys.put(Tokens.T_MATCH, MATCH);
        reservedKeys.put(Tokens.T_MAX, MAX);
        reservedKeys.put(Tokens.T_MAX_CARDINALITY, MAX_CARDINALITY);
        reservedKeys.put(Tokens.T_MEMBER, MEMBER);
        reservedKeys.put(Tokens.T_MERGE, MERGE);
        reservedKeys.put(Tokens.T_METHOD, METHOD);
        reservedKeys.put(Tokens.T_MIN, MIN);
        reservedKeys.put(Tokens.T_MINUTE, MINUTE);
        reservedKeys.put(Tokens.T_MOD, MOD);
        reservedKeys.put(Tokens.T_MODIFIES, MODIFIES);
        reservedKeys.put(Tokens.T_MODULE, MODULE);
        reservedKeys.put(Tokens.T_MONTH, MONTH);
        reservedKeys.put(Tokens.T_MULTISET, MULTISET);
        reservedKeys.put(Tokens.T_NATIONAL, NATIONAL);
        reservedKeys.put(Tokens.T_NATURAL, NATURAL);
        reservedKeys.put(Tokens.T_NCHAR, NCHAR);
        reservedKeys.put(Tokens.T_NCLOB, NCLOB);
        reservedKeys.put(Tokens.T_NEW, NEW);
        reservedKeys.put(Tokens.T_NO, NO);
        reservedKeys.put(Tokens.T_NONE, NONE);
        reservedKeys.put(Tokens.T_NORMALIZE, NORMALIZE);
        reservedKeys.put(Tokens.T_NOT, NOT);
        reservedKeys.put(Tokens.T_NTH_VALUE, NTH_VALUE);
        reservedKeys.put(Tokens.T_NTILE, NTILE);
        reservedKeys.put(Tokens.T_NULL, NULL);
        reservedKeys.put(Tokens.T_NULLIF, NULLIF);
        reservedKeys.put(Tokens.T_NUMERIC, NUMERIC);
        reservedKeys.put(Tokens.T_OCCURRENCES_REGEX, OCCURRENCES_REGEX);
        reservedKeys.put(Tokens.T_OCTET_LENGTH, OCTET_LENGTH);
        reservedKeys.put(Tokens.T_OF, OF);
        reservedKeys.put(Tokens.T_OFFSET, OFFSET);
        reservedKeys.put(Tokens.T_OLD, OLD);
        reservedKeys.put(Tokens.T_ON, ON);
        reservedKeys.put(Tokens.T_ONLY, ONLY);
        reservedKeys.put(Tokens.T_OPEN, OPEN);
        reservedKeys.put(Tokens.T_OR, OR);
        reservedKeys.put(Tokens.T_ORDER, ORDER);
        reservedKeys.put(Tokens.T_OUT, OUT);
        reservedKeys.put(Tokens.T_OUTER, OUTER);
        reservedKeys.put(Tokens.T_OVER, OVER);
        reservedKeys.put(Tokens.T_OVERLAPS, OVERLAPS);
        reservedKeys.put(Tokens.T_OVERLAY, OVERLAY);
        reservedKeys.put(Tokens.T_PARAMETER, PARAMETER);
        reservedKeys.put(Tokens.T_PARTITION, PARTITION);
        reservedKeys.put(Tokens.T_PERCENT_RANK, PERCENT_RANK);
        reservedKeys.put(Tokens.T_PERCENTILE_CONT, PERCENTILE_CONT);
        reservedKeys.put(Tokens.T_PERCENTILE_DISC, PERCENTILE_DISC);
        reservedKeys.put(Tokens.T_POSITION, POSITION);
        reservedKeys.put(Tokens.T_POSITION_REGEX, POSITION_REGEX);
        reservedKeys.put(Tokens.T_POWER, POWER);
        reservedKeys.put(Tokens.T_PRECISION, PRECISION);
        reservedKeys.put(Tokens.T_PREPARE, PREPARE);
        reservedKeys.put(Tokens.T_PRIMARY, PRIMARY);
        reservedKeys.put(Tokens.T_PROCEDURE, PROCEDURE);
        reservedKeys.put(Tokens.T_RANGE, RANGE);
        reservedKeys.put(Tokens.T_RANK, RANK);
        reservedKeys.put(Tokens.T_READS, READS);
        reservedKeys.put(Tokens.T_REAL, REAL);
        reservedKeys.put(Tokens.T_RECURSIVE, RECURSIVE);
        reservedKeys.put(Tokens.T_REF, REF);
        reservedKeys.put(Tokens.T_REFERENCES, REFERENCES);
        reservedKeys.put(Tokens.T_REFERENCING, REFERENCING);
        reservedKeys.put(Tokens.T_REGR_AVGX, REGR_AVGX);
        reservedKeys.put(Tokens.T_REGR_AVGY, REGR_AVGY);
        reservedKeys.put(Tokens.T_REGR_COUNT, REGR_COUNT);
        reservedKeys.put(Tokens.T_REGR_INTERCEPT, REGR_INTERCEPT);
        reservedKeys.put(Tokens.T_REGR_R2, REGR_R2);
        reservedKeys.put(Tokens.T_REGR_SLOPE, REGR_SLOPE);
        reservedKeys.put(Tokens.T_REGR_SXX, REGR_SXX);
        reservedKeys.put(Tokens.T_REGR_SXY, REGR_SXY);
        reservedKeys.put(Tokens.T_REGR_SYY, REGR_SYY);
        reservedKeys.put(Tokens.T_RELEASE, RELEASE);
        reservedKeys.put(Tokens.T_REPEAT, REPEAT);
        reservedKeys.put(Tokens.T_RESIGNAL, RESIGNAL);
        reservedKeys.put(Tokens.T_RETURN, RETURN);
        reservedKeys.put(Tokens.T_RETURNS, RETURNS);
        reservedKeys.put(Tokens.T_REVOKE, REVOKE);
        reservedKeys.put(Tokens.T_RIGHT, RIGHT);
        reservedKeys.put(Tokens.T_ROLLBACK, ROLLBACK);
        reservedKeys.put(Tokens.T_ROLLUP, ROLLUP);
        reservedKeys.put(Tokens.T_ROW, ROW);
        reservedKeys.put(Tokens.T_ROW_NUMBER, ROW_NUMBER);
        reservedKeys.put(Tokens.T_ROWS, ROWS);
        reservedKeys.put(Tokens.T_SAVEPOINT, SAVEPOINT);
        reservedKeys.put(Tokens.T_SCOPE, SCOPE);
        reservedKeys.put(Tokens.T_SCROLL, SCROLL);
        reservedKeys.put(Tokens.T_SEARCH, SEARCH);
        reservedKeys.put(Tokens.T_SECOND, SECOND);
        reservedKeys.put(Tokens.T_SELECT, SELECT);
        reservedKeys.put(Tokens.T_SENSITIVE, SENSITIVE);
        reservedKeys.put(Tokens.T_SESSION_USER, SESSION_USER);
        reservedKeys.put(Tokens.T_SET, SET);
        reservedKeys.put(Tokens.T_SIGNAL, SIGNAL);
        reservedKeys.put(Tokens.T_SIMILAR, SIMILAR);
        reservedKeys.put(Tokens.T_SMALLINT, SMALLINT);
        reservedKeys.put(Tokens.T_SOME, SOME);
        
        reservedKeys.put(Tokens.T_SPACE, SPACE);
        
        reservedKeys.put(Tokens.T_SPECIFIC, SPECIFIC);
        reservedKeys.put(Tokens.T_SPECIFICTYPE, SPECIFICTYPE);
        reservedKeys.put(Tokens.T_SQL, SQL);
        reservedKeys.put(Tokens.T_SQLEXCEPTION, SQLEXCEPTION);
        reservedKeys.put(Tokens.T_SQLSTATE, SQLSTATE);
        reservedKeys.put(Tokens.T_SQLWARNING, SQLWARNING);
        reservedKeys.put(Tokens.T_SQRT, SQRT);
        reservedKeys.put(Tokens.T_STACKED, STACKED);
        reservedKeys.put(Tokens.T_START, START);
        reservedKeys.put(Tokens.T_STATIC, STATIC);
        reservedKeys.put(Tokens.T_STDDEV_POP, STDDEV_POP);
        reservedKeys.put(Tokens.T_STDDEV_SAMP, STDDEV_SAMP);
        reservedKeys.put(Tokens.T_SUBMULTISET, SUBMULTISET);
        reservedKeys.put(Tokens.T_SUBSTRING, SUBSTRING);
        reservedKeys.put(Tokens.T_SUBSTRING_REGEX, SUBSTRING_REGEX);
        reservedKeys.put(Tokens.T_SUM, SUM);
        reservedKeys.put(Tokens.T_SYMMETRIC, SYMMETRIC);
        reservedKeys.put(Tokens.T_SYSTEM, SYSTEM);
        reservedKeys.put(Tokens.T_SYSTEM_USER, SYSTEM_USER);
        reservedKeys.put(Tokens.T_TABLE, TABLE);
        reservedKeys.put(Tokens.T_TABLESAMPLE, TABLESAMPLE);
        reservedKeys.put(Tokens.T_THEN, THEN);
        reservedKeys.put(Tokens.T_TIME, TIME);
        reservedKeys.put(Tokens.T_TIMESTAMP, TIMESTAMP);
        reservedKeys.put(Tokens.T_TIMEZONE_HOUR, TIMEZONE_HOUR);
        reservedKeys.put(Tokens.T_TIMEZONE_MINUTE, TIMEZONE_MINUTE);
        reservedKeys.put(Tokens.T_TO, TO);
        reservedKeys.put(Tokens.T_TRAILING, TRAILING);
        reservedKeys.put(Tokens.T_TRANSLATE, TRANSLATE);
        reservedKeys.put(Tokens.T_TRANSLATE_REGEX, TRANSLATE_REGEX);
        reservedKeys.put(Tokens.T_TRANSLATION, TRANSLATION);
        reservedKeys.put(Tokens.T_TREAT, TREAT);
        reservedKeys.put(Tokens.T_TRIGGER, TRIGGER);
        reservedKeys.put(Tokens.T_TRIM, TRIM);
        reservedKeys.put(Tokens.T_TRIM_ARRAY, TRIM_ARRAY);
        reservedKeys.put(Tokens.T_TRUE, TRUE);
        reservedKeys.put(Tokens.T_TRUNCATE, TRUNCATE);
        reservedKeys.put(Tokens.T_UESCAPE, UESCAPE);
        reservedKeys.put(Tokens.T_UNDO, UNDO);
        reservedKeys.put(Tokens.T_UNION, UNION);
        reservedKeys.put(Tokens.T_UNIQUE, UNIQUE);
        
        reservedKeys.put(Tokens.T_ASSUMEUNIQUE, ASSUMEUNIQUE);    
        
        reservedKeys.put(Tokens.T_UNKNOWN, UNKNOWN);
        reservedKeys.put(Tokens.T_UNNEST, UNNEST);
        reservedKeys.put(Tokens.T_UNTIL, UNTIL);
        reservedKeys.put(Tokens.T_UPDATE, UPDATE);
        reservedKeys.put(Tokens.T_UPPER, UPPER);
        reservedKeys.put(Tokens.T_USER, USER);
        reservedKeys.put(Tokens.T_USING, USING);
        reservedKeys.put(Tokens.T_VALUE, VALUE);
        reservedKeys.put(Tokens.T_VALUES, VALUES);
        reservedKeys.put(Tokens.T_VAR_POP, VAR_POP);
        reservedKeys.put(Tokens.T_VAR_SAMP, VAR_SAMP);
        reservedKeys.put(Tokens.T_VARBINARY, VARBINARY);
        reservedKeys.put(Tokens.T_VARCHAR, VARCHAR);
        reservedKeys.put(Tokens.T_VARYING, VARYING);
        reservedKeys.put(Tokens.T_WHEN, WHEN);
        reservedKeys.put(Tokens.T_WHENEVER, WHENEVER);
        reservedKeys.put(Tokens.T_WHERE, WHERE);
        reservedKeys.put(Tokens.T_WIDTH_BUCKET, WIDTH_BUCKET);
        reservedKeys.put(Tokens.T_WINDOW, WINDOW);
        reservedKeys.put(Tokens.T_WITH, WITH);
        reservedKeys.put(Tokens.T_WITHIN, WITHIN);
        reservedKeys.put(Tokens.T_WITHOUT, WITHOUT);
        reservedKeys.put(Tokens.T_WHILE, WHILE);
        reservedKeys.put(Tokens.T_YEAR, YEAR);
        
        reservedKeys.put(Tokens.T_WEEKOFYEAR, WEEKOFYEAR);    
        reservedKeys.put(Tokens.T_WEEKDAY, WEEKDAY);          
        
    }

    private static final IntValueHashMap commandSet = new IntValueHashMap(251);

    static {
        commandSet.put(T_IF, Tokens.IF);
        commandSet.put(T_IFNULL, Tokens.IFNULL);
        commandSet.put(T_NVL, Tokens.IFNULL);
        commandSet.put(T_CASEWHEN, Tokens.CASEWHEN);

        
        commandSet.put(T_ADD, ADD);
        commandSet.put(T_ADMIN, ADMIN);
        commandSet.put(T_ACTION, ACTION);
        commandSet.put(T_AFTER, AFTER);
        commandSet.put(T_ALIAS, ALIAS);
        commandSet.put(T_ALWAYS, ALWAYS);
        commandSet.put(T_ASC, ASC);
        commandSet.put(T_AUTOCOMMIT, AUTOCOMMIT);
        commandSet.put(T_BACKUP, BACKUP);
        commandSet.put(T_BEFORE, BEFORE);
        commandSet.put(T_BIT, BIT);
        commandSet.put(T_BLOCKING, BLOCKING);
        commandSet.put(T_CACHE, CACHE);
        commandSet.put(T_CACHED, CACHED);
        commandSet.put(T_CASCADE, CASCADE);
        commandSet.put(T_CATALOG, CATALOG);
        commandSet.put(T_CHARACTERISTICS, CHARACTERISTICS);
        commandSet.put(T_CHECKPOINT, CHECKPOINT);
        commandSet.put(T_COLLATE, COLLATE);
        commandSet.put(T_COLLATION, COLLATION);
        commandSet.put(T_COMMITTED, COMMITTED);
        commandSet.put(T_COMPACT, COMPACT);
        commandSet.put(T_COMPRESSED, COMPRESSED);
        commandSet.put(T_CONDITION_IDENTIFIER, Tokens.CONDITION_IDENTIFIER);
        commandSet.put(T_CONTAINS, CONTAINS);
        commandSet.put(T_CONTINUE, CONTINUE);
        commandSet.put(T_CONTROL, CONTROL);
        commandSet.put(T_CURDATE, CURDATE);
        commandSet.put(T_CURTIME, CURTIME);
        commandSet.put(T_DATA, DATA);
        commandSet.put(T_DATABASE, DATABASE);
        commandSet.put(T_DEFAULTS, DEFAULTS);
        commandSet.put(T_DEFRAG, DEFRAG);
        commandSet.put(T_DESC, DESC);
        commandSet.put(T_DOMAIN, DOMAIN);
        commandSet.put(T_EXCLUDING, EXCLUDING);
        commandSet.put(T_EXPLAIN, EXPLAIN);
        commandSet.put(T_EVENT, EVENT);
        commandSet.put(T_FILE, FILE);
        commandSet.put(T_FILES, FILES);
        commandSet.put(T_FINAL, FINAL);
        commandSet.put(T_FIRST, FIRST);
        commandSet.put(T_G_FACTOR, G);
        commandSet.put(T_GENERATED, GENERATED);
        commandSet.put(T_GRANTED, GRANTED);
        commandSet.put(T_HEADER, HEADER);
        commandSet.put(T_IGNORECASE, IGNORECASE);
        commandSet.put(T_IMMEDIATELY, IMMEDIATELY);
        commandSet.put(T_INCLUDING, INCLUDING);
        commandSet.put(T_INCREMENT, INCREMENT);
        commandSet.put(T_INDEX, INDEX);
        commandSet.put(T_INITIAL, INITIAL);
        commandSet.put(T_INPUT, INPUT);
        commandSet.put(T_INSTEAD, INSTEAD);
        commandSet.put(T_ISOLATION, ISOLATION);
        commandSet.put(T_ISAUTOCOMMIT, ISAUTOCOMMIT);
        commandSet.put(T_ISREADONLYDATABASE, ISREADONLYDATABASE);
        commandSet.put(T_ISREADONLYDATABASEFILES, ISREADONLYDATABASEFILES);
        commandSet.put(T_ISREADONLYSESSION, ISREADONLYSESSION);
        commandSet.put(T_JAVA, JAVA);
        commandSet.put(T_K_FACTOR, K);
        commandSet.put(T_KEY, KEY);
        commandSet.put(T_LAST, LAST);
        commandSet.put(T_LENGTH, LENGTH);
        commandSet.put(T_LEVEL, LEVEL);
        commandSet.put(T_LIMIT, LIMIT);
        commandSet.put(T_LOGSIZE, LOGSIZE);
        commandSet.put(T_LOCK, LOCK);
        commandSet.put(T_LOCKS, LOCKS);
        commandSet.put(T_M_FACTOR, M);
        commandSet.put(T_MATCHED, MATCHED);
        commandSet.put(T_MAXROWS, MAXROWS);
        commandSet.put(T_MAXVALUE, MAXVALUE);
        commandSet.put(T_MEMORY, MEMORY);
        
        commandSet.put(T_MICROS, MICROS);                
        commandSet.put(T_MICROSECOND, MICROSECOND);      
        
        commandSet.put(T_MILLIS, MILLIS);
        
        commandSet.put(T_MILLISECOND, MILLISECOND);      
        
        commandSet.put(T_MINUS_EXCEPT, MINUS_EXCEPT);
        commandSet.put(T_MINVALUE, MINVALUE);
        commandSet.put(T_MVCC, MVCC);
        commandSet.put(T_NAME, NAME);
        commandSet.put(T_NEXT, NEXT);
        commandSet.put(T_NIO, NIO);
        commandSet.put(T_NOW, NOW);
        commandSet.put(T_NULLS, NULLS);
        commandSet.put(T_OFF, OFF);
        commandSet.put(T_OPTION, OPTION);
        commandSet.put(T_OVERRIDING, OVERRIDING);
        commandSet.put(T_P_FACTOR, P);
        commandSet.put(T_PARTIAL, PARTIAL);
        commandSet.put(T_PASSWORD, PASSWORD);
        commandSet.put(T_PLACING, PLACING);
        commandSet.put(T_PLAN, PLAN);
        commandSet.put(T_PRESERVE, PRESERVE);
        commandSet.put(T_PRIVILEGES, PRIVILEGES);
        commandSet.put(T_PROPERTY, PROPERTY);
        commandSet.put(T_READ, READ);
        commandSet.put(T_READONLY, READONLY);
        commandSet.put(T_REFERENTIAL_INTEGRITY, REFERENTIAL_INTEGRITY);
        commandSet.put(T_RENAME, RENAME);
        commandSet.put(T_REPEATABLE, REPEATABLE);
        commandSet.put(T_RESTART, RESTART);
        commandSet.put(T_RESTRICT, RESTRICT);
        commandSet.put(T_ROLE, ROLE);
        commandSet.put(T_SCHEMA, SCHEMA);
        commandSet.put(T_SCRIPT, SCRIPT);
        commandSet.put(T_SCRIPTFORMAT, SCRIPTFORMAT);
        commandSet.put(T_SEQUENCE, SEQUENCE);
        commandSet.put(T_SESSION, SESSION);
        commandSet.put(T_SERIALIZABLE, SERIALIZABLE);
        commandSet.put(T_SHUTDOWN, SHUTDOWN);
        commandSet.put(T_SIMPLE, SIMPLE);
        commandSet.put(T_SIZE, SIZE);
        commandSet.put(T_SOURCE, SOURCE);
        commandSet.put(T_SQL_BIGINT, SQL_BIGINT);
        commandSet.put(T_SQL_BINARY, SQL_BINARY);
        commandSet.put(T_SQL_BIT, SQL_BIT);
        commandSet.put(T_SQL_BLOB, SQL_BLOB);
        commandSet.put(T_SQL_BOOLEAN, SQL_BOOLEAN);
        commandSet.put(T_SQL_CHAR, SQL_CHAR);
        commandSet.put(T_SQL_CLOB, SQL_CLOB);
        commandSet.put(T_SQL_DATE, SQL_DATE);
        commandSet.put(T_SQL_DECIMAL, SQL_DECIMAL);
        commandSet.put(T_SQL_DATALINK, SQL_DATALINK);
        commandSet.put(T_SQL_DOUBLE, SQL_DOUBLE);
        commandSet.put(T_SQL_FLOAT, SQL_FLOAT);
        commandSet.put(T_SQL_INTEGER, SQL_INTEGER);
        commandSet.put(T_SQL_LONGVARBINARY, SQL_LONGVARBINARY);
        commandSet.put(T_SQL_LONGNVARCHAR, SQL_LONGNVARCHAR);
        commandSet.put(T_SQL_LONGVARCHAR, SQL_LONGVARCHAR);
        commandSet.put(T_SQL_NCHAR, SQL_NCHAR);
        commandSet.put(T_SQL_NCLOB, SQL_NCLOB);
        commandSet.put(T_SQL_NUMERIC, SQL_NUMERIC);
        commandSet.put(T_SQL_NVARCHAR, SQL_NVARCHAR);
        commandSet.put(T_SQL_REAL, SQL_REAL);
        commandSet.put(T_SQL_ROWID, SQL_ROWID);
        commandSet.put(T_SQL_SQLXML, SQL_SQLXML);
        commandSet.put(T_SQL_SMALLINT, SQL_SMALLINT);
        commandSet.put(T_SQL_TIME, SQL_TIME);
        commandSet.put(T_SQL_TIMESTAMP, SQL_TIMESTAMP);
        commandSet.put(T_SQL_TINYINT, SQL_TINYINT);
        commandSet.put(T_SQL_VARBINARY, SQL_VARBINARY);
        commandSet.put(T_SQL_VARCHAR, SQL_VARCHAR);
        commandSet.put(T_SQL_TSI_FRAC_SECOND, SQL_TSI_FRAC_SECOND);
        commandSet.put(T_SQL_TSI_SECOND, SQL_TSI_SECOND);
        commandSet.put(T_SQL_TSI_MINUTE, SQL_TSI_MINUTE);
        commandSet.put(T_SQL_TSI_HOUR, SQL_TSI_HOUR);
        commandSet.put(T_SQL_TSI_DAY, SQL_TSI_DAY);
        commandSet.put(T_SQL_TSI_WEEK, SQL_TSI_WEEK);
        commandSet.put(T_SQL_TSI_MONTH, SQL_TSI_MONTH);
        commandSet.put(T_SQL_TSI_QUARTER, SQL_TSI_QUARTER);
        commandSet.put(T_SQL_TSI_YEAR, SQL_TSI_YEAR);
        commandSet.put(T_STYLE, STYLE);
        commandSet.put(T_T_FACTOR, T);
        commandSet.put(T_TEMP, TEMP);
        commandSet.put(T_TEMPORARY, TEMPORARY);
        commandSet.put(T_TEXT, TEXT);
        commandSet.put(T_TIMESTAMPADD, TIMESTAMPADD);
        commandSet.put(T_TIMESTAMPDIFF, TIMESTAMPDIFF);
        commandSet.put(T_TO_CHAR, TO_CHAR);
        commandSet.put(T_TODAY, TODAY);
        commandSet.put(T_TOP, TOP);
        commandSet.put(T_TRANSACTION, TRANSACTION);
        commandSet.put(T_TYPE, TYPE);
        commandSet.put(T_UNCOMMITTED, UNCOMMITTED);
        commandSet.put(T_USAGE, USAGE);
        commandSet.put(T_VIEW, VIEW);
        commandSet.put(T_WRITE, WRITE);
        commandSet.put(T_WRITE_DELAY, WRITE_DELAY);
        commandSet.put(T_WORK, WORK);
        commandSet.put(T_ZONE, ZONE);

        
        
        commandSet.put(T_DAYOFWEEK, DAYOFWEEK);
        commandSet.put(T_DAYOFYEAR, DAYOFYEAR);
        commandSet.put(T_WEEK, WEEK);
        commandSet.put(T_WEEKOFYEAR, WEEKOFYEAR);
        commandSet.put(T_WEEK_OF_YEAR, WEEK_OF_YEAR);
        commandSet.put(T_WEEKDAY, WEEKDAY);
        
        commandSet.put(T_DAY_NAME, DAY_NAME);
        commandSet.put(T_MONTH_NAME, MONTH_NAME);
        commandSet.put(T_QUARTER, QUARTER);
        commandSet.put(T_DAY_OF_WEEK, DAY_OF_WEEK);
        commandSet.put(T_DAY_OF_MONTH, DAY_OF_MONTH);
        commandSet.put(T_DAY_OF_YEAR, DAY_OF_YEAR);
        commandSet.put(T_DAYOFMONTH, DAYOFMONTH);
        commandSet.put(T_BITLENGTH, BITLENGTH);
        commandSet.put(T_OCTETLENGTH, OCTETLENGTH);
        commandSet.put(T_ACOS, ACOS);
        commandSet.put(T_ASIN, ASIN);
        commandSet.put(T_ATAN, ATAN);
        commandSet.put(T_ATAN2, ATAN2);
        commandSet.put(T_COS, COS);
        commandSet.put(T_COT, COT);
        commandSet.put(T_DEGREES, DEGREES);
        commandSet.put(T_DMOD, DMOD);
        commandSet.put(T_LOG, LOG);
        commandSet.put(T_LOG10, LOG10);
        commandSet.put(T_PI, PI);
        commandSet.put(T_RADIANS, RADIANS);
        commandSet.put(T_RAND, RAND);
        commandSet.put(T_ROUND, ROUND);
        commandSet.put(T_SIGN, SIGN);
        commandSet.put(T_SIN, SIN);
        commandSet.put(T_TAN, TAN);
        commandSet.put(T_BITAND, BITAND);
        commandSet.put(T_BITOR, BITOR);
        commandSet.put(T_BITXOR, BITXOR);
        commandSet.put(T_ROUNDMAGIC, ROUNDMAGIC);
        commandSet.put(T_ASCII, ASCII);
        commandSet.put(T_CONCAT_WORD, CONCAT_WORD);
        commandSet.put(T_DIFFERENCE, DIFFERENCE);
        commandSet.put(T_HEXTORAW, HEXTORAW);
        commandSet.put(T_LCASE, LCASE);
        commandSet.put(T_LOCATE, LOCATE);
        commandSet.put(T_LTRIM, LTRIM);
        commandSet.put(T_RAWTOHEX, RAWTOHEX);
        commandSet.put(T_REPLACE, REPLACE);
        commandSet.put(T_RTRIM, RTRIM);
        commandSet.put(T_SOUNDEX, SOUNDEX);
        commandSet.put(T_SPACE_WORD, SPACE_WORD);
        commandSet.put(T_SUBSTR, SUBSTR);
        commandSet.put(T_UCASE, UCASE);
        commandSet.put(T_DATEDIFF, DATEDIFF);
        commandSet.put(T_SECONDS_MIDNIGHT, SECONDS_MIDNIGHT);

        
        commandSet.put(T_COLON, Tokens.COLON);
        commandSet.put(T_COMMA, Tokens.COMMA);
        commandSet.put(T_SEMICOLON, SEMICOLON);
        commandSet.put(T_EQUALS, Tokens.EQUALS);
        commandSet.put(T_NOT_EQUALS_ALT, Tokens.NOT_EQUALS);
        commandSet.put(T_NOT_EQUALS, Tokens.NOT_EQUALS);
        commandSet.put(T_LESS, Tokens.LESS);
        commandSet.put(T_GREATER, Tokens.GREATER);
        commandSet.put(T_LESS_EQUALS, Tokens.LESS_EQUALS);
        commandSet.put(T_GREATER_EQUALS, Tokens.GREATER_EQUALS);
        commandSet.put(T_PLUS, Tokens.PLUS);
        commandSet.put(T_MINUS, Tokens.MINUS);
        commandSet.put(T_ASTERISK, Tokens.ASTERISK);
        commandSet.put(T_DIVIDE, Tokens.DIVIDE);
        commandSet.put(T_CONCAT, Tokens.CONCAT);
        commandSet.put(T_QUESTION, Tokens.QUESTION);
        commandSet.put(T_OPENBRACKET, OPENBRACKET);
        commandSet.put(T_CLOSEBRACKET, CLOSEBRACKET);
    }

    static int get(String token) {

        int type = reservedKeys.get(token, -1);

        if (type == -1) {
            return commandSet.get(token, -1);
        }

        return type;
    }

    public static boolean isCoreKeyword(int token) {
        return coreReservedWords.contains(token);
    }

    public static boolean isKeyword(String token) {
        return reservedKeys.containsKey(token);
    }

    public static int getKeywordID(String token, int defaultValue) {
        return reservedKeys.get(token, defaultValue);
    }

    public static int getNonKeywordID(String token, int defaultValue) {
        return commandSet.get(token, defaultValue);
    }

    public static String getKeyword(int token) {

        String key = (String) reservedKeys.getKey(token);

        if (key != null) {
            return key;
        }

        key = (String) commandSet.getKey(token);

        return key;
    }

    private static final OrderedIntHashSet coreReservedWords;

    static {

        
        
        coreReservedWords = new OrderedIntHashSet(128);

        short[] keyword = {
            ADMIN, AS, AND, ALL, ANY, AT, AVG, BY, BETWEEN, BOTH, CALL, CASE,
            CAST, CORRESPONDING, CONVERT, COUNT, COALESCE, CREATE, CROSS,
            DISTINCT, DROP, ELSE, END, EVERY, EXISTS, EXCEPT, FOR, FROM, FULL,
            GRANT, GROUP, HAVING, INTO, IS, IN, INTERSECT, JOIN, INNER, LEFT,
            LEADING, LIKE, MAX, MIN, NATURAL, NULLIF, NOT, ON, ORDER, OR,
            OUTER, PRIMARY, REFERENCES, RIGHT, SELECT, SET, SOME, STDDEV_POP,
            STDDEV_SAMP, SUM, TABLE, THEN, TO, TRAILING, TRIGGER, UNION,
            UNIQUE, USING, VALUES, VAR_POP, VAR_SAMP, WHEN, WHERE, WITH,
            
            ASSUMEUNIQUE, 
            
            
            APPROX_COUNT_DISTINCT,
            
        };

        for (int i = 0; i < keyword.length; i++) {
            coreReservedWords.add(keyword[i]);
        }
    }

    public static final short[] SQL_INTERVAL_FIELD_CODES = new short[] {
        Tokens.YEAR, Tokens.MONTH, Tokens.DAY, Tokens.HOUR, Tokens.MINUTE,
        Tokens.SECOND
    };
    public static final String[] SQL_INTERVAL_FIELD_NAMES = new String[] {
        Tokens.T_YEAR, Tokens.T_MONTH, Tokens.T_DAY, Tokens.T_HOUR,
        Tokens.T_MINUTE, Tokens.T_SECOND
    };
}

<code block>



package org.hsqldb_voltpatches;

import java.math.BigDecimal;
import java.math.BigInteger;

import org.hsqldb_voltpatches.lib.HashSet;
import org.hsqldb_voltpatches.store.ValuePool;
import org.hsqldb_voltpatches.types.DTIType;
import org.hsqldb_voltpatches.types.IntervalMonthData;
import org.hsqldb_voltpatches.types.IntervalSecondData;
import org.hsqldb_voltpatches.types.IntervalType;
import org.hsqldb_voltpatches.types.NumberType;
import org.hsqldb_voltpatches.types.Type;

import java.io.Serializable;


public class SetFunction implements Serializable {

    private HashSet distinctValues;
    private boolean isDistinct;

    
    private int  setType;
    private int  dataType;
    private Type type;

    
    private int count;

    
    private boolean    hasNull;
    private boolean    every = true;
    private boolean    some  = false;
    private long       currentLong;
    private double     currentDouble;
    private BigDecimal currentBigDecimal;
    private Object     currentValue;

    SetFunction(int setType, Type type, boolean isDistinct) {

        this.setType = setType;
        this.type    = type;

        if (isDistinct) {
            this.isDistinct = true;
            distinctValues  = new HashSet();
        }

        if (setType == OpTypes.VAR_SAMP || setType == OpTypes.STDDEV_SAMP) {
            this.sample = true;
        }

        if (type != null) {
            dataType = type.typeCode;

            if (type.isIntervalType()) {
                dataType = Types.SQL_INTERVAL;
            }
        }
    }

    void add(Session session, Object item) {

        if (item == null) {
            hasNull = true;

            session.addWarning(Error.error(ErrorCode.W_01003));

            return;
        }

        if (isDistinct && !distinctValues.add(item)) {
            return;
        }

        count++;

        switch (setType) {

            case OpTypes.COUNT :
                return;
            
            case OpTypes.APPROX_COUNT_DISTINCT:
                
                throw Error.error(ErrorCode.X_42581, Tokens.T_APPROX_COUNT_DISTINCT);
            
            case OpTypes.AVG :
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        currentLong += ((Number) item).intValue();

                        return;

                    case Types.SQL_INTERVAL :
                        if (item instanceof IntervalSecondData) {
                            addLong(((IntervalSecondData) item).units);

                            currentLong += ((IntervalSecondData) item).nanos;

                            if (Math.abs(currentLong)
                                    >= DTIType.nanoScaleFactors[0]) {
                                addLong(currentLong
                                        / DTIType.nanoScaleFactors[0]);

                                currentLong %= DTIType.nanoScaleFactors[0];
                            }
                        } else if (item instanceof IntervalMonthData) {
                            addLong(((IntervalMonthData) item).units);
                        }

                        return;

                    case Types.SQL_BIGINT :
                        addLong(((Number) item).longValue());

                        return;

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        currentDouble += ((Number) item).doubleValue();

                        return;

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        if (currentBigDecimal == null) {
                            currentBigDecimal = (BigDecimal) item;
                        } else {
                            currentBigDecimal =
                                currentBigDecimal.add((BigDecimal) item);
                        }

                        return;

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.MIN : {
                if (currentValue == null) {
                    currentValue = item;

                    return;
                }

                if (type.compare(currentValue, item) > 0) {
                    currentValue = item;
                }

                return;
            }
            case OpTypes.MAX : {
                if (currentValue == null) {
                    currentValue = item;

                    return;
                }

                if (type.compare(currentValue, item) < 0) {
                    currentValue = item;
                }

                return;
            }
            case OpTypes.EVERY :
                if (!(item instanceof Boolean)) {
                    throw Error.error(ErrorCode.X_42565);
                }

                every = every && ((Boolean) item).booleanValue();

                return;

            case OpTypes.SOME :
                if (!(item instanceof Boolean)) {
                    throw Error.error(ErrorCode.X_42565);
                }

                some = some || ((Boolean) item).booleanValue();

                return;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                addDataPoint((Number) item);

                return;

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }
    }

    Object getValue() {

        if (setType == OpTypes.COUNT) {
            return ValuePool.getInt(count);
        }

        
        if (setType == OpTypes.APPROX_COUNT_DISTINCT) {
            throw Error.error(ErrorCode.X_42581, Tokens.T_APPROX_COUNT_DISTINCT);
        }
        
        if (count == 0) {
            return null;
        }

        switch (setType) {

            case OpTypes.AVG : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return new Long(currentLong / count);

                    case Types.SQL_BIGINT : {
                        long value = getLongSum().divide(
                            BigInteger.valueOf(count)).longValue();

                        return new Long(value);
                    }
                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return new Double(currentDouble / count);

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return currentBigDecimal.divide(new BigDecimal(count),
                                                        BigDecimal.ROUND_DOWN);

                    case Types.SQL_INTERVAL : {
                        BigInteger bi =
                            getLongSum().divide(BigInteger.valueOf(count));

                        if (!NumberType.isInLongLimits(bi)) {
                            throw Error.error(ErrorCode.X_22015);
                        }

                        if (((IntervalType) type).isDaySecondIntervalType()) {
                            return new IntervalSecondData(bi.longValue(),
                                                          currentLong,
                                                          (IntervalType) type,
                                                          true);
                        } else {
                            return IntervalMonthData.newIntervalMonth(
                                bi.longValue(), (IntervalType) type);
                        }
                    }
                    default :
                        throw Error.runtimeError(ErrorCode.U_S0500,
                                                 "SetFunction");
                }
            }
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return new Long(currentLong);

                    case Types.SQL_BIGINT :
                        return new BigDecimal(getLongSum());

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return new Double(currentDouble);

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return currentBigDecimal;

                    case Types.SQL_INTERVAL : {
                        BigInteger bi = getLongSum();

                        if (!NumberType.isInLongLimits(bi)) {
                            throw Error.error(ErrorCode.X_22015);
                        }

                        if (((IntervalType) type).isDaySecondIntervalType()) {
                            return new IntervalSecondData(bi.longValue(),
                                                          currentLong,
                                                          (IntervalType) type,
                                                          true);
                        } else {
                            return IntervalMonthData.newIntervalMonth(
                                bi.longValue(), (IntervalType) type);
                        }
                    }
                    default :
                        throw Error.runtimeError(ErrorCode.U_S0500,
                                                 "SetFunction");
                }
            }
            case OpTypes.MIN :
            case OpTypes.MAX :
                return currentValue;

            case OpTypes.EVERY :
                return every ? Boolean.TRUE
                             : Boolean.FALSE;

            case OpTypes.SOME :
                return some ? Boolean.TRUE
                            : Boolean.FALSE;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
                return getStdDev();

            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                return getVariance();

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }
    }

    
    static Type getType(int setType, Type type) {

        if (setType == OpTypes.COUNT) {
            return Type.SQL_INTEGER;
        }

        
        
        
        
        
        
        if (type == null) {
            throw Error.error(ErrorCode.U_S0500);
        }
        
        int dataType = type.isIntervalType() ? Types.SQL_INTERVAL
                                             : type.typeCode;

        switch (setType) {

            case OpTypes.AVG : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                    case Types.SQL_BIGINT :
                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                    case Types.SQL_INTERVAL :
                        return type;

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return Type.SQL_BIGINT;

                    case Types.SQL_BIGINT :
                        return Type.SQL_DECIMAL_BIGINT_SQR;

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return Type.SQL_DOUBLE;

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return Type.getType(type.typeCode, 0,
                                            type.precision * 2, type.scale);

                    case Types.SQL_INTERVAL :
                        return IntervalType.newIntervalType(
                            type.typeCode, DTIType.maxIntervalPrecision,
                            type.scale);

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.MIN :
            case OpTypes.MAX :
                return type;

            case OpTypes.EVERY :
            case OpTypes.SOME :
                if (type.isBooleanType()) {
                    return Type.SQL_BOOLEAN;
                }
                break;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                if (type.isNumberType()) {
                    return Type.SQL_DOUBLE;
                }
                break;

            
            case OpTypes.APPROX_COUNT_DISTINCT :
                switch (dataType) {
                case Types.TINYINT :
                case Types.SQL_SMALLINT :
                case Types.SQL_INTEGER :
                case Types.SQL_BIGINT :
                case Types.SQL_DECIMAL :
                case Types.SQL_TIMESTAMP :
                    return Type.SQL_DOUBLE;
                default:
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    throw Error.error(ErrorCode.X_42565);
                }
            
            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }

        throw Error.error(ErrorCode.X_42565);
    }

    

    
    static final BigInteger multiplier =
        BigInteger.valueOf(0x0000000100000000L);


    long hi;
    long lo;

    void addLong(long value) {

        if (value == 0) {}
        else if (value > 0) {
            hi += value >> 32;
            lo += value & 0x00000000ffffffffL;
        } else {
            if (value == Long.MIN_VALUE) {
                hi -= 0x000000080000000L;
            } else {
                long temp = ~value + 1;

                hi -= temp >> 32;
                lo -= temp & 0x00000000ffffffffL;
            }
        }


    }

    BigInteger getLongSum() {

        BigInteger biglo  = BigInteger.valueOf(lo);
        BigInteger bighi  = BigInteger.valueOf(hi);
        BigInteger result = (bighi.multiply(multiplier)).add(biglo);


        return result;
    }

    
    
    
    private double  sk;
    private double  vk;
    private long    n;
    private boolean initialized;
    private boolean sample;

    private void addDataPoint(Number x) {    

        double xi;
        double xsi;
        long   nm1;

        if (x == null) {
            return;
        }

        xi = x.doubleValue();

        if (!initialized) {
            n           = 1;
            sk          = xi;
            vk          = 0.0;
            initialized = true;

            return;
        }

        n++;

        nm1 = (n - 1);
        xsi = (sk - (xi * nm1));
        vk  += ((xsi * xsi) / n) / nm1;
        sk  += xi;
    }

    private Number getVariance() {

        if (!initialized) {
            return null;
        }

        return sample ? (n == 1) ? null    
                                 : new Double(vk / (double) (n - 1))
                      : new Double(vk / (double) (n));
    }

    private Number getStdDev() {

        if (!initialized) {
            return null;
        }

        return sample ? (n == 1) ? null    
                                 : new Double(Math.sqrt(vk / (double) (n - 1)))
                      : new Double(Math.sqrt(vk / (double) (n)));
    }

    
}

<code block>


package org.voltdb.planner;

import java.net.URL;
import java.util.List;

import junit.framework.TestCase;

import org.apache.commons.lang3.StringUtils;
import org.voltdb.catalog.Database;
import org.voltdb.compiler.DeterminismMode;
import org.voltdb.plannodes.AbstractPlanNode;
import org.voltdb.types.PlanNodeType;

public class PlannerTestCase extends TestCase {

    private PlannerTestAideDeCamp m_aide;
    private boolean m_byDefaultInferPartitioning = true;
    private boolean m_byDefaultPlanForSinglePartition;

    
    private int countQuestionMarks(String sql) {
        int paramCount = 0;
        int skip = 0;
        while (true) {
            
            skip = sql.indexOf('?', skip);
            if (skip == -1) {
                break;
            }
            skip++;
            paramCount++;
        }
        return paramCount;
    }

    protected void failToCompile(String sql, String... patterns)
    {
        int paramCount = countQuestionMarks(sql);
        try {
            m_aide.compile(sql, paramCount,
                    m_byDefaultInferPartitioning, m_byDefaultPlanForSinglePartition, null);
            fail("Expected planner failure, but found success.");
        }
        catch (Exception ex) {
            String result = ex.toString();
            for (String pattern : patterns) {
                if ( ! result.contains(pattern)) {
                    fail("Did not find pattern '" + pattern + "' in error string '" + result + "'");
                }
            }
        }
    }

    protected CompiledPlan compileAdHocPlan(String sql) {
        return compileAdHocPlan(sql, DeterminismMode.SAFER);
    }

    protected CompiledPlan compileAdHocPlan(String sql, DeterminismMode detMode) {
        CompiledPlan cp = null;
        try {
            cp = m_aide.compileAdHocPlan(sql, detMode);
            assertTrue(cp != null);
        }
        catch (Exception ex) {
            ex.printStackTrace();
            fail();
        }
        return cp;
    }

    final int paramCount = 0;
    String noJoinOrder = null;
    
    protected List<AbstractPlanNode> compileToFragments(String sql)
    {
        boolean planForSinglePartitionFalse = false;
        return compileWithJoinOrderToFragments(sql, planForSinglePartitionFalse, noJoinOrder);
    }

    protected List<AbstractPlanNode> compileToFragmentsForSinglePartition(String sql)
    {
        boolean planForSinglePartitionFalse = false;
        return compileWithJoinOrderToFragments(sql, planForSinglePartitionFalse, noJoinOrder);
    }


    
    protected List<AbstractPlanNode> compileWithJoinOrderToFragments(String sql, String joinOrder)
    {
        boolean planForSinglePartitionFalse = false;
        return compileWithJoinOrderToFragments(sql, planForSinglePartitionFalse, joinOrder);
    }

    
    private List<AbstractPlanNode> compileWithJoinOrderToFragments(String sql,
                                                                   boolean planForSinglePartition,
                                                                   String joinOrder)
    {
        
        int paramCount = StringUtils.countMatches(sql, "?");
        return compileWithJoinOrderToFragments(sql, paramCount, planForSinglePartition, joinOrder);
    }

    
    private List<AbstractPlanNode> compileWithJoinOrderToFragments(String sql, int paramCount,
                                                                   boolean planForSinglePartition,
                                                                   String joinOrder)
    {
        List<AbstractPlanNode> pn = m_aide.compile(sql, paramCount, m_byDefaultInferPartitioning, m_byDefaultPlanForSinglePartition, joinOrder);
        assertTrue(pn != null);
        assertFalse(pn.isEmpty());
        assertTrue(pn.get(0) != null);
        if (planForSinglePartition) {
            assertTrue(pn.size() == 1);
        }
        return pn;
    }

    protected AbstractPlanNode compileSPWithJoinOrder(String sql, String joinOrder)
    {
        try {
            return compileWithCountedParamsAndJoinOrder(sql, joinOrder);
        }
        catch (Exception ex) {
            ex.printStackTrace();
            fail();
            return null;
        }
    }

    protected void compileWithInvalidJoinOrder(String sql, String joinOrder) throws Exception
    {
        compileWithJoinOrderToFragments(sql, paramCount, m_byDefaultPlanForSinglePartition, joinOrder);
    }


    private AbstractPlanNode compileWithCountedParamsAndJoinOrder(String sql, String joinOrder) throws Exception
    {
        
        int paramCount = StringUtils.countMatches(sql, "?");
        return compileSPWithJoinOrder(sql, paramCount, joinOrder);
    }

    
    protected AbstractPlanNode compile(String sql)
    {
        
        int paramCount = StringUtils.countMatches(sql, "?");
        return compileSPWithJoinOrder(sql, paramCount, null);
    }

    
    protected AbstractPlanNode compileForSinglePartition(String sql)
    {
        
        int paramCount = StringUtils.countMatches(sql, "?");
        boolean m_infer = m_byDefaultInferPartitioning;
        boolean m_forceSP = m_byDefaultInferPartitioning;
        m_byDefaultInferPartitioning = false;
        m_byDefaultPlanForSinglePartition = true;

        AbstractPlanNode pn = compileSPWithJoinOrder(sql, paramCount, null);
        m_byDefaultInferPartitioning = m_infer;
        m_byDefaultPlanForSinglePartition = m_forceSP;
        return pn;
    }

    
    protected AbstractPlanNode compileSPWithJoinOrder(String sql, int paramCount, String joinOrder)
    {
        List<AbstractPlanNode> pns = null;
        try {
            pns = compileWithJoinOrderToFragments(sql, paramCount, m_byDefaultPlanForSinglePartition, joinOrder);
        }
        catch (Exception ex) {
            ex.printStackTrace();
            fail(ex.getMessage());
        }
        assertTrue(pns.get(0) != null);
        return pns.get(0);
    }

    
    protected static List<AbstractPlanNode> findAllAggPlanNodes(AbstractPlanNode fragment) {
        List<AbstractPlanNode> aggNodes = fragment.findAllNodesOfType(PlanNodeType.AGGREGATE);
        List<AbstractPlanNode> hashAggNodes = fragment.findAllNodesOfType(PlanNodeType.HASHAGGREGATE);
        List<AbstractPlanNode> partialAggNodes = fragment.findAllNodesOfType(PlanNodeType.PARTIALAGGREGATE);

        aggNodes.addAll(hashAggNodes);
        aggNodes.addAll(partialAggNodes);
        return aggNodes;
    }


    protected void setupSchema(URL ddlURL, String basename,
                               boolean planForSinglePartition) throws Exception
    {
        m_aide = new PlannerTestAideDeCamp(ddlURL, basename);
        m_byDefaultPlanForSinglePartition = planForSinglePartition;
    }

    protected void setupSchema(boolean inferPartitioning, URL ddlURL, String basename) throws Exception
    {
        m_byDefaultInferPartitioning = inferPartitioning;
        m_aide = new PlannerTestAideDeCamp(ddlURL, basename);
    }


    Database getDatabase() {
        return m_aide.getDatabase();
    }

    protected void printExplainPlan(List<AbstractPlanNode> planNodes) {
        for (AbstractPlanNode apn: planNodes) {
            System.out.println(apn.toExplainPlanString());
        }
    }

    protected String buildExplainPlan(List<AbstractPlanNode> planNodes) {
        String explain = "";
        for (AbstractPlanNode apn: planNodes) {
            explain += apn.toExplainPlanString() + '\n';
        }
        return explain;
    }

    protected void checkQueriesPlansAreTheSame(String sql1, String sql2) {
        String explainStr1, explainStr2;
        List<AbstractPlanNode> pns = compileToFragments(sql1);
        explainStr1 = buildExplainPlan(pns);
        pns = compileToFragments(sql2);
        explainStr2 = buildExplainPlan(pns);

        assertEquals(explainStr1, explainStr2);
    }

    
    static protected void assertClassesMatchNodeChain(
            List<Class<? extends AbstractPlanNode>> expectedClasses,
            AbstractPlanNode actualPlan) {
        AbstractPlanNode pn = actualPlan;
        for (Class<? extends AbstractPlanNode> c : expectedClasses) {
            assertFalse("Actual plan shorter than expected",
                    pn == null);
            assertTrue("Expected plan to contain an instance of " + c.getSimpleName() +", "
                    + "instead found " + pn.getClass().getSimpleName(),
                    c.isInstance(pn));
            if (pn.getChildCount() > 0)
                pn = pn.getChild(0);
            else
                pn = null;
        }

        assertTrue("Actual plan longer than expected", pn == null);
    }
}

<code block>


package org.voltdb.planner;

import java.util.List;

import org.voltdb.plannodes.AbstractPlanNode;
import org.voltdb.plannodes.AggregatePlanNode;
import org.voltdb.types.ExpressionType;
import static org.voltdb.types.ExpressionType.*;


public class TestPlansApproxCountDistinct extends PlannerTestCase {

    private static final int COORDINATOR_FRAG = 0;
    private static final int PARTITION_FRAG = 1;

    @Override
    protected void setUp() throws Exception {
        setupSchema(getClass().getResource("testplans-count-ddl.sql"),
                    "testcount", false);
    }

    @Override
    protected void tearDown() throws Exception {
        super.tearDown();
    }

    private void assertAggPlanNodeContainsFunctions(AggregatePlanNode node, ExpressionType[] expectedAggFns) {
        List<ExpressionType> actualAggFns = node.getAggregateTypes();

        assertEquals("Wrong number of aggregate functions in plan", expectedAggFns.length, actualAggFns.size());

        int i = 0;
        for (ExpressionType expectedAggFn : expectedAggFns) {
            assertEquals("Found unexpected agg function", expectedAggFn, actualAggFns.get(i));
            ++i;
        }
    }

    private void assertFragContainsAggWithFunctions(AbstractPlanNode frag, ExpressionType... expectedAggFns) {
        List<AbstractPlanNode> aggNodes = findAllAggPlanNodes(frag);
        assertFalse("No aggregation node in fragment!", 0 == aggNodes.size());
        assertEquals("More than one aggregation node in fragment!", 1, aggNodes.size());

        AggregatePlanNode aggNode = (AggregatePlanNode)aggNodes.get(0);
        assertAggPlanNodeContainsFunctions(aggNode, expectedAggFns);
    }

    private void assertFragContainsTwoAggsWithFunctions(AbstractPlanNode frag,
            ExpressionType[] expectedAggFnsFirst,
            ExpressionType[] expectedAggFnsSecond) {
        List<AbstractPlanNode> aggNodes = findAllAggPlanNodes(frag);
        assertEquals("Wrong number of aggregation nodes in fragment!", 2, aggNodes.size());

        assertAggPlanNodeContainsFunctions((AggregatePlanNode)aggNodes.get(0), expectedAggFnsFirst);
        assertAggPlanNodeContainsFunctions((AggregatePlanNode)aggNodes.get(1), expectedAggFnsSecond);
    }

    private void assertFragContainsNoAggPlanNodes(AbstractPlanNode node) {
        List<AbstractPlanNode> aggNodes = findAllAggPlanNodes(node);
        assertEquals("Found an aggregation node in fragment, but didn't expect to!", 0, aggNodes.size());
    }

    public void testSinglePartitionTableAgg() throws Exception {
        List<AbstractPlanNode> pn = compileToFragments("SELECT approx_count_distinct(age) from T1");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG), AGGREGATE_APPROX_COUNT_DISTINCT);

        pn = compileToFragments("select approx_count_distinct(age), sum(points) from t1");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_SUM);

        pn = compileToFragments("select approx_count_distinct(age), sum(distinct points) from t1");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_SUM);

    }

    public void testSinglePartitionWithGroupBy() throws Exception {
        List<AbstractPlanNode> pn = compileToFragments(
                "SELECT id, approx_count_distinct(age) "
                + "from T1 "
                + "group by id");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG), AGGREGATE_APPROX_COUNT_DISTINCT);

        pn = compileToFragments(
                "select age, approx_count_distinct(points), max(username) "
                + "from t2 "
                + "group by age");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_MAX);

        pn = compileToFragments(
                "select username, approx_count_distinct(age), avg(distinct points) "
                + "from t2 "
                + "group by username");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_AVG);
    }

    public void testMultiPartitionTableAgg() throws Exception {
        List<AbstractPlanNode> pn = compileToFragments("SELECT approx_count_distinct(num) from P1");
        assertEquals(2,  pn.size());

        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG), AGGREGATE_HYPERLOGLOGS_TO_CARD);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG), AGGREGATE_VALS_TO_HYPERLOGLOG);

        
        pn = compileToFragments("SELECT approx_count_distinct(num), count(ratio) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        pn = compileToFragments("SELECT approx_count_distinct(num), min(desc), max(ratio) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_MIN, AGGREGATE_MAX);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_MIN, AGGREGATE_MAX);

        
        pn = compileToFragments("SELECT approx_count_distinct(num), count(distinct id) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        
        pn = compileToFragments("SELECT approx_count_distinct(id), count(distinct id) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        pn = compileToFragments("SELECT sum(distinct ratio), approx_count_distinct(num) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_SUM,
                AGGREGATE_APPROX_COUNT_DISTINCT);
        assertFragContainsNoAggPlanNodes(pn.get(PARTITION_FRAG));
    }

    public void testMultiPartitionWithGroupBy() throws Exception {
        List<AbstractPlanNode> pn = compileToFragments(
                "SELECT desc as modid, approx_count_distinct(num) "
                + "from P1 "
                + "group by desc");
        assertEquals(2,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG), AGGREGATE_HYPERLOGLOGS_TO_CARD);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG), AGGREGATE_VALS_TO_HYPERLOGLOG);

        
        pn = compileToFragments("SELECT desc, approx_count_distinct(num), count(ratio) "
                + "from P1 "
                + "group by desc");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        pn = compileToFragments(
                "SELECT desc, approx_count_distinct(num), max(ratio) "
                + "from P1 "
                + "group by desc");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_MAX);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_MAX);

        
        pn = compileToFragments(
                "SELECT ratio, approx_count_distinct(num), count(distinct id) "
                + "from P1 "
                + "group by ratio");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        
        pn = compileToFragments(
                "SELECT desc, approx_count_distinct(id), count(distinct id) "
                + "from P1 "
                + "group by desc");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        
        
        pn = compileToFragments(
                "SELECT id, sum(distinct ratio), approx_count_distinct(num) "
                + "from P1 "
                + "group by id");
        assertFragContainsNoAggPlanNodes(pn.get(COORDINATOR_FRAG));
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_SUM,
                AGGREGATE_APPROX_COUNT_DISTINCT);
    }

    public void testWithSubqueries() throws Exception {

        
        List<AbstractPlanNode> pn = compileToFragments(
                "select * "
                + "from "
                + "  T1, "
                + "  (select approx_count_distinct(age) from t1) as subq");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT);

        
        pn = compileToFragments(
                "select * "
                + "from "
                + "  (select username, approx_count_distinct(age), avg(distinct points) "
                + "   from t2 "
                + "   group by username) as subq"
                + "  inner join t2 "
                + "  on t2.username = subq.username;");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_AVG);

        
        pn = compileToFragments(
                "select * "
                + "from "
                + "t1, "
                + "(SELECT sum(distinct ratio), approx_count_distinct(num) from P1) as subq");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_SUM,
                AGGREGATE_APPROX_COUNT_DISTINCT);
        assertFragContainsNoAggPlanNodes(pn.get(PARTITION_FRAG));

        
        pn = compileToFragments(
                "select * "
                + "from p1 "
                + "inner join "
                + "(SELECT id, sum(distinct ratio), approx_count_distinct(num) "
                + "from P1 "
                + "where id = 10 "
                + "group by id) as subq "
                + "on subq.id = p1.id");
        assertEquals(1, pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_SUM,
                AGGREGATE_APPROX_COUNT_DISTINCT);

        
        pn = compileToFragments(
                "select * "
                + "from t1 "
                + "inner join "
                + "(SELECT id, approx_count_distinct(num) "
                + "from P1 "
                + "group by id) as subq "
                + "on subq.id = t1.id");
        for (AbstractPlanNode n : pn) {
            System.out.println(n.toExplainPlanString());
        }
        assertEquals(2, pn.size());
        assertFragContainsNoAggPlanNodes(pn.get(COORDINATOR_FRAG));
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT);
    }

    public void testSubqueriesWithMultipleAggs() throws Exception {
        List<AbstractPlanNode> pn;

        
        
        pn = compileToFragments("select approx_count_distinct(num) "
                + "from (select approx_count_distinct(points) from t1) as repl_subquery,"
                + "  p1");
        assertEquals(2, pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD);
        assertFragContainsTwoAggsWithFunctions(pn.get(PARTITION_FRAG),
                new ExpressionType[] {AGGREGATE_APPROX_COUNT_DISTINCT},
                new ExpressionType[] {AGGREGATE_VALS_TO_HYPERLOGLOG});

        
        
        pn = compileToFragments("select approx_count_distinct(num), sum(distinct num) "
                + "from (select approx_count_distinct(points) from t1) as repl_subquery,"
                + "  p1");
        assertEquals(2, pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT);

        
        pn = compileToFragments("select approx_count_distinct(points) "
                + "from (select approx_count_distinct(num) from p1) as repl_subquery,"
                + "  t1");
        assertEquals(2, pn.size());
        assertFragContainsTwoAggsWithFunctions(pn.get(COORDINATOR_FRAG),
                new ExpressionType[] {AGGREGATE_HYPERLOGLOGS_TO_CARD},
                new ExpressionType[] {AGGREGATE_APPROX_COUNT_DISTINCT});
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG);

        
        
        pn = compileToFragments("select approx_count_distinct(points) "
                + "from (select approx_count_distinct(num), sum(distinct num) from p1) as repl_subquery,"
                + "  t1");
        assertEquals(2, pn.size());
        assertFragContainsTwoAggsWithFunctions(pn.get(COORDINATOR_FRAG),
                new ExpressionType[] {AGGREGATE_APPROX_COUNT_DISTINCT, AGGREGATE_SUM},
                new ExpressionType[] {AGGREGATE_APPROX_COUNT_DISTINCT});
        assertFragContainsNoAggPlanNodes(pn.get(PARTITION_FRAG));
    }
}

<code block>



package org.hsqldb_voltpatches;


import java.lang.reflect.Field;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Vector;


import java.math.BigDecimal;
import org.hsqldb_voltpatches.types.BinaryData;
import org.hsqldb_voltpatches.types.TimestampData;
import org.hsqldb_voltpatches.types.NumberType;
import org.hsqldb_voltpatches.HSQLInterface.HSQLParseException;


import org.hsqldb_voltpatches.HsqlNameManager.SimpleName;
import org.hsqldb_voltpatches.ParserDQL.CompileContext;
import org.hsqldb_voltpatches.lib.ArrayListIdentity;
import org.hsqldb_voltpatches.lib.HsqlArrayList;
import org.hsqldb_voltpatches.lib.HsqlList;
import org.hsqldb_voltpatches.lib.OrderedHashSet;
import org.hsqldb_voltpatches.lib.OrderedIntHashSet;
import org.hsqldb_voltpatches.lib.Set;
import org.hsqldb_voltpatches.persist.PersistentStore;
import org.hsqldb_voltpatches.types.CharacterType;
import org.hsqldb_voltpatches.types.NullType;
import org.hsqldb_voltpatches.types.Type;


public class Expression {

    public static final int LEFT   = 0;
    public static final int RIGHT  = 1;
    public static final int UNARY  = 1;
    public static final int BINARY = 2;

    
    
    static final Expression[] emptyExpressionArray = new Expression[]{};

    
    static final Expression EXPR_TRUE  = new ExpressionLogical(true);
    static final Expression EXPR_FALSE = new ExpressionLogical(false);

    
    static final OrderedIntHashSet aggregateFunctionSet =
        new OrderedIntHashSet();

    static {
        aggregateFunctionSet.add(OpTypes.COUNT);
        
        aggregateFunctionSet.add(OpTypes.APPROX_COUNT_DISTINCT);
        
        aggregateFunctionSet.add(OpTypes.SUM);
        aggregateFunctionSet.add(OpTypes.MIN);
        aggregateFunctionSet.add(OpTypes.MAX);
        aggregateFunctionSet.add(OpTypes.AVG);
        aggregateFunctionSet.add(OpTypes.EVERY);
        aggregateFunctionSet.add(OpTypes.SOME);
        aggregateFunctionSet.add(OpTypes.STDDEV_POP);
        aggregateFunctionSet.add(OpTypes.STDDEV_SAMP);
        aggregateFunctionSet.add(OpTypes.VAR_POP);
        aggregateFunctionSet.add(OpTypes.VAR_SAMP);
    }

    static final OrderedIntHashSet columnExpressionSet =
        new OrderedIntHashSet();

    static {
        columnExpressionSet.add(OpTypes.COLUMN);
    }

    static final OrderedIntHashSet subqueryExpressionSet =
        new OrderedIntHashSet();

    static {
        subqueryExpressionSet.add(OpTypes.ROW_SUBQUERY);
        subqueryExpressionSet.add(OpTypes.TABLE_SUBQUERY);
    }

    static final OrderedIntHashSet subqueryAggregateExpressionSet =
        new OrderedIntHashSet();

    static {
        subqueryAggregateExpressionSet.add(OpTypes.COUNT);
        
        subqueryAggregateExpressionSet.add(OpTypes.APPROX_COUNT_DISTINCT);
        
        subqueryAggregateExpressionSet.add(OpTypes.SUM);
        subqueryAggregateExpressionSet.add(OpTypes.MIN);
        subqueryAggregateExpressionSet.add(OpTypes.MAX);
        subqueryAggregateExpressionSet.add(OpTypes.AVG);
        subqueryAggregateExpressionSet.add(OpTypes.EVERY);
        subqueryAggregateExpressionSet.add(OpTypes.SOME);
        subqueryAggregateExpressionSet.add(OpTypes.STDDEV_POP);
        subqueryAggregateExpressionSet.add(OpTypes.STDDEV_SAMP);
        subqueryAggregateExpressionSet.add(OpTypes.VAR_POP);
        subqueryAggregateExpressionSet.add(OpTypes.VAR_SAMP);

        
        subqueryAggregateExpressionSet.add(OpTypes.TABLE_SUBQUERY);
        subqueryAggregateExpressionSet.add(OpTypes.ROW_SUBQUERY);
    }

    static final OrderedIntHashSet emptyExpressionSet =
        new OrderedIntHashSet();

    
    protected int opType;

    
    protected int exprSubType;

    
    SimpleName alias;

    
    protected boolean isAggregate;

    
    protected Object       valueData;
    protected Expression[] nodes;
    Type[]                 nodeDataTypes;

    
    SubQuery subQuery;

    
    boolean isCorrelated;

    
    int columnIndex = -1;

    
    protected Type dataType;

    
    int     queryTableColumnIndex = -1;    
    boolean isParam;

    
    int parameterIndex = -1;

    
    int rangePosition = -1;

    
    boolean isColumnEqual;

    Expression(int type) {
        opType = type;
        nodes  = emptyExpressionArray;
    }

    

    
    Expression(int exprType, SubQuery sq) {

        this(OpTypes.TABLE_SUBQUERY);

        subQuery = sq;
    }

    
    Expression(int type, Expression[] list) {

        this(type);

        this.nodes = list;
    }

    public String describe(Session session) {
        return describe(session, 0);
    }

    static String getContextSQL(Expression expression) {

        if (expression == null) {
            return null;
        }

        String ddl = expression.getSQL();

        switch (expression.opType) {

            case OpTypes.VALUE :
            case OpTypes.COLUMN :
            case OpTypes.ROW :
            case OpTypes.FUNCTION :
            case OpTypes.SQL_FUNCTION :
            case OpTypes.ALTERNATIVE :
            case OpTypes.CASEWHEN :
            case OpTypes.CAST :
                return ddl;
        }

        StringBuffer sb = new StringBuffer();

        ddl = sb.append('(').append(ddl).append(')').toString();

        return ddl;
    }

    
    public String getSQL() {

        StringBuffer sb = new StringBuffer(64);

        switch (opType) {

            case OpTypes.VALUE :
                if (valueData == null) {
                    return Tokens.T_NULL;
                }

                return dataType.convertToSQLString(valueData);

            case OpTypes.ROW :
                sb.append('(');

                for (int i = 0; i < nodes.length; i++) {
                    sb.append(nodes[i].getSQL());

                    if (i < nodes.length - 1) {
                        sb.append(',');
                    }
                }

                sb.append(')');

                return sb.toString();

            
            case OpTypes.TABLE :
                for (int i = 0; i < nodes.length; i++) {
                    sb.append(nodes[i].getSQL());

                    if (i < nodes.length - 1) {
                        sb.append(',');
                    }
                }

                return sb.toString();
        }

        switch (opType) {

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY :

                break;

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "Expression");
        }

        return sb.toString();
    }

    protected String describe(Session session, int blanks) {

        StringBuffer sb = new StringBuffer(64);

        sb.append('\n');

        for (int i = 0; i < blanks; i++) {
            sb.append(' ');
        }

        switch (opType) {

            case OpTypes.VALUE :
                sb.append("VALUE = ").append(valueData);
                sb.append(", TYPE = ").append(dataType.getNameString());

                return sb.toString();

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY :
                sb.append("QUERY ");
                sb.append(subQuery.queryExpression.describe(session));

                return sb.toString();

            case OpTypes.ROW :
                sb.append("ROW = ");

                for (int i = 0; i < nodes.length; i++) {
                    sb.append(nodes[i].describe(session, blanks + 1));
                }

                sb.append("), TYPE = ").append(dataType.getNameString());
                break;

            case OpTypes.TABLE :
                sb.append("VALUELIST ");

                for (int i = 0; i < nodes.length; i++) {
                    sb.append(nodes[i].describe(session, blanks + 1));
                    sb.append(' ');
                }
                break;
        }

        if (nodes[LEFT] != null) {
            sb.append(" arg1=[");
            sb.append(nodes[LEFT].describe(session, blanks + 1));
            sb.append(']');
        }

        if (nodes[RIGHT] != null) {
            sb.append(" arg2=[");
            sb.append(nodes[RIGHT].describe(session, blanks + 1));
            sb.append(']');
        }

        return sb.toString();
    }

    
    void setDataType(Session session, Type type) {

        if (opType == OpTypes.VALUE) {
            valueData = type.convertToType(session, valueData, dataType);
        }

        dataType = type;
    }

    public boolean equals(Expression other) {

        if (other == this) {
            return true;
        }

        if (other == null) {
            return false;
        }

        if (opType != other.opType || exprSubType != other.exprSubType
                || !equals(dataType, other.dataType)) {
            return false;
        }

        switch (opType) {

            case OpTypes.SIMPLE_COLUMN :
                return this.columnIndex == other.columnIndex;

            case OpTypes.VALUE :
                return equals(valueData, other.valueData);

            default :
                return equals(nodes, other.nodes)
                       && equals(subQuery, other.subQuery);
        }
    }

    public boolean equals(Object other) {

        if (other == this) {
            return true;
        }

        if (other instanceof Expression) {
            return equals((Expression) other);
        }

        return false;
    }

    public int hashCode() {

        int val = opType + exprSubType;

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                val += nodes[i].hashCode();
            }
        }

        return val;
    }

    static boolean equals(Object o1, Object o2) {

        if (o1 == o2) {
            return true;
        }

        return (o1 == null) ? o2 == null
                            : o1.equals(o2);
    }

    static boolean equals(Expression[] row1, Expression[] row2) {

        if (row1 == row2) {
            return true;
        }

        if (row1.length != row2.length) {
            return false;
        }

        int len = row1.length;

        for (int i = 0; i < len; i++) {
            Expression e1     = row1[i];
            Expression e2     = row2[i];
            boolean    equals = (e1 == null) ? e2 == null
                                             : e1.equals(e2);

            if (!equals) {
                return false;
            }
        }

        return true;
    }

    boolean isComposedOf(Expression exprList[], int start, int end,
                         OrderedIntHashSet excludeSet) {

        if (opType == OpTypes.VALUE) {
            return true;
        }

        if (excludeSet.contains(opType)) {
            return true;
        }

        for (int i = start; i < end; i++) {
            if (equals(exprList[i])) {
                return true;
            }
        }

        switch (opType) {

            case OpTypes.LIKE :
            case OpTypes.MATCH_SIMPLE :
            case OpTypes.MATCH_PARTIAL :
            case OpTypes.MATCH_FULL :
            case OpTypes.MATCH_UNIQUE_SIMPLE :
            case OpTypes.MATCH_UNIQUE_PARTIAL :
            case OpTypes.MATCH_UNIQUE_FULL :
            case OpTypes.UNIQUE :
            case OpTypes.EXISTS :
            case OpTypes.TABLE_SUBQUERY :
            case OpTypes.ROW_SUBQUERY :

            
            case OpTypes.COUNT :
            
            case OpTypes.APPROX_COUNT_DISTINCT:
            
            case OpTypes.SUM :
            case OpTypes.MIN :
            case OpTypes.MAX :
            case OpTypes.AVG :
            case OpTypes.EVERY :
            case OpTypes.SOME :
            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                return false;
        }

        if (nodes.length == 0) {
            return false;
        }

        boolean result = true;

        for (int i = 0; i < nodes.length; i++) {
            result &= (nodes[i] == null
                       || nodes[i].isComposedOf(exprList, start, end,
                                                excludeSet));
        }

        return result;
    }

    boolean isComposedOf(OrderedHashSet expressions,
                         OrderedIntHashSet excludeSet) {

        
        if (opType == OpTypes.VALUE || opType == OpTypes.DYNAMIC_PARAM
                || opType == OpTypes.PARAMETER || opType == OpTypes.VARIABLE) {
            return true;
        }
        

        if (excludeSet.contains(opType)) {
            return true;
        }

        for (int i = 0; i < expressions.size(); i++) {
            if (equals(expressions.get(i))) {
                return true;
            }
        }

        switch (opType) {

            case OpTypes.COUNT :
            
            case OpTypes.APPROX_COUNT_DISTINCT:
            
            case OpTypes.SUM :
            case OpTypes.MIN :
            case OpTypes.MAX :
            case OpTypes.AVG :
            case OpTypes.EVERY :
            case OpTypes.SOME :
            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                return false;
        }


        if (nodes.length == 0) {
            return false;
        }

        boolean result = true;

        for (int i = 0; i < nodes.length; i++) {
            result &= (nodes[i] == null
                       || nodes[i].isComposedOf(expressions, excludeSet));
        }

        return result;
    }

    Expression replace(OrderedHashSet expressions,
                       OrderedHashSet replacements) {

        if (opType == OpTypes.VALUE) {
            return this;
        }

        int index = expressions.getIndex(this);

        if (index != -1) {
            return (Expression) replacements.get(index);
        }

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            nodes[i] = nodes[i].replace(expressions, replacements);
        }

        return this;
    }

    Expression replaceColumnReferences(RangeVariable range,
                                       Expression[] list) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            nodes[i] = nodes[i].replaceColumnReferences(range, list);
        }

        return this;
    }

    void convertToSimpleColumn(OrderedHashSet expressions,
                               OrderedHashSet replacements) {

        if (opType == OpTypes.VALUE) {
            return;
        }

        int index = expressions.getIndex(this);

        if (index != -1) {
            Expression e = (Expression) replacements.get(index);

            nodes         = emptyExpressionArray;
            opType        = OpTypes.SIMPLE_COLUMN;
            columnIndex   = e.columnIndex;
            rangePosition = e.rangePosition;

            return;
        }

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            nodes[i].convertToSimpleColumn(expressions, replacements);
        }
    }

    boolean isSelfAggregate() {
        return false;
    }

    
    void setAlias(SimpleName name) {
        alias = name;
    }

    
    String getAlias() {

        if (alias != null) {
            return alias.name;
        }

        return "";
    }

    SimpleName getSimpleName() {

        if (alias != null) {
            return alias;
        }

        return null;
    }

    
    public int getType() {
        return opType;
    }

    
    Expression getLeftNode() {
        return nodes.length > 0 ? nodes[LEFT]
                                : null;
    }

    
    Expression getRightNode() {
        return nodes.length > 1 ? nodes[RIGHT]
                                : null;
    }

    void setLeftNode(Expression e) {
        nodes[LEFT] = e;
    }

    void setRightNode(Expression e) {
        nodes[RIGHT] = e;
    }

    
    RangeVariable getRangeVariable() {
        return null;
    }

    
    Expression replaceAliasInOrderBy(Expression[] columns, int length) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            nodes[i] = nodes[i].replaceAliasInOrderBy(columns, length);
        }

        return this;
    }

    
    int findMatchingRangeVariableIndex(RangeVariable[] rangeVarArray) {
        return -1;
    }

    
    void collectRangeVariables(RangeVariable[] rangeVariables, Set set) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                nodes[i].collectRangeVariables(rangeVariables, set);
            }
        }

        if (subQuery != null && subQuery.queryExpression != null) {
            HsqlList unresolvedExpressions =
                subQuery.queryExpression.getUnresolvedExpressions();

            if (unresolvedExpressions != null) {
                for (int i = 0; i < unresolvedExpressions.size(); i++) {
                    Expression e = (Expression) unresolvedExpressions.get(i);

                    e.collectRangeVariables(rangeVariables, set);
                }
            }
        }
    }

    
    void collectObjectNames(Set set) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                nodes[i].collectObjectNames(set);
            }
        }

        if (subQuery != null) {
            if (subQuery.queryExpression != null) {
                subQuery.queryExpression.collectObjectNames(set);
            }
        }
    }

    
    boolean hasReference(RangeVariable range) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                if (nodes[i].hasReference(range)) {
                    return true;
                }
            }
        }

        if (subQuery != null && subQuery.queryExpression != null) {
            if (subQuery.queryExpression.hasReference(range)) {
                return true;
            }
        }

        return false;
    }

    
    public HsqlList resolveColumnReferences(RangeVariable[] rangeVarArray,
            HsqlList unresolvedSet) {
        return resolveColumnReferences(rangeVarArray, rangeVarArray.length,
                                       unresolvedSet, true);
    }

    public HsqlList resolveColumnReferences(RangeVariable[] rangeVarArray,
            int rangeCount, HsqlList unresolvedSet, boolean acceptsSequences) {

        if (opType == OpTypes.VALUE) {
            return unresolvedSet;
        }

        switch (opType) {

            case OpTypes.CASEWHEN :
                acceptsSequences = false;
                break;

            case OpTypes.TABLE : {
                HsqlList localSet = null;

                for (int i = 0; i < nodes.length; i++) {
                    if (nodes[i] == null) {
                        continue;
                    }

                    localSet = nodes[i].resolveColumnReferences(
                        RangeVariable.emptyArray, localSet);
                }

                if (localSet != null) {
                    isCorrelated = true;

                    if (subQuery != null) {
                        subQuery.setCorrelated();
                    }

                    for (int i = 0; i < localSet.size(); i++) {
                        Expression e = (Expression) localSet.get(i);

                        unresolvedSet =
                            e.resolveColumnReferences(rangeVarArray,
                                                      unresolvedSet);
                    }

                    unresolvedSet = Expression.resolveColumnSet(rangeVarArray,
                            localSet, unresolvedSet);
                }

                return unresolvedSet;
            }
        }

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            unresolvedSet = nodes[i].resolveColumnReferences(rangeVarArray,
                    rangeCount, unresolvedSet, acceptsSequences);
        }

        switch (opType) {

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY : {
                QueryExpression queryExpression = subQuery.queryExpression;

                if (!queryExpression.areColumnsResolved()) {
                    isCorrelated = true;

                    subQuery.setCorrelated();

                    
                    if (unresolvedSet == null) {
                        unresolvedSet = new ArrayListIdentity();
                    }

                    unresolvedSet.addAll(
                        queryExpression.getUnresolvedExpressions());
                }

                break;
            }
            default :
        }

        return unresolvedSet;
    }

    public OrderedHashSet getUnkeyedColumns(OrderedHashSet unresolvedSet) {

        if (opType == OpTypes.VALUE) {
            return unresolvedSet;
        }

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] == null) {
                continue;
            }

            unresolvedSet = nodes[i].getUnkeyedColumns(unresolvedSet);
        }

        switch (opType) {

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY :
                if (subQuery != null) {
                    if (unresolvedSet == null) {
                        unresolvedSet = new OrderedHashSet();
                    }

                    unresolvedSet.add(this);
                }
                break;
        }

        return unresolvedSet;
    }

    public void resolveTypes(Session session, Expression parent) {

        for (int i = 0; i < nodes.length; i++) {
            if (nodes[i] != null) {
                nodes[i].resolveTypes(session, this);
            }
        }

        switch (opType) {

            case OpTypes.VALUE :
                break;

            case OpTypes.TABLE :

                
                break;

            case OpTypes.ROW :
                nodeDataTypes = new Type[nodes.length];

                for (int i = 0; i < nodes.length; i++) {
                    if (nodes[i] != null) {
                        nodeDataTypes[i] = nodes[i].dataType;
                    }
                }
                break;

            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY : {
                QueryExpression queryExpression = subQuery.queryExpression;

                queryExpression.resolveTypes(session);
                subQuery.prepareTable(session);

                nodeDataTypes = queryExpression.getColumnTypes();
                dataType      = nodeDataTypes[0];

                break;
            }
            default :
                throw Error.runtimeError(ErrorCode.U_S0500,
                                         "Expression.resolveTypes()");
        }
    }

    void setAsConstantValue(Session session) {

        valueData = getConstantValue(session);
        opType    = OpTypes.VALUE;
        nodes     = emptyExpressionArray;
    }

    void setAsConstantValue(Object value) {

        valueData = value;
        opType    = OpTypes.VALUE;
        nodes     = emptyExpressionArray;
    }

    void prepareTable(Session session, Expression row, int degree) {

        if (nodeDataTypes != null) {
            return;
        }

        for (int i = 0; i < nodes.length; i++) {
            Expression e = nodes[i];

            if (e.opType == OpTypes.ROW) {
                if (degree != e.nodes.length) {
                    throw Error.error(ErrorCode.X_42564);
                }
            } else if (degree == 1) {
                nodes[i]       = new Expression(OpTypes.ROW);
                nodes[i].nodes = new Expression[]{ e };
            } else {
                throw Error.error(ErrorCode.X_42564);
            }
        }

        nodeDataTypes = new Type[degree];

        for (int j = 0; j < degree; j++) {
            Type type = row == null ? null
                                    : row.nodes[j].dataType;

            for (int i = 0; i < nodes.length; i++) {
                type = Type.getAggregateType(nodes[i].nodes[j].dataType, type);
            }

            if (type == null) {
                throw Error.error(ErrorCode.X_42567);
            }

            nodeDataTypes[j] = type;

            if (row != null && row.nodes[j].isParam) {
                row.nodes[j].dataType = type;
            }

            for (int i = 0; i < nodes.length; i++) {
                if (nodes[i].nodes[j].isParam) {
                    nodes[i].nodes[j].dataType = nodeDataTypes[j];

                    continue;
                }

                if (nodes[i].nodes[j].opType == OpTypes.VALUE) {
                    if (nodes[i].nodes[j].valueData == null) {
                        nodes[i].nodes[j].dataType = nodeDataTypes[j];
                    }
                }
            }

            if (nodeDataTypes[j].isCharacterType()
                    && !((CharacterType) nodeDataTypes[j])
                        .isEqualIdentical()) {

                
            }
        }
    }

    
    void insertValuesIntoSubqueryTable(Session session,
                                       PersistentStore store) {

        TableDerived table = subQuery.getTable();

        for (int i = 0; i < nodes.length; i++) {
            Object[] data = nodes[i].getRowValue(session);

            for (int j = 0; j < nodeDataTypes.length; j++) {
                data[j] = nodeDataTypes[j].convertToType(session, data[j],
                        nodes[i].nodes[j].dataType);
            }

            Row row = (Row) store.getNewCachedObject(session, data);

            try {
                store.indexRow(session, row);
            } catch (HsqlException e) {}
        }
    }

    
    String getColumnName() {
        return getAlias();
    }

    ColumnSchema getColumn() {
        return null;
    }

    
    int getColumnIndex() {
        return columnIndex;
    }

    
    Type getDataType() {
        return dataType;
    }

    int getDegree() {
        return opType == OpTypes.ROW ? nodes.length
                                     : 1;
    }

    public Object[] getRowValue(Session session) {

        switch (opType) {

            case OpTypes.ROW : {
                Object[] data = new Object[nodes.length];

                for (int i = 0; i < nodes.length; i++) {
                    data[i] = nodes[i].getValue(session);
                }

                return data;
            }
            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY : {
                return subQuery.queryExpression.getValues(session);
            }
            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "Expression");
        }
    }

    Object getValue(Session session, Type type) {

        Object o = getValue(session);

        if (o == null || dataType == type) {
            return o;
        }

        return type.convertToType(session, o, dataType);
    }

    public Object getConstantValue(Session session) {
        return getValue(session);
    }

    public Object getConstantValueNoCheck(Session session) {

        try {
            return getValue(session);
        } catch (HsqlException e) {
            return null;
        }
    }

    public Object getValue(Session session) {

        switch (opType) {

            case OpTypes.VALUE :
                return valueData;

            case OpTypes.SIMPLE_COLUMN : {
                Object[] data =
                    session.sessionContext.rangeIterators[rangePosition]
                        .getCurrent();

                return data[columnIndex];
            }
            case OpTypes.ROW : {
                if (nodes.length == 1) {
                    return nodes[0].getValue(session);
                }

                Object[] row = new Object[nodes.length];

                for (int i = 0; i < nodes.length; i++) {
                    row[i] = nodes[i].getValue(session);
                }

                return row;
            }
            case OpTypes.ROW_SUBQUERY :
            case OpTypes.TABLE_SUBQUERY : {
                subQuery.materialiseCorrelated(session);

                Object value = subQuery.getValue(session);

                return value;
            }
            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "Expression");
        }
    }

    boolean testCondition(Session session) {
        return Boolean.TRUE.equals(getValue(session));
    }

    static int countNulls(Object[] a) {

        int nulls = 0;

        for (int i = 0; i < a.length; i++) {
            if (a[i] == null) {
                nulls++;
            }
        }

        return nulls;
    }

    static void convertToType(Session session, Object[] data, Type[] dataType,
                              Type[] newType) {

        for (int i = 0; i < data.length; i++) {
            data[i] = newType[i].convertToType(session, data[i], dataType[i]);
        }
    }

    
    static QuerySpecification getCheckSelect(Session session, Table t,
            Expression e) {

        CompileContext     compileContext = new CompileContext(session);
        QuerySpecification s = new QuerySpecification(compileContext);

        s.exprColumns    = new Expression[1];
        s.exprColumns[0] = EXPR_TRUE;

        RangeVariable range = new RangeVariable(t, null, null, null,
            compileContext);

        s.rangeVariables = new RangeVariable[]{ range };

        HsqlList unresolved = e.resolveColumnReferences(s.rangeVariables,
            null);

        ExpressionColumn.checkColumnsResolved(unresolved);
        e.resolveTypes(session, null);

        if (Type.SQL_BOOLEAN != e.getDataType()) {
            throw Error.error(ErrorCode.X_42568);
        }

        Expression condition = new ExpressionLogical(OpTypes.NOT, e);

        s.queryCondition = condition;

        s.resolveReferences(session);
        s.resolveTypes(session);

        return s;
    }

    boolean isParam() {
        return isParam;
    }

    void setAttributesAsColumn(ColumnSchema column, boolean isWritable) {
        throw Error.runtimeError(ErrorCode.U_S0500,
                                 "Expression.setAttributesAsColumn");
    }

    String getValueClassName() {

        Type type = dataType == null ? NullType.getNullType()
                                     : dataType;

        return type.getJDBCClassName();
    }

    public void collectAllFunctionExpressions(HsqlList set) {

        Expression.collectAllExpressions(set, this,
                                         Expression.emptyExpressionSet,
                                         Expression.emptyExpressionSet);
    }

    
    static void collectAllExpressions(HsqlList set, Expression e,
                                      OrderedIntHashSet typeSet,
                                      OrderedIntHashSet stopAtTypeSet) {

        if (e == null) {
            return;
        }

        if (stopAtTypeSet.contains(e.opType)) {
            return;
        }

        for (int i = 0; i < e.nodes.length; i++) {
            collectAllExpressions(set, e.nodes[i], typeSet, stopAtTypeSet);
        }

        if (typeSet.contains(e.opType)) {
            set.add(e);
        }

        if (e.subQuery != null && e.subQuery.queryExpression != null) {
            e.subQuery.queryExpression.collectAllExpressions(set, typeSet,
                    stopAtTypeSet);
        }
    }

    
    public boolean isCorrelated() {

        if (opType == OpTypes.TABLE_SUBQUERY && subQuery != null
                && subQuery.isCorrelated()) {
            return true;
        }

        return false;
    }

    
    public void checkValidCheckConstraint() {

        HsqlArrayList set = new HsqlArrayList();

        Expression.collectAllExpressions(set, this, subqueryExpressionSet,
                                         emptyExpressionSet);

        if (!set.isEmpty()) {
            throw Error.error(ErrorCode.X_0A000,
                              "subquery in check constraint");
        }
    }

    static HsqlList resolveColumnSet(RangeVariable[] rangeVars,
                                     HsqlList sourceSet, HsqlList targetSet) {

        if (sourceSet == null) {
            return targetSet;
        }

        for (int i = 0; i < sourceSet.size(); i++) {
            Expression e = (Expression) sourceSet.get(i);

            targetSet = e.resolveColumnReferences(rangeVars, targetSet);
        }

        return targetSet;
    }

    Expression getIndexableExpression(RangeVariable rangeVar) {
        return null;
    }

    

    
    public void collectAllColumnExpressions(HsqlList set) {

        Expression.collectAllExpressions(set, this,
                                         Expression.columnExpressionSet,
                                         Expression.emptyExpressionSet);
    }

    static Map<Integer, VoltXMLElement> prototypes = new HashMap<Integer, VoltXMLElement>();

    static {
        prototypes.put(OpTypes.VALUE,         new VoltXMLElement("value")); 
        prototypes.put(OpTypes.COLUMN,        new VoltXMLElement("columnref")); 
        prototypes.put(OpTypes.COALESCE,      new VoltXMLElement("columnref")); 
        prototypes.put(OpTypes.DEFAULT,       new VoltXMLElement("columnref")); 
        prototypes.put(OpTypes.SIMPLE_COLUMN, (new VoltXMLElement("simplecolumn")));

        prototypes.put(OpTypes.VARIABLE,      null); 
        prototypes.put(OpTypes.PARAMETER,     null); 
        prototypes.put(OpTypes.DYNAMIC_PARAM, (new VoltXMLElement("value")).withValue("isparam", "true")); 
        prototypes.put(OpTypes.ASTERISK,      new VoltXMLElement("asterisk"));
        prototypes.put(OpTypes.SEQUENCE,      null); 
        prototypes.put(OpTypes.SCALAR_SUBQUERY,null); 
        prototypes.put(OpTypes.ROW_SUBQUERY,  null); 
        prototypes.put(OpTypes.TABLE_SUBQUERY,new VoltXMLElement("tablesubquery"));
        prototypes.put(OpTypes.ROW,           new VoltXMLElement("row")); 
        prototypes.put(OpTypes.TABLE,         new VoltXMLElement("table")); 
        prototypes.put(OpTypes.FUNCTION,      null); 
        prototypes.put(OpTypes.SQL_FUNCTION,  new VoltXMLElement("function"));
        prototypes.put(OpTypes.ROUTINE_FUNCTION, null); 

        
        prototypes.put(OpTypes.NEGATE,        (new VoltXMLElement("operation")).withValue("optype", "negate"));

        prototypes.put(OpTypes.ADD,           (new VoltXMLElement("operation")).withValue("optype", "add"));
        prototypes.put(OpTypes.SUBTRACT,      (new VoltXMLElement("operation")).withValue("optype", "subtract"));
        prototypes.put(OpTypes.MULTIPLY,      (new VoltXMLElement("operation")).withValue("optype", "multiply"));
        prototypes.put(OpTypes.DIVIDE,        (new VoltXMLElement("operation")).withValue("optype", "divide"));

        prototypes.put(OpTypes.CONCAT,        (new VoltXMLElement("function")) 
                                               .withValue("function_id", FunctionCustom.FUNC_CONCAT_ID_STRING)
                                               .withValue("name", Tokens.T_CONCAT_WORD)
                                               .withValue("valuetype", Type.SQL_VARCHAR.getNameString()));

        
        prototypes.put(OpTypes.EQUAL,         (new VoltXMLElement("operation")).withValue("optype", "equal"));
        prototypes.put(OpTypes.GREATER_EQUAL, (new VoltXMLElement("operation")).withValue("optype", "greaterthanorequalto"));
        prototypes.put(OpTypes.GREATER,       (new VoltXMLElement("operation")).withValue("optype", "greaterthan"));
        prototypes.put(OpTypes.SMALLER,       (new VoltXMLElement("operation")).withValue("optype", "lessthan"));
        prototypes.put(OpTypes.SMALLER_EQUAL, (new VoltXMLElement("operation")).withValue("optype", "lessthanorequalto"));
        prototypes.put(OpTypes.NOT_EQUAL,     (new VoltXMLElement("operation")).withValue("optype", "notequal"));
        prototypes.put(OpTypes.IS_NULL,       (new VoltXMLElement("operation")).withValue("optype", "is_null"));

        
        prototypes.put(OpTypes.NOT,           (new VoltXMLElement("operation")).withValue("optype", "not"));
        prototypes.put(OpTypes.AND,           (new VoltXMLElement("operation")).withValue("optype", "and"));
        prototypes.put(OpTypes.OR,            (new VoltXMLElement("operation")).withValue("optype", "or"));

        
        prototypes.put(OpTypes.ALL_QUANTIFIED,null); 
        prototypes.put(OpTypes.ANY_QUANTIFIED,null); 

        
        prototypes.put(OpTypes.LIKE,          (new VoltXMLElement("operation")).withValue("optype", "like"));
        prototypes.put(OpTypes.IN,            null); 
        prototypes.put(OpTypes.EXISTS,        (new VoltXMLElement("operation")).withValue("optype", "exists"));
        prototypes.put(OpTypes.OVERLAPS,      null); 
        prototypes.put(OpTypes.UNIQUE,        null); 
        prototypes.put(OpTypes.NOT_DISTINCT,  null); 
        prototypes.put(OpTypes.MATCH_SIMPLE,  null); 
        prototypes.put(OpTypes.MATCH_PARTIAL, null); 
        prototypes.put(OpTypes.MATCH_FULL,    null); 
        prototypes.put(OpTypes.MATCH_UNIQUE_SIMPLE,  null); 
        prototypes.put(OpTypes.MATCH_UNIQUE_PARTIAL, null); 
        prototypes.put(OpTypes.MATCH_UNIQUE_FULL,    null); 
        
        prototypes.put(OpTypes.COUNT,         (new VoltXMLElement("aggregation")).withValue("optype", "count"));
        
        prototypes.put(OpTypes.APPROX_COUNT_DISTINCT, (new VoltXMLElement("aggregation")).withValue("optype", "approx_count_distinct"));
        
        prototypes.put(OpTypes.SUM,           (new VoltXMLElement("aggregation")).withValue("optype", "sum"));
        prototypes.put(OpTypes.MIN,           (new VoltXMLElement("aggregation")).withValue("optype", "min"));
        prototypes.put(OpTypes.MAX,           (new VoltXMLElement("aggregation")).withValue("optype", "max"));
        prototypes.put(OpTypes.AVG,           (new VoltXMLElement("aggregation")).withValue("optype", "avg"));
        prototypes.put(OpTypes.EVERY,         (new VoltXMLElement("aggregation")).withValue("optype", "every"));
        prototypes.put(OpTypes.SOME,          (new VoltXMLElement("aggregation")).withValue("optype", "some"));
        prototypes.put(OpTypes.STDDEV_POP,    (new VoltXMLElement("aggregation")).withValue("optype", "stddevpop"));
        prototypes.put(OpTypes.STDDEV_SAMP,   (new VoltXMLElement("aggregation")).withValue("optype", "stddevsamp"));
        prototypes.put(OpTypes.VAR_POP,       (new VoltXMLElement("aggregation")).withValue("optype", "varpop"));
        prototypes.put(OpTypes.VAR_SAMP,      (new VoltXMLElement("aggregation")).withValue("optype", "varsamp"));
        
        prototypes.put(OpTypes.CAST,          (new VoltXMLElement("operation")).withValue("optype", "cast"));
        prototypes.put(OpTypes.ZONE_MODIFIER, null); 
        prototypes.put(OpTypes.CASEWHEN,      (new VoltXMLElement("operation")).withValue("optype", "operator_case_when"));
        prototypes.put(OpTypes.ORDER_BY,      new VoltXMLElement("orderby"));
        prototypes.put(OpTypes.LIMIT,         new VoltXMLElement("limit"));
        prototypes.put(OpTypes.ALTERNATIVE,   (new VoltXMLElement("operation")).withValue("optype", "operator_alternative"));
        prototypes.put(OpTypes.MULTICOLUMN,   null); 
    }

    
    VoltXMLElement voltGetXML(Session session)
            throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException
    {
        return voltGetXML(session, null, null, -1);
    }

    VoltXMLElement voltGetXML(Session session, List<Expression> displayCols,
            java.util.Set<Integer> ignoredDisplayColIndexes, int startKey)
            throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException
    {
        return voltGetXML(session, displayCols, ignoredDisplayColIndexes, startKey, null);
    }

    
    VoltXMLElement voltGetXML(Session session, List<Expression> displayCols,
            java.util.Set<Integer> ignoredDisplayColIndexes, int startKey, String realAlias)
        throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException
    {
        
        
        int exprOp = getType();

        
        
        
        
        
        
        
        
        
        
        if (exprOp == OpTypes.SIMPLE_COLUMN) {
            if (displayCols == null) {
                if (this instanceof ExpressionColumn == false) {
                    throw new org.hsqldb_voltpatches.HSQLInterface.HSQLParseException(
                            "VoltDB does not support this complex query currently.");
                }
                
                opType = OpTypes.COLUMN;
                exprOp = OpTypes.COLUMN;
            } else {
                
                for (int ii=startKey+1; ii < displayCols.size(); ++ii)
                {
                    Expression otherCol = displayCols.get(ii);
                    
                    
                    
                    if (otherCol != null && (otherCol.opType != OpTypes.SIMPLE_COLUMN) &&
                             (otherCol.columnIndex == this.columnIndex)  &&
                             !(otherCol instanceof ExpressionColumn))
                    {
                        ignoredDisplayColIndexes.add(ii);
                        
                        
                        
                        return otherCol.voltGetXML(session, displayCols, ignoredDisplayColIndexes, startKey, getAlias());
                    }
                }
                assert(false);
            }
        }

        
        
        VoltXMLElement exp = prototypes.get(exprOp);
        if (exp == null) {
            
            throwForUnsupportedExpression(exprOp);
        }

        
        
        exp = exp.duplicate();
        exp.attributes.put("id", this.getUniqueId(session));

        if (realAlias != null) {
            exp.attributes.put("alias", realAlias);
        } else if ((alias != null) && (getAlias().length() > 0)) {
            exp.attributes.put("alias", getAlias());
        }

        
        if (exprSubType == OpTypes.ANY_QUANTIFIED) {
            exp.attributes.put("opsubtype", "any");
        } else if (exprSubType == OpTypes.ALL_QUANTIFIED) {
            exp.attributes.put("opsubtype", "all");
        }

        for (Expression expr : nodes) {
            if (expr != null) {
                VoltXMLElement vxmle = expr.voltGetXML(session, displayCols, ignoredDisplayColIndexes, startKey);
                exp.children.add(vxmle);
                assert(vxmle != null);
            }
        }

        
        
        
        
        
        
        switch (exprOp) {
        case OpTypes.VALUE:
            
            
            
            if (valueData == null) {
                if (dataType == null) {
                    exp.attributes.put("valuetype", "NULL");
                    return exp;
                }
                exp.attributes.put("valuetype", Types.getTypeName(dataType.typeCode));
                return exp;
            }

            if (dataType.isBooleanType()) {
                
                
                
                
                
                
                
                
                
                
                
                
                throw new org.hsqldb_voltpatches.HSQLInterface.HSQLParseException(
                        "VoltDB does not support WHERE clauses containing only constants");
            }

            exp.attributes.put("valuetype", Types.getTypeName(dataType.typeCode));

            if (valueData instanceof TimestampData) {
                
                
                
                
                
                
                TimestampData time = (TimestampData) valueData;
                exp.attributes.put("value", Long.toString(Math.round((time.getSeconds() +
                                                                      time.getZone()) * 1e6) +
                                                          time.getNanos() / 1000));
                return exp;
            }

            
            if (valueData instanceof BinaryData) {
                BinaryData bd = (BinaryData) valueData;
                exp.attributes.put("value", hexEncode(bd.getBytes()));
                return exp;
            }

            
            if (dataType instanceof NumberType && ! dataType.isIntegralType()) {
                
                exp.attributes.put("value", new BigDecimal(valueData.toString()).toPlainString());
                return exp;
            }
            exp.attributes.put("value", valueData.toString());
            return exp;

        case OpTypes.COLUMN:
        case OpTypes.COALESCE:
            ExpressionColumn ec = (ExpressionColumn)this;
            return ec.voltAnnotateColumnXML(exp);

        case OpTypes.SQL_FUNCTION:
            FunctionSQL fn = (FunctionSQL)this;
            return fn.voltAnnotateFunctionXML(exp);

        case OpTypes.COUNT:
        
        case OpTypes.APPROX_COUNT_DISTINCT:
        
        case OpTypes.SUM:
        case OpTypes.AVG:
            if (((ExpressionAggregate)this).isDistinctAggregate) {
                exp.attributes.put("distinct", "true");
            }
            return exp;

        case OpTypes.ORDER_BY:
            if (((ExpressionOrderBy)this).isDescending()) {
                exp.attributes.put("desc", "true");
            }
            return exp;

        case OpTypes.CAST:
            if (dataType == null) {
                throw new org.hsqldb_voltpatches.HSQLInterface.HSQLParseException(
                        "VoltDB could not determine the type in a CAST operation");
            }
            exp.attributes.put("valuetype", dataType.getNameString());
            return exp;

        case OpTypes.TABLE_SUBQUERY:
            if (subQuery == null || subQuery.queryExpression == null) {
                throw new HSQLParseException("VoltDB could not determine the subquery");
            }
            ExpressionColumn parameters[] = new ExpressionColumn[0];
            exp.children.add(StatementQuery.voltGetXMLExpression(subQuery.queryExpression, parameters, session));
            return exp;

        case OpTypes.ALTERNATIVE:
            assert(nodes.length == 2);
            
            if (nodes[RIGHT] instanceof ExpressionValue) {
                ExpressionValue val = (ExpressionValue) nodes[RIGHT];
                if (val.valueData == null && val.dataType == Type.SQL_ALL_TYPES) {
                    exp.children.get(RIGHT).attributes.put("valuetype", dataType.getNameString());
                }
            }
        case OpTypes.CASEWHEN:
            
            assert(dataType != null);
            exp.attributes.put("valuetype", dataType.getNameString());
            return exp;

        default:
            return exp;
        }
    }

    private static final int caseDiff = ('a' - 'A');
    
    public static String hexEncode(byte[] data) {
        if (data == null)
            return null;

        StringBuilder sb = new StringBuilder();
        for (byte b : data) {
            
            char ch = Character.forDigit((b >> 4) & 0xF, 16);
            
            if (Character.isLetter(ch)) {
                ch -= caseDiff;
            }
            sb.append(ch);
            ch = Character.forDigit(b & 0xF, 16);
            if (Character.isLetter(ch)) {
                ch -= caseDiff;
            }
            sb.append(ch);
        }
        return sb.toString();
    }

    private static void throwForUnsupportedExpression(int exprOp)
            throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException
    {
        String opAsString;
        switch (exprOp) {
        
        

        case OpTypes.VARIABLE:
            opAsString = "HSQL session variables"; break; 
        case OpTypes.PARAMETER:
            opAsString = "HSQL session parameters"; break; 

        case OpTypes.SEQUENCE:
            opAsString = "sequence types"; break; 

        case OpTypes.SCALAR_SUBQUERY:
        case OpTypes.ROW_SUBQUERY:
        case OpTypes.TABLE_SUBQUERY:
        case OpTypes.ROW:
        case OpTypes.TABLE:
        case OpTypes.EXISTS:
            throw new HSQLParseException("Unsupported subquery syntax within an expression. Consider using a join or multiple statements instead");

        case OpTypes.FUNCTION:             opAsString = "HSQL-style user-defined Java SQL functions"; break;

        case OpTypes.ROUTINE_FUNCTION:     opAsString = "HSQL routine functions"; break; 

        case OpTypes.ALL_QUANTIFIED:
        case OpTypes.ANY_QUANTIFIED:
            opAsString = "sequences or subqueries"; break; 

        case OpTypes.IN:
            opAsString = "the IN operator. Consider using an OR expression"; break; 

        case OpTypes.OVERLAPS:
        case OpTypes.UNIQUE:
        case OpTypes.NOT_DISTINCT:
            opAsString = "sequences or subqueries"; break; 

        case OpTypes.MATCH_SIMPLE:
        case OpTypes.MATCH_PARTIAL:
        case OpTypes.MATCH_FULL:
        case OpTypes.MATCH_UNIQUE_SIMPLE:
        case OpTypes.MATCH_UNIQUE_PARTIAL:
        case OpTypes.MATCH_UNIQUE_FULL:
            opAsString = "the MATCH operator"; break; 

        case OpTypes.ZONE_MODIFIER:
            opAsString = "ZONE modifier operations"; break; 
        case OpTypes.MULTICOLUMN:
            opAsString = "a MULTICOLUMN operation"; break; 

        default:
            opAsString = " the unknown operator with numeric code (" + String.valueOf(exprOp) + ")";
        }
        throw new org.hsqldb_voltpatches.HSQLInterface.HSQLParseException(
                "VoltDB does not support " + opAsString);
    }

    
    public Expression eliminateDuplicates(final Session session) {
        
        
        Map<String, Expression> subExprMap = new HashMap<String, Expression>();
        extractAndSubExpressions(session, this, subExprMap);
        
        if (!subExprMap.isEmpty()) {
            Iterator<Map.Entry<String, Expression>> itExpr = subExprMap.entrySet().iterator();
            Expression finalExpr = itExpr.next().getValue();
            while (itExpr.hasNext()) {
                finalExpr = new ExpressionLogical(OpTypes.AND, finalExpr, itExpr.next().getValue());
            }
            return finalExpr;
        }
        return this;
    }

    protected void extractAndSubExpressions(final Session session, Expression expr,
            Map<String, Expression> subExprMap) {
        
        if (expr instanceof ExpressionLogical && ((ExpressionLogical) expr).opType == OpTypes.AND) {
            extractAndSubExpressions(session, expr.nodes[LEFT], subExprMap);
            extractAndSubExpressions(session, expr.nodes[RIGHT], subExprMap);
        } else {
            String id = expr.getUniqueId(session);
            subExprMap.put(id, expr);
       }
    }

    protected String cached_id = null;

    
    protected String getUniqueId(final Session session) {
        if (cached_id != null) {
            return cached_id;
        }

        
        
        

        
        
        cached_id = new String();
        int hashCode = 0;
        
        
        
        if (getType() == OpTypes.VALUE || getType() == OpTypes.COLUMN) {
            hashCode = super.hashCode();
        
        
        
        } else {
            
            
            
            final List<String> id_list = new Vector<String>();
            new Object() {
                public void traverse(Expression exp) {
                    for (Expression expr : exp.nodes) {
                        if (expr != null)
                            id_list.add(expr.getUniqueId(session));
                    }
                }
            }.traverse(this);

            if (id_list.size() > 0) {
                
                for (String temp : id_list)
                    this.cached_id += "+" + temp;
                hashCode = this.cached_id.intern().hashCode();
            }
            else
                hashCode = super.hashCode();
        }

        long id = session.getNodeIdForExpression(hashCode);
        cached_id = Long.toString(id);
        return cached_id;
    }

    
    public VoltXMLElement voltGetExpressionXML(Session session, Table table)
            throws org.hsqldb_voltpatches.HSQLInterface.HSQLParseException {
        resolveTableColumns(table);
        Expression parent = null; 
        resolveTypes(session, parent);
        return voltGetXML(session);
    }

    
    private void resolveTableColumns(Table table) {
        HsqlList set = new HsqlArrayList();
        collectAllColumnExpressions(set);
        for (int i = 0; i < set.size(); i++) {
            ExpressionColumn array_element = (ExpressionColumn)set.get(i);
            ColumnSchema column = table.getColumn(table.getColumnIndex(array_element.getAlias()));
            array_element.setAttributesAsColumn(column, false);

        }
    }

    
    @Override
    public String toString() {
        String type = null;

        
        
        
        Field[] fields = OpTypes.class.getFields();
        for (Field f : fields) {
            if (f.getType() != int.class) continue;
            int value = 0;
            try {
                value = f.getInt(null);
            } catch (Exception e) {
                
                e.printStackTrace();
            }

            
            if (value == opType) {
                type = f.getName();
                break;
            }
        }
        assert(type != null);

        
        String str = super.toString() + " with opType " + type +
                ", isAggregate: " + isAggregate +
                ", columnIndex: " + columnIndex;
        if (this instanceof ExpressionOrderBy) {
            str += "\n  " + this.nodes[LEFT].toString();
        }
        return str;
    }
    
}

<code block>



package org.hsqldb_voltpatches;

import org.hsqldb_voltpatches.lib.IntValueHashMap;
import org.hsqldb_voltpatches.lib.OrderedIntHashSet;


public class Tokens {

    
    
    static final String        T_ABS              = "ABS";
    public static final String T_ALL              = "ALL";
    static final String        T_ALLOCATE         = "ALLOCATE";
    public static final String T_ALTER            = "ALTER";
    static final String        T_AND              = "AND";
    static final String        T_ANY              = "ANY";
    static final String        T_ARE              = "ARE";
    static final String        T_ARRAY            = "ARRAY";
    public static final String T_AS               = "AS";
    static final String        T_ASENSITIVE       = "ASENSITIVE";
    static final String        T_ASYMMETRIC       = "ASYMMETRIC";
    static final String        T_AT               = "AT";
    static final String        T_ATOMIC           = "ATOMIC";
    public static final String T_AUTHORIZATION    = "AUTHORIZATION";
    static final String        T_AVG              = "AVG";
    static final String        T_BEGIN            = "BEGIN";
    static final String        T_BETWEEN          = "BETWEEN";
    public static final String T_BIGINT           = "BIGINT";
    public static final String T_BINARY           = "BINARY";
    static final String        T_BIT_LENGTH       = "BIT_LENGTH";
    
    static final String        T_BYTES            = "BYTES"; 
    
    public static final String T_BLOB             = "BLOB";
    public static final String T_BOOLEAN          = "BOOLEAN";
    static final String        T_BOTH             = "BOTH";
    static final String        T_BY               = "BY";
    static final String        T_CALL             = "CALL";
    static final String        T_CALLED           = "CALLED";
    static final String        T_CARDINALITY      = "CARDINALITY";
    public static final String T_CASCADED         = "CASCADED";
    static final String        T_CASE             = "CASE";
    static final String        T_CAST             = "CAST";
    static final String        T_CEIL             = "CEIL";
    static final String        T_CEILING          = "CEILING";
    static final String        T_CHAR             = "CHAR";
    static final String        T_CHAR_LENGTH      = "CHAR_LENGTH";
    public static final String T_CHARACTER        = "CHARACTER";
    static final String        T_CHARACTER_LENGTH = "CHARACTER_LENGTH";
    public static final String T_CHECK            = "CHECK";
    public static final String T_CLOB             = "CLOB";
    static final String        T_CLOSE            = "CLOSE";
    static final String        T_COALESCE         = "COALESCE";
    static final String        T_COLLATE          = "COLLATE";
    static final String        T_COLLECT          = "COLLECT";
    static final String        T_COLUMN           = "COLUMN";
    public static final String T_COMMIT           = "COMMIT";
    static final String        T_CONDITION        = "CONDIITON";
    public static final String T_CONNECT          = "CONNECT";
    public static final String T_CONSTRAINT       = "CONSTRAINT";
    static final String        T_CONVERT          = "CONVERT";
    static final String        T_CORR             = "CORR";
    static final String        T_CORRESPONDING    = "CORRESPONDING";
    static final String        T_COUNT            = "COUNT";
    
    static final String        T_APPROX_COUNT_DISTINCT = "APPROX_COUNT_DISTINCT";
    
    static final String        T_COVAR_POP        = "COVAR_POP";
    static final String        T_COVAR_SAMP       = "COVAR_SAMP";
    public static final String T_CREATE           = "CREATE";
    static final String        T_CROSS            = "CROSS";
    static final String        T_CUBE             = "CUBE";
    static final String        T_CUME_DIST        = "CUME_DIST";
    static final String        T_CURRENT          = "CURRENT";
    static final String        T_CURRENT_CATALOG  = "CURRENT_CATALOG";
    static final String        T_CURRENT_DATE     = "CURRENT_DATE";
    static final String T_CURRENT_DEFAULT_TRANSFORM_GROUP =
        "CURRENT_DEFAULT_TRANSFORM_GROUP";
    static final String T_CURRENT_PATH      = "CURRENT_PATH";
    static final String T_CURRENT_ROLE      = "CURRENT_ROLE";
    static final String T_CURRENT_SCHEMA    = "CURRENT_SCHEMA";
    static final String T_CURRENT_TIME      = "CURRENT_TIME";
    static final String T_CURRENT_TIMESTAMP = "CURRENT_TIMESTAMP";
    static final String T_CURRENT_TRANSFORM_GROUP_FOR_TYPE =
        "CURRENT_TRANSFORM_GROUP_FOR_TYPE";
    static final String        T_CURRENT_USER      = "CURRENT_USER";
    static final String        T_CURSOR            = "CURSOR";
    static final String        T_CYCLE             = "CYCLE";
    public static final String T_DATE              = "DATE";
    public static final String T_DAY               = "DAY";
    static final String        T_DEALLOCATE        = "DEALLOCATE";
    static final String        T_DEC               = "DEC";
    public static final String T_DECIMAL           = "DECIMAL";
    static final String        T_DECLARE           = "DECLARE";
    public static final String T_DEFAULT           = "DEFAULT";
    public static final String T_DELETE            = "DELETE";
    static final String        T_DENSE_RANK        = "DENSE_RANK";
    static final String        T_DEREF             = "DEREF";
    static final String        T_DESCRIBE          = "DESCRIBE";
    static final String        T_DETERMINISTIC     = "DETERMINISTIC";
    static final String        T_DISCONNECT        = "DISCONNECT";
    static final String        T_DISTINCT          = "DISTINCT";
    public static final String T_DO                = "DO";
    
    public static final String T_DOUBLE            = "FLOAT";
    
    
    static final String        T_DROP              = "DROP";
    static final String        T_DYNAMIC           = "DYNAMIC";
    static final String        T_EACH              = "EACH";
    static final String        T_ELEMENT           = "ELEMENT";
    static final String        T_ELSE              = "ELSE";
    static final String        T_ELSEIF            = "ELSEIF";
    static final String        T_END               = "END";
    static final String        T_END_EXEC          = "END_EXEC";
    static final String        T_ESCAPE            = "ESCAPE";
    static final String        T_EVERY             = "EVERY";
    static final String        T_EXCEPT            = "EXCEPT";
    static final String        T_EXEC              = "EXEC";
    public static final String T_EXECUTE           = "EXECUTE";
    static final String        T_EXISTS            = "EXISTS";
    static final String        T_EXP               = "EXP";
    static final String        T_EXTERNAL          = "EXTERNAL";
    static final String        T_EXTRACT           = "EXTRACT";
    static final String        T_FALSE             = "FALSE";
    static final String        T_FETCH             = "FETCH";
    static final String        T_FILTER            = "FILTER";
    static final String        T_FIRST_VALUE       = "FIRST_VALUE";
    public static final String T_FLOAT             = "FLOAT";
    static final String        T_FLOOR             = "FLOOR";
    static final String        T_FOR               = "FOR";
    static final String        T_FOREIGN           = "FOREIGN";
    static final String        T_FREE              = "FREE";
    static final String        T_FROM              = "FROM";
    static final String        T_FULL              = "FULL";
    static final String        T_FUNCTION          = "FUNCTION";
    static final String        T_FUSION            = "FUSION";
    public static final String T_GET               = "GET";
    static final String        T_GLOBAL            = "GLOBAL";
    public static final String T_GRANT             = "GRANT";
    static final String        T_GROUP             = "GROUP";
    static final String        T_GROUPING          = "GROUPING";
    static final String        T_HANDLER           = "HANDLER";
    static final String        T_HAVING            = "HAVING";
    static final String        T_HOLD              = "HOLD";
    public static final String T_HOUR              = "HOUR";
    static final String        T_IDENTITY          = "IDENTITY";
    static final String        T_IF                = "IF";
    static final String        T_IN                = "IN";
    static final String        T_INDICATOR         = "INDICATOR";
    static final String        T_INNER             = "INNER";
    static final String        T_INOUT             = "INOUT";
    static final String        T_INSENSITIVE       = "INSENSITIVE";
    public static final String T_INSERT            = "INSERT";
    static final String        T_INT               = "INT";
    public static final String T_INTEGER           = "INTEGER";
    static final String        T_INTERSECT         = "INTERSECT";
    static final String        T_INTERSECTION      = "INTERSECTION";
    public static final String T_INTERVAL          = "INTERVAL";
    static final String        T_INTO              = "INTO";
    static final String        T_ITERATE           = "ITERATE";
    static final String        T_IS                = "IS";
    static final String        T_JAR               = "JAR";             
    static final String        T_JOIN              = "JOIN";
    static final String        T_LAG               = "LAG";
    static final String        T_LANGUAGE          = "LANGUAGE";
    static final String        T_LARGE             = "LARGE";
    static final String        T_LAST_VALUE        = "LAST_VALUE";
    static final String        T_LATERAL           = "LATERAL";
    static final String        T_LEAD              = "LEAD";
    static final String        T_LEADING           = "LEADING";
    static final String        T_LEAVE             = "LEAVE";
    static final String        T_LEFT              = "LEFT";
    static final String        T_LIKE              = "LIKE";
    static final String        T_LIKE_REGX         = "LIKE_REGX";
    static final String        T_LN                = "LN";
    public static final String T_LOCAL             = "LOCAL";
    static final String        T_LOCALTIME         = "LOCALTIME";
    static final String        T_LOCALTIMESTAMP    = "LOCALTIMESTAMP";
    public static final String T_LOOP              = "LOOP";
    static final String        T_LOWER             = "LOWER";
    static final String        T_MATCH             = "MATCH";
    static final String        T_MAX               = "MAX";
    static final String        T_MAX_CARDINALITY   = "MAX_CARDINALITY";
    static final String        T_MEMBER            = "MEMBER";
    static final String        T_MERGE             = "MERGE";
    static final String        T_METHOD            = "METHOD";
    static final String        T_MIN               = "MIN";
    public static final String T_MINUTE            = "MINUTE";
    static final String        T_MOD               = "MOD";
    static final String        T_MODIFIES          = "MODIFIES";
    static final String        T_MODULE            = "MODULE";
    public static final String T_MONTH             = "MONTH";
    static final String        T_MULTISET          = "MULTISET";
    static final String        T_NATIONAL          = "NATIONAL";
    static final String        T_NATURAL           = "NATURAL";
    static final String        T_NCHAR             = "NCHAR";
    static final String        T_NCLOB             = "NCLOB";
    static final String        T_NEW               = "NEW";
    public static final String T_NO                = "NO";
    public static final String T_NONE              = "NONE";
    static final String        T_NORMALIZE         = "NORMALIZE";
    static final String        T_NOT               = "NOT";
    static final String        T_NTH_VALUE         = "NTH_VALUE";
    static final String        T_NTILE             = "NTILE";
    public static final String T_NULL              = "NULL";
    public static final String T_NULLIF            = "NULLIF";
    public static final String T_NUMERIC           = "NUMERIC";
    static final String        T_OCCURRENCES_REGEX = "OCCURRENCES_REGEX";
    static final String        T_OCTET_LENGTH      = "OCTET_LENGTH";
    static final String        T_OF                = "OF";
    static final String        T_OFFSET            = "OFFSET";
    static final String        T_OLD               = "OLD";
    public static final String T_ON                = "ON";
    static final String        T_ONLY              = "ONLY";
    static final String        T_OPEN              = "OPEN";
    static final String        T_OR                = "OR";
    static final String        T_ORDER             = "ORDER";
    static final String        T_OUT               = "OUT";
    static final String        T_OUTER             = "OUTER";
    static final String        T_OVER              = "OVER";
    static final String        T_OVERLAPS          = "OVERLAPS";
    static final String        T_OVERLAY           = "OVERLAY";
    static final String        T_PARAMETER         = "PARAMETER";
    static final String        T_PARTITION         = "PARTITION";
    static final String        T_PERCENT_RANK      = "PERCENT_RANK";
    static final String        T_PERCENTILE_CONT   = "PERCENTILE_CONT";
    static final String        T_PERCENTILE_DISC   = "PERCENTILE_DISC";
    static final String        T_POSITION          = "POSITION";
    static final String        T_POSITION_REGEX    = "POSITION_REGEX";
    static final String        T_POWER             = "POWER";
    static final String        T_PRECISION         = "PRECISION";
    static final String        T_PREPARE           = "PREPARE";
    static final String        T_PRIMARY           = "PRIMARY";
    static final String        T_PROCEDURE         = "PROCEDURE";
    static final String        T_RANGE             = "RANGE";
    static final String        T_RANK              = "RANK";
    static final String        T_READS             = "READS";
    public static final String T_REAL              = "REAL";
    static final String        T_RECURSIVE         = "RECURSIVE";
    static final String        T_REF               = "REF";
    public static final String T_REFERENCES        = "REFERENCES";
    static final String        T_REFERENCING       = "REFERENCING";
    static final String        T_REGR_AVGX         = "REGR_AVGX";
    static final String        T_REGR_AVGY         = "REGR_AVGY";
    static final String        T_REGR_COUNT        = "REGR_COUNT";
    static final String        T_REGR_INTERCEPT    = "REGR_INTERCEPT";
    static final String        T_REGR_R2           = "REGR_R2";
    static final String        T_REGR_SLOPE        = "REGR_SLOPE";
    static final String        T_REGR_SXX          = "REGR_SXX";
    static final String        T_REGR_SXY          = "REGR_SXY";
    static final String        T_REGR_SYY          = "REGR_SYY";
    static final String        T_RELEASE           = "RELEASE";
    static final String        T_REPEAT            = "REPEAT";
    static final String        T_RESIGNAL          = "RESIGNAL";
    static final String        T_RESULT            = "RESULT";
    static final String        T_RETURN            = "RETURN";
    static final String        T_RETURNS           = "RETURNS";
    static final String        T_REVOKE            = "REVOKE";
    static final String        T_RIGHT             = "RIGHT";
    static final String        T_ROLLBACK          = "ROLLBACK";
    static final String        T_ROLLUP            = "ROLLUP";
    static final String        T_ROW               = "ROW";
    static final String        T_ROW_NUMBER        = "ROW_NUMBER";
    static final String        T_ROWS              = "ROWS";
    static final String        T_SAVEPOINT         = "SAVEPOINT";
    static final String        T_SCOPE             = "SCOPE";
    static final String        T_SCROLL            = "SCROLL";
    static final String        T_SEARCH            = "SEARCH";
    public static final String T_SECOND            = "SECOND";
    public static final String T_SELECT            = "SELECT";
    static final String        T_SENSITIVE         = "SENSITIVE";
    static final String        T_SESSION_USER      = "SESSION_USER";
    public static final String T_SET               = "SET";
    static final String        T_SIGNAL            = "SIGNAL";
    static final String        T_SIMILAR           = "SIMILAR";
    public static final String T_SMALLINT          = "SMALLINT";
    static final String        T_SOME              = "SOME";
    static final String        T_SPECIFIC          = "SPECIFIC";
    static final String        T_SPECIFICTYPE      = "SPECIFICTYPE";
    static final String        T_SQL               = "SQL";
    static final String        T_SQLEXCEPTION      = "SQLEXCEPTION";
    static final String        T_SQLSTATE          = "SQLSTATE";
    static final String        T_SQLWARNING        = "SQLWARNING";
    static final String        T_SQRT              = "SQRT";
    static final String        T_START             = "START";
    static final String        T_STATIC            = "STATIC";
    static final String        T_STDDEV_POP        = "STDDEV_POP";
    static final String        T_STDDEV_SAMP       = "STDDEV_SAMP";
    static final String        T_SUBMULTISET       = "SUBMULTISET";
    static final String        T_SUBSTRING         = "SUBSTRING";
    static final String        T_SUBSTRING_REGEX   = "SUBSTRING_REGEX";
    static final String        T_SUM               = "SUM";
    static final String        T_SYMMETRIC         = "SYMMETRIC";
    static final String        T_SYSTEM            = "SYSTEM";
    static final String        T_SYSTEM_USER       = "SYSTEM_USER";
    static final String        T_TABLE             = "TABLE";
    static final String        T_TABLESAMPLE       = "TABLESAMPLE";
    static final String        T_THEN              = "THEN";
    public static final String T_TIME              = "TIME";
    public static final String T_TIMESTAMP         = "TIMESTAMP";
    public static final String T_TIMEZONE_HOUR     = "TIMEZONE_HOUR";
    public static final String T_TIMEZONE_MINUTE   = "TIMEZONE_MINUTE";
    public static final String T_TO                = "TO";
    static final String        T_TRAILING          = "TRAILING";
    static final String        T_TRANSLATE         = "TRANSLATE";
    static final String        T_TRANSLATE_REGEX   = "TRANSLATE_REGEX";
    static final String        T_TRANSLATION       = "TRANSLATION";
    static final String        T_TREAT             = "TREAT";
    public static final String T_TRIGGER           = "TRIGGER";
    static final String        T_TRIM              = "TRIM";
    static final String        T_TRIM_ARRAY        = "TRIM_ARRAY";
    static final String        T_TRUE              = "TRUE";
    static final String        T_TRUNCATE          = "TRUNCATE";
    static final String        T_UESCAPE           = "UESCAPE";
    static final String        T_UNION             = "UNION";
    
    static final String        T_ASSUMEUNIQUE      = "ASSUMEUNIQUE";     
    
    public static final String T_UNIQUE            = "UNIQUE";
    static final String        T_UNKNOWN           = "UNKNOWN";
    static final String        T_UNNEST            = "UNNEST";
    static final String        T_UNTIL             = "UNTIL";
    public static final String T_UPDATE            = "UPDATE";
    static final String        T_UPPER             = "UPPER";
    public static final String T_USER              = "USER";
    static final String        T_USING             = "USING";
    static final String        T_VALUE             = "VALUE";
    static final String        T_VALUES            = "VALUES";
    static final String        T_VAR_POP           = "VAR_POP";
    static final String        T_VAR_SAMP          = "VAR_SAMP";
    public static final String T_VARBINARY         = "VARBINARY";
    public static final String T_VARCHAR           = "VARCHAR";
    static final String        T_VARYING           = "VARYING";
    static final String        T_WHEN              = "WHEN";
    static final String        T_WHENEVER          = "WHENEVER";
    static final String        T_WHERE             = "WHERE";
    public static final String T_WHILE             = "WHILE";
    static final String        T_WIDTH_BUCKET      = "WIDTH_BUCKET";
    static final String        T_WINDOW            = "WINDOW";
    public static final String T_WITH              = "WITH";
    static final String        T_WITHIN            = "WITHIN";
    static final String        T_WITHOUT           = "WITHOUT";
    public static final String T_YEAR              = "YEAR";

    
    static final String        T_ASTERISK       = "*";
    static final String        T_COMMA          = ",";
    static final String        T_CIRCUMFLEX     = "^";
    static final String        T_CLOSEBRACKET   = ")";
    static final String        T_COLON          = ":";
    static final String        T_CONCAT         = "||";
    public static final String T_DIVIDE         = "/";
    static final String        T_EQUALS         = "=";
    static final String        T_GREATER        = ">";
    static final String        T_GREATER_EQUALS = ">=";
    static final String        T_LESS           = "<";
    static final String        T_LESS_EQUALS    = "<=";
    static final String        T_PERCENT        = "%";
    static final String        T_PLUS           = "+";
    static final String        T_MINUS          = "-";
    static final String        T_NOT_EQUALS     = "<>";
    static final String        T_NOT_EQUALS_ALT = "!=";
    static final String        T_OPENBRACKET    = "(";
    static final String        T_QUESTION       = "?";
    static final String        T_SEMICOLON      = ";";
    static final String        T_DOUBLE_COLON   = "::";

    
    static final String T_A                      = "A";
    static final String T_ABSOLUTE               = "ABSOLUTE";
    static final String T_ACTION                 = "ACTION";
    static final String T_ADA                    = "ADA";
    static final String T_ADMIN                  = "ADMIN";
    static final String T_AFTER                  = "AFTER";
    static final String T_ALWAYS                 = "ALWAYS";
    static final String T_ASC                    = "ASC";
    static final String T_ASSERTION              = "ASSERTION";
    static final String T_ASSIGNMENT             = "ASSIGNMENT";
    static final String T_ATTRIBUTE              = "ATTRIBUTE";
    static final String T_ATTRIBUTES             = "ATTRIBUTES";
    static final String T_BEFORE                 = "BEFORE";
    static final String T_BERNOULLI              = "BERNOULLI";
    static final String T_BREADTH                = "BREADTH";
    static final String T_C                      = "C";
    static final String T_CASCADE                = "CASCADE";
    static final String T_CATALOG                = "CATALOG";
    static final String T_CATALOG_NAME           = "CATALOG_NAME";
    static final String T_CHAIN                  = "CHAIN";
    static final String T_CHARACTER_SET_CATALOG  = "CHARACTER_SET_CATALOG";
    static final String T_CHARACTER_SET_NAME     = "CHARACTER_SET_NAME";
    static final String T_CHARACTER_SET_SCHEMA   = "CHARACTER_SET_SCHEMA";
    static final String T_CHARACTERISTICS        = "CHARACTERISTICS";
    static final String T_CHARACTERS             = "CHARACTERS";
    static final String T_CLASS_ORIGIN           = "CLASS_ORIGIN";
    static final String T_COBOL                  = "COBOL";
    static final String T_COLLATION              = "COLLATION";
    static final String T_COLLATION_CATALOG      = "COLLATION_CATALOG";
    static final String T_COLLATION_NAME         = "COLLATION_NAME";
    static final String T_COLLATION_SCHEMA       = "COLLATION_SCHEMA";
    static final String T_COLUMN_NAME            = "COLUMN_NAME";
    static final String T_COMMAND_FUNCTION       = "COMMAND_FUNCTION";
    static final String T_COMMAND_FUNCTION_CODE  = "COMMAND_FUNCTION_CODE";
    static final String T_COMMITTED              = "COMMITTED";
    static final String T_COMPARABLE             = "COMPARABLE";        
    static final String T_CONDITION_IDENTIFIER   = "CONDIITON_IDENTIFIER";
    static final String T_CONDITION_NUMBER       = "CONDITION_NUMBER";
    static final String T_CONNECTION_NAME        = "CONNECTION_NAME";
    static final String T_CONSTRAINT_CATALOG     = "CONSTRAINT_CATALOG";
    static final String T_CONSTRAINT_NAME        = "CONSTRAINT_NAME";
    static final String T_CONSTRAINT_SCHEMA      = "CONSTRAINT_SCHEMA";
    static final String T_CONSTRAINTS            = "CONSTRAINTS";
    static final String T_CONSTRUCTOR            = "CONSTRUCTOR";
    static final String T_CONTAINS               = "CONTAINS";
    static final String T_CONTINUE               = "CONTINUE";
    static final String T_CURRENT_COLLATION      = "CURRENT_COLLATION";
    static final String T_CURSOR_NAME            = "CURSOR_NAME";
    static final String T_DATA                   = "DATA";
    static final String T_DATETIME_INTERVAL_CODE = "DATETIME_INTERVAL_CODE";
    static final String T_DATETIME_INTERVAL_PRECISION =
        "DATETIME_INTERVAL_PRECISION";
    static final String        T_DEFAULTS             = "DEFAULTS";
    static final String        T_DEFERRABLE           = "DEFERRABLE";
    static final String        T_DEFERRED             = "DEFERRED";
    static final String        T_DEFINED              = "DEFINED";
    static final String        T_DEFINER              = "DEFINER";
    static final String        T_DEGREE               = "DEGREE";
    static final String        T_DEPTH                = "DEPTH";
    static final String        T_DERIVED              = "DERIVED";
    static final String        T_DESC                 = "DESC";
    static final String        T_DESCRIPTOR           = "DESCRIPTOR";
    static final String        T_DIAGNOSTICS          = "DIAGNOSTICS";
    static final String        T_DISPATCH             = "DISPATCH";
    public static final String T_DOMAIN               = "DOMAIN";
    static final String        T_DYNAMIC_FUNCTION     = "DYNAMIC_FUNCTION";
    static final String T_DYNAMIC_FUNCTION_CODE = "DYNAMIC_FUNCTION_CODE";
    static final String        T_EXCEPTION            = "EXCEPTION";
    static final String        T_EXCLUDE              = "EXCLUDE";
    static final String        T_EXCLUDING            = "EXCLUDING";
    static final String        T_EXIT                 = "EXIT";
    static final String        T_FINAL                = "FINAL";
    static final String        T_FIRST                = "FIRST";
    static final String        T_FOLLOWING            = "FOLLOWING";
    static final String        T_FORTRAN              = "FORTRAN";
    static final String        T_FOUND                = "FOUND";
    public static final String T_G_FACTOR             = "G";
    static final String        T_GENERAL              = "GENERAL";
    static final String        T_GO                   = "GO";
    static final String        T_GOTO                 = "GOTO";
    static final String        T_GRANTED              = "GRANTED";
    static final String        T_HIERARCHY            = "HIERARCHY";
    static final String        T_IMPLEMENTATION       = "IMPLEMENTATION";
    static final String        T_INCLUDING            = "INCLUDING";
    static final String        T_INCREMENT            = "INCREMENT";
    static final String        T_INITIALLY            = "INITIALLY";
    static final String        T_INPUT                = "INPUT";
    static final String        T_INSTANCE             = "INSTANCE";
    static final String        T_INSTANTIABLE         = "INSTANTIABLE";
    static final String        T_INSTEAD              = "INSTEAD";
    static final String        T_INTERFACE            = "INTERFACE";    
    static final String        T_INVOKER              = "INVOKER";
    static final String        T_ISOLATION            = "ISOLATION";
    static final String        T_JAVA                 = "JAVA";         
    public static final String T_K_FACTOR             = "K";
    static final String        T_KEY                  = "KEY";
    static final String        T_KEY_MEMBER           = "KEY_MEMBER";
    static final String        T_KEY_TYPE             = "KEY_TYPE";
    static final String        T_LAST                 = "LAST";
    static final String        T_LENGTH               = "LENGTH";
    static final String        T_LEVEL                = "LEVEL";
    static final String        T_LOCATOR              = "LOCATOR";
    public static final String T_M_FACTOR             = "M";
    static final String        T_MAP                  = "MAP";
    static final String        T_MATCHED              = "MATCHED";
    static final String        T_MAXVALUE             = "MAXVALUE";
    static final String        T_MESSAGE_LENGTH       = "MESSAGE_LENGTH";
    static final String        T_MESSAGE_OCTET_LENGTH = "MESSAGE_OCTET_LENGTH";
    static final String        T_MESSAGE_TEXT         = "MESSAGE_TEXT";
    static final String        T_MINVALUE             = "MINVALUE";
    static final String        T_MORE                 = "MORE";
    static final String        T_MUMPS                = "MUMPS";
    static final String        T_NAME                 = "NAME";
    static final String        T_NAMES                = "NAMES";
    static final String        T_NESTING              = "NESTING";
    static final String        T_NEXT                 = "NEXT";
    static final String        T_NORMALIZED           = "NORMALIZED";
    static final String        T_NULLABLE             = "NULLABLE";
    static final String        T_NULLS                = "NULLS";
    static final String        T_NUMBER               = "NUMBER";
    public static final String T_OBJECT               = "OBJECT";
    static final String        T_OCTETS               = "OCTETS";
    static final String        T_OPTION               = "OPTION";
    static final String        T_OPTIONS              = "OPTIONS";
    static final String        T_ORDERING             = "ORDERING";
    static final String        T_ORDINALITY           = "ORDINALITY";
    static final String        T_OTHERS               = "OTHERS";
    static final String        T_OVERRIDING           = "OVERRIDING";
    public static final String T_P_FACTOR             = "P";
    static final String        T_PAD                  = "PAD";
    static final String        T_PARAMETER_MODE       = "PARAMETER_MODE";
    static final String        T_PARAMETER_NAME       = "PARAMETER_NAME";
    static final String T_PARAMETER_ORDINAL_POSITION =
        "PARAMETER_ORDINAL_POSITION";
    static final String T_PARAMETER_SPECIFIC_CATALOG =
        "PARAMETER_SPECIFIC_CATALOG";
    static final String T_PARAMETER_SPEC_NAME = "PARAMETER_SPECIFIC_NAME";
    static final String T_PARAMETER_SPEC_SCHEMA = "PARAMETER_SPECIFIC_SCHEMA";
    static final String        T_PARTIAL              = "PARTIAL";
    static final String        T_PASCAL               = "PASCAL";
    static final String        T_PATH                 = "PATH";
    static final String        T_PLACING              = "PLACING";
    static final String        T_PLI                  = "PLI";
    static final String        T_PRECEDING            = "PRECEDING";
    static final String        T_PRESERVE             = "PRESERVE";
    static final String        T_PRIOR                = "PRIOR";
    static final String        T_PRIVILEGES           = "PRIVILEGES";
    static final String        T_PUBLIC               = "PUBLIC";
    static final String        T_READ                 = "READ";
    static final String        T_RELATIVE             = "RELATIVE";
    static final String        T_REPEATABLE           = "REPEATABLE";
    static final String        T_RESTART              = "RESTART";
    static final String        T_RETURNED_CARDINALITY = "RETURNED_CARDINALITY";
    static final String        T_RETURNED_LENGTH      = "RETURNED_LENGTH";
    static final String T_RETURNED_OCTET_LENGTH = "RETURNED_OCTET_LENGTH";
    static final String        T_RETURNED_SQLSTATE    = "RETURNED_SQLSTATE";
    public static final String T_ROLE                 = "ROLE";
    static final String        T_ROUTINE              = "ROUTINE";
    static final String        T_ROUTINE_CATALOG      = "ROUTINE_CATALOG";
    static final String        T_ROUTINE_NAME         = "ROUTINE_NAME";
    static final String        T_ROUTINE_SCHEMA       = "ROUTINE_SCHEMA";
    static final String        T_ROW_COUNT            = "ROW_COUNT";
    static final String        T_SCALE                = "SCALE";
    public static final String T_SCHEMA               = "SCHEMA";
    static final String        T_SCHEMA_NAME          = "SCHEMA_NAME";
    static final String        T_SCOPE_CATALOG        = "SCOPE_CATALOG";
    static final String        T_SCOPE_NAME           = "SCOPE_NAME";
    static final String        T_SCOPE_SCHEMA         = "SCOPE_SCHEMA";
    static final String        T_SECTION              = "SECTION";
    static final String        T_SECURITY             = "SECURITY";
    static final String        T_SELF                 = "SELF";
    static final String        T_SEQUENCE             = "SEQUENCE";
    static final String        T_SERIALIZABLE         = "SERIALIZABLE";
    static final String        T_SERVER_NAME          = "SERVER_NAME";
    public static final String T_SESSION              = "SESSION";
    static final String        T_SETS                 = "SETS";
    static final String        T_SIMPLE               = "SIMPLE";
    static final String        T_SIZE                 = "SIZE";
    static final String        T_SOURCE               = "SOURCE";
    static final String        T_SPACE                = "SPACE";
    static final String        T_SPECIFIC_NAME        = "SPECIFIC_NAME";
    static final String        T_SQLDATA              = "SQLDATA";      
    static final String        T_STACKED              = "STACKED";
    static final String        T_STATE                = "STATE";
    static final String        T_STATEMENT            = "STATEMENT";
    static final String        T_STRUCTURE            = "STRUCTURE";
    static final String        T_STYLE                = "STYLE";
    static final String        T_SUBCLASS_ORIGIN      = "SUBCLASS_ORIGIN";
    public static final String T_T_FACTOR             = "T";
    static final String        T_TABLE_NAME           = "TABLE_NAME";
    static final String        T_TEMPORARY            = "TEMPORARY";
    static final String        T_TIES                 = "TIES";
    static final String        T_TOP_LEVEL_COUNT      = "TOP_LEVEL_COUNT";
    static final String        T_TRANSACTION          = "TRANSACTION";
    static final String        T_TRANSACT_COMMITTED = "TRANSACTIONS_COMMITTED";
    static final String T_TRANSACTION_ROLLED_BACK = "TRANSACTIONS_ROLLED_BACK";
    static final String        T_TRANSACT_ACTIVE      = "TRANSACTION_ACTIVE";
    static final String        T_TRANSFORM            = "TRANSFORM";
    static final String        T_TRANSFORMS           = "TRANSFORMS";
    static final String        T_TRIGGER_CATALOG      = "TRIGGER_CATALOG";
    static final String        T_TRIGGER_NAME         = "TRIGGER_NAME";
    static final String        T_TRIGGER_SCHEMA       = "TRIGGER_SCHEMA";
    public static final String T_TYPE                 = "TYPE";
    static final String        T_UNBOUNDED            = "UNBOUNDED";
    static final String        T_UNCOMMITTED          = "UNCOMMITTED";
    static final String        T_UNDER                = "UNDER";
    static final String        T_UNDO                 = "UNDO";
    static final String        T_UNNAMED              = "UNNAMED";
    public static final String T_USAGE                = "USAGE";
    static final String T_USER_DEFINED_TYPE_CATALOG =
        "USER_DEFINED_TYPE_CATALOG";
    static final String T_USER_DEFINED_TYPE_CODE = "USER_DEFINED_TYPE_CODE";
    static final String T_USER_DEFINED_TYPE_NAME = "USER_DEFINED_TYPE_NAME";
    static final String T_USER_DEFINED_TYPE_SCHEMA =
        "USER_DEFINED_TYPE_SCHEMA";
    static final String        T_VIEW  = "VIEW";
    static final String        T_WORK  = "WORK";
    static final String        T_WRITE = "WRITE";
    public static final String T_ZONE  = "ZONE";

    
    static final String        T_ADD                 = "ADD";
    static final String        T_ALIAS               = "ALIAS";
    static final String        T_AUTOCOMMIT          = "AUTOCOMMIT";
    static final String        T_BACKUP              = "BACKUP";
    public static final String T_BIT                 = "BIT";
    static final String        T_BITLENGTH           = "BITLENGTH";
    static final String        T_CACHE               = "CACHE";
    static final String        T_CACHED              = "CACHED";
    static final String        T_CASEWHEN            = "CASEWHEN";
    static final String        T_CHECKPOINT          = "CHECKPOINT";
    static final String        T_CLASS               = "CLASS";
    static final String        T_COMPACT             = "COMPACT";
    public static final String T_COMPRESSED          = "COMPRESSED";
    static final String        T_CONTROL             = "CONTROL";
    static final String        T_CURDATE             = "CURDATE";
    static final String        T_CURTIME             = "CURTIME";
    static final String        T_DATABASE            = "DATABASE";
    static final String        T_DEFRAG              = "DEFRAG";
    static final String        T_EXPLAIN             = "EXPLAIN";
    static final String        T_EVENT               = "EVENT";
    static final String        T_FILE                = "FILE";
    static final String        T_FILES               = "FILES";
    static final String        T_FOLD                = "FOLD";
    static final String        T_GENERATED           = "GENERATED";
    static final String        T_HEADER              = "HEADER";
    static final String        T_IFNULL              = "IFNULL";
    static final String        T_IGNORECASE          = "IGNORECASE";
    static final String        T_IMMEDIATELY         = "IMMEDIATELY";
    public static final String T_INDEX               = "INDEX";
    public static final String T_INITIAL             = "INITIAL";
    static final String        T_ISAUTOCOMMIT        = "ISAUTOCOMMIT";
    static final String        T_ISREADONLYDATABASE  = "ISREADONLYDATABASE";
    static final String T_ISREADONLYDATABASEFILES = "ISREADONLYDATABASEFILES";
    static final String        T_ISREADONLYSESSION   = "ISREADONLYSESSION";
    static final String        T_LIMIT               = "LIMIT";
    static final String        T_LOCK                = "LOCK";
    static final String        T_LOCKS               = "LOCKS";
    static final String        T_LOGSIZE             = "LOGSIZE";
    static final String        T_MAXROWS             = "MAXROWS";
    static final String        T_MEMORY              = "MEMORY";
    
    static final String        T_MICROS              = "MICROS";         
    static final String        T_MICROSECOND         = "MICROSECOND";    
    
    static final String        T_MILLIS              = "MILLIS";
    
    static final String        T_MILLISECOND         = "MILLISECOND";    
    
    static final String        T_MINUS_EXCEPT        = "MINUS";
    static final String        T_MVCC                = "MVCC";
    static final String        T_NIO                 = "NIO";
    static final String        T_NOW                 = "NOW";
    static final String        T_NOWAIT              = "NOWAIT";
    static final String        T_NVL                 = "NVL";
    static final String        T_OCTETLENGTH         = "OCTETLENGTH";
    static final String        T_OFF                 = "OFF";
    public static final String T_OTHER               = "OTHER";
    public static final String T_PASSWORD            = "PASSWORD";
    static final String        T_PLAN                = "PLAN";
    static final String        T_PROPERTY            = "PROPERTY";
    static final String        T_QUEUE               = "QUEUE";
    static final String        T_READONLY            = "READONLY";
    static final String T_REFERENTIAL_INTEGRITY      = "REFERENTIAL_INTEGRITY";
    static final String        T_RENAME              = "RENAME";
    static final String        T_RESTRICT            = "RESTRICT";
    static final String        T_SCRIPT              = "SCRIPT";
    static final String        T_SCRIPTFORMAT        = "SCRIPTFORMAT";
    static final String        T_BLOCKING            = "BLOCKING";
    static final String        T_SHUTDOWN            = "SHUTDOWN";
    static final String        T_SQL_TSI_DAY         = "SQL_TSI_DAY";
    static final String        T_SQL_TSI_FRAC_SECOND = "SQL_TSI_FRAC_SECOND";
    static final String        T_SQL_TSI_HOUR        = "SQL_TSI_HOUR";
    static final String        T_SQL_TSI_MINUTE      = "SQL_TSI_MINUTE";
    static final String        T_SQL_TSI_MONTH       = "SQL_TSI_MONTH";
    static final String        T_SQL_TSI_QUARTER     = "SQL_TSI_QUARTER";
    static final String        T_SQL_TSI_SECOND      = "SQL_TSI_SECOND";
    static final String        T_SQL_TSI_WEEK        = "SQL_TSI_WEEK";
    static final String        T_SQL_TSI_YEAR        = "SQL_TSI_YEAR";
    static final String        T_SQL_BIGINT          = "SQL_BIGINT";
    static final String        T_SQL_BINARY          = "SQL_BINARY";
    static final String        T_SQL_BIT             = "SQL_BIT";
    static final String        T_SQL_BLOB            = "SQL_BLOB";
    static final String        T_SQL_BOOLEAN         = "SQL_BOOLEAN";
    static final String        T_SQL_CHAR            = "SQL_CHAR";
    static final String        T_SQL_CLOB            = "SQL_CLOB";
    static final String        T_SQL_DATE            = "SQL_DATE";
    static final String        T_SQL_DECIMAL         = "SQL_DECIMAL";
    static final String        T_SQL_DATALINK        = "SQL_DATALINK";
    static final String        T_SQL_DOUBLE          = "SQL_DOUBLE";
    static final String        T_SQL_FLOAT           = "SQL_FLOAT";
    static final String        T_SQL_INTEGER         = "SQL_INTEGER";
    static final String        T_SQL_LONGVARBINARY   = "SQL_LONGVARBINARY";
    static final String        T_SQL_LONGNVARCHAR    = "SQL_LONGNVARCHAR";
    static final String        T_SQL_LONGVARCHAR     = "SQL_LONGVARCHAR";
    static final String        T_SQL_NCHAR           = "SQL_NCHAR";
    static final String        T_SQL_NCLOB           = "SQL_NCLOB";
    static final String        T_SQL_NUMERIC         = "SQL_NUMERIC";
    static final String        T_SQL_NVARCHAR        = "SQL_NVARCHAR";
    static final String        T_SQL_REAL            = "SQL_REAL";
    static final String        T_SQL_ROWID           = "SQL_ROWID";
    static final String        T_SQL_SQLXML          = "SQL_SQLXML";
    static final String        T_SQL_SMALLINT        = "SQL_SMALLINT";
    static final String        T_SQL_TIME            = "SQL_TIME";
    static final String        T_SQL_TIMESTAMP       = "SQL_TIMESTAMP";
    static final String        T_SQL_TINYINT         = "SQL_TINYINT";
    static final String        T_SQL_VARBINARY       = "SQL_VARBINARY";
    static final String        T_SQL_VARCHAR         = "SQL_VARCHAR";
    static final String        T_SYSDATE             = "SYSDATE";
    static final String        T_TEMP                = "TEMP";
    public static final String T_TEXT                = "TEXT";
    static final String        T_TIMESTAMPADD        = "TIMESTAMPADD";
    static final String        T_TIMESTAMPDIFF       = "TIMESTAMPDIFF";
    public static final String T_TINYINT             = "TINYINT";
    static final String        T_TO_CHAR             = "TO_CHAR";
    static final String        T_TODAY               = "TODAY";
    static final String        T_TOP                 = "TOP";
    public static final String T_VARCHAR_IGNORECASE  = "VARCHAR_IGNORECASE";
    static final String        T_WRITE_DELAY         = "WRITE_DELAY";
    public static final String T_YES                 = "YES";
    public static final String T_DAY_NAME            = "DAY_NAME";
    public static final String T_MONTH_NAME          = "MONTH_NAME";
    public static final String T_QUARTER             = "QUARTER";
    public static final String T_DAY_OF_WEEK         = "DAY_OF_WEEK";
    public static final String T_DAY_OF_MONTH        = "DAY_OF_MONTH";
    public static final String T_DAY_OF_YEAR         = "DAY_OF_YEAR";
    public static final String T_WEEK_OF_YEAR        = "WEEK_OF_YEAR";
    static final String        T_DAYNAME             = "DAYNAME";
    static final String        T_NONTHNAME           = "NONTHNAME";
    static final String        T_DAYOFMONTH          = "DAYOFMONTH";
    static final String        T_DAYOFWEEK           = "DAYOFWEEK";
    static final String        T_DAYOFYEAR           = "DAYOFYEAR";
    static final String        T_WEEK                = "WEEK";
    
    static final String        T_WEEKOFYEAR          = "WEEKOFYEAR"; 
    static final String        T_WEEKDAY             = "WEEKDAY";    
    

    
    static final String        T_ACOS             = "ACOS";
    static final String        T_ASIN             = "ASIN";
    static final String        T_ATAN             = "ATAN";
    static final String        T_ATAN2            = "ATAN2";
    static final String        T_COS              = "COS";
    static final String        T_COT              = "COT";
    static final String        T_DEGREES          = "DEGREES";
    static final String        T_DMOD             = "DMOD";
    static final String        T_LOG              = "LOG";
    static final String        T_LOG10            = "LOG10";
    static final String        T_PI               = "PI";
    static final String        T_RADIANS          = "RADIANS";
    static final String        T_RAND             = "RAND";
    static final String        T_ROUND            = "ROUND";
    static final String        T_SIGN             = "SIGN";
    static final String        T_SIN              = "SIN";
    static final String        T_TAN              = "TAN";
    static final String        T_BITAND           = "BITAND";
    static final String        T_BITOR            = "BITOR";
    static final String        T_BITXOR           = "BITXOR";
    
    static final String        T_CONCAT_WORD      = "CONCAT";
    
    static final String        T_ROUNDMAGIC       = "ROUNDMAGIC";
    static final String        T_ASCII            = "ASCII";
    
    
    
    static final String        T_DIFFERENCE       = "DIFFERENCE";
    static final String        T_HEXTORAW         = "HEXTORAW";
    static final String        T_LCASE            = "LCASE";
    static final String        T_LOCATE           = "LOCATE";
    static final String        T_LTRIM            = "LTRIM";
    static final String        T_RAWTOHEX         = "RAWTOHEX";
    static final String        T_REPLACE          = "REPLACE";
    static final String        T_RTRIM            = "RTRIM";
    static final String        T_SOUNDEX          = "SOUNDEX";
    static final String        T_SPACE_WORD       = "SPACE_WORD";
    static final String        T_SUBSTR           = "SUBSTR";
    static final String        T_UCASE            = "UCASE";
    static final String        T_DATEDIFF         = "DATEDIFF";
    public static final String T_SECONDS_MIDNIGHT = "SECONDS_SINCE_MIDNIGHT";

    
    
    
    public static final int ABS                              = 1;
    public static final int ALL                              = 2;
    public static final int ALLOCATE                         = 3;
    public static final int ALTER                            = 4;
    public static final int AND                              = 5;
    public static final int ANY                              = 6;
    public static final int ARE                              = 7;
    public static final int ARRAY                            = 8;
    public static final int AS                               = 9;
    public static final int ASENSITIVE                       = 10;
    public static final int ASYMMETRIC                       = 11;
    public static final int AT                               = 12;
    public static final int ATOMIC                           = 13;
    public static final int AUTHORIZATION                    = 14;
    public static final int AVG                              = 15;
    public static final int BEGIN                            = 16;
    public static final int BETWEEN                          = 17;
    public static final int BIGINT                           = 18;
    public static final int BINARY                           = 19;
    public static final int BLOB                             = 20;
    public static final int BOOLEAN                          = 21;
    public static final int BOTH                             = 22;
    public static final int BY                               = 23;
    public static final int CALL                             = 24;
    public static final int CALLED                           = 25;
    public static final int CARDINALITY                      = 26;
    public static final int CASCADED                         = 27;
    public static final int CASE                             = 28;
    public static final int CAST                             = 29;
    public static final int CEIL                             = 30;
    public static final int CEILING                          = 31;
    public static final int CHAR                             = 32;
    public static final int CHAR_LENGTH                      = 33;
    public static final int CHARACTER                        = 34;
    public static final int CHARACTER_LENGTH                 = 35;
    public static final int CHECK                            = 36;
    public static final int CLOB                             = 37;
    public static final int CLOSE                            = 38;
    public static final int COALESCE                         = 39;
    public static final int COLLATE                          = 40;
    public static final int COLLECT                          = 41;
    public static final int COLUMN                           = 42;
    public static final int COMMIT                           = 43;
    public static final int COMPARABLE                       = 44;
    public static final int CONDITION                        = 45;
    public static final int CONNECT                          = 46;
    public static final int CONSTRAINT                       = 47;
    public static final int CONVERT                          = 48;
    public static final int CORR                             = 49;
    public static final int CORRESPONDING                    = 50;
    public static final int COUNT                            = 51;
    
    public static final int APPROX_COUNT_DISTINCT            = 1304;
    
    public static final int COVAR_POP                        = 52;
    public static final int COVAR_SAMP                       = 53;
    public static final int CREATE                           = 54;
    public static final int CROSS                            = 55;
    public static final int CUBE                             = 56;
    public static final int CUME_DIST                        = 57;
    public static final int CURRENT                          = 58;
    public static final int CURRENT_CATALOG                  = 59;
    public static final int CURRENT_DATE                     = 60;
    public static final int CURRENT_DEFAULT_TRANSFORM_GROUP  = 61;
    public static final int CURRENT_PATH                     = 62;
    public static final int CURRENT_ROLE                     = 63;
    public static final int CURRENT_SCHEMA                   = 64;
    public static final int CURRENT_TIME                     = 65;
    public static final int CURRENT_TIMESTAMP                = 66;
    public static final int CURRENT_TRANSFORM_GROUP_FOR_TYPE = 67;
    public static final int CURRENT_USER                     = 68;
    public static final int CURSOR                           = 69;
    public static final int CYCLE                            = 70;
    public static final int DATE                             = 71;
    public static final int DAY                              = 72;
    public static final int DEALLOCATE                       = 73;
    public static final int DEC                              = 74;
    public static final int DECIMAL                          = 75;
    public static final int DECLARE                          = 76;
    public static final int DEFAULT                          = 77;
    public static final int DELETE                           = 78;
    public static final int DENSE_RANK                       = 79;
    public static final int DEREF                            = 80;
    public static final int DESCRIBE                         = 81;
    public static final int DETERMINISTIC                    = 82;
    public static final int DISCONNECT                       = 83;
    public static final int DISTINCT                         = 84;
    public static final int DO                               = 85;
    public static final int DOUBLE                           = 86;
    public static final int DROP                             = 87;
    public static final int DYNAMIC                          = 88;
    public static final int EACH                             = 89;
    public static final int ELEMENT                          = 90;
    public static final int ELSE                             = 91;
    public static final int ELSEIF                           = 92;
    public static final int END                              = 93;
    public static final int END_EXEC                         = 94;
    public static final int ESCAPE                           = 95;
    public static final int EVERY                            = 96;
    public static final int EXCEPT                           = 97;
    public static final int EXEC                             = 98;
    public static final int EXECUTE                          = 99;
    public static final int EXISTS                           = 100;
    public static final int EXIT                             = 101;
    public static final int EXP                              = 102;
    public static final int EXTERNAL                         = 103;
    public static final int EXTRACT                          = 104;
    public static final int FALSE                            = 105;
    public static final int FETCH                            = 106;
    public static final int FILTER                           = 107;
    public static final int FIRST_VALUE                      = 108;
    public static final int FLOAT                            = 109;
    public static final int FLOOR                            = 110;
    public static final int FOR                              = 111;
    public static final int FOREIGN                          = 112;
    public static final int FREE                             = 113;
    public static final int FROM                             = 114;
    public static final int FULL                             = 115;
    public static final int FUNCTION                         = 116;
    public static final int FUSION                           = 117;
    public static final int GET                              = 118;
    public static final int GLOBAL                           = 119;
    public static final int GRANT                            = 120;
    public static final int GROUP                            = 121;
    public static final int GROUPING                         = 122;
    public static final int HANDLER                          = 123;
    public static final int HAVING                           = 124;
    public static final int HOLD                             = 125;
    public static final int HOUR                             = 126;
    public static final int IDENTITY                         = 127;
    public static final int IN                               = 128;
    public static final int INDICATOR                        = 129;
    public static final int INNER                            = 130;
    public static final int INOUT                            = 131;
    public static final int INSENSITIVE                      = 132;
    public static final int INSERT                           = 133;
    public static final int INT                              = 134;
    public static final int INTEGER                          = 135;
    public static final int INTERSECT                        = 136;
    public static final int INTERSECTION                     = 137;
    public static final int INTERVAL                         = 138;
    public static final int INTO                             = 139;
    public static final int IS                               = 140;
    public static final int ITERATE                          = 141;
    public static final int JOIN                             = 142;
    public static final int LAG                              = 143;
    public static final int LANGUAGE                         = 144;
    public static final int LARGE                            = 145;
    public static final int LAST_VALUE                       = 146;
    public static final int LATERAL                          = 147;
    public static final int LEAD                             = 148;
    public static final int LEADING                          = 149;
    public static final int LEAVE                            = 150;
    public static final int LEFT                             = 151;
    public static final int LIKE                             = 152;
    public static final int LIKE_REGEX                       = 153;
    public static final int LN                               = 154;
    public static final int LOCAL                            = 155;
    public static final int LOCALTIME                        = 156;
    public static final int LOCALTIMESTAMP                   = 157;
    public static final int LOOP                             = 158;
    public static final int LOWER                            = 159;
    public static final int MATCH                            = 160;
    public static final int MAX                              = 161;
    public static final int MAX_CARDINALITY                  = 162;
    public static final int MEMBER                           = 163;
    public static final int MERGE                            = 164;
    public static final int METHOD                           = 165;
    public static final int MIN                              = 166;
    public static final int MINUTE                           = 167;
    public static final int MOD                              = 168;
    public static final int MODIFIES                         = 169;
    public static final int MODULE                           = 170;
    public static final int MONTH                            = 171;
    public static final int MULTISET                         = 172;
    public static final int NATIONAL                         = 173;
    public static final int NATURAL                          = 174;
    public static final int NCHAR                            = 175;
    public static final int NCLOB                            = 176;
    public static final int NEW                              = 177;
    public static final int NO                               = 178;
    public static final int NONE                             = 179;
    public static final int NORMALIZE                        = 180;
    public static final int NOT                              = 181;
    public static final int NTH_VALUE                        = 182;
    public static final int NTILE                            = 183;
    public static final int NULL                             = 184;
    public static final int NULLIF                           = 185;
    public static final int NUMERIC                          = 186;
    public static final int OCCURRENCES_REGEX                = 187;
    public static final int OCTET_LENGTH                     = 188;
    public static final int OF                               = 189;
    public static final int OFFSET                           = 190;
    public static final int OLD                              = 191;
    public static final int ON                               = 192;
    public static final int ONLY                             = 193;
    public static final int OPEN                             = 194;
    public static final int OR                               = 195;
    public static final int ORDER                            = 196;
    public static final int OUT                              = 197;
    public static final int OUTER                            = 198;
    public static final int OVER                             = 199;
    public static final int OVERLAPS                         = 200;
    public static final int OVERLAY                          = 201;
    public static final int PARAMETER                        = 202;
    public static final int PARTITION                        = 203;
    public static final int PERCENT_RANK                     = 204;
    public static final int PERCENTILE_CONT                  = 205;
    public static final int PERCENTILE_DISC                  = 206;
    public static final int POSITION                         = 207;
    public static final int POSITION_REGEX                   = 208;
    public static final int POWER                            = 209;
    public static final int PRECISION                        = 210;
    public static final int PREPARE                          = 211;
    public static final int PRIMARY                          = 212;
    public static final int PROCEDURE                        = 213;
    public static final int RANGE                            = 214;
    public static final int RANK                             = 215;
    public static final int READS                            = 216;
    public static final int REAL                             = 217;
    public static final int RECURSIVE                        = 218;
    public static final int REF                              = 219;
    public static final int REFERENCES                       = 220;
    public static final int REFERENCING                      = 221;
    public static final int REGR_AVGX                        = 222;
    public static final int REGR_AVGY                        = 223;
    public static final int REGR_COUNT                       = 224;
    public static final int REGR_INTERCEPT                   = 225;
    public static final int REGR_R2                          = 226;
    public static final int REGR_SLOPE                       = 227;
    public static final int REGR_SXX                         = 228;
    public static final int REGR_SXY                         = 229;
    public static final int REGR_SYY                         = 230;
    public static final int RELEASE                          = 231;
    public static final int REPEAT                           = 232;
    public static final int RESIGNAL                         = 233;
    public static final int RESULT                           = 234;
    public static final int RETURN                           = 235;
    public static final int RETURNS                          = 236;
    public static final int REVOKE                           = 237;
    public static final int RIGHT                            = 238;
    public static final int ROLLBACK                         = 239;
    public static final int ROLLUP                           = 240;
    public static final int ROW                              = 241;
    public static final int ROW_NUMBER                       = 242;
    public static final int ROWS                             = 243;
    public static final int SAVEPOINT                        = 244;
    public static final int SCOPE                            = 245;
    public static final int SCROLL                           = 246;
    public static final int SEARCH                           = 247;
    public static final int SECOND                           = 248;
    public static final int SELECT                           = 249;
    public static final int SENSITIVE                        = 250;
    public static final int SESSION_USER                     = 251;
    public static final int SET                              = 252;
    public static final int SIGNAL                           = 253;
    public static final int SIMILAR                          = 254;
    public static final int SMALLINT                         = 255;
    public static final int SOME                             = 256;
    public static final int SPECIFIC                         = 257;
    public static final int SPECIFICTYPE                     = 258;
    public static final int SQL                              = 259;
    public static final int SQLEXCEPTION                     = 260;
    public static final int SQLSTATE                         = 261;
    public static final int SQLWARNING                       = 262;
    public static final int SQRT                             = 263;
    public static final int STACKED                          = 264;
    public static final int START                            = 265;
    public static final int STATIC                           = 266;
    public static final int STDDEV_POP                       = 267;
    public static final int STDDEV_SAMP                      = 268;
    public static final int SUBMULTISET                      = 269;
    public static final int SUBSTRING                        = 270;
    public static final int SUBSTRING_REGEX                  = 271;
    public static final int SUM                              = 272;
    public static final int SYMMETRIC                        = 273;
    public static final int SYSTEM                           = 274;
    public static final int SYSTEM_USER                      = 275;
    public static final int TABLE                            = 276;
    public static final int TABLESAMPLE                      = 277;
    public static final int THEN                             = 278;
    public static final int TIME                             = 279;
    public static final int TIMESTAMP                        = 280;
    public static final int TIMEZONE_HOUR                    = 281;
    public static final int TIMEZONE_MINUTE                  = 282;
    public static final int TO                               = 283;
    public static final int TRAILING                         = 284;
    public static final int TRANSLATE                        = 285;
    public static final int TRANSLATE_REGEX                  = 286;
    public static final int TRANSLATION                      = 287;
    public static final int TREAT                            = 288;
    public static final int TRIGGER                          = 289;
    public static final int TRIM                             = 290;
    public static final int TRIM_ARRAY                       = 291;
    public static final int TRUE                             = 292;
    public static final int TRUNCATE                         = 293;
    public static final int UESCAPE                          = 294;
    public static final int UNDO                             = 295;
    public static final int UNION                            = 296;
    public static final int UNIQUE                           = 297;
    
    public static final int ASSUMEUNIQUE                     = 1303;    
    
    public static final int UNKNOWN                          = 298;
    public static final int UNNEST                           = 299;
    public static final int UNTIL                            = 300;
    public static final int UPDATE                           = 301;
    public static final int UPPER                            = 302;
    public static final int USER                             = 303;
    public static final int USING                            = 304;
    public static final int VALUE                            = 305;
    public static final int VALUES                           = 306;
    public static final int VAR_POP                          = 307;
    public static final int VAR_SAMP                         = 308;
    public static final int VARBINARY                        = 309;
    public static final int VARCHAR                          = 310;
    public static final int VARYING                          = 311;
    public static final int WHEN                             = 312;
    public static final int WHENEVER                         = 313;
    public static final int WHERE                            = 314;
    public static final int WIDTH_BUCKET                     = 315;
    public static final int WINDOW                           = 316;
    public static final int WITH                             = 317;
    public static final int WITHIN                           = 318;
    public static final int WITHOUT                          = 319;
    public static final int WHILE                            = 320;
    public static final int YEAR                             = 321;

    
    public static final int A                           = 330;
    public static final int ABSOLUTE                    = 331;
    public static final int ACTION                      = 332;
    public static final int ADA                         = 333;
    public static final int ADD                         = 334;
    public static final int ADMIN                       = 335;
    public static final int AFTER                       = 336;
    public static final int ALWAYS                      = 337;
    public static final int ASC                         = 338;
    public static final int ASSERTION                   = 339;
    public static final int ASSIGNMENT                  = 340;
    public static final int ATTRIBUTE                   = 341;
    public static final int ATTRIBUTES                  = 342;
    public static final int BEFORE                      = 343;
    public static final int BERNOULLI                   = 344;
    public static final int BREADTH                     = 345;
    public static final int C                           = 346;
    public static final int CASCADE                     = 347;
    public static final int CATALOG                     = 348;
    public static final int CATALOG_NAME                = 349;
    public static final int CHAIN                       = 350;
    public static final int CHARACTER_SET_CATALOG       = 351;
    public static final int CHARACTER_SET_NAME          = 352;
    public static final int CHARACTER_SET_SCHEMA        = 353;
    public static final int CHARACTERISTICS             = 354;
    public static final int CHARACTERS                  = 355;
    public static final int CLASS_ORIGIN                = 356;
    public static final int COBOL                       = 357;
    public static final int COLLATION                   = 358;
    public static final int COLLATION_CATALOG           = 359;
    public static final int COLLATION_NAME              = 360;
    public static final int COLLATION_SCHEMA            = 361;
    public static final int COLUMN_NAME                 = 362;
    public static final int COMMAND_FUNCTION            = 363;
    public static final int COMMAND_FUNCTION_CODE       = 364;
    public static final int COMMITTED                   = 365;
    public static final int CONDITION_IDENTIFIER        = 366;
    public static final int CONDITION_NUMBER            = 367;
    public static final int CONNECTION                  = 368;
    public static final int CONNECTION_NAME             = 369;
    public static final int CONSTRAINT_CATALOG          = 370;
    public static final int CONSTRAINT_NAME             = 371;
    public static final int CONSTRAINT_SCHEMA           = 372;
    public static final int CONSTRAINTS                 = 373;
    public static final int CONSTRUCTOR                 = 374;
    public static final int CONTAINS                    = 375;
    public static final int CONTINUE                    = 376;
    public static final int CURSOR_NAME                 = 377;
    public static final int DATA                        = 378;
    public static final int DATETIME_INTERVAL_CODE      = 379;
    public static final int DATETIME_INTERVAL_PRECISION = 380;
    public static final int DEFAULTS                    = 381;
    public static final int DEFERRABLE                  = 382;
    public static final int DEFERRED                    = 383;
    public static final int DEFINED                     = 384;
    public static final int DEFINER                     = 385;
    public static final int DEGREE                      = 386;
    public static final int DEPTH                       = 387;
    public static final int DERIVED                     = 388;
    public static final int DESC                        = 389;
    public static final int DESCRIPTOR                  = 390;
    public static final int DIAGNOSTICS                 = 391;
    public static final int DISPATCH                    = 392;
    public static final int DOMAIN                      = 393;
    public static final int DYNAMIC_FUNCTION            = 394;
    public static final int DYNAMIC_FUNCTION_CODE       = 395;
    public static final int EQUALS                      = 396;
    public static final int EXCEPTION                   = 397;
    public static final int EXCLUDE                     = 398;
    public static final int EXCLUDING                   = 399;
    public static final int FINAL                       = 400;
    public static final int FIRST                       = 401;
    public static final int FOLLOWING                   = 402;
    public static final int FORTRAN                     = 403;
    public static final int FOUND                       = 404;
    public static final int G                           = 405;
    public static final int GENERAL                     = 406;
    public static final int GENERATED                   = 407;
    public static final int GO                          = 408;
    public static final int GOTO                        = 409;
    public static final int GRANTED                     = 410;
    public static final int HIERARCHY                   = 411;
    public static final int IF                          = 412;
    public static final int IGNORE                      = 413;
    public static final int IMMEDIATE                   = 414;
    public static final int IMPLEMENTATION              = 415;
    public static final int INCLUDING                   = 416;
    public static final int INCREMENT                   = 417;
    public static final int INITIALLY                   = 418;
    public static final int INPUT                       = 419;
    public static final int INSTANCE                    = 420;
    public static final int INSTANTIABLE                = 421;
    public static final int INSTEAD                     = 422;
    public static final int INVOKER                     = 423;
    public static final int ISOLATION                   = 424;
    public static final int JAVA                        = 425;
    public static final int K                           = 426;
    public static final int KEY                         = 427;
    public static final int KEY_MEMBER                  = 428;
    public static final int KEY_TYPE                    = 429;
    public static final int LAST                        = 430;
    public static final int LENGTH                      = 431;
    public static final int LEVEL                       = 432;
    public static final int LOCATOR                     = 433;
    public static final int M                           = 434;
    public static final int MAP                         = 435;
    public static final int MATCHED                     = 436;
    public static final int MAXVALUE                    = 437;
    public static final int MESSAGE_LENGTH              = 438;
    public static final int MESSAGE_OCTET_LENGTH        = 439;
    public static final int MESSAGE_TEXT                = 440;
    public static final int MINVALUE                    = 441;
    public static final int MORE                        = 442;
    public static final int MUMPS                       = 443;
    public static final int NAME                        = 444;
    public static final int NAMES                       = 445;
    public static final int NESTING                     = 446;
    public static final int NEXT                        = 447;
    public static final int NORMALIZED                  = 448;
    public static final int NULLABLE                    = 449;
    public static final int NULLS                       = 450;
    public static final int NUMBER                      = 451;
    public static final int OBJECT                      = 452;
    public static final int OCTETS                      = 453;
    public static final int OPTION                      = 454;
    public static final int OPTIONS                     = 455;
    public static final int ORDERING                    = 456;
    public static final int ORDINALITY                  = 457;
    public static final int OTHERS                      = 458;
    public static final int OUTPUT                      = 459;
    public static final int OVERRIDING                  = 460;
    public static final int PAD                         = 461;
    public static final int PARAMETER_MODE              = 462;
    public static final int PARAMETER_NAME              = 463;
    public static final int PARAMETER_ORDINAL_POSITION  = 464;
    public static final int PARAMETER_SPECIFIC_CATALOG  = 465;
    public static final int PARAMETER_SPECIFIC_NAME     = 466;
    public static final int PARAMETER_SPECIFIC_SCHEMA   = 467;
    public static final int PARTIAL                     = 468;
    public static final int PASCAL                      = 469;
    public static final int PATH                        = 470;
    public static final int PLACING                     = 471;
    public static final int PLI                         = 472;
    public static final int PRECEDING                   = 473;
    public static final int PRESERVE                    = 474;
    public static final int PRIOR                       = 475;
    public static final int PRIVILEGES                  = 476;
    public static final int PUBLIC                      = 477;
    public static final int READ                        = 478;
    public static final int RELATIVE                    = 479;
    public static final int REPEATABLE                  = 480;
    public static final int RESPECT                     = 481;
    public static final int RESTART                     = 482;
    public static final int RESTRICT                    = 483;
    public static final int RETURNED_CARDINALITY        = 484;
    public static final int RETURNED_LENGTH             = 485;
    public static final int RETURNED_OCTET_LENGTH       = 486;
    public static final int RETURNED_SQLSTATE           = 487;
    public static final int ROLE                        = 488;
    public static final int ROUTINE                     = 489;
    public static final int ROUTINE_CATALOG             = 490;
    public static final int ROUTINE_NAME                = 491;
    public static final int ROUTINE_SCHEMA              = 492;
    public static final int ROW_COUNT                   = 493;
    public static final int SCALE                       = 494;
    public static final int SCHEMA                      = 495;
    public static final int SCHEMA_NAME                 = 496;
    public static final int SCOPE_CATALOG               = 497;
    public static final int SCOPE_NAME                  = 498;
    public static final int SCOPE_SCHEMA                = 499;
    public static final int SECTION                     = 500;
    public static final int SECURITY                    = 501;
    public static final int SELF                        = 502;
    public static final int SEQUENCE                    = 503;
    public static final int SERIALIZABLE                = 504;
    public static final int SERVER_NAME                 = 505;
    public static final int SESSION                     = 506;
    public static final int SETS                        = 507;
    public static final int SIMPLE                      = 508;
    public static final int SIZE                        = 509;
    public static final int SOURCE                      = 510;
    public static final int SPACE                       = 511;
    public static final int SPECIFIC_NAME               = 512;
    public static final int STATE                       = 513;
    public static final int STATEMENT                   = 514;
    public static final int STRUCTURE                   = 515;
    public static final int STYLE                       = 516;
    public static final int SUBCLASS_ORIGIN             = 517;
    public static final int TABLE_NAME                  = 518;
    public static final int TEMPORARY                   = 519;
    public static final int TIES                        = 520;
    public static final int TOP_LEVEL_COUNT             = 521;
    public static final int TRANSACTION                 = 522;
    public static final int TRANSACTION_ACTIVE          = 523;
    public static final int TRANSACTIONS_COMMITTED      = 524;
    public static final int TRANSACTIONS_ROLLED_BACK    = 525;
    public static final int TRANSFORM                   = 526;
    public static final int TRANSFORMS                  = 527;
    public static final int TRIGGER_CATALOG             = 528;
    public static final int TRIGGER_NAME                = 529;
    public static final int TRIGGER_SCHEMA              = 530;
    public static final int TYPE                        = 531;
    public static final int UNBOUNDED                   = 532;
    public static final int UNCOMMITTED                 = 533;
    public static final int UNDER                       = 534;
    public static final int UNNAMED                     = 535;
    public static final int USAGE                       = 536;
    public static final int USER_DEFINED_TYPE_CATALOG   = 537;
    public static final int USER_DEFINED_TYPE_CODE      = 538;
    public static final int USER_DEFINED_TYPE_NAME      = 539;
    public static final int USER_DEFINED_TYPE_SCHEMA    = 540;
    public static final int VIEW                        = 541;
    public static final int WORK                        = 542;
    public static final int WRITE                       = 543;
    public static final int ZONE                        = 544;

    
    public static final int P = 545;
    public static final int T = 546;

    
    static final int        ALIAS                 = 551;
    static final int        AUTOCOMMIT            = 552;
    static final int        BIT                   = 553;
    static final int        BIT_LENGTH            = 554;
    
    static final int        BYTES                 = 1010; 
    
    static final int        CACHED                = 555;
    static final int        CASEWHEN              = 556;
    static final int        CHECKPOINT            = 557;
    static final int        COMPACT               = 558;
    static final int        DATABASE              = 559;
    public static final int DAY_OF_WEEK           = 560;
    static final int        DEFRAG                = 561;
    static final int        EXPLAIN               = 562;
    static final int        HEADER                = 563;
    static final int        IGNORECASE            = 564;
    static final int        IFNULL                = 565;
    static final int        INDEX                 = 566;
    static final int        IMMEDIATELY           = 567;
    static final int        INITIAL               = 568;
    static final int        LIMIT                 = 569;
    static final int        LOGSIZE               = 570;
    static final int        MAXROWS               = 571;
    static final int        MEMORY                = 572;
    
    static final int        MICROS                = 1000; 
    static final int        MICROSECOND           = 1001; 
    
    static final int        MILLIS                = 573;
    
    static final int        MILLISECOND           = 1002; 
    
    static final int        MINUS_EXCEPT          = 574;
    static final int        NOW                   = 575;
    static final int        OFF                   = 576;
    static final int        PASSWORD              = 577;
    static final int        PLAN                  = 578;
    static final int        PROPERTY              = 579;
    static final int        READONLY              = 580;
    static final int        REFERENTIAL_INTEGRITY = 581;
    static final int        RENAME                = 582;
    static final int        SCRIPT                = 583;
    static final int        SCRIPTFORMAT          = 584;
    static final int        SEMICOLON             = 585;
    static final int        SHUTDOWN              = 586;
    static final int        TEMP                  = 587;
    static final int        TEXT                  = 588;
    static final int        TO_CHAR               = 589;
    static final int        TODAY                 = 590;
    static final int        TOP                   = 591;
    public static final int WEEK_OF_YEAR          = 592;
    static final int        WRITE_DELAY           = 593;
    static final int        COMPRESSED            = 594;
    static final int        EVENT                 = 595;
    static final int        BACKUP                = 596;
    static final int        BLOCKING              = 597;

    
    static final int        CURDATE                 = 598;
    static final int        CURTIME                 = 599;
    static final int        TIMESTAMPADD            = 600;
    static final int        TIMESTAMPDIFF           = 601;
    static final int        SYSDATE                 = 602;
    static final int        ISAUTOCOMMIT            = 603;
    static final int        ISREADONLYSESSION       = 604;
    static final int        ISREADONLYDATABASE      = 605;
    static final int        ISREADONLYDATABASEFILES = 606;
    public static final int DAY_NAME                = 607;
    public static final int MONTH_NAME              = 608;
    public static final int QUARTER                 = 609;
    public static final int DAY_OF_MONTH            = 610;
    public static final int DAY_OF_YEAR             = 611;
    static final int        DAYNAME                 = 612;
    static final int        NONTHNAME               = 613;
    static final int        DAYOFMONTH              = 614;
    static final int        DAYOFWEEK               = 615;
    static final int        DAYOFYEAR               = 616;
    
    public static final int WEEK                    = 617;
    
    
    static final int        OCTETLENGTH             = 618;
    static final int        BITLENGTH               = 619;

    
    static final int        ACOS             = 620;
    static final int        ASIN             = 621;
    static final int        ATAN             = 622;
    static final int        ATAN2            = 623;
    static final int        COS              = 624;
    static final int        COT              = 625;
    static final int        DEGREES          = 626;
    static final int        DMOD             = 627;
    static final int        LOG              = 628;
    static final int        LOG10            = 629;
    static final int        PI               = 630;
    static final int        RADIANS          = 631;
    static final int        RAND             = 632;
    static final int        ROUND            = 633;
    static final int        SIGN             = 634;
    static final int        SIN              = 635;
    static final int        TAN              = 636;
    static final int        BITAND           = 637;
    static final int        BITOR            = 638;
    static final int        BITXOR           = 639;
    static final int        ROUNDMAGIC       = 640;
    static final int        ASCII            = 641;
    static final int        CONCAT_WORD      = 642;
    static final int        DIFFERENCE       = 643;
    static final int        HEXTORAW         = 644;
    static final int        LCASE            = 645;
    static final int        LOCATE           = 646;
    static final int        LTRIM            = 647;
    static final int        RAWTOHEX         = 648;
    static final int        REPLACE          = 649;
    static final int        RTRIM            = 650;
    static final int        SOUNDEX          = 651;
    static final int        SPACE_WORD       = 652;
    static final int        SUBSTR           = 653;
    static final int        UCASE            = 654;
    static final int        DATEDIFF         = 655;
    public static final int SECONDS_MIDNIGHT = 656;

    
    static final int CONTROL = 657;
    static final int LOCK    = 658;
    static final int LOCKS   = 659;
    static final int MVCC    = 660;

    
    static final int        ASTERISK         = 661;
    static final int        CLOSEBRACKET     = 662;
    static final int        COLON            = 663;
    static final int        COMMA            = 664;
    static final int        CONCAT           = 665;
    static final int        DIVIDE           = 666;
    static final int        DOUBLE_COLON_OP  = 667;
    static final int        DOUBLE_PERIOD_OP = 668;
    static final int        DOUBLE_COLUMN_OP = 669;
    static final int        GREATER          = 670;
    static final int        GREATER_EQUALS   = 671;
    static final int        LESS             = 672;
    static final int        LESS_EQUALS      = 673;
    public static final int MINUS            = 674;
    static final int        NOT_EQUALS       = 675;
    static final int        OPENBRACKET      = 676;
    static final int        PLUS             = 677;
    static final int        QUESTION         = 678;
    static final int        RIGHT_ARROW_OP   = 679;
    static final int        DOUBLE_COLON     = 680;

    
    static final int SQL_TSI_FRAC_SECOND = 681;
    static final int SQL_TSI_SECOND      = 682;
    static final int SQL_TSI_MINUTE      = 683;
    static final int SQL_TSI_HOUR        = 684;
    static final int SQL_TSI_DAY         = 685;
    static final int SQL_TSI_WEEK        = 686;
    static final int SQL_TSI_MONTH       = 687;
    static final int SQL_TSI_QUARTER     = 688;
    static final int SQL_TSI_YEAR        = 689;

    
    static final int FILE  = 691;
    static final int FILES = 692;
    static final int CACHE = 693;
    static final int NIO = 694;

    
    static final int SQL_BIGINT        = 701;
    static final int SQL_BINARY        = 702;
    static final int SQL_BIT           = 703;
    static final int SQL_BLOB          = 704;
    static final int SQL_BOOLEAN       = 705;
    static final int SQL_CHAR          = 706;
    static final int SQL_CLOB          = 707;
    static final int SQL_DATE          = 708;
    static final int SQL_DECIMAL       = 709;
    static final int SQL_DATALINK      = 710;
    static final int SQL_DOUBLE        = 711;
    static final int SQL_FLOAT         = 712;
    static final int SQL_INTEGER       = 713;
    static final int SQL_LONGVARBINARY = 714;
    static final int SQL_LONGNVARCHAR  = 715;
    static final int SQL_LONGVARCHAR   = 716;
    static final int SQL_NCHAR         = 717;
    static final int SQL_NCLOB         = 718;
    static final int SQL_NUMERIC       = 719;
    static final int SQL_NVARCHAR      = 720;
    static final int SQL_REAL          = 721;
    static final int SQL_ROWID         = 722;
    static final int SQL_SQLXML        = 723;
    static final int SQL_SMALLINT      = 724;
    static final int SQL_TIME          = 725;
    static final int SQL_TIMESTAMP     = 726;
    static final int SQL_TINYINT       = 727;
    static final int SQL_VARBINARY     = 728;
    static final int SQL_VARCHAR       = 729;

    
    static final int X_KEYSET      = 730;
    static final int X_OPTION      = 731;
    static final int X_REPEAT      = 732;
    static final int X_POS_INTEGER = 733;

    
    public static final int X_VALUE                    = 734;
    public static final int X_IDENTIFIER               = 735;
    public static final int X_DELIMITED_IDENTIFIER     = 736;
    public static final int X_ENDPARSE                 = 737;
    public static final int X_STARTPARSE               = 738;
    public static final int X_REMARK                   = 739;
    public static final int X_NULL                     = 730;
    public static final int X_LOB_SIZE                 = 731;
    public static final int X_MALFORMED_STRING         = 732;
    public static final int X_MALFORMED_NUMERIC        = 733;
    public static final int X_MALFORMED_BIT_STRING     = 734;
    public static final int X_MALFORMED_BINARY_STRING  = 735;
    public static final int X_MALFORMED_UNICODE_STRING = 736;
    public static final int X_MALFORMED_COMMENT        = 737;
    public static final int X_MALFORMED_IDENTIFIER     = 738;
    public static final int X_MALFORMED_UNICODE_ESCAPE = 739;
    
    public static final int WEEKOFYEAR                 = 740; 
    public static final int WEEKDAY                    = 741; 
    

    
    public static final int X_UNKNOWN_TOKEN = -1;
    private static final IntValueHashMap reservedKeys =
        new IntValueHashMap(351);

    static {
        reservedKeys.put(Tokens.T_ABS, ABS);
        reservedKeys.put(Tokens.T_ALL, ALL);
        reservedKeys.put(Tokens.T_ALLOCATE, ALLOCATE);
        reservedKeys.put(Tokens.T_ALTER, ALTER);
        reservedKeys.put(Tokens.T_AND, AND);
        reservedKeys.put(Tokens.T_ANY, ANY);
        reservedKeys.put(Tokens.T_ARE, ARE);
        reservedKeys.put(Tokens.T_ARRAY, ARRAY);
        reservedKeys.put(Tokens.T_AS, AS);
        reservedKeys.put(Tokens.T_ASENSITIVE, ASENSITIVE);
        reservedKeys.put(Tokens.T_ASYMMETRIC, ASYMMETRIC);
        reservedKeys.put(Tokens.T_AT, AT);
        reservedKeys.put(Tokens.T_ATOMIC, ATOMIC);
        reservedKeys.put(Tokens.T_AUTHORIZATION, AUTHORIZATION);
        reservedKeys.put(Tokens.T_AVG, AVG);
        reservedKeys.put(Tokens.T_BEGIN, BEGIN);
        reservedKeys.put(Tokens.T_BETWEEN, BETWEEN);
        reservedKeys.put(Tokens.T_BIGINT, BIGINT);
        reservedKeys.put(Tokens.T_BINARY, BINARY);
        reservedKeys.put(Tokens.T_BIT_LENGTH, BIT_LENGTH);
        
        reservedKeys.put(Tokens.T_BYTES, BYTES); 
        
        reservedKeys.put(Tokens.T_BLOB, BLOB);
        reservedKeys.put(Tokens.T_BOOLEAN, BOOLEAN);
        reservedKeys.put(Tokens.T_BOTH, BOTH);
        reservedKeys.put(Tokens.T_BY, BY);
        reservedKeys.put(Tokens.T_CALL, CALL);
        reservedKeys.put(Tokens.T_CALLED, CALLED);
        reservedKeys.put(Tokens.T_CARDINALITY, CARDINALITY);
        reservedKeys.put(Tokens.T_CASCADED, CASCADED);
        reservedKeys.put(Tokens.T_CASE, CASE);
        reservedKeys.put(Tokens.T_CAST, CAST);
        reservedKeys.put(Tokens.T_CEIL, CEIL);
        reservedKeys.put(Tokens.T_CEILING, CEILING);
        reservedKeys.put(Tokens.T_CHAR, CHAR);
        reservedKeys.put(Tokens.T_CHAR_LENGTH, CHAR_LENGTH);
        reservedKeys.put(Tokens.T_CHARACTER, CHARACTER);
        reservedKeys.put(Tokens.T_CHARACTER_LENGTH, CHARACTER_LENGTH);
        reservedKeys.put(Tokens.T_CHECK, CHECK);
        reservedKeys.put(Tokens.T_CLOB, CLOB);
        reservedKeys.put(Tokens.T_CLOSE, CLOSE);
        reservedKeys.put(Tokens.T_COALESCE, COALESCE);
        reservedKeys.put(Tokens.T_COLLATE, COLLATE);
        reservedKeys.put(Tokens.T_COLLECT, COLLECT);
        reservedKeys.put(Tokens.T_COLUMN, COLUMN);
        reservedKeys.put(Tokens.T_COMMIT, COMMIT);
        reservedKeys.put(Tokens.T_COMPARABLE, COMPARABLE);
        
        reservedKeys.put(Tokens.T_CONCAT, CONCAT);
        
        reservedKeys.put(Tokens.T_CONDITION, CONDITION);
        reservedKeys.put(Tokens.T_CONNECT, CONNECT);
        reservedKeys.put(Tokens.T_CONSTRAINT, CONSTRAINT);
        reservedKeys.put(Tokens.T_CONVERT, CONVERT);
        reservedKeys.put(Tokens.T_CORR, CORR);
        reservedKeys.put(Tokens.T_CORRESPONDING, CORRESPONDING);
        reservedKeys.put(Tokens.T_COUNT, COUNT);
        
        reservedKeys.put(Tokens.T_APPROX_COUNT_DISTINCT, APPROX_COUNT_DISTINCT);
        
        reservedKeys.put(Tokens.T_COVAR_POP, COVAR_POP);
        reservedKeys.put(Tokens.T_COVAR_SAMP, COVAR_SAMP);
        reservedKeys.put(Tokens.T_CREATE, CREATE);
        reservedKeys.put(Tokens.T_CROSS, CROSS);
        reservedKeys.put(Tokens.T_CUBE, CUBE);
        reservedKeys.put(Tokens.T_CUME_DIST, CUME_DIST);
        reservedKeys.put(Tokens.T_CURRENT, CURRENT);
        reservedKeys.put(Tokens.T_CURRENT_CATALOG, CURRENT_CATALOG);
        reservedKeys.put(Tokens.T_CURRENT_DATE, CURRENT_DATE);
        reservedKeys.put(Tokens.T_CURRENT_DEFAULT_TRANSFORM_GROUP,
                         CURRENT_DEFAULT_TRANSFORM_GROUP);
        reservedKeys.put(Tokens.T_CURRENT_PATH, CURRENT_PATH);
        reservedKeys.put(Tokens.T_CURRENT_ROLE, CURRENT_ROLE);
        reservedKeys.put(Tokens.T_CURRENT_SCHEMA, CURRENT_SCHEMA);
        reservedKeys.put(Tokens.T_CURRENT_TIME, CURRENT_TIME);
        reservedKeys.put(Tokens.T_CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
        reservedKeys.put(Tokens.T_DO, DO);
        reservedKeys.put(Tokens.T_CURRENT_TRANSFORM_GROUP_FOR_TYPE,
                         CURRENT_TRANSFORM_GROUP_FOR_TYPE);
        reservedKeys.put(Tokens.T_CURRENT_USER, CURRENT_USER);
        reservedKeys.put(Tokens.T_CURSOR, CURSOR);
        reservedKeys.put(Tokens.T_CYCLE, CYCLE);
        reservedKeys.put(Tokens.T_DATE, DATE);
        reservedKeys.put(Tokens.T_DAY, DAY);
        reservedKeys.put(Tokens.T_DEALLOCATE, DEALLOCATE);
        reservedKeys.put(Tokens.T_DEC, DEC);
        reservedKeys.put(Tokens.T_DECIMAL, DECIMAL);
        reservedKeys.put(Tokens.T_DECLARE, DECLARE);
        reservedKeys.put(Tokens.T_DEFAULT, DEFAULT);
        reservedKeys.put(Tokens.T_DELETE, DELETE);
        reservedKeys.put(Tokens.T_DENSE_RANK, DENSE_RANK);
        reservedKeys.put(Tokens.T_DEREF, DEREF);
        reservedKeys.put(Tokens.T_DESCRIBE, DESCRIBE);
        reservedKeys.put(Tokens.T_DETERMINISTIC, DETERMINISTIC);
        reservedKeys.put(Tokens.T_DISCONNECT, DISCONNECT);
        reservedKeys.put(Tokens.T_DISTINCT, DISTINCT);
        reservedKeys.put(Tokens.T_DOUBLE, DOUBLE);
        reservedKeys.put(Tokens.T_DROP, DROP);
        reservedKeys.put(Tokens.T_DYNAMIC, DYNAMIC);
        reservedKeys.put(Tokens.T_EACH, EACH);
        reservedKeys.put(Tokens.T_ELEMENT, ELEMENT);
        reservedKeys.put(Tokens.T_ELSE, ELSE);
        reservedKeys.put(Tokens.T_ELSEIF, ELSEIF);
        reservedKeys.put(Tokens.T_END, END);
        reservedKeys.put(Tokens.T_END_EXEC, END_EXEC);
        reservedKeys.put(Tokens.T_ESCAPE, ESCAPE);
        reservedKeys.put(Tokens.T_EVERY, EVERY);
        reservedKeys.put(Tokens.T_EXCEPT, EXCEPT);
        reservedKeys.put(Tokens.T_EXEC, EXEC);
        reservedKeys.put(Tokens.T_EXECUTE, EXECUTE);
        reservedKeys.put(Tokens.T_EXISTS, EXISTS);
        reservedKeys.put(Tokens.T_EXIT, EXIT);
        reservedKeys.put(Tokens.T_EXP, EXP);
        reservedKeys.put(Tokens.T_EXTERNAL, EXTERNAL);
        reservedKeys.put(Tokens.T_EXTRACT, EXTRACT);
        reservedKeys.put(Tokens.T_FALSE, FALSE);
        reservedKeys.put(Tokens.T_FETCH, FETCH);
        reservedKeys.put(Tokens.T_FILTER, FILTER);
        reservedKeys.put(Tokens.T_FIRST_VALUE, FIRST_VALUE);
        reservedKeys.put(Tokens.T_FLOAT, FLOAT);
        reservedKeys.put(Tokens.T_FLOOR, FLOOR);
        reservedKeys.put(Tokens.T_FOR, FOR);
        reservedKeys.put(Tokens.T_FOREIGN, FOREIGN);
        reservedKeys.put(Tokens.T_FREE, FREE);
        reservedKeys.put(Tokens.T_FROM, FROM);
        reservedKeys.put(Tokens.T_FULL, FULL);
        reservedKeys.put(Tokens.T_FUNCTION, FUNCTION);
        reservedKeys.put(Tokens.T_FUSION, FUSION);
        reservedKeys.put(Tokens.T_GET, GET);
        reservedKeys.put(Tokens.T_GLOBAL, GLOBAL);
        reservedKeys.put(Tokens.T_GRANT, GRANT);
        reservedKeys.put(Tokens.T_GROUP, GROUP);
        reservedKeys.put(Tokens.T_GROUPING, GROUPING);
        reservedKeys.put(Tokens.T_HANDLER, HANDLER);
        reservedKeys.put(Tokens.T_HAVING, HAVING);
        reservedKeys.put(Tokens.T_HOLD, HOLD);
        reservedKeys.put(Tokens.T_HOUR, HOUR);
        reservedKeys.put(Tokens.T_IDENTITY, IDENTITY);
        reservedKeys.put(Tokens.T_IF, IF);
        reservedKeys.put(Tokens.T_IN, IN);
        reservedKeys.put(Tokens.T_INDICATOR, INDICATOR);
        reservedKeys.put(Tokens.T_INNER, INNER);
        reservedKeys.put(Tokens.T_INOUT, INOUT);
        reservedKeys.put(Tokens.T_INSENSITIVE, INSENSITIVE);
        reservedKeys.put(Tokens.T_INSERT, INSERT);
        reservedKeys.put(Tokens.T_INT, INT);
        reservedKeys.put(Tokens.T_INTEGER, INTEGER);
        reservedKeys.put(Tokens.T_INTERSECT, INTERSECT);
        reservedKeys.put(Tokens.T_INTERSECTION, INTERSECTION);
        reservedKeys.put(Tokens.T_INTERVAL, INTERVAL);
        reservedKeys.put(Tokens.T_INTO, INTO);
        reservedKeys.put(Tokens.T_IS, IS);
        reservedKeys.put(Tokens.T_ITERATE, ITERATE);
        reservedKeys.put(Tokens.T_JOIN, JOIN);
        reservedKeys.put(Tokens.T_LAG, LAG);
        reservedKeys.put(Tokens.T_LANGUAGE, LANGUAGE);
        reservedKeys.put(Tokens.T_LARGE, LARGE);
        reservedKeys.put(Tokens.T_LAST_VALUE, LAST_VALUE);
        reservedKeys.put(Tokens.T_LATERAL, LATERAL);
        reservedKeys.put(Tokens.T_LEAD, LEAD);
        reservedKeys.put(Tokens.T_LEADING, LEADING);
        reservedKeys.put(Tokens.T_LEAVE, LEAVE);
        reservedKeys.put(Tokens.T_LEFT, LEFT);
        reservedKeys.put(Tokens.T_LIKE, LIKE);
        reservedKeys.put(Tokens.T_LIKE_REGX, LIKE_REGEX);
        reservedKeys.put(Tokens.T_LN, LN);
        reservedKeys.put(Tokens.T_LOCAL, LOCAL);
        reservedKeys.put(Tokens.T_LOCALTIME, LOCALTIME);
        reservedKeys.put(Tokens.T_LOCALTIMESTAMP, LOCALTIMESTAMP);
        reservedKeys.put(Tokens.T_LOOP, LOOP);
        reservedKeys.put(Tokens.T_LOWER, LOWER);
        reservedKeys.put(Tokens.T_MATCH, MATCH);
        reservedKeys.put(Tokens.T_MAX, MAX);
        reservedKeys.put(Tokens.T_MAX_CARDINALITY, MAX_CARDINALITY);
        reservedKeys.put(Tokens.T_MEMBER, MEMBER);
        reservedKeys.put(Tokens.T_MERGE, MERGE);
        reservedKeys.put(Tokens.T_METHOD, METHOD);
        reservedKeys.put(Tokens.T_MIN, MIN);
        reservedKeys.put(Tokens.T_MINUTE, MINUTE);
        reservedKeys.put(Tokens.T_MOD, MOD);
        reservedKeys.put(Tokens.T_MODIFIES, MODIFIES);
        reservedKeys.put(Tokens.T_MODULE, MODULE);
        reservedKeys.put(Tokens.T_MONTH, MONTH);
        reservedKeys.put(Tokens.T_MULTISET, MULTISET);
        reservedKeys.put(Tokens.T_NATIONAL, NATIONAL);
        reservedKeys.put(Tokens.T_NATURAL, NATURAL);
        reservedKeys.put(Tokens.T_NCHAR, NCHAR);
        reservedKeys.put(Tokens.T_NCLOB, NCLOB);
        reservedKeys.put(Tokens.T_NEW, NEW);
        reservedKeys.put(Tokens.T_NO, NO);
        reservedKeys.put(Tokens.T_NONE, NONE);
        reservedKeys.put(Tokens.T_NORMALIZE, NORMALIZE);
        reservedKeys.put(Tokens.T_NOT, NOT);
        reservedKeys.put(Tokens.T_NTH_VALUE, NTH_VALUE);
        reservedKeys.put(Tokens.T_NTILE, NTILE);
        reservedKeys.put(Tokens.T_NULL, NULL);
        reservedKeys.put(Tokens.T_NULLIF, NULLIF);
        reservedKeys.put(Tokens.T_NUMERIC, NUMERIC);
        reservedKeys.put(Tokens.T_OCCURRENCES_REGEX, OCCURRENCES_REGEX);
        reservedKeys.put(Tokens.T_OCTET_LENGTH, OCTET_LENGTH);
        reservedKeys.put(Tokens.T_OF, OF);
        reservedKeys.put(Tokens.T_OFFSET, OFFSET);
        reservedKeys.put(Tokens.T_OLD, OLD);
        reservedKeys.put(Tokens.T_ON, ON);
        reservedKeys.put(Tokens.T_ONLY, ONLY);
        reservedKeys.put(Tokens.T_OPEN, OPEN);
        reservedKeys.put(Tokens.T_OR, OR);
        reservedKeys.put(Tokens.T_ORDER, ORDER);
        reservedKeys.put(Tokens.T_OUT, OUT);
        reservedKeys.put(Tokens.T_OUTER, OUTER);
        reservedKeys.put(Tokens.T_OVER, OVER);
        reservedKeys.put(Tokens.T_OVERLAPS, OVERLAPS);
        reservedKeys.put(Tokens.T_OVERLAY, OVERLAY);
        reservedKeys.put(Tokens.T_PARAMETER, PARAMETER);
        reservedKeys.put(Tokens.T_PARTITION, PARTITION);
        reservedKeys.put(Tokens.T_PERCENT_RANK, PERCENT_RANK);
        reservedKeys.put(Tokens.T_PERCENTILE_CONT, PERCENTILE_CONT);
        reservedKeys.put(Tokens.T_PERCENTILE_DISC, PERCENTILE_DISC);
        reservedKeys.put(Tokens.T_POSITION, POSITION);
        reservedKeys.put(Tokens.T_POSITION_REGEX, POSITION_REGEX);
        reservedKeys.put(Tokens.T_POWER, POWER);
        reservedKeys.put(Tokens.T_PRECISION, PRECISION);
        reservedKeys.put(Tokens.T_PREPARE, PREPARE);
        reservedKeys.put(Tokens.T_PRIMARY, PRIMARY);
        reservedKeys.put(Tokens.T_PROCEDURE, PROCEDURE);
        reservedKeys.put(Tokens.T_RANGE, RANGE);
        reservedKeys.put(Tokens.T_RANK, RANK);
        reservedKeys.put(Tokens.T_READS, READS);
        reservedKeys.put(Tokens.T_REAL, REAL);
        reservedKeys.put(Tokens.T_RECURSIVE, RECURSIVE);
        reservedKeys.put(Tokens.T_REF, REF);
        reservedKeys.put(Tokens.T_REFERENCES, REFERENCES);
        reservedKeys.put(Tokens.T_REFERENCING, REFERENCING);
        reservedKeys.put(Tokens.T_REGR_AVGX, REGR_AVGX);
        reservedKeys.put(Tokens.T_REGR_AVGY, REGR_AVGY);
        reservedKeys.put(Tokens.T_REGR_COUNT, REGR_COUNT);
        reservedKeys.put(Tokens.T_REGR_INTERCEPT, REGR_INTERCEPT);
        reservedKeys.put(Tokens.T_REGR_R2, REGR_R2);
        reservedKeys.put(Tokens.T_REGR_SLOPE, REGR_SLOPE);
        reservedKeys.put(Tokens.T_REGR_SXX, REGR_SXX);
        reservedKeys.put(Tokens.T_REGR_SXY, REGR_SXY);
        reservedKeys.put(Tokens.T_REGR_SYY, REGR_SYY);
        reservedKeys.put(Tokens.T_RELEASE, RELEASE);
        reservedKeys.put(Tokens.T_REPEAT, REPEAT);
        reservedKeys.put(Tokens.T_RESIGNAL, RESIGNAL);
        reservedKeys.put(Tokens.T_RETURN, RETURN);
        reservedKeys.put(Tokens.T_RETURNS, RETURNS);
        reservedKeys.put(Tokens.T_REVOKE, REVOKE);
        reservedKeys.put(Tokens.T_RIGHT, RIGHT);
        reservedKeys.put(Tokens.T_ROLLBACK, ROLLBACK);
        reservedKeys.put(Tokens.T_ROLLUP, ROLLUP);
        reservedKeys.put(Tokens.T_ROW, ROW);
        reservedKeys.put(Tokens.T_ROW_NUMBER, ROW_NUMBER);
        reservedKeys.put(Tokens.T_ROWS, ROWS);
        reservedKeys.put(Tokens.T_SAVEPOINT, SAVEPOINT);
        reservedKeys.put(Tokens.T_SCOPE, SCOPE);
        reservedKeys.put(Tokens.T_SCROLL, SCROLL);
        reservedKeys.put(Tokens.T_SEARCH, SEARCH);
        reservedKeys.put(Tokens.T_SECOND, SECOND);
        reservedKeys.put(Tokens.T_SELECT, SELECT);
        reservedKeys.put(Tokens.T_SENSITIVE, SENSITIVE);
        reservedKeys.put(Tokens.T_SESSION_USER, SESSION_USER);
        reservedKeys.put(Tokens.T_SET, SET);
        reservedKeys.put(Tokens.T_SIGNAL, SIGNAL);
        reservedKeys.put(Tokens.T_SIMILAR, SIMILAR);
        reservedKeys.put(Tokens.T_SMALLINT, SMALLINT);
        reservedKeys.put(Tokens.T_SOME, SOME);
        
        reservedKeys.put(Tokens.T_SPACE, SPACE);
        
        reservedKeys.put(Tokens.T_SPECIFIC, SPECIFIC);
        reservedKeys.put(Tokens.T_SPECIFICTYPE, SPECIFICTYPE);
        reservedKeys.put(Tokens.T_SQL, SQL);
        reservedKeys.put(Tokens.T_SQLEXCEPTION, SQLEXCEPTION);
        reservedKeys.put(Tokens.T_SQLSTATE, SQLSTATE);
        reservedKeys.put(Tokens.T_SQLWARNING, SQLWARNING);
        reservedKeys.put(Tokens.T_SQRT, SQRT);
        reservedKeys.put(Tokens.T_STACKED, STACKED);
        reservedKeys.put(Tokens.T_START, START);
        reservedKeys.put(Tokens.T_STATIC, STATIC);
        reservedKeys.put(Tokens.T_STDDEV_POP, STDDEV_POP);
        reservedKeys.put(Tokens.T_STDDEV_SAMP, STDDEV_SAMP);
        reservedKeys.put(Tokens.T_SUBMULTISET, SUBMULTISET);
        reservedKeys.put(Tokens.T_SUBSTRING, SUBSTRING);
        reservedKeys.put(Tokens.T_SUBSTRING_REGEX, SUBSTRING_REGEX);
        reservedKeys.put(Tokens.T_SUM, SUM);
        reservedKeys.put(Tokens.T_SYMMETRIC, SYMMETRIC);
        reservedKeys.put(Tokens.T_SYSTEM, SYSTEM);
        reservedKeys.put(Tokens.T_SYSTEM_USER, SYSTEM_USER);
        reservedKeys.put(Tokens.T_TABLE, TABLE);
        reservedKeys.put(Tokens.T_TABLESAMPLE, TABLESAMPLE);
        reservedKeys.put(Tokens.T_THEN, THEN);
        reservedKeys.put(Tokens.T_TIME, TIME);
        reservedKeys.put(Tokens.T_TIMESTAMP, TIMESTAMP);
        reservedKeys.put(Tokens.T_TIMEZONE_HOUR, TIMEZONE_HOUR);
        reservedKeys.put(Tokens.T_TIMEZONE_MINUTE, TIMEZONE_MINUTE);
        reservedKeys.put(Tokens.T_TO, TO);
        reservedKeys.put(Tokens.T_TRAILING, TRAILING);
        reservedKeys.put(Tokens.T_TRANSLATE, TRANSLATE);
        reservedKeys.put(Tokens.T_TRANSLATE_REGEX, TRANSLATE_REGEX);
        reservedKeys.put(Tokens.T_TRANSLATION, TRANSLATION);
        reservedKeys.put(Tokens.T_TREAT, TREAT);
        reservedKeys.put(Tokens.T_TRIGGER, TRIGGER);
        reservedKeys.put(Tokens.T_TRIM, TRIM);
        reservedKeys.put(Tokens.T_TRIM_ARRAY, TRIM_ARRAY);
        reservedKeys.put(Tokens.T_TRUE, TRUE);
        reservedKeys.put(Tokens.T_TRUNCATE, TRUNCATE);
        reservedKeys.put(Tokens.T_UESCAPE, UESCAPE);
        reservedKeys.put(Tokens.T_UNDO, UNDO);
        reservedKeys.put(Tokens.T_UNION, UNION);
        reservedKeys.put(Tokens.T_UNIQUE, UNIQUE);
        
        reservedKeys.put(Tokens.T_ASSUMEUNIQUE, ASSUMEUNIQUE);    
        
        reservedKeys.put(Tokens.T_UNKNOWN, UNKNOWN);
        reservedKeys.put(Tokens.T_UNNEST, UNNEST);
        reservedKeys.put(Tokens.T_UNTIL, UNTIL);
        reservedKeys.put(Tokens.T_UPDATE, UPDATE);
        reservedKeys.put(Tokens.T_UPPER, UPPER);
        reservedKeys.put(Tokens.T_USER, USER);
        reservedKeys.put(Tokens.T_USING, USING);
        reservedKeys.put(Tokens.T_VALUE, VALUE);
        reservedKeys.put(Tokens.T_VALUES, VALUES);
        reservedKeys.put(Tokens.T_VAR_POP, VAR_POP);
        reservedKeys.put(Tokens.T_VAR_SAMP, VAR_SAMP);
        reservedKeys.put(Tokens.T_VARBINARY, VARBINARY);
        reservedKeys.put(Tokens.T_VARCHAR, VARCHAR);
        reservedKeys.put(Tokens.T_VARYING, VARYING);
        reservedKeys.put(Tokens.T_WHEN, WHEN);
        reservedKeys.put(Tokens.T_WHENEVER, WHENEVER);
        reservedKeys.put(Tokens.T_WHERE, WHERE);
        reservedKeys.put(Tokens.T_WIDTH_BUCKET, WIDTH_BUCKET);
        reservedKeys.put(Tokens.T_WINDOW, WINDOW);
        reservedKeys.put(Tokens.T_WITH, WITH);
        reservedKeys.put(Tokens.T_WITHIN, WITHIN);
        reservedKeys.put(Tokens.T_WITHOUT, WITHOUT);
        reservedKeys.put(Tokens.T_WHILE, WHILE);
        reservedKeys.put(Tokens.T_YEAR, YEAR);
        
        reservedKeys.put(Tokens.T_WEEKOFYEAR, WEEKOFYEAR);    
        reservedKeys.put(Tokens.T_WEEKDAY, WEEKDAY);          
        
    }

    private static final IntValueHashMap commandSet = new IntValueHashMap(251);

    static {
        commandSet.put(T_IF, Tokens.IF);
        commandSet.put(T_IFNULL, Tokens.IFNULL);
        commandSet.put(T_NVL, Tokens.IFNULL);
        commandSet.put(T_CASEWHEN, Tokens.CASEWHEN);

        
        commandSet.put(T_ADD, ADD);
        commandSet.put(T_ADMIN, ADMIN);
        commandSet.put(T_ACTION, ACTION);
        commandSet.put(T_AFTER, AFTER);
        commandSet.put(T_ALIAS, ALIAS);
        commandSet.put(T_ALWAYS, ALWAYS);
        commandSet.put(T_ASC, ASC);
        commandSet.put(T_AUTOCOMMIT, AUTOCOMMIT);
        commandSet.put(T_BACKUP, BACKUP);
        commandSet.put(T_BEFORE, BEFORE);
        commandSet.put(T_BIT, BIT);
        commandSet.put(T_BLOCKING, BLOCKING);
        commandSet.put(T_CACHE, CACHE);
        commandSet.put(T_CACHED, CACHED);
        commandSet.put(T_CASCADE, CASCADE);
        commandSet.put(T_CATALOG, CATALOG);
        commandSet.put(T_CHARACTERISTICS, CHARACTERISTICS);
        commandSet.put(T_CHECKPOINT, CHECKPOINT);
        commandSet.put(T_COLLATE, COLLATE);
        commandSet.put(T_COLLATION, COLLATION);
        commandSet.put(T_COMMITTED, COMMITTED);
        commandSet.put(T_COMPACT, COMPACT);
        commandSet.put(T_COMPRESSED, COMPRESSED);
        commandSet.put(T_CONDITION_IDENTIFIER, Tokens.CONDITION_IDENTIFIER);
        commandSet.put(T_CONTAINS, CONTAINS);
        commandSet.put(T_CONTINUE, CONTINUE);
        commandSet.put(T_CONTROL, CONTROL);
        commandSet.put(T_CURDATE, CURDATE);
        commandSet.put(T_CURTIME, CURTIME);
        commandSet.put(T_DATA, DATA);
        commandSet.put(T_DATABASE, DATABASE);
        commandSet.put(T_DEFAULTS, DEFAULTS);
        commandSet.put(T_DEFRAG, DEFRAG);
        commandSet.put(T_DESC, DESC);
        commandSet.put(T_DOMAIN, DOMAIN);
        commandSet.put(T_EXCLUDING, EXCLUDING);
        commandSet.put(T_EXPLAIN, EXPLAIN);
        commandSet.put(T_EVENT, EVENT);
        commandSet.put(T_FILE, FILE);
        commandSet.put(T_FILES, FILES);
        commandSet.put(T_FINAL, FINAL);
        commandSet.put(T_FIRST, FIRST);
        commandSet.put(T_G_FACTOR, G);
        commandSet.put(T_GENERATED, GENERATED);
        commandSet.put(T_GRANTED, GRANTED);
        commandSet.put(T_HEADER, HEADER);
        commandSet.put(T_IGNORECASE, IGNORECASE);
        commandSet.put(T_IMMEDIATELY, IMMEDIATELY);
        commandSet.put(T_INCLUDING, INCLUDING);
        commandSet.put(T_INCREMENT, INCREMENT);
        commandSet.put(T_INDEX, INDEX);
        commandSet.put(T_INITIAL, INITIAL);
        commandSet.put(T_INPUT, INPUT);
        commandSet.put(T_INSTEAD, INSTEAD);
        commandSet.put(T_ISOLATION, ISOLATION);
        commandSet.put(T_ISAUTOCOMMIT, ISAUTOCOMMIT);
        commandSet.put(T_ISREADONLYDATABASE, ISREADONLYDATABASE);
        commandSet.put(T_ISREADONLYDATABASEFILES, ISREADONLYDATABASEFILES);
        commandSet.put(T_ISREADONLYSESSION, ISREADONLYSESSION);
        commandSet.put(T_JAVA, JAVA);
        commandSet.put(T_K_FACTOR, K);
        commandSet.put(T_KEY, KEY);
        commandSet.put(T_LAST, LAST);
        commandSet.put(T_LENGTH, LENGTH);
        commandSet.put(T_LEVEL, LEVEL);
        commandSet.put(T_LIMIT, LIMIT);
        commandSet.put(T_LOGSIZE, LOGSIZE);
        commandSet.put(T_LOCK, LOCK);
        commandSet.put(T_LOCKS, LOCKS);
        commandSet.put(T_M_FACTOR, M);
        commandSet.put(T_MATCHED, MATCHED);
        commandSet.put(T_MAXROWS, MAXROWS);
        commandSet.put(T_MAXVALUE, MAXVALUE);
        commandSet.put(T_MEMORY, MEMORY);
        
        commandSet.put(T_MICROS, MICROS);                
        commandSet.put(T_MICROSECOND, MICROSECOND);      
        
        commandSet.put(T_MILLIS, MILLIS);
        
        commandSet.put(T_MILLISECOND, MILLISECOND);      
        
        commandSet.put(T_MINUS_EXCEPT, MINUS_EXCEPT);
        commandSet.put(T_MINVALUE, MINVALUE);
        commandSet.put(T_MVCC, MVCC);
        commandSet.put(T_NAME, NAME);
        commandSet.put(T_NEXT, NEXT);
        commandSet.put(T_NIO, NIO);
        commandSet.put(T_NOW, NOW);
        commandSet.put(T_NULLS, NULLS);
        commandSet.put(T_OFF, OFF);
        commandSet.put(T_OPTION, OPTION);
        commandSet.put(T_OVERRIDING, OVERRIDING);
        commandSet.put(T_P_FACTOR, P);
        commandSet.put(T_PARTIAL, PARTIAL);
        commandSet.put(T_PASSWORD, PASSWORD);
        commandSet.put(T_PLACING, PLACING);
        commandSet.put(T_PLAN, PLAN);
        commandSet.put(T_PRESERVE, PRESERVE);
        commandSet.put(T_PRIVILEGES, PRIVILEGES);
        commandSet.put(T_PROPERTY, PROPERTY);
        commandSet.put(T_READ, READ);
        commandSet.put(T_READONLY, READONLY);
        commandSet.put(T_REFERENTIAL_INTEGRITY, REFERENTIAL_INTEGRITY);
        commandSet.put(T_RENAME, RENAME);
        commandSet.put(T_REPEATABLE, REPEATABLE);
        commandSet.put(T_RESTART, RESTART);
        commandSet.put(T_RESTRICT, RESTRICT);
        commandSet.put(T_ROLE, ROLE);
        commandSet.put(T_SCHEMA, SCHEMA);
        commandSet.put(T_SCRIPT, SCRIPT);
        commandSet.put(T_SCRIPTFORMAT, SCRIPTFORMAT);
        commandSet.put(T_SEQUENCE, SEQUENCE);
        commandSet.put(T_SESSION, SESSION);
        commandSet.put(T_SERIALIZABLE, SERIALIZABLE);
        commandSet.put(T_SHUTDOWN, SHUTDOWN);
        commandSet.put(T_SIMPLE, SIMPLE);
        commandSet.put(T_SIZE, SIZE);
        commandSet.put(T_SOURCE, SOURCE);
        commandSet.put(T_SQL_BIGINT, SQL_BIGINT);
        commandSet.put(T_SQL_BINARY, SQL_BINARY);
        commandSet.put(T_SQL_BIT, SQL_BIT);
        commandSet.put(T_SQL_BLOB, SQL_BLOB);
        commandSet.put(T_SQL_BOOLEAN, SQL_BOOLEAN);
        commandSet.put(T_SQL_CHAR, SQL_CHAR);
        commandSet.put(T_SQL_CLOB, SQL_CLOB);
        commandSet.put(T_SQL_DATE, SQL_DATE);
        commandSet.put(T_SQL_DECIMAL, SQL_DECIMAL);
        commandSet.put(T_SQL_DATALINK, SQL_DATALINK);
        commandSet.put(T_SQL_DOUBLE, SQL_DOUBLE);
        commandSet.put(T_SQL_FLOAT, SQL_FLOAT);
        commandSet.put(T_SQL_INTEGER, SQL_INTEGER);
        commandSet.put(T_SQL_LONGVARBINARY, SQL_LONGVARBINARY);
        commandSet.put(T_SQL_LONGNVARCHAR, SQL_LONGNVARCHAR);
        commandSet.put(T_SQL_LONGVARCHAR, SQL_LONGVARCHAR);
        commandSet.put(T_SQL_NCHAR, SQL_NCHAR);
        commandSet.put(T_SQL_NCLOB, SQL_NCLOB);
        commandSet.put(T_SQL_NUMERIC, SQL_NUMERIC);
        commandSet.put(T_SQL_NVARCHAR, SQL_NVARCHAR);
        commandSet.put(T_SQL_REAL, SQL_REAL);
        commandSet.put(T_SQL_ROWID, SQL_ROWID);
        commandSet.put(T_SQL_SQLXML, SQL_SQLXML);
        commandSet.put(T_SQL_SMALLINT, SQL_SMALLINT);
        commandSet.put(T_SQL_TIME, SQL_TIME);
        commandSet.put(T_SQL_TIMESTAMP, SQL_TIMESTAMP);
        commandSet.put(T_SQL_TINYINT, SQL_TINYINT);
        commandSet.put(T_SQL_VARBINARY, SQL_VARBINARY);
        commandSet.put(T_SQL_VARCHAR, SQL_VARCHAR);
        commandSet.put(T_SQL_TSI_FRAC_SECOND, SQL_TSI_FRAC_SECOND);
        commandSet.put(T_SQL_TSI_SECOND, SQL_TSI_SECOND);
        commandSet.put(T_SQL_TSI_MINUTE, SQL_TSI_MINUTE);
        commandSet.put(T_SQL_TSI_HOUR, SQL_TSI_HOUR);
        commandSet.put(T_SQL_TSI_DAY, SQL_TSI_DAY);
        commandSet.put(T_SQL_TSI_WEEK, SQL_TSI_WEEK);
        commandSet.put(T_SQL_TSI_MONTH, SQL_TSI_MONTH);
        commandSet.put(T_SQL_TSI_QUARTER, SQL_TSI_QUARTER);
        commandSet.put(T_SQL_TSI_YEAR, SQL_TSI_YEAR);
        commandSet.put(T_STYLE, STYLE);
        commandSet.put(T_T_FACTOR, T);
        commandSet.put(T_TEMP, TEMP);
        commandSet.put(T_TEMPORARY, TEMPORARY);
        commandSet.put(T_TEXT, TEXT);
        commandSet.put(T_TIMESTAMPADD, TIMESTAMPADD);
        commandSet.put(T_TIMESTAMPDIFF, TIMESTAMPDIFF);
        commandSet.put(T_TO_CHAR, TO_CHAR);
        commandSet.put(T_TODAY, TODAY);
        commandSet.put(T_TOP, TOP);
        commandSet.put(T_TRANSACTION, TRANSACTION);
        commandSet.put(T_TYPE, TYPE);
        commandSet.put(T_UNCOMMITTED, UNCOMMITTED);
        commandSet.put(T_USAGE, USAGE);
        commandSet.put(T_VIEW, VIEW);
        commandSet.put(T_WRITE, WRITE);
        commandSet.put(T_WRITE_DELAY, WRITE_DELAY);
        commandSet.put(T_WORK, WORK);
        commandSet.put(T_ZONE, ZONE);

        
        
        commandSet.put(T_DAYOFWEEK, DAYOFWEEK);
        commandSet.put(T_DAYOFYEAR, DAYOFYEAR);
        commandSet.put(T_WEEK, WEEK);
        commandSet.put(T_WEEKOFYEAR, WEEKOFYEAR);
        commandSet.put(T_WEEK_OF_YEAR, WEEK_OF_YEAR);
        commandSet.put(T_WEEKDAY, WEEKDAY);
        
        commandSet.put(T_DAY_NAME, DAY_NAME);
        commandSet.put(T_MONTH_NAME, MONTH_NAME);
        commandSet.put(T_QUARTER, QUARTER);
        commandSet.put(T_DAY_OF_WEEK, DAY_OF_WEEK);
        commandSet.put(T_DAY_OF_MONTH, DAY_OF_MONTH);
        commandSet.put(T_DAY_OF_YEAR, DAY_OF_YEAR);
        commandSet.put(T_DAYOFMONTH, DAYOFMONTH);
        commandSet.put(T_BITLENGTH, BITLENGTH);
        commandSet.put(T_OCTETLENGTH, OCTETLENGTH);
        commandSet.put(T_ACOS, ACOS);
        commandSet.put(T_ASIN, ASIN);
        commandSet.put(T_ATAN, ATAN);
        commandSet.put(T_ATAN2, ATAN2);
        commandSet.put(T_COS, COS);
        commandSet.put(T_COT, COT);
        commandSet.put(T_DEGREES, DEGREES);
        commandSet.put(T_DMOD, DMOD);
        commandSet.put(T_LOG, LOG);
        commandSet.put(T_LOG10, LOG10);
        commandSet.put(T_PI, PI);
        commandSet.put(T_RADIANS, RADIANS);
        commandSet.put(T_RAND, RAND);
        commandSet.put(T_ROUND, ROUND);
        commandSet.put(T_SIGN, SIGN);
        commandSet.put(T_SIN, SIN);
        commandSet.put(T_TAN, TAN);
        commandSet.put(T_BITAND, BITAND);
        commandSet.put(T_BITOR, BITOR);
        commandSet.put(T_BITXOR, BITXOR);
        commandSet.put(T_ROUNDMAGIC, ROUNDMAGIC);
        commandSet.put(T_ASCII, ASCII);
        commandSet.put(T_CONCAT_WORD, CONCAT_WORD);
        commandSet.put(T_DIFFERENCE, DIFFERENCE);
        commandSet.put(T_HEXTORAW, HEXTORAW);
        commandSet.put(T_LCASE, LCASE);
        commandSet.put(T_LOCATE, LOCATE);
        commandSet.put(T_LTRIM, LTRIM);
        commandSet.put(T_RAWTOHEX, RAWTOHEX);
        commandSet.put(T_REPLACE, REPLACE);
        commandSet.put(T_RTRIM, RTRIM);
        commandSet.put(T_SOUNDEX, SOUNDEX);
        commandSet.put(T_SPACE_WORD, SPACE_WORD);
        commandSet.put(T_SUBSTR, SUBSTR);
        commandSet.put(T_UCASE, UCASE);
        commandSet.put(T_DATEDIFF, DATEDIFF);
        commandSet.put(T_SECONDS_MIDNIGHT, SECONDS_MIDNIGHT);

        
        commandSet.put(T_COLON, Tokens.COLON);
        commandSet.put(T_COMMA, Tokens.COMMA);
        commandSet.put(T_SEMICOLON, SEMICOLON);
        commandSet.put(T_EQUALS, Tokens.EQUALS);
        commandSet.put(T_NOT_EQUALS_ALT, Tokens.NOT_EQUALS);
        commandSet.put(T_NOT_EQUALS, Tokens.NOT_EQUALS);
        commandSet.put(T_LESS, Tokens.LESS);
        commandSet.put(T_GREATER, Tokens.GREATER);
        commandSet.put(T_LESS_EQUALS, Tokens.LESS_EQUALS);
        commandSet.put(T_GREATER_EQUALS, Tokens.GREATER_EQUALS);
        commandSet.put(T_PLUS, Tokens.PLUS);
        commandSet.put(T_MINUS, Tokens.MINUS);
        commandSet.put(T_ASTERISK, Tokens.ASTERISK);
        commandSet.put(T_DIVIDE, Tokens.DIVIDE);
        commandSet.put(T_CONCAT, Tokens.CONCAT);
        commandSet.put(T_QUESTION, Tokens.QUESTION);
        commandSet.put(T_OPENBRACKET, OPENBRACKET);
        commandSet.put(T_CLOSEBRACKET, CLOSEBRACKET);
    }

    static int get(String token) {

        int type = reservedKeys.get(token, -1);

        if (type == -1) {
            return commandSet.get(token, -1);
        }

        return type;
    }

    public static boolean isCoreKeyword(int token) {
        return coreReservedWords.contains(token);
    }

    public static boolean isKeyword(String token) {
        return reservedKeys.containsKey(token);
    }

    public static int getKeywordID(String token, int defaultValue) {
        return reservedKeys.get(token, defaultValue);
    }

    public static int getNonKeywordID(String token, int defaultValue) {
        return commandSet.get(token, defaultValue);
    }

    public static String getKeyword(int token) {

        String key = (String) reservedKeys.getKey(token);

        if (key != null) {
            return key;
        }

        key = (String) commandSet.getKey(token);

        return key;
    }

    private static final OrderedIntHashSet coreReservedWords;

    static {

        
        
        coreReservedWords = new OrderedIntHashSet(128);

        short[] keyword = {
            ADMIN, AS, AND, ALL, ANY, AT, AVG, BY, BETWEEN, BOTH, CALL, CASE,
            CAST, CORRESPONDING, CONVERT, COUNT, COALESCE, CREATE, CROSS,
            DISTINCT, DROP, ELSE, END, EVERY, EXISTS, EXCEPT, FOR, FROM, FULL,
            GRANT, GROUP, HAVING, INTO, IS, IN, INTERSECT, JOIN, INNER, LEFT,
            LEADING, LIKE, MAX, MIN, NATURAL, NULLIF, NOT, ON, ORDER, OR,
            OUTER, PRIMARY, REFERENCES, RIGHT, SELECT, SET, SOME, STDDEV_POP,
            STDDEV_SAMP, SUM, TABLE, THEN, TO, TRAILING, TRIGGER, UNION,
            UNIQUE, USING, VALUES, VAR_POP, VAR_SAMP, WHEN, WHERE, WITH,
            
            ASSUMEUNIQUE, 
            
            
            APPROX_COUNT_DISTINCT,
            
        };

        for (int i = 0; i < keyword.length; i++) {
            coreReservedWords.add(keyword[i]);
        }
    }

    public static final short[] SQL_INTERVAL_FIELD_CODES = new short[] {
        Tokens.YEAR, Tokens.MONTH, Tokens.DAY, Tokens.HOUR, Tokens.MINUTE,
        Tokens.SECOND
    };
    public static final String[] SQL_INTERVAL_FIELD_NAMES = new String[] {
        Tokens.T_YEAR, Tokens.T_MONTH, Tokens.T_DAY, Tokens.T_HOUR,
        Tokens.T_MINUTE, Tokens.T_SECOND
    };
}

<code block>



package org.hsqldb_voltpatches;

import java.math.BigDecimal;
import java.math.BigInteger;

import org.hsqldb_voltpatches.lib.HashSet;
import org.hsqldb_voltpatches.store.ValuePool;
import org.hsqldb_voltpatches.types.DTIType;
import org.hsqldb_voltpatches.types.IntervalMonthData;
import org.hsqldb_voltpatches.types.IntervalSecondData;
import org.hsqldb_voltpatches.types.IntervalType;
import org.hsqldb_voltpatches.types.NumberType;
import org.hsqldb_voltpatches.types.Type;

import java.io.Serializable;


public class SetFunction implements Serializable {

    private HashSet distinctValues;
    private boolean isDistinct;

    
    private int  setType;
    private int  dataType;
    private Type type;

    
    private int count;

    
    private boolean    hasNull;
    private boolean    every = true;
    private boolean    some  = false;
    private long       currentLong;
    private double     currentDouble;
    private BigDecimal currentBigDecimal;
    private Object     currentValue;

    SetFunction(int setType, Type type, boolean isDistinct) {

        this.setType = setType;
        this.type    = type;

        if (isDistinct) {
            this.isDistinct = true;
            distinctValues  = new HashSet();
        }

        if (setType == OpTypes.VAR_SAMP || setType == OpTypes.STDDEV_SAMP) {
            this.sample = true;
        }

        if (type != null) {
            dataType = type.typeCode;

            if (type.isIntervalType()) {
                dataType = Types.SQL_INTERVAL;
            }
        }
    }

    void add(Session session, Object item) {

        if (item == null) {
            hasNull = true;

            session.addWarning(Error.error(ErrorCode.W_01003));

            return;
        }

        if (isDistinct && !distinctValues.add(item)) {
            return;
        }

        count++;

        switch (setType) {

            case OpTypes.COUNT :
                return;
            
            case OpTypes.APPROX_COUNT_DISTINCT:
                
                throw Error.error(ErrorCode.X_42581, Tokens.T_APPROX_COUNT_DISTINCT);
            
            case OpTypes.AVG :
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        currentLong += ((Number) item).intValue();

                        return;

                    case Types.SQL_INTERVAL :
                        if (item instanceof IntervalSecondData) {
                            addLong(((IntervalSecondData) item).units);

                            currentLong += ((IntervalSecondData) item).nanos;

                            if (Math.abs(currentLong)
                                    >= DTIType.nanoScaleFactors[0]) {
                                addLong(currentLong
                                        / DTIType.nanoScaleFactors[0]);

                                currentLong %= DTIType.nanoScaleFactors[0];
                            }
                        } else if (item instanceof IntervalMonthData) {
                            addLong(((IntervalMonthData) item).units);
                        }

                        return;

                    case Types.SQL_BIGINT :
                        addLong(((Number) item).longValue());

                        return;

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        currentDouble += ((Number) item).doubleValue();

                        return;

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        if (currentBigDecimal == null) {
                            currentBigDecimal = (BigDecimal) item;
                        } else {
                            currentBigDecimal =
                                currentBigDecimal.add((BigDecimal) item);
                        }

                        return;

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.MIN : {
                if (currentValue == null) {
                    currentValue = item;

                    return;
                }

                if (type.compare(currentValue, item) > 0) {
                    currentValue = item;
                }

                return;
            }
            case OpTypes.MAX : {
                if (currentValue == null) {
                    currentValue = item;

                    return;
                }

                if (type.compare(currentValue, item) < 0) {
                    currentValue = item;
                }

                return;
            }
            case OpTypes.EVERY :
                if (!(item instanceof Boolean)) {
                    throw Error.error(ErrorCode.X_42565);
                }

                every = every && ((Boolean) item).booleanValue();

                return;

            case OpTypes.SOME :
                if (!(item instanceof Boolean)) {
                    throw Error.error(ErrorCode.X_42565);
                }

                some = some || ((Boolean) item).booleanValue();

                return;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                addDataPoint((Number) item);

                return;

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }
    }

    Object getValue() {

        if (setType == OpTypes.COUNT) {
            return ValuePool.getInt(count);
        }

        
        if (setType == OpTypes.APPROX_COUNT_DISTINCT) {
            throw Error.error(ErrorCode.X_42581, Tokens.T_APPROX_COUNT_DISTINCT);
        }
        
        if (count == 0) {
            return null;
        }

        switch (setType) {

            case OpTypes.AVG : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return new Long(currentLong / count);

                    case Types.SQL_BIGINT : {
                        long value = getLongSum().divide(
                            BigInteger.valueOf(count)).longValue();

                        return new Long(value);
                    }
                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return new Double(currentDouble / count);

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return currentBigDecimal.divide(new BigDecimal(count),
                                                        BigDecimal.ROUND_DOWN);

                    case Types.SQL_INTERVAL : {
                        BigInteger bi =
                            getLongSum().divide(BigInteger.valueOf(count));

                        if (!NumberType.isInLongLimits(bi)) {
                            throw Error.error(ErrorCode.X_22015);
                        }

                        if (((IntervalType) type).isDaySecondIntervalType()) {
                            return new IntervalSecondData(bi.longValue(),
                                                          currentLong,
                                                          (IntervalType) type,
                                                          true);
                        } else {
                            return IntervalMonthData.newIntervalMonth(
                                bi.longValue(), (IntervalType) type);
                        }
                    }
                    default :
                        throw Error.runtimeError(ErrorCode.U_S0500,
                                                 "SetFunction");
                }
            }
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return new Long(currentLong);

                    case Types.SQL_BIGINT :
                        return new BigDecimal(getLongSum());

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return new Double(currentDouble);

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return currentBigDecimal;

                    case Types.SQL_INTERVAL : {
                        BigInteger bi = getLongSum();

                        if (!NumberType.isInLongLimits(bi)) {
                            throw Error.error(ErrorCode.X_22015);
                        }

                        if (((IntervalType) type).isDaySecondIntervalType()) {
                            return new IntervalSecondData(bi.longValue(),
                                                          currentLong,
                                                          (IntervalType) type,
                                                          true);
                        } else {
                            return IntervalMonthData.newIntervalMonth(
                                bi.longValue(), (IntervalType) type);
                        }
                    }
                    default :
                        throw Error.runtimeError(ErrorCode.U_S0500,
                                                 "SetFunction");
                }
            }
            case OpTypes.MIN :
            case OpTypes.MAX :
                return currentValue;

            case OpTypes.EVERY :
                return every ? Boolean.TRUE
                             : Boolean.FALSE;

            case OpTypes.SOME :
                return some ? Boolean.TRUE
                            : Boolean.FALSE;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
                return getStdDev();

            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                return getVariance();

            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }
    }

    
    static Type getType(int setType, Type type) {

        if (setType == OpTypes.COUNT) {
            return Type.SQL_INTEGER;
        }

        
        
        
        
        
        
        if (type == null) {
            throw Error.error(ErrorCode.U_S0500);
        }
        
        int dataType = type.isIntervalType() ? Types.SQL_INTERVAL
                                             : type.typeCode;

        switch (setType) {

            case OpTypes.AVG : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                    case Types.SQL_BIGINT :
                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                    case Types.SQL_INTERVAL :
                        return type;

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.SUM : {
                switch (dataType) {

                    case Types.TINYINT :
                    case Types.SQL_SMALLINT :
                    case Types.SQL_INTEGER :
                        return Type.SQL_BIGINT;

                    case Types.SQL_BIGINT :
                        return Type.SQL_DECIMAL_BIGINT_SQR;

                    case Types.SQL_REAL :
                    case Types.SQL_FLOAT :
                    case Types.SQL_DOUBLE :
                        return Type.SQL_DOUBLE;

                    case Types.SQL_NUMERIC :
                    case Types.SQL_DECIMAL :
                        return Type.getType(type.typeCode, 0,
                                            type.precision * 2, type.scale);

                    case Types.SQL_INTERVAL :
                        return IntervalType.newIntervalType(
                            type.typeCode, DTIType.maxIntervalPrecision,
                            type.scale);

                    default :
                        throw Error.error(ErrorCode.X_42565);
                }
            }
            case OpTypes.MIN :
            case OpTypes.MAX :
                return type;

            case OpTypes.EVERY :
            case OpTypes.SOME :
                if (type.isBooleanType()) {
                    return Type.SQL_BOOLEAN;
                }
                break;

            case OpTypes.STDDEV_POP :
            case OpTypes.STDDEV_SAMP :
            case OpTypes.VAR_POP :
            case OpTypes.VAR_SAMP :
                if (type.isNumberType()) {
                    return Type.SQL_DOUBLE;
                }
                break;

            
            case OpTypes.APPROX_COUNT_DISTINCT :
                switch (dataType) {
                case Types.TINYINT :
                case Types.SQL_SMALLINT :
                case Types.SQL_INTEGER :
                case Types.SQL_BIGINT :
                case Types.SQL_DECIMAL :
                case Types.SQL_TIMESTAMP :
                    return Type.SQL_DOUBLE;
                default:
                    throw Error.error(ErrorCode.X_42565);
                }
            
            default :
                throw Error.runtimeError(ErrorCode.U_S0500, "SetFunction");
        }

        throw Error.error(ErrorCode.X_42565);
    }

    

    
    static final BigInteger multiplier =
        BigInteger.valueOf(0x0000000100000000L);


    long hi;
    long lo;

    void addLong(long value) {

        if (value == 0) {}
        else if (value > 0) {
            hi += value >> 32;
            lo += value & 0x00000000ffffffffL;
        } else {
            if (value == Long.MIN_VALUE) {
                hi -= 0x000000080000000L;
            } else {
                long temp = ~value + 1;

                hi -= temp >> 32;
                lo -= temp & 0x00000000ffffffffL;
            }
        }


    }

    BigInteger getLongSum() {

        BigInteger biglo  = BigInteger.valueOf(lo);
        BigInteger bighi  = BigInteger.valueOf(hi);
        BigInteger result = (bighi.multiply(multiplier)).add(biglo);


        return result;
    }

    
    
    
    private double  sk;
    private double  vk;
    private long    n;
    private boolean initialized;
    private boolean sample;

    private void addDataPoint(Number x) {    

        double xi;
        double xsi;
        long   nm1;

        if (x == null) {
            return;
        }

        xi = x.doubleValue();

        if (!initialized) {
            n           = 1;
            sk          = xi;
            vk          = 0.0;
            initialized = true;

            return;
        }

        n++;

        nm1 = (n - 1);
        xsi = (sk - (xi * nm1));
        vk  += ((xsi * xsi) / n) / nm1;
        sk  += xi;
    }

    private Number getVariance() {

        if (!initialized) {
            return null;
        }

        return sample ? (n == 1) ? null    
                                 : new Double(vk / (double) (n - 1))
                      : new Double(vk / (double) (n));
    }

    private Number getStdDev() {

        if (!initialized) {
            return null;
        }

        return sample ? (n == 1) ? null    
                                 : new Double(Math.sqrt(vk / (double) (n - 1)))
                      : new Double(Math.sqrt(vk / (double) (n)));
    }

    
}

<code block>


package org.voltdb.planner;

import java.net.URL;
import java.util.List;

import junit.framework.TestCase;

import org.apache.commons.lang3.StringUtils;
import org.voltdb.catalog.Database;
import org.voltdb.compiler.DeterminismMode;
import org.voltdb.plannodes.AbstractPlanNode;

public class PlannerTestCase extends TestCase {

    private PlannerTestAideDeCamp m_aide;
    private boolean m_byDefaultInferPartitioning = true;
    private boolean m_byDefaultPlanForSinglePartition;

    
    private int countQuestionMarks(String sql) {
        int paramCount = 0;
        int skip = 0;
        while (true) {
            
            skip = sql.indexOf('?', skip);
            if (skip == -1) {
                break;
            }
            skip++;
            paramCount++;
        }
        return paramCount;
    }

    protected void failToCompile(String sql, String... patterns)
    {
        int paramCount = countQuestionMarks(sql);
        try {
            m_aide.compile(sql, paramCount,
                    m_byDefaultInferPartitioning, m_byDefaultPlanForSinglePartition, null);
            fail("Expected planner failure, but found success.");
        }
        catch (Exception ex) {
            String result = ex.toString();
            for (String pattern : patterns) {
                if ( ! result.contains(pattern)) {
                    fail("Did not find pattern '" + pattern + "' in error string '" + result + "'");
                }
            }
        }
    }

    protected CompiledPlan compileAdHocPlan(String sql) {
        return compileAdHocPlan(sql, DeterminismMode.SAFER);
    }

    protected CompiledPlan compileAdHocPlan(String sql, DeterminismMode detMode) {
        CompiledPlan cp = null;
        try {
            cp = m_aide.compileAdHocPlan(sql, detMode);
            assertTrue(cp != null);
        }
        catch (Exception ex) {
            ex.printStackTrace();
            fail();
        }
        return cp;
    }

    final int paramCount = 0;
    String noJoinOrder = null;
    
    protected List<AbstractPlanNode> compileToFragments(String sql)
    {
        boolean planForSinglePartitionFalse = false;
        return compileWithJoinOrderToFragments(sql, planForSinglePartitionFalse, noJoinOrder);
    }

    protected List<AbstractPlanNode> compileToFragmentsForSinglePartition(String sql)
    {
        boolean planForSinglePartitionFalse = false;
        return compileWithJoinOrderToFragments(sql, planForSinglePartitionFalse, noJoinOrder);
    }


    
    protected List<AbstractPlanNode> compileWithJoinOrderToFragments(String sql, String joinOrder)
    {
        boolean planForSinglePartitionFalse = false;
        return compileWithJoinOrderToFragments(sql, planForSinglePartitionFalse, joinOrder);
    }

    
    private List<AbstractPlanNode> compileWithJoinOrderToFragments(String sql,
                                                                   boolean planForSinglePartition,
                                                                   String joinOrder)
    {
        
        int paramCount = StringUtils.countMatches(sql, "?");
        return compileWithJoinOrderToFragments(sql, paramCount, planForSinglePartition, joinOrder);
    }

    
    private List<AbstractPlanNode> compileWithJoinOrderToFragments(String sql, int paramCount,
                                                                   boolean planForSinglePartition,
                                                                   String joinOrder)
    {
        List<AbstractPlanNode> pn = m_aide.compile(sql, paramCount, m_byDefaultInferPartitioning, m_byDefaultPlanForSinglePartition, joinOrder);
        assertTrue(pn != null);
        assertFalse(pn.isEmpty());
        assertTrue(pn.get(0) != null);
        if (planForSinglePartition) {
            assertTrue(pn.size() == 1);
        }
        return pn;
    }

    protected AbstractPlanNode compileSPWithJoinOrder(String sql, String joinOrder)
    {
        try {
            return compileWithCountedParamsAndJoinOrder(sql, joinOrder);
        }
        catch (Exception ex) {
            ex.printStackTrace();
            fail();
            return null;
        }
    }

    protected void compileWithInvalidJoinOrder(String sql, String joinOrder) throws Exception
    {
        compileWithJoinOrderToFragments(sql, paramCount, m_byDefaultPlanForSinglePartition, joinOrder);
    }


    private AbstractPlanNode compileWithCountedParamsAndJoinOrder(String sql, String joinOrder) throws Exception
    {
        
        int paramCount = StringUtils.countMatches(sql, "?");
        return compileSPWithJoinOrder(sql, paramCount, joinOrder);
    }

    
    protected AbstractPlanNode compile(String sql)
    {
        
        int paramCount = StringUtils.countMatches(sql, "?");
        return compileSPWithJoinOrder(sql, paramCount, null);
    }

    
    protected AbstractPlanNode compileForSinglePartition(String sql)
    {
        
        int paramCount = StringUtils.countMatches(sql, "?");
        boolean m_infer = m_byDefaultInferPartitioning;
        boolean m_forceSP = m_byDefaultInferPartitioning;
        m_byDefaultInferPartitioning = false;
        m_byDefaultPlanForSinglePartition = true;

        AbstractPlanNode pn = compileSPWithJoinOrder(sql, paramCount, null);
        m_byDefaultInferPartitioning = m_infer;
        m_byDefaultPlanForSinglePartition = m_forceSP;
        return pn;
    }

    
    protected AbstractPlanNode compileSPWithJoinOrder(String sql, int paramCount, String joinOrder)
    {
        List<AbstractPlanNode> pns = null;
        try {
            pns = compileWithJoinOrderToFragments(sql, paramCount, m_byDefaultPlanForSinglePartition, joinOrder);
        }
        catch (Exception ex) {
            ex.printStackTrace();
            fail(ex.getMessage());
        }
        assertTrue(pns.get(0) != null);
        return pns.get(0);
    }


    protected void setupSchema(URL ddlURL, String basename,
                               boolean planForSinglePartition) throws Exception
    {
        m_aide = new PlannerTestAideDeCamp(ddlURL, basename);
        m_byDefaultPlanForSinglePartition = planForSinglePartition;
    }

    protected void setupSchema(boolean inferPartitioning, URL ddlURL, String basename) throws Exception
    {
        m_byDefaultInferPartitioning = inferPartitioning;
        m_aide = new PlannerTestAideDeCamp(ddlURL, basename);
    }


    Database getDatabase() {
        return m_aide.getDatabase();
    }

    protected void printExplainPlan(List<AbstractPlanNode> planNodes) {
        for (AbstractPlanNode apn: planNodes) {
            System.out.println(apn.toExplainPlanString());
        }
    }

    protected String buildExplainPlan(List<AbstractPlanNode> planNodes) {
        String explain = "";
        for (AbstractPlanNode apn: planNodes) {
            explain += apn.toExplainPlanString() + '\n';
        }
        return explain;
    }

    protected void checkQueriesPlansAreTheSame(String sql1, String sql2) {
        String explainStr1, explainStr2;
        List<AbstractPlanNode> pns = compileToFragments(sql1);
        explainStr1 = buildExplainPlan(pns);
        pns = compileToFragments(sql2);
        explainStr2 = buildExplainPlan(pns);

        assertEquals(explainStr1, explainStr2);
    }

    
    static protected void assertClassesMatchNodeChain(
            List<Class<? extends AbstractPlanNode>> expectedClasses,
            AbstractPlanNode actualPlan) {
        AbstractPlanNode pn = actualPlan;
        for (Class<? extends AbstractPlanNode> c : expectedClasses) {
            assertFalse("Actual plan shorter than expected",
                    pn == null);
            assertTrue("Expected plan to contain an instance of " + c.getSimpleName() +", "
                    + "instead found " + pn.getClass().getSimpleName(),
                    c.isInstance(pn));
            if (pn.getChildCount() > 0)
                pn = pn.getChild(0);
            else
                pn = null;
        }

        assertTrue("Actual plan longer than expected", pn == null);
    }
}

<code block>


package org.voltdb.planner;

import java.util.List;

import org.voltdb.plannodes.AbstractPlanNode;
import org.voltdb.plannodes.AggregatePlanNode;
import org.voltdb.types.ExpressionType;
import static org.voltdb.types.ExpressionType.*;
import org.voltdb.types.PlanNodeType;


public class TestPlansApproxCountDistinct extends PlannerTestCase {

    private static final int COORDINATOR_FRAG = 0;
    private static final int PARTITION_FRAG = 1;

    @Override
    protected void setUp() throws Exception {
        setupSchema(getClass().getResource("testplans-count-ddl.sql"),
                    "testcount", false);
    }

    @Override
    protected void tearDown() throws Exception {
        super.tearDown();
    }

    
    private static List<AbstractPlanNode> findAllAggPlanNodes(AbstractPlanNode node) {
        List<AbstractPlanNode> aggNodes = node.findAllNodesOfType(PlanNodeType.AGGREGATE);
        List<AbstractPlanNode> hashAggNodes = node.findAllNodesOfType(PlanNodeType.HASHAGGREGATE);
        List<AbstractPlanNode> partialAggNodes = node.findAllNodesOfType(PlanNodeType.PARTIALAGGREGATE);

        aggNodes.addAll(hashAggNodes);
        aggNodes.addAll(partialAggNodes);
        return aggNodes;
    }

    private void assertAggPlanNodeContainsFunctions(AggregatePlanNode node, ExpressionType[] expectedAggFns) {
        List<ExpressionType> actualAggFns = node.getAggregateTypes();

        assertEquals("Wrong number of aggregate functions in plan", expectedAggFns.length, actualAggFns.size());

        int i = 0;
        for (ExpressionType expectedAggFn : expectedAggFns) {
            assertEquals("Found unexpected agg function", expectedAggFn, actualAggFns.get(i));
            ++i;
        }
    }

    private void assertFragContainsAggWithFunctions(AbstractPlanNode frag, ExpressionType... expectedAggFns) {
        List<AbstractPlanNode> aggNodes = findAllAggPlanNodes(frag);
        assertFalse("No aggregation node in fragment!", 0 == aggNodes.size());
        assertEquals("More than one aggregation node in fragment!", 1, aggNodes.size());

        AggregatePlanNode aggNode = (AggregatePlanNode)aggNodes.get(0);
        assertAggPlanNodeContainsFunctions(aggNode, expectedAggFns);
    }

    private void assertFragContainsTwoAggsWithFunctions(AbstractPlanNode frag,
            ExpressionType[] expectedAggFnsFirst,
            ExpressionType[] expectedAggFnsSecond) {
        List<AbstractPlanNode> aggNodes = findAllAggPlanNodes(frag);
        assertEquals("Wrong number of aggregation nodes in fragment!", 2, aggNodes.size());

        assertAggPlanNodeContainsFunctions((AggregatePlanNode)aggNodes.get(0), expectedAggFnsFirst);
        assertAggPlanNodeContainsFunctions((AggregatePlanNode)aggNodes.get(1), expectedAggFnsSecond);
    }

    private void assertFragContainsNoAggPlanNodes(AbstractPlanNode node) {
        List<AbstractPlanNode> aggNodes = findAllAggPlanNodes(node);
        assertEquals("Found an aggregation node in fragment, but didn't expect to!", 0, aggNodes.size());
    }

    public void testSinglePartitionTableAgg() throws Exception {
        List<AbstractPlanNode> pn = compileToFragments("SELECT approx_count_distinct(age) from T1");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG), AGGREGATE_APPROX_COUNT_DISTINCT);

        pn = compileToFragments("select approx_count_distinct(age), sum(points) from t1");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_SUM);

        pn = compileToFragments("select approx_count_distinct(age), sum(distinct points) from t1");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_SUM);

    }

    public void testSinglePartitionWithGroupBy() throws Exception {
        List<AbstractPlanNode> pn = compileToFragments(
                "SELECT id, approx_count_distinct(age) "
                + "from T1 "
                + "group by id");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG), AGGREGATE_APPROX_COUNT_DISTINCT);

        pn = compileToFragments(
                "select age, approx_count_distinct(points), max(username) "
                + "from t2 "
                + "group by age");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_MAX);

        pn = compileToFragments(
                "select username, approx_count_distinct(age), avg(distinct points) "
                + "from t2 "
                + "group by username");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_AVG);
    }

    public void testMultiPartitionTableAgg() throws Exception {
        List<AbstractPlanNode> pn = compileToFragments("SELECT approx_count_distinct(num) from P1");
        assertEquals(2,  pn.size());

        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG), AGGREGATE_HYPERLOGLOGS_TO_CARD);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG), AGGREGATE_VALS_TO_HYPERLOGLOG);

        
        pn = compileToFragments("SELECT approx_count_distinct(num), count(ratio) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        pn = compileToFragments("SELECT approx_count_distinct(num), min(desc), max(ratio) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_MIN, AGGREGATE_MAX);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_MIN, AGGREGATE_MAX);

        
        pn = compileToFragments("SELECT approx_count_distinct(num), count(distinct id) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        
        pn = compileToFragments("SELECT approx_count_distinct(id), count(distinct id) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        pn = compileToFragments("SELECT sum(distinct ratio), approx_count_distinct(num) from P1");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_SUM,
                AGGREGATE_APPROX_COUNT_DISTINCT);
        assertFragContainsNoAggPlanNodes(pn.get(PARTITION_FRAG));
    }

    public void testMultiPartitionWithGroupBy() throws Exception {
        List<AbstractPlanNode> pn = compileToFragments(
                "SELECT desc as modid, approx_count_distinct(num) "
                + "from P1 "
                + "group by desc");
        assertEquals(2,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG), AGGREGATE_HYPERLOGLOGS_TO_CARD);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG), AGGREGATE_VALS_TO_HYPERLOGLOG);

        
        pn = compileToFragments("SELECT desc, approx_count_distinct(num), count(ratio) "
                + "from P1 "
                + "group by desc");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        pn = compileToFragments(
                "SELECT desc, approx_count_distinct(num), max(ratio) "
                + "from P1 "
                + "group by desc");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_MAX);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_MAX);

        
        pn = compileToFragments(
                "SELECT ratio, approx_count_distinct(num), count(distinct id) "
                + "from P1 "
                + "group by ratio");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        
        pn = compileToFragments(
                "SELECT desc, approx_count_distinct(id), count(distinct id) "
                + "from P1 "
                + "group by desc");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG,
                AGGREGATE_COUNT);

        
        
        
        pn = compileToFragments(
                "SELECT id, sum(distinct ratio), approx_count_distinct(num) "
                + "from P1 "
                + "group by id");
        assertFragContainsNoAggPlanNodes(pn.get(COORDINATOR_FRAG));
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_SUM,
                AGGREGATE_APPROX_COUNT_DISTINCT);
    }

    public void testWithSubqueries() throws Exception {

        
        List<AbstractPlanNode> pn = compileToFragments(
                "select * "
                + "from "
                + "  T1, "
                + "  (select approx_count_distinct(age) from t1) as subq");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT);

        
        pn = compileToFragments(
                "select * "
                + "from "
                + "  (select username, approx_count_distinct(age), avg(distinct points) "
                + "   from t2 "
                + "   group by username) as subq"
                + "  inner join t2 "
                + "  on t2.username = subq.username;");
        assertEquals(1,  pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_AVG);

        
        pn = compileToFragments(
                "select * "
                + "from "
                + "t1, "
                + "(SELECT sum(distinct ratio), approx_count_distinct(num) from P1) as subq");
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_SUM,
                AGGREGATE_APPROX_COUNT_DISTINCT);
        assertFragContainsNoAggPlanNodes(pn.get(PARTITION_FRAG));

        
        pn = compileToFragments(
                "select * "
                + "from p1 "
                + "inner join "
                + "(SELECT id, sum(distinct ratio), approx_count_distinct(num) "
                + "from P1 "
                + "where id = 10 "
                + "group by id) as subq "
                + "on subq.id = p1.id");
        assertEquals(1, pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_SUM,
                AGGREGATE_APPROX_COUNT_DISTINCT);

        
        pn = compileToFragments(
                "select * "
                + "from t1 "
                + "inner join "
                + "(SELECT id, approx_count_distinct(num) "
                + "from P1 "
                + "group by id) as subq "
                + "on subq.id = t1.id");
        for (AbstractPlanNode n : pn) {
            System.out.println(n.toExplainPlanString());
        }
        assertEquals(2, pn.size());
        assertFragContainsNoAggPlanNodes(pn.get(COORDINATOR_FRAG));
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT);
    }

    public void testSubqueriesWithMultipleAggs() throws Exception {
        List<AbstractPlanNode> pn;

        
        
        pn = compileToFragments("select approx_count_distinct(num) "
                + "from (select approx_count_distinct(points) from t1) as repl_subquery,"
                + "  p1");
        assertEquals(2, pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_HYPERLOGLOGS_TO_CARD);
        assertFragContainsTwoAggsWithFunctions(pn.get(PARTITION_FRAG),
                new ExpressionType[] {AGGREGATE_APPROX_COUNT_DISTINCT},
                new ExpressionType[] {AGGREGATE_VALS_TO_HYPERLOGLOG});

        
        
        pn = compileToFragments("select approx_count_distinct(num), sum(distinct num) "
                + "from (select approx_count_distinct(points) from t1) as repl_subquery,"
                + "  p1");
        assertEquals(2, pn.size());
        assertFragContainsAggWithFunctions(pn.get(COORDINATOR_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT,
                AGGREGATE_SUM);
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_APPROX_COUNT_DISTINCT);

        
        pn = compileToFragments("select approx_count_distinct(points) "
                + "from (select approx_count_distinct(num) from p1) as repl_subquery,"
                + "  t1");
        assertEquals(2, pn.size());
        assertFragContainsTwoAggsWithFunctions(pn.get(COORDINATOR_FRAG),
                new ExpressionType[] {AGGREGATE_HYPERLOGLOGS_TO_CARD},
                new ExpressionType[] {AGGREGATE_APPROX_COUNT_DISTINCT});
        assertFragContainsAggWithFunctions(pn.get(PARTITION_FRAG),
                AGGREGATE_VALS_TO_HYPERLOGLOG);

        
        
        pn = compileToFragments("select approx_count_distinct(points) "
                + "from (select approx_count_distinct(num), sum(distinct num) from p1) as repl_subquery,"
                + "  t1");
        assertEquals(2, pn.size());
        assertFragContainsTwoAggsWithFunctions(pn.get(COORDINATOR_FRAG),
                new ExpressionType[] {AGGREGATE_APPROX_COUNT_DISTINCT, AGGREGATE_SUM},
                new ExpressionType[] {AGGREGATE_APPROX_COUNT_DISTINCT});
        assertFragContainsNoAggPlanNodes(pn.get(PARTITION_FRAG));
    }
}

<code block>


package org.voltdb;

import com.google_voltpatches.common.base.Charsets;


public enum OperationMode {
    INITIALIZING, RUNNING, PAUSED, SHUTTINGDOWN;

    private final byte [] bytes;

    OperationMode() {
        bytes = name().getBytes(Charsets.UTF_8);
    }

    
    public static OperationMode get(byte val) {
        for (OperationMode mode : OperationMode.values()) {
            if (mode.ordinal() == val) {
                return mode;
            }
        }
        throw new AssertionError("Unknown mode: " + val);
    }

    public byte [] getBytes() {
        return bytes;
    }

    public static OperationMode valueOf(byte [] bytes) {
        return valueOf(new String(bytes, Charsets.UTF_8));
    }
}

<code block>

package org.voltdb.importclient.kafka;

import java.net.URI;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.SortedSet;
import java.util.TreeSet;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;

import kafka.api.ConsumerMetadataRequest;
import kafka.api.FetchRequest;
import kafka.api.FetchRequestBuilder;
import kafka.api.PartitionOffsetRequestInfo;
import kafka.cluster.Broker;
import kafka.common.ErrorMapping;
import kafka.common.OffsetAndMetadata;
import kafka.common.TopicAndPartition;
import kafka.javaapi.ConsumerMetadataResponse;
import kafka.javaapi.FetchResponse;
import kafka.javaapi.OffsetCommitRequest;
import kafka.javaapi.OffsetCommitResponse;
import kafka.javaapi.OffsetResponse;
import kafka.javaapi.PartitionMetadata;
import kafka.javaapi.TopicMetadata;
import kafka.javaapi.TopicMetadataRequest;
import kafka.javaapi.consumer.SimpleConsumer;
import kafka.message.MessageAndOffset;
import kafka.network.BlockingChannel;

import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltdb.VoltDB;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureCallback;
import org.voltdb.importer.CSVInvocation;
import org.voltdb.importer.ImportHandlerProxy;
import org.voltdb.importer.ImporterChannelAssignment;
import org.voltdb.importer.VersionedOperationMode;


public class KafkaStreamImporter extends ImportHandlerProxy implements BundleActivator {

    
    private Properties m_properties;
    
    private String m_groupId;
    
    private String m_procedure;
    
    private List<String> m_topicList;
    
    private final List<HostAndPort> m_brokerList = new ArrayList<HostAndPort>();
    
    private int m_fetchSize = (2*1024*1024);
    private int m_consumerSocketTimeout = 30000; 

    private static final String GROUP_ID = "voltdb";
    private static final String CLIENT_ID = "voltdb-importer";
    private static final int KAFKA_DEFAULT_BROKER_PORT = 9092;
    
    private final Semaphore m_done = new Semaphore(0);
    private boolean m_stopping = false;

    
    private final Map<String, List<TopicMetadata>> m_topicPartitionMetaData = new HashMap<String, List<TopicMetadata>>();
    
    private final Map<String, List<Integer>> m_topicPartitions = new HashMap<String, List<Integer>>();
    
    private final Map<String, HostAndPort> m_topicPartitionLeader = new HashMap<String, HostAndPort>();
    private final Map<String, TopicPartitionFetcher> m_fetchers = new HashMap<String, TopicPartitionFetcher>();

    private ExecutorService m_es = null;

    
    public static class HostAndPort {

        private final String m_host;
        private final int m_port;
        private final String m_connectionString;

        public HostAndPort(String h, int p) {
            m_host = h;
            m_port = p;
            m_connectionString = m_host + ":" + m_port;
        }

        public static HostAndPort fromString(String hap) {
            String s[] = hap.split(":");
            int p = KAFKA_DEFAULT_BROKER_PORT;
            if (s.length > 1 && s[1] != null && s[1].length() > 0) {
                p = Integer.parseInt(s[1].trim());
            }
            return new HostAndPort(s[0].trim(), p);
        }

        public String getHost() {
            return m_host;
        }

        public int getPort() {
            return m_port;
        }

        @Override
        public String toString() {
            return m_host + ":" + m_port;
        }

        @Override
        public int hashCode() {
            return m_connectionString.hashCode();
        }

        @Override
        public boolean equals(Object o) {
            if (!(o instanceof HostAndPort)) {
                return false;
            }
            HostAndPort hap = (HostAndPort )o;
            if (hap == this) {
                return true;
            }
            if (hap.getHost().equals(getHost()) && hap.getPort() == getPort()) {
                return true;
            }
            return false;
        }
    }

    
    @Override
    public void start(BundleContext context) throws Exception {
        context.registerService(this.getClass().getName(), this, null);
    }

    @Override
    public void stop(BundleContext context) throws Exception {
        
    }

    @Override
    public boolean isRunEveryWhere() {
        
        return false;
    }

    
    private Set<URI> buildTopicLeaderMetadata(SimpleConsumer consumer) {

        
        Set<URI> availableResources = new TreeSet<URI>();
        for (String topic : m_topicList) {
            TopicMetadataRequest req = new TopicMetadataRequest(Collections.singletonList(topic));
            kafka.javaapi.TopicMetadataResponse resp = null;
            try {
                resp = consumer.send(req);
            } catch (Exception ex) {
                error("Failed to send topic metada request for topic " + topic, ex);
                continue;
            }

            List<TopicMetadata> metaData = resp.topicsMetadata();
            if (metaData == null) {
                error("Failed to get topic metadata for topic " + topic);
                continue;
            }
            m_topicPartitionMetaData.put(topic, metaData);
            List<Integer> partitions = m_topicPartitions.get(topic);
            if (partitions == null) {
                partitions = new ArrayList<Integer>();
                m_topicPartitions.put(topic, partitions);
            }
            for (TopicMetadata item : metaData) {
                for (PartitionMetadata part : item.partitionsMetadata()) {
                    partitions.add(part.partitionId());
                    for (kafka.cluster.Broker replica : part.replicas()) {
                        String leaderKey = topic + "-" + part.partitionId();
                        m_topicPartitionLeader.put(leaderKey, new HostAndPort(replica.host(), replica.port()));
                        URI uri = URI.create("kafka:/" + topic + "/partition/" + part.partitionId());
                        availableResources.add(uri);
                    }
                }
            }
        }

        info("Available Channels are: " + availableResources);
        
        m_es = Executors.newFixedThreadPool(availableResources.size() + 1);
        return availableResources;
    }

    @Override
    public Set<URI> getAllResponsibleResources() {
        SimpleConsumer simpleConsumer = null;
        Set<URI> availableResources = new TreeSet<URI>();
        try {
            simpleConsumer = new SimpleConsumer(m_brokerList.get(0).getHost(), m_brokerList.get(0).getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID);
            
            availableResources = buildTopicLeaderMetadata(simpleConsumer);
        } catch (Exception ex) {
            VoltDB.crashLocalVoltDB("Failed to get available resources for kafka importer", true, ex);
        } finally {
            closeConsumer(simpleConsumer);
        }
        return availableResources;
    }

    @Override
    public void stop() {
        m_stopping = true;
        
        for (TopicPartitionFetcher fetcher : m_fetchers.values()) {
            fetcher.shutdown();
        }
        m_done.release();
        if (m_es != null) {
            
            m_es.shutdown();
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException ex) {
                
                ex.printStackTrace();
            }
        }
        m_fetchers.clear();
    }

    
    @Override
    public String getName() {
        return "KafkaImporter82";
    }

    
    @Override
    public void configure(Properties p) {
        m_properties = (Properties) p.clone();
        m_procedure = m_properties.getProperty("procedure", "").trim();
        if (m_procedure.isEmpty()) {
            throw new RuntimeException("Missing procedure.");
        }
        
        String topics = m_properties.getProperty("topics", "").trim();
        if (topics.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
        m_topicList = Arrays.asList(topics.split("\\s*,\\s*"));
        if (m_topicList == null || m_topicList.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
       String brokers = m_properties.getProperty("brokers", "").trim();
        if (brokers.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        List<String> brokerList = Arrays.asList(brokers.split("\\s*,\\s*"));
        if (brokerList == null || brokerList.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        for (String broker : brokerList) {
            HostAndPort hap = HostAndPort.fromString(broker);
            m_brokerList.add(hap);
        }
        if (m_brokerList.isEmpty()) {
            throw new RuntimeException("Missing or misconfigured kafka broker list. See brokers property");
        }
        m_groupId = m_properties.getProperty("groupid", GROUP_ID).trim();
        
        m_fetchSize = Integer.parseInt(m_properties.getProperty("fetch.message.max.bytes", "65536"));
        m_consumerSocketTimeout = Integer.parseInt(m_properties.getProperty("socket.timeout.ms", "30000"));
    }

    
    private class TopicPartitionFetcher implements Runnable {

        
        private final URI m_url;
        
        private final HostAndPort m_leader;
        
        private HostAndPort m_coordinator;
        private boolean m_shutdown = false;
        private final int m_fetchSize;
        
        private final List<HostAndPort> m_brokers;
        private final int m_consumerSocketTimeout;
        
        private final AtomicLong m_currentOffset = new AtomicLong(-1);
        private final SortedSet<Long> m_pendingOffsets = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final SortedSet<Long> m_seenOffset = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final int m_perTopicPendingLimit = Integer.getInteger("voltdb.kafka.pertopicPendingLimit", 50000);
        private final AtomicReference<SimpleConsumer> m_offsetManager = new AtomicReference<SimpleConsumer>();
        private final TopicAndPartition m_topicAndPartition;

        public TopicPartitionFetcher(List<HostAndPort> brokers, URI uri, String topic, int partition, HostAndPort leader, int fetchSize, int consumerSocketTimeout) {
            m_url = uri;
            m_brokers = brokers;
            m_leader = leader;
            m_coordinator = leader;
            m_fetchSize = fetchSize;
            m_consumerSocketTimeout = consumerSocketTimeout;
            m_topicAndPartition = new TopicAndPartition(topic, partition);
        }

        public final URI getUrl() {
            return m_url;
        }

        
        private PartitionMetadata findLeader() {
            PartitionMetadata returnMetaData = null;
            loop:
            for (HostAndPort broker : m_brokers) {
                SimpleConsumer consumer = null;
                try {
                    consumer = new SimpleConsumer(broker.getHost(), broker.getPort(), m_consumerSocketTimeout, m_fetchSize, "findLeader");

                    List<String> topics = Collections.singletonList(m_topicAndPartition.topic());
                    TopicMetadataRequest req = new TopicMetadataRequest(topics);
                    kafka.javaapi.TopicMetadataResponse resp = consumer.send(req);

                    List<TopicMetadata> metaData = resp.topicsMetadata();
                    for (TopicMetadata item : metaData) {
                        for (PartitionMetadata part : item.partitionsMetadata()) {
                            if (part.partitionId() == m_topicAndPartition.partition()) {
                                returnMetaData = part;
                                break loop;
                            }
                        }
                    }
                } catch (Exception e) {
                    error("Error in finding leader for " + m_topicAndPartition, e);
                } finally {
                    closeConsumer(consumer);
                }
            }
            if (returnMetaData == null) {
                error("Failed to find Leader for " + m_topicAndPartition);
            }
            return returnMetaData;
        }

        
        private HostAndPort findNewLeader() {
            for (int i = 0; i < 3; i++) {
                boolean shouldSleep = false;
                PartitionMetadata metadata = findLeader();
                if (metadata == null) {
                    shouldSleep = true;
                } else if (metadata.leader() == null) {
                    shouldSleep = true;
                } else if (m_leader.getHost().equalsIgnoreCase(metadata.leader().host()) && i == 0) {
                    
                    
                    shouldSleep = true;
                } else {
                    return new HostAndPort(metadata.leader().host(), metadata.leader().port());
                }
                if (shouldSleep) {
                    backoffSleep(i+1);
                }
            }
            
            info("Failed to find new leader for " + m_topicAndPartition);
            return null;
        }

        
        public void shutdown() {
            m_shutdown = true;
        }

        public void getOffsetCoordinator() {
            BlockingChannel channel = null;
            for (int i = 0; i < 3; i++) {
                try {
                    
                    channel = new BlockingChannel(m_coordinator.getHost(), m_coordinator.getPort(),
                            BlockingChannel.UseDefaultBufferSize(),
                            BlockingChannel.UseDefaultBufferSize(),
                            m_consumerSocketTimeout );
                    channel.connect();
                    int correlationId = 0;
                    channel.send(new ConsumerMetadataRequest(m_groupId, ConsumerMetadataRequest.CurrentVersion(), correlationId++, CLIENT_ID));
                    ConsumerMetadataResponse metadataResponse = ConsumerMetadataResponse.readFrom(channel.receive().buffer());

                    if (metadataResponse.errorCode() == ErrorMapping.NoError()) {
                        Broker offsetManager = metadataResponse.coordinator();
                        m_coordinator = new HostAndPort(offsetManager.host(), offsetManager.port());
                        SimpleConsumer consumer = m_offsetManager.getAndSet(new SimpleConsumer(m_coordinator.getHost(), m_coordinator.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID) );
                        closeConsumer(consumer);
                        consumer = null;
                        break;
                    }
                    error("Failed to get Offset Coordinator for " + m_topicAndPartition + " Code: " + metadataResponse.errorCode());
                } catch (Exception e) {
                    
                    error("Failed to get Offset Coordinator for " + m_topicAndPartition, e);
                    backoffSleep(i+1);
                } finally {
                    if (channel != null) {
                        channel.disconnect();
                    }
                }
            }
            info("Coordinator for " + m_topicAndPartition + " consumer is: " + m_coordinator);
        }

        public long getLastOffset(long whichTime) {
            if (m_offsetManager.get() == null) {
                return -1;
            }
            SimpleConsumer consumer = m_offsetManager.get();
            try {
                Map<TopicAndPartition, PartitionOffsetRequestInfo> requestInfo = new HashMap<TopicAndPartition, PartitionOffsetRequestInfo>();
                requestInfo.put(m_topicAndPartition, new PartitionOffsetRequestInfo(whichTime, 1));
                kafka.javaapi.OffsetRequest request = new kafka.javaapi.OffsetRequest(requestInfo, kafka.api.OffsetRequest.CurrentVersion(), CLIENT_ID);
                OffsetResponse response = consumer.getOffsetsBefore(request);

                if (response.hasError()) {
                    short code = response.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                    if (code == ErrorMapping.NotLeaderForPartitionCode() || code == ErrorMapping.UnknownTopicOrPartitionCode()) {
                        HostAndPort leaderBroker = findNewLeader();
                        if (leaderBroker != null) {
                            info("Found new leader for " + m_topicAndPartition + " Coordinator will be updated.");
                            SimpleConsumer oconsumer = m_offsetManager.getAndSet(new SimpleConsumer(leaderBroker.getHost(), leaderBroker.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID) );
                            closeConsumer(oconsumer);
                            oconsumer = null;
                            m_coordinator = leaderBroker;
                        }
                    }
                    info("Error fetching Offset Data from Broker " + m_topicAndPartition.toString() +
                            " Reason: " + response.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition()) );
                    return -1;
                }
                long[] offsets = response.offsets(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                return offsets[0];
            } catch (Exception ex) {
                error("Failed to get last Offset for " + m_topicAndPartition, ex);
            }
            return -1;
        }

        
        private class TopicPartitionInvocationCallback implements ProcedureCallback {

            private final long m_offset;
            private final long m_nextOffset;
            private final TopicAndPartition m_topicAndPartition;

            public TopicPartitionInvocationCallback(long offset, long noffset, TopicAndPartition tAndP) {
                m_offset = offset;
                m_nextOffset = noffset;
                m_topicAndPartition = tAndP;
            }

            public boolean commitOffset(long offset) {

                final int correlationId = m_topicAndPartition.partition();
                final short version = 1;

                OffsetAndMetadata offsetMetdata = new OffsetAndMetadata(offset, "commitRequest", ErrorMapping.NoError());
                Map<TopicAndPartition, OffsetAndMetadata> reqMap = new HashMap<TopicAndPartition, OffsetAndMetadata>();
                reqMap.put(m_topicAndPartition, offsetMetdata);
                OffsetCommitRequest offsetCommitRequest = new OffsetCommitRequest(m_groupId, reqMap, correlationId, CLIENT_ID, version);
                OffsetCommitResponse offsetCommitResponse = null;
                try {
                    SimpleConsumer consumer = m_offsetManager.get();
                    if (consumer == null) {
                        getOffsetCoordinator();
                        consumer = m_offsetManager.get();
                    }
                    if (consumer != null) {
                        offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                        final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
                        if (code == ErrorMapping.NotCoordinatorForConsumerCode()) {
                            info("Not coordinator for committing offset for " + m_topicAndPartition + " Updating coordinator.");
                            getOffsetCoordinator();
                            consumer = m_offsetManager.get();
                            if (consumer != null) {
                                offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                            }
                        }
                    } else {
                        error("Commit Offset Failed to get offset coordinator for " + m_topicAndPartition);
                        return false;
                    }
                } catch (Exception e) {
                    error("Failed to commit Offset for " + m_topicAndPartition, e);
                    return false;
                }
                final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
                if (code != ErrorMapping.NoError()) {
                    error("Commit Offset Failed to commit for " + m_topicAndPartition + " Code: " + code);
                    return false;
                }
                return true;
            }

            private void commitAndSaveOffset(long currentNext) {
                try {
                    
                    if (m_seenOffset.size() >= m_perTopicPendingLimit) {
                        
                        long commit = m_seenOffset.last();
                        if (commitOffset(commit)) {
                            debug("Committed offset " + commit + " for " + m_topicAndPartition);
                            m_currentOffset.set(commit);
                        }
                        synchronized(m_seenOffset) {
                            m_seenOffset.clear();
                        }
                        info("Seen offset commit list is too big. Size " + m_perTopicPendingLimit + " Commiting highest offset and clean.");
                        return;
                    }
                    long commit;
                    synchronized(m_seenOffset) {
                        if (!m_seenOffset.isEmpty()) {
                            m_seenOffset.add(currentNext);
                            
                            commit = m_seenOffset.first();
                            while (m_seenOffset.contains(++commit)) {
                                m_seenOffset.remove(commit);
                            }
                        } else {
                           commit =  currentNext;
                        }
                    }

                    
                    if (commitOffset(commit)) {
                        debug("Committed offset " + commit + " for " + m_topicAndPartition);
                        m_currentOffset.set(commit);
                    }
                    
                } catch (Exception ex) {
                    error("Failed to commit and save offset " + currentNext, ex);
                }
            }

            @Override
            public void clientCallback(ClientResponse response) throws Exception {
                try {
                    
                    assert(!m_pendingOffsets.isEmpty());

                    m_pendingOffsets.remove(m_offset);
                    commitAndSaveOffset(m_nextOffset);

                } catch (Throwable t) {
                    
                  t.printStackTrace();
                }
            }

        }

        
        private int backoffSleep(int fetchFailedCount) {
            try {
                Thread.sleep(1000 * fetchFailedCount++);
                if (fetchFailedCount > 10) fetchFailedCount = 1;
            } catch (InterruptedException ie) {
            }
            return fetchFailedCount;
        }

        @Override
        public void run() {
            SimpleConsumer consumer = null;
            info("Starting partition fetcher for " + m_topicAndPartition);
            try {
                
                HostAndPort leaderBroker = m_leader;
                int fetchFailedCount = 1;
                while (!m_shutdown) {
                    if (consumer == null) {
                        consumer = new SimpleConsumer(leaderBroker.getHost(), leaderBroker.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID);
                    }
                    
                    if (m_currentOffset.get() < 0) {
                        getOffsetCoordinator();
                        m_currentOffset.set(getLastOffset(kafka.api.OffsetRequest.LatestTime()));
                        if (m_currentOffset.get() < 0) {
                            fetchFailedCount = backoffSleep(fetchFailedCount);
                            continue;
                        }
                        info("Starting offset for " + m_topicAndPartition + " is set to: " + m_currentOffset.get());
                    }
                    long currentFetchCount = 0;
                    
                    if (m_pendingOffsets.size() < m_perTopicPendingLimit) {
                        FetchRequest req = new FetchRequestBuilder().clientId(CLIENT_ID)
                                .addFetch(m_topicAndPartition.topic(),
                                        m_topicAndPartition.partition(), m_currentOffset.get(), m_fetchSize)
                                .build();
                        FetchResponse fetchResponse = null;
                        try {
                            fetchResponse = consumer.fetch(req);
                            if (fetchResponse == null) {
                                fetchFailedCount = backoffSleep(fetchFailedCount);
                                continue;
                            }
                        } catch (Exception ex) {
                            error("Failed to fetch from " + m_topicAndPartition, ex);
                            fetchFailedCount = backoffSleep(fetchFailedCount);
                            continue;
                        }

                        if (fetchResponse.hasError()) {
                            
                            short code = fetchResponse.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                            fetchFailedCount = backoffSleep(fetchFailedCount);
                            error("Failed to fetch messages for " + m_topicAndPartition + " Code " + code);
                            if (code == ErrorMapping.OffsetOutOfRangeCode()) {
                                
                                info("Invalid offset requested for " + m_topicAndPartition);
                                getOffsetCoordinator();
                                m_currentOffset.set(getLastOffset(kafka.api.OffsetRequest.LatestTime()));
                                continue;
                            }
                            closeConsumer(consumer);
                            consumer = null;
                            leaderBroker = findNewLeader();
                            if (leaderBroker == null) {
                                
                                error("Failed to find leader continue with old leader: " + m_leader);
                                leaderBroker = m_leader;
                            } else {
                                if (!leaderBroker.equals(m_leader)) {
                                    info("Found new leader for " + m_topicAndPartition + " New Leader: " + leaderBroker);
                                }
                            }
                            continue;
                        }
                        fetchFailedCount = 1;
                        for (MessageAndOffset messageAndOffset : fetchResponse.messageSet(m_topicAndPartition.topic(), m_topicAndPartition.partition())) {
                            long currentOffset = messageAndOffset.offset();
                            
                            if (currentOffset < m_currentOffset.get() || m_pendingOffsets.contains(currentOffset)) {
                                continue;
                            }
                            ByteBuffer payload = messageAndOffset.message().payload();

                            currentFetchCount++;
                            byte[] bytes = new byte[payload.limit()];
                            payload.get(bytes);
                            String line = new String(bytes, "UTF-8");
                            CSVInvocation invocation = new CSVInvocation(m_procedure, line);
                            TopicPartitionInvocationCallback cb = new TopicPartitionInvocationCallback(currentOffset, messageAndOffset.nextOffset(), m_topicAndPartition);
                            m_pendingOffsets.add(currentOffset);
                            if (!callProcedure(cb, invocation)) {
                                debug("Failed to process Invocation possibly bad data: " + line);
                                m_pendingOffsets.remove(messageAndOffset.nextOffset());
                                
                                synchronized(m_seenOffset) {
                                    m_seenOffset.add(messageAndOffset.nextOffset());
                                }
                                continue;
                            }
                        }
                    }

                    if (currentFetchCount == 0) {
                        try {
                            Thread.sleep(1000);
                        } catch (InterruptedException ie) {
                        }
                    }
                }
                info("Partition fecher stopping for " + m_topicAndPartition);
                int cnt = 1;
                while (m_pendingOffsets.size() > 0) {
                    cnt = backoffSleep(cnt);
                }
                info("Partition fecher stopped for " + m_topicAndPartition + " Last commit point is: " + m_currentOffset.get());
            } catch (Exception ex) {
                error("Failed to start topic partition fetcher for " + m_topicAndPartition, ex);
            } finally {
                closeConsumer(consumer);
                consumer = null;
            }
        }

    }

    public void closeConsumer(SimpleConsumer consumer) {
        try {
            if (consumer != null) {
                consumer.close();
            }
        } catch (Exception e) {
            error("Failed to close consumer connection.", e);
        }
    }

    
    @Override
    public void onChange(ImporterChannelAssignment assignment) {
        if (m_stopping) {
            info("Importer is stopping, ignoring the change notification.");
            return;
        }
        if (m_es == null) {
            
            VoltDB.crashLocalVoltDB("buildTopicLeaderMetadata must be called before getting an onChange", false, null);
        }

        
        for (URI nuri : assignment.getAdded()) {
            Map<String, List<Integer>> topicMap = new HashMap<String, List<Integer>>();
            for (String topic : m_topicList) {
                topicMap.put(topic, Collections.singletonList(0));
            }
            for (String topic : m_topicList) {
                List<Integer> topicPartitions = m_topicPartitions.get(topic);
                if (topicPartitions == null) {
                    
                    VoltDB.crashLocalVoltDB("Unknown kafka topic added for this node", false, null);
                }
                for (int partition : topicPartitions) {
                    String leaderKey = topic + "-" + partition;
                    URI assignedKey = URI.create("kafka:/" + topic + "/partition/" + partition);
                    
                    if (!m_fetchers.containsKey(nuri) && nuri.equals(assignedKey)) {
                        info("Channel " + assignedKey + " mastership is assigned to this node.");
                        HostAndPort hap = m_topicPartitionLeader.get(leaderKey);
                        TopicPartitionFetcher fetcher = new TopicPartitionFetcher(m_brokerList, assignedKey, topic, partition,
                                hap, m_fetchSize, m_consumerSocketTimeout);
                        m_fetchers.put(assignedKey.toString(), fetcher);
                        m_es.submit(fetcher);
                        info("KafkaImporter is fetching for resource: " + nuri);
                    }
                }
            }
        }

        
        for (URI r : assignment.getRemoved()) {
            TopicPartitionFetcher fetcher = m_fetchers.get(r.toString());
            if (fetcher != null) {
                fetcher.shutdown();
                info("KafkaImporter is NOT fetching for resource: " + r);
                m_fetchers.remove(r.toString());
            }
        }
    }

    
    @Override
    public void onClusterStateChange(VersionedOperationMode mode) {
        info("cluster state change notification: " + mode);
    }

    
    @Override
    public void readyForData() {
        try {
            info("Configured and ready with properties: " + m_properties);
            
            m_done.acquire();
        } catch (Exception ex) {
            error("Kafka Importer finished with exeception ", ex);
        }
    }

}

<code block>


package org.voltdb.sysprocs;

import java.util.List;
import java.util.Map;

import org.voltdb.DependencyPair;
import org.voltdb.OperationMode;
import org.voltdb.ParameterSet;
import org.voltdb.ProcInfo;
import org.voltdb.SystemProcedureExecutionContext;
import org.voltdb.VoltDB;
import org.voltdb.VoltSystemProcedure;
import org.voltdb.VoltTable;
import org.voltdb.VoltZK;

@ProcInfo(singlePartition = false)

public class Resume extends VoltSystemProcedure
{
    @Override
    public void init() {}

    @Override
    public DependencyPair executePlanFragment(
            Map<Integer, List<VoltTable>> dependencies, long fragmentId,
            ParameterSet params, SystemProcedureExecutionContext context)
    {
        throw new RuntimeException("Resume was given an " +
                                   "invalid fragment id: " + String.valueOf(fragmentId));
    }

    
    public VoltTable[] run(SystemProcedureExecutionContext ctx)
    {
        
        if (ctx.isLowestSiteId())
        {
            VoltDB.instance().setMode(OperationMode.RUNNING);
            try {
                VoltDB.instance().getHostMessenger().getZK().setData(
                        VoltZK.operationMode,
                        OperationMode.RUNNING.getBytes(), -1);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }

        VoltTable t = new VoltTable(VoltSystemProcedure.STATUS_SCHEMA);
        t.addRow(VoltSystemProcedure.STATUS_OK);
        return (new VoltTable[] {t});
    }
}

<code block>


package org.voltdb.sysprocs;

import java.util.List;
import java.util.Map;

import org.voltdb.DependencyPair;
import org.voltdb.OperationMode;
import org.voltdb.ParameterSet;
import org.voltdb.ProcInfo;
import org.voltdb.SystemProcedureExecutionContext;
import org.voltdb.VoltDB;
import org.voltdb.VoltSystemProcedure;
import org.voltdb.VoltTable;
import org.voltdb.VoltZK;

@ProcInfo(singlePartition = false)

public class Pause extends VoltSystemProcedure
{
    @Override
    public void init() {}

    @Override
    public DependencyPair executePlanFragment(
            Map<Integer, List<VoltTable>> dependencies, long fragmentId,
            ParameterSet params, SystemProcedureExecutionContext context)
    {
        throw new RuntimeException("Pause was given an " +
                                   "invalid fragment id: " + String.valueOf(fragmentId));
    }

    
    public VoltTable[] run(SystemProcedureExecutionContext ctx)
    {
        
        if (ctx.isLowestSiteId())
        {
            VoltDB.instance().setMode(OperationMode.PAUSED);
            try {
                VoltDB.instance().getHostMessenger().getZK().setData(
                        VoltZK.operationMode,
                        OperationMode.PAUSED.getBytes(), -1);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }

        VoltTable t = new VoltTable(VoltSystemProcedure.STATUS_SCHEMA);
        t.addRow(VoltSystemProcedure.STATUS_OK);
        return (new VoltTable[] {t});
    }
}

<code block>


package org.voltdb.importer;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.net.URI;
import java.util.Set;
import java.util.concurrent.TimeUnit;

import org.voltdb.client.ProcedureCallback;


public abstract class ImportHandlerProxy implements ImportContext, ChannelChangeCallback {

    private Object m_handler = null;
    private Method m_callProcMethod;
    private Method m_asyncCallProcMethod;
    private Method m_hasTableMethod;
    private Method m_info_log;
    private Method m_error_log;
    private Method m_warn_log;
    private Method m_error_log_withT;
    private Method m_debug_log;

    @Override
    public boolean canContinue() {
        return true;
    }

    public boolean hasTable(String name) {
        try {
            return (Boolean) m_hasTableMethod.invoke(m_handler, name);
        } catch(InvocationTargetException e) { 
            throw new RuntimeException(e);
        } catch(IllegalAccessException e) { 
            throw new RuntimeException(e);
        }
    }

    
    @Override
    public boolean callProcedure(String proc, Object... fieldList) {
        try {
            return (Boolean )m_callProcMethod.invoke(m_handler, this, proc, fieldList);
        } catch (Exception ex) {
            return false;
        }
    }

    @Override
    public boolean callProcedure(Invocation invocation) {
        try {
            Object params[] = invocation.getParams();
            return (Boolean )m_callProcMethod.invoke(m_handler, this, invocation.getProcedure(), params);
        } catch (Exception ex) {
            return false;
        }
    }

    @Override
    public boolean callProcedure(ProcedureCallback cb, Invocation invocation) {
        try {
            Object params[] = invocation.getParams();
            return (Boolean )m_asyncCallProcMethod.invoke(m_handler, this, cb, invocation.getProcedure(), params);
        } catch (Exception ex) {
            return false;
        }
    }

    @Override
    public void setHandler(Object handler) throws Exception {
        m_handler = handler;
        m_callProcMethod = m_handler.getClass().getMethod("callProcedure", ImportContext.class, String.class, Object[].class);
        m_asyncCallProcMethod = m_handler.getClass().getMethod("callProcedure", ImportContext.class, ProcedureCallback.class, String.class, Object[].class);
        m_hasTableMethod = m_handler.getClass().getMethod("hasTable", String.class);
        m_info_log = m_handler.getClass().getMethod("info", String.class);
        m_error_log = m_handler.getClass().getMethod("error", String.class);
        m_warn_log = m_handler.getClass().getMethod("warn", String.class);
        m_debug_log = m_handler.getClass().getMethod("debug", String.class);
        m_error_log_withT = m_handler.getClass().getMethod("error", String.class, Throwable.class);
    }

    @Override
    public void info(String message) {
        try {
            if (m_info_log != null) {
                m_info_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void error(String message, Throwable t) {
        try {
            if (m_error_log != null) {
                m_error_log_withT.invoke(m_handler, message, t);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void error(String message) {
        try {
            if (m_error_log != null) {
                m_error_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void warn(String message) {
        try {
            if (m_error_log != null) {
                m_warn_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void debug(String message) {
        try {
            if (m_debug_log != null) {
                m_debug_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public long getBackpressureTimeout() {
        return TimeUnit.MINUTES.toNanos(2);
    }

    @Override
    public boolean isRunEveryWhere() {
        return true;
    }

    @Override
    public Set<URI> getAllResponsibleResources() {
        throw new UnsupportedOperationException("For Distributed Importer this must be implemented.");
    }

    @Override
    public void onChange(ImporterChannelAssignment assignment) {
        throw new UnsupportedOperationException("For Distributed Importer this must be implemented.");
    }

    @Override
    public void onClusterStateChange(VersionedOperationMode mode) {
        throw new UnsupportedOperationException("For Distributed Importer this must be implemented.");
    }
}

<code block>


package org.voltdb.importer;

import java.util.concurrent.atomic.AtomicStampedReference;

import org.voltdb.OperationMode;

public final class VersionedOperationMode {
    final OperationMode mode;
    final int version;

    VersionedOperationMode(AtomicStampedReference<OperationMode> ref) {
        if (ref == null) {
            throw new IllegalArgumentException("stamped reference is null");
        }
        int [] stamp = new int[]{0};
        this.mode = ref.get(stamp);
        this.version = stamp[0];
    }

    VersionedOperationMode(OperationMode mode, int version) {
        if (mode == null) {
            throw new IllegalArgumentException("operation mode is null");
        }
        if (version < 0) {
            throw new IllegalArgumentException("version is less than 0");
        }
        this.mode = mode;
        this.version = version;
    }

    public OperationMode getMode() {
        return mode;
    }

    public int getVersion() {
        return version;
    }

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + ((mode == null) ? 0 : mode.hashCode());
        result = prime * result + version;
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null)
            return false;
        if (getClass() != obj.getClass())
            return false;
        VersionedOperationMode other = (VersionedOperationMode) obj;
        if (mode != other.mode)
            return false;
        if (version != other.version)
            return false;
        return true;
    }

    @Override
    public String toString() {
        return "VersionedOperationalMode [mode=" + mode + ", version="
                + version + "]";
    }
}
<code block>


package org.voltdb.importer;

import java.net.URI;
import java.util.List;
import java.util.NavigableSet;
import java.util.Set;

import com.google_voltpatches.common.collect.ImmutableList;
import com.google_voltpatches.common.collect.ImmutableSet;
import com.google_voltpatches.common.collect.ImmutableSetMultimap;
import com.google_voltpatches.common.collect.SetMultimap;
import com.google_voltpatches.common.collect.Sets;

public class ChannelAssignment {

    final Set<ChannelSpec> added;
    final Set<ChannelSpec> removed;
    final NavigableSet<ChannelSpec> channels;
    final int version;
    final List<ImporterChannelAssignment> assignments;

    ChannelAssignment(NavigableSet<ChannelSpec> prev, NavigableSet<ChannelSpec> next, int version) {
        this.version  = version;
        this.added    = Sets.difference(next, prev);
        this.removed  = Sets.difference(prev, next);
        this.channels = next;

        this.assignments = perImporterAssignments();
    }

    public Set<ChannelSpec> getAdded() {
        return added;
    }

    public Set<ChannelSpec> getRemoved() {
        return removed;
    }

    public NavigableSet<ChannelSpec> getChannels() {
        return channels;
    }

    public int getVersion() {
        return version;
    }

    public boolean hasChanges() {
        return !removed.isEmpty() || !added.isEmpty();
    }

    @Override
    public String toString() {
        return "ChannelAssignment [added=" + added + ", removed=" + removed
                + ", channels=" + channels + ", version=" + version + "]";
    }

    public List<ImporterChannelAssignment> getImporterChannelAssignments() {
        return assignments;
    }

    private SetMultimap<String, URI> mapByImporter(Set<ChannelSpec> specs) {
        ImmutableSetMultimap.Builder<String, URI> mmbldr = ImmutableSetMultimap.builder();
        for (ChannelSpec spec: specs) {
            mmbldr.put(spec.getImporter(),spec.getUri());
        }
        return mmbldr.build();
    }

    private List<ImporterChannelAssignment> perImporterAssignments() {

        ImmutableSet.Builder<String> sbldr = ImmutableSet.builder();
        for (ChannelSpec spec: Sets.union(added, removed)) {
            sbldr.add(spec.getImporter());
        }

        ImmutableList.Builder<ImporterChannelAssignment> lbldr = ImmutableList.builder();

        final SetMultimap<String, URI> added = mapByImporter(getAdded());
        final SetMultimap<String, URI> removed = mapByImporter(getRemoved());
        final SetMultimap<String, URI> assigned = mapByImporter(getChannels());

        for (String importer: sbldr.build()) {
            lbldr.add(new ImporterChannelAssignment(
                    importer,
                    added.get(importer),
                    removed.get(importer),
                    assigned.get(importer),
                    version
                    ));
        }
        return lbldr.build();
    }
}

<code block>


package org.voltdb.importer;

import java.net.URI;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Properties;
import java.util.Set;

import org.osgi.framework.Bundle;
import org.osgi.framework.BundleException;
import org.osgi.framework.ServiceReference;
import org.osgi.framework.launch.Framework;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltdb.CatalogContext;
import org.voltdb.ImportHandler;
import org.voltdb.VoltDB;

import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.base.Throwables;

public class ImportProcessor implements ImportDataProcessor {

    private static final VoltLogger m_logger = new VoltLogger("IMPORT");
    private final Map<String, BundleWrapper> m_bundles = new HashMap<String, BundleWrapper>();
    private final Map<String, BundleWrapper> m_bundlesByName = new HashMap<String, BundleWrapper>();
    private final Framework m_framework;
    private final ChannelDistributer m_distributer;

    public ImportProcessor(int myHostId, ChannelDistributer distributer, Framework framework) throws BundleException {
        m_framework = framework;
        m_distributer = distributer;
    }

    
    public class BundleWrapper {
        public final Bundle m_bundle;
        public final Properties m_properties;
        public final ImportHandlerProxy m_handlerProxy;
        private ImportHandler m_handler;
        private ChannelDistributer m_channelDistributer;

        public BundleWrapper(ImportHandlerProxy handler, Properties properties, Bundle bundle) {
            m_bundle = bundle;
            m_handlerProxy = handler;
            m_properties = properties;
        }

        public void setChannelDistributer(ChannelDistributer distributer) {
            m_channelDistributer = distributer;
        }

        public void setHandler(ImportHandler handler) throws Exception {
            Preconditions.checkState((m_handler == null), "ImportHandler can only be set once.");
            m_handler = handler;
            m_handlerProxy.setHandler(handler);
        }

        public ImportHandler getHandler() {
            return m_handler;
        }

        public void stop() {
            try {
                m_handler.stop();
                if (m_bundle != null) {
                    m_bundle.stop();
                }
                if (m_channelDistributer != null) {
                    m_channelDistributer.registerChannels(m_handlerProxy.getName(), new HashSet<URI>());
                }
            } catch (Exception ex) {
                m_logger.error("Failed to stop the import bundles.", ex);
            }
        }
    }

    public void addProcessorConfig(Properties properties) {
        String module = properties.getProperty(ImportDataProcessor.IMPORT_MODULE);
        String moduleAttrs[] = module.split("\\|");
        String bundleJar = moduleAttrs[1];
        String moduleType = moduleAttrs[0];

        Preconditions.checkState(!m_bundles.containsKey(bundleJar), "Import to source is already defined.");
        try {
            BundleWrapper wrapper = null;
            ImportHandlerProxy importHandlerProxy = null;
            if (moduleType.equalsIgnoreCase("osgi")) {

                Bundle bundle = m_framework.getBundleContext().installBundle(bundleJar);
                bundle.start();
                ServiceReference refs[] = bundle.getRegisteredServices();
                
                ServiceReference reference = refs[0];
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    bundle.stop();
                    return;
                }
                Object o = bundle.getBundleContext().getService(reference);
                importHandlerProxy = (ImportHandlerProxy )o;
                wrapper = new BundleWrapper(importHandlerProxy, properties, bundle);
            } else {
                
                Class reference = this.getClass().getClassLoader().loadClass(bundleJar);
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    return;
                }

                importHandlerProxy = (ImportHandlerProxy )reference.newInstance();
                 wrapper = new BundleWrapper(importHandlerProxy, properties, null);
            }
            importHandlerProxy.configure(properties);
            String name = importHandlerProxy.getName();
            if (name == null || name.trim().length() == 0) {
                throw new RuntimeException("Importer must implement and return a valid unique name.");
            }
            Preconditions.checkState(!m_bundlesByName.containsKey(name), "Importer must implement and return a valid unique name: " + name);
            m_bundlesByName.put(name, wrapper);
            m_bundles.put(bundleJar, wrapper);
        } catch(Throwable t) {
            m_logger.error("Failed to configure import handler for " + bundleJar, t);
            Throwables.propagate(t);
        }
    }

    @Override
    public synchronized void readyForData(CatalogContext catContext, HostMessenger messenger) {

        for (BundleWrapper bw : m_bundles.values()) {
            try {
                ImportHandler importHandler = new ImportHandler(bw.m_handlerProxy, catContext);
                
                bw.setHandler(importHandler);
                if (!bw.m_handlerProxy.isRunEveryWhere()) {
                    
                    Set<URI> allResources = bw.m_handlerProxy.getAllResponsibleResources();
                    m_logger.info("All Available Resources for " + bw.m_handlerProxy.getName() + " Are: " + allResources);

                    bw.setChannelDistributer(m_distributer);
                    
                    m_distributer.registerCallback(bw.m_handlerProxy.getName(), bw.m_handlerProxy);
                    m_distributer.registerChannels(bw.m_handlerProxy.getName(), allResources);
                }
                importHandler.readyForData();
                m_logger.info("Importer started: " + bw.m_handlerProxy.getName());
            } catch (Exception ex) {
                
                VoltDB.crashLocalVoltDB("Import failed to set Handler", true, ex);
                m_logger.error("Failed to start the import handler: " + bw.m_handlerProxy.getName(), ex);
            }
        }
        
    }

    @Override
    public synchronized void shutdown() {
        try {
            
            for (BundleWrapper bw : m_bundles.values()) {
                try {
                    bw.stop();
                } catch (Exception ex) {
                    m_logger.error("Failed to stop the import handler: " + bw.m_handlerProxy.getName(), ex);
                }
            }
            m_bundles.clear();
        } catch (Exception ex) {
            m_logger.error("Failed to stop the import bundles.", ex);
        }
    }

    @Override
    public void setProcessorConfig(Map<String, Properties> config) {
        for (String cname : config.keySet()) {
            Properties properties = config.get(cname);

            String importBundleJar = properties.getProperty(IMPORT_MODULE);
            Preconditions.checkNotNull(importBundleJar, "Import source is undefined or custom export plugin class missing.");
            addProcessorConfig(properties);
        }
    }

}

<code block>


package org.voltdb.importer;

import static org.voltcore.common.Constants.VOLT_TMP_DIR;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.ServiceLoader;
import java.util.concurrent.atomic.AtomicReference;

import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.osgi.framework.BundleException;
import org.osgi.framework.Constants;
import org.osgi.framework.launch.Framework;
import org.osgi.framework.launch.FrameworkFactory;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltdb.CatalogContext;
import org.voltdb.VoltDB;
import org.voltdb.utils.CatalogUtil;


public class ImportManager {

    
    private static final VoltLogger importLog = new VoltLogger("IMPORT");

    AtomicReference<ImportDataProcessor> m_processor = new AtomicReference<ImportDataProcessor>();
    private volatile Map<String, Properties> m_processorConfig = new HashMap<>();

    
    private static ImportManager m_self;
    private final HostMessenger m_messenger;

    private final FrameworkFactory m_frameworkFactory;
    private final Map<String, String> m_frameworkProps;
    private final Framework m_framework;
    private final int m_myHostId;
    private final ChannelDistributer m_distributer;
    
    public static ImportManager instance() {
        return m_self;
    }

    protected ImportManager(int myHostId, HostMessenger messenger) throws BundleException {
        m_myHostId = myHostId;
        m_messenger = messenger;
        m_distributer = new ChannelDistributer(m_messenger.getZK(), String.valueOf(m_myHostId), null);

        
        m_frameworkProps = new HashMap<String, String>();
        
        m_frameworkProps.put(Constants.FRAMEWORK_SYSTEMPACKAGES_EXTRA, "org.voltcore.network;version=1.0.0"
                + ",org.voltdb.importer;version=1.0.0,org.apache.log4j;version=1.0.0,org.voltdb.client;version=1.0.0,org.slf4j;version=1.0.0,org.voltcore.utils;version=1.0.0");
        
        m_frameworkProps.put("org.osgi.framework.storage.clean", "onFirstInit");
        String tmpFilePath = System.getProperty(VOLT_TMP_DIR, System.getProperty("java.io.tmpdir"));
        m_frameworkProps.put("felix.cache.rootdir", tmpFilePath);
        m_frameworkFactory = ServiceLoader.load(FrameworkFactory.class).iterator().next();
        importLog.info("Framework properties are: " + m_frameworkProps);
        m_framework = m_frameworkFactory.newFramework(m_frameworkProps);
        m_framework.start();
    }

    
    public static synchronized void initialize(int myHostId, CatalogContext catalogContext, List<Integer> partitions, HostMessenger messenger) throws BundleException {
        ImportManager em = new ImportManager(myHostId, messenger);

        m_self = em;
        em.create(myHostId, m_self.m_distributer, catalogContext, messenger.getZK());
    }

    
    private synchronized void create(int myHostId, ChannelDistributer distributer, CatalogContext catalogContext, ZooKeeper zk) {
        try {
            if (catalogContext.getDeployment().getImport() == null) {
                return;
            }
            ImportDataProcessor newProcessor = new ImportProcessor(myHostId, distributer, m_framework);
            m_processorConfig = CatalogUtil.getImportProcessorConfig(catalogContext.getDeployment().getImport());
            newProcessor.setProcessorConfig(m_processorConfig);
            m_processor.set(newProcessor);
            importLog.info("Import Processor is configured.");
        } catch (final Exception e) {
            VoltDB.crashLocalVoltDB("Error creating import processor", true, e);
        }
    }

    public synchronized void shutdown() {
        close();
        m_distributer.shutdown();
    }

    public synchronized void close() {
        
        if (m_processor.get() == null) {
            return;
        }
        m_processor.get().shutdown();
        
        m_processor.set(null);
    }

    
    public synchronized void restart(CatalogContext catalogContext, HostMessenger messenger) {
        
        m_self.close();
        assert(m_processor.get() == null);
        m_self.create(m_myHostId, m_distributer, catalogContext, messenger.getZK());
        m_self.readyForData(catalogContext, messenger);
    }

    public void updateCatalog(CatalogContext catalogContext, HostMessenger messenger) {
        restart(catalogContext, messenger);
    }

    public synchronized void readyForData(CatalogContext catalogContext, HostMessenger messenger) {
        
        if (m_processor.get() == null) {
            return;
        }
        
        m_processor.get().readyForData(catalogContext, messenger);
    }

}

<code block>

package org.voltdb.importer;

import java.net.URI;
import java.util.Set;

public class ImporterChannelAssignment {

    final int version;
    final String importer;
    final Set<URI> added;
    final Set<URI> removed;
    final Set<URI> assigned;

    ImporterChannelAssignment(
            String importer,
            Set<URI> added,
            Set<URI> removed,
            Set<URI> assigned,
            int version
    ) {
        if (importer == null || importer.trim().isEmpty()) {
            throw new IllegalArgumentException("null or empty or blank importer");
        }
        if (version < 0) {
            throw new IllegalArgumentException("version is less than 0");
        }
        if (added == null) {
            throw new IllegalArgumentException("added is null");
        }
        if (removed == null) {
            throw new IllegalArgumentException("removed is null");
        }
        if (assigned == null) {
            throw new IllegalArgumentException("assigned is null");
        }

        this.version = version;
        this.importer = importer;
        this.added = added;
        this.removed = removed;
        this.assigned = assigned;
    }

    public int getVersion() {
        return version;
    }

    public String getImporter() {
        return importer;
    }

    public Set<URI> getAdded() {
        return added;
    }

    public Set<URI> getRemoved() {
        return removed;
    }

    public Set<URI> getAssigned() {
        return assigned;
    }

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + ((added == null) ? 0 : added.hashCode());
        result = prime * result
                + ((assigned == null) ? 0 : assigned.hashCode());
        result = prime * result
                + ((importer == null) ? 0 : importer.hashCode());
        result = prime * result + ((removed == null) ? 0 : removed.hashCode());
        result = prime * result + version;
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null)
            return false;
        if (getClass() != obj.getClass())
            return false;
        ImporterChannelAssignment other = (ImporterChannelAssignment) obj;
        if (added == null) {
            if (other.added != null)
                return false;
        } else if (!added.equals(other.added))
            return false;
        if (assigned == null) {
            if (other.assigned != null)
                return false;
        } else if (!assigned.equals(other.assigned))
            return false;
        if (importer == null) {
            if (other.importer != null)
                return false;
        } else if (!importer.equals(other.importer))
            return false;
        if (removed == null) {
            if (other.removed != null)
                return false;
        } else if (!removed.equals(other.removed))
            return false;
        if (version != other.version)
            return false;
        return true;
    }

    @Override
    public String toString() {
        return "ImporterChannelAssignment [importer=" + importer + ", added="
                + added + ", removed=" + removed + ", assigned=" + assigned
                + ", version=" + version + "]";
    }
}

<code block>


package org.voltdb.importer;


public interface ChannelChangeCallback {
    void onChange(ImporterChannelAssignment assignment);
    void onClusterStateChange(VersionedOperationMode mode);
}

<code block>


package org.voltdb.importer;

import static com.google_voltpatches.common.base.Preconditions.checkNotNull;
import static com.google_voltpatches.common.base.Predicates.equalTo;
import static com.google_voltpatches.common.base.Predicates.isNull;
import static com.google_voltpatches.common.base.Predicates.not;
import static org.voltcore.zk.ZKUtil.joinZKPath;

import java.io.File;
import java.net.URI;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Deque;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.NavigableMap;
import java.util.NavigableSet;
import java.util.Random;
import java.util.Set;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicStampedReference;

import org.apache.zookeeper_voltpatches.AsyncCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.Children2Callback;
import org.apache.zookeeper_voltpatches.AsyncCallback.DataCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.StatCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.StringCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.VoidCallback;
import org.apache.zookeeper_voltpatches.CreateMode;
import org.apache.zookeeper_voltpatches.KeeperException;
import org.apache.zookeeper_voltpatches.KeeperException.Code;
import org.apache.zookeeper_voltpatches.KeeperException.NodeExistsException;
import org.apache.zookeeper_voltpatches.WatchedEvent;
import org.apache.zookeeper_voltpatches.Watcher;
import org.apache.zookeeper_voltpatches.Watcher.Event.EventType;
import org.apache.zookeeper_voltpatches.Watcher.Event.KeeperState;
import org.apache.zookeeper_voltpatches.ZooDefs;
import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.apache.zookeeper_voltpatches.data.Stat;
import org.json_voltpatches.JSONArray;
import org.json_voltpatches.JSONException;
import org.json_voltpatches.JSONStringer;
import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.CoreUtils;
import org.voltcore.zk.ZKUtil;
import org.voltdb.OperationMode;
import org.voltdb.VoltZK;

import com.google_voltpatches.common.base.Function;
import com.google_voltpatches.common.base.Optional;
import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.base.Predicate;
import com.google_voltpatches.common.collect.FluentIterable;
import com.google_voltpatches.common.collect.ImmutableSortedMap;
import com.google_voltpatches.common.collect.ImmutableSortedSet;
import com.google_voltpatches.common.collect.Maps;
import com.google_voltpatches.common.collect.Sets;
import com.google_voltpatches.common.collect.TreeMultimap;
import com.google_voltpatches.common.eventbus.AsyncEventBus;
import com.google_voltpatches.common.eventbus.DeadEvent;
import com.google_voltpatches.common.eventbus.EventBus;
import com.google_voltpatches.common.eventbus.Subscribe;
import com.google_voltpatches.common.eventbus.SubscriberExceptionContext;
import com.google_voltpatches.common.eventbus.SubscriberExceptionHandler;


public class ChannelDistributer implements ChannelChangeCallback {

    private final static VoltLogger LOG = new VoltLogger("IMPORT");

    
    static final String IMPORT_DN = "/import";
    
    static final String HOST_DN = joinZKPath(IMPORT_DN, "host");
    
    static final String MASTER_DN = joinZKPath(IMPORT_DN, "master");
    
    static final String CANDIDATE_PN = joinZKPath(MASTER_DN, "candidate_");

    static final byte[] EMPTY_ARRAY = "[]".getBytes(StandardCharsets.UTF_8);

    static void mkdirs(ZooKeeper zk, String zkNode, byte[] content) {
        try {
            ZKUtil.asyncMkdirs(zk, zkNode, content).get();
        } catch (NodeExistsException itIsOk) {
        } catch (InterruptedException | KeeperException e) {
            String msg = "Unable to create zk directory: " + zkNode;
            LOG.error(msg, e);
            throw new DistributerException(msg, e);
        }
    }

    
    static DistributerException loggedDistributerException(Throwable cause, String format, Object...args) {
        Optional<DistributerException> causeFor = DistributerException.isCauseFor(cause);
        if (causeFor.isPresent()) {
            return causeFor.get();
        }
        String msg = String.format(format, args);
        if (cause != null) {
            LOG.error(msg, cause);
            return new DistributerException(msg, cause);
        } else {
            LOG.error(msg);
            return new DistributerException(msg);
        }
    }

    
    static Optional<DistributerException> checkCode(Code code, String format, Object...args) {
        if (code != Code.OK) {
            KeeperException kex = KeeperException.create(code);
            return Optional.of(loggedDistributerException(kex, format, args));
        } else {
            return Optional.absent();
        }
    }

    
    static void acquireAndRelease(Semaphore lock) {
        try {
            lock.acquire();
            lock.release();
        } catch (InterruptedException ex) {
            throw loggedDistributerException(ex, "iterruped while waiting for a semaphare");
        }
    }

    
    static NavigableSet<ChannelSpec> asChannelSet(byte[] data)
            throws JSONException, IllegalArgumentException {
        ImmutableSortedSet.Builder<ChannelSpec> sbld = ImmutableSortedSet.naturalOrder();
        JSONArray ja = new JSONArray(new String(data, StandardCharsets.UTF_8));
        for (int i=0; i< ja.length(); ++i) {
            sbld.add(new ChannelSpec(ja.getString(i)));
        }
        return  sbld.build();
    }

    
    static byte [] asHostData(NavigableSet<ChannelSpec> specs)
            throws JSONException, IllegalArgumentException {
        JSONStringer js = new JSONStringer();
        js.array();
        for (ChannelSpec spec: specs) {
            js.value(spec.asJSONValue());
        }
        js.endArray();
        return js.toString().getBytes(StandardCharsets.UTF_8);
    }

    
    static String id(Object o) {
        if (o == null) return "(null)";
        Thread t = Thread.currentThread();
        StringBuilder sb = new StringBuilder(128);
        sb.append("(T[").append(t.getName()).append("]@");
        sb.append(Long.toString(t.getId(), Character.MAX_RADIX));
        sb.append(":O[").append(o.getClass().getSimpleName());
        sb.append("]@");
        sb.append(Long.toString(System.identityHashCode(o),Character.MAX_RADIX));
        sb.append(")");
        return sb.toString();
    }

    final static SubscriberExceptionHandler eventBusFaultHandler = new SubscriberExceptionHandler() {
        @Override
        public void handleException(Throwable exception, SubscriberExceptionContext context) {
            loggedDistributerException(
                    exception,
                    "fault during callback dispatch for event %s",
                    context.getEvent()
                    );
        }
    };

    private final ExecutorService m_es;
    private final AtomicBoolean m_done = new AtomicBoolean(false);
    private final ZooKeeper m_zk;
    private final String m_hostId;
    private final String m_candidate;
    private final Deque<ImporterChannelAssignment> m_undispatched;
    private final EventBus m_eb;
    private final ExecutorService m_buses;

    volatile boolean m_isLeader = false;
    final SpecsRef m_specs = new SpecsRef();
    final HostsRef m_hosts = new HostsRef();
    final ChannelsRef m_channels = new ChannelsRef();
    final CallbacksRef m_callbacks = new CallbacksRef();
    final AtomicStampedReference<OperationMode> m_mode;

    
    public ChannelDistributer(ZooKeeper zk, String hostId, BlockingDeque<ChannelAssignment> queue) {
        Preconditions.checkArgument(
                hostId != null && !hostId.trim().isEmpty(),
                "hostId is null or empty"
                );
        m_hostId = hostId;
        m_zk = Preconditions.checkNotNull(zk, "zookeeper is null");
        m_es = CoreUtils.getCachedSingleThreadExecutor("Import Channel Distributer for Host " + hostId, 15000);
        m_buses = CoreUtils.getCachedSingleThreadExecutor(
                "Import Channel Distributer Event Bus Dispatcher for Host " + hostId, 15000
                );
        m_eb = new AsyncEventBus(m_buses, eventBusFaultHandler);
        m_eb.register(this);
        m_mode = new AtomicStampedReference<>(OperationMode.INITIALIZING, 0);
        m_undispatched = new LinkedList<>();

        
        mkdirs(zk, VoltZK.operationMode, OperationMode.INITIALIZING.getBytes());
        mkdirs(zk, HOST_DN, EMPTY_ARRAY);
        mkdirs(zk, MASTER_DN, EMPTY_ARRAY);

        GetOperationalMode opMode = new GetOperationalMode(VoltZK.operationMode);
        MonitorHostNodes monitor = new MonitorHostNodes(HOST_DN);
        CreateNode createHostNode = new CreateNode(
                joinZKPath(HOST_DN, hostId),
                EMPTY_ARRAY, CreateMode.EPHEMERAL
                );
        CreateNode electionCandidate = new CreateNode(
                CANDIDATE_PN,
                EMPTY_ARRAY, CreateMode.EPHEMERAL_SEQUENTIAL
                );
        ElectLeader elector = new ElectLeader(MASTER_DN, electionCandidate);

        opMode.getMode();
        monitor.getChildren();
        createHostNode.getNode();
        elector.elect();

        m_candidate = electionCandidate.getNode();
        
        new GetChannels(MASTER_DN).getChannels();
    }

    public String getHostId() {
        return m_hostId;
    }

    public VersionedOperationMode getOperationMode() {
        return new VersionedOperationMode(m_mode);
    }

    
    public void registerChannels(String importer, Set<URI> uris) {
        NavigableSet<String> registered = m_callbacks.getReference().navigableKeySet();
        Preconditions.checkArgument(
                importer != null && !importer.trim().isEmpty(),
                "importer is null or empty"
                );
        Preconditions.checkArgument(uris != null, "uris set is null");
        Preconditions.checkArgument(
                !FluentIterable.from(uris).anyMatch(isNull()),
                "uris set %s contains null elements", uris
                );
        Preconditions.checkState(
                registered.contains(importer),
                "no callbacks registered for %s", importer
                );

        Predicate<ChannelSpec> forImporter = ChannelSpec.importerIs(importer);
        Function<URI,ChannelSpec> asSpec = ChannelSpec.fromUri(importer);

        
        NavigableSet<ChannelSpec> proposed = ImmutableSortedSet.copyOf(
                FluentIterable.from(uris).transform(asSpec)
                );

        LOG.info("(" + m_hostId + ") proposing channels " + proposed);

        int [] stamp = new int[]{0};

        ImmutableSortedSet.Builder<ChannelSpec> sbldr = null;
        NavigableSet<ChannelSpec> prev = null;
        SetData setter = null;

        
        do {
            prev = m_channels.get(stamp);

            NavigableSet<ChannelSpec> current  = Sets.filter(prev, forImporter);
            if (current.equals(proposed)) {
                return;
            }
            sbldr = ImmutableSortedSet.naturalOrder();
            sbldr.addAll(Sets.filter(prev, not(forImporter)));
            sbldr.addAll(proposed);

            byte [] data = null;
            try {
                data = asHostData(sbldr.build());
            } catch (JSONException|IllegalArgumentException e) {
                throw loggedDistributerException(e, "failed to serialize the registration as json");
            }

            setter = new SetData(MASTER_DN, stamp[0], data);
        } while (setter.getCallbackCode() == Code.BADVERSION);

        setter.getStat();
    }

    
    public void registerCallback(String importer, ChannelChangeCallback callback) {
        Preconditions.checkArgument(
                importer != null && !importer.trim().isEmpty(),
                "importer is null or empty"
                );
        callback = checkNotNull(callback, "callback is null");

        if (m_done.get()) return;

        int [] stamp = new int[]{0};
        NavigableMap<String,ChannelChangeCallback> prev = null;
        NavigableMap<String,ChannelChangeCallback> next = null;
        ImmutableSortedMap.Builder<String,ChannelChangeCallback> mbldr = null;

        synchronized (m_undispatched) {
            do {
                prev = m_callbacks.get(stamp);
                mbldr = ImmutableSortedMap.naturalOrder();
                mbldr.putAll(Maps.filterKeys(prev, not(equalTo(importer))));
                mbldr.put(importer, callback);
                next = mbldr.build();
            } while (!m_callbacks.compareAndSet(prev, next, stamp[0], stamp[0]+1));

            NavigableSet<String> registered = next.navigableKeySet();

            Iterator<ImporterChannelAssignment> itr = m_undispatched.iterator();
            while (itr.hasNext()) {
                final ImporterChannelAssignment assignment = itr.next();
                if (registered.contains(assignment.getImporter())) {
                    final ChannelChangeCallback dispatch = next.get(assignment.getImporter());
                    m_buses.submit(new DistributerRunnable() {
                        @Override
                        public void susceptibleRun() throws Exception {
                            dispatch.onChange(assignment);
                        }
                    });
                    itr.remove();
                }
            }
        }
    }

    
    public void shutdown() {
        if (m_done.compareAndSet(false, true)) {
            m_es.shutdown();
            m_buses.shutdown();
            DeleteNode deleteHost = new DeleteNode(joinZKPath(HOST_DN, m_hostId));
            DeleteNode deleteCandidate = new DeleteNode(m_candidate);
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException e) {
                throw loggedDistributerException(e, "interrupted while waiting for executor termination");
            }
            try {
                m_buses.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException e) {
                throw loggedDistributerException(e, "interrupted while waiting for executor termination");
            }
            deleteHost.onComplete();
            deleteCandidate.onComplete();
        }
    }

    
    @Subscribe
    public void undispatched(DeadEvent e) {
        if (!m_done.get() && e.getEvent() instanceof ImporterChannelAssignment) {
            ImporterChannelAssignment assignment = (ImporterChannelAssignment)e.getEvent();

            synchronized (m_undispatched) {
                NavigableSet<String> registered = m_callbacks.getReference().navigableKeySet();
                if (registered.contains(assignment.getImporter())) {
                    m_eb.post(assignment);
                } else {
                    m_undispatched.add(assignment);
                }
            }
        }
    }

    @Override
    @Subscribe
    public void onChange(ImporterChannelAssignment assignment) {
        ChannelChangeCallback cb = m_callbacks.getReference().get(assignment.getImporter());
        if (cb != null && !m_done.get()) try {
            cb.onChange(assignment);
        } catch (Exception callbackException) {
            throw loggedDistributerException(
                    callbackException,
                    "failed to invoke the onChange() calback for importer %s",
                    assignment.getImporter()
                    );
        } else synchronized(m_undispatched) {
            m_undispatched.add(assignment);
        }
    }

    @Override
    @Subscribe
    public void onClusterStateChange(VersionedOperationMode mode) {
        Optional<DistributerException> fault = Optional.absent();
        for (Map.Entry<String, ChannelChangeCallback> e: m_callbacks.getReference().entrySet()) try {
            if (!m_done.get()) e.getValue().onClusterStateChange(mode);
        } catch (Exception callbackException) {
            fault = Optional.of(loggedDistributerException(
                    callbackException,
                    "failed to invoke the onClusterStateChange() calback for importer %s",
                    e.getKey()
                    ));
        }
        if (fault.isPresent()) {
            throw fault.get();
        }
    }

    
    abstract class DistributerRunnable implements Runnable {
        @Override
        public void run() {
            try {
                if (!m_done.get()) {
                    susceptibleRun();
                }
            } catch (Exception ex) {
                throw loggedDistributerException(ex, "Fault occured while executing runnable");
            }
        }

        public abstract void susceptibleRun() throws Exception;
    }

    
    class AssignChannels extends DistributerRunnable {

        
        final NavigableSet<ChannelSpec> channels = m_channels.getReference();
        
        final NavigableMap<ChannelSpec,String> specs = m_specs.getReference();
        
        final NavigableMap<String,AtomicInteger> hosts = m_hosts.getReference();

        @Override
        public void susceptibleRun() throws Exception {
            if (m_mode.getReference() == OperationMode.INITIALIZING) {
                return;
            }

            NavigableSet<ChannelSpec> assigned = specs.navigableKeySet();
            Set<ChannelSpec> added   = Sets.difference(channels, assigned);
            Set<ChannelSpec> removed = Sets.difference(assigned, channels);

            if (added.isEmpty() && removed.isEmpty()) {
                return;
            }

            Predicate<Map.Entry<ChannelSpec,String>> withoutRemoved =
                    not(ChannelSpec.specKeyIn(removed, String.class));
            NavigableMap<ChannelSpec,String> pruned =
                    Maps.filterEntries(specs, withoutRemoved);

            if (!removed.isEmpty()) {
                LOG.info("LEADER (" + m_hostId + ") removing channels " + removed);
            }
            
            TreeMultimap<String, ChannelSpec> byhost = TreeMultimap.create();

            for (Map.Entry<ChannelSpec,String> e: pruned.entrySet()) {
                byhost.put(e.getValue(), e.getKey());
            }
            
            int fair = new Double(Math.ceil(channels.size()/(double)hosts.size())).intValue();
            List<String> hostassoc = new ArrayList<>(added.size());
            for (String host: hosts.navigableKeySet()) {
                
                int room = fair - byhost.get(host).size();
                for (int i = 0; i < room; ++i) {
                    hostassoc.add(host);
                }
            }
            Collections.shuffle(hostassoc, new Random(System.identityHashCode(this)));

            Iterator<String> hitr = hostassoc.iterator();
            Iterator<ChannelSpec> citr = added.iterator();
            while (citr.hasNext()) {
                String host = hitr.next();
                ChannelSpec spec = citr.next();
                byhost.put(host, spec);
                LOG.info("LEADER (" + m_hostId + ") assingning " + spec + " to host " + host);
            }

            try {
                
                NavigableSet<ChannelSpec> previous = null;
                NavigableSet<ChannelSpec> needed = null;
                SetNodeChannels setter = null;

                for (String host: hosts.navigableKeySet()) {
                    previous = Maps.filterValues(specs,equalTo(host)).navigableKeySet();
                    needed = byhost.get(host);
                    if (!needed.equals(previous)) {
                        int version = hosts.get(host).get();
                        byte [] nodedata = asHostData(needed);
                        setter = new SetNodeChannels(joinZKPath(HOST_DN, host), version, nodedata);
                    }
                }
                
                if (setter != null) {
                    setter.getCallbackCode();
                }
            } catch (JSONException|IllegalArgumentException e) {
                LOG.fatal("unable to create json document to assign imported channels to nodes", e);
            }
        }
    }

    
    class SetData implements StatCallback {

        final String path;
        final int version;

        final Semaphore lock = new Semaphore(0);
        volatile Optional<Stat> stat = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();
        volatile Optional<Code> callbackCode = Optional.absent();

        SetData(String path, int version, byte [] data ) {
            this.path = path;
            this.version = version;
            m_zk.setData(path, data, version, this, null);
        }

        void internalProcessResult(int rc, String path, Object ctx, Stat stat) {
            callbackCode = Optional.of(Code.get(rc));
            Code code = callbackCode.get();
            if (code == Code.OK) {
                this.stat = Optional.of(stat);
            } else if (code == Code.NONODE || code == Code.BADVERSION) {
                
                KeeperException e = KeeperException.create(code);
                fault = Optional.of(new DistributerException("failed to write to " + path, e));
            } else if (!m_done.get()) {
                fault = checkCode(code, "failed to write to %s", path);
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx, Stat stat) {
            try {
                internalProcessResult(rc, path, ctx, stat);
            } finally {
                lock.release();
            }
        }

        public Stat getStat() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return stat.get();
        }

        public Code getCallbackCode() {
            acquireAndRelease(lock);
            return callbackCode.get();
        }
    }

    
    class SetNodeChannels extends SetData {

        SetNodeChannels(String path, int version, byte[] data) {
            super(path, version, data);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, Stat stat) {
            try {
                internalProcessResult(rc, path, ctx, stat);
                Code code = Code.get(rc);
                
                
                if ((code == Code.NONODE || code == Code.BADVERSION) && !m_done.get()) {
                    m_es.submit(new AssignChannels());
                }
            } finally {
                lock.release();
            }
        }
    }

    
    class CreateNode implements StringCallback {

        final Semaphore lock = new Semaphore(0);
        volatile Optional<String> node = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();

        CreateNode(String path, byte [] data, CreateMode cmode) {
            m_zk.create(path, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, cmode, this, null);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, String name) {
            try {
                Code code = Code.get(rc);
                switch(code) {
                case NODEEXISTS:
                    code = Code.OK;
                    break;
                case OK:
                    node = Optional.of(name);
                    break;
                default:
                    node = Optional.of(path);
                }
                fault = checkCode(code, "cannot create node %s", node.get());
            } finally {
                lock.release();
            }
        }

        String getNode() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return node.get();
        }
    }

    
    class DeleteNode implements VoidCallback {
        final String path;

        final Semaphore lock = new Semaphore(0);
        volatile Optional<DistributerException> fault = Optional.absent();
        volatile Optional<Code> callbackCode = Optional.absent();

        DeleteNode(String path) {
            this.path = path;
            m_zk.delete(path, -1, this, null);
        }

        void internalProcessResult(int rc, String path, Object ctx) {
            callbackCode = Optional.of(Code.get(rc));
            switch (callbackCode.get()) {
            case OK:
            case NONODE:
            case SESSIONEXPIRED:
            case SESSIONMOVED:
            case CONNECTIONLOSS:
                break;
            default:
                fault = checkCode(callbackCode.get(), "failed to delete %s", path);
                break;
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx) {
            try {
                internalProcessResult(rc, path, ctx);
            } finally {
                lock.release();
            }
        }

        public Code getCallbackCode() {
            acquireAndRelease(lock);
            return callbackCode.get();
        }

        public void onComplete() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
        }
    }

    
    class GetChildren extends DistributerRunnable implements Children2Callback, Watcher {

        final String path;
        final Semaphore lock = new Semaphore(0);

        volatile Optional<Stat> stat = Optional.absent();
        volatile Optional<NavigableSet<String>> children = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();

        GetChildren(String path) {
            this.path = path;
            m_zk.getChildren(path, this, this, null);
        }

        void internalProcessResults(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            Code code = Code.get(rc);
            if (code == Code.OK) {
                NavigableSet<String> childset = ImmutableSortedSet.copyOf(children);
                this.stat = Optional.of(stat);
                this.children = Optional.of(childset);
            } else if (code == Code.SESSIONEXPIRED) {
                
                KeeperException e = KeeperException.create(code);
                fault = Optional.of(new DistributerException("unable to get children for " + path, e));
            } else if (!m_done.get()) {
                fault = checkCode(code, "unable to get children for %s", path);
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, children, stat);
            } finally {
                lock.release();
            }
        }

        public NavigableSet<String> getChildren() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return children.get();
        }

        public Optional<Stat> getStat() {
            return stat;
        }

        @Override
        public void process(WatchedEvent e) {
            if (   e.getState() == KeeperState.SyncConnected
                && e.getType() == EventType.NodeChildrenChanged
                && !m_done.get())
            {
                m_es.submit(this);
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetChildren(path);
        }
    }

    
    class ElectLeader extends GetChildren {
        final CreateNode leaderCandidate;

        ElectLeader(String path, CreateNode leaderCandidate) {
            super(path);
            this.leaderCandidate = Preconditions.checkNotNull(leaderCandidate,"candidate is null");
        }

        @Override
        public void processResult(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, children, stat);
                if (Code.get(rc) != Code.OK || m_done.get()) {
                    return;
                }
                m_es.submit(new DistributerRunnable() {
                    @Override
                    public void susceptibleRun() throws Exception {
                        String candidate = basename.apply(leaderCandidate.getNode());
                        if (!m_isLeader && candidate.equals(ElectLeader.this.children.get().first())) {
                            m_isLeader = true;
                            LOG.info("LEADER (" + m_hostId + ") is now the importer channel leader");
                            
                            new AssignChannels().run();
                        }
                    }
                });
            } finally {
                lock.release();
            }
        }

        boolean elect() {
            return getChildren().first().equals(leaderCandidate.getNode());
        }

        @Override
        public void susceptibleRun() throws Exception {
            new ElectLeader(path, leaderCandidate);
        }
    }

    
    class GetData extends DistributerRunnable implements DataCallback, Watcher {

        final String path;
        final Semaphore lock = new Semaphore(0);

        volatile Optional<Stat> stat = Optional.absent();
        volatile Optional<byte[]> data = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();

        GetData(String path) {
            this.path = path;
            m_zk.getData(path, this, this, null);
        }

        @Override
        public void process(WatchedEvent e) {
            if (   e.getState() == KeeperState.SyncConnected
                && e.getType() == EventType.NodeDataChanged
                && !m_done.get())
            {
                m_es.submit(this);
            }
        }

        void internalProcessResults(int rc, String path, Object ctx, byte[] data, Stat stat) {
            Code code = Code.get(rc);
            if (code == Code.OK) {
                this.stat = Optional.of(stat);
                this.data = Optional.of(data != null ? data : EMPTY_ARRAY);
            } else if (code == Code.NONODE || code == Code.SESSIONEXPIRED) {
                
                KeeperException e = KeeperException.create(code);
                fault = Optional.of(new DistributerException(path + " went away", e));
            } else if (!m_done.get()) {
                fault = checkCode(code, "unable to read data in %s", path);
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetData(path);
        }

        public byte [] getData() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return data.get();
        }
    }

    
    class GetHostChannels extends GetData {
        Optional<DistributerException> fault = Optional.absent();
        Optional<NavigableSet<ChannelSpec>> nodespecs = Optional.absent();

        final String host;
        final Predicate<Map.Entry<ChannelSpec,String>> thisHost;

        public GetHostChannels(String path) {
            super(path);
            this.host = basename.apply(path);
            this.thisHost = hostValueIs(this.host, ChannelSpec.class);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }
                try {
                    nodespecs = Optional.of(asChannelSet(data));
                } catch (IllegalArgumentException|JSONException e) {
                    fault = Optional.of(
                            loggedDistributerException(e, "failed to parse json in %s", path)
                            );
                    return;
                }

                int [] sstamp = new int[]{0};
                AtomicInteger dstamp = m_hosts.getReference().get(host);
                if (dstamp == null) {
                    LOG.warn("(" + m_hostId + ") has no data stamp for "
                            + host + ", host registry contains: " + m_hosts.getReference()
                            );
                    dstamp = new AtomicInteger(0);
                }
                NavigableMap<ChannelSpec,String> prev = null;
                NavigableSet<ChannelSpec> oldspecs = null;
                ImmutableSortedMap.Builder<ChannelSpec,String> mbldr = null;

                do {
                    final int specversion = dstamp.get();
                    
                    if (specversion >= stat.getVersion()) {
                        return;
                    }
                    
                    if (!dstamp.compareAndSet(specversion, stat.getVersion())) {
                        return;
                    }

                    prev = m_specs.get(sstamp);
                    oldspecs = Maps.filterEntries(prev, thisHost).navigableKeySet();
                    
                    mbldr = ImmutableSortedMap.naturalOrder();
                    mbldr.putAll(Maps.filterEntries(prev, not(thisHost)));
                    for (ChannelSpec spec: nodespecs.get()) {
                        mbldr.put(spec, host);
                    }
                } while (!m_specs.compareAndSet(prev, mbldr.build(), sstamp[0], sstamp[0]+1));

                if (host.equals(m_hostId) && !m_done.get()) {
                    ChannelAssignment assignment = new ChannelAssignment(
                            oldspecs, nodespecs.get(), stat.getVersion()
                            );
                    for (ImporterChannelAssignment cassigns: assignment.getImporterChannelAssignments()) {
                        m_eb.post(cassigns);
                    }
                    if (!assignment.getRemoved().isEmpty()) {
                        LOG.info("(" + m_hostId + ") removing the following channel assingments: " + assignment.getRemoved());
                    }
                    if (!assignment.getAdded().isEmpty()) {
                        LOG.info("(" + m_hostId + ") adding the following channel assingments: " + assignment.getAdded());
                    }
                }
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetHostChannels(path);
        }

        NavigableSet<ChannelSpec> getSpecs() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return nodespecs.get();
        }
    }

    
    class GetChannels extends GetData {

        Optional<DistributerException> fault = Optional.absent();
        Optional<NavigableSet<ChannelSpec>> channels = Optional.absent();

        public GetChannels(String path) {
            super(path);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }
                try {
                    channels = Optional.of(asChannelSet(data));
                } catch (IllegalArgumentException|JSONException e) {
                    fault = Optional.of(
                            loggedDistributerException(e, "failed to parse json in %s", path)
                            );
                    return;
                }
                int [] stamp = new int[]{0};
                NavigableSet<ChannelSpec> oldspecs = m_channels.get(stamp);
                if (stamp[0] >= stat.getVersion()) {
                    return;
                }
                if (!m_channels.compareAndSet(oldspecs, channels.get(), stamp[0], stat.getVersion())) {
                    return;
                }
                LOG.info("(" + m_hostId + ") succesfully received channel assignment master copy");
                if (m_isLeader && !m_done.get()) {
                    m_es.submit(new AssignChannels());
                }
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetChannels(path);
        }

        NavigableSet<ChannelSpec> getChannels() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return channels.get();
        }
    }

    
    class GetOperationalMode extends GetData {
        Optional<VersionedOperationMode> mode = Optional.absent();

        GetOperationalMode(String path) {
            super(path);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }

                int [] stamp = new int[]{0};
                OperationMode prev = m_mode.get(stamp);
                if ( stamp[0] > stat.getVersion()) {
                    return;
                }
                OperationMode next = data != null ?  OperationMode.valueOf(data) : OperationMode.INITIALIZING;
                if (!m_mode.compareAndSet(prev, next, stamp[0], stat.getVersion())) {
                    return;
                }
                mode = Optional.of(new VersionedOperationMode(next, stat.getVersion()));
                if (m_isLeader && !m_done.get() && next == OperationMode.RUNNING) {
                    m_es.submit(new AssignChannels());
                }
                m_eb.post(mode.get());

            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetOperationalMode(path);
        }

        VersionedOperationMode getMode() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            if (!mode.isPresent()) {
                throw new DistributerException("failed to mirror cluster operation mode");
            }
            return mode.get();
        }
    }

    
    class MonitorHostNodes extends GetChildren {

        MonitorHostNodes(String path) {
            super(path);
        }

        @Override
        public void processResult(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, children, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }

                int [] hstamp = new int[]{0};
                NavigableMap<String,AtomicInteger> oldgen = m_hosts.get(hstamp);
                if (hstamp[0] >= stat.getCversion()) {
                    return;
                }

                final Set<String> added   = Sets.difference(this.children.get(), oldgen.navigableKeySet());
                final Set<String> removed = Sets.difference(oldgen.navigableKeySet(), this.children.get());

                ImmutableSortedMap.Builder<String,AtomicInteger> hbldr = ImmutableSortedMap.naturalOrder();
                hbldr.putAll(Maps.filterEntries(oldgen, not(hostKeyIn(removed, AtomicInteger.class))));
                for (String add: added) {
                    hbldr.put(add, new AtomicInteger(0));
                }
                NavigableMap<String,AtomicInteger> newgen = hbldr.build();

                if (!m_hosts.compareAndSet(oldgen, newgen, hstamp[0], stat.getCversion())) {
                    return;
                }

                if (!removed.isEmpty()) {
                    final Predicate<Map.Entry<ChannelSpec,String>> inRemoved =
                            hostValueIn(removed, ChannelSpec.class);

                    int [] sstamp = new int[]{0};
                    NavigableMap<ChannelSpec,String> prev = null;
                    NavigableMap<ChannelSpec,String> next = null;

                    do {
                        prev = m_specs.get(sstamp);
                        next = Maps.filterEntries(prev, not(inRemoved));
                    } while (!m_specs.compareAndSet(prev, next, sstamp[0], sstamp[0]+1));

                    LOG.info("(" + m_hostId + ") hosts " + removed + " no longer servicing importer channels");

                    if (m_isLeader && !m_done.get()) {
                        m_es.submit(new AssignChannels());
                    }
                }

                if (!added.isEmpty() && !m_done.get()) {
                    m_es.submit(new DistributerRunnable() {
                        @Override
                        public void susceptibleRun() throws Exception {
                            for (String host: added) {
                                LOG.info("(" + m_hostId + ") starting to monitor host node " + host);
                                new GetHostChannels(joinZKPath(HOST_DN, host));
                            }
                        }
                    });
                }
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new MonitorHostNodes(path);
        }
    }

    
    final static class HostsRef extends AtomicStampedReference<NavigableMap<String,AtomicInteger>> {
        static final NavigableMap<String,AtomicInteger> EMPTY_MAP = ImmutableSortedMap.of();

        public HostsRef(NavigableMap<String,AtomicInteger> initialRef, int initialStamp) {
            super(initialRef, initialStamp);
        }

        public HostsRef() {
            this(EMPTY_MAP, 0);
        }
    }

    
    final static class ChannelsRef extends AtomicStampedReference<NavigableSet<ChannelSpec>> {
        static final NavigableSet<ChannelSpec> EMPTY_SET = ImmutableSortedSet.of();

        public ChannelsRef(NavigableSet<ChannelSpec> initialRef, int initialStamp) {
            super(initialRef, initialStamp);
        }

        public ChannelsRef() {
            this(EMPTY_SET, 0);
        }
    }

    
    final static class SpecsRef extends AtomicStampedReference<NavigableMap<ChannelSpec,String>> {
        static final NavigableMap<ChannelSpec,String> EMPTY_MAP = ImmutableSortedMap.of();

        public SpecsRef(NavigableMap<ChannelSpec,String> initialRef, int initialStamp) {
            super(initialRef, initialStamp);
        }

        public SpecsRef() {
            this(EMPTY_MAP, 0);
        }
    }

    
    final static class CallbacksRef
        extends AtomicStampedReference<NavigableMap<String,ChannelChangeCallback>> {

        static final NavigableMap<String,ChannelChangeCallback> EMTPY_MAP =
                ImmutableSortedMap.of();

        public CallbacksRef(
                NavigableMap<String,ChannelChangeCallback> initialRef,
                int initialStamp) {
            super(initialRef, initialStamp);
        }

        public CallbacksRef() {
            this(EMTPY_MAP,0);
        }
    }

    static <K> Predicate<Map.Entry<K, String>> hostValueIs(final String s, Class<K> clazz) {
        return new Predicate<Map.Entry<K,String>>() {
            @Override
            public boolean apply(Entry<K, String> e) {
                return s.equals(e.getValue());
            }
        };
    }

    static <K> Predicate<Map.Entry<K, String>> hostValueIn(final Set<String> s, Class<K> clazz) {
        return new Predicate<Map.Entry<K,String>>() {
            @Override
            public boolean apply(Entry<K, String> e) {
                return s.contains(e.getValue());
            }
        };
    }

    static <V> Predicate<Map.Entry<String,V>> hostKeyIn(final Set<String> s, Class<V> clazz) {
        return new Predicate<Map.Entry<String,V>>() {
            @Override
            public boolean apply(Entry<String,V> e) {
                return s.contains(e.getKey());
            }
        };
    }

    final static Function<String,String> basename = new Function<String, String>() {
        @Override
        public String apply(String path) {
            return new File(path).getName();
        }
    };

    public final static Predicate<ImporterChannelAssignment> importerIs(final String importer) {
        return new Predicate<ImporterChannelAssignment>() {
            @Override
            public boolean apply(ImporterChannelAssignment assignment) {
                return importer.equals(assignment.getImporter());
            }
        };
    }

    public final static Predicate<ImporterChannelAssignment> importerIn(final Set<String> importers) {
        return new Predicate<ImporterChannelAssignment>() {
            @Override
            public boolean apply(ImporterChannelAssignment assignment) {
                return importers.contains(assignment.getImporter());
            }
        };
    }
}

<code block>


package org.voltdb.importer;

import static com.google_voltpatches.common.base.Predicates.equalTo;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;

import java.net.URI;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.LinkedBlockingDeque;
import java.util.concurrent.TimeUnit;

import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.voltcore.zk.ZKTestBase;
import org.voltdb.OperationMode;
import org.voltdb.VoltZK;

import com.google_voltpatches.common.collect.FluentIterable;
import com.google_voltpatches.common.collect.ImmutableMap;
import com.google_voltpatches.common.collect.ImmutableSet;
import com.google_voltpatches.common.collect.Maps;
import com.google_voltpatches.common.collect.Sets;

public class TestChannelDistributer extends ZKTestBase {

    private final static String ZERO = "zero";
    private final static String UNO  = "uno";
    private final static String DUE  = "due";
    private final static String YO   = "yo";

    Map<String, ZooKeeper> zks;
    Map<String, ChannelDistributer> distributers;
    BlockingDeque<ImporterChannelAssignment> queue;

    public class Collector implements ChannelChangeCallback {
        @Override
        public void onChange(ImporterChannelAssignment assignment) {
            queue.offer(assignment);
        }
        @Override
        public void onClusterStateChange(VersionedOperationMode mode) {
        }
    }

    static Set<URI> generateURIs(int count) {
        ImmutableSet.Builder<URI> sbldr = ImmutableSet.builder();
        for (int i=0; i < count; ++i) {
            sbldr.add(URI.create(String.format("x-import:
        }
        return sbldr.build();
    }

    static Set<ChannelSpec> asSpecs(Set<URI> uris) {
        return FluentIterable.from(uris).transform(ChannelSpec.fromUri(YO)).toSet();
    }

    Set<URI> getRemoved(int expected) throws Exception {
        int received = 0;
        ImmutableSet.Builder<URI> sbldr = ImmutableSet.builder();
        ImporterChannelAssignment assignment = null;
        while (received < expected && (assignment=queue.poll(200,TimeUnit.MILLISECONDS)) != null) {
            received += assignment.getRemoved().size();
            sbldr.addAll(assignment.getRemoved());
        }
        assertEquals("failed to poll the expected number of removed", expected, received);
        assertTrue(queue.isEmpty());
        return sbldr.build();
    }

    Set<URI> getAdded(int expected) throws Exception {
        int received = 0;
        ImmutableSet.Builder<URI> sbldr = ImmutableSet.builder();
        ImporterChannelAssignment assignment = null;
        while (received < expected && (assignment=queue.poll(200, TimeUnit.MILLISECONDS)) != null) {
            received += assignment.getAdded().size();
            sbldr.addAll(assignment.getAdded());
        }
        assertEquals("failed to poll the expected number of removed", expected, received);
        assertTrue(queue.isEmpty());
        return sbldr.build();
    }

    @Before
    public void setup() throws Exception {
        setUpZK(3);
        queue = new LinkedBlockingDeque<>();
        zks = ImmutableMap.<String, ZooKeeper>builder()
                .put(ZERO, getClient(0))
                .put(UNO,  getClient(1))
                .put(DUE,  getClient(2))
                .build();
        distributers = ImmutableMap.<String, ChannelDistributer>builder()
                .put(ZERO, new ChannelDistributer(zks.get(ZERO), ZERO, null))
                .put(UNO,  new ChannelDistributer(zks.get(UNO), UNO, null))
                .put(DUE,  new ChannelDistributer(zks.get(DUE), DUE, null))
                .build();
        for (ChannelDistributer cd: distributers.values()) {
            cd.registerCallback(YO, new Collector());
        }
    }

    @Test
    public void testRegistration() throws Exception {
        Set<URI> uris = generateURIs(9);
        Set<URI> expected = uris;
        
        distributers.get(UNO).registerChannels(YO, uris);
        
        assertNull(queue.poll(200, TimeUnit.MILLISECONDS));

        zks.get(ZERO).setData(VoltZK.operationMode, OperationMode.RUNNING.getBytes(), -1);
        Set<URI> actual = getAdded(9);

        assertEquals(expected, actual);

        Set<URI> pruned = generateURIs(6);
        expected = Sets.difference(uris, pruned);
        
        distributers.get(DUE).registerChannels(YO, pruned);
        actual = getRemoved(3);

        assertEquals(expected, actual);
        
        distributers.get(ZERO).registerChannels(YO, pruned);
        assertNull(queue.poll(200, TimeUnit.MILLISECONDS));

        uris = generateURIs(8);
        expected = Sets.difference(uris, pruned);
        
        distributers.get(UNO).registerChannels(YO, uris);
        actual = getAdded(2);

        assertEquals(expected, actual);

        expected = uris;
        
        distributers.get(UNO).registerChannels(YO, ImmutableSet.<URI>of());
        actual = getRemoved(8);

        assertEquals(expected, actual);

        int leaderCount = 0;
        for (ChannelDistributer distributer: distributers.values()) {
            if (distributer.m_isLeader) {
                ++leaderCount;
            }
        }
        assertEquals(1, leaderCount);
    }

    @Test
    public void testHostFailure() throws Exception {
        Set<URI> uris = generateURIs(9);
        Set<URI> expected = uris;
        zks.get(ZERO).setData(VoltZK.operationMode, OperationMode.RUNNING.getBytes(), -1);
        
        distributers.get(UNO).registerChannels(YO, uris);
        Set<URI> actual = getAdded(9);

        assertEquals(expected, actual);

        
        int attempts = 4;
        boolean settled = false;
        while (!settled && --attempts >=0) {
            Thread.sleep(50);
            settled = true;
            int stamp = distributers.get(ZERO).m_specs.getStamp();
            for (ChannelDistributer distributer: distributers.values()) {
                settled = settled && stamp == distributer.m_specs.getStamp();
            }
        }
        assertTrue(settled);

        Set<ChannelSpec> inZERO = Maps.filterValues(
                distributers.get(DUE).m_specs.getReference(),
                equalTo(ZERO))
                .navigableKeySet();
        assertTrue(inZERO.size() > 0);

        zks.get(ZERO).close();

        actual = getAdded(inZERO.size());
        assertEquals(inZERO, asSpecs(actual));
    }

    @After
    public void tearDown() throws Exception {
        for (ChannelDistributer distributer: distributers.values()) {
            distributer.shutdown();
        }
        tearDownZK();
    }
}

<code block>


package org.voltdb;


public enum OperationMode {
    INITIALIZING, RUNNING, PAUSED, SHUTTINGDOWN;

    
    public static OperationMode get(byte val) {
        for (OperationMode mode : OperationMode.values()) {
            if (mode.ordinal() == val) {
                return mode;
            }
        }
        throw new AssertionError("Unknown mode: " + val);
    }
}

<code block>

package org.voltdb.importclient.kafka;

import java.net.URI;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import kafka.api.FetchRequestBuilder;

import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import kafka.javaapi.consumer.SimpleConsumer;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.SortedSet;
import java.util.TreeSet;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;
import kafka.api.ConsumerMetadataRequest;
import kafka.api.FetchRequest;
import kafka.api.PartitionOffsetRequestInfo;
import kafka.cluster.Broker;
import kafka.common.ErrorMapping;
import kafka.common.OffsetAndMetadata;
import kafka.common.TopicAndPartition;
import kafka.javaapi.ConsumerMetadataResponse;
import kafka.javaapi.FetchResponse;
import kafka.javaapi.OffsetCommitRequest;
import kafka.javaapi.OffsetCommitResponse;
import kafka.javaapi.OffsetResponse;
import kafka.javaapi.PartitionMetadata;
import kafka.javaapi.TopicMetadata;
import kafka.javaapi.TopicMetadataRequest;
import kafka.message.MessageAndOffset;
import kafka.network.BlockingChannel;

import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltdb.VoltDB;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureCallback;
import org.voltdb.importer.CSVInvocation;
import org.voltdb.importer.ImportHandlerProxy;


public class KafkaStreamImporter extends ImportHandlerProxy implements BundleActivator {

    
    private Properties m_properties;
    
    private String m_groupId;
    
    private String m_procedure;
    
    private List<String> m_topicList;
    
    private final List<HostAndPort> m_brokerList = new ArrayList<HostAndPort>();
    
    private int m_fetchSize = (2*1024*1024);
    private int m_consumerSocketTimeout = 30000; 

    private static final String GROUP_ID = "voltdb";
    private static final String CLIENT_ID = "voltdb-importer";
    private static final int KAFKA_DEFAULT_BROKER_PORT = 9092;
    
    private final Semaphore m_done = new Semaphore(0);
    private boolean m_stopping = false;

    
    private final Map<String, List<TopicMetadata>> m_topicPartitionMetaData = new HashMap<String, List<TopicMetadata>>();
    
    private final Map<String, List<Integer>> m_topicPartitions = new HashMap<String, List<Integer>>();
    
    private final Map<String, HostAndPort> m_topicPartitionLeader = new HashMap<String, HostAndPort>();
    private final Map<String, TopicPartitionFetcher> m_fetchers = new HashMap<String, TopicPartitionFetcher>();

    private ExecutorService m_es = null;

    
    public static class HostAndPort {

        private final String m_host;
        private final int m_port;
        private final String m_connectionString;

        public HostAndPort(String h, int p) {
            m_host = h;
            m_port = p;
            m_connectionString = m_host + ":" + m_port;
        }

        public static HostAndPort fromString(String hap) {
            String s[] = hap.split(":");
            int p = KAFKA_DEFAULT_BROKER_PORT;
            if (s.length > 1 && s[1] != null && s[1].length() > 0) {
                p = Integer.parseInt(s[1].trim());
            }
            return new HostAndPort(s[0].trim(), p);
        }

        public String getHost() {
            return m_host;
        }

        public int getPort() {
            return m_port;
        }

        @Override
        public String toString() {
            return m_host + ":" + m_port;
        }

        @Override
        public int hashCode() {
            return m_connectionString.hashCode();
        }

        @Override
        public boolean equals(Object o) {
            if (!(o instanceof HostAndPort)) {
                return false;
            }
            HostAndPort hap = (HostAndPort )o;
            if (hap == this) {
                return true;
            }
            if (hap.getHost().equals(getHost()) && hap.getPort() == getPort()) {
                return true;
            }
            return false;
        }
    }

    
    @Override
    public void start(BundleContext context) throws Exception {
        context.registerService(this.getClass().getName(), this, null);
    }

    @Override
    public void stop(BundleContext context) throws Exception {
        
    }

    @Override
    public boolean isRunEveryWhere() {
        
        return false;
    }

    
    private Set<URI> buildTopicLeaderMetadata(SimpleConsumer consumer) {

        
        Set<URI> availableResources = new TreeSet<URI>();
        for (String topic : m_topicList) {
            TopicMetadataRequest req = new TopicMetadataRequest(Collections.singletonList(topic));
            kafka.javaapi.TopicMetadataResponse resp = null;
            try {
                resp = consumer.send(req);
            } catch (Exception ex) {
                error("Failed to send topic metada request for topic " + topic, ex);
                continue;
            }

            List<TopicMetadata> metaData = resp.topicsMetadata();
            if (metaData == null) {
                error("Failed to get topic metadata for topic " + topic);
                continue;
            }
            m_topicPartitionMetaData.put(topic, metaData);
            List<Integer> partitions = m_topicPartitions.get(topic);
            if (partitions == null) {
                partitions = new ArrayList<Integer>();
                m_topicPartitions.put(topic, partitions);
            }
            for (TopicMetadata item : metaData) {
                for (PartitionMetadata part : item.partitionsMetadata()) {
                    partitions.add(part.partitionId());
                    for (kafka.cluster.Broker replica : part.replicas()) {
                        String leaderKey = topic + "-" + part.partitionId();
                        m_topicPartitionLeader.put(leaderKey, new HostAndPort(replica.host(), replica.port()));
                        URI uri = URI.create("kafka:/" + topic + "/partition/" + part.partitionId());
                        availableResources.add(uri);
                    }
                }
            }
        }

        info("Available Channels are: " + availableResources);
        
        m_es = Executors.newFixedThreadPool(availableResources.size() + 1);
        return availableResources;
    }

    @Override
    public Set<URI> getAllResponsibleResources() {
        SimpleConsumer simpleConsumer = null;
        Set<URI> availableResources = new TreeSet<URI>();
        try {
            simpleConsumer = new SimpleConsumer(m_brokerList.get(0).getHost(), m_brokerList.get(0).getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID);
            
            availableResources = buildTopicLeaderMetadata(simpleConsumer);
        } catch (Exception ex) {
            VoltDB.crashLocalVoltDB("Failed to get available resources for kafka importer", true, ex);
        } finally {
            closeConsumer(simpleConsumer);
        }
        return availableResources;
    }

    @Override
    public void stop() {
        m_stopping = true;
        
        for (TopicPartitionFetcher fetcher : m_fetchers.values()) {
            fetcher.shutdown();
        }
        m_done.release();
        if (m_es != null) {
            
            m_es.shutdown();
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException ex) {
                
                ex.printStackTrace();
            }
        }
        m_fetchers.clear();
    }

    
    @Override
    public String getName() {
        return "KafkaImporter82";
    }

    
    @Override
    public void configure(Properties p) {
        m_properties = (Properties) p.clone();
        m_procedure = m_properties.getProperty("procedure", "").trim();
        if (m_procedure.isEmpty()) {
            throw new RuntimeException("Missing procedure.");
        }
        
        String topics = m_properties.getProperty("topics", "").trim();
        if (topics.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
        m_topicList = Arrays.asList(topics.split("\\s*,\\s*"));
        if (m_topicList == null || m_topicList.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
       String brokers = m_properties.getProperty("brokers", "").trim();
        if (brokers.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        List<String> brokerList = Arrays.asList(brokers.split("\\s*,\\s*"));
        if (brokerList == null || brokerList.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        for (String broker : brokerList) {
            HostAndPort hap = HostAndPort.fromString(broker);
            m_brokerList.add(hap);
        }
        if (m_brokerList.isEmpty()) {
            throw new RuntimeException("Missing or misconfigured kafka broker list. See brokers property");
        }
        m_groupId = m_properties.getProperty("groupid", GROUP_ID).trim();
        
        m_fetchSize = Integer.parseInt(m_properties.getProperty("fetch.message.max.bytes", "65536"));
        m_consumerSocketTimeout = Integer.parseInt(m_properties.getProperty("socket.timeout.ms", "30000"));
    }

    
    private class TopicPartitionFetcher implements Runnable {

        
        private final URI m_url;
        
        private final HostAndPort m_leader;
        
        private HostAndPort m_coordinator;
        private boolean m_shutdown = false;
        private final int m_fetchSize;
        
        private final List<HostAndPort> m_brokers;
        private final int m_consumerSocketTimeout;
        
        private final AtomicLong m_currentOffset = new AtomicLong(-1);
        private final SortedSet<Long> m_pendingOffsets = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final SortedSet<Long> m_seenOffset = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final int m_perTopicPendingLimit = Integer.getInteger("voltdb.kafka.pertopicPendingLimit", 50000);
        private final AtomicReference<SimpleConsumer> m_offsetManager = new AtomicReference<SimpleConsumer>();
        private final TopicAndPartition m_topicAndPartition;

        public TopicPartitionFetcher(List<HostAndPort> brokers, URI uri, String topic, int partition, HostAndPort leader, int fetchSize, int consumerSocketTimeout) {
            m_url = uri;
            m_brokers = brokers;
            m_leader = leader;
            m_coordinator = leader;
            m_fetchSize = fetchSize;
            m_consumerSocketTimeout = consumerSocketTimeout;
            m_topicAndPartition = new TopicAndPartition(topic, partition);
        }

        public final URI getUrl() {
            return m_url;
        }

        
        private PartitionMetadata findLeader() {
            PartitionMetadata returnMetaData = null;
            loop:
            for (HostAndPort broker : m_brokers) {
                SimpleConsumer consumer = null;
                try {
                    consumer = new SimpleConsumer(broker.getHost(), broker.getPort(), m_consumerSocketTimeout, m_fetchSize, "findLeader");

                    List<String> topics = Collections.singletonList(m_topicAndPartition.topic());
                    TopicMetadataRequest req = new TopicMetadataRequest(topics);
                    kafka.javaapi.TopicMetadataResponse resp = consumer.send(req);

                    List<TopicMetadata> metaData = resp.topicsMetadata();
                    for (TopicMetadata item : metaData) {
                        for (PartitionMetadata part : item.partitionsMetadata()) {
                            if (part.partitionId() == m_topicAndPartition.partition()) {
                                returnMetaData = part;
                                break loop;
                            }
                        }
                    }
                } catch (Exception e) {
                    error("Error in finding leader for " + m_topicAndPartition, e);
                } finally {
                    closeConsumer(consumer);
                }
            }
            if (returnMetaData == null) {
                error("Failed to find Leader for " + m_topicAndPartition);
            }
            return returnMetaData;
        }

        
        private HostAndPort findNewLeader() {
            for (int i = 0; i < 3; i++) {
                boolean shouldSleep = false;
                PartitionMetadata metadata = findLeader();
                if (metadata == null) {
                    shouldSleep = true;
                } else if (metadata.leader() == null) {
                    shouldSleep = true;
                } else if (m_leader.getHost().equalsIgnoreCase(metadata.leader().host()) && i == 0) {
                    
                    
                    shouldSleep = true;
                } else {
                    return new HostAndPort(metadata.leader().host(), metadata.leader().port());
                }
                if (shouldSleep) {
                    backoffSleep(i+1);
                }
            }
            
            info("Failed to find new leader for " + m_topicAndPartition);
            return null;
        }

        
        public void shutdown() {
            m_shutdown = true;
        }

        public void getOffsetCoordinator() {
            BlockingChannel channel = null;
            for (int i = 0; i < 3; i++) {
                try {
                    
                    channel = new BlockingChannel(m_coordinator.getHost(), m_coordinator.getPort(),
                            BlockingChannel.UseDefaultBufferSize(),
                            BlockingChannel.UseDefaultBufferSize(),
                            m_consumerSocketTimeout );
                    channel.connect();
                    int correlationId = 0;
                    channel.send(new ConsumerMetadataRequest(m_groupId, ConsumerMetadataRequest.CurrentVersion(), correlationId++, CLIENT_ID));
                    ConsumerMetadataResponse metadataResponse = ConsumerMetadataResponse.readFrom(channel.receive().buffer());

                    if (metadataResponse.errorCode() == ErrorMapping.NoError()) {
                        Broker offsetManager = metadataResponse.coordinator();
                        m_coordinator = new HostAndPort(offsetManager.host(), offsetManager.port());
                        SimpleConsumer consumer = m_offsetManager.getAndSet(new SimpleConsumer(m_coordinator.getHost(), m_coordinator.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID) );
                        closeConsumer(consumer);
                        consumer = null;
                        break;
                    }
                    error("Failed to get Offset Coordinator for " + m_topicAndPartition + " Code: " + metadataResponse.errorCode());
                } catch (Exception e) {
                    
                    error("Failed to get Offset Coordinator for " + m_topicAndPartition, e);
                    backoffSleep(i+1);
                } finally {
                    if (channel != null) {
                        channel.disconnect();
                    }
                }
            }
            info("Coordinator for " + m_topicAndPartition + " consumer is: " + m_coordinator);
        }

        public long getLastOffset(long whichTime) {
            if (m_offsetManager.get() == null) {
                return -1;
            }
            SimpleConsumer consumer = m_offsetManager.get();
            try {
                Map<TopicAndPartition, PartitionOffsetRequestInfo> requestInfo = new HashMap<TopicAndPartition, PartitionOffsetRequestInfo>();
                requestInfo.put(m_topicAndPartition, new PartitionOffsetRequestInfo(whichTime, 1));
                kafka.javaapi.OffsetRequest request = new kafka.javaapi.OffsetRequest(requestInfo, kafka.api.OffsetRequest.CurrentVersion(), CLIENT_ID);
                OffsetResponse response = consumer.getOffsetsBefore(request);

                if (response.hasError()) {
                    short code = response.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                    if (code == ErrorMapping.NotLeaderForPartitionCode() || code == ErrorMapping.UnknownTopicOrPartitionCode()) {
                        HostAndPort leaderBroker = findNewLeader();
                        if (leaderBroker != null) {
                            info("Found new leader for " + m_topicAndPartition + " Coordinator will be updated.");
                            SimpleConsumer oconsumer = m_offsetManager.getAndSet(new SimpleConsumer(leaderBroker.getHost(), leaderBroker.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID) );
                            closeConsumer(oconsumer);
                            oconsumer = null;
                            m_coordinator = leaderBroker;
                        }
                    }
                    info("Error fetching Offset Data from Broker " + m_topicAndPartition.toString() +
                            " Reason: " + response.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition()) );
                    return -1;
                }
                long[] offsets = response.offsets(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                return offsets[0];
            } catch (Exception ex) {
                error("Failed to get last Offset for " + m_topicAndPartition, ex);
            }
            return -1;
        }

        
        private class TopicPartitionInvocationCallback implements ProcedureCallback {

            private final long m_offset;
            private final long m_nextOffset;
            private final TopicAndPartition m_topicAndPartition;

            public TopicPartitionInvocationCallback(long offset, long noffset, TopicAndPartition tAndP) {
                m_offset = offset;
                m_nextOffset = noffset;
                m_topicAndPartition = tAndP;
            }

            public boolean commitOffset(long offset) {

                final int correlationId = m_topicAndPartition.partition();
                final short version = 1;

                OffsetAndMetadata offsetMetdata = new OffsetAndMetadata(offset, "commitRequest", ErrorMapping.NoError());
                Map<TopicAndPartition, OffsetAndMetadata> reqMap = new HashMap<TopicAndPartition, OffsetAndMetadata>();
                reqMap.put(m_topicAndPartition, offsetMetdata);
                OffsetCommitRequest offsetCommitRequest = new OffsetCommitRequest(m_groupId, reqMap, correlationId, CLIENT_ID, version);
                OffsetCommitResponse offsetCommitResponse = null;
                try {
                    SimpleConsumer consumer = m_offsetManager.get();
                    if (consumer == null) {
                        getOffsetCoordinator();
                        consumer = m_offsetManager.get();
                    }
                    if (consumer != null) {
                        offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                        final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
                        if (code == ErrorMapping.NotCoordinatorForConsumerCode()) {
                            info("Not coordinator for committing offset for " + m_topicAndPartition + " Updating coordinator.");
                            getOffsetCoordinator();
                            consumer = m_offsetManager.get();
                            if (consumer != null) {
                                offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                            }
                        }
                    } else {
                        error("Commit Offset Failed to get offset coordinator for " + m_topicAndPartition);
                        return false;
                    }
                } catch (Exception e) {
                    error("Failed to commit Offset for " + m_topicAndPartition, e);
                    return false;
                }
                final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
                if (code != ErrorMapping.NoError()) {
                    error("Commit Offset Failed to commit for " + m_topicAndPartition + " Code: " + code);
                    return false;
                }
                return true;
            }

            private void commitAndSaveOffset(long currentNext) {
                try {
                    
                    if (m_seenOffset.size() >= m_perTopicPendingLimit) {
                        
                        long commit = m_seenOffset.last();
                        if (commitOffset(commit)) {
                            debug("Committed offset " + commit + " for " + m_topicAndPartition);
                            m_currentOffset.set(commit);
                        }
                        synchronized(m_seenOffset) {
                            m_seenOffset.clear();
                        }
                        info("Seen offset commit list is too big. Size " + m_perTopicPendingLimit + " Commiting highest offset and clean.");
                        return;
                    }
                    long commit;
                    synchronized(m_seenOffset) {
                        if (!m_seenOffset.isEmpty()) {
                            m_seenOffset.add(currentNext);
                            
                            commit = m_seenOffset.first();
                            while (m_seenOffset.contains(++commit)) {
                                m_seenOffset.remove(commit);
                            }
                        } else {
                           commit =  currentNext;
                        }
                    }

                    
                    if (commitOffset(commit)) {
                        debug("Committed offset " + commit + " for " + m_topicAndPartition);
                        m_currentOffset.set(commit);
                    }
                    
                } catch (Exception ex) {
                    error("Failed to commit and save offset " + currentNext, ex);
                }
            }

            @Override
            public void clientCallback(ClientResponse response) throws Exception {
                try {
                    
                    assert(!m_pendingOffsets.isEmpty());

                    m_pendingOffsets.remove(m_offset);
                    commitAndSaveOffset(m_nextOffset);

                } catch (Throwable t) {
                    
                  t.printStackTrace();
                }
            }

        }

        
        private int backoffSleep(int fetchFailedCount) {
            try {
                Thread.sleep(1000 * fetchFailedCount++);
                if (fetchFailedCount > 10) fetchFailedCount = 1;
            } catch (InterruptedException ie) {
            }
            return fetchFailedCount;
        }

        @Override
        public void run() {
            SimpleConsumer consumer = null;
            info("Starting partition fetcher for " + m_topicAndPartition);
            try {
                
                HostAndPort leaderBroker = m_leader;
                int fetchFailedCount = 1;
                while (!m_shutdown) {
                    if (consumer == null) {
                        consumer = new SimpleConsumer(leaderBroker.getHost(), leaderBroker.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID);
                    }
                    
                    if (m_currentOffset.get() < 0) {
                        getOffsetCoordinator();
                        m_currentOffset.set(getLastOffset(kafka.api.OffsetRequest.LatestTime()));
                        if (m_currentOffset.get() < 0) {
                            fetchFailedCount = backoffSleep(fetchFailedCount);
                            continue;
                        }
                        info("Starting offset for " + m_topicAndPartition + " is set to: " + m_currentOffset.get());
                    }
                    long currentFetchCount = 0;
                    
                    if (m_pendingOffsets.size() < m_perTopicPendingLimit) {
                        FetchRequest req = new FetchRequestBuilder().clientId(CLIENT_ID)
                                .addFetch(m_topicAndPartition.topic(),
                                        m_topicAndPartition.partition(), m_currentOffset.get(), m_fetchSize)
                                .build();
                        FetchResponse fetchResponse = null;
                        try {
                            fetchResponse = consumer.fetch(req);
                            if (fetchResponse == null) {
                                fetchFailedCount = backoffSleep(fetchFailedCount);
                                continue;
                            }
                        } catch (Exception ex) {
                            error("Failed to fetch from " + m_topicAndPartition, ex);
                            fetchFailedCount = backoffSleep(fetchFailedCount);
                            continue;
                        }

                        if (fetchResponse.hasError()) {
                            
                            short code = fetchResponse.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                            fetchFailedCount = backoffSleep(fetchFailedCount);
                            error("Failed to fetch messages for " + m_topicAndPartition + " Code " + code);
                            if (code == ErrorMapping.OffsetOutOfRangeCode()) {
                                
                                info("Invalid offset requested for " + m_topicAndPartition);
                                getOffsetCoordinator();
                                m_currentOffset.set(getLastOffset(kafka.api.OffsetRequest.LatestTime()));
                                continue;
                            }
                            closeConsumer(consumer);
                            consumer = null;
                            leaderBroker = findNewLeader();
                            if (leaderBroker == null) {
                                
                                error("Failed to find leader continue with old leader: " + m_leader);
                                leaderBroker = m_leader;
                            } else {
                                if (!leaderBroker.equals(m_leader)) {
                                    info("Found new leader for " + m_topicAndPartition + " New Leader: " + leaderBroker);
                                }
                            }
                            continue;
                        }
                        fetchFailedCount = 1;
                        for (MessageAndOffset messageAndOffset : fetchResponse.messageSet(m_topicAndPartition.topic(), m_topicAndPartition.partition())) {
                            long currentOffset = messageAndOffset.offset();
                            
                            if (currentOffset < m_currentOffset.get() || m_pendingOffsets.contains(currentOffset)) {
                                continue;
                            }
                            ByteBuffer payload = messageAndOffset.message().payload();

                            currentFetchCount++;
                            byte[] bytes = new byte[payload.limit()];
                            payload.get(bytes);
                            String line = new String(bytes, "UTF-8");
                            CSVInvocation invocation = new CSVInvocation(m_procedure, line);
                            TopicPartitionInvocationCallback cb = new TopicPartitionInvocationCallback(currentOffset, messageAndOffset.nextOffset(), m_topicAndPartition);
                            m_pendingOffsets.add(currentOffset);
                            if (!callProcedure(cb, invocation)) {
                                debug("Failed to process Invocation possibly bad data: " + line);
                                m_pendingOffsets.remove(messageAndOffset.nextOffset());
                                
                                synchronized(m_seenOffset) {
                                    m_seenOffset.add(messageAndOffset.nextOffset());
                                }
                                continue;
                            }
                        }
                    }

                    if (currentFetchCount == 0) {
                        try {
                            Thread.sleep(1000);
                        } catch (InterruptedException ie) {
                        }
                    }
                }
                info("Partition fecher stopping for " + m_topicAndPartition);
                int cnt = 1;
                while (m_pendingOffsets.size() > 0) {
                    cnt = backoffSleep(cnt);
                }
                info("Partition fecher stopped for " + m_topicAndPartition + " Last commit point is: " + m_currentOffset.get());
            } catch (Exception ex) {
                error("Failed to start topic partition fetcher for " + m_topicAndPartition, ex);
            } finally {
                closeConsumer(consumer);
                consumer = null;
            }
        }

    }

    public void closeConsumer(SimpleConsumer consumer) {
        try {
            if (consumer != null) {
                consumer.close();
            }
        } catch (Exception e) {
            error("Failed to close consumer connection.", e);
        }
    }

    
    @Override
    public void onChange(Set<URI> added, Set<URI> removed, Set<URI> assigned, int version) {
        if (m_stopping) {
            info("Importer is stopping ignoring the change notification.");
        }
        if (m_es == null) {
            
            VoltDB.crashLocalVoltDB("buildTopicLeaderMetadata must be called before getting an onChange", false, null);
        }

        
        for (URI nuri : added) {
            Map<String, List<Integer>> topicMap = new HashMap<String, List<Integer>>();
            for (String topic : m_topicList) {
                topicMap.put(topic, Collections.singletonList(0));
            }
            for (String topic : m_topicList) {
                List<Integer> topicPartitions = m_topicPartitions.get(topic);
                if (topicPartitions == null) {
                    
                    VoltDB.crashLocalVoltDB("Unknown kafka topic added for this node", false, null);
                }
                for (int partition : topicPartitions) {
                    String leaderKey = topic + "-" + partition;
                    URI assignedKey = URI.create("kafka:/" + topic + "/partition/" + partition);
                    
                    if (!m_fetchers.containsKey(nuri) && nuri.equals(assignedKey)) {
                        info("Channel " + assignedKey + " mastership is assigned to this node.");
                        HostAndPort hap = m_topicPartitionLeader.get(leaderKey);
                        TopicPartitionFetcher fetcher = new TopicPartitionFetcher(m_brokerList, assignedKey, topic, partition,
                                hap, m_fetchSize, m_consumerSocketTimeout);
                        m_fetchers.put(assignedKey.toString(), fetcher);
                        m_es.submit(fetcher);
                        info("KafkaImporter is fetching for resource: " + nuri);
                    }
                }
            }
        }

        
        for (URI r : removed) {
            TopicPartitionFetcher fetcher = m_fetchers.get(r.toString());
            if (fetcher != null) {
                fetcher.shutdown();
                info("KafkaImporter is NOT fetching for resource: " + r);
                m_fetchers.remove(r.toString());
            }
        }
    }


    
    @Override
    public void readyForData() {
        try {
            info("Configured and ready with properties: " + m_properties);
            
            m_done.acquire();
        } catch (Exception ex) {
            error("Kafka Importer finished with exeception ", ex);
        }
    }

}

<code block>


package org.voltdb.sysprocs;

import java.util.List;
import java.util.Map;

import org.voltdb.DependencyPair;
import org.voltdb.SystemProcedureExecutionContext;
import org.voltdb.OperationMode;
import org.voltdb.ParameterSet;
import org.voltdb.ProcInfo;
import org.voltdb.VoltDB;
import org.voltdb.VoltSystemProcedure;
import org.voltdb.VoltTable;
import org.voltdb.VoltZK;

@ProcInfo(singlePartition = false)

public class Resume extends VoltSystemProcedure
{
    @Override
    public void init() {}

    @Override
    public DependencyPair executePlanFragment(
            Map<Integer, List<VoltTable>> dependencies, long fragmentId,
            ParameterSet params, SystemProcedureExecutionContext context)
    {
        throw new RuntimeException("Resume was given an " +
                                   "invalid fragment id: " + String.valueOf(fragmentId));
    }

    
    public VoltTable[] run(SystemProcedureExecutionContext ctx)
    {
        
        if (ctx.isLowestSiteId())
        {
            VoltDB.instance().setMode(OperationMode.RUNNING);
            try {
                VoltDB.instance().getHostMessenger().getZK().setData(
                        VoltZK.operationMode,
                        OperationMode.RUNNING.toString().getBytes("UTF-8"), -1);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }

        VoltTable t = new VoltTable(VoltSystemProcedure.STATUS_SCHEMA);
        t.addRow(VoltSystemProcedure.STATUS_OK);
        return (new VoltTable[] {t});
    }
}

<code block>


package org.voltdb.sysprocs;

import java.util.List;
import java.util.Map;

import org.voltdb.DependencyPair;
import org.voltdb.SystemProcedureExecutionContext;
import org.voltdb.OperationMode;
import org.voltdb.ParameterSet;
import org.voltdb.ProcInfo;
import org.voltdb.VoltDB;
import org.voltdb.VoltSystemProcedure;
import org.voltdb.VoltTable;
import org.voltdb.VoltZK;

@ProcInfo(singlePartition = false)

public class Pause extends VoltSystemProcedure
{
    @Override
    public void init() {}

    @Override
    public DependencyPair executePlanFragment(
            Map<Integer, List<VoltTable>> dependencies, long fragmentId,
            ParameterSet params, SystemProcedureExecutionContext context)
    {
        throw new RuntimeException("Pause was given an " +
                                   "invalid fragment id: " + String.valueOf(fragmentId));
    }

    
    public VoltTable[] run(SystemProcedureExecutionContext ctx)
    {
        
        if (ctx.isLowestSiteId())
        {
            VoltDB.instance().setMode(OperationMode.PAUSED);
            try {
                VoltDB.instance().getHostMessenger().getZK().setData(
                        VoltZK.operationMode,
                        OperationMode.PAUSED.toString().getBytes("UTF-8"), -1);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }

        VoltTable t = new VoltTable(VoltSystemProcedure.STATUS_SCHEMA);
        t.addRow(VoltSystemProcedure.STATUS_OK);
        return (new VoltTable[] {t});
    }
}

<code block>


package org.voltdb.importer;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.net.URI;
import java.util.Set;
import java.util.concurrent.TimeUnit;
import org.voltdb.client.ProcedureCallback;


public abstract class ImportHandlerProxy implements ImportContext, ChannelChangeCallback {

    private Object m_handler = null;
    private Method m_callProcMethod;
    private Method m_asyncCallProcMethod;
    private Method m_hasTableMethod;
    private Method m_info_log;
    private Method m_error_log;
    private Method m_warn_log;
    private Method m_error_log_withT;
    private Method m_debug_log;

    @Override
    public boolean canContinue() {
        return true;
    }

    public boolean hasTable(String name) {
        try {
            return (Boolean) m_hasTableMethod.invoke(m_handler, name);
        } catch(InvocationTargetException e) { 
            throw new RuntimeException(e);
        } catch(IllegalAccessException e) { 
            throw new RuntimeException(e);
        }
    }

    
    @Override
    public boolean callProcedure(String proc, Object... fieldList) {
        try {
            return (Boolean )m_callProcMethod.invoke(m_handler, this, proc, fieldList);
        } catch (Exception ex) {
            return false;
        }
    }

    @Override
    public boolean callProcedure(Invocation invocation) {
        try {
            Object params[] = invocation.getParams();
            return (Boolean )m_callProcMethod.invoke(m_handler, this, invocation.getProcedure(), params);
        } catch (Exception ex) {
            return false;
        }
    }

    @Override
    public boolean callProcedure(ProcedureCallback cb, Invocation invocation) {
        try {
            Object params[] = invocation.getParams();
            return (Boolean )m_asyncCallProcMethod.invoke(m_handler, this, cb, invocation.getProcedure(), params);
        } catch (Exception ex) {
            return false;
        }
    }

    @Override
    public void setHandler(Object handler) throws Exception {
        m_handler = handler;
        m_callProcMethod = m_handler.getClass().getMethod("callProcedure", ImportContext.class, String.class, Object[].class);
        m_asyncCallProcMethod = m_handler.getClass().getMethod("callProcedure", ImportContext.class, ProcedureCallback.class, String.class, Object[].class);
        m_hasTableMethod = m_handler.getClass().getMethod("hasTable", String.class);
        m_info_log = m_handler.getClass().getMethod("info", String.class);
        m_error_log = m_handler.getClass().getMethod("error", String.class);
        m_warn_log = m_handler.getClass().getMethod("warn", String.class);
        m_debug_log = m_handler.getClass().getMethod("debug", String.class);
        m_error_log_withT = m_handler.getClass().getMethod("error", String.class, Throwable.class);
    }

    @Override
    public void info(String message) {
        try {
            if (m_info_log != null) {
                m_info_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void error(String message, Throwable t) {
        try {
            if (m_error_log != null) {
                m_error_log_withT.invoke(m_handler, message, t);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void error(String message) {
        try {
            if (m_error_log != null) {
                m_error_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void warn(String message) {
        try {
            if (m_error_log != null) {
                m_warn_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void debug(String message) {
        try {
            if (m_debug_log != null) {
                m_debug_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public long getBackpressureTimeout() {
        return TimeUnit.MINUTES.toNanos(2);
    }

    @Override
    public boolean isRunEveryWhere() {
        return true;
    }

    @Override
    public Set<URI> getAllResponsibleResources() {
        throw new UnsupportedOperationException("For Distributed Importer this must be implemented.");
    }

    @Override
    public void onChange(Set<URI> added, Set<URI> removed, Set<URI> assigned, int version) {
        throw new UnsupportedOperationException("For Distributed Importer this must be implemented.");
    }
}

<code block>


package org.voltdb.importer;

import java.util.NavigableSet;
import java.util.Set;

import com.google_voltpatches.common.collect.Sets;

public class ChannelAssignment {

    final Set<ChannelSpec> added;
    final Set<ChannelSpec> removed;
    final NavigableSet<ChannelSpec> channels;
    final int version;

    ChannelAssignment(NavigableSet<ChannelSpec> prev, NavigableSet<ChannelSpec> next, int version) {
        this.version  = version;
        this.added    = Sets.difference(next, prev);
        this.removed  = Sets.difference(prev, next);
        this.channels = next;
    }

    public Set<ChannelSpec> getAdded() {
        return added;
    }

    public Set<ChannelSpec> getRemoved() {
        return removed;
    }

    public NavigableSet<ChannelSpec> getChannels() {
        return channels;
    }

    public int getVersion() {
        return version;
    }

    public boolean hasChanges() {
        return !removed.isEmpty() || !added.isEmpty();
    }

    @Override
    public String toString() {
        return "ChannelAssignment [added=" + added + ", removed=" + removed
                + ", channels=" + channels + ", version=" + version + "]";
    }
}

<code block>


package org.voltdb.importer;

import java.util.HashMap;
import java.util.Map;
import java.util.Properties;

import org.osgi.framework.Bundle;
import org.osgi.framework.ServiceReference;
import org.osgi.framework.launch.Framework;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltdb.CatalogContext;
import org.voltdb.ImportHandler;
import org.voltdb.VoltDB;

import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.base.Throwables;
import java.net.URI;
import java.util.HashSet;
import java.util.Set;
import org.osgi.framework.BundleException;

public class ImportProcessor implements ImportDataProcessor {

    private static final VoltLogger m_logger = new VoltLogger("IMPORT");
    private final Map<String, BundleWrapper> m_bundles = new HashMap<String, BundleWrapper>();
    private final Map<String, BundleWrapper> m_bundlesByName = new HashMap<String, BundleWrapper>();
    private final Framework m_framework;
    private final ChannelDistributer m_distributer;
    private final ChannelChangeNotifier m_channelNotifier;

    public ImportProcessor(int myHostId, ChannelDistributer distributer, Framework framework) throws BundleException {
        m_framework = framework;
        m_distributer = distributer;
        m_channelNotifier = new ChannelChangeNotifier();
    }

    
    public class BundleWrapper {
        public final Bundle m_bundle;
        public final Properties m_properties;
        public final ImportHandlerProxy m_handlerProxy;
        private ImportHandler m_handler;
        private ChannelDistributer m_channelDistributer;

        public BundleWrapper(ImportHandlerProxy handler, Properties properties, Bundle bundle) {
            m_bundle = bundle;
            m_handlerProxy = handler;
            m_properties = properties;
        }

        public void setChannelDistributer(ChannelDistributer distributer) {
            m_channelDistributer = distributer;
        }

        public void setHandler(ImportHandler handler) throws Exception {
            Preconditions.checkState((m_handler == null), "ImportHandler can only be set once.");
            m_handler = handler;
            m_handlerProxy.setHandler(handler);
        }

        public ImportHandler getHandler() {
            return m_handler;
        }

        public void stop() {
            try {
                m_handler.stop();
                if (m_bundle != null) {
                    m_bundle.stop();
                }
                if (m_channelDistributer != null) {
                    m_channelDistributer.registerChannels(m_handlerProxy.getName(), new HashSet<URI>());
                }
            } catch (Exception ex) {
                m_logger.error("Failed to stop the import bundles.", ex);
            }
        }
    }

    public void addProcessorConfig(Properties properties) {
        String module = properties.getProperty(ImportDataProcessor.IMPORT_MODULE);
        String moduleAttrs[] = module.split("\\|");
        String bundleJar = moduleAttrs[1];
        String moduleType = moduleAttrs[0];

        Preconditions.checkState(!m_bundles.containsKey(bundleJar), "Import to source is already defined.");
        try {
            BundleWrapper wrapper = null;
            ImportHandlerProxy importHandlerProxy = null;
            if (moduleType.equalsIgnoreCase("osgi")) {

                Bundle bundle = m_framework.getBundleContext().installBundle(bundleJar);
                bundle.start();
                ServiceReference refs[] = bundle.getRegisteredServices();
                
                ServiceReference reference = refs[0];
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    bundle.stop();
                    return;
                }
                Object o = bundle.getBundleContext().getService(reference);
                importHandlerProxy = (ImportHandlerProxy )o;
                wrapper = new BundleWrapper(importHandlerProxy, properties, bundle);
            } else {
                
                Class reference = this.getClass().getClassLoader().loadClass(bundleJar);
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    return;
                }

                importHandlerProxy = (ImportHandlerProxy )reference.newInstance();
                 wrapper = new BundleWrapper(importHandlerProxy, properties, null);
            }
            importHandlerProxy.configure(properties);
            String name = importHandlerProxy.getName();
            if (name == null || name.trim().length() == 0) {
                throw new RuntimeException("Importer must implement and return a valid unique name.");
            }
            Preconditions.checkState(!m_bundlesByName.containsKey(name), "Importer must implement and return a valid unique name: " + name);
            m_bundlesByName.put(name, wrapper);
            m_bundles.put(bundleJar, wrapper);
        } catch(Throwable t) {
            m_logger.error("Failed to configure import handler for " + bundleJar, t);
            Throwables.propagate(t);
        }
    }

    @Override
    public synchronized void readyForData(CatalogContext catContext, HostMessenger messenger) {

        for (BundleWrapper bw : m_bundles.values()) {
            try {
                ImportHandler importHandler = new ImportHandler(bw.m_handlerProxy, catContext);
                
                bw.setHandler(importHandler);
                if (!bw.m_handlerProxy.isRunEveryWhere()) {
                    
                    Set<URI> allResources = bw.m_handlerProxy.getAllResponsibleResources();
                    m_logger.info("All Available Resources for " + bw.m_handlerProxy.getName() + " Are: " + allResources);

                    bw.setChannelDistributer(m_distributer);
                    
                    m_channelNotifier.registerCallback(bw.m_handlerProxy.getName(), bw.m_handlerProxy);
                    m_distributer.registerChannels(bw.m_handlerProxy.getName(), allResources);
                }
                importHandler.readyForData();
                m_logger.info("Importer started: " + bw.m_handlerProxy.getName());
            } catch (Exception ex) {
                
                VoltDB.crashLocalVoltDB("Import failed to set Handler", true, ex);
                m_logger.error("Failed to start the import handler: " + bw.m_handlerProxy.getName(), ex);
            }
        }
        
        m_channelNotifier.startPolling(m_distributer.getChannelAssignmentQueue());
    }

    @Override
    public synchronized void shutdown() {
        try {
            
            m_channelNotifier.shutdown();
            
            for (BundleWrapper bw : m_bundles.values()) {
                try {
                    bw.stop();
                } catch (Exception ex) {
                    m_logger.error("Failed to stop the import handler: " + bw.m_handlerProxy.getName(), ex);
                }
            }
            m_bundles.clear();
        } catch (Exception ex) {
            m_logger.error("Failed to stop the import bundles.", ex);
        }
    }

    @Override
    public void setProcessorConfig(Map<String, Properties> config) {
        for (String cname : config.keySet()) {
            Properties properties = config.get(cname);

            String importBundleJar = properties.getProperty(IMPORT_MODULE);
            Preconditions.checkNotNull(importBundleJar, "Import source is undefined or custom export plugin class missing.");
            addProcessorConfig(properties);
        }
    }

}

<code block>


package org.voltdb.importer;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.ServiceLoader;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.LinkedBlockingDeque;
import java.util.concurrent.atomic.AtomicReference;
import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.osgi.framework.BundleException;
import org.osgi.framework.Constants;
import org.osgi.framework.launch.Framework;
import org.osgi.framework.launch.FrameworkFactory;
import static org.voltcore.common.Constants.VOLT_TMP_DIR;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltdb.CatalogContext;
import org.voltdb.VoltDB;
import org.voltdb.utils.CatalogUtil;


public class ImportManager {

    
    private static final VoltLogger importLog = new VoltLogger("IMPORT");

    AtomicReference<ImportDataProcessor> m_processor = new AtomicReference<ImportDataProcessor>();
    private volatile Map<String, Properties> m_processorConfig = new HashMap<>();

    
    private static ImportManager m_self;
    private final HostMessenger m_messenger;

    private final FrameworkFactory m_frameworkFactory;
    private final Map<String, String> m_frameworkProps;
    private final Framework m_framework;
    private final int m_myHostId;
    private BlockingDeque<ChannelAssignment> m_queue = new LinkedBlockingDeque<ChannelAssignment>(Integer.getInteger("voltdb.import.maxchannels", 2048));
    private final ChannelDistributer m_distributer;
    
    public static ImportManager instance() {
        return m_self;
    }

    protected ImportManager(int myHostId, HostMessenger messenger) throws BundleException {
        m_myHostId = myHostId;
        m_messenger = messenger;
        m_distributer = new ChannelDistributer(m_messenger.getZK(), String.valueOf(m_myHostId), m_queue);

        
        m_frameworkProps = new HashMap<String, String>();
        
        m_frameworkProps.put(Constants.FRAMEWORK_SYSTEMPACKAGES_EXTRA, "org.voltcore.network;version=1.0.0"
                + ",org.voltdb.importer;version=1.0.0,org.apache.log4j;version=1.0.0,org.voltdb.client;version=1.0.0,org.slf4j;version=1.0.0,org.voltcore.utils;version=1.0.0");
        
        m_frameworkProps.put("org.osgi.framework.storage.clean", "onFirstInit");
        String tmpFilePath = System.getProperty(VOLT_TMP_DIR, System.getProperty("java.io.tmpdir"));
        m_frameworkProps.put("felix.cache.rootdir", tmpFilePath);
        m_frameworkFactory = ServiceLoader.load(FrameworkFactory.class).iterator().next();
        importLog.info("Framework properties are: " + m_frameworkProps);
        m_framework = m_frameworkFactory.newFramework(m_frameworkProps);
        m_framework.start();
    }

    
    public static synchronized void initialize(int myHostId, CatalogContext catalogContext, List<Integer> partitions, HostMessenger messenger) throws BundleException {
        ImportManager em = new ImportManager(myHostId, messenger);

        m_self = em;
        em.create(myHostId, m_self.m_distributer, catalogContext, messenger.getZK());
    }

    
    private synchronized void create(int myHostId, ChannelDistributer distributer, CatalogContext catalogContext, ZooKeeper zk) {
        try {
            if (catalogContext.getDeployment().getImport() == null) {
                return;
            }
            ImportDataProcessor newProcessor = new ImportProcessor(myHostId, distributer, m_framework);
            m_processorConfig = CatalogUtil.getImportProcessorConfig(catalogContext.getDeployment().getImport());
            newProcessor.setProcessorConfig(m_processorConfig);
            m_processor.set(newProcessor);
            importLog.info("Import Processor is configured.");
        } catch (final Exception e) {
            VoltDB.crashLocalVoltDB("Error creating import processor", true, e);
        }
    }

    public synchronized void shutdown() {
        close();
        m_distributer.shutdown();
    }

    public synchronized void close() {
        
        if (m_processor.get() == null) {
            return;
        }
        m_processor.get().shutdown();
        
        m_processor.set(null);
    }

    
    public synchronized void restart(CatalogContext catalogContext, HostMessenger messenger) {
        
        m_self.close();
        assert(m_processor.get() == null);
        m_self.create(m_myHostId, m_distributer, catalogContext, messenger.getZK());
        m_self.readyForData(catalogContext, messenger);
    }

    public void updateCatalog(CatalogContext catalogContext, HostMessenger messenger) {
        restart(catalogContext, messenger);
    }

    public synchronized void readyForData(CatalogContext catalogContext, HostMessenger messenger) {
        
        if (m_processor.get() == null) {
            return;
        }
        
        m_processor.get().readyForData(catalogContext, messenger);
    }

}

<code block>


package org.voltdb.importer;

import java.net.URI;
import java.util.Set;

public interface ChannelChangeCallback {
    void onChange(Set<URI> added, Set<URI> removed, Set<URI> assigned, int version);
}

<code block>


package org.voltdb.importer;

import static com.google_voltpatches.common.base.Preconditions.checkNotNull;
import static com.google_voltpatches.common.base.Predicates.equalTo;
import static com.google_voltpatches.common.base.Predicates.not;

import java.net.URI;
import java.util.Map;
import java.util.NavigableMap;
import java.util.Set;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.atomic.AtomicStampedReference;

import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.CoreUtils;

import com.google_voltpatches.common.base.Optional;
import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.collect.ImmutableSetMultimap;
import com.google_voltpatches.common.collect.ImmutableSortedMap;
import com.google_voltpatches.common.collect.Maps;
import com.google_voltpatches.common.collect.SetMultimap;
import com.google_voltpatches.common.collect.Sets;

public class ChannelChangeNotifier implements Runnable {

    private final static VoltLogger LOG = new VoltLogger("IMPORT");

    
    static DistributerException loggedDistributerException(Throwable cause, String format, Object...args) {
        Optional<DistributerException> causeFor = DistributerException.isCauseFor(cause);
        if (causeFor.isPresent()) {
            return causeFor.get();
        }
        String msg = String.format(format, args);
        if (cause != null) {
            LOG.error(msg, cause);
            return new DistributerException(msg, cause);
        } else {
            LOG.error(msg);
            return new DistributerException(msg);
        }
    }

    SetMultimap<String, URI> mapByImporter(Set<ChannelSpec> specs) {
        ImmutableSetMultimap.Builder<String, URI> mmbldr = ImmutableSetMultimap.builder();
        for (ChannelSpec spec: specs) {
            mmbldr.put(spec.getImporter(),spec.getUri());
        }
        return mmbldr.build();
    }

    private final CallbacksRef m_callbacks = new CallbacksRef();
    private final AtomicReference<BlockingDeque<ChannelAssignment>> m_qref = new AtomicReference<>();
    private final AtomicBoolean m_done = new AtomicBoolean(false);
    private final ExecutorService m_es;

    public ChannelChangeNotifier() {
        m_es = CoreUtils.getCachedSingleThreadExecutor("Import Channel Change Notification Dispatcher", 15000);
    }

    public void startPolling(BlockingDeque<ChannelAssignment> deque) {
        if (m_qref.compareAndSet(null, checkNotNull(deque, "deque is null"))) {
            m_es.submit(this);
        } else {
            throw new IllegalStateException("this notifier has already an assigned blocking deque");
        }
    }

    public void registerCallback(String importer, ChannelChangeCallback callback) {
        Preconditions.checkArgument(
                importer != null && !importer.trim().isEmpty(),
                "importer is null or empty"
                );
        callback = checkNotNull(callback, "callback is null");

        int [] stamp = new int[]{0};
        NavigableMap<String, ChannelChangeCallback> prev = null;
        ImmutableSortedMap.Builder<String,ChannelChangeCallback> mbldr = null;

        do {
            prev = m_callbacks.get(stamp);
            mbldr = ImmutableSortedMap.naturalOrder();
            mbldr.putAll(Maps.filterKeys(prev, not(equalTo(importer))));
            mbldr.put(importer, callback);
        } while (!m_callbacks.compareAndSet(prev, mbldr.build(), stamp[0], stamp[0]+1));
    }

    public void shutdown() {
        if (m_done.compareAndSet(false, true)) {
            m_es.shutdown();
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException e) {
                throw loggedDistributerException(e, "interrupted while waiting for executor termination");
            }
        }
    }

    @Override
    public void run() {
        if (m_done.get()) return;
        ChannelAssignment assignment = null;
        try {
            assignment = m_qref.get().poll(200, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            throw loggedDistributerException(e, "interrupted while polling for channel assignmanets");
        }
        if (assignment != null) {

            final SetMultimap<String, URI> added = mapByImporter(assignment.getAdded());
            final SetMultimap<String, URI> removed = mapByImporter(assignment.getRemoved());
            final SetMultimap<String, URI> assigned = mapByImporter(assignment.getChannels());

            NavigableMap<String, ChannelChangeCallback> callbacks = m_callbacks.getReference();
            for (Map.Entry<String, ChannelChangeCallback> e: callbacks.entrySet()) {
                final String importer = e.getKey();
                if (added.get(importer).isEmpty() && removed.get(importer).isEmpty()) {
                    continue;
                }
                final ChannelChangeCallback callback = e.getValue();
                final int version = assignment.getVersion();
                m_es.submit(new Runnable() {
                    @Override
                    public void run() {
                        if (m_done.get()) return;
                        try {
                            callback.onChange(
                                    added.get(importer),
                                    removed.get(importer),
                                    assigned.get(importer),
                                    version
                                    );
                        } catch (Exception e) {
                            throw loggedDistributerException(
                                    e, "failed to invoke channel changed callback for %s", importer
                                    );
                        }
                    }
                });
            }
            for (String noCallbackFor: Sets.difference(assigned.keySet(), callbacks.keySet())) {
                LOG.warn("Missing channel notification callbacks for importer \"" + noCallbackFor
                        + "\", which leave these channels \"" + assigned.get(noCallbackFor)
                        + "\" without any assigned handler"
                        );
            }
        }
        if (!m_done.get()) {
            m_es.submit(this);
        }
    }

    final static class CallbacksRef
        extends AtomicStampedReference<NavigableMap<String,ChannelChangeCallback>> {

        static final NavigableMap<String,ChannelChangeCallback> EMTPY_MAP =
                ImmutableSortedMap.of();

        public CallbacksRef(
                NavigableMap<String, ChannelChangeCallback> initialRef,
                int initialStamp) {
            super(initialRef, initialStamp);
        }

        public CallbacksRef() {
            this(EMTPY_MAP,0);
        }
    }
}

<code block>


package org.voltdb.importer;

import static com.google_voltpatches.common.base.Predicates.equalTo;
import static com.google_voltpatches.common.base.Predicates.isNull;
import static com.google_voltpatches.common.base.Predicates.not;
import static org.voltcore.zk.ZKUtil.joinZKPath;

import java.io.File;
import java.net.URI;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.NavigableMap;
import java.util.NavigableSet;
import java.util.Random;
import java.util.Set;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicStampedReference;

import org.apache.zookeeper_voltpatches.AsyncCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.Children2Callback;
import org.apache.zookeeper_voltpatches.AsyncCallback.DataCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.StatCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.StringCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.VoidCallback;
import org.apache.zookeeper_voltpatches.CreateMode;
import org.apache.zookeeper_voltpatches.KeeperException;
import org.apache.zookeeper_voltpatches.KeeperException.Code;
import org.apache.zookeeper_voltpatches.KeeperException.NodeExistsException;
import org.apache.zookeeper_voltpatches.WatchedEvent;
import org.apache.zookeeper_voltpatches.Watcher;
import org.apache.zookeeper_voltpatches.Watcher.Event.EventType;
import org.apache.zookeeper_voltpatches.Watcher.Event.KeeperState;
import org.apache.zookeeper_voltpatches.ZooDefs;
import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.apache.zookeeper_voltpatches.data.Stat;
import org.json_voltpatches.JSONArray;
import org.json_voltpatches.JSONException;
import org.json_voltpatches.JSONStringer;
import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.CoreUtils;
import org.voltcore.zk.ZKUtil;

import com.google_voltpatches.common.base.Function;
import com.google_voltpatches.common.base.Optional;
import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.base.Predicate;
import com.google_voltpatches.common.collect.FluentIterable;
import com.google_voltpatches.common.collect.ImmutableSortedMap;
import com.google_voltpatches.common.collect.ImmutableSortedSet;
import com.google_voltpatches.common.collect.Maps;
import com.google_voltpatches.common.collect.Sets;
import com.google_voltpatches.common.collect.TreeMultimap;


public class ChannelDistributer {

    private final static VoltLogger LOG = new VoltLogger("IMPORT");

    
    static final String IMPORT_DN = "/import";
    
    static final String HOST_DN = joinZKPath(IMPORT_DN, "host");
    
    static final String MASTER_DN = joinZKPath(IMPORT_DN, "master");
    
    static final String CANDIDATE_PN = joinZKPath(MASTER_DN, "candidate_");

    static final byte[] EMPTY_ARRAY = "[]".getBytes(StandardCharsets.UTF_8);

    static void mkdirs(ZooKeeper zk, String zkNode) {
        try {
            ZKUtil.asyncMkdirs(zk, zkNode, EMPTY_ARRAY).get();
        } catch (NodeExistsException itIsOk) {
        } catch (InterruptedException | KeeperException e) {
            String msg = "Unable to create zk directory: " + zkNode;
            LOG.error(msg, e);
            throw new DistributerException(msg, e);
        }
    }

    
    static DistributerException loggedDistributerException(Throwable cause, String format, Object...args) {
        Optional<DistributerException> causeFor = DistributerException.isCauseFor(cause);
        if (causeFor.isPresent()) {
            return causeFor.get();
        }
        String msg = String.format(format, args);
        if (cause != null) {
            LOG.error(msg, cause);
            return new DistributerException(msg, cause);
        } else {
            LOG.error(msg);
            return new DistributerException(msg);
        }
    }

    
    static Optional<DistributerException> checkCode(Code code, String format, Object...args) {
        if (code != Code.OK) {
            KeeperException kex = KeeperException.create(code);
            return Optional.of(loggedDistributerException(kex, format, args));
        } else {
            return Optional.absent();
        }
    }

    
    static void acquireAndRelease(Semaphore lock) {
        try {
            lock.acquire();
            lock.release();
        } catch (InterruptedException ex) {
            throw loggedDistributerException(ex, "iterruped while waiting for a semaphare");
        }
    }

    
    static NavigableSet<ChannelSpec> asChannelSet(byte[] data)
            throws JSONException, IllegalArgumentException {
        ImmutableSortedSet.Builder<ChannelSpec> sbld = ImmutableSortedSet.naturalOrder();
        JSONArray ja = new JSONArray(new String(data, StandardCharsets.UTF_8));
        for (int i=0; i< ja.length(); ++i) {
            sbld.add(new ChannelSpec(ja.getString(i)));
        }
        return  sbld.build();
    }

    
    static byte [] asHostData(NavigableSet<ChannelSpec> specs)
            throws JSONException, IllegalArgumentException {
        JSONStringer js = new JSONStringer();
        js.array();
        for (ChannelSpec spec: specs) {
            js.value(spec.asJSONValue());
        }
        js.endArray();
        return js.toString().getBytes(StandardCharsets.UTF_8);
    }

    
    static String id(Object o) {
        if (o == null) return "(null)";
        Thread t = Thread.currentThread();
        StringBuilder sb = new StringBuilder(128);
        sb.append("(T[").append(t.getName()).append("]@");
        sb.append(Long.toString(t.getId(), Character.MAX_RADIX));
        sb.append(":O[").append(o.getClass().getSimpleName());
        sb.append("]@");
        sb.append(Long.toString(System.identityHashCode(o),Character.MAX_RADIX));
        sb.append(")");
        return sb.toString();
    }

    private final ExecutorService m_es;
    private final AtomicBoolean m_done = new AtomicBoolean(false);
    private final ZooKeeper m_zk;
    private final String m_hostId;
    private final String m_candidate;
    private final BlockingDeque<ChannelAssignment> m_assignq;

    volatile boolean m_isLeader = false;
    volatile SpecsRef m_specs = new SpecsRef();
    volatile HostsRef m_hosts = new HostsRef();
    volatile ChannelsRef m_channels = new ChannelsRef();

    
    public ChannelDistributer(ZooKeeper zk, String hostId, BlockingDeque<ChannelAssignment> queue) {
        Preconditions.checkArgument(
                hostId != null && !hostId.trim().isEmpty(),
                "hostId is null or empty"
                );
        m_hostId = hostId;
        m_zk = Preconditions.checkNotNull(zk, "zookeeper is null");
        m_assignq = Preconditions.checkNotNull(queue, "assignment queue is null");
        m_es = CoreUtils.getCachedSingleThreadExecutor("Import Channel Distributer for Host " + hostId, 15000);

        
        mkdirs(zk, HOST_DN);
        mkdirs(zk, MASTER_DN);

        MonitorHostNodes monitor = new MonitorHostNodes(HOST_DN);
        CreateNode createHostNode = new CreateNode(
                joinZKPath(HOST_DN, hostId),
                EMPTY_ARRAY, CreateMode.EPHEMERAL
                );
        CreateNode electionCandidate = new CreateNode(
                CANDIDATE_PN,
                EMPTY_ARRAY, CreateMode.EPHEMERAL_SEQUENTIAL
                );
        ElectLeader elector = new ElectLeader(MASTER_DN, electionCandidate);

        monitor.getChildren();
        createHostNode.getNode();
        elector.elect();

        m_candidate = electionCandidate.getNode();
        
        new GetChannels(MASTER_DN).getChannels();
    }

    public final BlockingDeque<ChannelAssignment> getChannelAssignmentQueue() {
        return m_assignq;
    }

    public String getHostId() {
        return m_hostId;
    }

    
    public void registerChannels(String importer, Set<URI> uris) {
        Preconditions.checkArgument(
                importer != null && !importer.trim().isEmpty(),
                "importer is null or empty"
                );
        Preconditions.checkArgument(uris != null, "uris set is null");
        Preconditions.checkArgument(
                !FluentIterable.from(uris).anyMatch(isNull()),
                "uris set %s contains null elements",uris
                );

        Predicate<ChannelSpec> forImporter = ChannelSpec.importerIs(importer);
        Function<URI,ChannelSpec> asSpec = ChannelSpec.fromUri(importer);

        
        NavigableSet<ChannelSpec> proposed = ImmutableSortedSet.copyOf(
                FluentIterable.from(uris).transform(asSpec)
                );

        LOG.info("(" + m_hostId + ") proposing channels " + proposed);

        int [] stamp = new int[]{0};

        ImmutableSortedSet.Builder<ChannelSpec> sbldr = null;
        NavigableSet<ChannelSpec> prev = null;
        SetData setter = null;

        
        do {
            prev = m_channels.get(stamp);

            NavigableSet<ChannelSpec> current  = Sets.filter(prev, forImporter);
            if (current.equals(proposed)) {
                return;
            }
            sbldr = ImmutableSortedSet.naturalOrder();
            sbldr.addAll(Sets.filter(prev, not(forImporter)));
            sbldr.addAll(proposed);

            byte [] data = null;
            try {
                data = asHostData(sbldr.build());
            } catch (JSONException|IllegalArgumentException e) {
                throw loggedDistributerException(e, "failed to serialize the registration as json");
            }

            setter = new SetData(MASTER_DN, stamp[0], data);
        } while (setter.getCallbackCode() == Code.BADVERSION);

        setter.getStat();
    }

    
    public void shutdown() {
        if (m_done.compareAndSet(false, true)) {
            m_es.shutdown();
            DeleteNode deleteHost = new DeleteNode(joinZKPath(HOST_DN, m_hostId));
            DeleteNode deleteCandidate = new DeleteNode(m_candidate);
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException e) {
                throw loggedDistributerException(e, "interrupted while waiting for executor termination");
            }
            deleteHost.onComplete();
            deleteCandidate.onComplete();
        }
    }

    
    abstract class DistributerRunnable implements Runnable {
        @Override
        public void run() {
            try {
                if (!m_done.get()) {
                    susceptibleRun();
                }
            } catch (Exception ex) {
                throw loggedDistributerException(ex, "Fault occured while executing runnable");
            }
        }

        public abstract void susceptibleRun() throws Exception;
    }

    
    class AssignChannels extends DistributerRunnable {

        
        final NavigableSet<ChannelSpec> channels = m_channels.getReference();
        
        final NavigableMap<ChannelSpec,String> specs = m_specs.getReference();
        
        final NavigableMap<String,AtomicInteger> hosts = m_hosts.getReference();

        @Override
        public void susceptibleRun() throws Exception {
            NavigableSet<ChannelSpec> assigned = specs.navigableKeySet();
            Set<ChannelSpec> added   = Sets.difference(channels, assigned);
            Set<ChannelSpec> removed = Sets.difference(assigned, channels);

            if (added.isEmpty() && removed.isEmpty()) {
                return;
            }

            Predicate<Map.Entry<ChannelSpec,String>> withoutRemoved =
                    not(ChannelSpec.specKeyIn(removed, String.class));
            NavigableMap<ChannelSpec,String> pruned =
                    Maps.filterEntries(specs, withoutRemoved);

            if (!removed.isEmpty()) {
                LOG.info("LEADER (" + m_hostId + ") removing channels " + removed);
            }
            
            TreeMultimap<String, ChannelSpec> byhost = TreeMultimap.create();

            for (Map.Entry<ChannelSpec,String> e: pruned.entrySet()) {
                byhost.put(e.getValue(), e.getKey());
            }
            
            int fair = new Double(Math.ceil(channels.size()/(double)hosts.size())).intValue();
            List<String> hostassoc = new ArrayList<>(added.size());
            for (String host: hosts.navigableKeySet()) {
                
                int room = fair - byhost.get(host).size();
                for (int i = 0; i < room; ++i) {
                    hostassoc.add(host);
                }
            }
            Collections.shuffle(hostassoc, new Random(System.identityHashCode(this)));

            Iterator<String> hitr = hostassoc.iterator();
            Iterator<ChannelSpec> citr = added.iterator();
            while (citr.hasNext()) {
                String host = hitr.next();
                ChannelSpec spec = citr.next();
                byhost.put(host, spec);
                LOG.info("LEADER (" + m_hostId + ") assingning " + spec + " to host " + host);
            }

            try {
                
                NavigableSet<ChannelSpec> previous = null;
                NavigableSet<ChannelSpec> needed = null;
                SetNodeChannels setter = null;

                for (String host: hosts.navigableKeySet()) {
                    previous = Maps.filterValues(specs,equalTo(host)).navigableKeySet();
                    needed = byhost.get(host);
                    if (!needed.equals(previous)) {
                        int version = hosts.get(host).get();
                        byte [] nodedata = asHostData(needed);
                        setter = new SetNodeChannels(joinZKPath(HOST_DN, host), version, nodedata);
                    }
                }
                
                if (setter != null) {
                    setter.getCallbackCode();
                }
            } catch (JSONException|IllegalArgumentException e) {
                LOG.fatal("unable to create json document to assign imported channels to nodes", e);
            }
        }
    }

    
    class SetData implements StatCallback {

        final String path;
        final int version;

        final Semaphore lock = new Semaphore(0);
        volatile Optional<Stat> stat = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();
        volatile Optional<Code> callbackCode = Optional.absent();

        SetData(String path, int version, byte [] data ) {
            this.path = path;
            this.version = version;
            m_zk.setData(path, data, version, this, null);
        }

        void internalProcessResult(int rc, String path, Object ctx, Stat stat) {
            callbackCode = Optional.of(Code.get(rc));
            Code code = callbackCode.get();
            if (code == Code.OK) {
                this.stat = Optional.of(stat);
            } else if (code == Code.NONODE || code == Code.BADVERSION) {
                
                KeeperException e = KeeperException.create(code);
                fault = Optional.of(new DistributerException("failed to write to " + path, e));
            } else if (!m_done.get()) {
                fault = checkCode(code, "failed to write to %s", path);
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx, Stat stat) {
            try {
                internalProcessResult(rc, path, ctx, stat);
            } finally {
                lock.release();
            }
        }

        public Stat getStat() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return stat.get();
        }

        public Code getCallbackCode() {
            acquireAndRelease(lock);
            return callbackCode.get();
        }
    }

    
    class SetNodeChannels extends SetData {

        SetNodeChannels(String path, int version, byte[] data) {
            super(path, version, data);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, Stat stat) {
            try {
                internalProcessResult(rc, path, ctx, stat);
                Code code = Code.get(rc);
                
                
                if ((code == Code.NONODE || code == Code.BADVERSION) && !m_done.get()) {
                    m_es.submit(new AssignChannels());
                }
            } finally {
                lock.release();
            }
        }
    }

    
    class CreateNode implements StringCallback {

        final Semaphore lock = new Semaphore(0);
        volatile Optional<String> node = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();

        CreateNode(String path, byte [] data, CreateMode cmode) {
            m_zk.create(path, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, cmode, this, null);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, String name) {
            try {
                Code code = Code.get(rc);
                switch(code) {
                case NODEEXISTS:
                    code = Code.OK;
                    break;
                case OK:
                    node = Optional.of(name);
                    break;
                default:
                    node = Optional.of(path);
                }
                fault = checkCode(code, "cannot create node %s", node.get());
            } finally {
                lock.release();
            }
        }

        String getNode() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return node.get();
        }
    }

    
    class DeleteNode implements VoidCallback {
        final String path;

        final Semaphore lock = new Semaphore(0);
        volatile Optional<DistributerException> fault = Optional.absent();
        volatile Optional<Code> callbackCode = Optional.absent();

        DeleteNode(String path) {
            this.path = path;
            m_zk.delete(path, -1, this, null);
        }

        void internalProcessResult(int rc, String path, Object ctx) {
            callbackCode = Optional.of(Code.get(rc));
            switch (callbackCode.get()) {
            case OK:
            case NONODE:
            case SESSIONEXPIRED:
            case SESSIONMOVED:
            case CONNECTIONLOSS:
                break;
            default:
                fault = checkCode(callbackCode.get(), "failed to delete %s", path);
                break;
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx) {
            try {
                internalProcessResult(rc, path, ctx);
            } finally {
                lock.release();
            }
        }

        public Code getCallbackCode() {
            acquireAndRelease(lock);
            return callbackCode.get();
        }

        public void onComplete() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
        }
    }

    
    class GetChildren extends DistributerRunnable implements Children2Callback, Watcher {

        final String path;
        final Semaphore lock = new Semaphore(0);

        volatile Optional<Stat> stat = Optional.absent();
        volatile Optional<NavigableSet<String>> children = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();

        GetChildren(String path) {
            this.path = path;
            m_zk.getChildren(path, this, this, null);
        }

        void internalProcessResults(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            Code code = Code.get(rc);
            if (code == Code.OK) {
                NavigableSet<String> childset = ImmutableSortedSet.copyOf(children);
                this.stat = Optional.of(stat);
                this.children = Optional.of(childset);
            } else if (code == Code.SESSIONEXPIRED) {
                
                KeeperException e = KeeperException.create(code);
                fault = Optional.of(new DistributerException("unable to get children for " + path, e));
            } else if (!m_done.get()) {
                fault = checkCode(code, "unable to get children for %s", path);
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, children, stat);
            } finally {
                lock.release();
            }
        }

        public NavigableSet<String> getChildren() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return children.get();
        }

        public Optional<Stat> getStat() {
            return stat;
        }

        @Override
        public void process(WatchedEvent e) {
            if (   e.getState() == KeeperState.SyncConnected
                && e.getType() == EventType.NodeChildrenChanged
                && !m_done.get())
            {
                m_es.submit(this);
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetChildren(path);
        }
    }

    
    class ElectLeader extends GetChildren {
        final CreateNode leaderCandidate;

        ElectLeader(String path, CreateNode leaderCandidate) {
            super(path);
            this.leaderCandidate = Preconditions.checkNotNull(leaderCandidate,"candidate is null");
        }

        @Override
        public void processResult(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, children, stat);
                if (Code.get(rc) != Code.OK || m_done.get()) {
                    return;
                }
                m_es.submit(new DistributerRunnable() {
                    @Override
                    public void susceptibleRun() throws Exception {
                        String candidate = basename.apply(leaderCandidate.getNode());
                        if (!m_isLeader && candidate.equals(ElectLeader.this.children.get().first())) {
                            m_isLeader = true;
                            LOG.info("LEADER (" + m_hostId + ") is now the importer channel leader");
                            
                            new AssignChannels().run();
                        }
                    }
                });
            } finally {
                lock.release();
            }
        }

        boolean elect() {
            return getChildren().first().equals(leaderCandidate.getNode());
        }

        @Override
        public void susceptibleRun() throws Exception {
            new ElectLeader(path, leaderCandidate);
        }
    }

    
    class GetData extends DistributerRunnable implements DataCallback, Watcher {

        final String path;
        final Semaphore lock = new Semaphore(0);

        volatile Optional<Stat> stat = Optional.absent();
        volatile Optional<byte[]> data = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();

        GetData(String path) {
            this.path = path;
            m_zk.getData(path, this, this, null);
        }

        @Override
        public void process(WatchedEvent e) {
            if (   e.getState() == KeeperState.SyncConnected
                && e.getType() == EventType.NodeDataChanged
                && !m_done.get())
            {
                m_es.submit(this);
            }
        }

        void internalProcessResults(int rc, String path, Object ctx, byte[] data, Stat stat) {
            Code code = Code.get(rc);
            if (code == Code.OK) {
                this.stat = Optional.of(stat);
                this.data = Optional.of(data != null ? data : EMPTY_ARRAY);
            } else if (code == Code.NONODE || code == Code.SESSIONEXPIRED) {
                
                KeeperException e = KeeperException.create(code);
                fault = Optional.of(new DistributerException(path + " went away", e));
            } else if (!m_done.get()) {
                fault = checkCode(code, "unable to read data in %s", path);
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetData(path);
        }

        public byte [] getData() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return data.get();
        }
    }

    
    class GetHostChannels extends GetData {
        Optional<DistributerException> fault = Optional.absent();
        Optional<NavigableSet<ChannelSpec>> nodespecs = Optional.absent();

        final String host;
        final Predicate<Map.Entry<ChannelSpec,String>> thisHost;

        public GetHostChannels(String path) {
            super(path);
            this.host = basename.apply(path);
            this.thisHost = hostValueIs(this.host, ChannelSpec.class);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }
                try {
                    nodespecs = Optional.of(asChannelSet(data));
                } catch (IllegalArgumentException|JSONException e) {
                    fault = Optional.of(
                            loggedDistributerException(e, "failed to parse json in %s", path)
                            );
                    return;
                }

                int [] sstamp = new int[]{0};
                AtomicInteger dstamp = m_hosts.getReference().get(host);
                if (dstamp == null) {
                    LOG.warn("(" + m_hostId + ") has no data stamp for "
                            + host + ", host registry contains: " + m_hosts.getReference()
                            );
                    dstamp = new AtomicInteger(0);
                }
                NavigableMap<ChannelSpec,String> prev = null;
                NavigableSet<ChannelSpec> oldspecs = null;
                ImmutableSortedMap.Builder<ChannelSpec,String> mbldr = null;

                do {
                    final int specversion = dstamp.get();
                    
                    if (specversion >= stat.getVersion()) {
                        return;
                    }
                    
                    if (!dstamp.compareAndSet(specversion, stat.getVersion())) {
                        return;
                    }

                    prev = m_specs.get(sstamp);
                    oldspecs = Maps.filterEntries(prev, thisHost).navigableKeySet();
                    
                    mbldr = ImmutableSortedMap.naturalOrder();
                    mbldr.putAll(Maps.filterEntries(prev, not(thisHost)));
                    for (ChannelSpec spec: nodespecs.get()) {
                        mbldr.put(spec, host);
                    }
                } while (!m_specs.compareAndSet(prev, mbldr.build(), sstamp[0], sstamp[0]+1));

                if (host.equals(m_hostId) && !m_done.get()) {
                    ChannelAssignment assignment = new ChannelAssignment(
                            oldspecs, nodespecs.get(), stat.getVersion()
                            );
                    if (assignment.hasChanges() && !m_assignq.offer(assignment)) {
                        fault = Optional.of(
                                loggedDistributerException(null, "failed to offer channel assignments")
                                );
                    }
                    if (!assignment.getRemoved().isEmpty()) {
                        LOG.info("(" + m_hostId + ") removing the following channel assingments: " + assignment.getRemoved());
                    }
                    if (!assignment.getAdded().isEmpty()) {
                        LOG.info("(" + m_hostId + ") adding the following channel assingments: " + assignment.getAdded());
                    }
                }
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetHostChannels(path);
        }

        NavigableSet<ChannelSpec> getSpecs() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return nodespecs.get();
        }
    }

    
    class GetChannels extends GetData {

        Optional<DistributerException> fault = Optional.absent();
        Optional<NavigableSet<ChannelSpec>> channels = Optional.absent();

        public GetChannels(String path) {
            super(path);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }
                try {
                    channels = Optional.of(asChannelSet(data));
                } catch (IllegalArgumentException|JSONException e) {
                    fault = Optional.of(
                            loggedDistributerException(e, "failed to parse json in %s", path)
                            );
                    return;
                }
                int [] stamp = new int[]{0};
                NavigableSet<ChannelSpec> oldspecs = m_channels.get(stamp);
                if (stamp[0] >= stat.getVersion()) {
                    return;
                }
                if (!m_channels.compareAndSet(oldspecs, channels.get(), stamp[0], stat.getVersion())) {
                    return;
                }
                LOG.info("(" + m_hostId + ") succesfully received channel assignment master copy");
                if (m_isLeader && !m_done.get()) {
                    m_es.submit(new AssignChannels());
                }
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetChannels(path);
        }

        NavigableSet<ChannelSpec> getChannels() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return channels.get();
        }
    }

    
    class MonitorHostNodes extends GetChildren {

        MonitorHostNodes(String path) {
            super(path);
        }

        @Override
        public void processResult(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, children, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }

                int [] hstamp = new int[]{0};
                NavigableMap<String,AtomicInteger> oldgen = m_hosts.get(hstamp);
                if (hstamp[0] >= stat.getCversion()) {
                    return;
                }

                final Set<String> added   = Sets.difference(this.children.get(), oldgen.navigableKeySet());
                final Set<String> removed = Sets.difference(oldgen.navigableKeySet(), this.children.get());

                ImmutableSortedMap.Builder<String,AtomicInteger> hbldr = ImmutableSortedMap.naturalOrder();
                hbldr.putAll(Maps.filterEntries(oldgen, not(hostKeyIn(removed, AtomicInteger.class))));
                for (String add: added) {
                    hbldr.put(add, new AtomicInteger(0));
                }
                NavigableMap<String,AtomicInteger> newgen = hbldr.build();

                if (!m_hosts.compareAndSet(oldgen, newgen, hstamp[0], stat.getCversion())) {
                    return;
                }

                if (!removed.isEmpty()) {
                    final Predicate<Map.Entry<ChannelSpec,String>> inRemoved =
                            hostValueIn(removed, ChannelSpec.class);

                    int [] sstamp = new int[]{0};
                    NavigableMap<ChannelSpec,String> prev = null;
                    NavigableMap<ChannelSpec,String> next = null;

                    do {
                        prev = m_specs.get(sstamp);
                        next = Maps.filterEntries(prev, not(inRemoved));
                    } while (!m_specs.compareAndSet(prev, next, sstamp[0], sstamp[0]+1));

                    LOG.info("(" + m_hostId + ") hosts " + removed + " no longer servicing importer channels");

                    if (m_isLeader && !m_done.get()) {
                        m_es.submit(new AssignChannels());
                    }
                }

                if (!added.isEmpty() && !m_done.get()) {
                    m_es.submit(new DistributerRunnable() {
                        @Override
                        public void susceptibleRun() throws Exception {
                            for (String host: added) {
                                LOG.info("(" + m_hostId + ") starting to monitor host node " + host);
                                new GetHostChannels(joinZKPath(HOST_DN, host));
                            }
                        }
                    });
                }
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new MonitorHostNodes(path);
        }
    }

    
    final static class HostsRef extends AtomicStampedReference<NavigableMap<String,AtomicInteger>> {
        static final NavigableMap<String,AtomicInteger> EMPTY_MAP = ImmutableSortedMap.of();

        public HostsRef(NavigableMap<String,AtomicInteger> initialRef, int initialStamp) {
            super(initialRef, initialStamp);
        }

        public HostsRef() {
            this(EMPTY_MAP, 0);
        }
    }

    
    final static class ChannelsRef extends AtomicStampedReference<NavigableSet<ChannelSpec>> {
        static final NavigableSet<ChannelSpec> EMPTY_SET = ImmutableSortedSet.of();

        public ChannelsRef(NavigableSet<ChannelSpec> initialRef, int initialStamp) {
            super(initialRef, initialStamp);
        }

        public ChannelsRef() {
            this(EMPTY_SET, 0);
        }
    }

    
    final static class SpecsRef extends AtomicStampedReference<NavigableMap<ChannelSpec,String>> {
        static final NavigableMap<ChannelSpec,String> EMPTY_MAP = ImmutableSortedMap.of();

        public SpecsRef(NavigableMap<ChannelSpec,String> initialRef, int initialStamp) {
            super(initialRef, initialStamp);
        }

        public SpecsRef() {
            this(EMPTY_MAP, 0);
        }
    }

    static <K> Predicate<Map.Entry<K, String>> hostValueIs(final String s, Class<K> clazz) {
        return new Predicate<Map.Entry<K,String>>() {
            @Override
            public boolean apply(Entry<K, String> e) {
                return s.equals(e.getValue());
            }
        };
    }

    static <K> Predicate<Map.Entry<K, String>> hostValueIn(final Set<String> s, Class<K> clazz) {
        return new Predicate<Map.Entry<K,String>>() {
            @Override
            public boolean apply(Entry<K, String> e) {
                return s.contains(e.getValue());
            }
        };
    }

    static <V> Predicate<Map.Entry<String,V>> hostKeyIn(final Set<String> s, Class<V> clazz) {
        return new Predicate<Map.Entry<String,V>>() {
            @Override
            public boolean apply(Entry<String,V> e) {
                return s.contains(e.getKey());
            }
        };
    }

    final static Function<String,String> basename = new Function<String, String>() {
        @Override
        public String apply(String path) {
            return new File(path).getName();
        }
    };
}

<code block>


package org.voltdb.importer;

import static com.google_voltpatches.common.base.Predicates.equalTo;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;

import java.net.URI;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.LinkedBlockingDeque;
import java.util.concurrent.TimeUnit;

import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.voltcore.zk.ZKTestBase;

import com.google_voltpatches.common.collect.FluentIterable;
import com.google_voltpatches.common.collect.ImmutableMap;
import com.google_voltpatches.common.collect.ImmutableSet;
import com.google_voltpatches.common.collect.Maps;
import com.google_voltpatches.common.collect.Sets;

public class TestChannelDistributer extends ZKTestBase {

    private final static String ZERO = "zero";
    private final static String UNO  = "uno";
    private final static String DUE  = "due";
    private final static String YO   = "yo";

    Map<String, ZooKeeper> zks;
    Map<String, ChannelDistributer> distributers;
    BlockingDeque<ChannelAssignment> queue;

    static Set<ChannelSpec> fromURIs(Set<URI> uris) {
        return FluentIterable.from(uris).transform(ChannelSpec.fromUri(YO)).toSet();
    }

    static Set<URI> generateURIs(int count) {
        ImmutableSet.Builder<URI> sbldr = ImmutableSet.builder();
        for (int i=0; i < count; ++i) {
            sbldr.add(URI.create(String.format("x-import:
        }
        return sbldr.build();
    }

    Set<ChannelSpec> getRemoved(int expected) throws Exception {
        int received = 0;
        ImmutableSet.Builder<ChannelSpec> sbldr = ImmutableSet.builder();
        ChannelAssignment assignment = null;
        while (received < expected && (assignment=queue.poll(200,TimeUnit.MILLISECONDS)) != null) {
            received += assignment.getRemoved().size();
            sbldr.addAll(assignment.getRemoved());
        }
        assertEquals("failed to poll the expected number of removed", expected, received);
        assertTrue(queue.isEmpty());
        return sbldr.build();
    }

    Set<ChannelSpec> getAdded(int expected) throws Exception {
        int received = 0;
        ImmutableSet.Builder<ChannelSpec> sbldr = ImmutableSet.builder();
        ChannelAssignment assignment = null;
        while (received < expected && (assignment=queue.poll(200,TimeUnit.MILLISECONDS)) != null) {
            received += assignment.getAdded().size();
            sbldr.addAll(assignment.getAdded());
        }
        assertEquals("failed to poll the expected number of removed", expected, received);
        assertTrue(queue.isEmpty());
        return sbldr.build();
    }

    @Before
    public void setup() throws Exception {
        setUpZK(3);
        queue = new LinkedBlockingDeque<>();
        zks = ImmutableMap.<String, ZooKeeper>builder()
                .put(ZERO, getClient(0))
                .put(UNO,  getClient(1))
                .put(DUE,  getClient(2))
                .build();
        distributers = ImmutableMap.<String, ChannelDistributer>builder()
                .put(ZERO, new ChannelDistributer(zks.get(ZERO), ZERO, queue))
                .put(UNO,  new ChannelDistributer(zks.get(UNO), UNO, queue))
                .put(DUE,  new ChannelDistributer(zks.get(DUE), DUE, queue))
                .build();
    }

    @Test
    public void testRegistration() throws Exception {
        Set<URI> uris = generateURIs(9);
        Set<ChannelSpec> expected = fromURIs(uris);
        
        distributers.get(UNO).registerChannels(YO, uris);
        Set<ChannelSpec> actual = getAdded(9);

        assertEquals(expected, actual);

        Set<URI> pruned = generateURIs(6);
        expected = Sets.difference(fromURIs(uris), fromURIs(pruned));
        
        distributers.get(DUE).registerChannels(YO, pruned);
        actual = getRemoved(3);

        assertEquals(expected, actual);
        
        distributers.get(ZERO).registerChannels(YO, pruned);
        assertNull(queue.poll(200,TimeUnit.MILLISECONDS));

        uris = generateURIs(8);
        expected = Sets.difference(fromURIs(uris), fromURIs(pruned));
        
        distributers.get(UNO).registerChannels(YO, uris);
        actual = getAdded(2);

        assertEquals(expected, actual);

        expected = fromURIs(uris);
        
        distributers.get(UNO).registerChannels(YO, ImmutableSet.<URI>of());
        actual = getRemoved(8);

        assertEquals(expected, actual);

        int leaderCount = 0;
        for (ChannelDistributer distributer: distributers.values()) {
            if (distributer.m_isLeader) {
                ++leaderCount;
            }
        }
        assertEquals(1, leaderCount);
    }

    @Test
    public void testHostFailure() throws Exception {
        Set<URI> uris = generateURIs(9);
        Set<ChannelSpec> expected = fromURIs(uris);
        
        distributers.get(UNO).registerChannels(YO, uris);
        Set<ChannelSpec> actual = getAdded(9);

        assertEquals(expected, actual);

        
        int attempts = 4;
        boolean settled = false;
        while (!settled && --attempts >=0) {
            Thread.sleep(50);
            settled = true;
            int stamp = distributers.get(ZERO).m_specs.getStamp();
            for (ChannelDistributer distributer: distributers.values()) {
                settled = settled && stamp == distributer.m_specs.getStamp();
            }
        }
        assertTrue(settled);

        Set<ChannelSpec> inZERO = Maps.filterValues(
                distributers.get(DUE).m_specs.getReference(),
                equalTo(ZERO))
                .navigableKeySet();
        assertTrue(inZERO.size() > 0);

        zks.get(ZERO).close();

        actual = getAdded(inZERO.size());
        assertEquals(inZERO, actual);
    }

    @After
    public void tearDown() throws Exception {
        for (ChannelDistributer distributer: distributers.values()) {
            distributer.shutdown();
        }
        tearDownZK();
    }
}

<code block>

package org.voltdb.importclient;

import java.util.Arrays;
import java.util.IllegalFormatConversionException;
import java.util.MissingFormatArgumentException;
import java.util.UnknownFormatConversionException;

public class ImportBaseException extends RuntimeException
{
    private static final long serialVersionUID = -2562766985614166710L;

    public ImportBaseException() {
    }

    public ImportBaseException(String format, Object...args) {
        super(format(format, args));
    }

    public ImportBaseException(Throwable cause) {
        super(cause);
    }

    public ImportBaseException(String format, Throwable cause, Object...args) {
        super(format(format, args), cause);
    }

    static protected String format(String format, Object...args) {
        String formatted = null;
        try {
            formatted = String.format(format, args);
        } catch (MissingFormatArgumentException|IllegalFormatConversionException|
                UnknownFormatConversionException ignoreThem) {
        }
        finally {
            if (formatted == null) {
                formatted = "Format: " + format + ", arguments: " + Arrays.toString(args);
            }
        }
        return formatted;
    }
}

<code block>

package org.voltdb.importclient.kafka;

import org.voltdb.importclient.ImportBaseException;

public class KafkaStreamImporterException extends ImportBaseException
{
    private static final long serialVersionUID = 7668280657393399984L;

    public KafkaStreamImporterException() {
    }

    public KafkaStreamImporterException(String format, Object... args) {
        super(format, args);
    }

    public KafkaStreamImporterException(Throwable cause) {
        super(cause);
    }

    public KafkaStreamImporterException(String format, Throwable cause,
            Object... args) {
        super(format, cause, args);
    }
}



<code block>

package org.voltdb.importclient.kafka;

import static java.util.Collections.singletonList;
import static java.util.Collections.singletonMap;

import java.io.IOException;
import java.net.URI;
import java.nio.ByteBuffer;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.SortedSet;
import java.util.TreeSet;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;
import java.util.regex.Pattern;

import kafka.api.ConsumerMetadataRequest;
import kafka.api.FetchRequest;
import kafka.api.FetchRequestBuilder;
import kafka.api.PartitionOffsetRequestInfo;
import kafka.cluster.Broker;
import kafka.common.ErrorMapping;
import kafka.common.OffsetAndMetadata;
import kafka.common.TopicAndPartition;
import kafka.javaapi.ConsumerMetadataResponse;
import kafka.javaapi.FetchResponse;
import kafka.javaapi.OffsetCommitRequest;
import kafka.javaapi.OffsetCommitResponse;
import kafka.javaapi.OffsetFetchRequest;
import kafka.javaapi.OffsetFetchResponse;
import kafka.javaapi.OffsetResponse;
import kafka.javaapi.PartitionMetadata;
import kafka.javaapi.TopicMetadata;
import kafka.javaapi.TopicMetadataRequest;
import kafka.javaapi.consumer.SimpleConsumer;
import kafka.message.MessageAndOffset;
import kafka.network.BlockingChannel;

import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltdb.VoltDB;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureCallback;
import org.voltdb.importclient.ImportBaseException;
import org.voltdb.importer.CSVInvocation;
import org.voltdb.importer.ImportHandlerProxy;
import org.voltdb.importer.ImporterChannelAssignment;
import org.voltdb.importer.VersionedOperationMode;


public class KafkaStreamImporter extends ImportHandlerProxy implements BundleActivator {

    private final static PartitionOffsetRequestInfo LATEST_OFFSET =
            new PartitionOffsetRequestInfo(kafka.api.OffsetRequest.LatestTime(), 1);
    private final static PartitionOffsetRequestInfo EARLIEST_OFFSET =
            new PartitionOffsetRequestInfo(kafka.api.OffsetRequest.EarliestTime(), 1);

    
    private Properties m_properties;
    
    private String m_groupId;
    
    private String m_procedure;
    
    private int m_backpressureSleepMs = 200;

    
    private List<String> m_topicList;
    
    private final List<HostAndPort> m_brokerList = new ArrayList<HostAndPort>();
    
    private int m_fetchSize = (2*1024*1024);
    private int m_consumerSocketTimeout = 30000; 

    private static final String GROUP_ID = "voltdb";
    private static final String CLIENT_ID = "voltdb-importer";
    private static final int KAFKA_DEFAULT_BROKER_PORT = 9092;
    
    private final Semaphore m_done = new Semaphore(0);
    private boolean m_stopping = false;

    
    private final Map<String, List<TopicMetadata>> m_topicPartitionMetaData = new HashMap<String, List<TopicMetadata>>();
    
    private final Map<String, List<Integer>> m_topicPartitions = new HashMap<String, List<Integer>>();
    
    private final Map<String, HostAndPort> m_topicPartitionLeader = new HashMap<String, HostAndPort>();
    private final Map<String, TopicPartitionFetcher> m_fetchers = new HashMap<String, TopicPartitionFetcher>();

    private ExecutorService m_es = null;

    private static final Pattern legalTopicNamesPattern = Pattern.compile("[a-zA-Z0-9\\._\\-]+");
    private static final int topicMaxNameLength = 255;

    
    public static class HostAndPort {

        private final String m_host;
        private final int m_port;
        private final String m_connectionString;

        public HostAndPort(String h, int p) {
            m_host = h;
            m_port = p;
            m_connectionString = m_host + ":" + m_port;
        }

        public static HostAndPort fromString(String hap) {
            String s[] = hap.split(":");
            int p = KAFKA_DEFAULT_BROKER_PORT;
            if (s.length > 1 && s[1] != null && s[1].length() > 0) {
                p = Integer.parseInt(s[1].trim());
            }
            return new HostAndPort(s[0].trim(), p);
        }

        public String getHost() {
            return m_host;
        }

        public int getPort() {
            return m_port;
        }

        @Override
        public String toString() {
            return m_host + ":" + m_port;
        }

        @Override
        public int hashCode() {
            return m_connectionString.hashCode();
        }

        @Override
        public boolean equals(Object o) {
            if (!(o instanceof HostAndPort)) {
                return false;
            }
            if (this.getClass() != o.getClass()) {
                return false;
            }
            HostAndPort hap = (HostAndPort )o;
            if (hap == this) {
                return true;
            }
            return (hap.getHost().equals(getHost()) && hap.getPort() == getPort());
        }
    }

    
    @Override
    public void start(BundleContext context) throws Exception {
        context.registerService(this.getClass().getName(), this, null);
    }

    @Override
    public void stop(BundleContext context) throws Exception {
        
    }

    @Override
    public boolean isRunEveryWhere() {
        
        return false;
    }

    
    private Set<URI> buildTopicLeaderMetadata(SimpleConsumer consumer) {

        
        Set<URI> availableResources = new TreeSet<URI>();
        for (String topic : m_topicList) {
            TopicMetadataRequest req = new TopicMetadataRequest(singletonList(topic));
            kafka.javaapi.TopicMetadataResponse resp = null;
            try {
                resp = consumer.send(req);
            } catch (Exception ex) {
                
                error(ex, "Failed to send topic metadata request for topic " + topic);
                continue;
            }

            List<TopicMetadata> metaData = resp.topicsMetadata();
            if (metaData == null) {
                
                error("Failed to get topic metadata for topic " + topic);
                continue;
            }
            m_topicPartitionMetaData.put(topic, metaData);
            List<Integer> partitions = m_topicPartitions.get(topic);
            if (partitions == null) {
                partitions = new ArrayList<Integer>();
                m_topicPartitions.put(topic, partitions);
            }
            for (TopicMetadata item : metaData) {
                for (PartitionMetadata part : item.partitionsMetadata()) {
                    partitions.add(part.partitionId());
                    URI uri = URI.create("kafka:/" + topic + "/partition/" + part.partitionId());
                    availableResources.add(uri);
                    String leaderKey = topic + "-" + part.partitionId();
                    Broker leader = part.leader();
                    m_topicPartitionLeader.put(leaderKey, new HostAndPort(leader.host(), leader.port()));
                }
            }
        }

        info("Available Channels are: " + availableResources);
        
        m_es = Executors.newFixedThreadPool(availableResources.size() + 1,
                getThreadFactory("KafkaImporter", "KafkaImporterTopicFetcher", ImportHandlerProxy.MEDIUM_STACK_SIZE));
        return availableResources;
    }

    @Override
    public Set<URI> getAllResponsibleResources() {
        SimpleConsumer simpleConsumer = null;
        Set<URI> availableResources = new TreeSet<URI>();
        try {
            simpleConsumer = new SimpleConsumer(m_brokerList.get(0).getHost(), m_brokerList.get(0).getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID);
            
            availableResources = buildTopicLeaderMetadata(simpleConsumer);
        } catch (Exception ex) {
            VoltDB.crashLocalVoltDB("Failed to get available resources for kafka importer", true, ex);
        } finally {
            closeConsumer(simpleConsumer);
        }
        return availableResources;
    }

    @Override
    public void stop() {
        m_stopping = true;
        
        for (TopicPartitionFetcher fetcher : m_fetchers.values()) {
            fetcher.shutdown();
        }
        if (m_es != null) {
            
            m_es.shutdown();
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException ex) {
                
                ex.printStackTrace();
            }
        }
        m_fetchers.clear();
        m_done.release();
    }

    
    @Override
    public String getName() {
        return "KafkaImporter82";
    }

    
    @Override
    public void configure(Properties p) {
        m_properties = (Properties) p.clone();
        m_procedure = m_properties.getProperty("procedure", "").trim();
        if (m_procedure.isEmpty()) {
            throw new RuntimeException("Missing procedure.");
        }
        
        String topics = m_properties.getProperty("topics", "").trim();
        if (topics.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
        m_topicList = Arrays.asList(topics.split("\\s*,\\s*"));
        if (m_topicList == null || m_topicList.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
        for (String topic : m_topicList) {
            if (topic.contains("..") || topic.contains(".")) {
                throw new RuntimeException("topic name cannot be \".\" or \"..\"");
            }
            if (topic.length() > topicMaxNameLength) {
                throw new RuntimeException("topic name is illegal, can't be longer than "
                        + topicMaxNameLength + " characters");
            }
            if (!legalTopicNamesPattern.matcher(topic).matches()) {
                throw new RuntimeException("topic name " + topic + " is illegal, contains a character other than ASCII alphanumerics, '.', '_' and '-'");
            }
        }

       String brokers = m_properties.getProperty("brokers", "").trim();
        if (brokers.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        List<String> brokerList = Arrays.asList(brokers.split("\\s*,\\s*"));
        if (brokerList == null || brokerList.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        for (String broker : brokerList) {
            HostAndPort hap = HostAndPort.fromString(broker);
            m_brokerList.add(hap);
        }
        if (m_brokerList.isEmpty()) {
            throw new RuntimeException("Missing or misconfigured kafka broker list. See brokers property");
        }
        m_groupId = m_properties.getProperty("groupid", GROUP_ID).trim();
        
        m_fetchSize = Integer.parseInt(m_properties.getProperty("fetch.message.max.bytes", "65536"));
        m_consumerSocketTimeout = Integer.parseInt(m_properties.getProperty("socket.timeout.ms", "30000"));
        m_backpressureSleepMs = Integer.parseInt(m_properties.getProperty("backpressure.sleep.ms", "50"));
    }

    
    private class TopicPartitionFetcher implements Runnable {

        
        private final URI m_url;
        
        private HostAndPort m_leader;
        
        private HostAndPort m_coordinator;
        private boolean m_shutdown = false;
        private volatile boolean m_hasBackPressure = false;
        private final int m_fetchSize;
        
        private final List<HostAndPort> m_brokers;
        private final int m_consumerSocketTimeout;
        
        private final AtomicLong m_currentOffset = new AtomicLong(-1);
        private final SortedSet<Long> m_pendingOffsets = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final SortedSet<Long> m_seenOffset = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final AtomicReference<SimpleConsumer> m_offsetManager = new AtomicReference<SimpleConsumer>();
        private SimpleConsumer m_consumer = null;
        private final TopicAndPartition m_topicAndPartition;

        public TopicPartitionFetcher(List<HostAndPort> brokers, URI uri, String topic, int partition, HostAndPort leader, int fetchSize, int consumerSocketTimeout) {
            m_url = uri;
            m_brokers = brokers;
            m_leader = leader;
            m_coordinator = leader;
            m_fetchSize = fetchSize;
            m_consumerSocketTimeout = consumerSocketTimeout;
            m_topicAndPartition = new TopicAndPartition(topic, partition);
        }

        public final URI getUrl() {
            return m_url;
        }

        public void hasBackPressure(boolean flag) {
            m_hasBackPressure = flag;
        }

        
        private PartitionMetadata findLeader() {
            PartitionMetadata returnMetaData = null;
            loop:
            for (HostAndPort broker : m_brokers) {
                SimpleConsumer consumer = null;
                try {
                    consumer = new SimpleConsumer(broker.getHost(), broker.getPort(), m_consumerSocketTimeout, m_fetchSize, "findLeader");

                    List<String> topics = singletonList(m_topicAndPartition.topic());
                    TopicMetadataRequest req = new TopicMetadataRequest(topics);
                    kafka.javaapi.TopicMetadataResponse resp = consumer.send(req);

                    List<TopicMetadata> metaData = resp.topicsMetadata();
                    for (TopicMetadata item : metaData) {
                        for (PartitionMetadata part : item.partitionsMetadata()) {
                            if (part.partitionId() == m_topicAndPartition.partition()) {
                                returnMetaData = part;
                                break loop;
                            }
                        }
                    }
                } catch (Exception e) {
                    error(e, "Error in finding leader for %s", m_topicAndPartition);
                } finally {
                    closeConsumer(consumer);
                }
            }
            if (returnMetaData == null) {
                error(null, "Failed to find Leader for %s", m_topicAndPartition);
            }
            return returnMetaData;
        }

        
        private HostAndPort findNewLeader() {
            for (int i = 0; i < 3; i++) {
                boolean shouldSleep = false;
                PartitionMetadata metadata = findLeader();
                if (metadata == null) {
                    shouldSleep = true;
                } else if (metadata.leader() == null) {
                    shouldSleep = true;
                } else if (m_leader.getHost().equalsIgnoreCase(metadata.leader().host()) && i == 0) {
                    
                    
                    shouldSleep = true;
                } else {
                    return new HostAndPort(metadata.leader().host(), metadata.leader().port());
                }
                if (shouldSleep) {
                    backoffSleep(i+1);
                }
            }
            
            error(null, "Failed to find new leader for %s", m_topicAndPartition);
            return null;
        }

        
        public void shutdown() {
            m_shutdown = true;
        }

        public void getOffsetCoordinator() {
            KafkaStreamImporterException probeException = null;
            int correlationId = 0;

            for (int attempts = 0; attempts < 3; ++attempts) {
                for (HostAndPort hp: m_brokerList) {
                    BlockingChannel channel = null;
                    try {
                        channel = new BlockingChannel(hp.getHost(), hp.getPort(),
                                BlockingChannel.UseDefaultBufferSize(), BlockingChannel.UseDefaultBufferSize(), m_consumerSocketTimeout);
                        channel.connect();
                        channel.send(new ConsumerMetadataRequest(m_groupId, ConsumerMetadataRequest.CurrentVersion(), correlationId++, CLIENT_ID));
                        ConsumerMetadataResponse metadataResponse = ConsumerMetadataResponse.readFrom(channel.receive().buffer());
                        if (metadataResponse.errorCode() == ErrorMapping.NoError()) {
                            Broker offsetManager = metadataResponse.coordinator();
                            m_coordinator = new HostAndPort(offsetManager.host(), offsetManager.port());
                            SimpleConsumer consumer = m_offsetManager.getAndSet(
                                    new SimpleConsumer(
                                            m_coordinator.getHost(),
                                            m_coordinator.getPort(),
                                            m_consumerSocketTimeout,
                                            m_fetchSize, CLIENT_ID
                                            ));
                            info("Offset Coordinator for " + m_topicAndPartition + " is " + offsetManager);
                            closeConsumer(consumer);
                            probeException = null;
                            consumer = null;
                            break;
                        }
                        probeException = new KafkaStreamImporterException("Failed to get Offset Coordinator for %s",
                                ErrorMapping.exceptionFor(metadataResponse.errorCode()), m_topicAndPartition
                                );
                    } catch (Exception e) {
                        probeException = new KafkaStreamImporterException(
                                "Failed to get Offset Coordinator for %s", e, m_topicAndPartition
                                );
                    } finally {
                        if (channel != null) {
                            channel.disconnect();
                        }
                    }
                }
                if (probeException != null) {
                    error(probeException, "Failed to query all brokers for the offeset coordinator for " + m_topicAndPartition);
                }
                backoffSleep(attempts+1);
            }
        }

        private OffsetResponse getTopicOffset(PartitionOffsetRequestInfo pori) {
            final int partition = m_topicAndPartition.partition();
            final String topic = m_topicAndPartition.topic();

            kafka.javaapi.OffsetRequest earlyRq = new kafka.javaapi.OffsetRequest(
                    singletonMap(m_topicAndPartition, pori),
                    kafka.api.OffsetRequest.CurrentVersion(), CLIENT_ID
                    );
            OffsetResponse response = null;
            Throwable fault = null;

            for (int attempts = 0; attempts < 3; ++attempts) try {
                response = m_consumer.getOffsetsBefore(earlyRq);
                if (response.hasError()) {
                    short code = response.errorCode(topic, partition);
                    fault = ErrorMapping.exceptionFor(code);
                    resetLeader();
                } else {
                    return response;
                }
            } catch (Exception e) {
                if (e instanceof IOException) {
                    resetLeader();
                }
                fault = e;
            }
            if (fault != null) {
                error(fault, "unable to fetch earliest offset for " + m_topicAndPartition);
                response = null;
            }
            return response;
        }

        private OffsetFetchResponse getClientTopicOffset() {
            final short version = 1;
            final OffsetFetchRequest rq = new OffsetFetchRequest(
                    m_groupId, singletonList(m_topicAndPartition), version, 1, CLIENT_ID
                    );
            OffsetFetchResponse rsp = null;
            Throwable fault = null;

            for (int attempts = 0; attempts < 3; ++attempts) try {
                rsp = m_offsetManager.get().fetchOffsets(rq);
                short code = rsp.offsets().get(m_topicAndPartition).error();
                if (code != ErrorMapping.NoError()) {
                    fault = ErrorMapping.exceptionFor(code);
                    if (code == ErrorMapping.NotCoordinatorForConsumerCode()) {
                        getOffsetCoordinator();
                    } else if (code == ErrorMapping.UnknownTopicOrPartitionCode()) {
                        fault = null;
                        break;
                    }
                } else {
                    fault = null;
                    break;
                }
            } catch (Exception e) {
                if (e instanceof IOException) {
                    getOffsetCoordinator();
                }
                fault = e;
            }
            if (fault != null) {
                error(fault, "unable to fetch earliest offset for " + m_topicAndPartition);
                rsp = null;
            }
            return rsp;
        }

        public long getLastOffset() {

            final int partition = m_topicAndPartition.partition();
            final String topic = m_topicAndPartition.topic();

            OffsetResponse response = getTopicOffset(EARLIEST_OFFSET);
            if (response == null) return -1L;

            long earliest = response.offsets(topic, partition)[0];

            response = getTopicOffset(LATEST_OFFSET);
            if (response == null) return -1L;

            long latest = response.offsets(topic, partition)[0];
            if (latest == earliest) return latest;

            OffsetFetchResponse ofr = getClientTopicOffset();
            if (ofr == null) return earliest;

            long current = ofr.offsets().get(m_topicAndPartition).offset();
            if (current < earliest) return earliest;

            if (current < latest) return current;

            return latest;
        }

        
        private class TopicPartitionInvocationCallback implements ProcedureCallback {

            private final long m_offset;
            private final long m_nextOffset;
            private final AtomicLong m_cbcnt;

            public TopicPartitionInvocationCallback(long offset, long noffset, AtomicLong cbcnt) {
                m_offset = offset;
                m_nextOffset = noffset;
                m_cbcnt = cbcnt;
            }

            @Override
            public void clientCallback(ClientResponse response) throws Exception {
                
                assert(!m_pendingOffsets.isEmpty());
                m_cbcnt.incrementAndGet();
                m_pendingOffsets.remove(m_offset);
                
                m_seenOffset.add(m_nextOffset);
            }

        }

        
        private int backoffSleep(int fetchFailedCount) {
            try {
                Thread.sleep(1000 * fetchFailedCount++);
                if (fetchFailedCount > 10) fetchFailedCount = 1;
            } catch (InterruptedException ie) {
            }
            return fetchFailedCount;
        }

        private void resetLeader() {
            HostAndPort leaderBroker = m_leader;

            closeConsumer(m_consumer);
            m_consumer = null;
            leaderBroker = findNewLeader();
            if (leaderBroker == null) {
                
                error(null, "Fetch Failed to find leader continue with old leader: %s", m_leader);
                leaderBroker = m_leader;
            } else {
                if (!leaderBroker.equals(m_leader)) {
                    info("Fetch Found new leader for " + m_topicAndPartition + " New Leader: " + leaderBroker);
                    m_leader = leaderBroker;
                }
            }
            m_consumer = new SimpleConsumer(
                    leaderBroker.getHost(), leaderBroker.getPort(),
                    m_consumerSocketTimeout, m_fetchSize, CLIENT_ID
                    );
        }

        @Override
        public void run() {
            info("Starting partition fetcher for " + m_topicAndPartition);
            long submitCount = 0;
            AtomicLong cbcnt = new AtomicLong(0);
            try {
                
                resetLeader();

                int sleepCounter = 1;
                while (!m_shutdown) {
                    
                    if (m_currentOffset.get() < 0) {
                        getOffsetCoordinator();
                        long lastOffset = getLastOffset();
                        m_currentOffset.set(lastOffset);
                        if (m_currentOffset.get() < 0) {
                            sleepCounter = backoffSleep(sleepCounter);
                            info("Latest offset not found for " + m_topicAndPartition + " using earliest offset.");
                            
                            
                            continue;
                        }
                    }
                    long currentFetchCount = 0;
                    
                    FetchRequest req = new FetchRequestBuilder().clientId(CLIENT_ID)
                            .addFetch(m_topicAndPartition.topic(),
                                    m_topicAndPartition.partition(), m_currentOffset.get(), m_fetchSize)
                            .build();
                    FetchResponse fetchResponse = null;
                    try {
                        fetchResponse = m_consumer.fetch(req);
                        if (fetchResponse == null) {
                            sleepCounter = backoffSleep(sleepCounter);
                            continue;
                        }
                    } catch (Exception ex) {
                        error(ex, "Failed to fetch from %s", m_topicAndPartition);
                        
                        if (ex instanceof IOException) {
                            resetLeader();
                            
                            continue;
                        }
                        sleepCounter = backoffSleep(sleepCounter);
                        continue;
                    }

                    if (fetchResponse.hasError()) {
                        
                        short code = fetchResponse.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                        warn(ErrorMapping.exceptionFor(code), "Failed to fetch messages for %s", m_topicAndPartition);
                        sleepCounter = backoffSleep(sleepCounter);
                        if (code == ErrorMapping.OffsetOutOfRangeCode()) {
                            
                            info("Invalid offset requested for " + m_topicAndPartition);
                            getOffsetCoordinator();
                            m_currentOffset.set(-1L);
                            continue;
                        }
                        resetLeader();
                        continue;
                    }
                    sleepCounter = 1;
                    for (MessageAndOffset messageAndOffset : fetchResponse.messageSet(m_topicAndPartition.topic(), m_topicAndPartition.partition())) {
                        
                        currentFetchCount++;
                        long currentOffset = messageAndOffset.offset();
                        
                        if (currentOffset < m_currentOffset.get()) {
                            continue;
                        }
                        ByteBuffer payload = messageAndOffset.message().payload();

                        String line = new String(payload.array(),payload.arrayOffset(),payload.limit(),StandardCharsets.UTF_8);
                        CSVInvocation invocation = new CSVInvocation(m_procedure, line);
                        TopicPartitionInvocationCallback cb = new TopicPartitionInvocationCallback(currentOffset, messageAndOffset.nextOffset(), cbcnt);
                        m_pendingOffsets.add(currentOffset);
                        if (!callProcedure(cb, invocation)) {
                            if (isDebugEnabled()) {
                                debug("Failed to process Invocation possibly bad data: " + line);
                            }
                            synchronized(m_seenOffset) {
                                
                                m_seenOffset.add(messageAndOffset.nextOffset());
                            }
                            m_pendingOffsets.remove(currentOffset);
                        }
                        submitCount++;
                        m_currentOffset.set(messageAndOffset.nextOffset());
                        if (m_shutdown) {
                            break;
                        }
                    }
                    if (m_shutdown) {
                        break;
                    }

                    
                    if (currentFetchCount == 0 || m_hasBackPressure) {
                        try {
                            Thread.sleep(m_backpressureSleepMs);
                        } catch (InterruptedException ie) {
                        }
                    }
                    commitOffset();
                }
                
                info("Partition fecher stopped for " + m_topicAndPartition
                        + " Last commit point is: " + m_currentOffset.get()
                        + " Callback Rcvd: " + cbcnt.get()
                        + " Submitted: " + submitCount);
            } catch (Exception ex) {
                error("Failed to start topic partition fetcher for " + m_topicAndPartition, ex);
            } finally {
                commitOffset();
                closeConsumer(m_consumer);
                m_consumer = null;
                closeConsumer(m_offsetManager.getAndSet(null));
            }
        }

        public boolean commitOffset() {

            if (m_seenOffset.isEmpty())
                return false;
            long offset = m_seenOffset.last();
            final int correlationId = m_topicAndPartition.partition();
            final short version = 1;

            OffsetAndMetadata offsetMetdata = new OffsetAndMetadata(offset, "commitRequest", ErrorMapping.NoError());
            Map<TopicAndPartition, OffsetAndMetadata> reqMap = new HashMap<TopicAndPartition, OffsetAndMetadata>();
            reqMap.put(m_topicAndPartition, offsetMetdata);
            OffsetCommitRequest offsetCommitRequest = new OffsetCommitRequest(m_groupId, reqMap, correlationId, CLIENT_ID, version);
            OffsetCommitResponse offsetCommitResponse = null;
            try {
                SimpleConsumer consumer = m_offsetManager.get();
                if (consumer == null) {
                    getOffsetCoordinator();
                    consumer = m_offsetManager.get();
                }
                if (consumer != null) {
                    offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                    final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
                    if (code == ErrorMapping.NotCoordinatorForConsumerCode()) {
                        info("Not coordinator for committing offset for " + m_topicAndPartition + " Updating coordinator.");
                        getOffsetCoordinator();
                        consumer = m_offsetManager.get();
                        if (consumer != null) {
                            offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                        }
                    }
                    if ((Short)offsetCommitResponse.errors().get(m_topicAndPartition) == ErrorMapping.NoError()){
                        info("[STEBUG] " + "Committed offset " + offset + " for " + m_topicAndPartition);
                    }
                } else {
                    error("Commit Offset Failed to get offset coordinator for " + m_topicAndPartition);
                    return false;
                }
            } catch (Exception e) {
                error(e, "Failed to commit Offset for " + m_topicAndPartition);
                return false;
            }
            final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
            if (code != ErrorMapping.NoError()) {
                final String msg = "Commit Offset Failed to commit for " + m_topicAndPartition + " Code: %d";
                error(null, msg, code);
                return false;
            }
            synchronized(m_seenOffset) {
                m_seenOffset.clear();
            }
            return true;
        }

    }

    public void closeConsumer(SimpleConsumer consumer) {
        try {
            if (consumer != null) {
                consumer.close();
            }
        } catch (Exception e) {
            error("Failed to close consumer connection.", e);
        }
    }

    @Override
    public void hasBackPressure(boolean flag) {
        if (m_stopping) return;
        for (TopicPartitionFetcher fetcher : m_fetchers.values()) {
            fetcher.hasBackPressure(flag);
        }
    }

    
    @Override
    public void onChange(ImporterChannelAssignment assignment) {
        if (m_stopping) {
            info("Importer is stopping, ignoring the change notification.");
            return;
        }
        if (m_es == null) {
            
            VoltDB.crashLocalVoltDB("buildTopicLeaderMetadata must be called before getting an onChange", false, null);
        }

        
        for (URI nuri : assignment.getAdded()) {
            Map<String, List<Integer>> topicMap = new HashMap<String, List<Integer>>();
            for (String topic : m_topicList) {
                topicMap.put(topic, singletonList(0));
            }
            for (String topic : m_topicList) {
                List<Integer> topicPartitions = m_topicPartitions.get(topic);
                if (topicPartitions == null) {
                    
                    VoltDB.crashLocalVoltDB("Unknown kafka topic added for this node", false, null);
                }
                for (int partition : topicPartitions) {
                    String leaderKey = topic + "-" + partition;
                    URI assignedKey = URI.create("kafka:/" + topic + "/partition/" + partition);
                    
                    if (!m_fetchers.containsKey(nuri.toString()) && nuri.equals(assignedKey)) {
                        info("Channel " + assignedKey + " mastership is assigned to this node.");
                        HostAndPort hap = m_topicPartitionLeader.get(leaderKey);
                        TopicPartitionFetcher fetcher = new TopicPartitionFetcher(m_brokerList, assignedKey, topic, partition,
                                hap, m_fetchSize, m_consumerSocketTimeout);
                        m_fetchers.put(assignedKey.toString(), fetcher);
                        m_es.submit(fetcher);
                        info("KafkaImporter is fetching for resource: " + nuri);
                    }
                }
            }
        }

        
        for (URI r : assignment.getRemoved()) {
            TopicPartitionFetcher fetcher = m_fetchers.get(r.toString());
            if (fetcher != null) {
                fetcher.shutdown();
                info("KafkaImporter is NOT fetching for resource: " + r);
                m_fetchers.remove(r.toString());
            }
        }
    }

    
    @Override
    public void onClusterStateChange(VersionedOperationMode mode) {
        info("cluster state change notification: " + mode);
    }

    
    @Override
    public void readyForData() {
        try {
            info("Configured and ready with properties: " + m_properties);
            
            m_done.acquire();
        } catch (Exception ex) {
            error("Kafka Importer finished with exeception ", ex);
        }
    }

    public class KafkaStreamImporterException extends ImportBaseException
    {
        private static final long serialVersionUID = 7668280657393399984L;

        public KafkaStreamImporterException() {
        }

        public KafkaStreamImporterException(String format, Object... args) {
            super(format, args);
        }

        public KafkaStreamImporterException(Throwable cause) {
            super(cause);
        }

        public KafkaStreamImporterException(String format, Throwable cause,
                Object... args) {
            super(format, cause, args);
        }

    }

}

<code block>

package org.voltdb.importclient.kafka;

import java.net.URI;
import java.nio.ByteBuffer;
import java.nio.channels.ClosedChannelException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.SortedSet;
import java.util.TreeSet;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;
import java.util.regex.Pattern;

import kafka.api.ConsumerMetadataRequest;
import kafka.api.FetchRequest;
import kafka.api.FetchRequestBuilder;
import kafka.api.PartitionOffsetRequestInfo;
import kafka.cluster.Broker;
import kafka.common.ErrorMapping;
import kafka.common.OffsetAndMetadata;
import kafka.common.TopicAndPartition;
import kafka.javaapi.ConsumerMetadataResponse;
import kafka.javaapi.FetchResponse;
import kafka.javaapi.OffsetCommitRequest;
import kafka.javaapi.OffsetCommitResponse;
import kafka.javaapi.OffsetResponse;
import kafka.javaapi.PartitionMetadata;
import kafka.javaapi.TopicMetadata;
import kafka.javaapi.TopicMetadataRequest;
import kafka.javaapi.consumer.SimpleConsumer;
import kafka.message.MessageAndOffset;
import kafka.network.BlockingChannel;

import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltdb.VoltDB;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureCallback;
import org.voltdb.importer.CSVInvocation;
import org.voltdb.importer.ImportHandlerProxy;
import org.voltdb.importer.ImporterChannelAssignment;
import org.voltdb.importer.VersionedOperationMode;


public class KafkaStreamImporter extends ImportHandlerProxy implements BundleActivator {

    
    private Properties m_properties;
    
    private String m_groupId;
    
    private String m_procedure;
    
    private int m_backpressureSleepMs = 200;

    
    private List<String> m_topicList;
    
    private final List<HostAndPort> m_brokerList = new ArrayList<HostAndPort>();
    
    private int m_fetchSize = (2*1024*1024);
    private int m_consumerSocketTimeout = 30000; 

    private static final String GROUP_ID = "voltdb";
    private static final String CLIENT_ID = "voltdb-importer";
    private static final int KAFKA_DEFAULT_BROKER_PORT = 9092;
    
    private final Semaphore m_done = new Semaphore(0);
    private boolean m_stopping = false;

    
    private final Map<String, List<TopicMetadata>> m_topicPartitionMetaData = new HashMap<String, List<TopicMetadata>>();
    
    private final Map<String, List<Integer>> m_topicPartitions = new HashMap<String, List<Integer>>();
    
    private final Map<String, HostAndPort> m_topicPartitionLeader = new HashMap<String, HostAndPort>();
    private final Map<String, TopicPartitionFetcher> m_fetchers = new HashMap<String, TopicPartitionFetcher>();

    private ExecutorService m_es = null;

    private static final Pattern legalTopicNamesPattern = Pattern.compile("[a-zA-Z0-9\\._\\-]+");
    private static final int topicMaxNameLength = 255;

    
    public static class HostAndPort {

        private final String m_host;
        private final int m_port;
        private final String m_connectionString;

        public HostAndPort(String h, int p) {
            m_host = h;
            m_port = p;
            m_connectionString = m_host + ":" + m_port;
        }

        public static HostAndPort fromString(String hap) {
            String s[] = hap.split(":");
            int p = KAFKA_DEFAULT_BROKER_PORT;
            if (s.length > 1 && s[1] != null && s[1].length() > 0) {
                p = Integer.parseInt(s[1].trim());
            }
            return new HostAndPort(s[0].trim(), p);
        }

        public String getHost() {
            return m_host;
        }

        public int getPort() {
            return m_port;
        }

        @Override
        public String toString() {
            return m_host + ":" + m_port;
        }

        @Override
        public int hashCode() {
            return m_connectionString.hashCode();
        }

        @Override
        public boolean equals(Object o) {
            if (!(o instanceof HostAndPort)) {
                return false;
            }
            if (this.getClass() != o.getClass()) {
                return false;
            }
            HostAndPort hap = (HostAndPort )o;
            if (hap == this) {
                return true;
            }
            return (hap.getHost().equals(getHost()) && hap.getPort() == getPort());
        }
    }

    
    @Override
    public void start(BundleContext context) throws Exception {
        context.registerService(this.getClass().getName(), this, null);
    }

    @Override
    public void stop(BundleContext context) throws Exception {
        
    }

    @Override
    public boolean isRunEveryWhere() {
        
        return false;
    }

    
    private Set<URI> buildTopicLeaderMetadata(SimpleConsumer consumer) {

        
        Set<URI> availableResources = new TreeSet<URI>();
        for (String topic : m_topicList) {
            TopicMetadataRequest req = new TopicMetadataRequest(Collections.singletonList(topic));
            kafka.javaapi.TopicMetadataResponse resp = null;
            try {
                resp = consumer.send(req);
            } catch (Exception ex) {
                
                error(ex, "Failed to send topic metadata request for topic " + topic);
                continue;
            }

            List<TopicMetadata> metaData = resp.topicsMetadata();
            if (metaData == null) {
                
                error("Failed to get topic metadata for topic " + topic);
                continue;
            }
            m_topicPartitionMetaData.put(topic, metaData);
            List<Integer> partitions = m_topicPartitions.get(topic);
            if (partitions == null) {
                partitions = new ArrayList<Integer>();
                m_topicPartitions.put(topic, partitions);
            }
            for (TopicMetadata item : metaData) {
                for (PartitionMetadata part : item.partitionsMetadata()) {
                    partitions.add(part.partitionId());
                    for (kafka.cluster.Broker replica : part.replicas()) {
                        String leaderKey = topic + "-" + part.partitionId();
                        m_topicPartitionLeader.put(leaderKey, new HostAndPort(replica.host(), replica.port()));
                        URI uri = URI.create("kafka:/" + topic + "/partition/" + part.partitionId());
                        availableResources.add(uri);
                    }
                }
            }
        }

        info("Available Channels are: " + availableResources);
        
        m_es = Executors.newFixedThreadPool(availableResources.size() + 1,
                getThreadFactory("KafkaImporter", "KafkaImporterTopicFetcher", ImportHandlerProxy.MEDIUM_STACK_SIZE));
        return availableResources;
    }

    @Override
    public Set<URI> getAllResponsibleResources() {
        SimpleConsumer simpleConsumer = null;
        Set<URI> availableResources = new TreeSet<URI>();
        try {
            simpleConsumer = new SimpleConsumer(m_brokerList.get(0).getHost(), m_brokerList.get(0).getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID);
            
            availableResources = buildTopicLeaderMetadata(simpleConsumer);
        } catch (Exception ex) {
            VoltDB.crashLocalVoltDB("Failed to get available resources for kafka importer", true, ex);
        } finally {
            closeConsumer(simpleConsumer);
        }
        return availableResources;
    }

    @Override
    public void stop() {
        m_stopping = true;
        
        for (TopicPartitionFetcher fetcher : m_fetchers.values()) {
            fetcher.shutdown();
        }
        if (m_es != null) {
            
            m_es.shutdown();
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException ex) {
                
                ex.printStackTrace();
            }
        }
        m_fetchers.clear();
        m_done.release();
    }

    
    @Override
    public String getName() {
        return "KafkaImporter82";
    }

    
    @Override
    public void configure(Properties p) {
        m_properties = (Properties) p.clone();
        m_procedure = m_properties.getProperty("procedure", "").trim();
        if (m_procedure.isEmpty()) {
            throw new RuntimeException("Missing procedure.");
        }
        
        String topics = m_properties.getProperty("topics", "").trim();
        if (topics.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
        m_topicList = Arrays.asList(topics.split("\\s*,\\s*"));
        if (m_topicList == null || m_topicList.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
        for (String topic : m_topicList) {
            if (topic.contains("..") || topic.contains(".")) {
                throw new RuntimeException("topic name cannot be \".\" or \"..\"");
            }
            if (topic.length() > topicMaxNameLength) {
                throw new RuntimeException("topic name is illegal, can't be longer than "
                        + topicMaxNameLength + " characters");
            }
            if (!legalTopicNamesPattern.matcher(topic).matches()) {
                throw new RuntimeException("topic name " + topic + " is illegal, contains a character other than ASCII alphanumerics, '.', '_' and '-'");
            }
        }

       String brokers = m_properties.getProperty("brokers", "").trim();
        if (brokers.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        List<String> brokerList = Arrays.asList(brokers.split("\\s*,\\s*"));
        if (brokerList == null || brokerList.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        for (String broker : brokerList) {
            HostAndPort hap = HostAndPort.fromString(broker);
            m_brokerList.add(hap);
        }
        if (m_brokerList.isEmpty()) {
            throw new RuntimeException("Missing or misconfigured kafka broker list. See brokers property");
        }
        m_groupId = m_properties.getProperty("groupid", GROUP_ID).trim();
        
        m_fetchSize = Integer.parseInt(m_properties.getProperty("fetch.message.max.bytes", "65536"));
        m_consumerSocketTimeout = Integer.parseInt(m_properties.getProperty("socket.timeout.ms", "30000"));
        m_backpressureSleepMs = Integer.parseInt(m_properties.getProperty("backpressure.sleep.ms", "50"));
    }

    
    private class TopicPartitionFetcher implements Runnable {

        
        private final URI m_url;
        
        private final HostAndPort m_leader;
        
        private HostAndPort m_coordinator;
        private boolean m_shutdown = false;
        private volatile boolean m_hasBackPressure = false;
        private final int m_fetchSize;
        
        private final List<HostAndPort> m_brokers;
        private final int m_consumerSocketTimeout;
        
        private final AtomicLong m_currentOffset = new AtomicLong(-1);
        private final SortedSet<Long> m_pendingOffsets = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final SortedSet<Long> m_seenOffset = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final AtomicReference<SimpleConsumer> m_offsetManager = new AtomicReference<SimpleConsumer>();
        private final TopicAndPartition m_topicAndPartition;

        public TopicPartitionFetcher(List<HostAndPort> brokers, URI uri, String topic, int partition, HostAndPort leader, int fetchSize, int consumerSocketTimeout) {
            m_url = uri;
            m_brokers = brokers;
            m_leader = leader;
            m_coordinator = leader;
            m_fetchSize = fetchSize;
            m_consumerSocketTimeout = consumerSocketTimeout;
            m_topicAndPartition = new TopicAndPartition(topic, partition);
        }

        public final URI getUrl() {
            return m_url;
        }

        public void hasBackPressure(boolean flag) {
            m_hasBackPressure = flag;
        }

        
        private PartitionMetadata findLeader() {
            PartitionMetadata returnMetaData = null;
            loop:
            for (HostAndPort broker : m_brokers) {
                SimpleConsumer consumer = null;
                try {
                    consumer = new SimpleConsumer(broker.getHost(), broker.getPort(), m_consumerSocketTimeout, m_fetchSize, "findLeader");

                    List<String> topics = Collections.singletonList(m_topicAndPartition.topic());
                    TopicMetadataRequest req = new TopicMetadataRequest(topics);
                    kafka.javaapi.TopicMetadataResponse resp = consumer.send(req);

                    List<TopicMetadata> metaData = resp.topicsMetadata();
                    for (TopicMetadata item : metaData) {
                        for (PartitionMetadata part : item.partitionsMetadata()) {
                            if (part.partitionId() == m_topicAndPartition.partition()) {
                                returnMetaData = part;
                                break loop;
                            }
                        }
                    }
                } catch (Exception e) {
                    error(e, "Error in finding leader for %s", m_topicAndPartition);
                } finally {
                    closeConsumer(consumer);
                }
            }
            if (returnMetaData == null) {
                error(null, "Failed to find Leader for %s", m_topicAndPartition);
            }
            return returnMetaData;
        }

        
        private HostAndPort findNewLeader() {
            for (int i = 0; i < 3; i++) {
                boolean shouldSleep = false;
                PartitionMetadata metadata = findLeader();
                if (metadata == null) {
                    shouldSleep = true;
                } else if (metadata.leader() == null) {
                    shouldSleep = true;
                } else if (m_leader.getHost().equalsIgnoreCase(metadata.leader().host()) && i == 0) {
                    
                    
                    shouldSleep = true;
                } else {
                    return new HostAndPort(metadata.leader().host(), metadata.leader().port());
                }
                if (shouldSleep) {
                    backoffSleep(i+1);
                }
            }
            
            error(null, "Failed to find new leader for %s", m_topicAndPartition);
            return null;
        }

        
        public void shutdown() {
            m_shutdown = true;
        }

        public void getOffsetCoordinator() {
            BlockingChannel channel = null;
            int correlationId = 0;
            for (int i = 0; i < 3; i++) {
                try {
                    
                    channel = new BlockingChannel(m_coordinator.getHost(), m_coordinator.getPort(),
                            BlockingChannel.UseDefaultBufferSize(), BlockingChannel.UseDefaultBufferSize(), m_consumerSocketTimeout);
                    channel.connect();
                    channel.send(new ConsumerMetadataRequest(m_groupId, ConsumerMetadataRequest.CurrentVersion(), correlationId++, CLIENT_ID));
                    ConsumerMetadataResponse metadataResponse = ConsumerMetadataResponse.readFrom(channel.receive().buffer());

                    if (metadataResponse.errorCode() == ErrorMapping.NoError()) {
                        Broker offsetManager = metadataResponse.coordinator();
                        m_coordinator = new HostAndPort(offsetManager.host(), offsetManager.port());
                        SimpleConsumer consumer = m_offsetManager.getAndSet(new SimpleConsumer(m_coordinator.getHost(), m_coordinator.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID) );
                        closeConsumer(consumer);
                        consumer = null;
                        break;
                    }
                    final String msg = "Failed to get Offset Coordinator for " + m_topicAndPartition + " Code: %d";
                    
                    warn(null, msg, metadataResponse.errorCode());
                    backoffSleep(i+1);
                } catch (Exception e) {
                    
                    error(e, "Failed to get Offset Coordinator for " + m_topicAndPartition);
                    backoffSleep(i+1);
                } finally {
                    if (channel != null) {
                        channel.disconnect();
                    }
                }
            }
            info("Coordinator for " + m_topicAndPartition + " consumer is: " + m_coordinator);
        }

        public long getLastOffset(long whichTime) {
            if (m_offsetManager.get() == null) {
                return -1;
            }
            SimpleConsumer consumer = m_offsetManager.get();
            try {
                Map<TopicAndPartition, PartitionOffsetRequestInfo> requestInfo = new HashMap<TopicAndPartition, PartitionOffsetRequestInfo>();
                requestInfo.put(m_topicAndPartition, new PartitionOffsetRequestInfo(whichTime, 1));
                kafka.javaapi.OffsetRequest request = new kafka.javaapi.OffsetRequest(requestInfo, kafka.api.OffsetRequest.CurrentVersion(), CLIENT_ID);
                OffsetResponse response = consumer.getOffsetsBefore(request);

                if (response.hasError()) {
                    short code = response.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                    if (code == ErrorMapping.NotLeaderForPartitionCode() || code == ErrorMapping.UnknownTopicOrPartitionCode()) {
                        HostAndPort leaderBroker = findNewLeader();
                        if (leaderBroker != null) {
                            info("Found new leader for " + m_topicAndPartition + " Coordinator will be updated.");
                            SimpleConsumer oconsumer = m_offsetManager.getAndSet(new SimpleConsumer(leaderBroker.getHost(), leaderBroker.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID) );
                            closeConsumer(oconsumer);
                            oconsumer = null;
                            m_coordinator = leaderBroker;
                        }
                    }
                    info("Error fetching Offset Data from Broker " + m_topicAndPartition.toString() +
                            " Reason: " + response.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition()) );
                    return -1;
                }
                long[] offsets = response.offsets(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                return offsets[0];
            } catch (Exception ex) {
                error(ex, "Failed to get last Offset for " + m_topicAndPartition);
            }
            return -1;
        }

        
        private class TopicPartitionInvocationCallback implements ProcedureCallback {

            private final long m_offset;
            private final long m_nextOffset;
            private final AtomicLong m_cbcnt;

            public TopicPartitionInvocationCallback(long offset, long noffset, AtomicLong cbcnt) {
                m_offset = offset;
                m_nextOffset = noffset;
                m_cbcnt = cbcnt;
            }

            @Override
            public void clientCallback(ClientResponse response) throws Exception {
                
                assert(!m_pendingOffsets.isEmpty());
                m_cbcnt.incrementAndGet();
                m_pendingOffsets.remove(m_offset);
                
                m_seenOffset.add(m_nextOffset);
            }

        }

        
        private int backoffSleep(int fetchFailedCount) {
            try {
                Thread.sleep(1000 * fetchFailedCount++);
                if (fetchFailedCount > 10) fetchFailedCount = 1;
            } catch (InterruptedException ie) {
            }
            return fetchFailedCount;
        }

        @Override
        public void run() {
            SimpleConsumer consumer = null;
            info("Starting partition fetcher for " + m_topicAndPartition);
            long submitCount = 0;
            AtomicLong cbcnt = new AtomicLong(0);
            try {
                
                HostAndPort leaderBroker = m_leader;
                int sleepCounter = 1;
                while (!m_shutdown) {
                    if (consumer == null) {
                        consumer = new SimpleConsumer(leaderBroker.getHost(), leaderBroker.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID);
                    }
                    
                    if (m_currentOffset.get() < 0) {
                        getOffsetCoordinator();
                        m_currentOffset.set(getLastOffset(kafka.api.OffsetRequest.LatestTime()));
                        if (m_currentOffset.get() < 0) {
                            sleepCounter = backoffSleep(sleepCounter);
                            info("Latest offset not found for " + m_topicAndPartition + " using earliest offset.");
                            
                            m_currentOffset.set(getLastOffset(kafka.api.OffsetRequest.EarliestTime()));
                        }
                        sleepCounter = backoffSleep(sleepCounter);
                        info("Starting offset for " + m_topicAndPartition + " is set to: " + m_currentOffset.get());
                        continue;
                    }
                    long currentFetchCount = 0;
                    
                    FetchRequest req = new FetchRequestBuilder().clientId(CLIENT_ID)
                            .addFetch(m_topicAndPartition.topic(),
                                    m_topicAndPartition.partition(), m_currentOffset.get(), m_fetchSize)
                            .build();
                    FetchResponse fetchResponse = null;
                    try {
                        fetchResponse = consumer.fetch(req);
                        if (fetchResponse == null) {
                            sleepCounter = backoffSleep(sleepCounter);
                            continue;
                        }
                    } catch (Exception ex) {
                        error(ex, "Failed to fetch from %s", m_topicAndPartition);
                        
                        if (ex instanceof ClosedChannelException) {
                            closeConsumer(consumer);
                            consumer = null;
                            leaderBroker = findNewLeader();
                            if (leaderBroker == null) {
                                
                                error(null, "Fetch Failed to find leader continue with old leader: %s", m_leader);
                                leaderBroker = m_leader;
                            } else {
                                if (!leaderBroker.equals(m_leader)) {
                                    info("Fetch Found new leader for " + m_topicAndPartition + " New Leader: " + leaderBroker);
                                }
                            }
                            
                            continue;
                        }
                        sleepCounter = backoffSleep(sleepCounter);
                        continue;
                    }

                    if (fetchResponse.hasError()) {
                        
                        short code = fetchResponse.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                        warn(null, "Failed to fetch messages for %s Code: %d", m_topicAndPartition, code);
                        sleepCounter = backoffSleep(sleepCounter);
                        if (code == ErrorMapping.OffsetOutOfRangeCode()) {
                            
                            info("Invalid offset requested for " + m_topicAndPartition);
                            getOffsetCoordinator();
                            m_currentOffset.set(getLastOffset(kafka.api.OffsetRequest.LatestTime()));
                            continue;
                        }
                        closeConsumer(consumer);
                        consumer = null;
                        leaderBroker = findNewLeader();
                        if (leaderBroker == null) {
                            
                            error(null, "Failed to find leader continue with old leader: %s", m_leader);
                            leaderBroker = m_leader;
                        } else {
                            if (!leaderBroker.equals(m_leader)) {
                                info("Found new leader for " + m_topicAndPartition + " New Leader: " + leaderBroker);
                            }
                        }
                        continue;
                    }
                    sleepCounter = 1;
                    for (MessageAndOffset messageAndOffset : fetchResponse.messageSet(m_topicAndPartition.topic(), m_topicAndPartition.partition())) {
                        
                        currentFetchCount++;
                        long currentOffset = messageAndOffset.offset();
                        
                        if (currentOffset < m_currentOffset.get()) {
                            continue;
                        }
                        ByteBuffer payload = messageAndOffset.message().payload();

                        String line = new String(payload.array(),payload.arrayOffset(),payload.limit(),"UTF-8");
                        CSVInvocation invocation = new CSVInvocation(m_procedure, line);
                        TopicPartitionInvocationCallback cb = new TopicPartitionInvocationCallback(currentOffset, messageAndOffset.nextOffset(), cbcnt);
                        m_pendingOffsets.add(currentOffset);
                        if (!callProcedure(cb, invocation)) {
                            if (isDebugEnabled()) {
                                debug("Failed to process Invocation possibly bad data: " + line);
                            }
                            synchronized(m_seenOffset) {
                                
                                m_seenOffset.add(messageAndOffset.nextOffset());
                            }
                            m_pendingOffsets.remove(currentOffset);
                        }
                        submitCount++;
                        m_currentOffset.set(messageAndOffset.nextOffset());
                        if (m_shutdown) {
                            break;
                        }
                    }
                    if (m_shutdown) {
                        break;
                    }

                    
                    if (currentFetchCount == 0 || m_hasBackPressure) {
                        try {
                            Thread.sleep(m_backpressureSleepMs);
                        } catch (InterruptedException ie) {
                        }
                    }
                    commitOffset();
                }
                
                info("Partition fecher stopped for " + m_topicAndPartition
                        + " Last commit point is: " + m_currentOffset.get()
                        + " Callback Rcvd: " + cbcnt.get()
                        + " Submitted: " + submitCount);
            } catch (Exception ex) {
                error("Failed to start topic partition fetcher for " + m_topicAndPartition, ex);
            } finally {
                commitOffset();
                closeConsumer(consumer);
                consumer = null;
                closeConsumer(m_offsetManager.getAndSet(null));
            }
        }

        public boolean commitOffset() {

            if (m_seenOffset.isEmpty())
                return false;
            long offset = m_seenOffset.last();
            final int correlationId = m_topicAndPartition.partition();
            final short version = 1;

            OffsetAndMetadata offsetMetdata = new OffsetAndMetadata(offset, "commitRequest", ErrorMapping.NoError());
            Map<TopicAndPartition, OffsetAndMetadata> reqMap = new HashMap<TopicAndPartition, OffsetAndMetadata>();
            reqMap.put(m_topicAndPartition, offsetMetdata);
            OffsetCommitRequest offsetCommitRequest = new OffsetCommitRequest(m_groupId, reqMap, correlationId, CLIENT_ID, version);
            OffsetCommitResponse offsetCommitResponse = null;
            try {
                SimpleConsumer consumer = m_offsetManager.get();
                if (consumer == null) {
                    getOffsetCoordinator();
                    consumer = m_offsetManager.get();
                }
                if (consumer != null) {
                    offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                    final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
                    if (code == ErrorMapping.NotCoordinatorForConsumerCode()) {
                        info("Not coordinator for committing offset for " + m_topicAndPartition + " Updating coordinator.");
                        getOffsetCoordinator();
                        consumer = m_offsetManager.get();
                        if (consumer != null) {
                            offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                        }
                    }
                } else {
                    error("Commit Offset Failed to get offset coordinator for " + m_topicAndPartition);
                    return false;
                }
            } catch (Exception e) {
                error(e, "Failed to commit Offset for " + m_topicAndPartition);
                return false;
            }
            final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
            if (code != ErrorMapping.NoError()) {
                final String msg = "Commit Offset Failed to commit for " + m_topicAndPartition + " Code: %d";
                error(null, msg, code);
                return false;
            }
            synchronized(m_seenOffset) {
                m_seenOffset.clear();
            }
            return true;
        }

    }

    public void closeConsumer(SimpleConsumer consumer) {
        try {
            if (consumer != null) {
                consumer.close();
            }
        } catch (Exception e) {
            error("Failed to close consumer connection.", e);
        }
    }

    @Override
    public void hasBackPressure(boolean flag) {
        if (m_stopping) return;
        for (TopicPartitionFetcher fetcher : m_fetchers.values()) {
            fetcher.hasBackPressure(flag);
        }
    }

    
    @Override
    public void onChange(ImporterChannelAssignment assignment) {
        if (m_stopping) {
            info("Importer is stopping, ignoring the change notification.");
            return;
        }
        if (m_es == null) {
            
            VoltDB.crashLocalVoltDB("buildTopicLeaderMetadata must be called before getting an onChange", false, null);
        }

        
        for (URI nuri : assignment.getAdded()) {
            Map<String, List<Integer>> topicMap = new HashMap<String, List<Integer>>();
            for (String topic : m_topicList) {
                topicMap.put(topic, Collections.singletonList(0));
            }
            for (String topic : m_topicList) {
                List<Integer> topicPartitions = m_topicPartitions.get(topic);
                if (topicPartitions == null) {
                    
                    VoltDB.crashLocalVoltDB("Unknown kafka topic added for this node", false, null);
                }
                for (int partition : topicPartitions) {
                    String leaderKey = topic + "-" + partition;
                    URI assignedKey = URI.create("kafka:/" + topic + "/partition/" + partition);
                    
                    if (!m_fetchers.containsKey(nuri.toString()) && nuri.equals(assignedKey)) {
                        info("Channel " + assignedKey + " mastership is assigned to this node.");
                        HostAndPort hap = m_topicPartitionLeader.get(leaderKey);
                        TopicPartitionFetcher fetcher = new TopicPartitionFetcher(m_brokerList, assignedKey, topic, partition,
                                hap, m_fetchSize, m_consumerSocketTimeout);
                        m_fetchers.put(assignedKey.toString(), fetcher);
                        m_es.submit(fetcher);
                        info("KafkaImporter is fetching for resource: " + nuri);
                    }
                }
            }
        }

        
        for (URI r : assignment.getRemoved()) {
            TopicPartitionFetcher fetcher = m_fetchers.get(r.toString());
            if (fetcher != null) {
                fetcher.shutdown();
                info("KafkaImporter is NOT fetching for resource: " + r);
                m_fetchers.remove(r.toString());
            }
        }
    }

    
    @Override
    public void onClusterStateChange(VersionedOperationMode mode) {
        info("cluster state change notification: " + mode);
    }

    
    @Override
    public void readyForData() {
        try {
            info("Configured and ready with properties: " + m_properties);
            
            m_done.acquire();
        } catch (Exception ex) {
            error("Kafka Importer finished with exeception ", ex);
        }
    }

}

<code block>


package org.voltdb;

import org.voltdb.VoltDB.Configuration;
import org.voltdb.client.ProcCallException;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.utils.MiscUtils;

public class TestAdhocCreateDropIndex extends AdhocDDLTestBase {

    

    public void testBasicCreateIndex() throws Exception
    {
        VoltDB.Configuration config = new VoltDB.Configuration();
        String ddl = "create table FOO (" +
                     "ID integer not null," +
                     "VAL bigint, " +
                     "constraint PK_TREE primary key (ID)" +
                     ");\n" +
                     "create table FOO_R (" +
                     "ID integer not null," +
                     "VAL bigint, " +
                     "constraint PK_TREE_R primary key (ID)" +
                     ");\n" +
                     "Partition table FOO on column ID;\n";
        createSchema(config, ddl, 2, 1, 0);

        try {
            startSystem(config);

            
            assertFalse(findIndexInSystemCatalogResults("FOODEX"));
            try {
                m_client.callProcedure("@AdHoc",
                        "create index FOODEX on FOO (VAL);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create an index on a partitioned table");
            }
            assertTrue(findIndexInSystemCatalogResults("FOODEX"));
            
            assertFalse(findIndexInSystemCatalogResults("FOODEX_R"));
            try {
                m_client.callProcedure("@AdHoc",
                        "create index FOODEX_R on FOO_R (VAL);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create an index on a replicated table");
            }
            assertTrue(findIndexInSystemCatalogResults("FOODEX_R"));

            
            assertFalse(findIndexInSystemCatalogResults("UNIQFOODEX"));
            boolean threw = false;
            try {
                m_client.callProcedure("@AdHoc",
                        "create assumeunique index UNIQFOODEX on FOO (VAL);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create a unique index on a partitioned table");
            }
            assertTrue(findIndexInSystemCatalogResults("UNIQFOODEX"));
            
            try {
                m_client.callProcedure("@AdHoc",
                        "create unique index UNIQFOODEX2 on FOO (ID);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create redundant unique index");
            }
            
            assertFalse(findIndexInSystemCatalogResults("UNIQFOODEX2"));

            
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index FOODEX;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to drop an index");
            }
            assertFalse(findIndexInSystemCatalogResults("FOODEX"));
            
            threw = false;
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index FOODEX;");
            }
            catch (ProcCallException pce) {
                threw = true;
            }
            assertTrue("Shouldn't be able to drop bad index without if exists", threw);
            assertFalse(findIndexInSystemCatalogResults("FOODEX"));
            
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index FOODEX if exists;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to drop a bad index with if exists");
            }
            assertFalse(findIndexInSystemCatalogResults("FOODEX"));
        }
        finally {
            teardownSystem();
        }
    }

    public void testCreateDropIndexonView() throws Exception
    {
        VoltDB.Configuration config = new VoltDB.Configuration();
        String ddl = "create table FOO (" +
                     "ID integer not null," +
                     "VAL bigint, " +
                     "VAL1 float," +
                     "constraint PK_TREE primary key (ID)" +
                     ");\n" +
                     "create table FOO_R (" +
                     "ID integer not null," +
                     "VAL bigint, " +
                     "constraint PK_TREE_R primary key (ID)" +
                     ");\n" +
                     "Partition table FOO on column ID;\n";
        createSchema(config, ddl, 2, 1, 0);

        try {
            startSystem(config);

            
            assertFalse(findTableInSystemCatalogResults("FOOVIEW"));
            try {
                m_client.callProcedure("@AdHoc",
                    "create view FOOVIEW (VAL, VAL1, TOTAL) as " +
                    "select VAL, VAL1, COUNT(*) from FOO group by VAL, VAL1;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create a view");
            }
            assertTrue(findTableInSystemCatalogResults("FOOVIEW"));

            
            assertFalse(findIndexInSystemCatalogResults("VALDEX"));
            try {
                m_client.callProcedure("@AdHoc",
                        "create index SimpleIndex on FOOVIEW (VAL);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create an index on a view");
            }
            assertTrue(findIndexInSystemCatalogResults("SimpleIndex"));

            
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index SimpleIndex;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to drop an index on a view");
            }
            assertFalse(findIndexInSystemCatalogResults("SimpleIndex"));

            
            boolean threw = false;
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index SimpleIndex;");
            }
            catch (ProcCallException pce) {
                threw = true;
            }
            assertTrue("Shouldn't be able to drop bad index without if exists", threw);
            assertFalse(findIndexInSystemCatalogResults("SimpleIndex"));

            
            
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index SimpleIndex if exists;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to drop a bad index with if exists");
            }
            assertFalse(findIndexInSystemCatalogResults("SimpleIndex"));

            
            try {
                m_client.callProcedure("@AdHoc",
                        "create index ComplexIndex on FOOVIEW (VAL, TOTAL);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to recreate an index on a view");
            }
            assertTrue(findIndexInSystemCatalogResults("ComplexIndex"));

            
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index ComplexIndex if exists;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to drop an index on a view");
            }
            assertFalse(findIndexInSystemCatalogResults("ComplexIndex"));
        }
        finally {
            teardownSystem();
        }
    }

    private void createSchema(VoltDB.Configuration config,
                              String ddl,
                              final int sitesPerHost,
                              final int hostCount,
                              final int replication) throws Exception
    {
        VoltProjectBuilder builder = new VoltProjectBuilder();
        builder.addLiteralSchema(ddl);
        builder.setUseDDLSchema(true);
        config.m_pathToCatalog = Configuration.getPathToCatalogForTest("adhocddl.jar");
        boolean success = builder.compile(config.m_pathToCatalog, sitesPerHost, hostCount, replication);
        assertTrue("Schema compilation failed", success);
        config.m_pathToDeployment = Configuration.getPathToCatalogForTest("adhocddl.xml");
        MiscUtils.copyFile(builder.getPathToDeployment(), config.m_pathToDeployment);
    }
}

<code block>


package org.voltdb;

import org.voltdb.VoltDB.Configuration;
import org.voltdb.client.ProcCallException;
import org.voltdb.compiler.VoltProjectBuilder;
import org.voltdb.utils.MiscUtils;

public class TestAdhocCreateDropIndex extends AdhocDDLTestBase {

    

    public void testBasicCreateIndex() throws Exception
    {
        String pathToCatalog = Configuration.getPathToCatalogForTest("adhocddl.jar");
        String pathToDeployment = Configuration.getPathToCatalogForTest("adhocddl.xml");

        VoltProjectBuilder builder = new VoltProjectBuilder();
        builder.addLiteralSchema(
                "create table FOO (" +
                "ID integer not null," +
                "VAL bigint, " +
                "constraint PK_TREE primary key (ID)" +
                ");\n" +
                "create table FOO_R (" +
                "ID integer not null," +
                "VAL bigint, " +
                "constraint PK_TREE_R primary key (ID)" +
                ");\n"
                );
        builder.addPartitionInfo("FOO", "ID");
        builder.setUseDDLSchema(true);
        boolean success = builder.compile(pathToCatalog, 2, 1, 0);
        assertTrue("Schema compilation failed", success);
        MiscUtils.copyFile(builder.getPathToDeployment(), pathToDeployment);

        VoltDB.Configuration config = new VoltDB.Configuration();
        config.m_pathToCatalog = pathToCatalog;
        config.m_pathToDeployment = pathToDeployment;

        try {
            startSystem(config);

            
            assertFalse(findIndexInSystemCatalogResults("FOODEX"));
            try {
                m_client.callProcedure("@AdHoc",
                        "create index FOODEX on FOO (VAL);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create an index on a partitioned table");
            }
            assertTrue(findIndexInSystemCatalogResults("FOODEX"));
            
            assertFalse(findIndexInSystemCatalogResults("FOODEX_R"));
            try {
                m_client.callProcedure("@AdHoc",
                        "create index FOODEX_R on FOO_R (VAL);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create an index on a replicated table");
            }
            assertTrue(findIndexInSystemCatalogResults("FOODEX_R"));

            
            assertFalse(findIndexInSystemCatalogResults("UNIQFOODEX"));
            boolean threw = false;
            try {
                m_client.callProcedure("@AdHoc",
                        "create assumeunique index UNIQFOODEX on FOO (VAL);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create a unique index on a partitioned table");
            }
            assertTrue(findIndexInSystemCatalogResults("UNIQFOODEX"));
            
            try {
                m_client.callProcedure("@AdHoc",
                        "create unique index UNIQFOODEX2 on FOO (ID);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create redundant unique index");
            }
            
            assertFalse(findIndexInSystemCatalogResults("UNIQFOODEX2"));

            
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index FOODEX;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to drop an index");
            }
            assertFalse(findIndexInSystemCatalogResults("FOODEX"));
            
            threw = false;
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index FOODEX;");
            }
            catch (ProcCallException pce) {
                threw = true;
            }
            assertTrue("Shouldn't be able to drop bad index without if exists", threw);
            assertFalse(findIndexInSystemCatalogResults("FOODEX"));
            
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index FOODEX if exists;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to drop a bad index with if exists");
            }
            assertFalse(findIndexInSystemCatalogResults("FOODEX"));
        }
        finally {
            teardownSystem();
        }
    }

    public void testCreateDropIndexonView() throws Exception
    {
        String pathToCatalog = Configuration.getPathToCatalogForTest("adhocddl.jar");
        String pathToDeployment = Configuration.getPathToCatalogForTest("adhocddl.xml");

        VoltProjectBuilder builder = new VoltProjectBuilder();
        builder.addLiteralSchema(
                "create table FOO (" +
                "ID integer not null," +
                "VAL bigint, " +
                "constraint PK_TREE primary key (ID)" +
                ");\n" +
                "create table FOO_R (" +
                "ID integer not null," +
                "VAL bigint, " +
                "constraint PK_TREE_R primary key (ID)" +
                ");\n"
                );
        builder.addPartitionInfo("FOO", "ID");
        builder.setUseDDLSchema(true);
        boolean success = builder.compile(pathToCatalog, 2, 1, 0);
        assertTrue("Schema compilation failed", success);
        MiscUtils.copyFile(builder.getPathToDeployment(), pathToDeployment);

        VoltDB.Configuration config = new VoltDB.Configuration();
        config.m_pathToCatalog = pathToCatalog;
        config.m_pathToDeployment = pathToDeployment;

        try {
            startSystem(config);

            
            assertFalse(findTableInSystemCatalogResults("FOOVIEW"));
            try {
                m_client.callProcedure("@AdHoc",
                    "create view FOOVIEW (VAL, TOTAL) as " +
                    "select VAL, COUNT(*) from FOO group by VAL;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create a view");
            }
            assertTrue(findTableInSystemCatalogResults("FOOVIEW"));

            
            boolean threw = false;
            try {
                m_client.callProcedure("@AdHoc",
                    "create view FOOVIEW (VAL, TOTAL) as " +
                    "select VAL, COUNT(*) from FOO group by VAL;");
            }
            catch (ProcCallException pce) {
                threw = true;
            }
            assertTrue("Shouldn't be able to create the same view twice", threw);
            assertTrue(findTableInSystemCatalogResults("FOOVIEW"));

            
            assertFalse(findIndexInSystemCatalogResults("VALDEX"));
            try {
                m_client.callProcedure("@AdHoc",
                        "create index VALDEX on FOOVIEW (VAL);");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to create an index on a view");
            }
            assertTrue(findIndexInSystemCatalogResults("VALDEX"));

            
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index VALDEX;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to drop an index on a view");
            }
            assertFalse(findIndexInSystemCatalogResults("VALDEX"));

            
            threw = false;
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index VALDEX;");
            }
            catch (ProcCallException pce) {
                threw = true;
            }
            assertTrue("Shouldn't be able to drop bad index without if exists", threw);
            assertFalse(findIndexInSystemCatalogResults("VALDEX"));
            
            try {
                m_client.callProcedure("@AdHoc",
                        "drop index VALDEX if exists;");
            }
            catch (ProcCallException pce) {
                pce.printStackTrace();
                fail("Should be able to drop a bad index with if exists");
            }
            assertFalse(findIndexInSystemCatalogResults("VALDEX"));
        }
        finally {
            teardownSystem();
        }
    }
}
