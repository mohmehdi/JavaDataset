
package com.datastax.driver.stress;

import java.io.IOException;
import java.util.*;

import com.datastax.driver.core.*;
import com.datastax.driver.core.exceptions.*;

import org.apache.log4j.PropertyConfigurator;

import joptsimple.*;


public class Stress {

    private static final Map<String, QueryGenerator.Builder> generators = new HashMap<String, QueryGenerator.Builder>();
    static {
        PropertyConfigurator.configure(System.getProperty("log4j.configuration", "./conf/log4j.properties"));

        QueryGenerator.Builder[] gs = new QueryGenerator.Builder[] {
            Generators.INSERTER,
            Generators.READER
        };

        for (QueryGenerator.Builder b : gs)
            register(b.name(), b);
    }

    private static OptionParser defaultParser() {
        OptionParser parser = new OptionParser() {{
            accepts("h", "Show this help message");
            accepts("n", "Number of requests to perform (default: unlimited)").withRequiredArg().ofType(Integer.class);
            accepts("t", "Level of concurrency to use").withRequiredArg().ofType(Integer.class).defaultsTo(50);
            accepts("async", "Make asynchronous requests instead of blocking ones");
            accepts("ip", "The hosts ip to connect to").withRequiredArg().ofType(String.class).defaultsTo("127.0.0.1");
            accepts("report-file", "The name of csv file to use for reporting results").withRequiredArg().ofType(String.class).defaultsTo("last.csv");
            accepts("print-delay", "The delay in seconds at which to report on the console").withRequiredArg().ofType(Integer.class).defaultsTo(5);
            accepts("compression", "Use compression (SNAPPY)");
            accepts("connections-per-host", "The number of connections per hosts (default: based on the number of threads)").withRequiredArg().ofType(Integer.class);
        }};
        String msg = "Where <generator> can be one of " + generators.keySet() + '\n'
                   + "You can get more help on a particular generator with: stress <generator> -h";
        parser.formatHelpWith(Help.formatFor("<generator>", msg));
        return parser;
    }

    public static void register(String name, QueryGenerator.Builder generator) {
        if (generators.containsKey(name))
            throw new IllegalStateException("There is already a generator registered with the name " + name);

        generators.put(name, generator);
    }

    private static class Stresser {
        private final QueryGenerator.Builder genBuilder;
        private final OptionParser parser;
        private final OptionSet options;

        private Stresser(QueryGenerator.Builder genBuilder, OptionParser parser, OptionSet options) {
            this.genBuilder = genBuilder;
            this.parser = parser;
            this.options = options;
        }

        public static Stresser forCommandLineArguments(String[] args) {
            OptionParser parser = defaultParser();

            String generatorName = findPotentialGenerator(args);
            if (generatorName == null) {
                
                OptionSet options = parseOptions(parser, args);
                System.err.println("Missing generator, you need to provide a generator.");
                printHelp(parser);
                System.exit(1);
            }

            if (!generators.containsKey(generatorName)) {
                System.err.println(String.format("Unknown generator '%s'", generatorName));
                printHelp(parser);
                System.exit(1);
            }

            QueryGenerator.Builder genBuilder = generators.get(generatorName);
            parser = genBuilder.addOptions(parser);
            OptionSet options = parseOptions(parser, args);

            List<?> nonOpts = options.nonOptionArguments();
            if (nonOpts.size() > 1) {
                System.err.println("Too many generators provided. Got " + nonOpts + " but only one generator supported.");
                printHelp(parser);
                System.exit(1);
            }

            return new Stresser(genBuilder, parser, options);
        }

        private static String findPotentialGenerator(String[] args) {
            for (String arg : args)
                if (!arg.startsWith("-"))
                    return arg;

            return null;
        }

        private static OptionSet parseOptions(OptionParser parser, String[] args) {
            try {
                OptionSet options = parser.parse(args);
                if (options.has("h")) {
                    printHelp(parser);
                    System.exit(0);
                }
                return options;
            } catch (Exception e) {
                System.err.println("Error parsing options: " + e.getMessage());
                printHelp(parser);
                System.exit(1);
                throw new AssertionError();
            }
        }

        private static void printHelp(OptionParser parser) {
            try {
                parser.printHelpOn(System.out);
            } catch (IOException e) {
                throw new AssertionError(e);
            }
        }

        public OptionSet getOptions() {
            return options;
        }

        public void prepare(Session session) {
            genBuilder.prepare(options, session);
        }

        public QueryGenerator newGenerator(int id, Session session, int iterations) {
            return genBuilder.create(id, iterations, options, session);
        }
    }

    public static class Help implements HelpFormatter {

        private final HelpFormatter defaultFormatter;
        private final String generator;
        private final String header;

        private Help(HelpFormatter defaultFormatter, String generator, String header) {
            this.defaultFormatter = defaultFormatter;
            this.generator = generator;
            this.header = header;
        }

        public static Help formatFor(String generator, String header) {
            
            
            int width = 120; 
            return new Help(new BuiltinHelpFormatter(width, 4), generator, header);
        }

        @Override
        public String format(Map<String, ? extends OptionDescriptor> options) {
            StringBuilder sb = new StringBuilder();

            sb.append("Usage: stress ").append(generator).append(" [<option>]*").append("\n\n");
            sb.append(header).append("\n\n");
            sb.append(defaultFormatter.format(options));
            return sb.toString();
        }
    }

    public static void main(String[] args) throws Exception {

        Stresser stresser = Stresser.forCommandLineArguments(args);
        OptionSet options = stresser.getOptions();

        int requests = options.has("n") ? (Integer)options.valueOf("n") : -1;
        int concurrency = (Integer)options.valueOf("t");

        String reportFileName = (String)options.valueOf("report-file");

        boolean async = options.has("async");

        int iterations = (requests  == -1 ? -1 : requests / concurrency);

        final int maxRequestsPerConnection = 128;
        int maxConnections = options.has("connections-per-host")
                           ? (Integer)options.valueOf("connections-per-host")
                           : concurrency / maxRequestsPerConnection + 1;

        PoolingOptions pools = new PoolingOptions();
        pools.setNewConnectionThreshold(HostDistance.LOCAL, concurrency);
        pools.setCoreConnectionsPerHost(HostDistance.LOCAL, maxConnections);
        pools.setMaxConnectionsPerHost(HostDistance.LOCAL, maxConnections);
        pools.setCoreConnectionsPerHost(HostDistance.REMOTE, maxConnections);
        pools.setMaxConnectionsPerHost(HostDistance.REMOTE, maxConnections);

        System.out.println("Initializing stress test:");
        System.out.println("  request count:        " + (requests == -1 ? "unlimited" : requests));
        System.out.println("  concurrency:          " + concurrency + " (" + iterations + " requests/thread)");
        System.out.println("  mode:                 " + (async ? "asynchronous" : "blocking"));
        System.out.println("  per-host connections: " + maxConnections);
        System.out.println("  compression:          " + options.has("compression"));

        try {
            
            Cluster cluster = new Cluster.Builder()
                                         .addContactPoints(String.valueOf(options.valueOf("ip")))
                                         .withPoolingOptions(pools)
                                         .withSocketOptions(new SocketOptions().setTcpNoDelay(true))
                                         .build();

            if (options.has("compression"))
                cluster.getConfiguration().getProtocolOptions().setCompression(ProtocolOptions.Compression.SNAPPY);

            Session session = cluster.connect();

            Metadata metadata = cluster.getMetadata();
            System.out.println(String.format("Connected to cluster '%s' on %s.", metadata.getClusterName(), metadata.getAllHosts()));

            System.out.println("Preparing test...");
            stresser.prepare(session);

            Reporter reporter = new Reporter((Integer)options.valueOf("print-delay"), reportFileName, args, requests);

            Consumer[] consumers = new Consumer[concurrency];
            for (int i = 0; i < concurrency; i++) {
                QueryGenerator generator = stresser.newGenerator(i, session, iterations);
                consumers[i] = async ? new AsynchronousConsumer(session, generator, reporter) :
                                       new BlockingConsumer(session, generator, reporter);
            }

            System.out.println("Starting to stress test...");
            System.out.println();

            reporter.start();

            for (Consumer consumer : consumers)
                consumer.start();

            for (Consumer consumer : consumers)
                consumer.join();

            reporter.stop();

            System.out.println("Stress test successful.");
            System.exit(0);

        } catch (NoHostAvailableException e) {
            System.err.println("No alive hosts to use: " + e.getMessage());
            System.exit(1);
        } catch (Exception e) {
            System.err.println("Unexpected error: " + e.getMessage());
            e.printStackTrace();
            System.exit(1);
        }
    }
}

<code block>

package com.datastax.driver.core;


import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.locks.*;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.collect.Lists;
import com.google.common.util.concurrent.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.datastax.driver.core.exceptions.AuthenticationException;
import com.datastax.driver.core.utils.MoreFutures;

import static com.datastax.driver.core.Connection.State.*;


class DynamicConnectionPool extends HostConnectionPool {

    private static final Logger logger = LoggerFactory.getLogger(DynamicConnectionPool.class);

    private static final int MAX_SIMULTANEOUS_CREATION = 1;

    
    
    
    private static final int MIN_AVAILABLE_STREAMS = 96;

    final List<Connection> connections;
    private final AtomicInteger open;
    
    final AtomicInteger totalInFlight = new AtomicInteger();
    
    private final AtomicInteger maxTotalInFlight = new AtomicInteger();

    @VisibleForTesting
    final Set<Connection> trash = new CopyOnWriteArraySet<Connection>();

    private volatile int waiter = 0;
    private final Lock waitLock = new ReentrantLock(true);
    private final Condition hasAvailableConnection = waitLock.newCondition();

    private final Runnable newConnectionTask;

    private final AtomicInteger scheduledForCreation = new AtomicInteger();

    public DynamicConnectionPool(Host host, HostDistance hostDistance, SessionManager manager) {
        super(host, hostDistance, manager);

        this.newConnectionTask = new Runnable() {
            @Override
            public void run() {
                addConnectionIfUnderMaximum();
                scheduledForCreation.decrementAndGet();
            }
        };

        this.connections = new CopyOnWriteArrayList<Connection>();
        this.open = new AtomicInteger();
    }

    @Override
    ListenableFuture<Void> initAsync(Connection reusedConnection) {
        
        int capacity = options().getCoreConnectionsPerHost(hostDistance);
        final List<Connection> connections = Lists.newArrayListWithCapacity(capacity);
        final List<ListenableFuture<Void>> connectionFutures = Lists.newArrayListWithCapacity(capacity);
        for (int i = 0; i < capacity; i++) {
            Connection connection;
            ListenableFuture<Void> connectionFuture;
            
            if (reusedConnection != null && reusedConnection.setPool(this)) {
                connection = reusedConnection;
                connectionFuture = MoreFutures.VOID_SUCCESS;
            } else {
                connection = manager.connectionFactory().newConnection(this);
                connectionFuture = connection.initAsync();
            }
            reusedConnection = null;
            connections.add(connection);
            connectionFutures.add(connectionFuture);
        }

        Executor initExecutor = manager.cluster.manager.configuration.getPoolingOptions().getInitializationExecutor();

        ListenableFuture<List<Void>> allConnectionsFuture = Futures.allAsList(connectionFutures);

        final SettableFuture<Void> initFuture = SettableFuture.create();
        Futures.addCallback(allConnectionsFuture, new FutureCallback<List<Void>>() {
            @Override
            public void onSuccess(List<Void> l) {
                DynamicConnectionPool.this.connections.addAll(connections);
                open.set(l.size());
                if (isClosed()) {
                    initFuture.setException(new ConnectionException(host.getSocketAddress(), "Pool was closed during initialization"));
                    
                    forceClose(connections);
                } else {
                    logger.trace("Created connection pool to host {}", host);
                    phase.compareAndSet(Phase.INITIALIZING, Phase.READY);
                    initFuture.set(null);
                }
            }

            @Override
            public void onFailure(Throwable t) {
                phase.compareAndSet(Phase.INITIALIZING, Phase.INIT_FAILED);
                forceClose(connections);
                initFuture.setException(t);
            }
        }, initExecutor);
        return initFuture;
    }

    
    private void forceClose(List<Connection> connections) {
        for (Connection connection : connections) {
            connection.closeAsync().force();
        }
    }

    private PoolingOptions options() {
        return manager.configuration().getPoolingOptions();
    }

    @Override
    public Connection borrowConnection(long timeout, TimeUnit unit) throws ConnectionException, TimeoutException {
        Phase phase = this.phase.get();
        if (phase != Phase.READY)
            
            
            throw new ConnectionException(host.getSocketAddress(), "Pool is " + phase);

        if (connections.isEmpty()) {
            for (int i = 0; i < options().getCoreConnectionsPerHost(hostDistance); i++) {
                
                
                scheduledForCreation.incrementAndGet();
                manager.blockingExecutor().submit(newConnectionTask);
            }
            Connection c = waitForConnection(timeout, unit);
            totalInFlight.incrementAndGet();
            c.setKeyspace(manager.poolsState.keyspace);
            return c;
        }

        int minInFlight = Integer.MAX_VALUE;
        Connection leastBusy = null;
        for (Connection connection : connections) {
            int inFlight = connection.inFlight.get();
            if (inFlight < minInFlight) {
                minInFlight = inFlight;
                leastBusy = connection;
            }
        }

        if (leastBusy == null) {
            
            if (isClosed())
                throw new ConnectionException(host.getSocketAddress(), "Pool is shutdown");
            
            
            
            leastBusy = waitForConnection(timeout, unit);
        } else {
            while (true) {
                int inFlight = leastBusy.inFlight.get();

                if (inFlight >= leastBusy.maxAvailableStreams()) {
                    leastBusy = waitForConnection(timeout, unit);
                    break;
                }

                if (leastBusy.inFlight.compareAndSet(inFlight, inFlight + 1))
                    break;
            }
        }

        int totalInFlightCount = totalInFlight.incrementAndGet();
        
        while (true) {
            int oldMax = maxTotalInFlight.get();
            if (totalInFlightCount <= oldMax || maxTotalInFlight.compareAndSet(oldMax, totalInFlightCount))
                break;
        }

        int connectionCount = open.get() + scheduledForCreation.get();
        if (connectionCount < options().getMaxConnectionsPerHost(hostDistance)) {
            
            int currentCapacity = (connectionCount - 1) * StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2
                + options().getNewConnectionThreshold(hostDistance);
            if (totalInFlightCount > currentCapacity)
                maybeSpawnNewConnection();
        }

        leastBusy.setKeyspace(manager.poolsState.keyspace);
        return leastBusy;
    }

    private void awaitAvailableConnection(long timeout, TimeUnit unit) throws InterruptedException {
        waitLock.lock();
        waiter++;
        try {
            hasAvailableConnection.await(timeout, unit);
        } finally {
            waiter--;
            waitLock.unlock();
        }
    }

    private void signalAvailableConnection() {
        
        if (waiter == 0)
            return;

        waitLock.lock();
        try {
            hasAvailableConnection.signal();
        } finally {
            waitLock.unlock();
        }
    }

    private void signalAllAvailableConnection() {
        
        if (waiter == 0)
            return;

        waitLock.lock();
        try {
            hasAvailableConnection.signalAll();
        } finally {
            waitLock.unlock();
        }
    }

    private Connection waitForConnection(long timeout, TimeUnit unit) throws ConnectionException, TimeoutException {
        if (timeout == 0)
            throw new TimeoutException();

        long start = System.nanoTime();
        long remaining = timeout;
        do {
            try {
                awaitAvailableConnection(remaining, unit);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                
                timeout = 0; 
            }

            if (isClosed())
                throw new ConnectionException(host.getSocketAddress(), "Pool is shutdown");

            int minInFlight = Integer.MAX_VALUE;
            Connection leastBusy = null;
            for (Connection connection : connections) {
                int inFlight = connection.inFlight.get();
                if (inFlight < minInFlight) {
                    minInFlight = inFlight;
                    leastBusy = connection;
                }
            }

            
            
            if (leastBusy != null) {
                while (true) {
                    int inFlight = leastBusy.inFlight.get();

                    if (inFlight >= leastBusy.maxAvailableStreams())
                        break;

                    if (leastBusy.inFlight.compareAndSet(inFlight, inFlight + 1))
                        return leastBusy;
                }
            }

            remaining = timeout - Cluster.timeSince(start, unit);
        } while (remaining > 0);

        throw new TimeoutException();
    }

    @Override
    public void returnConnection(Connection connection) {
        connection.inFlight.decrementAndGet();
        totalInFlight.decrementAndGet();

        if (isClosed()) {
            close(connection);
            return;
        }

        if (connection.isDefunct()) {
            
            
            return;
        }

        if (connection.state.get() != TRASHED) {
            if (connection.maxAvailableStreams() < MIN_AVAILABLE_STREAMS) {
                replaceConnection(connection);
            } else {
                signalAvailableConnection();
            }
        }
    }

    
    
    private void replaceConnection(Connection connection) {
        if (!connection.state.compareAndSet(OPEN, TRASHED))
            return;
        open.decrementAndGet();
        maybeSpawnNewConnection();
        connection.maxIdleTime = Long.MIN_VALUE;
        doTrashConnection(connection);
    }

    private boolean trashConnection(Connection connection) {
        if (!connection.state.compareAndSet(OPEN, TRASHED))
            return true;

        
        for (;;) {
            int opened = open.get();
            if (opened <= options().getCoreConnectionsPerHost(hostDistance)) {
                connection.state.set(OPEN);
                return false;
            }

            if (open.compareAndSet(opened, opened - 1))
                break;
        }
        logger.trace("Trashing {}", connection);
        connection.maxIdleTime = System.currentTimeMillis() + options().getIdleTimeoutSeconds() * 1000;
        doTrashConnection(connection);
        return true;
    }

    private void doTrashConnection(Connection connection) {
        connections.remove(connection);
        trash.add(connection);
    }

    private boolean addConnectionIfUnderMaximum() {

        
        for(;;) {
            int opened = open.get();
            if (opened >= options().getMaxConnectionsPerHost(hostDistance))
                return false;

            if (open.compareAndSet(opened, opened + 1))
                break;
        }

        if (phase.get() != Phase.READY) {
            open.decrementAndGet();
            return false;
        }

        
        try {
            Connection newConnection = tryResurrectFromTrash();
            if (newConnection == null) {
                logger.debug("Creating new connection on busy pool to {}", host);
                newConnection = manager.connectionFactory().open(this);
            }
            connections.add(newConnection);

            newConnection.state.compareAndSet(RESURRECTING, OPEN); 

            
            if (isClosed() && !newConnection.isClosed()) {
                close(newConnection);
                open.decrementAndGet();
                return false;
            }

            signalAvailableConnection();
            return true;
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            
            open.decrementAndGet();
            return false;
        } catch (ConnectionException e) {
            open.decrementAndGet();
            logger.debug("Connection error to {} while creating additional connection", host);
            return false;
        } catch (AuthenticationException e) {
            
            open.decrementAndGet();
            logger.error("Authentication error while creating additional connection (error is: {})", e.getMessage());
            return false;
        } catch (UnsupportedProtocolVersionException e) {
            
            open.decrementAndGet();
            logger.error("UnsupportedProtocolVersionException error while creating additional connection (error is: {})", e.getMessage());
            return false;
        } catch (ClusterNameMismatchException e) {
            open.decrementAndGet();
            logger.error("ClusterNameMismatchException error while creating additional connection (error is: {})", e.getMessage());
            return false;
        }
    }

    private Connection tryResurrectFromTrash() {
        long highestMaxIdleTime = System.currentTimeMillis();
        Connection chosen = null;

        while (true) {
            for (Connection connection : trash)
                if (connection.maxIdleTime > highestMaxIdleTime && connection.maxAvailableStreams() > MIN_AVAILABLE_STREAMS) {
                    chosen = connection;
                    highestMaxIdleTime = connection.maxIdleTime;
                }

            if (chosen == null)
                return null;
            else if (chosen.state.compareAndSet(TRASHED, RESURRECTING))
                break;
        }
        logger.trace("Resurrecting {}", chosen);
        trash.remove(chosen);
        return chosen;
    }

    private void maybeSpawnNewConnection() {
        while (true) {
            int inCreation = scheduledForCreation.get();
            if (inCreation >= MAX_SIMULTANEOUS_CREATION)
                return;
            if (scheduledForCreation.compareAndSet(inCreation, inCreation + 1))
                break;
        }

        manager.blockingExecutor().submit(newConnectionTask);
    }

    @Override
    void replaceDefunctConnection(final Connection connection) {
        if (connection.state.compareAndSet(OPEN, GONE))
            open.decrementAndGet();
        if (connections.remove(connection))
            manager.blockingExecutor().submit(new Runnable() {
                @Override
                public void run() {
                    addConnectionIfUnderMaximum();
                }
            });
    }

    @Override
    void cleanupIdleConnections(long now) {
        if (isClosed())
            return;

        shrinkIfBelowCapacity();
        cleanupTrash(now);
    }

    
    private void shrinkIfBelowCapacity() {
        int currentLoad = maxTotalInFlight.getAndSet(totalInFlight.get());

        int needed = currentLoad / StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2 + 1;
        if (currentLoad % StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2 > options().getNewConnectionThreshold(hostDistance))
            needed += 1;
        needed = Math.max(needed, options().getCoreConnectionsPerHost(hostDistance));
        int actual = open.get();
        int toTrash = Math.max(0, actual - needed);

        logger.trace("Current inFlight = {}, {} connections needed, {} connections available, trashing {}",
            currentLoad, needed, actual, toTrash);

        if (toTrash <= 0)
            return;

        for (Connection connection : connections)
            if (trashConnection(connection)) {
                toTrash -= 1;
                if (toTrash == 0)
                    return;
            }
    }

    
    private void cleanupTrash(long now) {
        for (Connection connection : trash) {
            if (connection.maxIdleTime < now && connection.state.compareAndSet(TRASHED, GONE)) {
                if (connection.inFlight.get() == 0) {
                    logger.trace("Cleaning up {}", connection);
                    trash.remove(connection);
                    close(connection);
                } else {
                    
                    
                    
                    connection.state.set(TRASHED);
                }
            }
        }
    }

    private void close(final Connection connection) {
        connection.closeAsync();
    }

    protected CloseFuture makeCloseFuture() {
        
        signalAllAvailableConnection();

        return new CloseFuture.Forwarding(discardAvailableConnections());
    }

    private List<CloseFuture> discardAvailableConnections() {
        
        

        List<CloseFuture> futures = new ArrayList<CloseFuture>(connections.size() + trash.size());

        for (final Connection connection : connections) {
            CloseFuture future = connection.closeAsync();
            future.addListener(new Runnable() {
                public void run() {
                    if (connection.state.compareAndSet(OPEN, GONE))
                        open.decrementAndGet();
                }
            }, MoreExecutors.sameThreadExecutor());
            futures.add(future);
        }

        
        for (Connection connection : trash)
            futures.add(connection.closeAsync());

        return futures;
    }

    
    
    @Override
    public void ensureCoreConnections() {
        if (isClosed())
            return;

        
        
        
        int opened = open.get();
        for (int i = opened; i < options().getCoreConnectionsPerHost(hostDistance); i++) {
            
            
            scheduledForCreation.incrementAndGet();
            manager.blockingExecutor().submit(newConnectionTask);
        }
    }

    @Override
    public int opened() {
        return open.get();
    }

    @Override
    int trashed() {
        return trash.size();
    }

    @Override
    public int inFlightQueriesCount() {
        int count = 0;
        for (Connection connection : connections) {
            count += connection.inFlight.get();
        }
        return count;
    }
}

<code block>

package com.datastax.driver.core;

import java.util.concurrent.Executor;

import com.google.common.base.Preconditions;
import com.google.common.util.concurrent.MoreExecutors;


public class PoolingOptions {

    private static final int DEFAULT_NEW_CONNECTION_THRESHOLD = 100;

    private static final int DEFAULT_CORE_POOL_LOCAL = 2;
    private static final int DEFAULT_CORE_POOL_REMOTE = 1;

    private static final int DEFAULT_MAX_POOL_LOCAL = 8;
    private static final int DEFAULT_MAX_POOL_REMOTE = 2;

    private static final int DEFAULT_MAX_REQUESTS_PER_CONNECTION_LOCAL = 1024;
    private static final int DEFAULT_MAX_REQUESTS_PER_CONNECTION_REMOTE = 256;

    private static final int DEFAULT_IDLE_TIMEOUT_SECONDS = 120;
    private static final int DEFAULT_POOL_TIMEOUT_MILLIS = 5000;
    private static final int DEFAULT_HEARTBEAT_INTERVAL_SECONDS = 30;

    private static final Executor DEFAULT_INITIALIZATION_EXECUTOR = MoreExecutors.sameThreadExecutor();

    private volatile Cluster.Manager manager;


    private final int[] coreConnections = new int[] { DEFAULT_CORE_POOL_LOCAL, DEFAULT_CORE_POOL_REMOTE, 0 };
    private final int[] maxConnections = new int[] { DEFAULT_MAX_POOL_LOCAL , DEFAULT_MAX_POOL_REMOTE, 0 };

    private final int[] newConnectionThreshold = new int[]{ DEFAULT_NEW_CONNECTION_THRESHOLD, DEFAULT_NEW_CONNECTION_THRESHOLD, 0 };

    private volatile int maxRequestsPerConnectionLocal = DEFAULT_MAX_REQUESTS_PER_CONNECTION_LOCAL;
    private volatile int maxRequestsPerConnectionRemote = DEFAULT_MAX_REQUESTS_PER_CONNECTION_REMOTE;

    private volatile int idleTimeoutSeconds = DEFAULT_IDLE_TIMEOUT_SECONDS;
    private volatile int poolTimeoutMillis = DEFAULT_POOL_TIMEOUT_MILLIS;
    private volatile int heartbeatIntervalSeconds = DEFAULT_HEARTBEAT_INTERVAL_SECONDS;

    private volatile Executor initializationExecutor = DEFAULT_INITIALIZATION_EXECUTOR;

    public PoolingOptions() {}

    void register(Cluster.Manager manager) {
        this.manager = manager;
    }

    
    public int getCoreConnectionsPerHost(HostDistance distance) {
        return coreConnections[distance.ordinal()];
    }

    
    public synchronized PoolingOptions setCoreConnectionsPerHost(HostDistance distance, int newCoreConnections) {
        if (distance == HostDistance.IGNORED)
            throw new IllegalArgumentException("Cannot set core connections per host for " + distance + " hosts");

        checkConnectionsPerHostOrder(newCoreConnections, maxConnections[distance.ordinal()], distance);
        int oldCore = coreConnections[distance.ordinal()];
        coreConnections[distance.ordinal()] = newCoreConnections;
        if (oldCore < newCoreConnections && manager != null)
            manager.ensurePoolsSizing();
        return this;
    }

    
    public int getMaxConnectionsPerHost(HostDistance distance) {
        return maxConnections[distance.ordinal()];
    }

    
    public synchronized PoolingOptions setMaxConnectionsPerHost(HostDistance distance, int newMaxConnections) {
        if (distance == HostDistance.IGNORED)
            throw new IllegalArgumentException("Cannot set max connections per host for " + distance + " hosts");

        checkConnectionsPerHostOrder(coreConnections[distance.ordinal()], newMaxConnections, distance);
        maxConnections[distance.ordinal()] = newMaxConnections;
        return this;
    }

    
    public int getNewConnectionThreshold(HostDistance distance) {
        return newConnectionThreshold[distance.ordinal()];
    }

    
    public synchronized PoolingOptions setNewConnectionThreshold(HostDistance distance, int newValue) {
        if (distance == HostDistance.IGNORED)
            throw new IllegalArgumentException("Cannot set new connection threshold for " + distance + " hosts");

        checkRequestsPerConnectionRange(newValue, "New connection threshold", distance);
        newConnectionThreshold[distance.ordinal()] = newValue;
        return this;
    }

    
    public int getMaxRequestsPerConnection(HostDistance distance) {
        switch (distance) {
            case LOCAL:
                return maxRequestsPerConnectionLocal;
            case REMOTE:
                return maxRequestsPerConnectionRemote;
            default:
                return 0;
        }
    }

    
    public PoolingOptions setMaxRequestsPerConnection(HostDistance distance, int newMaxRequests) {
        if (newMaxRequests <= 0 || newMaxRequests > StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V3)
            throw new IllegalArgumentException(String.format("Max requests must be in the range (1, %d)",
                StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V3));

        switch (distance) {
            case LOCAL:
                maxRequestsPerConnectionLocal = newMaxRequests;
                break;
            case REMOTE:
                maxRequestsPerConnectionRemote = newMaxRequests;
                break;
            default:
                throw new IllegalArgumentException("Cannot set max requests per host for " + distance + " hosts");
        }
        return this;
    }

    
    public int getIdleTimeoutSeconds() {
        return idleTimeoutSeconds;
    }

    
    public PoolingOptions setIdleTimeoutSeconds(int idleTimeoutSeconds) {
        if (idleTimeoutSeconds < 0)
            throw new IllegalArgumentException("Idle timeout must be positive");
        this.idleTimeoutSeconds = idleTimeoutSeconds;
        return this;
    }

    
    public int getPoolTimeoutMillis() {
        return poolTimeoutMillis;
    }

    
    public PoolingOptions setPoolTimeoutMillis(int poolTimeoutMillis) {
        if (poolTimeoutMillis < 0)
            throw new IllegalArgumentException("Pool timeout must be positive");
        this.poolTimeoutMillis = poolTimeoutMillis;
        return this;
    }

    
    public int getHeartbeatIntervalSeconds() {
        return heartbeatIntervalSeconds;
    }

    
    public PoolingOptions setHeartbeatIntervalSeconds(int heartbeatIntervalSeconds) {
        if (heartbeatIntervalSeconds < 0)
            throw new IllegalArgumentException("Heartbeat interval must be positive");

        this.heartbeatIntervalSeconds = heartbeatIntervalSeconds;
        return this;
    }

    
    public Executor getInitializationExecutor() {
        return initializationExecutor;
    }

    
    public PoolingOptions setInitializationExecutor(Executor initializationExecutor) {
        Preconditions.checkNotNull(initializationExecutor);
        this.initializationExecutor = initializationExecutor;
        return this;
    }

    
    public void refreshConnectedHosts() {
        manager.refreshConnectedHosts();
    }

    
    public void refreshConnectedHost(Host host) {
        manager.refreshConnectedHost(host);
    }

    private static void checkRequestsPerConnectionRange(int value, String description, HostDistance distance) {
        if (value < 0 || value > StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2)
            throw new IllegalArgumentException(String.format("%s for %s hosts must be in the range (0, %d)",
                                                             description, distance,
                                                             StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2));
    }

    private static void checkConnectionsPerHostOrder(int core, int max, HostDistance distance) {
        if (core > max)
            throw new IllegalArgumentException(String.format("Core connections for %s hosts must be less than max (%d > %d)",
                                                             distance, core, max));
    }

    
    @Deprecated
    public int getMinSimultaneousRequestsPerConnectionThreshold(HostDistance distance) {
        return 0;
    }

    
    @Deprecated
    public synchronized PoolingOptions setMinSimultaneousRequestsPerConnectionThreshold(HostDistance distance, int newMinSimultaneousRequests) {
        return this;
    }

    
    @Deprecated
    public int getMaxSimultaneousRequestsPerConnectionThreshold(HostDistance distance) {
        return getNewConnectionThreshold(distance);
    }

    
    @Deprecated
    public PoolingOptions setMaxSimultaneousRequestsPerConnectionThreshold(HostDistance distance, int newMaxSimultaneousRequests) {
        return this.setNewConnectionThreshold(distance, newMaxSimultaneousRequests);
    }

    
    @Deprecated
    public int getMaxSimultaneousRequestsPerHostThreshold(HostDistance distance) {
        return this.getMaxRequestsPerConnection(distance);
    }

    
    @Deprecated
    public PoolingOptions setMaxSimultaneousRequestsPerHostThreshold(HostDistance distance, int newMaxRequests) {
        return this.setMaxRequestsPerConnection(distance, newMaxRequests);
    }
}

<code block>

package com.datastax.driver.core;


import java.util.ArrayList;
import java.util.List;
import java.util.Set;
import java.util.concurrent.CopyOnWriteArraySet;
import java.util.concurrent.Executor;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

import com.google.common.util.concurrent.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.datastax.driver.core.exceptions.AuthenticationException;
import com.datastax.driver.core.utils.MoreFutures;

import static com.datastax.driver.core.Connection.State.GONE;
import static com.datastax.driver.core.Connection.State.OPEN;
import static com.datastax.driver.core.Connection.State.TRASHED;


class SingleConnectionPool extends HostConnectionPool {

    private static final Logger logger = LoggerFactory.getLogger(SingleConnectionPool.class);

    
    
    
    private static final int MIN_AVAILABLE_STREAMS = 32768 * 3 / 4;

    volatile AtomicReference<Connection> connectionRef = new AtomicReference<Connection>();
    private final AtomicBoolean open = new AtomicBoolean();
    private final Set<Connection> trash = new CopyOnWriteArraySet<Connection>();

    private volatile int waiter = 0;
    private final Lock waitLock = new ReentrantLock(true);
    private final Condition hasAvailableConnection = waitLock.newCondition();

    private final Runnable newConnectionTask;

    private final AtomicBoolean scheduledForCreation = new AtomicBoolean();

    public SingleConnectionPool(Host host, HostDistance hostDistance, SessionManager manager) {
        super(host, hostDistance, manager);

        this.newConnectionTask = new Runnable() {
            @Override
            public void run() {
                addConnectionIfNeeded();
                scheduledForCreation.set(false);
            }
        };
    }

    @Override
    ListenableFuture<Void> initAsync(Connection reusedConnection) {
        final Connection connection;
        ListenableFuture<Void> connectionFuture;
        if (reusedConnection != null && reusedConnection.setPool(this)) {
            connection = reusedConnection;
            connectionFuture = MoreFutures.VOID_SUCCESS;
        } else {
            connection = manager.connectionFactory().newConnection(this);
            connectionFuture = connection.initAsync();
        }

        Executor initExecutor = manager.cluster.manager.configuration.getPoolingOptions().getInitializationExecutor();

        final SettableFuture<Void> initFuture = SettableFuture.create();
        Futures.addCallback(connectionFuture, new FutureCallback<Void>() {
            @Override
            public void onSuccess(Void result) {
                connectionRef.set(connection);
                open.set(true);
                if (isClosed()) {
                    initFuture.setException(new ConnectionException(host.getSocketAddress(), "Pool was closed during initialization"));
                    
                    connection.closeAsync().force();
                } else {
                    logger.trace("Created connection pool to host {}", host);
                    phase.compareAndSet(Phase.INITIALIZING, Phase.READY);
                    initFuture.set(null);
                }
            }

            @Override
            public void onFailure(Throwable t) {
                phase.compareAndSet(Phase.INITIALIZING, Phase.INIT_FAILED);
                initFuture.setException(t);
            }
        }, initExecutor);

        return initFuture;
    }

    private PoolingOptions options() {
        return manager.configuration().getPoolingOptions();
    }

    @Override
    public Connection borrowConnection(long timeout, TimeUnit unit) throws ConnectionException, TimeoutException {
        Phase phase = this.phase.get();
        if (phase != Phase.READY)
            
            
            throw new ConnectionException(host.getSocketAddress(), "Pool is " + phase);

        Connection connection = connectionRef.get();
        if (connection == null) {
            if (scheduledForCreation.compareAndSet(false, true))
                manager.blockingExecutor().submit(newConnectionTask);
            connection = waitForConnection(timeout, unit);
        } else {
            while (true) {
                int inFlight = connection.inFlight.get();

                if (inFlight >= Math.min(connection.maxAvailableStreams(),
                                         options().getMaxRequestsPerConnection(hostDistance))) {
                    connection = waitForConnection(timeout, unit);
                    break;
                }

                if (connection.inFlight.compareAndSet(inFlight, inFlight + 1))
                    break;
            }
        }
        connection.setKeyspace(manager.poolsState.keyspace);
        return connection;
    }

    private void awaitAvailableConnection(long timeout, TimeUnit unit) throws InterruptedException {
        waitLock.lock();
        waiter++;
        try {
            hasAvailableConnection.await(timeout, unit);
        } finally {
            waiter--;
            waitLock.unlock();
        }
    }

    private void signalAvailableConnection() {
        
        if (waiter == 0)
            return;

        waitLock.lock();
        try {
            hasAvailableConnection.signal();
        } finally {
            waitLock.unlock();
        }
    }

    private void signalAllAvailableConnection() {
        
        if (waiter == 0)
            return;

        waitLock.lock();
        try {
            hasAvailableConnection.signalAll();
        } finally {
            waitLock.unlock();
        }
    }

    private Connection waitForConnection(long timeout, TimeUnit unit) throws ConnectionException, TimeoutException {
        if (timeout == 0)
            throw new TimeoutException();

        long start = System.nanoTime();
        long remaining = timeout;
        do {
            try {
                awaitAvailableConnection(remaining, unit);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                
                timeout = 0; 
            }

            if (isClosed())
                throw new ConnectionException(host.getSocketAddress(), "Pool is shutdown");

            Connection connection = connectionRef.get();
            
            
            if (connection != null) {
                while (true) {
                    int inFlight = connection.inFlight.get();

                    if (inFlight >= Math.min(connection.maxAvailableStreams(),
                                             options().getMaxRequestsPerConnection(hostDistance)))
                        break;

                    if (connection.inFlight.compareAndSet(inFlight, inFlight + 1))
                        return connection;
                }
            }

            remaining = timeout - Cluster.timeSince(start, unit);
        } while (remaining > 0);

        throw new TimeoutException();
    }

    @Override
    public void returnConnection(Connection connection) {
        int inFlight = connection.inFlight.decrementAndGet();

        if (isClosed()) {
            close(connection);
            return;
        }

        if (connection.isDefunct()) {
            
            
            return;
        }

        if (trash.contains(connection)) {
            if (inFlight == 0 && trash.remove(connection))
                close(connection);
        } else {
            if (connection.maxAvailableStreams() < MIN_AVAILABLE_STREAMS) {
                replaceConnection(connection);
            } else {
                signalAvailableConnection();
            }
        }
    }

    
    
    private void replaceConnection(Connection connection) {
        if (!connection.state.compareAndSet(OPEN, TRASHED))
            return;
        open.set(false);
        maybeSpawnNewConnection();
        doTrashConnection(connection);
    }

    private void doTrashConnection(Connection connection) {
        connectionRef.compareAndSet(connection, null);
        trash.add(connection);

        if (connection.inFlight.get() == 0 && trash.remove(connection))
            close(connection);
    }

    private boolean addConnectionIfNeeded() {
        if (!open.compareAndSet(false, true))
            return false;

        if (phase.get() != Phase.READY) {
            open.set(false);
            return false;
        }

        
        try {
            logger.debug("Creating new connection on busy pool to {}", host);
            Connection newConnection = manager.connectionFactory().open(this);
            connectionRef.set(newConnection);

            
            if (isClosed() && !newConnection.isClosed()) {
                close(newConnection);
                this.open.set(false);
                return false;
            }

            signalAvailableConnection();
            return true;
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            
            open.set(false);
            return false;
        } catch (ConnectionException e) {
            open.set(false);
            logger.debug("Connection error to {} while creating additional connection", host);
            return false;
        } catch (AuthenticationException e) {
            
            open.set(false);
            logger.error("Authentication error while creating additional connection (error is: {})", e.getMessage());
            return false;
        } catch (UnsupportedProtocolVersionException e) {
            
            open.set(false);
            logger.error("UnsupportedProtocolVersionException error while creating additional connection (error is: {})", e.getMessage());
            return false;
        } catch (ClusterNameMismatchException e) {
            open.set(false);
            logger.error("ClusterNameMismatchException error while creating additional connection (error is: {})", e.getMessage());
            return false;
        }
    }

    private void maybeSpawnNewConnection() {
        if (!scheduledForCreation.compareAndSet(false, true))
            return;

        manager.blockingExecutor().submit(newConnectionTask);
    }

    @Override
    public void replaceDefunctConnection(final Connection connection) {
        if (connection.state.compareAndSet(OPEN, GONE))
            open.set(false);
        if (connectionRef.compareAndSet(connection, null))
            manager.blockingExecutor().submit(new Runnable() {
                @Override
                public void run() {
                    addConnectionIfNeeded();
                }
            });
    }

    @Override
    void cleanupIdleConnections(long now) {
    }

    private void close(final Connection connection) {
        connection.closeAsync();
    }

    protected CloseFuture makeCloseFuture() {
        
        signalAllAvailableConnection();

        return new CloseFuture.Forwarding(discardConnection());
    }

    private List<CloseFuture> discardConnection() {

        List<CloseFuture> futures = new ArrayList<CloseFuture>();

        final Connection connection = connectionRef.get();
        if (connection != null) {
            CloseFuture future = connection.closeAsync();
            future.addListener(new Runnable() {
                public void run() {
                    if (connection.state.compareAndSet(OPEN, GONE))
                        open.set(false);
                }
            }, MoreExecutors.sameThreadExecutor());
            futures.add(future);
        }
        return futures;
    }

    @Override
    public void ensureCoreConnections() {
        if (isClosed())
            return;

        if (!open.get() && scheduledForCreation.compareAndSet(false, true)) {
            manager.blockingExecutor().submit(newConnectionTask);
        }
    }

    @Override
    public int opened() {
        return open.get() ? 1 : 0;
    }

    @Override
    int trashed() {
        return trash.size();
    }

    @Override
    public int inFlightQueriesCount() {
        Connection connection = connectionRef.get();
        return connection == null ? 0 : connection.inFlight.get();
    }
}

<code block>

package com.datastax.driver.core;

import java.net.InetSocketAddress;
import java.util.Collection;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

import org.testng.annotations.Test;
import org.testng.collections.Lists;

import static org.testng.Assert.fail;

import com.datastax.driver.core.utils.CassandraVersion;

@CassandraVersion(major=2.1)
public class SingleConnectionPoolTest extends CCMBridge.PerClassSingleNodeCluster {
    @Override
    protected Collection<String> getTableDefinitions() {
        return Lists.newArrayList();
    }

    @Test(groups = "short")
    public void should_throttle_requests() {
        
        final int maxRequests = 10;
        cluster.getConfiguration().getPoolingOptions()
               .setMaxRequestsPerConnection(HostDistance.LOCAL, maxRequests);

        
        final AtomicBoolean excessInflightQueriesSpotted = new AtomicBoolean(false);
        final Host host = cluster.getMetadata().getHost(new InetSocketAddress(CCMBridge.IP_PREFIX + "1", 9042));
        ScheduledExecutorService openConnectionsWatcherExecutor = Executors.newScheduledThreadPool(1);
        final Runnable openConnectionsWatcher = new Runnable() {
            @Override
            public void run() {
                int inFlight = session.getState().getInFlightQueries(host);
                if (inFlight > maxRequests)
                    excessInflightQueriesSpotted.set(true);
            }
        };
        openConnectionsWatcherExecutor.scheduleAtFixedRate(openConnectionsWatcher, 200, 200, TimeUnit.MILLISECONDS);

        
        for (int i = 0; i < 10000; i++)
            session.executeAsync("SELECT release_version FROM system.local");

        openConnectionsWatcherExecutor.shutdownNow();
        if (excessInflightQueriesSpotted.get()) {
            fail("Inflight queries exceeded the limit");
        }
    }
}

<code block>

package com.datastax.driver.stress;

import java.io.IOException;
import java.util.*;

import com.datastax.driver.core.*;
import com.datastax.driver.core.exceptions.*;

import org.apache.log4j.PropertyConfigurator;

import joptsimple.*;


public class Stress {

    private static final Map<String, QueryGenerator.Builder> generators = new HashMap<String, QueryGenerator.Builder>();
    static {
        PropertyConfigurator.configure(System.getProperty("log4j.configuration", "./conf/log4j.properties"));

        QueryGenerator.Builder[] gs = new QueryGenerator.Builder[] {
            Generators.INSERTER,
            Generators.READER
        };

        for (QueryGenerator.Builder b : gs)
            register(b.name(), b);
    }

    private static OptionParser defaultParser() {
        OptionParser parser = new OptionParser() {{
            accepts("h", "Show this help message");
            accepts("n", "Number of requests to perform (default: unlimited)").withRequiredArg().ofType(Integer.class);
            accepts("t", "Level of concurrency to use").withRequiredArg().ofType(Integer.class).defaultsTo(50);
            accepts("async", "Make asynchronous requests instead of blocking ones");
            accepts("ip", "The hosts ip to connect to").withRequiredArg().ofType(String.class).defaultsTo("127.0.0.1");
            accepts("report-file", "The name of csv file to use for reporting results").withRequiredArg().ofType(String.class).defaultsTo("last.csv");
            accepts("print-delay", "The delay in seconds at which to report on the console").withRequiredArg().ofType(Integer.class).defaultsTo(5);
            accepts("compression", "Use compression (SNAPPY)");
            accepts("connections-per-host", "The number of connections per hosts (default: based on the number of threads)").withRequiredArg().ofType(Integer.class);
        }};
        String msg = "Where <generator> can be one of " + generators.keySet() + '\n'
                   + "You can get more help on a particular generator with: stress <generator> -h";
        parser.formatHelpWith(Help.formatFor("<generator>", msg));
        return parser;
    }

    public static void register(String name, QueryGenerator.Builder generator) {
        if (generators.containsKey(name))
            throw new IllegalStateException("There is already a generator registered with the name " + name);

        generators.put(name, generator);
    }

    private static class Stresser {
        private final QueryGenerator.Builder genBuilder;
        private final OptionParser parser;
        private final OptionSet options;

        private Stresser(QueryGenerator.Builder genBuilder, OptionParser parser, OptionSet options) {
            this.genBuilder = genBuilder;
            this.parser = parser;
            this.options = options;
        }

        public static Stresser forCommandLineArguments(String[] args) {
            OptionParser parser = defaultParser();

            String generatorName = findPotentialGenerator(args);
            if (generatorName == null) {
                
                OptionSet options = parseOptions(parser, args);
                System.err.println("Missing generator, you need to provide a generator.");
                printHelp(parser);
                System.exit(1);
            }

            if (!generators.containsKey(generatorName)) {
                System.err.println(String.format("Unknown generator '%s'", generatorName));
                printHelp(parser);
                System.exit(1);
            }

            QueryGenerator.Builder genBuilder = generators.get(generatorName);
            parser = genBuilder.addOptions(parser);
            OptionSet options = parseOptions(parser, args);

            List<?> nonOpts = options.nonOptionArguments();
            if (nonOpts.size() > 1) {
                System.err.println("Too many generators provided. Got " + nonOpts + " but only one generator supported.");
                printHelp(parser);
                System.exit(1);
            }

            return new Stresser(genBuilder, parser, options);
        }

        private static String findPotentialGenerator(String[] args) {
            for (String arg : args)
                if (!arg.startsWith("-"))
                    return arg;

            return null;
        }

        private static OptionSet parseOptions(OptionParser parser, String[] args) {
            try {
                OptionSet options = parser.parse(args);
                if (options.has("h")) {
                    printHelp(parser);
                    System.exit(0);
                }
                return options;
            } catch (Exception e) {
                System.err.println("Error parsing options: " + e.getMessage());
                printHelp(parser);
                System.exit(1);
                throw new AssertionError();
            }
        }

        private static void printHelp(OptionParser parser) {
            try {
                parser.printHelpOn(System.out);
            } catch (IOException e) {
                throw new AssertionError(e);
            }
        }

        public OptionSet getOptions() {
            return options;
        }

        public void prepare(Session session) {
            genBuilder.prepare(options, session);
        }

        public QueryGenerator newGenerator(int id, Session session, int iterations) {
            return genBuilder.create(id, iterations, options, session);
        }
    }

    public static class Help implements HelpFormatter {

        private final HelpFormatter defaultFormatter;
        private final String generator;
        private final String header;

        private Help(HelpFormatter defaultFormatter, String generator, String header) {
            this.defaultFormatter = defaultFormatter;
            this.generator = generator;
            this.header = header;
        }

        public static Help formatFor(String generator, String header) {
            
            
            int width = 120; 
            return new Help(new BuiltinHelpFormatter(width, 4), generator, header);
        }

        @Override
        public String format(Map<String, ? extends OptionDescriptor> options) {
            StringBuilder sb = new StringBuilder();

            sb.append("Usage: stress ").append(generator).append(" [<option>]*").append("\n\n");
            sb.append(header).append("\n\n");
            sb.append(defaultFormatter.format(options));
            return sb.toString();
        }
    }

    public static void main(String[] args) throws Exception {

        Stresser stresser = Stresser.forCommandLineArguments(args);
        OptionSet options = stresser.getOptions();

        int requests = options.has("n") ? (Integer)options.valueOf("n") : -1;
        int concurrency = (Integer)options.valueOf("t");

        String reportFileName = (String)options.valueOf("report-file");

        boolean async = options.has("async");

        int iterations = (requests  == -1 ? -1 : requests / concurrency);

        final int maxRequestsPerConnection = 128;
        int maxConnections = options.has("connections-per-host")
                           ? (Integer)options.valueOf("connections-per-host")
                           : concurrency / maxRequestsPerConnection + 1;

        PoolingOptions pools = new PoolingOptions();
        pools.setMaxSimultaneousRequestsPerConnectionThreshold(HostDistance.LOCAL, concurrency);
        pools.setCoreConnectionsPerHost(HostDistance.LOCAL, maxConnections);
        pools.setMaxConnectionsPerHost(HostDistance.LOCAL, maxConnections);
        pools.setCoreConnectionsPerHost(HostDistance.REMOTE, maxConnections);
        pools.setMaxConnectionsPerHost(HostDistance.REMOTE, maxConnections);

        System.out.println("Initializing stress test:");
        System.out.println("  request count:        " + (requests == -1 ? "unlimited" : requests));
        System.out.println("  concurrency:          " + concurrency + " (" + iterations + " requests/thread)");
        System.out.println("  mode:                 " + (async ? "asynchronous" : "blocking"));
        System.out.println("  per-host connections: " + maxConnections);
        System.out.println("  compression:          " + options.has("compression"));

        try {
            
            Cluster cluster = new Cluster.Builder()
                                         .addContactPoints(String.valueOf(options.valueOf("ip")))
                                         .withPoolingOptions(pools)
                                         .withSocketOptions(new SocketOptions().setTcpNoDelay(true))
                                         .build();

            if (options.has("compression"))
                cluster.getConfiguration().getProtocolOptions().setCompression(ProtocolOptions.Compression.SNAPPY);

            Session session = cluster.connect();

            Metadata metadata = cluster.getMetadata();
            System.out.println(String.format("Connected to cluster '%s' on %s.", metadata.getClusterName(), metadata.getAllHosts()));

            System.out.println("Preparing test...");
            stresser.prepare(session);

            Reporter reporter = new Reporter((Integer)options.valueOf("print-delay"), reportFileName, args, requests);

            Consumer[] consumers = new Consumer[concurrency];
            for (int i = 0; i < concurrency; i++) {
                QueryGenerator generator = stresser.newGenerator(i, session, iterations);
                consumers[i] = async ? new AsynchronousConsumer(session, generator, reporter) :
                                       new BlockingConsumer(session, generator, reporter);
            }

            System.out.println("Starting to stress test...");
            System.out.println();

            reporter.start();

            for (Consumer consumer : consumers)
                consumer.start();

            for (Consumer consumer : consumers)
                consumer.join();

            reporter.stop();

            System.out.println("Stress test successful.");
            System.exit(0);

        } catch (NoHostAvailableException e) {
            System.err.println("No alive hosts to use: " + e.getMessage());
            System.exit(1);
        } catch (Exception e) {
            System.err.println("Unexpected error: " + e.getMessage());
            e.printStackTrace();
            System.exit(1);
        }
    }
}

<code block>

package com.datastax.driver.core;


import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.locks.*;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.collect.Lists;
import com.google.common.util.concurrent.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.datastax.driver.core.exceptions.AuthenticationException;
import com.datastax.driver.core.utils.MoreFutures;

import static com.datastax.driver.core.Connection.State.*;


class DynamicConnectionPool extends HostConnectionPool {

    private static final Logger logger = LoggerFactory.getLogger(DynamicConnectionPool.class);

    private static final int MAX_SIMULTANEOUS_CREATION = 1;

    
    
    
    private static final int MIN_AVAILABLE_STREAMS = 96;

    final List<Connection> connections;
    private final AtomicInteger open;
    
    final AtomicInteger totalInFlight = new AtomicInteger();
    
    private final AtomicInteger maxTotalInFlight = new AtomicInteger();

    @VisibleForTesting
    final Set<Connection> trash = new CopyOnWriteArraySet<Connection>();

    private volatile int waiter = 0;
    private final Lock waitLock = new ReentrantLock(true);
    private final Condition hasAvailableConnection = waitLock.newCondition();

    private final Runnable newConnectionTask;

    private final AtomicInteger scheduledForCreation = new AtomicInteger();

    public DynamicConnectionPool(Host host, HostDistance hostDistance, SessionManager manager) {
        super(host, hostDistance, manager);

        this.newConnectionTask = new Runnable() {
            @Override
            public void run() {
                addConnectionIfUnderMaximum();
                scheduledForCreation.decrementAndGet();
            }
        };

        this.connections = new CopyOnWriteArrayList<Connection>();
        this.open = new AtomicInteger();
    }

    @Override
    ListenableFuture<Void> initAsync(Connection reusedConnection) {
        
        int capacity = options().getCoreConnectionsPerHost(hostDistance);
        final List<Connection> connections = Lists.newArrayListWithCapacity(capacity);
        final List<ListenableFuture<Void>> connectionFutures = Lists.newArrayListWithCapacity(capacity);
        for (int i = 0; i < capacity; i++) {
            Connection connection;
            ListenableFuture<Void> connectionFuture;
            
            if (reusedConnection != null && reusedConnection.setPool(this)) {
                connection = reusedConnection;
                connectionFuture = MoreFutures.VOID_SUCCESS;
            } else {
                connection = manager.connectionFactory().newConnection(this);
                connectionFuture = connection.initAsync();
            }
            reusedConnection = null;
            connections.add(connection);
            connectionFutures.add(connectionFuture);
        }

        Executor initExecutor = manager.cluster.manager.configuration.getPoolingOptions().getInitializationExecutor();

        ListenableFuture<List<Void>> allConnectionsFuture = Futures.allAsList(connectionFutures);

        final SettableFuture<Void> initFuture = SettableFuture.create();
        Futures.addCallback(allConnectionsFuture, new FutureCallback<List<Void>>() {
            @Override
            public void onSuccess(List<Void> l) {
                DynamicConnectionPool.this.connections.addAll(connections);
                open.set(l.size());
                if (isClosed()) {
                    initFuture.setException(new ConnectionException(host.getSocketAddress(), "Pool was closed during initialization"));
                    
                    forceClose(connections);
                } else {
                    logger.trace("Created connection pool to host {}", host);
                    phase.compareAndSet(Phase.INITIALIZING, Phase.READY);
                    initFuture.set(null);
                }
            }

            @Override
            public void onFailure(Throwable t) {
                phase.compareAndSet(Phase.INITIALIZING, Phase.INIT_FAILED);
                forceClose(connections);
                initFuture.setException(t);
            }
        }, initExecutor);
        return initFuture;
    }

    
    private void forceClose(List<Connection> connections) {
        for (Connection connection : connections) {
            connection.closeAsync().force();
        }
    }

    private PoolingOptions options() {
        return manager.configuration().getPoolingOptions();
    }

    @Override
    public Connection borrowConnection(long timeout, TimeUnit unit) throws ConnectionException, TimeoutException {
        Phase phase = this.phase.get();
        if (phase != Phase.READY)
            
            
            throw new ConnectionException(host.getSocketAddress(), "Pool is " + phase);

        if (connections.isEmpty()) {
            for (int i = 0; i < options().getCoreConnectionsPerHost(hostDistance); i++) {
                
                
                scheduledForCreation.incrementAndGet();
                manager.blockingExecutor().submit(newConnectionTask);
            }
            Connection c = waitForConnection(timeout, unit);
            totalInFlight.incrementAndGet();
            c.setKeyspace(manager.poolsState.keyspace);
            return c;
        }

        int minInFlight = Integer.MAX_VALUE;
        Connection leastBusy = null;
        for (Connection connection : connections) {
            int inFlight = connection.inFlight.get();
            if (inFlight < minInFlight) {
                minInFlight = inFlight;
                leastBusy = connection;
            }
        }

        if (leastBusy == null) {
            
            if (isClosed())
                throw new ConnectionException(host.getSocketAddress(), "Pool is shutdown");
            
            
            
            leastBusy = waitForConnection(timeout, unit);
        } else {
            while (true) {
                int inFlight = leastBusy.inFlight.get();

                if (inFlight >= leastBusy.maxAvailableStreams()) {
                    leastBusy = waitForConnection(timeout, unit);
                    break;
                }

                if (leastBusy.inFlight.compareAndSet(inFlight, inFlight + 1))
                    break;
            }
        }

        int totalInFlightCount = totalInFlight.incrementAndGet();
        
        while (true) {
            int oldMax = maxTotalInFlight.get();
            if (totalInFlightCount <= oldMax || maxTotalInFlight.compareAndSet(oldMax, totalInFlightCount))
                break;
        }

        int connectionCount = open.get() + scheduledForCreation.get();
        if (connectionCount < options().getMaxConnectionsPerHost(hostDistance)) {
            
            int currentCapacity = (connectionCount - 1) * StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2
                + options().getMaxSimultaneousRequestsPerConnectionThreshold(hostDistance);
            if (totalInFlightCount > currentCapacity)
                maybeSpawnNewConnection();
        }

        leastBusy.setKeyspace(manager.poolsState.keyspace);
        return leastBusy;
    }

    private void awaitAvailableConnection(long timeout, TimeUnit unit) throws InterruptedException {
        waitLock.lock();
        waiter++;
        try {
            hasAvailableConnection.await(timeout, unit);
        } finally {
            waiter--;
            waitLock.unlock();
        }
    }

    private void signalAvailableConnection() {
        
        if (waiter == 0)
            return;

        waitLock.lock();
        try {
            hasAvailableConnection.signal();
        } finally {
            waitLock.unlock();
        }
    }

    private void signalAllAvailableConnection() {
        
        if (waiter == 0)
            return;

        waitLock.lock();
        try {
            hasAvailableConnection.signalAll();
        } finally {
            waitLock.unlock();
        }
    }

    private Connection waitForConnection(long timeout, TimeUnit unit) throws ConnectionException, TimeoutException {
        if (timeout == 0)
            throw new TimeoutException();

        long start = System.nanoTime();
        long remaining = timeout;
        do {
            try {
                awaitAvailableConnection(remaining, unit);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                
                timeout = 0; 
            }

            if (isClosed())
                throw new ConnectionException(host.getSocketAddress(), "Pool is shutdown");

            int minInFlight = Integer.MAX_VALUE;
            Connection leastBusy = null;
            for (Connection connection : connections) {
                int inFlight = connection.inFlight.get();
                if (inFlight < minInFlight) {
                    minInFlight = inFlight;
                    leastBusy = connection;
                }
            }

            
            
            if (leastBusy != null) {
                while (true) {
                    int inFlight = leastBusy.inFlight.get();

                    if (inFlight >= leastBusy.maxAvailableStreams())
                        break;

                    if (leastBusy.inFlight.compareAndSet(inFlight, inFlight + 1))
                        return leastBusy;
                }
            }

            remaining = timeout - Cluster.timeSince(start, unit);
        } while (remaining > 0);

        throw new TimeoutException();
    }

    @Override
    public void returnConnection(Connection connection) {
        connection.inFlight.decrementAndGet();
        totalInFlight.decrementAndGet();

        if (isClosed()) {
            close(connection);
            return;
        }

        if (connection.isDefunct()) {
            
            
            return;
        }

        if (connection.state.get() != TRASHED) {
            if (connection.maxAvailableStreams() < MIN_AVAILABLE_STREAMS) {
                replaceConnection(connection);
            } else {
                signalAvailableConnection();
            }
        }
    }

    
    
    private void replaceConnection(Connection connection) {
        if (!connection.state.compareAndSet(OPEN, TRASHED))
            return;
        open.decrementAndGet();
        maybeSpawnNewConnection();
        connection.maxIdleTime = Long.MIN_VALUE;
        doTrashConnection(connection);
    }

    private boolean trashConnection(Connection connection) {
        if (!connection.state.compareAndSet(OPEN, TRASHED))
            return true;

        
        for (;;) {
            int opened = open.get();
            if (opened <= options().getCoreConnectionsPerHost(hostDistance)) {
                connection.state.set(OPEN);
                return false;
            }

            if (open.compareAndSet(opened, opened - 1))
                break;
        }
        logger.trace("Trashing {}", connection);
        connection.maxIdleTime = System.currentTimeMillis() + options().getIdleTimeoutSeconds() * 1000;
        doTrashConnection(connection);
        return true;
    }

    private void doTrashConnection(Connection connection) {
        connections.remove(connection);
        trash.add(connection);
    }

    private boolean addConnectionIfUnderMaximum() {

        
        for(;;) {
            int opened = open.get();
            if (opened >= options().getMaxConnectionsPerHost(hostDistance))
                return false;

            if (open.compareAndSet(opened, opened + 1))
                break;
        }

        if (phase.get() != Phase.READY) {
            open.decrementAndGet();
            return false;
        }

        
        try {
            Connection newConnection = tryResurrectFromTrash();
            if (newConnection == null) {
                logger.debug("Creating new connection on busy pool to {}", host);
                newConnection = manager.connectionFactory().open(this);
            }
            connections.add(newConnection);

            newConnection.state.compareAndSet(RESURRECTING, OPEN); 

            
            if (isClosed() && !newConnection.isClosed()) {
                close(newConnection);
                open.decrementAndGet();
                return false;
            }

            signalAvailableConnection();
            return true;
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            
            open.decrementAndGet();
            return false;
        } catch (ConnectionException e) {
            open.decrementAndGet();
            logger.debug("Connection error to {} while creating additional connection", host);
            return false;
        } catch (AuthenticationException e) {
            
            open.decrementAndGet();
            logger.error("Authentication error while creating additional connection (error is: {})", e.getMessage());
            return false;
        } catch (UnsupportedProtocolVersionException e) {
            
            open.decrementAndGet();
            logger.error("UnsupportedProtocolVersionException error while creating additional connection (error is: {})", e.getMessage());
            return false;
        } catch (ClusterNameMismatchException e) {
            open.decrementAndGet();
            logger.error("ClusterNameMismatchException error while creating additional connection (error is: {})", e.getMessage());
            return false;
        }
    }

    private Connection tryResurrectFromTrash() {
        long highestMaxIdleTime = System.currentTimeMillis();
        Connection chosen = null;

        while (true) {
            for (Connection connection : trash)
                if (connection.maxIdleTime > highestMaxIdleTime && connection.maxAvailableStreams() > MIN_AVAILABLE_STREAMS) {
                    chosen = connection;
                    highestMaxIdleTime = connection.maxIdleTime;
                }

            if (chosen == null)
                return null;
            else if (chosen.state.compareAndSet(TRASHED, RESURRECTING))
                break;
        }
        logger.trace("Resurrecting {}", chosen);
        trash.remove(chosen);
        return chosen;
    }

    private void maybeSpawnNewConnection() {
        while (true) {
            int inCreation = scheduledForCreation.get();
            if (inCreation >= MAX_SIMULTANEOUS_CREATION)
                return;
            if (scheduledForCreation.compareAndSet(inCreation, inCreation + 1))
                break;
        }

        manager.blockingExecutor().submit(newConnectionTask);
    }

    @Override
    void replaceDefunctConnection(final Connection connection) {
        if (connection.state.compareAndSet(OPEN, GONE))
            open.decrementAndGet();
        if (connections.remove(connection))
            manager.blockingExecutor().submit(new Runnable() {
                @Override
                public void run() {
                    addConnectionIfUnderMaximum();
                }
            });
    }

    @Override
    void cleanupIdleConnections(long now) {
        if (isClosed())
            return;

        shrinkIfBelowCapacity();
        cleanupTrash(now);
    }

    
    private void shrinkIfBelowCapacity() {
        int currentLoad = maxTotalInFlight.getAndSet(totalInFlight.get());

        int needed = currentLoad / StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2 + 1;
        if (currentLoad % StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2 > options().getMaxSimultaneousRequestsPerConnectionThreshold(hostDistance))
            needed += 1;
        needed = Math.max(needed, options().getCoreConnectionsPerHost(hostDistance));
        int actual = open.get();
        int toTrash = Math.max(0, actual - needed);

        logger.trace("Current inFlight = {}, {} connections needed, {} connections available, trashing {}",
            currentLoad, needed, actual, toTrash);

        if (toTrash <= 0)
            return;

        for (Connection connection : connections)
            if (trashConnection(connection)) {
                toTrash -= 1;
                if (toTrash == 0)
                    return;
            }
    }

    
    private void cleanupTrash(long now) {
        for (Connection connection : trash) {
            if (connection.maxIdleTime < now && connection.state.compareAndSet(TRASHED, GONE)) {
                if (connection.inFlight.get() == 0) {
                    logger.trace("Cleaning up {}", connection);
                    trash.remove(connection);
                    close(connection);
                } else {
                    
                    
                    
                    connection.state.set(TRASHED);
                }
            }
        }
    }

    private void close(final Connection connection) {
        connection.closeAsync();
    }

    protected CloseFuture makeCloseFuture() {
        
        signalAllAvailableConnection();

        return new CloseFuture.Forwarding(discardAvailableConnections());
    }

    private List<CloseFuture> discardAvailableConnections() {
        
        

        List<CloseFuture> futures = new ArrayList<CloseFuture>(connections.size() + trash.size());

        for (final Connection connection : connections) {
            CloseFuture future = connection.closeAsync();
            future.addListener(new Runnable() {
                public void run() {
                    if (connection.state.compareAndSet(OPEN, GONE))
                        open.decrementAndGet();
                }
            }, MoreExecutors.sameThreadExecutor());
            futures.add(future);
        }

        
        for (Connection connection : trash)
            futures.add(connection.closeAsync());

        return futures;
    }

    
    
    @Override
    public void ensureCoreConnections() {
        if (isClosed())
            return;

        
        
        
        int opened = open.get();
        for (int i = opened; i < options().getCoreConnectionsPerHost(hostDistance); i++) {
            
            
            scheduledForCreation.incrementAndGet();
            manager.blockingExecutor().submit(newConnectionTask);
        }
    }

    @Override
    public int opened() {
        return open.get();
    }

    @Override
    int trashed() {
        return trash.size();
    }

    @Override
    public int inFlightQueriesCount() {
        int count = 0;
        for (Connection connection : connections) {
            count += connection.inFlight.get();
        }
        return count;
    }
}

<code block>

package com.datastax.driver.core;

import java.util.concurrent.Executor;

import com.google.common.base.Preconditions;
import com.google.common.util.concurrent.MoreExecutors;


public class PoolingOptions {

    private static final int DEFAULT_MAX_REQUESTS_PER_CONNECTION = 100;

    private static final int DEFAULT_CORE_POOL_LOCAL = 2;
    private static final int DEFAULT_CORE_POOL_REMOTE = 1;

    private static final int DEFAULT_MAX_POOL_LOCAL = 8;
    private static final int DEFAULT_MAX_POOL_REMOTE = 2;

    private static final int DEFAULT_MAX_REQUESTS_PER_HOST_LOCAL = 1024;
    private static final int DEFAULT_MAX_REQUESTS_PER_HOST_REMOTE = 256;

    private static final int DEFAULT_IDLE_TIMEOUT_SECONDS = 120;
    private static final int DEFAULT_POOL_TIMEOUT_MILLIS = 5000;
    private static final int DEFAULT_HEARTBEAT_INTERVAL_SECONDS = 30;

    private static final Executor DEFAULT_INITIALIZATION_EXECUTOR = MoreExecutors.sameThreadExecutor();

    private volatile Cluster.Manager manager;

    private final int[] maxSimultaneousRequestsPerConnection = new int[]{ DEFAULT_MAX_REQUESTS_PER_CONNECTION, DEFAULT_MAX_REQUESTS_PER_CONNECTION, 0 };

    private final int[] coreConnections = new int[] { DEFAULT_CORE_POOL_LOCAL, DEFAULT_CORE_POOL_REMOTE, 0 };
    private final int[] maxConnections = new int[] { DEFAULT_MAX_POOL_LOCAL , DEFAULT_MAX_POOL_REMOTE, 0 };

    private volatile int maxSimultaneousRequestsPerHostLocal = DEFAULT_MAX_REQUESTS_PER_HOST_LOCAL;
    private volatile int maxSimultaneousRequestsPerHostRemote = DEFAULT_MAX_REQUESTS_PER_HOST_REMOTE;
    
    private volatile int idleTimeoutSeconds = DEFAULT_IDLE_TIMEOUT_SECONDS;
    private volatile int poolTimeoutMillis = DEFAULT_POOL_TIMEOUT_MILLIS;
    private volatile int heartbeatIntervalSeconds = DEFAULT_HEARTBEAT_INTERVAL_SECONDS;

    private volatile Executor initializationExecutor = DEFAULT_INITIALIZATION_EXECUTOR;

    public PoolingOptions() {}

    void register(Cluster.Manager manager) {
        this.manager = manager;
    }

    
    @Deprecated
    public int getMinSimultaneousRequestsPerConnectionThreshold(HostDistance distance) {
        return 0;
    }

    
    @Deprecated
    public synchronized PoolingOptions setMinSimultaneousRequestsPerConnectionThreshold(HostDistance distance, int newMinSimultaneousRequests) {
        return this;
    }

    
    public int getMaxSimultaneousRequestsPerConnectionThreshold(HostDistance distance) {
        return maxSimultaneousRequestsPerConnection[distance.ordinal()];
    }

    
    public synchronized PoolingOptions setMaxSimultaneousRequestsPerConnectionThreshold(HostDistance distance, int newMaxSimultaneousRequests) {
        if (distance == HostDistance.IGNORED)
            throw new IllegalArgumentException("Cannot set max simultaneous requests per connection threshold for " + distance + " hosts");

        checkRequestsPerConnectionRange(newMaxSimultaneousRequests, "Max simultaneous requests per connection", distance);
        maxSimultaneousRequestsPerConnection[distance.ordinal()] = newMaxSimultaneousRequests;
        return this;
    }

    
    public int getCoreConnectionsPerHost(HostDistance distance) {
        return coreConnections[distance.ordinal()];
    }

    
    public synchronized PoolingOptions setCoreConnectionsPerHost(HostDistance distance, int newCoreConnections) {
        if (distance == HostDistance.IGNORED)
                throw new IllegalArgumentException("Cannot set core connections per host for " + distance + " hosts");

        checkConnectionsPerHostOrder(newCoreConnections, maxConnections[distance.ordinal()], distance);
        int oldCore = coreConnections[distance.ordinal()];
        coreConnections[distance.ordinal()] = newCoreConnections;
        if (oldCore < newCoreConnections && manager != null)
            manager.ensurePoolsSizing();
        return this;
    }

    
    public int getMaxConnectionsPerHost(HostDistance distance) {
        return maxConnections[distance.ordinal()];
    }

    
    public synchronized PoolingOptions setMaxConnectionsPerHost(HostDistance distance, int newMaxConnections) {
        if (distance == HostDistance.IGNORED)
            throw new IllegalArgumentException("Cannot set max connections per host for " + distance + " hosts");

        checkConnectionsPerHostOrder(coreConnections[distance.ordinal()], newMaxConnections, distance);
        maxConnections[distance.ordinal()] = newMaxConnections;
        return this;
    }

    
    public int getIdleTimeoutSeconds() {
        return idleTimeoutSeconds;
    }

    
    public PoolingOptions setIdleTimeoutSeconds(int idleTimeoutSeconds) {
        if (idleTimeoutSeconds < 0)
            throw new IllegalArgumentException("Idle timeout must be positive");
        this.idleTimeoutSeconds = idleTimeoutSeconds;
        return this;
    }

    
    public int getPoolTimeoutMillis() {
        return poolTimeoutMillis;
    }

    
    public PoolingOptions setPoolTimeoutMillis(int poolTimeoutMillis) {
        if (poolTimeoutMillis < 0)
            throw new IllegalArgumentException("Pool timeout must be positive");
        this.poolTimeoutMillis = poolTimeoutMillis;
        return this;
    }

    
    public int getHeartbeatIntervalSeconds() {
        return heartbeatIntervalSeconds;
    }

    
    public PoolingOptions setHeartbeatIntervalSeconds(int heartbeatIntervalSeconds) {
        if (heartbeatIntervalSeconds < 0)
            throw new IllegalArgumentException("Heartbeat interval must be positive");

        this.heartbeatIntervalSeconds = heartbeatIntervalSeconds;
        return this;
    }

    
    public int getMaxSimultaneousRequestsPerHostThreshold(HostDistance distance) {
        switch (distance) {
            case LOCAL:
                return maxSimultaneousRequestsPerHostLocal;
            case REMOTE:
                return maxSimultaneousRequestsPerHostRemote;
            default:
                return 0;
        }
    }

    
    public PoolingOptions setMaxSimultaneousRequestsPerHostThreshold(HostDistance distance, int newMaxRequests) {
        if (newMaxRequests <= 0 || newMaxRequests > StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V3)
            throw new IllegalArgumentException(String.format("Max requests must be in the range (1, %d)",
                                               StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V3));

        switch (distance) {
            case LOCAL:
                maxSimultaneousRequestsPerHostLocal = newMaxRequests;
                break;
            case REMOTE:
                maxSimultaneousRequestsPerHostRemote = newMaxRequests;
                break;
            default:
                throw new IllegalArgumentException("Cannot set max requests per host for " + distance + " hosts");
        }
        return this;
    }

    
    public Executor getInitializationExecutor() {
        return initializationExecutor;
    }

    
    public PoolingOptions setInitializationExecutor(Executor initializationExecutor) {
        Preconditions.checkNotNull(initializationExecutor);
        this.initializationExecutor = initializationExecutor;
        return this;
    }

    
    public void refreshConnectedHosts() {
        manager.refreshConnectedHosts();
    }

    
    public void refreshConnectedHost(Host host) {
        manager.refreshConnectedHost(host);
    }

    private static void checkRequestsPerConnectionRange(int value, String description, HostDistance distance) {
        if (value < 0 || value > StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2)
            throw new IllegalArgumentException(String.format("%s for %s hosts must be in the range (0, %d)",
                                                             description, distance,
                                                             StreamIdGenerator.MAX_STREAM_PER_CONNECTION_V2));
    }

    private static void checkConnectionsPerHostOrder(int core, int max, HostDistance distance) {
        if (core > max)
            throw new IllegalArgumentException(String.format("Core connections for %s hosts must be less than max (%d > %d)",
                                                             distance, core, max));
    }
}

<code block>

package com.datastax.driver.core;


import java.util.ArrayList;
import java.util.List;
import java.util.Set;
import java.util.concurrent.CopyOnWriteArraySet;
import java.util.concurrent.Executor;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

import com.google.common.util.concurrent.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.datastax.driver.core.exceptions.AuthenticationException;
import com.datastax.driver.core.utils.MoreFutures;

import static com.datastax.driver.core.Connection.State.GONE;
import static com.datastax.driver.core.Connection.State.OPEN;
import static com.datastax.driver.core.Connection.State.TRASHED;


class SingleConnectionPool extends HostConnectionPool {

    private static final Logger logger = LoggerFactory.getLogger(SingleConnectionPool.class);

    
    
    
    private static final int MIN_AVAILABLE_STREAMS = 32768 * 3 / 4;

    volatile AtomicReference<Connection> connectionRef = new AtomicReference<Connection>();
    private final AtomicBoolean open = new AtomicBoolean();
    private final Set<Connection> trash = new CopyOnWriteArraySet<Connection>();

    private volatile int waiter = 0;
    private final Lock waitLock = new ReentrantLock(true);
    private final Condition hasAvailableConnection = waitLock.newCondition();

    private final Runnable newConnectionTask;

    private final AtomicBoolean scheduledForCreation = new AtomicBoolean();

    public SingleConnectionPool(Host host, HostDistance hostDistance, SessionManager manager) {
        super(host, hostDistance, manager);

        this.newConnectionTask = new Runnable() {
            @Override
            public void run() {
                addConnectionIfNeeded();
                scheduledForCreation.set(false);
            }
        };
    }

    @Override
    ListenableFuture<Void> initAsync(Connection reusedConnection) {
        final Connection connection;
        ListenableFuture<Void> connectionFuture;
        if (reusedConnection != null && reusedConnection.setPool(this)) {
            connection = reusedConnection;
            connectionFuture = MoreFutures.VOID_SUCCESS;
        } else {
            connection = manager.connectionFactory().newConnection(this);
            connectionFuture = connection.initAsync();
        }

        Executor initExecutor = manager.cluster.manager.configuration.getPoolingOptions().getInitializationExecutor();

        final SettableFuture<Void> initFuture = SettableFuture.create();
        Futures.addCallback(connectionFuture, new FutureCallback<Void>() {
            @Override
            public void onSuccess(Void result) {
                connectionRef.set(connection);
                open.set(true);
                if (isClosed()) {
                    initFuture.setException(new ConnectionException(host.getSocketAddress(), "Pool was closed during initialization"));
                    
                    connection.closeAsync().force();
                } else {
                    logger.trace("Created connection pool to host {}", host);
                    phase.compareAndSet(Phase.INITIALIZING, Phase.READY);
                    initFuture.set(null);
                }
            }

            @Override
            public void onFailure(Throwable t) {
                phase.compareAndSet(Phase.INITIALIZING, Phase.INIT_FAILED);
                initFuture.setException(t);
            }
        }, initExecutor);

        return initFuture;
    }

    private PoolingOptions options() {
        return manager.configuration().getPoolingOptions();
    }

    @Override
    public Connection borrowConnection(long timeout, TimeUnit unit) throws ConnectionException, TimeoutException {
        Phase phase = this.phase.get();
        if (phase != Phase.READY)
            
            
            throw new ConnectionException(host.getSocketAddress(), "Pool is " + phase);

        Connection connection = connectionRef.get();
        if (connection == null) {
            if (scheduledForCreation.compareAndSet(false, true))
                manager.blockingExecutor().submit(newConnectionTask);
            connection = waitForConnection(timeout, unit);
        } else {
            while (true) {
                int inFlight = connection.inFlight.get();

                if (inFlight >= Math.min(connection.maxAvailableStreams(),
                                         options().getMaxSimultaneousRequestsPerHostThreshold(hostDistance))) {
                    connection = waitForConnection(timeout, unit);
                    break;
                }

                if (connection.inFlight.compareAndSet(inFlight, inFlight + 1))
                    break;
            }
        }
        connection.setKeyspace(manager.poolsState.keyspace);
        return connection;
    }

    private void awaitAvailableConnection(long timeout, TimeUnit unit) throws InterruptedException {
        waitLock.lock();
        waiter++;
        try {
            hasAvailableConnection.await(timeout, unit);
        } finally {
            waiter--;
            waitLock.unlock();
        }
    }

    private void signalAvailableConnection() {
        
        if (waiter == 0)
            return;

        waitLock.lock();
        try {
            hasAvailableConnection.signal();
        } finally {
            waitLock.unlock();
        }
    }

    private void signalAllAvailableConnection() {
        
        if (waiter == 0)
            return;

        waitLock.lock();
        try {
            hasAvailableConnection.signalAll();
        } finally {
            waitLock.unlock();
        }
    }

    private Connection waitForConnection(long timeout, TimeUnit unit) throws ConnectionException, TimeoutException {
        if (timeout == 0)
            throw new TimeoutException();

        long start = System.nanoTime();
        long remaining = timeout;
        do {
            try {
                awaitAvailableConnection(remaining, unit);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                
                timeout = 0; 
            }

            if (isClosed())
                throw new ConnectionException(host.getSocketAddress(), "Pool is shutdown");

            Connection connection = connectionRef.get();
            
            
            if (connection != null) {
                while (true) {
                    int inFlight = connection.inFlight.get();

                    if (inFlight >= Math.min(connection.maxAvailableStreams(),
                                             options().getMaxSimultaneousRequestsPerHostThreshold(hostDistance)))
                        break;

                    if (connection.inFlight.compareAndSet(inFlight, inFlight + 1))
                        return connection;
                }
            }

            remaining = timeout - Cluster.timeSince(start, unit);
        } while (remaining > 0);

        throw new TimeoutException();
    }

    @Override
    public void returnConnection(Connection connection) {
        int inFlight = connection.inFlight.decrementAndGet();

        if (isClosed()) {
            close(connection);
            return;
        }

        if (connection.isDefunct()) {
            
            
            return;
        }

        if (trash.contains(connection)) {
            if (inFlight == 0 && trash.remove(connection))
                close(connection);
        } else {
            if (connection.maxAvailableStreams() < MIN_AVAILABLE_STREAMS) {
                replaceConnection(connection);
            } else {
                signalAvailableConnection();
            }
        }
    }

    
    
    private void replaceConnection(Connection connection) {
        if (!connection.state.compareAndSet(OPEN, TRASHED))
            return;
        open.set(false);
        maybeSpawnNewConnection();
        doTrashConnection(connection);
    }

    private void doTrashConnection(Connection connection) {
        connectionRef.compareAndSet(connection, null);
        trash.add(connection);

        if (connection.inFlight.get() == 0 && trash.remove(connection))
            close(connection);
    }

    private boolean addConnectionIfNeeded() {
        if (!open.compareAndSet(false, true))
            return false;

        if (phase.get() != Phase.READY) {
            open.set(false);
            return false;
        }

        
        try {
            logger.debug("Creating new connection on busy pool to {}", host);
            Connection newConnection = manager.connectionFactory().open(this);
            connectionRef.set(newConnection);

            
            if (isClosed() && !newConnection.isClosed()) {
                close(newConnection);
                this.open.set(false);
                return false;
            }

            signalAvailableConnection();
            return true;
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            
            open.set(false);
            return false;
        } catch (ConnectionException e) {
            open.set(false);
            logger.debug("Connection error to {} while creating additional connection", host);
            return false;
        } catch (AuthenticationException e) {
            
            open.set(false);
            logger.error("Authentication error while creating additional connection (error is: {})", e.getMessage());
            return false;
        } catch (UnsupportedProtocolVersionException e) {
            
            open.set(false);
            logger.error("UnsupportedProtocolVersionException error while creating additional connection (error is: {})", e.getMessage());
            return false;
        } catch (ClusterNameMismatchException e) {
            open.set(false);
            logger.error("ClusterNameMismatchException error while creating additional connection (error is: {})", e.getMessage());
            return false;
        }
    }

    private void maybeSpawnNewConnection() {
        if (!scheduledForCreation.compareAndSet(false, true))
            return;

        manager.blockingExecutor().submit(newConnectionTask);
    }

    @Override
    public void replaceDefunctConnection(final Connection connection) {
        if (connection.state.compareAndSet(OPEN, GONE))
            open.set(false);
        if (connectionRef.compareAndSet(connection, null))
            manager.blockingExecutor().submit(new Runnable() {
                @Override
                public void run() {
                    addConnectionIfNeeded();
                }
            });
    }

    @Override
    void cleanupIdleConnections(long now) {
    }

    private void close(final Connection connection) {
        connection.closeAsync();
    }

    protected CloseFuture makeCloseFuture() {
        
        signalAllAvailableConnection();

        return new CloseFuture.Forwarding(discardConnection());
    }

    private List<CloseFuture> discardConnection() {

        List<CloseFuture> futures = new ArrayList<CloseFuture>();

        final Connection connection = connectionRef.get();
        if (connection != null) {
            CloseFuture future = connection.closeAsync();
            future.addListener(new Runnable() {
                public void run() {
                    if (connection.state.compareAndSet(OPEN, GONE))
                        open.set(false);
                }
            }, MoreExecutors.sameThreadExecutor());
            futures.add(future);
        }
        return futures;
    }

    @Override
    public void ensureCoreConnections() {
        if (isClosed())
            return;

        if (!open.get() && scheduledForCreation.compareAndSet(false, true)) {
            manager.blockingExecutor().submit(newConnectionTask);
        }
    }

    @Override
    public int opened() {
        return open.get() ? 1 : 0;
    }

    @Override
    int trashed() {
        return trash.size();
    }

    @Override
    public int inFlightQueriesCount() {
        Connection connection = connectionRef.get();
        return connection == null ? 0 : connection.inFlight.get();
    }
}

<code block>

package com.datastax.driver.core;

import java.net.InetSocketAddress;
import java.util.Collection;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

import org.testng.annotations.Test;
import org.testng.collections.Lists;

import static org.testng.Assert.fail;

import com.datastax.driver.core.utils.CassandraVersion;

@CassandraVersion(major=2.1)
public class SingleConnectionPoolTest extends CCMBridge.PerClassSingleNodeCluster {
    @Override
    protected Collection<String> getTableDefinitions() {
        return Lists.newArrayList();
    }

    @Test(groups = "short")
    public void should_throttle_requests() {
        
        final int maxRequests = 10;
        cluster.getConfiguration().getPoolingOptions()
               .setMaxSimultaneousRequestsPerHostThreshold(HostDistance.LOCAL, maxRequests);

        
        final AtomicBoolean excessInflightQueriesSpotted = new AtomicBoolean(false);
        final Host host = cluster.getMetadata().getHost(new InetSocketAddress(CCMBridge.IP_PREFIX + "1", 9042));
        ScheduledExecutorService openConnectionsWatcherExecutor = Executors.newScheduledThreadPool(1);
        final Runnable openConnectionsWatcher = new Runnable() {
            @Override
            public void run() {
                int inFlight = session.getState().getInFlightQueries(host);
                if (inFlight > maxRequests)
                    excessInflightQueriesSpotted.set(true);
            }
        };
        openConnectionsWatcherExecutor.scheduleAtFixedRate(openConnectionsWatcher, 200, 200, TimeUnit.MILLISECONDS);

        
        for (int i = 0; i < 10000; i++)
            session.executeAsync("SELECT release_version FROM system.local");

        openConnectionsWatcherExecutor.shutdownNow();
        if (excessInflightQueriesSpotted.get()) {
            fail("Inflight queries exceeded the limit");
        }
    }
}

<code block>

package com.datastax.driver.core;

import java.net.InetSocketAddress;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;

import com.codahale.metrics.Timer;
import com.google.common.collect.Sets;
import io.netty.util.HashedWheelTimer;
import io.netty.util.Timeout;
import io.netty.util.TimerTask;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.datastax.driver.core.exceptions.*;
import com.datastax.driver.core.policies.RetryPolicy;
import com.datastax.driver.core.policies.RetryPolicy.RetryDecision.Type;
import com.datastax.driver.core.policies.SpeculativeExecutionPolicy.SpeculativeExecutionPlan;


class RequestHandler {
    private static final Logger logger = LoggerFactory.getLogger(RequestHandler.class);

    final String id;

    private final SessionManager manager;
    private final Callback callback;

    private final QueryPlan queryPlan;
    private final SpeculativeExecutionPlan speculativeExecutionPlan;
    private final boolean allowSpeculativeExecutions;
    private final Set<SpeculativeExecution> runningExecutions = Sets.newCopyOnWriteArraySet();
    private final Set<Timeout> scheduledExecutions = Sets.newCopyOnWriteArraySet();
    private final Statement statement;
    private final HashedWheelTimer scheduler;

    private volatile List<Host> triedHosts;

    private volatile Map<InetSocketAddress, Throwable> errors;

    private final Timer.Context timerContext;
    private final long startTime;

    private final AtomicBoolean isDone = new AtomicBoolean();
    private AtomicInteger executionCount = new AtomicInteger();

    public RequestHandler(SessionManager manager, Callback callback, Statement statement) {
        this.id = Long.toString(System.identityHashCode(this));
        if(logger.isTraceEnabled())
            logger.trace("[{}] {}", id, statement);
        this.manager = manager;
        this.callback = callback;
        this.scheduler = manager.cluster.manager.connectionFactory.timer;

        callback.register(this);

        this.queryPlan = new QueryPlan(manager.loadBalancingPolicy().newQueryPlan(manager.poolsState.keyspace, statement));
        this.speculativeExecutionPlan = manager.speculativeRetryPolicy().newPlan(manager.poolsState.keyspace, statement);
        this.allowSpeculativeExecutions = statement != Statement.DEFAULT
            && statement.isIdempotentWithDefault(manager.configuration().getQueryOptions());
        this.statement = statement;

        this.timerContext = metricsEnabled()
            ? metrics().getRequestsTimer().time()
            : null;
        this.startTime = System.nanoTime();
    }

    void sendRequest() {
        startNewExecution();
    }

    
    void cancel() {
        if (!isDone.compareAndSet(false, true))
            return;

        cancelPendingExecutions(null);
    }

    private void startNewExecution() {
        if (isDone.get())
            return;

        Message.Request request = callback.request();
        int position = executionCount.incrementAndGet();
        
        
        if (position > 1)
            request = request.copy();

        SpeculativeExecution execution = new SpeculativeExecution(request, position);
        runningExecutions.add(execution);
        execution.sendRequest();
    }

    private void scheduleExecution(long delayMillis) {
        if (isDone.get() || delayMillis <= 0)
            return;
        if(logger.isTraceEnabled())
            logger.trace("[{}] Schedule next speculative execution in {} ms", id, delayMillis);
        scheduledExecutions.add(scheduler.newTimeout(newExecutionTask, delayMillis, TimeUnit.MILLISECONDS));
    }

    private final TimerTask newExecutionTask = new TimerTask() {
        @Override
        public void run(final Timeout timeout) throws Exception {
            scheduledExecutions.remove(timeout);
            if (!isDone.get())
                
                manager.executor().execute(new Runnable() {
                    @Override
                    public void run() {
                        metrics().getErrorMetrics().getSpeculativeExecutions().inc();
                        startNewExecution();
                    }
                });
        }
    };

    private void cancelPendingExecutions(SpeculativeExecution ignore) {
        for (SpeculativeExecution execution : runningExecutions)
            if (execution != ignore) 
                execution.cancel();
        for (Timeout execution : scheduledExecutions)
            execution.cancel();
    }

    private void logError(InetSocketAddress address, Throwable exception) {
        logger.debug("Error querying {}, trying next host (error is: {})", address, exception.toString());
        if (errors == null)
            errors = new ConcurrentHashMap<InetSocketAddress, Throwable>();
        errors.put(address, exception);
    }

    private void setFinalResult(SpeculativeExecution execution, Connection connection, Message.Response response) {
        if (!isDone.compareAndSet(false, true)) {
            if(logger.isTraceEnabled())
                logger.trace("[{}] Got beaten to setting the result", execution.id);
            return;
        }

        if(logger.isTraceEnabled())
            logger.trace("[{}] Setting final result", execution.id);

        cancelPendingExecutions(execution);

        try {
            if (timerContext != null)
                timerContext.stop();

            ExecutionInfo info = execution.current.defaultExecutionInfo;
            if (triedHosts != null) {
                triedHosts.add(execution.current);
                info = new ExecutionInfo(triedHosts);
            }
            if (execution.retryConsistencyLevel != null)
                info = info.withAchievedConsistency(execution.retryConsistencyLevel);
            callback.onSet(connection, response, info, statement, System.nanoTime() - startTime);
        } catch (Exception e) {
            callback.onException(connection,
                new DriverInternalError("Unexpected exception while setting final result from " + response, e),
                System.nanoTime() - startTime, 0);
        }
    }

    private void setFinalException(SpeculativeExecution execution, Connection connection, Exception exception) {
        if (!isDone.compareAndSet(false, true)) {
            if(logger.isTraceEnabled())
                logger.trace("[{}] Got beaten to setting final exception", execution.id);
            return;
        }

        if(logger.isTraceEnabled())
            logger.trace("[{}] Setting final exception", execution.id);

        cancelPendingExecutions(execution);

        try {
            if (timerContext != null)
                timerContext.stop();
        } finally {
            callback.onException(connection, exception, System.nanoTime() - startTime, 0);
        }
    }

    
    
    private void reportNoMoreHosts(SpeculativeExecution execution) {
        runningExecutions.remove(execution);
        if (runningExecutions.isEmpty())
            setFinalException(execution, null, new NoHostAvailableException(
                errors == null ? Collections.<InetSocketAddress, Throwable>emptyMap() : errors));
    }

    private boolean metricsEnabled() {
        return manager.configuration().getMetricsOptions() != null;
    }

    private Metrics metrics() {
        return manager.cluster.manager.metrics;
    }

    interface Callback extends Connection.ResponseCallback {
        void onSet(Connection connection, Message.Response response, ExecutionInfo info, Statement statement, long latency);
        void register(RequestHandler handler);
    }

    
    class SpeculativeExecution implements Connection.ResponseCallback {
        final String id;
        private final Message.Request request;
        private volatile Host current;
        private volatile ConsistencyLevel retryConsistencyLevel;
        private final AtomicReference<QueryState> queryStateRef;
        private final AtomicBoolean nextExecutionScheduled = new AtomicBoolean();

        
        
        
        
        private volatile int retriesByPolicy;

        private volatile Connection.ResponseHandler connectionHandler;

        SpeculativeExecution(Message.Request request, int position) {
            this.id = RequestHandler.this.id + "-" + position;
            this.request = request;
            this.queryStateRef = new AtomicReference<QueryState>(QueryState.INITIAL);
            if(logger.isTraceEnabled())
                logger.trace("[{}] Starting", id);
        }

        void sendRequest() {
            sendRequest(true);
        }

        boolean sendRequest(boolean reportNoMoreHosts) {
            try {
                Host host;
                while (!isDone.get() && (host = queryPlan.next()) != null && !queryStateRef.get().isCancelled()) {
                    if(logger.isTraceEnabled())
                        logger.trace("[{}] Querying node {}", id, host);
                    if (query(host))
                        return true;
                }
                if(reportNoMoreHosts)
                    reportNoMoreHosts(this);
            } catch (Exception e) {
                
                setFinalException(null, new DriverInternalError("An unexpected error happened while sending requests", e));
            }
            return false;
        }

        private boolean query(final Host host) {
            HostConnectionPool currentPool = manager.pools.get(host);
            if (currentPool == null || currentPool.isClosed())
                return false;

            if (allowSpeculativeExecutions && nextExecutionScheduled.compareAndSet(false, true))
                scheduleExecution(speculativeExecutionPlan.nextExecution(host));

            Connection connection = null;
            try {
                connection = currentPool.borrowConnection(manager.configuration().getPoolingOptions().getPoolTimeoutMillis(), TimeUnit.MILLISECONDS);
                if (current != null) {
                    if (triedHosts == null)
                        triedHosts = new CopyOnWriteArrayList<Host>();
                    triedHosts.add(current);
                }
                current = host;
                write(connection, this);
                return true;
            } catch (ConnectionException e) {
                
                if (metricsEnabled())
                    metrics().getErrorMetrics().getConnectionErrors().inc();
                if (connection != null)
                    connection.release();
                logError(host.getSocketAddress(), e);
                return false;
            } catch (BusyConnectionException e) {
                
                connection.release();
                logError(host.getSocketAddress(), e);
                return false;
            } catch (TimeoutException e) {
                
                logError(host.getSocketAddress(), new DriverException("Timeout while trying to acquire available connection (you may want to increase the driver number of per-host connections)"));
                return false;
            } catch (RuntimeException e) {
                if (connection != null)
                    connection.release();
                logger.error("Unexpected error while querying " + host.getAddress(), e);
                logError(host.getSocketAddress(), e);
                return false;
            }
        }

        private void write(Connection connection, Connection.ResponseCallback responseCallback) throws ConnectionException, BusyConnectionException {
            
            
            connectionHandler = null;

            
            while (true) {
                QueryState previous = queryStateRef.get();
                if (previous.isCancelled()) {
                    connection.release();
                    return;
                }
                if (previous.inProgress || queryStateRef.compareAndSet(previous, previous.startNext()))
                    break;
            }

            connectionHandler = connection.write(responseCallback, false);
            
            
            connectionHandler.startTimeout();

            
            

            
            
            
            if (queryStateRef.get() == QueryState.CANCELLED_WHILE_IN_PROGRESS)
                connectionHandler.cancelHandler();
        }

        private void retry(final boolean retryCurrent, ConsistencyLevel newConsistencyLevel) {
            retry(retryCurrent, newConsistencyLevel, null, null);
        }

        private void retry(final boolean retryCurrent, ConsistencyLevel newConsistencyLevel, final Connection connection, final Message.Response response) {
            final Host h = current;
            this.retryConsistencyLevel = newConsistencyLevel;

            
            manager.executor().execute(new Runnable() {
                @Override
                public void run() {
                    if (queryStateRef.get().isCancelled())
                        return;
                    try {
                        if (retryCurrent) {
                            if (query(h))
                                return;
                            sendRequest();
                        } else if(connection != null && response != null) {
                            
                            
                            boolean requestSent = sendRequest(false);
                            if(!requestSent) {
                                setFinalResult(connection, response);
                            }
                        } else {
                            sendRequest();
                        }
                    } catch (Exception e) {
                        setFinalException(null, new DriverInternalError("Unexpected exception while retrying query", e));
                    }
                }
            });
        }

        void cancel() {
            
            
            while (true) {
                QueryState previous = queryStateRef.get();
                if (previous.isCancelled()) {
                    return;
                } else if (previous.inProgress && queryStateRef.compareAndSet(previous, QueryState.CANCELLED_WHILE_IN_PROGRESS)) {
                    if(logger.isTraceEnabled())
                        logger.trace("[{}] Cancelled while in progress", id);
                    
                    
                    if (connectionHandler != null)
                        connectionHandler.cancelHandler();
                    return;
                } else if (!previous.inProgress && queryStateRef.compareAndSet(previous, QueryState.CANCELLED_WHILE_COMPLETE)) {
                    if(logger.isTraceEnabled())
                        logger.trace("[{}] Cancelled while complete", id);
                    return;
                }
            }
        }

        @Override
        public Message.Request request() {
            if (retryConsistencyLevel != null && retryConsistencyLevel != request.consistency())
                return request.copy(retryConsistencyLevel);
            else
                return request;
        }

        @Override
        public void onSet(Connection connection, Message.Response response, long latency, int retryCount) {
            QueryState queryState = queryStateRef.get();
            if (!queryState.isInProgressAt(retryCount) ||
                !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                logger.debug("onSet triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                    retryCount, queryState, queryStateRef.get());
                return;
            }

            Host queriedHost = current;
            Exception exceptionToReport = null;
            try {
                switch (response.type) {
                    case RESULT:
                        connection.release();
                        setFinalResult(connection, response);
                        break;
                    case ERROR:
                        Responses.Error err = (Responses.Error)response;
                        exceptionToReport = err.asException(connection.address);
                        RetryPolicy.RetryDecision retry = null;
                        RetryPolicy retryPolicy = statement.getRetryPolicy() == null
                            ? manager.configuration().getPolicies().getRetryPolicy()
                            : statement.getRetryPolicy();
                        switch (err.code) {
                            case READ_TIMEOUT:
                                connection.release();
                                assert err.infos instanceof ReadTimeoutException;
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getReadTimeouts().inc();

                                ReadTimeoutException rte = (ReadTimeoutException)err.infos;
                                retry = retryPolicy.onReadTimeout(statement,
                                    rte.getConsistencyLevel(),
                                    rte.getRequiredAcknowledgements(),
                                    rte.getReceivedAcknowledgements(),
                                    rte.wasDataRetrieved(),
                                    retriesByPolicy);

                                if (metricsEnabled()) {
                                    if (retry.getType() == Type.RETRY)
                                        metrics().getErrorMetrics().getRetriesOnReadTimeout().inc();
                                    if (retry.getType() == Type.IGNORE)
                                        metrics().getErrorMetrics().getIgnoresOnReadTimeout().inc();
                                }
                                break;
                            case WRITE_TIMEOUT:
                                connection.release();
                                assert err.infos instanceof WriteTimeoutException;
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getWriteTimeouts().inc();

                                WriteTimeoutException wte = (WriteTimeoutException)err.infos;
                                retry = retryPolicy.onWriteTimeout(statement,
                                    wte.getConsistencyLevel(),
                                    wte.getWriteType(),
                                    wte.getRequiredAcknowledgements(),
                                    wte.getReceivedAcknowledgements(),
                                    retriesByPolicy);

                                if (metricsEnabled()) {
                                    if (retry.getType() == Type.RETRY)
                                        metrics().getErrorMetrics().getRetriesOnWriteTimeout().inc();
                                    if (retry.getType() == Type.IGNORE)
                                        metrics().getErrorMetrics().getIgnoresOnWriteTimeout().inc();
                                }
                                break;
                            case UNAVAILABLE:
                                connection.release();
                                assert err.infos instanceof UnavailableException;
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getUnavailables().inc();

                                UnavailableException ue = (UnavailableException)err.infos;
                                retry = retryPolicy.onUnavailable(statement,
                                    ue.getConsistencyLevel(),
                                    ue.getRequiredReplicas(),
                                    ue.getAliveReplicas(),
                                    retriesByPolicy);

                                if (metricsEnabled()) {
                                    if (retry.getType() == Type.RETRY)
                                        metrics().getErrorMetrics().getRetriesOnUnavailable().inc();
                                    if (retry.getType() == Type.IGNORE)
                                        metrics().getErrorMetrics().getIgnoresOnUnavailable().inc();
                                }
                                break;
                            case OVERLOADED:
                                connection.release();
                                
                                logger.warn("Host {} is overloaded, trying next host.", connection.address);
                                DriverException overloaded = new DriverException("Host overloaded");
                                logError(connection.address, overloaded);
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getOthers().inc();
                                retry(false, null);
                                return;
                            case SERVER_ERROR:
                                connection.release();
                                
                                logger.warn("{} replied with server error ({}), trying next host.", connection.address, err.message);
                                DriverException exception = new DriverException("Host replied with server error: " + err.message);
                                logError(connection.address, exception);
                                connection.defunct(exception);
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getOthers().inc();
                                retry(false, null);
                                return;
                            case IS_BOOTSTRAPPING:
                                connection.release();
                                
                                logger.error("Query sent to {} but it is bootstrapping. This shouldn't happen but trying next host.", connection.address);
                                DriverException bootstrapping = new DriverException("Host is bootstrapping");
                                logError(connection.address, bootstrapping);
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getOthers().inc();
                                retry(false, null);
                                return;
                            case UNPREPARED:
                                
                                assert err.infos instanceof MD5Digest;
                                MD5Digest id = (MD5Digest)err.infos;
                                PreparedStatement toPrepare = manager.cluster.manager.preparedQueries.get(id);
                                if (toPrepare == null) {
                                    
                                    connection.release();
                                    String msg = String.format("Tried to execute unknown prepared query %s", id);
                                    logger.error(msg);
                                    setFinalException(connection, new DriverInternalError(msg));
                                    return;
                                }

                                String currentKeyspace = connection.keyspace();
                                String prepareKeyspace = toPrepare.getQueryKeyspace();
                                if (prepareKeyspace != null && (currentKeyspace == null || !currentKeyspace.equals(prepareKeyspace))) {
                                    
                                    
                                    
                                    
                                    connection.release();
                                    throw new IllegalStateException(String.format("Statement was prepared on keyspace %s, can't execute it on %s (%s)",
                                        toPrepare.getQueryKeyspace(), connection.keyspace(), toPrepare.getQueryString()));
                                }

                                logger.info("Query {} is not prepared on {}, preparing before retrying executing. "
                                        + "Seeing this message a few times is fine, but seeing it a lot may be source of performance problems",
                                    toPrepare.getQueryString(), connection.address);

                                write(connection, prepareAndRetry(toPrepare.getQueryString()));
                                
                                return;
                            default:
                                connection.release();
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getOthers().inc();
                                break;
                        }

                        if (retry == null)
                            setFinalResult(connection, response);
                        else {
                            switch (retry.getType()) {
                                case RETRY:
                                    ++retriesByPolicy;
                                    if (logger.isDebugEnabled())
                                        logger.debug("Doing retry {} for query {} at consistency {}", retriesByPolicy, statement, retry.getRetryConsistencyLevel());
                                    if (metricsEnabled())
                                        metrics().getErrorMetrics().getRetries().inc();
                                    retry(retry.isRetryCurrent(), retry.getRetryConsistencyLevel(), connection, response);
                                    break;
                                case RETHROW:
                                    setFinalResult(connection, response);
                                    break;
                                case IGNORE:
                                    if (metricsEnabled())
                                        metrics().getErrorMetrics().getIgnores().inc();
                                    setFinalResult(connection, new Responses.Result.Void());
                                    break;
                            }
                        }
                        break;
                    default:
                        connection.release();
                        setFinalResult(connection, response);
                        break;
                }
            } catch (Exception e) {
                exceptionToReport = e;
                setFinalException(connection, e);
            } finally {
                if (queriedHost != null && statement != Statement.DEFAULT)
                    manager.cluster.manager.reportLatency(queriedHost, statement, exceptionToReport, latency);
            }
        }

        private Connection.ResponseCallback prepareAndRetry(final String toPrepare) {
            return new Connection.ResponseCallback() {

                @Override
                public Message.Request request() {
                    return new Requests.Prepare(toPrepare);
                }

                @Override
                public int retryCount() {
                    return SpeculativeExecution.this.retryCount();
                }

                @Override
                public void onSet(Connection connection, Message.Response response, long latency, int retryCount) {
                    QueryState queryState = queryStateRef.get();
                    if (!queryState.isInProgressAt(retryCount) ||
                        !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                        logger.debug("onSet triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                            retryCount, queryState, queryStateRef.get());
                        return;
                    }

                    connection.release();

                    
                    switch (response.type) {
                        case RESULT:
                            if (((Responses.Result)response).kind == Responses.Result.Kind.PREPARED) {
                                logger.debug("Scheduling retry now that query is prepared");
                                retry(true, null);
                            } else {
                                logError(connection.address, new DriverException("Got unexpected response to prepare message: " + response));
                                retry(false, null);
                            }
                            break;
                        case ERROR:
                            logError(connection.address, new DriverException("Error preparing query, got " + response));
                            if (metricsEnabled())
                                metrics().getErrorMetrics().getOthers().inc();
                            retry(false, null);
                            break;
                        default:
                            
                            SpeculativeExecution.this.setFinalResult(connection, response);
                            break;
                    }
                }

                @Override
                public void onException(Connection connection, Exception exception, long latency, int retryCount) {
                    SpeculativeExecution.this.onException(connection, exception, latency, retryCount);
                }

                @Override
                public boolean onTimeout(Connection connection, long latency, int retryCount) {
                    QueryState queryState = queryStateRef.get();
                    if (!queryState.isInProgressAt(retryCount) ||
                        !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                        logger.debug("onTimeout triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                            retryCount, queryState, queryStateRef.get());
                        return false;
                    }
                    logError(connection.address, new DriverException("Timeout waiting for response to prepare message"));
                    retry(false, null);
                    return true;
                }
            };
        }

        @Override
        public void onException(Connection connection, Exception exception, long latency, int retryCount) {
            QueryState queryState = queryStateRef.get();
            if (!queryState.isInProgressAt(retryCount) ||
                !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                logger.debug("onException triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                    retryCount, queryState, queryStateRef.get());
                return;
            }

            Host queriedHost = current;
            try {
                connection.release();

                if (exception instanceof ConnectionException) {
                    if (metricsEnabled())
                        metrics().getErrorMetrics().getConnectionErrors().inc();
                    ConnectionException ce = (ConnectionException)exception;
                    logError(ce.address, ce);
                    retry(false, null);
                    return;
                }
                setFinalException(connection, exception);
            } catch (Exception e) {
                
                setFinalException(null, new DriverInternalError("An unexpected error happened while handling exception " + exception, e));
            } finally {
                if (queriedHost != null && statement != Statement.DEFAULT)
                    manager.cluster.manager.reportLatency(queriedHost, statement, exception, latency);
            }
        }

        @Override
        public boolean onTimeout(Connection connection, long latency, int retryCount) {
            QueryState queryState = queryStateRef.get();
            if (!queryState.isInProgressAt(retryCount) ||
                !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                logger.debug("onTimeout triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                    retryCount, queryState, queryStateRef.get());
                return false;
            }

            Host queriedHost = current;
            OperationTimedOutException timeoutException = new OperationTimedOutException(connection.address);
            try {
                logError(connection.address, timeoutException);
                retry(false, null);
            } catch (Exception e) {
                
                setFinalException(null, new DriverInternalError("An unexpected error happened while handling timeout", e));
            } finally {
                if (queriedHost != null && statement != Statement.DEFAULT)
                    manager.cluster.manager.reportLatency(queriedHost, statement, timeoutException, latency);
            }
            return true;
        }

        @Override
        public int retryCount() {
            return queryStateRef.get().retryCount;
        }

        private void setFinalException(Connection connection, Exception exception) {
            RequestHandler.this.setFinalException(this, connection, exception);
        }

        private void setFinalResult(Connection connection, Message.Response response) {
            RequestHandler.this.setFinalResult(this, connection, response);
        }
    }

    
    static class QueryState {
        static final QueryState INITIAL = new QueryState(-1, false);
        static final QueryState CANCELLED_WHILE_IN_PROGRESS = new QueryState(Integer.MIN_VALUE, false);
        static final QueryState CANCELLED_WHILE_COMPLETE = new QueryState(Integer.MIN_VALUE + 1, false);

        final int retryCount;
        final boolean inProgress;

        private QueryState(int count, boolean inProgress) {
            this.retryCount = count;
            this.inProgress = inProgress;
        }

        boolean isInProgressAt(int retryCount) {
            return inProgress && this.retryCount == retryCount;
        }

        QueryState complete() {
            assert inProgress;
            return new QueryState(retryCount, false);
        }

        QueryState startNext() {
            assert !inProgress;
            return new QueryState(retryCount + 1, true);
        }

        public boolean isCancelled() {
            return this == CANCELLED_WHILE_IN_PROGRESS || this == CANCELLED_WHILE_COMPLETE;
        }

        @Override
        public String toString() {
            return String.format("QueryState(count=%d, inProgress=%s, cancelled=%s)", retryCount, inProgress, isCancelled());
        }
    }

    
    static class QueryPlan {
        private final Iterator<Host> iterator;

        QueryPlan(Iterator<Host> iterator) {
            this.iterator = iterator;
        }

        
        synchronized Host next() {
            return iterator.hasNext() ? iterator.next() : null;
        }
    }
}

<code block>

package com.datastax.driver.core.policies;

import java.util.List;
import java.util.Map;

import com.google.common.collect.ImmutableList;
import com.google.common.collect.ImmutableMap;
import org.mockito.Mockito;
import org.scassandra.http.client.PrimingRequest;
import org.testng.annotations.AfterClass;
import org.testng.annotations.AfterMethod;
import org.testng.annotations.BeforeClass;
import org.testng.annotations.BeforeMethod;

import static org.assertj.core.api.Assertions.assertThat;
import static org.mockito.Matchers.any;
import static org.mockito.Matchers.anyBoolean;
import static org.mockito.Matchers.anyInt;
import static org.mockito.Mockito.times;

import com.datastax.driver.core.*;


public class AbstractRetryPolicyIntegrationTest {
    protected SCassandraCluster scassandras;
    protected Cluster cluster = null;
    protected Metrics.Errors errors;
    protected Host host1, host2, host3;
    protected Session session;

    protected RetryPolicy retryPolicy;

    protected AbstractRetryPolicyIntegrationTest(RetryPolicy retryPolicy) {
        this.retryPolicy = Mockito.spy(retryPolicy);
    }

    @BeforeClass(groups = "short")
    public void beforeClass() {
        scassandras = new SCassandraCluster(CCMBridge.IP_PREFIX, 3);
    }

    @BeforeMethod(groups = "short")
    public void beforeMethod() {
        cluster = Cluster.builder()
            .addContactPoint(CCMBridge.ipOfNode(1))
            .withRetryPolicy(retryPolicy)
            .withLoadBalancingPolicy(new SortingLoadBalancingPolicy())
            .build();

        session = cluster.connect();

        host1 = TestUtils.findHost(cluster, 1);
        host2 = TestUtils.findHost(cluster, 2);
        host3 = TestUtils.findHost(cluster, 3);

        errors = cluster.getMetrics().getErrorMetrics();

        Mockito.reset(retryPolicy);
        scassandras.clearAllPrimes();
        scassandras.clearAllRecordedActivity();
    }

    protected void simulateError(int hostNumber, PrimingRequest.Result result) {
        scassandras
            .prime(hostNumber, PrimingRequest.queryBuilder()
                .withQuery("mock query")
                .withResult(result)
                .build());
    }

    protected void simulateNormalResponse(int hostNumber) {
        scassandras
            .prime(hostNumber, PrimingRequest.queryBuilder()
                .withQuery("mock query")
                .withRows(row("result", "result1"))
                .build());
    }

    private static List<Map<String, ?>> row(String key, String value) {
        return ImmutableList.<Map<String, ?>>of(ImmutableMap.of(key, value));
    }

    protected ResultSet query() {
        return query(session);
    }

    protected ResultSet query(Session session) {
        return session.execute("mock query");
    }

    protected void assertOnReadTimeoutWasCalled(int times) {
        Mockito.verify(retryPolicy, times(times)).onReadTimeout(
            any(Statement.class), any(ConsistencyLevel.class), anyInt(), anyInt(), anyBoolean(), anyInt());

    }

    protected void assertOnWriteTimeoutWasCalled(int times) {
        Mockito.verify(retryPolicy, times(times)).onWriteTimeout(
            any(Statement.class), any(ConsistencyLevel.class), any(WriteType.class), anyInt(), anyInt(), anyInt());
    }

    protected void assertOnUnavailableWasCalled(int times) {
        Mockito.verify(retryPolicy, times(times)).onUnavailable(
            any(Statement.class), any(ConsistencyLevel.class), anyInt(), anyInt(), anyInt());
    }

    protected void assertQueried(int hostNumber, int times) {
        assertThat(scassandras.retrieveQueries(hostNumber)).hasSize(times);
    }

    @AfterMethod(groups = "short")
    public void afterMethod() {
        scassandras.clearAllPrimes();
        if (cluster != null)
            cluster.close();
    }

    @AfterClass(groups = "short")
    public void afterClass() {
        if (scassandras != null)
            scassandras.stop();
    }
}

<code block>

package com.datastax.driver.core.policies;

import com.datastax.driver.core.*;
import org.testng.annotations.Test;

import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.fail;
import static org.scassandra.http.client.PrimingRequest.Result.read_request_timeout;
import static org.scassandra.http.client.PrimingRequest.Result.unavailable;
import static org.scassandra.http.client.PrimingRequest.Result.write_request_timeout;

import com.datastax.driver.core.exceptions.ReadTimeoutException;
import com.datastax.driver.core.exceptions.UnavailableException;
import com.datastax.driver.core.exceptions.WriteTimeoutException;

import java.util.Collections;

public class DefaultRetryPolicyIntegrationTest extends AbstractRetryPolicyIntegrationTest {
    public DefaultRetryPolicyIntegrationTest() {
        super(DefaultRetryPolicy.INSTANCE);
    }

    @Test(groups = "short")
    public void should_rethrow_on_read_timeout_with_0_receivedResponses() {
        simulateError(1, read_request_timeout);

        try {
            query();
            fail("expected a ReadTimeoutException");
        } catch (ReadTimeoutException e) { }

        assertOnReadTimeoutWasCalled(1);
        assertThat(errors.getRetriesOnReadTimeout().getCount()).isEqualTo(0);
        assertQueried(1, 1);
        assertQueried(2, 0);
        assertQueried(3, 0);
    }

    @Test(groups = "short")
    public void should_rethrow_on_write_timeout_with_SIMPLE_write_type() {
        simulateError(1, write_request_timeout);

        try {
            query();
            fail("expected a WriteTimeoutException");
        } catch (WriteTimeoutException e) {}

        assertOnWriteTimeoutWasCalled(1);
        assertThat(errors.getRetriesOnWriteTimeout().getCount()).isEqualTo(0);
        assertQueried(1, 1);
        assertQueried(2, 0);
        assertQueried(3, 0);
    }

    @Test(groups = "short")
    public void should_try_next_host_on_first_unavailable() {
        simulateError(1, unavailable);
        simulateNormalResponse(2);

        query();

        assertOnUnavailableWasCalled(1);
        assertThat(errors.getRetriesOnUnavailable().getCount()).isEqualTo(1);
        assertQueried(1, 1);
        assertQueried(2, 1);
        assertQueried(3, 0);
    }

    @Test(groups = "short")
    public void should_rethrow_on_second_unavailable() {
        simulateError(1, unavailable);
        simulateError(2, unavailable);

        try {
            query();
            fail("expected an UnavailableException");
        } catch (UnavailableException e) {}

        assertOnUnavailableWasCalled(2);
        assertThat(errors.getRetriesOnUnavailable().getCount()).isEqualTo(1);
        assertQueried(1, 1);
        assertQueried(2, 1);
        assertQueried(3, 0);
    }

    @Test(groups = "short")
    public void should_rethrow_on_first_unavailable_if_there_are_no_more_hosts() {
        LoadBalancingPolicy firstHostOnlyPolicy =
                new WhiteListPolicy(Policies.defaultLoadBalancingPolicy(),
                        Collections.singletonList(host1.getSocketAddress()));

        Cluster whiteListedCluster = Cluster.builder()
                .addContactPoint(CCMBridge.ipOfNode(1))
                .withRetryPolicy(retryPolicy)
                .withLoadBalancingPolicy(firstHostOnlyPolicy)
                .build();

        try {
            Session whiteListedSession = whiteListedCluster.connect();
            
            scassandras.clearAllRecordedActivity();

            simulateError(1, unavailable);

            try {
                query(whiteListedSession);
                fail("expected an UnavailableException");
            } catch (UnavailableException e) {}

            assertOnUnavailableWasCalled(1);
            
            Metrics.Errors whiteListErrors = whiteListedCluster.getMetrics().getErrorMetrics();
            assertThat(whiteListErrors.getRetriesOnUnavailable().getCount()).isEqualTo(1);
            assertQueried(1, 1);
            assertQueried(2, 0);
            assertQueried(3, 0);
        } finally {
            whiteListedCluster.close();
        }
    }
}

<code block>

package com.datastax.driver.core;

import java.net.InetSocketAddress;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;

import com.codahale.metrics.Timer;
import com.google.common.collect.Sets;
import io.netty.util.HashedWheelTimer;
import io.netty.util.Timeout;
import io.netty.util.TimerTask;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.datastax.driver.core.exceptions.*;
import com.datastax.driver.core.policies.RetryPolicy;
import com.datastax.driver.core.policies.RetryPolicy.RetryDecision.Type;
import com.datastax.driver.core.policies.SpeculativeExecutionPolicy.SpeculativeExecutionPlan;


class RequestHandler {
    private static final Logger logger = LoggerFactory.getLogger(RequestHandler.class);

    final String id;

    private final SessionManager manager;
    private final Callback callback;

    private final QueryPlan queryPlan;
    private final SpeculativeExecutionPlan speculativeExecutionPlan;
    private final boolean allowSpeculativeExecutions;
    private final Set<SpeculativeExecution> runningExecutions = Sets.newCopyOnWriteArraySet();
    private final Set<Timeout> scheduledExecutions = Sets.newCopyOnWriteArraySet();
    private final Statement statement;
    private final HashedWheelTimer scheduler;

    private volatile List<Host> triedHosts;

    private volatile Map<InetSocketAddress, Throwable> errors;

    private final Timer.Context timerContext;
    private final long startTime;

    private final AtomicBoolean isDone = new AtomicBoolean();
    private AtomicInteger executionCount = new AtomicInteger();

    public RequestHandler(SessionManager manager, Callback callback, Statement statement) {
        this.id = Long.toString(System.identityHashCode(this));
        if(logger.isTraceEnabled())
            logger.trace("[{}] {}", id, statement);
        this.manager = manager;
        this.callback = callback;
        this.scheduler = manager.cluster.manager.connectionFactory.timer;

        callback.register(this);

        this.queryPlan = new QueryPlan(manager.loadBalancingPolicy().newQueryPlan(manager.poolsState.keyspace, statement));
        this.speculativeExecutionPlan = manager.speculativeRetryPolicy().newPlan(manager.poolsState.keyspace, statement);
        this.allowSpeculativeExecutions = statement != Statement.DEFAULT
            && statement.isIdempotentWithDefault(manager.configuration().getQueryOptions());
        this.statement = statement;

        this.timerContext = metricsEnabled()
            ? metrics().getRequestsTimer().time()
            : null;
        this.startTime = System.nanoTime();
    }

    void sendRequest() {
        startNewExecution();
    }

    
    void cancel() {
        if (!isDone.compareAndSet(false, true))
            return;

        cancelPendingExecutions(null);
    }

    private void startNewExecution() {
        if (isDone.get())
            return;

        Message.Request request = callback.request();
        int position = executionCount.incrementAndGet();
        
        
        if (position > 1)
            request = request.copy();

        SpeculativeExecution execution = new SpeculativeExecution(request, position);
        runningExecutions.add(execution);
        execution.sendRequest();
    }

    private void scheduleExecution(long delayMillis) {
        if (isDone.get() || delayMillis <= 0)
            return;
        if(logger.isTraceEnabled())
            logger.trace("[{}] Schedule next speculative execution in {} ms", id, delayMillis);
        scheduledExecutions.add(scheduler.newTimeout(newExecutionTask, delayMillis, TimeUnit.MILLISECONDS));
    }

    private final TimerTask newExecutionTask = new TimerTask() {
        @Override
        public void run(final Timeout timeout) throws Exception {
            scheduledExecutions.remove(timeout);
            if (!isDone.get())
                
                manager.executor().execute(new Runnable() {
                    @Override
                    public void run() {
                        metrics().getErrorMetrics().getSpeculativeExecutions().inc();
                        startNewExecution();
                    }
                });
        }
    };

    private void cancelPendingExecutions(SpeculativeExecution ignore) {
        for (SpeculativeExecution execution : runningExecutions)
            if (execution != ignore) 
                execution.cancel();
        for (Timeout execution : scheduledExecutions)
            execution.cancel();
    }

    private void logError(InetSocketAddress address, Throwable exception) {
        logger.debug("Error querying {}, trying next host (error is: {})", address, exception.toString());
        if (errors == null)
            errors = new ConcurrentHashMap<InetSocketAddress, Throwable>();
        errors.put(address, exception);
    }

    private void setFinalResult(SpeculativeExecution execution, Connection connection, Message.Response response) {
        if (!isDone.compareAndSet(false, true)) {
            if(logger.isTraceEnabled())
                logger.trace("[{}] Got beaten to setting the result", execution.id);
            return;
        }

        if(logger.isTraceEnabled())
            logger.trace("[{}] Setting final result", execution.id);

        cancelPendingExecutions(execution);

        try {
            if (timerContext != null)
                timerContext.stop();

            ExecutionInfo info = execution.current.defaultExecutionInfo;
            if (triedHosts != null) {
                triedHosts.add(execution.current);
                info = new ExecutionInfo(triedHosts);
            }
            if (execution.retryConsistencyLevel != null)
                info = info.withAchievedConsistency(execution.retryConsistencyLevel);
            callback.onSet(connection, response, info, statement, System.nanoTime() - startTime);
        } catch (Exception e) {
            callback.onException(connection,
                new DriverInternalError("Unexpected exception while setting final result from " + response, e),
                System.nanoTime() - startTime, 0);
        }
    }

    private void setFinalException(SpeculativeExecution execution, Connection connection, Exception exception) {
        if (!isDone.compareAndSet(false, true)) {
            if(logger.isTraceEnabled())
                logger.trace("[{}] Got beaten to setting final exception", execution.id);
            return;
        }

        if(logger.isTraceEnabled())
            logger.trace("[{}] Setting final exception", execution.id);

        cancelPendingExecutions(execution);

        try {
            if (timerContext != null)
                timerContext.stop();
        } finally {
            callback.onException(connection, exception, System.nanoTime() - startTime, 0);
        }
    }

    
    
    private void reportNoMoreHosts(SpeculativeExecution execution) {
        runningExecutions.remove(execution);
        if (runningExecutions.isEmpty())
            setFinalException(execution, null, new NoHostAvailableException(
                errors == null ? Collections.<InetSocketAddress, Throwable>emptyMap() : errors));
    }

    private boolean metricsEnabled() {
        return manager.configuration().getMetricsOptions() != null;
    }

    private Metrics metrics() {
        return manager.cluster.manager.metrics;
    }

    interface Callback extends Connection.ResponseCallback {
        void onSet(Connection connection, Message.Response response, ExecutionInfo info, Statement statement, long latency);
        void register(RequestHandler handler);
    }

    
    class SpeculativeExecution implements Connection.ResponseCallback {
        final String id;
        private final Message.Request request;
        private volatile Host current;
        private volatile ConsistencyLevel retryConsistencyLevel;
        private final AtomicReference<QueryState> queryStateRef;
        private final AtomicBoolean nextExecutionScheduled = new AtomicBoolean();

        
        
        
        
        private volatile int retriesByPolicy;

        private volatile Connection.ResponseHandler connectionHandler;

        SpeculativeExecution(Message.Request request, int position) {
            this.id = RequestHandler.this.id + "-" + position;
            this.request = request;
            this.queryStateRef = new AtomicReference<QueryState>(QueryState.INITIAL);
            if(logger.isTraceEnabled())
                logger.trace("[{}] Starting", id);
        }

        void sendRequest() {
            try {
                Host host;
                while (!isDone.get() && (host = queryPlan.next()) != null && !queryStateRef.get().isCancelled()) {
                    if(logger.isTraceEnabled())
                        logger.trace("[{}] Querying node {}", id, host);
                    if (query(host))
                        return;
                }
                reportNoMoreHosts(this);
            } catch (Exception e) {
                
                setFinalException(null, new DriverInternalError("An unexpected error happened while sending requests", e));
            }
        }

        private boolean query(final Host host) {
            HostConnectionPool currentPool = manager.pools.get(host);
            if (currentPool == null || currentPool.isClosed())
                return false;

            if (allowSpeculativeExecutions && nextExecutionScheduled.compareAndSet(false, true))
                scheduleExecution(speculativeExecutionPlan.nextExecution(host));

            Connection connection = null;
            try {
                connection = currentPool.borrowConnection(manager.configuration().getPoolingOptions().getPoolTimeoutMillis(), TimeUnit.MILLISECONDS);
                if (current != null) {
                    if (triedHosts == null)
                        triedHosts = new CopyOnWriteArrayList<Host>();
                    triedHosts.add(current);
                }
                current = host;
                write(connection, this);
                return true;
            } catch (ConnectionException e) {
                
                if (metricsEnabled())
                    metrics().getErrorMetrics().getConnectionErrors().inc();
                if (connection != null)
                    connection.release();
                logError(host.getSocketAddress(), e);
                return false;
            } catch (BusyConnectionException e) {
                
                connection.release();
                logError(host.getSocketAddress(), e);
                return false;
            } catch (TimeoutException e) {
                
                logError(host.getSocketAddress(), new DriverException("Timeout while trying to acquire available connection (you may want to increase the driver number of per-host connections)"));
                return false;
            } catch (RuntimeException e) {
                if (connection != null)
                    connection.release();
                logger.error("Unexpected error while querying " + host.getAddress(), e);
                logError(host.getSocketAddress(), e);
                return false;
            }
        }

        private void write(Connection connection, Connection.ResponseCallback responseCallback) throws ConnectionException, BusyConnectionException {
            
            
            connectionHandler = null;

            
            while (true) {
                QueryState previous = queryStateRef.get();
                if (previous.isCancelled()) {
                    connection.release();
                    return;
                }
                if (previous.inProgress || queryStateRef.compareAndSet(previous, previous.startNext()))
                    break;
            }

            connectionHandler = connection.write(responseCallback, false);
            
            
            connectionHandler.startTimeout();

            
            

            
            
            
            if (queryStateRef.get() == QueryState.CANCELLED_WHILE_IN_PROGRESS)
                connectionHandler.cancelHandler();
        }

        private void retry(final boolean retryCurrent, ConsistencyLevel newConsistencyLevel) {
            final Host h = current;
            this.retryConsistencyLevel = newConsistencyLevel;

            
            manager.executor().execute(new Runnable() {
                @Override
                public void run() {
                    if (queryStateRef.get().isCancelled())
                        return;
                    try {
                        if (retryCurrent) {
                            if (query(h))
                                return;
                        }
                        sendRequest();
                    } catch (Exception e) {
                        setFinalException(null, new DriverInternalError("Unexpected exception while retrying query", e));
                    }
                }
            });
        }

        void cancel() {
            
            
            while (true) {
                QueryState previous = queryStateRef.get();
                if (previous.isCancelled()) {
                    return;
                } else if (previous.inProgress && queryStateRef.compareAndSet(previous, QueryState.CANCELLED_WHILE_IN_PROGRESS)) {
                    if(logger.isTraceEnabled())
                        logger.trace("[{}] Cancelled while in progress", id);
                    
                    
                    if (connectionHandler != null)
                        connectionHandler.cancelHandler();
                    return;
                } else if (!previous.inProgress && queryStateRef.compareAndSet(previous, QueryState.CANCELLED_WHILE_COMPLETE)) {
                    if(logger.isTraceEnabled())
                        logger.trace("[{}] Cancelled while complete", id);
                    return;
                }
            }
        }

        @Override
        public Message.Request request() {
            if (retryConsistencyLevel != null && retryConsistencyLevel != request.consistency())
                return request.copy(retryConsistencyLevel);
            else
                return request;
        }

        @Override
        public void onSet(Connection connection, Message.Response response, long latency, int retryCount) {
            QueryState queryState = queryStateRef.get();
            if (!queryState.isInProgressAt(retryCount) ||
                !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                logger.debug("onSet triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                    retryCount, queryState, queryStateRef.get());
                return;
            }

            Host queriedHost = current;
            Exception exceptionToReport = null;
            try {
                switch (response.type) {
                    case RESULT:
                        connection.release();
                        setFinalResult(connection, response);
                        break;
                    case ERROR:
                        Responses.Error err = (Responses.Error)response;
                        exceptionToReport = err.asException(connection.address);
                        RetryPolicy.RetryDecision retry = null;
                        RetryPolicy retryPolicy = statement.getRetryPolicy() == null
                            ? manager.configuration().getPolicies().getRetryPolicy()
                            : statement.getRetryPolicy();
                        switch (err.code) {
                            case READ_TIMEOUT:
                                connection.release();
                                assert err.infos instanceof ReadTimeoutException;
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getReadTimeouts().inc();

                                ReadTimeoutException rte = (ReadTimeoutException)err.infos;
                                retry = retryPolicy.onReadTimeout(statement,
                                    rte.getConsistencyLevel(),
                                    rte.getRequiredAcknowledgements(),
                                    rte.getReceivedAcknowledgements(),
                                    rte.wasDataRetrieved(),
                                    retriesByPolicy);

                                if (metricsEnabled()) {
                                    if (retry.getType() == Type.RETRY)
                                        metrics().getErrorMetrics().getRetriesOnReadTimeout().inc();
                                    if (retry.getType() == Type.IGNORE)
                                        metrics().getErrorMetrics().getIgnoresOnReadTimeout().inc();
                                }
                                break;
                            case WRITE_TIMEOUT:
                                connection.release();
                                assert err.infos instanceof WriteTimeoutException;
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getWriteTimeouts().inc();

                                WriteTimeoutException wte = (WriteTimeoutException)err.infos;
                                retry = retryPolicy.onWriteTimeout(statement,
                                    wte.getConsistencyLevel(),
                                    wte.getWriteType(),
                                    wte.getRequiredAcknowledgements(),
                                    wte.getReceivedAcknowledgements(),
                                    retriesByPolicy);

                                if (metricsEnabled()) {
                                    if (retry.getType() == Type.RETRY)
                                        metrics().getErrorMetrics().getRetriesOnWriteTimeout().inc();
                                    if (retry.getType() == Type.IGNORE)
                                        metrics().getErrorMetrics().getIgnoresOnWriteTimeout().inc();
                                }
                                break;
                            case UNAVAILABLE:
                                connection.release();
                                assert err.infos instanceof UnavailableException;
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getUnavailables().inc();

                                UnavailableException ue = (UnavailableException)err.infos;
                                retry = retryPolicy.onUnavailable(statement,
                                    ue.getConsistencyLevel(),
                                    ue.getRequiredReplicas(),
                                    ue.getAliveReplicas(),
                                    retriesByPolicy);

                                if (metricsEnabled()) {
                                    if (retry.getType() == Type.RETRY)
                                        metrics().getErrorMetrics().getRetriesOnUnavailable().inc();
                                    if (retry.getType() == Type.IGNORE)
                                        metrics().getErrorMetrics().getIgnoresOnUnavailable().inc();
                                }
                                break;
                            case OVERLOADED:
                                connection.release();
                                
                                logger.warn("Host {} is overloaded, trying next host.", connection.address);
                                DriverException overloaded = new DriverException("Host overloaded");
                                logError(connection.address, overloaded);
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getOthers().inc();
                                retry(false, null);
                                return;
                            case SERVER_ERROR:
                                connection.release();
                                
                                logger.warn("{} replied with server error ({}), trying next host.", connection.address, err.message);
                                DriverException exception = new DriverException("Host replied with server error: " + err.message);
                                logError(connection.address, exception);
                                connection.defunct(exception);
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getOthers().inc();
                                retry(false, null);
                                return;
                            case IS_BOOTSTRAPPING:
                                connection.release();
                                
                                logger.error("Query sent to {} but it is bootstrapping. This shouldn't happen but trying next host.", connection.address);
                                DriverException bootstrapping = new DriverException("Host is bootstrapping");
                                logError(connection.address, bootstrapping);
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getOthers().inc();
                                retry(false, null);
                                return;
                            case UNPREPARED:
                                
                                assert err.infos instanceof MD5Digest;
                                MD5Digest id = (MD5Digest)err.infos;
                                PreparedStatement toPrepare = manager.cluster.manager.preparedQueries.get(id);
                                if (toPrepare == null) {
                                    
                                    connection.release();
                                    String msg = String.format("Tried to execute unknown prepared query %s", id);
                                    logger.error(msg);
                                    setFinalException(connection, new DriverInternalError(msg));
                                    return;
                                }

                                String currentKeyspace = connection.keyspace();
                                String prepareKeyspace = toPrepare.getQueryKeyspace();
                                if (prepareKeyspace != null && (currentKeyspace == null || !currentKeyspace.equals(prepareKeyspace))) {
                                    
                                    
                                    
                                    
                                    connection.release();
                                    throw new IllegalStateException(String.format("Statement was prepared on keyspace %s, can't execute it on %s (%s)",
                                        toPrepare.getQueryKeyspace(), connection.keyspace(), toPrepare.getQueryString()));
                                }

                                logger.info("Query {} is not prepared on {}, preparing before retrying executing. "
                                        + "Seeing this message a few times is fine, but seeing it a lot may be source of performance problems",
                                    toPrepare.getQueryString(), connection.address);

                                write(connection, prepareAndRetry(toPrepare.getQueryString()));
                                
                                return;
                            default:
                                connection.release();
                                if (metricsEnabled())
                                    metrics().getErrorMetrics().getOthers().inc();
                                break;
                        }

                        if (retry == null)
                            setFinalResult(connection, response);
                        else {
                            switch (retry.getType()) {
                                case RETRY:
                                    ++retriesByPolicy;
                                    if (logger.isDebugEnabled())
                                        logger.debug("Doing retry {} for query {} at consistency {}", retriesByPolicy, statement, retry.getRetryConsistencyLevel());
                                    if (metricsEnabled())
                                        metrics().getErrorMetrics().getRetries().inc();
                                    retry(retry.isRetryCurrent(), retry.getRetryConsistencyLevel());
                                    break;
                                case RETHROW:
                                    setFinalResult(connection, response);
                                    break;
                                case IGNORE:
                                    if (metricsEnabled())
                                        metrics().getErrorMetrics().getIgnores().inc();
                                    setFinalResult(connection, new Responses.Result.Void());
                                    break;
                            }
                        }
                        break;
                    default:
                        connection.release();
                        setFinalResult(connection, response);
                        break;
                }
            } catch (Exception e) {
                exceptionToReport = e;
                setFinalException(connection, e);
            } finally {
                if (queriedHost != null && statement != Statement.DEFAULT)
                    manager.cluster.manager.reportLatency(queriedHost, statement, exceptionToReport, latency);
            }
        }

        private Connection.ResponseCallback prepareAndRetry(final String toPrepare) {
            return new Connection.ResponseCallback() {

                @Override
                public Message.Request request() {
                    return new Requests.Prepare(toPrepare);
                }

                @Override
                public int retryCount() {
                    return SpeculativeExecution.this.retryCount();
                }

                @Override
                public void onSet(Connection connection, Message.Response response, long latency, int retryCount) {
                    QueryState queryState = queryStateRef.get();
                    if (!queryState.isInProgressAt(retryCount) ||
                        !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                        logger.debug("onSet triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                            retryCount, queryState, queryStateRef.get());
                        return;
                    }

                    connection.release();

                    
                    switch (response.type) {
                        case RESULT:
                            if (((Responses.Result)response).kind == Responses.Result.Kind.PREPARED) {
                                logger.debug("Scheduling retry now that query is prepared");
                                retry(true, null);
                            } else {
                                logError(connection.address, new DriverException("Got unexpected response to prepare message: " + response));
                                retry(false, null);
                            }
                            break;
                        case ERROR:
                            logError(connection.address, new DriverException("Error preparing query, got " + response));
                            if (metricsEnabled())
                                metrics().getErrorMetrics().getOthers().inc();
                            retry(false, null);
                            break;
                        default:
                            
                            SpeculativeExecution.this.setFinalResult(connection, response);
                            break;
                    }
                }

                @Override
                public void onException(Connection connection, Exception exception, long latency, int retryCount) {
                    SpeculativeExecution.this.onException(connection, exception, latency, retryCount);
                }

                @Override
                public boolean onTimeout(Connection connection, long latency, int retryCount) {
                    QueryState queryState = queryStateRef.get();
                    if (!queryState.isInProgressAt(retryCount) ||
                        !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                        logger.debug("onTimeout triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                            retryCount, queryState, queryStateRef.get());
                        return false;
                    }
                    logError(connection.address, new DriverException("Timeout waiting for response to prepare message"));
                    retry(false, null);
                    return true;
                }
            };
        }

        @Override
        public void onException(Connection connection, Exception exception, long latency, int retryCount) {
            QueryState queryState = queryStateRef.get();
            if (!queryState.isInProgressAt(retryCount) ||
                !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                logger.debug("onException triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                    retryCount, queryState, queryStateRef.get());
                return;
            }

            Host queriedHost = current;
            try {
                connection.release();

                if (exception instanceof ConnectionException) {
                    if (metricsEnabled())
                        metrics().getErrorMetrics().getConnectionErrors().inc();
                    ConnectionException ce = (ConnectionException)exception;
                    logError(ce.address, ce);
                    retry(false, null);
                    return;
                }
                setFinalException(connection, exception);
            } catch (Exception e) {
                
                setFinalException(null, new DriverInternalError("An unexpected error happened while handling exception " + exception, e));
            } finally {
                if (queriedHost != null && statement != Statement.DEFAULT)
                    manager.cluster.manager.reportLatency(queriedHost, statement, exception, latency);
            }
        }

        @Override
        public boolean onTimeout(Connection connection, long latency, int retryCount) {
            QueryState queryState = queryStateRef.get();
            if (!queryState.isInProgressAt(retryCount) ||
                !queryStateRef.compareAndSet(queryState, queryState.complete())) {
                logger.debug("onTimeout triggered but the response was completed by another thread, cancelling (retryCount = {}, queryState = {}, queryStateRef = {})",
                    retryCount, queryState, queryStateRef.get());
                return false;
            }

            Host queriedHost = current;
            OperationTimedOutException timeoutException = new OperationTimedOutException(connection.address);
            try {
                logError(connection.address, timeoutException);
                retry(false, null);
            } catch (Exception e) {
                
                setFinalException(null, new DriverInternalError("An unexpected error happened while handling timeout", e));
            } finally {
                if (queriedHost != null && statement != Statement.DEFAULT)
                    manager.cluster.manager.reportLatency(queriedHost, statement, timeoutException, latency);
            }
            return true;
        }

        @Override
        public int retryCount() {
            return queryStateRef.get().retryCount;
        }

        private void setFinalException(Connection connection, Exception exception) {
            RequestHandler.this.setFinalException(this, connection, exception);
        }

        private void setFinalResult(Connection connection, Message.Response response) {
            RequestHandler.this.setFinalResult(this, connection, response);
        }
    }

    
    static class QueryState {
        static final QueryState INITIAL = new QueryState(-1, false);
        static final QueryState CANCELLED_WHILE_IN_PROGRESS = new QueryState(Integer.MIN_VALUE, false);
        static final QueryState CANCELLED_WHILE_COMPLETE = new QueryState(Integer.MIN_VALUE + 1, false);

        final int retryCount;
        final boolean inProgress;

        private QueryState(int count, boolean inProgress) {
            this.retryCount = count;
            this.inProgress = inProgress;
        }

        boolean isInProgressAt(int retryCount) {
            return inProgress && this.retryCount == retryCount;
        }

        QueryState complete() {
            assert inProgress;
            return new QueryState(retryCount, false);
        }

        QueryState startNext() {
            assert !inProgress;
            return new QueryState(retryCount + 1, true);
        }

        public boolean isCancelled() {
            return this == CANCELLED_WHILE_IN_PROGRESS || this == CANCELLED_WHILE_COMPLETE;
        }

        @Override
        public String toString() {
            return String.format("QueryState(count=%d, inProgress=%s, cancelled=%s)", retryCount, inProgress, isCancelled());
        }
    }

    
    static class QueryPlan {
        private final Iterator<Host> iterator;

        QueryPlan(Iterator<Host> iterator) {
            this.iterator = iterator;
        }

        
        synchronized Host next() {
            return iterator.hasNext() ? iterator.next() : null;
        }
    }
}

<code block>

package com.datastax.driver.core.policies;

import java.util.List;
import java.util.Map;

import com.google.common.collect.ImmutableList;
import com.google.common.collect.ImmutableMap;
import org.mockito.Mockito;
import org.scassandra.http.client.PrimingRequest;
import org.testng.annotations.AfterClass;
import org.testng.annotations.AfterMethod;
import org.testng.annotations.BeforeClass;
import org.testng.annotations.BeforeMethod;

import static org.assertj.core.api.Assertions.assertThat;
import static org.mockito.Matchers.any;
import static org.mockito.Matchers.anyBoolean;
import static org.mockito.Matchers.anyInt;
import static org.mockito.Mockito.times;

import com.datastax.driver.core.*;


public class AbstractRetryPolicyIntegrationTest {
    protected SCassandraCluster scassandras;
    protected Cluster cluster = null;
    protected Metrics.Errors errors;
    protected Host host1, host2, host3;
    protected Session session;

    protected RetryPolicy retryPolicy;

    protected AbstractRetryPolicyIntegrationTest(RetryPolicy retryPolicy) {
        this.retryPolicy = Mockito.spy(retryPolicy);
    }

    @BeforeClass(groups = "short")
    public void beforeClass() {
        scassandras = new SCassandraCluster(CCMBridge.IP_PREFIX, 3);
    }

    @BeforeMethod(groups = "short")
    public void beforeMethod() {
        cluster = Cluster.builder()
            .addContactPoint(CCMBridge.ipOfNode(1))
            .withRetryPolicy(retryPolicy)
            .withLoadBalancingPolicy(new SortingLoadBalancingPolicy())
            .build();

        session = cluster.connect();

        host1 = TestUtils.findHost(cluster, 1);
        host2 = TestUtils.findHost(cluster, 2);
        host3 = TestUtils.findHost(cluster, 3);

        errors = cluster.getMetrics().getErrorMetrics();

        Mockito.reset(retryPolicy);
        scassandras.clearAllPrimes();
        scassandras.clearAllRecordedActivity();
    }

    protected void simulateError(int hostNumber, PrimingRequest.Result result) {
        scassandras
            .prime(hostNumber, PrimingRequest.queryBuilder()
                .withQuery("mock query")
                .withResult(result)
                .build());
    }

    protected void simulateNormalResponse(int hostNumber) {
        scassandras
            .prime(hostNumber, PrimingRequest.queryBuilder()
                .withQuery("mock query")
                .withRows(row("result", "result1"))
                .build());
    }

    private static List<Map<String, ?>> row(String key, String value) {
        return ImmutableList.<Map<String, ?>>of(ImmutableMap.of(key, value));
    }

    protected ResultSet query() {
        return session.execute("mock query");
    }

    protected void assertOnReadTimeoutWasCalled(int times) {
        Mockito.verify(retryPolicy, times(times)).onReadTimeout(
            any(Statement.class), any(ConsistencyLevel.class), anyInt(), anyInt(), anyBoolean(), anyInt());

    }

    protected void assertOnWriteTimeoutWasCalled(int times) {
        Mockito.verify(retryPolicy, times(times)).onWriteTimeout(
            any(Statement.class), any(ConsistencyLevel.class), any(WriteType.class), anyInt(), anyInt(), anyInt());
    }

    protected void assertOnUnavailableWasCalled(int times) {
        Mockito.verify(retryPolicy, times(times)).onUnavailable(
            any(Statement.class), any(ConsistencyLevel.class), anyInt(), anyInt(), anyInt());
    }

    protected void assertQueried(int hostNumber, int times) {
        assertThat(scassandras.retrieveQueries(hostNumber)).hasSize(times);
    }

    @AfterMethod(groups = "short")
    public void afterMethod() {
        scassandras.clearAllPrimes();
        if (cluster != null)
            cluster.close();
    }

    @AfterClass(groups = "short")
    public void afterClass() {
        if (scassandras != null)
            scassandras.stop();
    }
}

<code block>

package com.datastax.driver.core.policies;

import org.testng.annotations.Test;

import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.fail;
import static org.scassandra.http.client.PrimingRequest.Result.read_request_timeout;
import static org.scassandra.http.client.PrimingRequest.Result.unavailable;
import static org.scassandra.http.client.PrimingRequest.Result.write_request_timeout;

import com.datastax.driver.core.exceptions.ReadTimeoutException;
import com.datastax.driver.core.exceptions.UnavailableException;
import com.datastax.driver.core.exceptions.WriteTimeoutException;

public class DefaultRetryPolicyIntegrationTest extends AbstractRetryPolicyIntegrationTest {
    public DefaultRetryPolicyIntegrationTest() {
        super(DefaultRetryPolicy.INSTANCE);
    }

    @Test(groups = "short")
    public void should_rethrow_on_read_timeout_with_0_receivedResponses() {
        simulateError(1, read_request_timeout);

        try {
            query();
            fail("expected a ReadTimeoutException");
        } catch (ReadTimeoutException e) { }

        assertOnReadTimeoutWasCalled(1);
        assertThat(errors.getRetriesOnReadTimeout().getCount()).isEqualTo(0);
        assertQueried(1, 1);
        assertQueried(2, 0);
        assertQueried(3, 0);
    }

    @Test(groups = "short")
    public void should_rethrow_on_write_timeout_with_SIMPLE_write_type() {
        simulateError(1, write_request_timeout);

        try {
            query();
            fail("expected a WriteTimeoutException");
        } catch (WriteTimeoutException e) {}

        assertOnWriteTimeoutWasCalled(1);
        assertThat(errors.getRetriesOnWriteTimeout().getCount()).isEqualTo(0);
        assertQueried(1, 1);
        assertQueried(2, 0);
        assertQueried(3, 0);
    }

    @Test(groups = "short")
    public void should_try_next_host_on_first_unavailable() {
        simulateError(1, unavailable);
        simulateNormalResponse(2);

        query();

        assertOnUnavailableWasCalled(1);
        assertThat(errors.getRetriesOnUnavailable().getCount()).isEqualTo(1);
        assertQueried(1, 1);
        assertQueried(2, 1);
        assertQueried(3, 0);
    }

    @Test(groups = "short")
    public void should_rethrow_on_second_unavailable() {
        simulateError(1, unavailable);
        simulateError(2, unavailable);

        try {
            query();
            fail("expected an UnavailableException");
        } catch (UnavailableException e) {}

        assertOnUnavailableWasCalled(2);
        assertThat(errors.getRetriesOnUnavailable().getCount()).isEqualTo(1);
        assertQueried(1, 1);
        assertQueried(2, 1);
        assertQueried(3, 0);
    }
}

<code block>

package com.datastax.driver.mapping;

import java.lang.reflect.Field;
import java.util.*;

import com.datastax.driver.core.ConsistencyLevel;
import static com.datastax.driver.core.querybuilder.QueryBuilder.quote;

abstract class EntityMapper<T> {

    public final Class<T> entityClass;
    private final String keyspace;
    private final String table;

    public final ConsistencyLevel writeConsistency;
    public final ConsistencyLevel readConsistency;

    public final List<ColumnMapper<T>> partitionKeys = new ArrayList<ColumnMapper<T>>();
    public final List<ColumnMapper<T>> clusteringColumns = new ArrayList<ColumnMapper<T>>();
    public final List<ColumnMapper<T>> regularColumns = new ArrayList<ColumnMapper<T>>();

    private final List<ColumnMapper<T>> allColumns = new ArrayList<ColumnMapper<T>>();

    public final StrategyType strategyType;

    protected EntityMapper(Class<T> entityClass, String keyspace, String table, ConsistencyLevel writeConsistency, ConsistencyLevel readConsistency, StrategyType strategyType) {
        this.entityClass = entityClass;
        this.keyspace = keyspace;
        this.table = table;
        this.writeConsistency = writeConsistency;
        this.readConsistency = readConsistency;
        this.strategyType = strategyType;
    }

    public String getKeyspace() {
        return quote(keyspace);
    }

    public String getTable() {
        return quote(table);
    }

    public int primaryKeySize() {
        return partitionKeys.size() + clusteringColumns.size();
    }

    public ColumnMapper<T> getPrimaryKeyColumn(int i) {
        return i < partitionKeys.size() ? partitionKeys.get(i) : clusteringColumns.get(i - partitionKeys.size());
    }

    public void addColumns(List<ColumnMapper<T>> pks, List<ColumnMapper<T>> ccs, List<ColumnMapper<T>> rgs) {
        partitionKeys.addAll(pks);
        allColumns.addAll(pks);

        clusteringColumns.addAll(ccs);
        allColumns.addAll(ccs);

        addColumns(rgs);
    }

    public void addColumns(List<ColumnMapper<T>> rgs) {
        regularColumns.addAll(rgs);
        allColumns.addAll(rgs);
    }

    public abstract T newEntity();

    public List<ColumnMapper<T>> allColumns() {
        return allColumns;
    }

    interface Factory {
        public <T> EntityMapper<T> create(Class<T> entityClass, String keyspace, String table, ConsistencyLevel writeConsistency, ConsistencyLevel readConsistency, StrategyType strategyType);
        public <T> ColumnMapper<T> createColumnMapper(Class<T> componentClass, Field field, int position, MappingManager mappingManager);
    }
}

<code block>

package com.datastax.driver.mapping;

import java.beans.IntrospectionException;
import java.beans.PropertyDescriptor;
import java.lang.reflect.Field;
import java.lang.reflect.Method;
import java.lang.reflect.ParameterizedType;
import java.lang.reflect.Type;
import java.util.HashMap;
import java.util.Map;

import com.datastax.driver.core.ConsistencyLevel;
import com.datastax.driver.core.DataType;
import com.datastax.driver.core.UDTValue;


class ReflectionMapper<T> extends EntityMapper<T> {

    private static ReflectionFactory factory = new ReflectionFactory();

    private ReflectionMapper(Class<T> entityClass, String keyspace, String table, ConsistencyLevel writeConsistency, ConsistencyLevel readConsistency, StrategyType strategyType) {
        super(entityClass, keyspace, table, writeConsistency, readConsistency, strategyType);
    }

    public static Factory factory() {
        return factory;
    }

    @Override
    public T newEntity() {
        try {
            return entityClass.newInstance();
        } catch (Exception e) {
            throw new RuntimeException("Can't create an instance of " + entityClass.getName());
        }
    }

    private static class LiteralMapper<T> extends ColumnMapper<T> {

        private final Method readMethod;
        private final Method writeMethod;

        private LiteralMapper(Field field, int position, PropertyDescriptor pd) {
            this(field, extractSimpleType(field), position, pd);
        }

        private LiteralMapper(Field field, DataType type, int position, PropertyDescriptor pd) {
            super(field, type, position);
            this.readMethod = pd.getReadMethod();
            this.writeMethod = pd.getWriteMethod();
        }

        @Override
        public Object getValue(T entity) {
            try {
                return readMethod.invoke(entity);
            } catch (IllegalArgumentException e) {
                throw new IllegalArgumentException("Could not get field '" + fieldName + "'");
            } catch (Exception e) {
                throw new IllegalStateException("Unable to access getter for '" + fieldName + "' in " + entity.getClass().getName(), e);
            }
        }

        @Override
        public void setValue(Object entity, Object value) {
            try {
                writeMethod.invoke(entity, value);
            } catch (IllegalArgumentException e) {
                throw new IllegalArgumentException("Could not set field '" + fieldName + "' to value '" + value + "'");
            } catch (Exception e) {
                throw new IllegalStateException("Unable to access setter for '" + fieldName + "' in " + entity.getClass().getName(), e);
            }
        }
    }

    private static class EnumMapper<T> extends LiteralMapper<T> {

        private final EnumType enumType;
        private final Map<String, Object> fromString;

        private EnumMapper(Field field, int position, PropertyDescriptor pd, EnumType enumType) {
            super(field, enumType == EnumType.STRING ? DataType.text() : DataType.cint(), position, pd);
            this.enumType = enumType;

            if (enumType == EnumType.STRING) {
                fromString = new HashMap<String, Object>(javaType.getEnumConstants().length);
                for (Object constant : javaType.getEnumConstants())
                    fromString.put(constant.toString().toLowerCase(), constant);

            } else {
                fromString = null;
            }
        }

        @SuppressWarnings("rawtypes")
        @Override
        public Object getValue(T entity) {
            Object value = super.getValue(entity);
            switch (enumType) {
                case STRING:
                    return (value == null) ? null : value.toString();
                case ORDINAL:
                    return (value == null) ? null : ((Enum)value).ordinal();
            }
            throw new AssertionError();
        }

        @Override
        public void setValue(Object entity, Object value) {
            Object converted = null;
            switch (enumType) {
                case STRING:
                    converted = fromString.get(value.toString().toLowerCase());
                    break;
                case ORDINAL:
                    converted = javaType.getEnumConstants()[(Integer)value];
                    break;
            }
            super.setValue(entity, converted);
        }
    }

    private static class UDTColumnMapper<T, U> extends LiteralMapper<T> {
        private final UDTMapper<U> udtMapper;

        private UDTColumnMapper(Field field, int position, PropertyDescriptor pd, UDTMapper<U> udtMapper) {
            super(field, udtMapper.getUserType(), position, pd);
            this.udtMapper = udtMapper;
        }

        @Override
        public Object getValue(T entity) {
            @SuppressWarnings("unchecked")
            U udtEntity = (U)super.getValue(entity);
            return udtEntity == null ? null : udtMapper.toUDT(udtEntity);
        }

        @Override
        public void setValue(Object entity, Object value) {
            assert value instanceof UDTValue;
            UDTValue udtValue = (UDTValue)value;
            assert udtValue.getType().equals(udtMapper.getUserType());

            super.setValue(entity, udtMapper.toEntity((udtValue)));
        }
    }

    private static class NestedUDTMapper<T> extends LiteralMapper<T> {
        private final InferredCQLType inferredCQLType;

        public NestedUDTMapper(Field field, int position, PropertyDescriptor pd, InferredCQLType inferredCQLType) {
            super(field, inferredCQLType.dataType, position, pd);
            this.inferredCQLType = inferredCQLType;
        }

        @Override
        @SuppressWarnings("unchecked")
        public Object getValue(T entity) {
            Object valueWithEntities = super.getValue(entity);
            return (T)UDTMapper.convertEntitiesToUDTs(valueWithEntities, inferredCQLType);
        }

        @Override
        public void setValue(Object entity, Object valueWithUDTValues) {
            super.setValue(entity, UDTMapper.convertUDTsToEntities(valueWithUDTValues, inferredCQLType));
        }
    }

    static DataType extractSimpleType(Field f) {
        Type type = f.getGenericType();

        assert !(type instanceof ParameterizedType);

        if (!(type instanceof Class))
            throw new IllegalArgumentException(String.format("Cannot map class %s for field %s", type, f.getName()));

        return TypeMappings.getSimpleType((Class<?>)type, f.getName());
    }

    private static class ReflectionFactory implements Factory {

        public <T> EntityMapper<T> create(Class<T> entityClass, String keyspace, String table, ConsistencyLevel writeConsistency, ConsistencyLevel readConsistency, StrategyType strategyType) {
            return new ReflectionMapper<T>(entityClass, keyspace, table, writeConsistency, readConsistency, strategyType);
        }

        @SuppressWarnings({ "unchecked", "rawtypes" })
        public <T> ColumnMapper<T> createColumnMapper(Class<T> entityClass, Field field, int position, MappingManager mappingManager) {
            String fieldName = field.getName();
            try {
                PropertyDescriptor pd = new PropertyDescriptor(fieldName, field.getDeclaringClass());

                if (field.getType().isEnum()) {
                    return new EnumMapper<T>(field, position, pd, AnnotationParser.enumType(field));
                }

                if (TypeMappings.isMappedUDT(field.getType())) {
                    UDTMapper<?> udtMapper = mappingManager.getUDTMapper(field.getType());
                    return (ColumnMapper<T>)new UDTColumnMapper(field, position, pd, udtMapper);
                }

                if (field.getGenericType() instanceof ParameterizedType) {
                    InferredCQLType inferredCQLType = InferredCQLType.from(field, mappingManager);
                    if (inferredCQLType.containsMappedUDT) {
                        
                        return (ColumnMapper<T>)new NestedUDTMapper(field, position, pd, inferredCQLType);
                    } else {
                        
                        return new LiteralMapper<T>(field, inferredCQLType.dataType, position, pd);
                    }
                }

                return new LiteralMapper<T>(field, position, pd);

            } catch (IntrospectionException e) {
                throw new IllegalArgumentException("Cannot find matching getter and setter for field '" + fieldName + "'");
            }
        }
    }
}

<code block>

package com.datastax.driver.mapping;

import java.util.*;

import com.google.common.base.Objects;

import com.datastax.driver.core.TableMetadata;
import com.datastax.driver.core.querybuilder.Delete;
import com.datastax.driver.core.querybuilder.Insert;
import com.datastax.driver.core.querybuilder.Select;

import static com.datastax.driver.core.querybuilder.QueryBuilder.*;

class QueryType {

    private enum Kind {SAVE, GET, DEL, SLICE, REVERSED_SLICE}

    ;
    private final Kind kind;

    
    private final int startBoundSize;
    private final boolean startInclusive;
    private final int endBoundSize;
    private final boolean endInclusive;

    public static final QueryType SAVE = new QueryType(Kind.SAVE);
    public static final QueryType DEL = new QueryType(Kind.DEL);
    public static final QueryType GET = new QueryType(Kind.GET);

    private QueryType(Kind kind) {
        this(kind, 0, false, 0, false);
    }

    private QueryType(Kind kind, int startBoundSize, boolean startInclusive, int endBoundSize, boolean endInclusive) {
        this.kind = kind;
        this.startBoundSize = startBoundSize;
        this.startInclusive = startInclusive;
        this.endBoundSize = endBoundSize;
        this.endInclusive = endInclusive;
    }

    public static QueryType slice(int startBoundSize, boolean startInclusive, int endBoundSize, boolean endInclusive, boolean reversed) {
        return new QueryType(reversed ? Kind.REVERSED_SLICE : Kind.SLICE, startBoundSize, startInclusive, endBoundSize, endInclusive);
    }

    String makePreparedQueryString(TableMetadata table, EntityMapper<?> mapper, Set<ColumnMapper<?>> columns, Mapper.Option... options) {
        switch (kind) {
            case SAVE: {
                Insert insert = table == null
                    ? insertInto(mapper.getKeyspace(), mapper.getTable())
                    : insertInto(table);
                for (ColumnMapper<?> cm : columns)
                    insert.value(cm.getColumnName(), bindMarker());
                if (options != null) {
                    Insert.Options usings = insert.using();
                    for (Mapper.Option opt : options) {
                        if (opt instanceof Mapper.Option.Ttl)
                            
                            usings.and(ttl(bindMarker()));
                        else
                            usings.and(timestamp(bindMarker()));
                    }
                }
                return insert.toString();
            }
            case GET: {
                Select select = table == null
                    ? select().all().from(mapper.getKeyspace(), mapper.getTable())
                    : select().all().from(table);
                Select.Where where = select.where();
                for (int i = 0; i < mapper.primaryKeySize(); i++)
                    where.and(eq(mapper.getPrimaryKeyColumn(i).getColumnName(), bindMarker()));
                return select.toString();
            }
            case DEL: {
                Delete delete = table == null
                    ? delete().all().from(mapper.getKeyspace(), mapper.getTable())
                    : delete().all().from(table);
                Delete.Where where = delete.where();
                for (int i = 0; i < mapper.primaryKeySize(); i++)
                    where.and(eq(mapper.getPrimaryKeyColumn(i).getColumnName(), bindMarker()));
                Delete.Options usings = delete.using();
                if (options != null){
                    for (Mapper.Option opt : options) {
                        if (opt instanceof Mapper.Option.Timestamp) {
                            usings.and(timestamp(bindMarker()));
                        } else {
                            throw new UnsupportedOperationException("Cannot use another option than TIMESTAMP for DELETE operations");
                        }
                    }
                }
                return delete.toString();
            }
            case SLICE:
            case REVERSED_SLICE: {
                Select select = table == null
                    ? select().all().from(mapper.getKeyspace(), mapper.getTable())
                    : select().all().from(table);
                Select.Where where = select.where();
                for (int i = 0; i < mapper.partitionKeys.size(); i++)
                    where.and(eq(mapper.partitionKeys.get(i).getColumnName(), bindMarker()));

                if (startBoundSize > 0) {
                    if (startBoundSize == 1) {
                        String name = mapper.clusteringColumns.get(0).getColumnName();
                        where.and(startInclusive ? gte(name, bindMarker()) : gt(name, bindMarker()));
                    } else {
                        List<String> names = new ArrayList<String>(startBoundSize);
                        List<Object> values = new ArrayList<Object>(startBoundSize);
                        for (int i = 0; i < startBoundSize; i++) {
                            names.add(mapper.clusteringColumns.get(i).getColumnName());
                            values.add(bindMarker());
                        }
                        where.and(startInclusive ? gte(names, values) : gt(names, values));
                    }
                }

                if (endBoundSize > 0) {
                    if (endBoundSize == 1) {
                        String name = mapper.clusteringColumns.get(0).getColumnName();
                        where.and(endInclusive ? gte(name, bindMarker()) : gt(name, bindMarker()));
                    } else {
                        List<String> names = new ArrayList<String>(endBoundSize);
                        List<Object> values = new ArrayList<Object>(endBoundSize);
                        for (int i = 0; i < endBoundSize; i++) {
                            names.add(mapper.clusteringColumns.get(i).getColumnName());
                            values.add(bindMarker());
                        }
                        where.and(endInclusive ? lte(names, values) : lt(names, values));
                    }
                }

                select = select.limit(bindMarker());

                if (kind == Kind.REVERSED_SLICE)
                    select = select.orderBy(desc(mapper.clusteringColumns.get(0).getColumnName()));

                return select.toString();
            }
        }
        throw new AssertionError();
    }


    @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null || this.getClass() != obj.getClass())
            return false;

        QueryType that = (QueryType)obj;
        return kind == that.kind
            && startBoundSize == that.startBoundSize
            && startInclusive == that.startInclusive
            && endBoundSize == that.endBoundSize
            && endInclusive == that.endInclusive;
    }

    @Override
    public int hashCode() {
        return Objects.hashCode(kind, startBoundSize, startInclusive, endBoundSize, endInclusive);
    }

}

<code block>

package com.datastax.driver.mapping;

import java.util.*;

import com.google.common.base.Function;
import com.google.common.base.Functions;
import com.google.common.util.concurrent.Futures;
import com.google.common.util.concurrent.ListenableFuture;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.datastax.driver.core.*;


public class Mapper<T> {

    private static final Logger logger = LoggerFactory.getLogger(EntityMapper.class);

    final MappingManager manager;
    final ProtocolVersion protocolVersion;
    final Class<T> klass;
    final EntityMapper<T> mapper;
    final TableMetadata tableMetadata;

    
    private volatile Map<String, PreparedStatement> preparedQueries = Collections.<String, PreparedStatement>emptyMap();

    private static final Function<Object, Void> NOOP = Functions.<Void>constant(null);

    private volatile Option[] defaultSaveOptions;
    private volatile Option[] defaultDeleteOptions;

    final Function<ResultSet, T> mapOneFunction;
    final Function<ResultSet, Result<T>> mapAllFunction;

    Mapper(MappingManager manager, Class<T> klass, EntityMapper<T> mapper) {
        this.manager = manager;
        this.klass = klass;
        this.mapper = mapper;

        KeyspaceMetadata keyspace = session().getCluster().getMetadata().getKeyspace(mapper.getKeyspace());
        this.tableMetadata = keyspace == null ? null : keyspace.getTable(Metadata.quote(mapper.getTable()));

        this.protocolVersion = manager.getSession().getCluster().getConfiguration().getProtocolOptions().getProtocolVersionEnum();
        this.mapOneFunction = new Function<ResultSet, T>() {
            public T apply(ResultSet rs) {
                return Mapper.this.map(rs).one();
            }
        };
        this.mapAllFunction = new Function<ResultSet, Result<T>>() {
            public Result<T> apply(ResultSet rs) {
                return Mapper.this.map(rs);
            }
        };
        this.preparedQueries.clear();
    }

    Session session() {
        return manager.getSession();
    }

    PreparedStatement getPreparedQuery(QueryType type, Set<ColumnMapper<?>> columns, Option... options) {
        String queryString;
        queryString = type.makePreparedQueryString(tableMetadata, mapper, columns, options);
        PreparedStatement stmt = preparedQueries.get(queryString);
        if (stmt == null) {
            synchronized (preparedQueries) {
                stmt = preparedQueries.get(queryString);
                if (stmt == null) {
                    logger.debug("Preparing query {}", queryString);
                    stmt = session().prepare(queryString);
                    Map<String, PreparedStatement> newQueries = new HashMap<String, PreparedStatement>(preparedQueries);
                    newQueries.put(queryString, stmt);
                    preparedQueries = newQueries;
                }
            }
        }
        return stmt;
    }

    PreparedStatement getPreparedQuery(QueryType type, Option... options){
        return getPreparedQuery(type, Collections.<ColumnMapper<?>>emptySet(), options);
    }

    
    public TableMetadata getTableMetadata() {
        return tableMetadata;
    }

    
    public MappingManager getManager() {
        return manager;
    }

    
    public Statement saveQuery(T entity, Option... options) {
        Map<ColumnMapper<?>, Object> values = new HashMap<ColumnMapper<?>, Object>();
        for (ColumnMapper<T> cm : mapper.allColumns()) {
            Object value = cm.getValue(entity);
            if (mapper.strategyType == StrategyType.ALL_FIELDS || value != null) {
                values.put(cm, value);
            }
        }
        PreparedStatement ps;
        if (options.length > 0){
            ps = getPreparedQuery(QueryType.SAVE, values.keySet(), options);
        } else {
            ps = getPreparedQuery(QueryType.SAVE, values.keySet(), this.defaultSaveOptions);
        }

        BoundStatement bs = ps.bind();
        int i = 0;
        for (Map.Entry<ColumnMapper<?>, Object> entry : values.entrySet()) {
            bs.setBytesUnsafe(i++, entry.getValue() == null ? null : entry.getKey().getDataType().serialize(entry.getValue(), protocolVersion));
        }

        if (options.length > 0) {
            for (Option opt : options) {
                if (opt instanceof Option.Ttl) {
                    Option.Ttl ttlOption = (Option.Ttl)opt;
                    bs.setInt(i++, ttlOption.getValue());
                }
                if (opt instanceof Option.Timestamp) {
                    Option.Timestamp tsOption = (Option.Timestamp)opt;
                    bs.setLong(i++, tsOption.getValue());
                }
            }
        }

        if (mapper.writeConsistency != null)
            bs.setConsistencyLevel(mapper.writeConsistency);
        return bs;
    }

    
    public void save(T entity) {
        session().execute(saveQuery(entity));
    }

    
    public void save(T entity, Option... options) {
        session().execute(saveQuery(entity, options));
    }

    
    public ListenableFuture<Void> saveAsync(T entity) {
        return Futures.transform(session().executeAsync(saveQuery(entity)), NOOP);
    }

    
    public ListenableFuture<Void> saveAsync(T entity, Option... options) {
        return Futures.transform(session().executeAsync(saveQuery(entity, options)), NOOP);
    }

    
    public Statement deleteQuery(T entity, Option... options) {
        Object[] pks = new Object[mapper.primaryKeySize()];
        for (int i = 0; i < pks.length; i++)
            pks[i] = mapper.getPrimaryKeyColumn(i).getValue(entity);

        return deleteQuery(pks, Arrays.asList(options));
    }

    
    public Statement deleteQuery(T entity) {
        Object[] pks = new Object[mapper.primaryKeySize()];
        for (int i = 0; i < pks.length; i++)
            pks[i] = mapper.getPrimaryKeyColumn(i).getValue(entity);

        return deleteQuery(pks);
    }

    
    public Statement deleteQuery(Object... args) {
        List<Object> pks = new ArrayList<Object>();
        List<Option> options = new ArrayList<Option>();
        for (Object o : args) {
            if (o instanceof Option) {
                options.add((Option)o);
            } else {
                pks.add(o);
            }
        }
        return deleteQuery(pks.toArray(), options);
    }

    private Statement deleteQuery(Object[] primaryKey, List<Option> options) {
        if (primaryKey.length != mapper.primaryKeySize())
            throw new IllegalArgumentException(String.format("Invalid number of PRIMARY KEY columns provided, %d expected but got %d", mapper.primaryKeySize(), primaryKey.length));

        PreparedStatement ps;
        if (options.size() != 0){
            ps = getPreparedQuery(QueryType.DEL, options.toArray(new Option[options.size()]));
        }
        else {
            ps = getPreparedQuery(QueryType.DEL, this.defaultDeleteOptions);
        }

        BoundStatement bs = ps.bind();
        int i;
        for (i = 0; i < primaryKey.length; i++) {
            ColumnMapper<T> column = mapper.getPrimaryKeyColumn(i);
            Object value = primaryKey[i];
            if (value == null)
                throw new IllegalArgumentException(String.format("Invalid null value for PRIMARY KEY column %s (argument %d)", column.getColumnName(), i));
            bs.setBytesUnsafe(i, column.getDataType().serialize(value, protocolVersion));
        }

        for (Option opt : options) {
            if (opt instanceof Option.Ttl) {
                Option.Ttl ttlOption = (Option.Ttl)opt;
                bs.setInt(i++, ttlOption.getValue());
            }
        }

        if (mapper.writeConsistency != null)
            bs.setConsistencyLevel(mapper.writeConsistency);
        return bs;
    }

    
    public void delete(T entity) {
        session().execute(deleteQuery(entity));
    }

    
    public void delete(T entity, Option... options) {
        session().execute(deleteQuery(entity, options));
    }

    
    public ListenableFuture<Void> deleteAsync(T entity) {
        return Futures.transform(session().executeAsync(deleteQuery(entity)), NOOP);
    }

    
    public ListenableFuture<Void> deleteAsync(T entity, Option... options) {
        return Futures.transform(session().executeAsync(deleteQuery(entity, options)), NOOP);
    }

    
    public void delete(Object... objects) {
        session().execute(deleteQuery(objects));
    }

    
    public ListenableFuture<Void> deleteAsync(Object... objects) {
        return Futures.transform(session().executeAsync(deleteQuery(objects)), NOOP);
    }

    
    public Result<T> map(ResultSet resultSet) {
        return new Result<T>(resultSet, mapper, protocolVersion);
    }

    
    public Statement getQuery(Object... primaryKey) {
        if (primaryKey.length != mapper.primaryKeySize())
            throw new IllegalArgumentException(String.format("Invalid number of PRIMARY KEY columns provided, %d expected but got %d", mapper.primaryKeySize(), primaryKey.length));

        PreparedStatement ps = getPreparedQuery(QueryType.GET);

        BoundStatement bs = ps.bind();
        for (int i = 0; i < primaryKey.length; i++) {
            ColumnMapper<T> column = mapper.getPrimaryKeyColumn(i);
            Object value = primaryKey[i];
            if (value == null)
                throw new IllegalArgumentException(String.format("Invalid null value for PRIMARY KEY column %s (argument %d)", column.getColumnName(), i));
            bs.setBytesUnsafe(i, column.getDataType().serialize(value, protocolVersion));
        }

        if (mapper.readConsistency != null)
            bs.setConsistencyLevel(mapper.readConsistency);
        return bs;
    }

    
    public T get(Object... primaryKey) {
        return map(session().execute(getQuery(primaryKey))).one();
    }

    
    public ListenableFuture<T> getAsync(Object... primaryKey) {
        return Futures.transform(session().executeAsync(getQuery(primaryKey)), mapOneFunction);
    }

    
    public void setDefaultSaveOptions(Option... options) {
        this.defaultSaveOptions = Arrays.copyOf(options, options.length);
    }

    
    public void resetDefaultSaveOptions() {
        this.defaultSaveOptions = null;
    }

    
    public void setDefaultDeleteOptions(Option... options) {
        this.defaultDeleteOptions = Arrays.copyOf(options, options.length);
    }

    
    public void resetDefaultDeleteOptions() {
        this.defaultDeleteOptions = null;
    }

    
    public static abstract class Option {

        static class Ttl extends Option {

            private int ttlValue;

            Ttl(int value) {
                this.ttlValue = value;
            }

            
            public int getValue() {
                return this.ttlValue;
            }
        }

        static class Timestamp extends Option {

            private long tsValue;

            Timestamp(long value) {
                this.tsValue = value;
            }

            
            public long getValue() {
                return this.tsValue;
            }
        }

        
        public static Option ttl(int value) {
            return new Ttl(value);
        }

        
        public static Option timestamp(long value) {
            return new Timestamp(value);
        }
    }

}

<code block>


package com.datastax.driver.mapping;


public enum StrategyType {
    ALL_FIELDS, NOT_NULL_FIELDS_ONLY
}

<code block>

package com.datastax.driver.mapping;

import java.lang.annotation.Annotation;
import java.lang.reflect.Field;
import java.lang.reflect.*;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;

import com.google.common.base.Strings;

import com.datastax.driver.core.ConsistencyLevel;
import com.datastax.driver.mapping.MethodMapper.EnumParamMapper;
import com.datastax.driver.mapping.MethodMapper.NestedUDTParamMapper;
import com.datastax.driver.mapping.MethodMapper.ParamMapper;
import com.datastax.driver.mapping.MethodMapper.UDTParamMapper;
import com.datastax.driver.mapping.annotations.*;


class AnnotationParser {

    private static final Comparator<Field> fieldComparator = new Comparator<Field>() {
        public int compare(Field f1, Field f2) {
            return position(f1) - position(f2);
        }
    };

    private AnnotationParser() {}

    public static <T> EntityMapper<T> parseEntity(Class<T> entityClass, EntityMapper.Factory factory, MappingManager mappingManager) {
        Table table = AnnotationChecks.getTypeAnnotation(Table.class, entityClass);

        String ksName = table.caseSensitiveKeyspace() ? table.keyspace() : table.keyspace().toLowerCase();
        String tableName = table.caseSensitiveTable() ? table.name() : table.name().toLowerCase();

        ConsistencyLevel writeConsistency = table.writeConsistency().isEmpty() ? null : ConsistencyLevel.valueOf(table.writeConsistency().toUpperCase());
        ConsistencyLevel readConsistency = table.readConsistency().isEmpty() ? null : ConsistencyLevel.valueOf(table.readConsistency().toUpperCase());

        if (Strings.isNullOrEmpty(table.keyspace())) {
            ksName = mappingManager.getSession().getLoggedKeyspace();
            if (Strings.isNullOrEmpty(ksName))
                throw new IllegalArgumentException(String.format(
                    "Error creating mapper for class %s, the @%s annotation declares no default keyspace, and the session is not currently logged to any keyspace",
                    entityClass.getSimpleName(),
                    Table.class.getSimpleName()
                ));
        }

        StrategyType insertStrategy = table.saveStrategy();

        EntityMapper<T> mapper = factory.create(entityClass, ksName, tableName, writeConsistency, readConsistency, insertStrategy);

        List<Field> pks = new ArrayList<Field>();
        List<Field> ccs = new ArrayList<Field>();
        List<Field> rgs = new ArrayList<Field>();

        for (Field field : entityClass.getDeclaredFields()) {
            if(field.isSynthetic() || (field.getModifiers() & Modifier.STATIC) == Modifier.STATIC)
                continue;
            
            AnnotationChecks.validateAnnotations(field, "entity",
                                                 Column.class, ClusteringColumn.class, Enumerated.class, Frozen.class, FrozenKey.class,
                                                 FrozenValue.class, PartitionKey.class, Transient.class);

            if (field.getAnnotation(Transient.class) != null)
                continue;

            switch (kind(field)) {
                case PARTITION_KEY:
                    pks.add(field);
                    break;
                case CLUSTERING_COLUMN:
                    ccs.add(field);
                    break;
                default:
                    rgs.add(field);
                    break;
            }
        }

        Collections.sort(pks, fieldComparator);
        Collections.sort(ccs, fieldComparator);

        validateOrder(pks, "@PartitionKey");
        validateOrder(ccs, "@ClusteringColumn");

        mapper.addColumns(convert(pks, factory, mapper.entityClass, mappingManager),
                          convert(ccs, factory, mapper.entityClass, mappingManager),
                          convert(rgs, factory, mapper.entityClass, mappingManager));
        return mapper;
    }

    public static <T> EntityMapper<T> parseUDT(Class<T> udtClass, EntityMapper.Factory factory, MappingManager mappingManager) {
        UDT udt = AnnotationChecks.getTypeAnnotation(UDT.class, udtClass);

        String ksName = udt.caseSensitiveKeyspace() ? udt.keyspace() : udt.keyspace().toLowerCase();
        String udtName = udt.caseSensitiveType() ? udt.name() : udt.name().toLowerCase();

        if (Strings.isNullOrEmpty(udt.keyspace())) {
            ksName = mappingManager.getSession().getLoggedKeyspace();
            if (Strings.isNullOrEmpty(ksName))
                throw new IllegalArgumentException(String.format(
                    "Error creating UDT mapper for class %s, the @%s annotation declares no default keyspace, and the session is not currently logged to any keyspace",
                    udtClass.getSimpleName(),
                    UDT.class.getSimpleName()
                ));
        }

        StrategyType insertUDTStrategy = udt.insert();

        EntityMapper<T> mapper = factory.create(udtClass, ksName, udtName, null, null, insertUDTStrategy);

        List<Field> columns = new ArrayList<Field>();

        for (Field field : udtClass.getDeclaredFields()) {
            if(field.isSynthetic() || (field.getModifiers() & Modifier.STATIC) == Modifier.STATIC)
                continue;
            
            AnnotationChecks.validateAnnotations(field, "UDT",
                                                 com.datastax.driver.mapping.annotations.Field.class, Frozen.class, FrozenKey.class,
                                                 FrozenValue.class, Enumerated.class, Transient.class);

            if (field.getAnnotation(Transient.class) != null)
                continue;

            switch (kind(field)) {
                case PARTITION_KEY:
                    throw new IllegalArgumentException("Annotation @PartitionKey is not allowed in a class annotated by @UDT");
                case CLUSTERING_COLUMN:
                    throw new IllegalArgumentException("Annotation @ClusteringColumn is not allowed in a class annotated by @UDT");
                default:
                    columns.add(field);
                    break;
            }
        }

        mapper.addColumns(convert(columns, factory, udtClass, mappingManager));
        return mapper;
    }

    private static <T> List<ColumnMapper<T>> convert(List<Field> fields, EntityMapper.Factory factory, Class<T> klass, MappingManager mappingManager) {
        List<ColumnMapper<T>> mappers = new ArrayList<ColumnMapper<T>>(fields.size());
        for (int i = 0; i < fields.size(); i++) {
            Field field = fields.get(i);
            int pos = position(field);
            mappers.add(factory.createColumnMapper(klass, field, pos < 0 ? i : pos, mappingManager));
        }
        return mappers;
    }

    private static void validateOrder(List<Field> fields, String annotation) {
        for (int i = 0; i < fields.size(); i++) {
            Field field = fields.get(i);
            int pos = position(field);
            if (pos != i)
                throw new IllegalArgumentException(String.format("Invalid ordering value %d for annotation %s of column %s, was expecting %d",
                                                                 pos, annotation, field.getName(), i));
        }
    }

    private static int position(Field field) {
        switch (kind(field)) {
            case PARTITION_KEY:
                return field.getAnnotation(PartitionKey.class).value();
            case CLUSTERING_COLUMN:
                return field.getAnnotation(ClusteringColumn.class).value();
            default:
                return -1;
        }
    }

    public static ColumnMapper.Kind kind(Field field) {
        PartitionKey pk = field.getAnnotation(PartitionKey.class);
        ClusteringColumn cc = field.getAnnotation(ClusteringColumn.class);
        if (pk != null && cc != null)
            throw new IllegalArgumentException("Field " + field.getName() + " cannot have both the @PartitionKey and @ClusteringColumn annotations");

        return pk != null
             ? ColumnMapper.Kind.PARTITION_KEY
             : (cc != null ? ColumnMapper.Kind.CLUSTERING_COLUMN : ColumnMapper.Kind.REGULAR);
    }

    public static EnumType enumType(Field field) {
        Class<?> type = field.getType();
        if (!type.isEnum())
            return null;

        Enumerated enumerated = field.getAnnotation(Enumerated.class);
        return (enumerated == null) ? EnumType.STRING : enumerated.value();
    }

    public static String columnName(Field field) {
        Column column = field.getAnnotation(Column.class);
        if (column != null && !column.name().isEmpty()) {
            return column.caseSensitive() ? column.name() : column.name().toLowerCase();
        }

        com.datastax.driver.mapping.annotations.Field udtField = field.getAnnotation(com.datastax.driver.mapping.annotations.Field.class);
        if (udtField != null && !udtField.name().isEmpty()) {
            return udtField.caseSensitive() ? udtField.name() : udtField.name().toLowerCase();
        }

        return field.getName().toLowerCase();
    }

    public static <T> AccessorMapper<T> parseAccessor(Class<T> accClass, AccessorMapper.Factory factory, MappingManager mappingManager) {
        if (!accClass.isInterface())
            throw new IllegalArgumentException("@Accessor annotation is only allowed on interfaces");

        AnnotationChecks.getTypeAnnotation(Accessor.class, accClass);

        List<MethodMapper> methods = new ArrayList<MethodMapper>();
        for (Method m : accClass.getDeclaredMethods()) {
            Query query = m.getAnnotation(Query.class);
            if (query == null)
                continue;

            String queryString = query.value();

            Annotation[][] paramAnnotations = m.getParameterAnnotations();
            Type[] paramTypes = m.getGenericParameterTypes();
            ParamMapper[] paramMappers = new ParamMapper[paramAnnotations.length];
            Boolean hasParamAnnotation = null;
            for (int i = 0; i < paramMappers.length; i++) {
                String paramName = null;
                for (Annotation a : paramAnnotations[i]) {
                    if (a.annotationType().equals(Param.class)) {
                        paramName = ((Param) a).value();
                        break;
                    }
                }
                if (hasParamAnnotation == null)
                    hasParamAnnotation = (paramName != null);
                if (hasParamAnnotation != (paramName != null))
                    throw new IllegalArgumentException(String.format("For method '%s', either all or none of the paramaters of a method must have a @Param annotation", m.getName()));

                paramMappers[i] = newParamMapper(accClass.getName(), m.getName(), i, paramName, paramTypes[i], paramAnnotations[i], mappingManager);
            }

            ConsistencyLevel cl = null;
            int fetchSize = -1;
            boolean tracing = false;

            QueryParameters options = m.getAnnotation(QueryParameters.class);
            if (options != null) {
                cl = options.consistency().isEmpty() ? null : ConsistencyLevel.valueOf(options.consistency().toUpperCase());
                fetchSize = options.fetchSize();
                tracing = options.tracing();
            }

            methods.add(new MethodMapper(m, queryString, paramMappers, cl, fetchSize, tracing));
        }

        return factory.create(accClass, methods);
    }

    @SuppressWarnings({ "unchecked", "rawtypes" })
    private static ParamMapper newParamMapper(String className, String methodName, int idx, String paramName, Type paramType, Annotation[] paramAnnotations, MappingManager mappingManager) {
        if (paramType instanceof Class) {
            Class<?> paramClass = (Class<?>) paramType;
            if (paramClass.isAnnotationPresent(UDT.class)) {
                UDTMapper<?> udtMapper = mappingManager.getUDTMapper(paramClass);
                return new UDTParamMapper(paramName, idx, udtMapper);
            } else if (paramClass.isEnum()) {
                EnumType enumType = EnumType.STRING;
                for (Annotation annotation : paramAnnotations) {
                    if (annotation instanceof Enumerated) {
                        enumType = ((Enumerated) annotation).value();
                    }
                }
                return new EnumParamMapper(paramName, idx, enumType);
            }
            return new ParamMapper(paramName, idx);
        } if (paramType instanceof ParameterizedType) {
            InferredCQLType inferredCQLType = InferredCQLType.from(className, methodName, idx, paramName, paramType, mappingManager);
            if (inferredCQLType.containsMappedUDT) {
                
                return new NestedUDTParamMapper(paramName, idx, inferredCQLType);
            } else {
                
                return new ParamMapper(paramName, idx, inferredCQLType.dataType);
            }
        } else {
            throw new IllegalArgumentException(String.format("Cannot map class %s for parameter %s of %s.%s", paramType, paramName, className, methodName));
        }
    }
}

<code block>

package com.datastax.driver.mapping.annotations;

import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;

import com.datastax.driver.mapping.Mapper;
import com.datastax.driver.mapping.StrategyType;


@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
public @interface Table {
    
    String keyspace() default "";
    
    String name();

    
    boolean caseSensitiveKeyspace() default false;
    
    boolean caseSensitiveTable() default false;

    
    String writeConsistency() default "";

    
    String readConsistency() default "";

    
    StrategyType saveStrategy() default StrategyType.ALL_FIELDS;
}

<code block>

package com.datastax.driver.mapping.annotations;

import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;

import com.datastax.driver.mapping.StrategyType;


@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
public @interface UDT {
    
    String keyspace() default "";
    
    String name();

    
    boolean caseSensitiveKeyspace() default false;
    
    boolean caseSensitiveType() default false;

    
    StrategyType insert() default StrategyType.ALL_FIELDS;
}

<code block>

package com.datastax.driver.mapping;

import java.util.Collection;

import com.google.common.collect.Lists;
import org.testng.annotations.Test;

import static org.assertj.core.api.Assertions.assertThat;

import com.datastax.driver.core.BoundStatement;
import com.datastax.driver.core.CCMBridge;
import com.datastax.driver.mapping.annotations.PartitionKey;
import com.datastax.driver.mapping.annotations.Table;

import static com.datastax.driver.mapping.Mapper.Option;

public class MapperOptionTest extends CCMBridge.PerClassSingleNodeCluster {

    @Override
    protected Collection<String> getTableDefinitions() {
        return Lists.newArrayList("CREATE TABLE user (key int primary key, v text)");
    }

    @Test(groups = "short")
    void should_use_using_options_to_save() {
        Long tsValue = 906L;
        Mapper<User> mapper = new MappingManager(session).mapper(User.class);
        mapper.saveAsync(new User(42, "helloworld"), Option.timestamp(tsValue));
        assertThat(mapper.get(42).getV()).isEqualTo("helloworld");
        Long tsReturned = session.execute("SELECT writetime(v) FROM user WHERE key=" + 42).one().getLong(0);
        assertThat(tsReturned).isEqualTo(tsValue);
    }

    @Test(groups = "short")
    void should_use_using_options_only_once() {
        Long tsValue = 1L;
        Mapper<User> mapper = new MappingManager(session).mapper(User.class);
        mapper.save(new User(43, "helloworld"), Option.timestamp(tsValue));
        mapper.save(new User(44, "test"));
        Long tsReturned = session.execute("SELECT writetime(v) FROM user WHERE key=" + 44).one().getLong(0);
        
        assertThat(tsReturned).isNotEqualTo(tsValue);
    }

    @Test(groups = "short")
    void should_allow_setting_default_options() {
        Mapper<User> mapper = new MappingManager(session).mapper(User.class);
        mapper.setDefaultSaveOptions(Option.timestamp(644746L), Option.ttl(76324));
        BoundStatement bs = (BoundStatement)mapper.saveQuery(new User(46, "rjhrgce"));
        assertThat(bs.preparedStatement().getQueryString()).contains("USING TIMESTAMP");
        mapper.resetDefaultSaveOptions();
        bs = (BoundStatement)mapper.saveQuery(new User(47, "rjhrgce"));
        assertThat(bs.preparedStatement().getQueryString()).doesNotContain("USING TIMESTAMP");
        mapper.setDefaultDeleteOptions(Option.timestamp(3245L));
        bs = (BoundStatement)mapper.deleteQuery(47);
        assertThat(bs.preparedStatement().getQueryString()).contains("USING TIMESTAMP");
        mapper.resetDefaultDeleteOptions();
        bs = (BoundStatement)mapper.deleteQuery(47);
        assertThat(bs.preparedStatement().getQueryString()).doesNotContain("USING TIMESTAMP");
    }

    @Test(groups = "short")
    void should_use_using_options_for_delete() {
        Mapper<User> mapper = new MappingManager(session).mapper(User.class);
        User todelete = new User(45, "todelete");
        mapper.save(todelete);
        Option opt = Option.timestamp(35);
        BoundStatement bs = (BoundStatement)mapper.deleteQuery(45, opt);
        assertThat(bs.preparedStatement().getQueryString()).contains("USING TIMESTAMP");
    }

    @Table(name = "user")
    public static class User {
        @PartitionKey
        private int key;
        private String v;

        public User() {
        }

        public User(int k, String val) {
            this.key = k;
            this.v = val;
        }

        public int getKey() {
            return this.key;
        }

        public void setKey(int pk) {
            this.key = pk;
        }

        public String getV() {
            return this.v;
        }

        public void setV(String val) {
            this.v = val;
        }
    }
}

<code block>

package com.datastax.driver.mapping;

import java.util.Collection;

import com.google.common.collect.Lists;
import org.testng.annotations.Test;

import static org.assertj.core.api.Assertions.assertThat;

import com.datastax.driver.core.BoundStatement;
import com.datastax.driver.core.CCMBridge;
import com.datastax.driver.mapping.annotations.PartitionKey;
import com.datastax.driver.mapping.annotations.Table;

public class MapperPersistenceStrategiesTest extends CCMBridge.PerClassSingleNodeCluster {

    @Override
    protected Collection<String> getTableDefinitions() {
        return Lists.newArrayList("CREATE TABLE user (key int primary key, v text)");
    }

    @Test(groups = "short")
    void should_include_null_fields_for_save() {
        Mapper<User2> mapper2 = new MappingManager(session).mapper(User2.class);
        User2 user2 = new User2(12, null);
        BoundStatement bs2 = (BoundStatement)mapper2.saveQuery(user2);
        assertThat(bs2.preparedStatement().getQueryString()).contains("\"v\"");
        session.execute(bs2);
        assertThat(mapper2.get(12).getV()).isNull();
    }

    @Test(groups = "short")
    void should_not_include_null_fields_for_save() {
        Mapper<User> mapper = new MappingManager(session).mapper(User.class);
        User user1 = new User(6, null);
        BoundStatement bs = (BoundStatement)mapper.saveQuery(user1);
        assertThat(bs.preparedStatement().getQueryString()).doesNotContain("\"v\"");
    }

    @Table(name = "user", saveStrategy = StrategyType.NOT_NULL_FIELDS_ONLY)
    public static class User {
        @PartitionKey
        private int key;
        private String v;

        public User() {
        }

        public User(int k, String val) {
            this.key = k;
            this.v = val;
        }

        public int getKey() {
            return this.key;
        }

        public void setKey(int pk) {
            this.key = pk;
        }

        public String getV() {
            return this.v;
        }

        public void setV(String val) {
            this.v = val;
        }
    }

    @Table(name = "user")
    public static class User2 {
        @PartitionKey
        private int key;
        private String v;

        public User2() {
        }

        public User2(int k, String val) {
            this.key = k;
            this.v = val;
        }

        public int getKey() {
            return this.key;
        }

        public void setKey(int pk) {
            this.key = pk;
        }

        public String getV() {
            return this.v;
        }

        public void setV(String val) {
            this.v = val;
        }
    }

}

<code block>

package com.datastax.driver.mapping;

import java.lang.reflect.Field;
import java.util.*;

import com.datastax.driver.core.ConsistencyLevel;
import static com.datastax.driver.core.querybuilder.QueryBuilder.quote;

abstract class EntityMapper<T> {

    public final Class<T> entityClass;
    private final String keyspace;
    private final String table;

    public final ConsistencyLevel writeConsistency;
    public final ConsistencyLevel readConsistency;

    public final List<ColumnMapper<T>> partitionKeys = new ArrayList<ColumnMapper<T>>();
    public final List<ColumnMapper<T>> clusteringColumns = new ArrayList<ColumnMapper<T>>();
    public final List<ColumnMapper<T>> regularColumns = new ArrayList<ColumnMapper<T>>();

    private final List<ColumnMapper<T>> allColumns = new ArrayList<ColumnMapper<T>>();

    protected EntityMapper(Class<T> entityClass, String keyspace, String table, ConsistencyLevel writeConsistency, ConsistencyLevel readConsistency) {
        this.entityClass = entityClass;
        this.keyspace = keyspace;
        this.table = table;
        this.writeConsistency = writeConsistency;
        this.readConsistency = readConsistency;
    }

    public String getKeyspace() {
        return quote(keyspace);
    }

    public String getTable() {
        return quote(table);
    }

    public int primaryKeySize() {
        return partitionKeys.size() + clusteringColumns.size();
    }

    public ColumnMapper<T> getPrimaryKeyColumn(int i) {
        return i < partitionKeys.size() ? partitionKeys.get(i) : clusteringColumns.get(i - partitionKeys.size());
    }

    public void addColumns(List<ColumnMapper<T>> pks, List<ColumnMapper<T>> ccs, List<ColumnMapper<T>> rgs) {
        partitionKeys.addAll(pks);
        allColumns.addAll(pks);

        clusteringColumns.addAll(ccs);
        allColumns.addAll(ccs);

        addColumns(rgs);
    }

    public void addColumns(List<ColumnMapper<T>> rgs) {
        regularColumns.addAll(rgs);
        allColumns.addAll(rgs);
    }

    public abstract T newEntity();

    public List<ColumnMapper<T>> allColumns() {
        return allColumns;
    }

    interface Factory {
        public <T> EntityMapper<T> create(Class<T> entityClass, String keyspace, String table, ConsistencyLevel writeConsistency, ConsistencyLevel readConsistency);
        public <T> ColumnMapper<T> createColumnMapper(Class<T> componentClass, Field field, int position, MappingManager mappingManager);
    }
}

<code block>

package com.datastax.driver.mapping;

import java.beans.IntrospectionException;
import java.beans.PropertyDescriptor;
import java.lang.reflect.Field;
import java.lang.reflect.Method;
import java.lang.reflect.ParameterizedType;
import java.lang.reflect.Type;
import java.util.HashMap;
import java.util.Map;

import com.datastax.driver.core.ConsistencyLevel;
import com.datastax.driver.core.DataType;
import com.datastax.driver.core.UDTValue;


class ReflectionMapper<T> extends EntityMapper<T> {

    private static ReflectionFactory factory = new ReflectionFactory();

    private ReflectionMapper(Class<T> entityClass, String keyspace, String table, ConsistencyLevel writeConsistency, ConsistencyLevel readConsistency) {
        super(entityClass, keyspace, table, writeConsistency, readConsistency);
    }

    public static Factory factory() {
        return factory;
    }

    @Override
    public T newEntity() {
        try {
            return entityClass.newInstance();
        } catch (Exception e) {
            throw new RuntimeException("Can't create an instance of " + entityClass.getName());
        }
    }

    private static class LiteralMapper<T> extends ColumnMapper<T> {

        private final Method readMethod;
        private final Method writeMethod;

        private LiteralMapper(Field field, int position, PropertyDescriptor pd) {
            this(field, extractSimpleType(field), position, pd);
        }

        private LiteralMapper(Field field, DataType type, int position, PropertyDescriptor pd) {
            super(field, type, position);
            this.readMethod = pd.getReadMethod();
            this.writeMethod = pd.getWriteMethod();
        }

        @Override
        public Object getValue(T entity) {
            try {
                return readMethod.invoke(entity);
            } catch (IllegalArgumentException e) {
                throw new IllegalArgumentException("Could not get field '" + fieldName + "'");
            } catch (Exception e) {
                throw new IllegalStateException("Unable to access getter for '" + fieldName + "' in " + entity.getClass().getName(), e);
            }
        }

        @Override
        public void setValue(Object entity, Object value) {
            try {
                writeMethod.invoke(entity, value);
            } catch (IllegalArgumentException e) {
                throw new IllegalArgumentException("Could not set field '" + fieldName + "' to value '" + value + "'");
            } catch (Exception e) {
                throw new IllegalStateException("Unable to access setter for '" + fieldName + "' in " + entity.getClass().getName(), e);
            }
        }
    }

    private static class EnumMapper<T> extends LiteralMapper<T> {

        private final EnumType enumType;
        private final Map<String, Object> fromString;

        private EnumMapper(Field field, int position, PropertyDescriptor pd, EnumType enumType) {
            super(field, enumType == EnumType.STRING ? DataType.text() : DataType.cint(), position, pd);
            this.enumType = enumType;

            if (enumType == EnumType.STRING) {
                fromString = new HashMap<String, Object>(javaType.getEnumConstants().length);
                for (Object constant : javaType.getEnumConstants())
                    fromString.put(constant.toString().toLowerCase(), constant);

            } else {
                fromString = null;
            }
        }

        @SuppressWarnings("rawtypes")
        @Override
        public Object getValue(T entity) {
            Object value = super.getValue(entity);
            switch (enumType) {
                case STRING:
                    return (value == null) ? null : value.toString();
                case ORDINAL:
                    return (value == null) ? null : ((Enum)value).ordinal();
            }
            throw new AssertionError();
        }

        @Override
        public void setValue(Object entity, Object value) {
            Object converted = null;
            switch (enumType) {
                case STRING:
                    converted = fromString.get(value.toString().toLowerCase());
                    break;
                case ORDINAL:
                    converted = javaType.getEnumConstants()[(Integer)value];
                    break;
            }
            super.setValue(entity, converted);
        }
    }

    private static class UDTColumnMapper<T, U> extends LiteralMapper<T> {
        private final UDTMapper<U> udtMapper;

        private UDTColumnMapper(Field field, int position, PropertyDescriptor pd, UDTMapper<U> udtMapper) {
            super(field, udtMapper.getUserType(), position, pd);
            this.udtMapper = udtMapper;
        }

        @Override
        public Object getValue(T entity) {
            @SuppressWarnings("unchecked")
            U udtEntity = (U)super.getValue(entity);
            return udtEntity == null ? null : udtMapper.toUDT(udtEntity);
        }

        @Override
        public void setValue(Object entity, Object value) {
            assert value instanceof UDTValue;
            UDTValue udtValue = (UDTValue)value;
            assert udtValue.getType().equals(udtMapper.getUserType());

            super.setValue(entity, udtMapper.toEntity((udtValue)));
        }
    }

    private static class NestedUDTMapper<T> extends LiteralMapper<T> {
        private final InferredCQLType inferredCQLType;

        public NestedUDTMapper(Field field, int position, PropertyDescriptor pd, InferredCQLType inferredCQLType) {
            super(field, inferredCQLType.dataType, position, pd);
            this.inferredCQLType = inferredCQLType;
        }

        @Override
        @SuppressWarnings("unchecked")
        public Object getValue(T entity) {
            Object valueWithEntities = super.getValue(entity);
            return (T)UDTMapper.convertEntitiesToUDTs(valueWithEntities, inferredCQLType);
        }

        @Override
        public void setValue(Object entity, Object valueWithUDTValues) {
            super.setValue(entity, UDTMapper.convertUDTsToEntities(valueWithUDTValues, inferredCQLType));
        }
    }

    static DataType extractSimpleType(Field f) {
        Type type = f.getGenericType();

        assert !(type instanceof ParameterizedType);

        if (!(type instanceof Class))
            throw new IllegalArgumentException(String.format("Cannot map class %s for field %s", type, f.getName()));

        return TypeMappings.getSimpleType((Class<?>)type, f.getName());
    }

    private static class ReflectionFactory implements Factory {

        public <T> EntityMapper<T> create(Class<T> entityClass, String keyspace, String table, ConsistencyLevel writeConsistency, ConsistencyLevel readConsistency) {
            return new ReflectionMapper<T>(entityClass, keyspace, table, writeConsistency, readConsistency);
        }

        @SuppressWarnings({ "unchecked", "rawtypes" })
        public <T> ColumnMapper<T> createColumnMapper(Class<T> entityClass, Field field, int position, MappingManager mappingManager) {
            String fieldName = field.getName();
            try {
                PropertyDescriptor pd = new PropertyDescriptor(fieldName, field.getDeclaringClass());

                if (field.getType().isEnum()) {
                    return new EnumMapper<T>(field, position, pd, AnnotationParser.enumType(field));
                }

                if (TypeMappings.isMappedUDT(field.getType())) {
                    UDTMapper<?> udtMapper = mappingManager.getUDTMapper(field.getType());
                    return (ColumnMapper<T>)new UDTColumnMapper(field, position, pd, udtMapper);
                }

                if (field.getGenericType() instanceof ParameterizedType) {
                    InferredCQLType inferredCQLType = InferredCQLType.from(field, mappingManager);
                    if (inferredCQLType.containsMappedUDT) {
                        
                        return (ColumnMapper<T>)new NestedUDTMapper(field, position, pd, inferredCQLType);
                    } else {
                        
                        return new LiteralMapper<T>(field, inferredCQLType.dataType, position, pd);
                    }
                }

                return new LiteralMapper<T>(field, position, pd);

            } catch (IntrospectionException e) {
                throw new IllegalArgumentException("Cannot find matching getter and setter for field '" + fieldName + "'");
            }
        }
    }
}

<code block>

package com.datastax.driver.mapping;

import java.util.ArrayList;
import java.util.List;

import com.google.common.base.Objects;

import com.datastax.driver.core.TableMetadata;
import com.datastax.driver.core.querybuilder.Delete;
import com.datastax.driver.core.querybuilder.Insert;
import com.datastax.driver.core.querybuilder.Select;

import static com.datastax.driver.core.querybuilder.QueryBuilder.*;

class QueryType {

    private enum Kind {SAVE, GET, DEL, SLICE, REVERSED_SLICE}

    ;
    private final Kind kind;

    
    private final int startBoundSize;
    private final boolean startInclusive;
    private final int endBoundSize;
    private final boolean endInclusive;

    public static final QueryType SAVE = new QueryType(Kind.SAVE);
    public static final QueryType DEL = new QueryType(Kind.DEL);
    public static final QueryType GET = new QueryType(Kind.GET);

    private QueryType(Kind kind) {
        this(kind, 0, false, 0, false);
    }

    private QueryType(Kind kind, int startBoundSize, boolean startInclusive, int endBoundSize, boolean endInclusive) {
        this.kind = kind;
        this.startBoundSize = startBoundSize;
        this.startInclusive = startInclusive;
        this.endBoundSize = endBoundSize;
        this.endInclusive = endInclusive;
    }

    public static QueryType slice(int startBoundSize, boolean startInclusive, int endBoundSize, boolean endInclusive, boolean reversed) {
        return new QueryType(reversed ? Kind.REVERSED_SLICE : Kind.SLICE, startBoundSize, startInclusive, endBoundSize, endInclusive);
    }

    String makePreparedQueryString(TableMetadata table, EntityMapper<?> mapper, Mapper.Option... options) {
        switch (kind) {
            case SAVE: {
                Insert insert = table == null
                    ? insertInto(mapper.getKeyspace(), mapper.getTable())
                    : insertInto(table);
                for (ColumnMapper<?> cm : mapper.allColumns())
                    insert.value(cm.getColumnName(), bindMarker());
                if (options != null) {
                    Insert.Options usings = insert.using();
                    for (Mapper.Option opt : options) {
                        if (opt instanceof Mapper.Option.Ttl)
                            
                            usings.and(ttl(bindMarker()));
                        else
                            usings.and(timestamp(bindMarker()));
                    }
                }
                return insert.toString();
            }
            case GET: {
                Select select = table == null
                    ? select().all().from(mapper.getKeyspace(), mapper.getTable())
                    : select().all().from(table);
                Select.Where where = select.where();
                for (int i = 0; i < mapper.primaryKeySize(); i++)
                    where.and(eq(mapper.getPrimaryKeyColumn(i).getColumnName(), bindMarker()));
                return select.toString();
            }
            case DEL: {
                Delete delete = table == null
                    ? delete().all().from(mapper.getKeyspace(), mapper.getTable())
                    : delete().all().from(table);
                Delete.Where where = delete.where();
                for (int i = 0; i < mapper.primaryKeySize(); i++)
                    where.and(eq(mapper.getPrimaryKeyColumn(i).getColumnName(), bindMarker()));
                Delete.Options usings = delete.using();
                if (options != null){
                    for (Mapper.Option opt : options) {
                        if (opt instanceof Mapper.Option.Timestamp) {
                            usings.and(timestamp(bindMarker()));
                        } else {
                            throw new UnsupportedOperationException("Cannot use another option than TIMESTAMP for DELETE operations");
                        }
                    }
                }
                return delete.toString();
            }
            case SLICE:
            case REVERSED_SLICE: {
                Select select = table == null
                    ? select().all().from(mapper.getKeyspace(), mapper.getTable())
                    : select().all().from(table);
                Select.Where where = select.where();
                for (int i = 0; i < mapper.partitionKeys.size(); i++)
                    where.and(eq(mapper.partitionKeys.get(i).getColumnName(), bindMarker()));

                if (startBoundSize > 0) {
                    if (startBoundSize == 1) {
                        String name = mapper.clusteringColumns.get(0).getColumnName();
                        where.and(startInclusive ? gte(name, bindMarker()) : gt(name, bindMarker()));
                    } else {
                        List<String> names = new ArrayList<String>(startBoundSize);
                        List<Object> values = new ArrayList<Object>(startBoundSize);
                        for (int i = 0; i < startBoundSize; i++) {
                            names.add(mapper.clusteringColumns.get(i).getColumnName());
                            values.add(bindMarker());
                        }
                        where.and(startInclusive ? gte(names, values) : gt(names, values));
                    }
                }

                if (endBoundSize > 0) {
                    if (endBoundSize == 1) {
                        String name = mapper.clusteringColumns.get(0).getColumnName();
                        where.and(endInclusive ? gte(name, bindMarker()) : gt(name, bindMarker()));
                    } else {
                        List<String> names = new ArrayList<String>(endBoundSize);
                        List<Object> values = new ArrayList<Object>(endBoundSize);
                        for (int i = 0; i < endBoundSize; i++) {
                            names.add(mapper.clusteringColumns.get(i).getColumnName());
                            values.add(bindMarker());
                        }
                        where.and(endInclusive ? lte(names, values) : lt(names, values));
                    }
                }

                select = select.limit(bindMarker());

                if (kind == Kind.REVERSED_SLICE)
                    select = select.orderBy(desc(mapper.clusteringColumns.get(0).getColumnName()));

                return select.toString();
            }
        }
        throw new AssertionError();
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null || this.getClass() != obj.getClass())
            return false;

        QueryType that = (QueryType)obj;
        return kind == that.kind
            && startBoundSize == that.startBoundSize
            && startInclusive == that.startInclusive
            && endBoundSize == that.endBoundSize
            && endInclusive == that.endInclusive;
    }

    @Override
    public int hashCode() {
        return Objects.hashCode(kind, startBoundSize, startInclusive, endBoundSize, endInclusive);
    }

}

<code block>

package com.datastax.driver.mapping;

import java.util.*;

import com.google.common.base.Function;
import com.google.common.base.Functions;
import com.google.common.util.concurrent.Futures;
import com.google.common.util.concurrent.ListenableFuture;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.datastax.driver.core.*;


public class Mapper<T> {

    private static final Logger logger = LoggerFactory.getLogger(EntityMapper.class);

    final MappingManager manager;
    final ProtocolVersion protocolVersion;
    final Class<T> klass;
    final EntityMapper<T> mapper;
    final TableMetadata tableMetadata;

    
    private volatile Map<String, PreparedStatement> preparedQueries = Collections.<String, PreparedStatement>emptyMap();

    private static final Function<Object, Void> NOOP = Functions.<Void>constant(null);

    private volatile Option[] defaultSaveOptions;
    private volatile Option[] defaultDeleteOptions;

    final Function<ResultSet, T> mapOneFunction;
    final Function<ResultSet, Result<T>> mapAllFunction;

    Mapper(MappingManager manager, Class<T> klass, EntityMapper<T> mapper) {
        this.manager = manager;
        this.klass = klass;
        this.mapper = mapper;

        KeyspaceMetadata keyspace = session().getCluster().getMetadata().getKeyspace(mapper.getKeyspace());
        this.tableMetadata = keyspace == null ? null : keyspace.getTable(Metadata.quote(mapper.getTable()));

        this.protocolVersion = manager.getSession().getCluster().getConfiguration().getProtocolOptions().getProtocolVersionEnum();
        this.mapOneFunction = new Function<ResultSet, T>() {
            public T apply(ResultSet rs) {
                return Mapper.this.map(rs).one();
            }
        };
        this.mapAllFunction = new Function<ResultSet, Result<T>>() {
            public Result<T> apply(ResultSet rs) {
                return Mapper.this.map(rs);
            }
        };
    }

    Session session() {
        return manager.getSession();
    }

    PreparedStatement getPreparedQuery(QueryType type, Option... options) {
        String queryString;
        queryString = type.makePreparedQueryString(tableMetadata, mapper, options);
        PreparedStatement stmt = preparedQueries.get(queryString);
        if (stmt == null) {
            synchronized (preparedQueries) {
                stmt = preparedQueries.get(queryString);
                if (stmt == null) {
                    logger.debug("Preparing query {}", queryString);
                    stmt = session().prepare(queryString);
                    Map<String, PreparedStatement> newQueries = new HashMap<String, PreparedStatement>(preparedQueries);
                    newQueries.put(queryString, stmt);
                    preparedQueries = newQueries;
                }
            }
        }
        return stmt;
    }

    
    public TableMetadata getTableMetadata() {
        return tableMetadata;
    }

    
    public MappingManager getManager() {
        return manager;
    }

    
    public Statement saveQuery(T entity) {
        PreparedStatement ps;
        if (this.defaultSaveOptions != null)
            ps = getPreparedQuery(QueryType.SAVE, this.defaultSaveOptions);
        else
            ps = getPreparedQuery(QueryType.SAVE);

        BoundStatement bs = ps.bind();
        int i = 0;
        for (ColumnMapper<T> cm : mapper.allColumns()) {
            Object value = cm.getValue(entity);
            bs.setBytesUnsafe(i++, value == null ? null : cm.getDataType().serialize(value, protocolVersion));
        }

        if (mapper.writeConsistency != null)
            bs.setConsistencyLevel(mapper.writeConsistency);
        return bs;
    }

    
    public Statement saveQuery(T entity, Option... options) {
        PreparedStatement ps = getPreparedQuery(QueryType.SAVE, options);

        BoundStatement bs = ps.bind();
        int i = 0;
        for (ColumnMapper<T> cm : mapper.allColumns()) {
            Object value = cm.getValue(entity);
            bs.setBytesUnsafe(i++, value == null ? null : cm.getDataType().serialize(value, protocolVersion));
        }

        if (options != null) {
            for (Option opt : options) {
                if (opt instanceof Option.Ttl) {
                    Option.Ttl ttlOption = (Option.Ttl)opt;
                    bs.setInt(i++, ttlOption.getValue());
                }
                if (opt instanceof Option.Timestamp) {
                    Option.Timestamp tsOption = (Option.Timestamp)opt;
                    bs.setLong(i++, tsOption.getValue());
                }
            }
        }
        if (mapper.writeConsistency != null)
            bs.setConsistencyLevel(mapper.writeConsistency);
        return bs;
    }

    
    public void save(T entity) {
        session().execute(saveQuery(entity));
    }

    
    public void save(T entity, Option... options) {
        session().execute(saveQuery(entity, options));
    }

    
    public ListenableFuture<Void> saveAsync(T entity) {
        return Futures.transform(session().executeAsync(saveQuery(entity)), NOOP);
    }

    
    public ListenableFuture<Void> saveAsync(T entity, Option... options) {
        return Futures.transform(session().executeAsync(saveQuery(entity, options)), NOOP);
    }

    
    public Statement deleteQuery(T entity, Option... options) {
        Object[] pks = new Object[mapper.primaryKeySize()];
        for (int i = 0; i < pks.length; i++)
            pks[i] = mapper.getPrimaryKeyColumn(i).getValue(entity);

        return deleteQuery(pks, Arrays.asList(options));
    }

    
    public Statement deleteQuery(T entity) {
        Object[] pks = new Object[mapper.primaryKeySize()];
        for (int i = 0; i < pks.length; i++)
            pks[i] = mapper.getPrimaryKeyColumn(i).getValue(entity);

        return deleteQuery(pks);
    }

    
    public Statement deleteQuery(Object... args) {
        List<Object> pks = new ArrayList<Object>();
        List<Option> options = new ArrayList<Option>();
        for (Object o : args) {
            if (o instanceof Option) {
                options.add((Option)o);
            } else {
                pks.add(o);
            }
        }
        return deleteQuery(pks.toArray(), options);
    }

    private Statement deleteQuery(Object[] primaryKey, List<Option> options) {
        if (primaryKey.length != mapper.primaryKeySize())
            throw new IllegalArgumentException(String.format("Invalid number of PRIMARY KEY columns provided, %d expected but got %d", mapper.primaryKeySize(), primaryKey.length));

        PreparedStatement ps;
        if (options.size() != 0){
            ps = getPreparedQuery(QueryType.DEL, options.toArray(new Option[options.size()]));
        }
        else {
            ps = getPreparedQuery(QueryType.DEL, this.defaultDeleteOptions);
        }

        BoundStatement bs = ps.bind();
        int i;
        for (i = 0; i < primaryKey.length; i++) {
            ColumnMapper<T> column = mapper.getPrimaryKeyColumn(i);
            Object value = primaryKey[i];
            if (value == null)
                throw new IllegalArgumentException(String.format("Invalid null value for PRIMARY KEY column %s (argument %d)", column.getColumnName(), i));
            bs.setBytesUnsafe(i, column.getDataType().serialize(value, protocolVersion));
        }

        for (Option opt : options) {
            if (opt instanceof Option.Ttl) {
                Option.Ttl ttlOption = (Option.Ttl)opt;
                bs.setInt(i++, ttlOption.getValue());
            }
        }

        if (mapper.writeConsistency != null)
            bs.setConsistencyLevel(mapper.writeConsistency);
        return bs;
    }

    
    public void delete(T entity) {
        session().execute(deleteQuery(entity));
    }

    
    public void delete(T entity, Option... options) {
        session().execute(deleteQuery(entity, options));
    }

    
    public ListenableFuture<Void> deleteAsync(T entity) {
        return Futures.transform(session().executeAsync(deleteQuery(entity)), NOOP);
    }

    
    public ListenableFuture<Void> deleteAsync(T entity, Option... options) {
        return Futures.transform(session().executeAsync(deleteQuery(entity, options)), NOOP);
    }

    
    public void delete(Object... objects) {
        session().execute(deleteQuery(objects));
    }

    
    public ListenableFuture<Void> deleteAsync(Object... objects) {
        return Futures.transform(session().executeAsync(deleteQuery(objects)), NOOP);
    }

    
    public Result<T> map(ResultSet resultSet) {
        return new Result<T>(resultSet, mapper, protocolVersion);
    }

    
    public Statement getQuery(Object... primaryKey) {
        if (primaryKey.length != mapper.primaryKeySize())
            throw new IllegalArgumentException(String.format("Invalid number of PRIMARY KEY columns provided, %d expected but got %d", mapper.primaryKeySize(), primaryKey.length));

        PreparedStatement ps = getPreparedQuery(QueryType.GET);

        BoundStatement bs = ps.bind();
        for (int i = 0; i < primaryKey.length; i++) {
            ColumnMapper<T> column = mapper.getPrimaryKeyColumn(i);
            Object value = primaryKey[i];
            if (value == null)
                throw new IllegalArgumentException(String.format("Invalid null value for PRIMARY KEY column %s (argument %d)", column.getColumnName(), i));
            bs.setBytesUnsafe(i, column.getDataType().serialize(value, protocolVersion));
        }

        if (mapper.readConsistency != null)
            bs.setConsistencyLevel(mapper.readConsistency);
        return bs;
    }

    
    public T get(Object... primaryKey) {
        return map(session().execute(getQuery(primaryKey))).one();
    }

    
    public ListenableFuture<T> getAsync(Object... primaryKey) {
        return Futures.transform(session().executeAsync(getQuery(primaryKey)), mapOneFunction);
    }

    
    public void setDefaultSaveOptions(Option... options) {
        this.defaultSaveOptions = Arrays.copyOf(options, options.length);
    }

    
    public void resetDefaultSaveOptions() {
        this.defaultSaveOptions = null;
    }

    
    public void setDefaultDeleteOptions(Option... options) {
        this.defaultDeleteOptions = Arrays.copyOf(options, options.length);
    }

    
    public void resetDefaultDeleteOptions() {
        this.defaultDeleteOptions = null;
    }

    
    public static abstract class Option {

        static class Ttl extends Option {

            private int ttlValue;

            Ttl(int value) {
                this.ttlValue = value;
            }

            
            public int getValue() {
                return this.ttlValue;
            }
        }

        static class Timestamp extends Option {

            private long tsValue;

            Timestamp(long value) {
                this.tsValue = value;
            }

            
            public long getValue() {
                return this.tsValue;
            }
        }

        
        public static Option ttl(int value) {
            return new Ttl(value);
        }

        
        public static Option timestamp(long value) {
            return new Timestamp(value);
        }
    }

}

<code block>

package com.datastax.driver.mapping;

import java.lang.annotation.Annotation;
import java.lang.reflect.Field;
import java.lang.reflect.*;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;

import com.google.common.base.Strings;

import com.datastax.driver.core.ConsistencyLevel;
import com.datastax.driver.mapping.MethodMapper.EnumParamMapper;
import com.datastax.driver.mapping.MethodMapper.NestedUDTParamMapper;
import com.datastax.driver.mapping.MethodMapper.ParamMapper;
import com.datastax.driver.mapping.MethodMapper.UDTParamMapper;
import com.datastax.driver.mapping.annotations.*;


class AnnotationParser {

    private static final Comparator<Field> fieldComparator = new Comparator<Field>() {
        public int compare(Field f1, Field f2) {
            return position(f1) - position(f2);
        }
    };

    private AnnotationParser() {}

    public static <T> EntityMapper<T> parseEntity(Class<T> entityClass, EntityMapper.Factory factory, MappingManager mappingManager) {
        Table table = AnnotationChecks.getTypeAnnotation(Table.class, entityClass);

        String ksName = table.caseSensitiveKeyspace() ? table.keyspace() : table.keyspace().toLowerCase();
        String tableName = table.caseSensitiveTable() ? table.name() : table.name().toLowerCase();

        ConsistencyLevel writeConsistency = table.writeConsistency().isEmpty() ? null : ConsistencyLevel.valueOf(table.writeConsistency().toUpperCase());
        ConsistencyLevel readConsistency = table.readConsistency().isEmpty() ? null : ConsistencyLevel.valueOf(table.readConsistency().toUpperCase());

        if (Strings.isNullOrEmpty(table.keyspace())) {
            ksName = mappingManager.getSession().getLoggedKeyspace();
            if (Strings.isNullOrEmpty(ksName))
                throw new IllegalArgumentException(String.format(
                    "Error creating mapper for class %s, the @%s annotation declares no default keyspace, and the session is not currently logged to any keyspace",
                    entityClass.getSimpleName(),
                    Table.class.getSimpleName()
                ));
        }

        EntityMapper<T> mapper = factory.create(entityClass, ksName, tableName, writeConsistency, readConsistency);

        List<Field> pks = new ArrayList<Field>();
        List<Field> ccs = new ArrayList<Field>();
        List<Field> rgs = new ArrayList<Field>();

        for (Field field : entityClass.getDeclaredFields()) {
            if(field.isSynthetic() || (field.getModifiers() & Modifier.STATIC) == Modifier.STATIC)
                continue;
            
            AnnotationChecks.validateAnnotations(field, "entity",
                                                 Column.class, ClusteringColumn.class, Enumerated.class, Frozen.class, FrozenKey.class,
                                                 FrozenValue.class, PartitionKey.class, Transient.class);

            if (field.getAnnotation(Transient.class) != null)
                continue;

            switch (kind(field)) {
                case PARTITION_KEY:
                    pks.add(field);
                    break;
                case CLUSTERING_COLUMN:
                    ccs.add(field);
                    break;
                default:
                    rgs.add(field);
                    break;
            }
        }

        Collections.sort(pks, fieldComparator);
        Collections.sort(ccs, fieldComparator);

        validateOrder(pks, "@PartitionKey");
        validateOrder(ccs, "@ClusteringColumn");

        mapper.addColumns(convert(pks, factory, mapper.entityClass, mappingManager),
                          convert(ccs, factory, mapper.entityClass, mappingManager),
                          convert(rgs, factory, mapper.entityClass, mappingManager));
        return mapper;
    }

    public static <T> EntityMapper<T> parseUDT(Class<T> udtClass, EntityMapper.Factory factory, MappingManager mappingManager) {
        UDT udt = AnnotationChecks.getTypeAnnotation(UDT.class, udtClass);

        String ksName = udt.caseSensitiveKeyspace() ? udt.keyspace() : udt.keyspace().toLowerCase();
        String udtName = udt.caseSensitiveType() ? udt.name() : udt.name().toLowerCase();

        if (Strings.isNullOrEmpty(udt.keyspace())) {
            ksName = mappingManager.getSession().getLoggedKeyspace();
            if (Strings.isNullOrEmpty(ksName))
                throw new IllegalArgumentException(String.format(
                    "Error creating UDT mapper for class %s, the @%s annotation declares no default keyspace, and the session is not currently logged to any keyspace",
                    udtClass.getSimpleName(),
                    UDT.class.getSimpleName()
                ));
        }

        EntityMapper<T> mapper = factory.create(udtClass, ksName, udtName, null, null);

        List<Field> columns = new ArrayList<Field>();

        for (Field field : udtClass.getDeclaredFields()) {
            if(field.isSynthetic() || (field.getModifiers() & Modifier.STATIC) == Modifier.STATIC)
                continue;
            
            AnnotationChecks.validateAnnotations(field, "UDT",
                                                 com.datastax.driver.mapping.annotations.Field.class, Frozen.class, FrozenKey.class,
                                                 FrozenValue.class, Enumerated.class, Transient.class);

            if (field.getAnnotation(Transient.class) != null)
                continue;

            switch (kind(field)) {
                case PARTITION_KEY:
                    throw new IllegalArgumentException("Annotation @PartitionKey is not allowed in a class annotated by @UDT");
                case CLUSTERING_COLUMN:
                    throw new IllegalArgumentException("Annotation @ClusteringColumn is not allowed in a class annotated by @UDT");
                default:
                    columns.add(field);
                    break;
            }
        }

        mapper.addColumns(convert(columns, factory, udtClass, mappingManager));
        return mapper;
    }

    private static <T> List<ColumnMapper<T>> convert(List<Field> fields, EntityMapper.Factory factory, Class<T> klass, MappingManager mappingManager) {
        List<ColumnMapper<T>> mappers = new ArrayList<ColumnMapper<T>>(fields.size());
        for (int i = 0; i < fields.size(); i++) {
            Field field = fields.get(i);
            int pos = position(field);
            mappers.add(factory.createColumnMapper(klass, field, pos < 0 ? i : pos, mappingManager));
        }
        return mappers;
    }

    private static void validateOrder(List<Field> fields, String annotation) {
        for (int i = 0; i < fields.size(); i++) {
            Field field = fields.get(i);
            int pos = position(field);
            if (pos != i)
                throw new IllegalArgumentException(String.format("Invalid ordering value %d for annotation %s of column %s, was expecting %d",
                                                                 pos, annotation, field.getName(), i));
        }
    }

    private static int position(Field field) {
        switch (kind(field)) {
            case PARTITION_KEY:
                return field.getAnnotation(PartitionKey.class).value();
            case CLUSTERING_COLUMN:
                return field.getAnnotation(ClusteringColumn.class).value();
            default:
                return -1;
        }
    }

    public static ColumnMapper.Kind kind(Field field) {
        PartitionKey pk = field.getAnnotation(PartitionKey.class);
        ClusteringColumn cc = field.getAnnotation(ClusteringColumn.class);
        if (pk != null && cc != null)
            throw new IllegalArgumentException("Field " + field.getName() + " cannot have both the @PartitionKey and @ClusteringColumn annotations");

        return pk != null
             ? ColumnMapper.Kind.PARTITION_KEY
             : (cc != null ? ColumnMapper.Kind.CLUSTERING_COLUMN : ColumnMapper.Kind.REGULAR);
    }

    public static EnumType enumType(Field field) {
        Class<?> type = field.getType();
        if (!type.isEnum())
            return null;

        Enumerated enumerated = field.getAnnotation(Enumerated.class);
        return (enumerated == null) ? EnumType.STRING : enumerated.value();
    }

    public static String columnName(Field field) {
        Column column = field.getAnnotation(Column.class);
        if (column != null && !column.name().isEmpty()) {
            return column.caseSensitive() ? column.name() : column.name().toLowerCase();
        }

        com.datastax.driver.mapping.annotations.Field udtField = field.getAnnotation(com.datastax.driver.mapping.annotations.Field.class);
        if (udtField != null && !udtField.name().isEmpty()) {
            return udtField.caseSensitive() ? udtField.name() : udtField.name().toLowerCase();
        }

        return field.getName().toLowerCase();
    }

    public static <T> AccessorMapper<T> parseAccessor(Class<T> accClass, AccessorMapper.Factory factory, MappingManager mappingManager) {
        if (!accClass.isInterface())
            throw new IllegalArgumentException("@Accessor annotation is only allowed on interfaces");

        AnnotationChecks.getTypeAnnotation(Accessor.class, accClass);

        List<MethodMapper> methods = new ArrayList<MethodMapper>();
        for (Method m : accClass.getDeclaredMethods()) {
            Query query = m.getAnnotation(Query.class);
            if (query == null)
                continue;

            String queryString = query.value();

            Annotation[][] paramAnnotations = m.getParameterAnnotations();
            Type[] paramTypes = m.getGenericParameterTypes();
            ParamMapper[] paramMappers = new ParamMapper[paramAnnotations.length];
            Boolean hasParamAnnotation = null;
            for (int i = 0; i < paramMappers.length; i++) {
                String paramName = null;
                for (Annotation a : paramAnnotations[i]) {
                    if (a.annotationType().equals(Param.class)) {
                        paramName = ((Param) a).value();
                        break;
                    }
                }
                if (hasParamAnnotation == null)
                    hasParamAnnotation = (paramName != null);
                if (hasParamAnnotation != (paramName != null))
                    throw new IllegalArgumentException(String.format("For method '%s', either all or none of the paramaters of a method must have a @Param annotation", m.getName()));

                paramMappers[i] = newParamMapper(accClass.getName(), m.getName(), i, paramName, paramTypes[i], paramAnnotations[i], mappingManager);
            }

            ConsistencyLevel cl = null;
            int fetchSize = -1;
            boolean tracing = false;

            QueryParameters options = m.getAnnotation(QueryParameters.class);
            if (options != null) {
                cl = options.consistency().isEmpty() ? null : ConsistencyLevel.valueOf(options.consistency().toUpperCase());
                fetchSize = options.fetchSize();
                tracing = options.tracing();
            }

            methods.add(new MethodMapper(m, queryString, paramMappers, cl, fetchSize, tracing));
        }

        return factory.create(accClass, methods);
    }

    @SuppressWarnings({ "unchecked", "rawtypes" })
    private static ParamMapper newParamMapper(String className, String methodName, int idx, String paramName, Type paramType, Annotation[] paramAnnotations, MappingManager mappingManager) {
        if (paramType instanceof Class) {
            Class<?> paramClass = (Class<?>) paramType;
            if (paramClass.isAnnotationPresent(UDT.class)) {
                UDTMapper<?> udtMapper = mappingManager.getUDTMapper(paramClass);
                return new UDTParamMapper(paramName, idx, udtMapper);
            } else if (paramClass.isEnum()) {
                EnumType enumType = EnumType.STRING;
                for (Annotation annotation : paramAnnotations) {
                    if (annotation instanceof Enumerated) {
                        enumType = ((Enumerated) annotation).value();
                    }
                }
                return new EnumParamMapper(paramName, idx, enumType);
            }
            return new ParamMapper(paramName, idx);
        } if (paramType instanceof ParameterizedType) {
            InferredCQLType inferredCQLType = InferredCQLType.from(className, methodName, idx, paramName, paramType, mappingManager);
            if (inferredCQLType.containsMappedUDT) {
                
                return new NestedUDTParamMapper(paramName, idx, inferredCQLType);
            } else {
                
                return new ParamMapper(paramName, idx, inferredCQLType.dataType);
            }
        } else {
            throw new IllegalArgumentException(String.format("Cannot map class %s for parameter %s of %s.%s", paramType, paramName, className, methodName));
        }
    }
}

<code block>

package com.datastax.driver.mapping.annotations;

import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;

import com.datastax.driver.mapping.Mapper;


@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
public @interface Table {
    
    String keyspace() default "";
    
    String name();

    
    boolean caseSensitiveKeyspace() default false;
    
    boolean caseSensitiveTable() default false;

    
    String writeConsistency() default "";

    
    String readConsistency() default "";
}

<code block>

package com.datastax.driver.mapping.annotations;

import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;


@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
public @interface UDT {
    
    String keyspace() default "";
    
    String name();

    
    boolean caseSensitiveKeyspace() default false;
    
    boolean caseSensitiveType() default false;
}

<code block>

package com.datastax.driver.mapping;

import java.util.Collection;

import com.google.common.collect.Lists;
import org.testng.annotations.Test;

import static org.assertj.core.api.Assertions.assertThat;

import com.datastax.driver.core.BoundStatement;
import com.datastax.driver.core.CCMBridge;
import com.datastax.driver.core.PreparedStatement;
import com.datastax.driver.mapping.annotations.PartitionKey;
import com.datastax.driver.mapping.annotations.Table;

import static com.datastax.driver.mapping.Mapper.Option;

public class MapperOptionTest extends CCMBridge.PerClassSingleNodeCluster {

    @Override
    protected Collection<String> getTableDefinitions() {
        return Lists.newArrayList("CREATE TABLE user (key int primary key, v text)");
    }

    @Test(groups = "short")
    void should_use_using_options_to_save() {
        Long tsValue = 906L;
        Mapper<User> mapper = new MappingManager(session).mapper(User.class);
        mapper.saveAsync(new User(42, "helloworld"), Option.timestamp(tsValue));
        assertThat(mapper.get(42).getV()).isEqualTo("helloworld");
        Long tsReturned = session.execute("SELECT writetime(v) FROM user WHERE key=" + 42).one().getLong(0);
        assertThat(tsReturned).isEqualTo(tsValue);
    }

    @Test(groups = "short")
    void should_use_using_options_only_once() {
        Long tsValue = 1L;
        Mapper<User> mapper = new MappingManager(session).mapper(User.class);
        mapper.save(new User(43, "helloworld"), Option.timestamp(tsValue));
        mapper.save(new User(44, "test"));
        Long tsReturned = session.execute("SELECT writetime(v) FROM user WHERE key=" + 44).one().getLong(0);
        
        assertThat(tsReturned).isNotEqualTo(tsValue);
    }

    @Test(groups = "short")
    void should_allow_setting_default_options() {
        Mapper<User> mapper = new MappingManager(session).mapper(User.class);
        mapper.setDefaultSaveOptions(Option.timestamp(644746L), Option.ttl(76324));
        BoundStatement bs = (BoundStatement)mapper.saveQuery(new User(46, "rjhrgce"));
        assertThat(bs.preparedStatement().getQueryString()).contains("USING TIMESTAMP");
        mapper.resetDefaultSaveOptions();
        bs = (BoundStatement)mapper.saveQuery(new User(47, "rjhrgce"));
        assertThat(bs.preparedStatement().getQueryString()).doesNotContain("USING TIMESTAMP");
        mapper.setDefaultDeleteOptions(Option.timestamp(3245L));
        bs = (BoundStatement)mapper.deleteQuery(47);
        assertThat(bs.preparedStatement().getQueryString()).contains("USING TIMESTAMP");
        mapper.resetDefaultDeleteOptions();
        bs = (BoundStatement)mapper.deleteQuery(47);
        assertThat(bs.preparedStatement().getQueryString()).doesNotContain("USING TIMESTAMP");
    }

    @Test(groups = "short")
    void should_use_using_options_for_delete() {
        Mapper<User> mapper = new MappingManager(session).mapper(User.class);
        User todelete = new User(45, "todelete");
        mapper.save(todelete);
        Option opt = Option.timestamp(35);
        BoundStatement bs = (BoundStatement)mapper.deleteQuery(45, opt);
        assertThat(bs.preparedStatement().getQueryString()).contains("USING TIMESTAMP");
    }

    @Table(name = "user")
    public static class User {
        @PartitionKey
        private int key;
        private String v;

        public User() {
        }

        public User(int k, String val) {
            this.key = k;
            this.v = val;
        }

        public int getKey() {
            return this.key;
        }

        public void setKey(int pk) {
            this.key = pk;
        }

        public String getV() {
            return this.v;
        }

        public void setV(String val) {
            this.v = val;
        }
    }
}

<code block>

package com.datastax.driver.mapping;

import java.lang.reflect.Method;
import java.lang.reflect.ParameterizedType;
import java.lang.reflect.Type;
import java.nio.ByteBuffer;
import java.util.Set;

import com.google.common.collect.Sets;
import com.google.common.util.concurrent.Futures;
import com.google.common.util.concurrent.ListenableFuture;

import com.datastax.driver.core.*;



class MethodMapper {

    public final Method method;
    public final String queryString;
    public final ParamMapper[] paramMappers;

    private final ConsistencyLevel consistency;
    private final int fetchSize;
    private final boolean tracing;

    private Session session;
    private PreparedStatement statement;

    private boolean returnStatement;
    private Mapper<?> returnMapper;
    private boolean mapOne;
    private boolean async;

    MethodMapper(Method method, String queryString, ParamMapper[] paramMappers, ConsistencyLevel consistency, int fetchSize, boolean enableTracing) {
        this.method = method;
        this.queryString = queryString;
        this.paramMappers = paramMappers;
        this.consistency = consistency;
        this.fetchSize = fetchSize;
        this.tracing = enableTracing;
    }

    public void prepare(MappingManager manager, PreparedStatement ps) {
        this.session = manager.getSession();
        this.statement = ps;

        validateParameters();

        Class<?> returnType = method.getReturnType();
        if (Void.TYPE.isAssignableFrom(returnType) || ResultSet.class.isAssignableFrom(returnType))
            return;

        if (Statement.class.isAssignableFrom(returnType)) {
            returnStatement = true;
            return;
        }

        if (ResultSetFuture.class.isAssignableFrom(returnType)) {
            this.async = true;
            return;
        }

        if (ListenableFuture.class.isAssignableFrom(returnType)) {
            this.async = true;
            Type k = ((ParameterizedType)method.getGenericReturnType()).getActualTypeArguments()[0];
            if (k instanceof Class && ResultSet.class.isAssignableFrom((Class<?>)k))
                return;

            mapType(manager, returnType, k);
        } else {
            mapType(manager, returnType, method.getGenericReturnType());
        }
    }

    
    private void validateParameters() {
        if (method.isVarArgs())
            throw new IllegalArgumentException(String.format("Invalid varargs method %s in @Accessor interface", method.getName()));

        ColumnDefinitions variables = statement.getVariables();
        Set<String> names = Sets.newHashSet();
        for (ColumnDefinitions.Definition variable : variables) {
            names.add(variable.getName());
        }

        if (method.getParameterTypes().length < names.size())
            throw new IllegalArgumentException(String.format("Not enough arguments for method %s, "
                    + "found %d but it should be at least the number of unique bind parameter names in the @Query (%d)",
                method.getName(), method.getParameterTypes().length, names.size()));

        if (method.getParameterTypes().length > variables.size())
            throw new IllegalArgumentException(String.format("Too many arguments for method %s, "
                    + "found %d but it should be at most the number of bind parameters in the @Query (%d)",
                method.getName(), method.getParameterTypes().length, variables.size()));

        
    }

    @SuppressWarnings("rawtypes")
    private void mapType(MappingManager manager, Class<?> fullReturnType, Type type) {

        if (type instanceof ParameterizedType) {
            ParameterizedType pt = (ParameterizedType)type;
            Type raw = pt.getRawType();
            if (raw instanceof Class && Result.class.isAssignableFrom((Class)raw)) {
                type = pt.getActualTypeArguments()[0];
            } else {
                mapOne = true;
            }
        } else {
            mapOne = true;
        }

        if (!(type instanceof Class))
            throw new RuntimeException(String.format("Cannot map return of method %s to unsupported type %s", method, type));

        try {
            this.returnMapper = (Mapper<?>)manager.mapper((Class<?>)type);
        } catch (Exception e) {
            throw new RuntimeException("Cannot map return to class " + fullReturnType, e);
        }
    }

    public Object invoke(Object[] args) {

        BoundStatement bs = statement.bind();

        ProtocolVersion protocolVersion = session.getCluster().getConfiguration().getProtocolOptions().getProtocolVersionEnum();
        for (int i = 0; i < args.length; i++) {
            paramMappers[i].setValue(bs, args[i], protocolVersion);
        }

        if (consistency != null)
            bs.setConsistencyLevel(consistency);
        if (fetchSize > 0)
            bs.setFetchSize(fetchSize);
        if (tracing)
            bs.enableTracing();

        if (returnStatement)
            return bs;

        if (async) {
            ListenableFuture<ResultSet> future = session.executeAsync(bs);
            if (returnMapper == null)
                return future;

            return mapOne
                 ? Futures.transform(future, returnMapper.mapOneFunctionWithoutAliases)
                 : Futures.transform(future, returnMapper.mapAllFunctionWithoutAliases);
        } else {
            ResultSet rs = session.execute(bs);
            if (returnMapper == null)
                return rs;

            Result<?> result = returnMapper.map(rs);
            return mapOne ? result.one() : result;
        }
    }

    static class ParamMapper {
        
        private final String paramName;
        private final int paramIdx;
        private final DataType dataType;

        public ParamMapper(String paramName, int paramIdx, DataType dataType) {
            this.paramName = paramName;
            this.paramIdx = paramIdx;
            this.dataType = dataType;
        }

        public ParamMapper(String paramName, int paramIdx) {
            this(paramName, paramIdx, null);
        }

        void setValue(BoundStatement boundStatement, Object arg, ProtocolVersion protocolVersion) {
            ByteBuffer serializedArg = (dataType == null)
                ? DataType.serializeValue(arg, protocolVersion)
                : dataType.serialize(arg, protocolVersion);
            if (paramName == null) {
                if (arg == null)
                    boundStatement.setToNull(paramIdx);
                else
                    boundStatement.setBytesUnsafe(paramIdx, serializedArg);
            } else {
                if (arg == null)
                    boundStatement.setToNull(paramName);
                else
                    boundStatement.setBytesUnsafe(paramName, serializedArg);
            }
        }
    }

    static class UDTParamMapper<V> extends ParamMapper {
        private final UDTMapper<V> udtMapper;

        UDTParamMapper(String paramName, int paramIdx, UDTMapper<V> udtMapper) {
            super(paramName, paramIdx);
            this.udtMapper = udtMapper;
        }

        @Override
        void setValue(BoundStatement boundStatement, Object arg, ProtocolVersion protocolVersion) {
            @SuppressWarnings("unchecked")
            V entity = (V) arg;
            UDTValue udtArg = arg != null ? udtMapper.toUDT(entity) : null;
            super.setValue(boundStatement, udtArg, protocolVersion);
        }
    }

    
    static class NestedUDTParamMapper extends ParamMapper {
        private final InferredCQLType inferredCQLType;

        NestedUDTParamMapper(String paramName, int paramIdx, InferredCQLType inferredCQLType) {
            super(paramName, paramIdx);
            this.inferredCQLType = inferredCQLType;
        }

        @Override
        void setValue(BoundStatement boundStatement, Object arg, ProtocolVersion protocolVersion) {
            super.setValue(boundStatement,
                UDTMapper.convertEntitiesToUDTs(arg, inferredCQLType),
                protocolVersion);
        }
    }

    static class EnumParamMapper extends ParamMapper {

        private final EnumType enumType;

        public EnumParamMapper(String paramName, int paramIdx, EnumType enumType) {
            super(paramName, paramIdx);
            this.enumType = enumType;
        }

        @Override
        void setValue(BoundStatement boundStatement, Object arg, ProtocolVersion protocolVersion) {
            super.setValue(boundStatement, convert(arg), protocolVersion);
        }

        @SuppressWarnings("rawtypes")
        private Object convert(Object arg) {
            if(arg == null)
                return arg;

            switch (enumType) {
            case STRING:
                return arg.toString();
            case ORDINAL:
                return ((Enum) arg).ordinal();
            }
            throw new AssertionError();
        }
    }
}

<code block>

package com.datastax.driver.mapping;

import java.util.Collection;

import com.google.common.collect.Lists;
import org.testng.annotations.Test;

import static org.assertj.core.api.Assertions.assertThat;

import com.datastax.driver.core.CCMBridge;
import com.datastax.driver.core.ResultSet;
import com.datastax.driver.core.Row;
import com.datastax.driver.mapping.annotations.*;

public class MapperAccessorParamsTest extends CCMBridge.PerClassSingleNodeCluster {
    @Override
    protected Collection<String> getTableDefinitions() {
        return Lists.newArrayList(
            "CREATE TABLE user ( key int primary key, gender int, home_phone text, work_phone text)",
            "CREATE INDEX on user(gender)",
            "CREATE TABLE user_str ( key int primary key, gender text)",
            "CREATE INDEX on user_str(gender)"
        );
    }

    @Test(groups = "short")
    public void should_allow_enum_as_int_in_accessor_params() {
        UserAccessor accessor = new MappingManager(session)
                .createAccessor(UserAccessor.class);

        accessor.addUser(0, Enum.FEMALE);
        accessor.addUser(1, Enum.MALE);

        assertThat(accessor.getUser(Enum.MALE).one().getGender()).isEqualTo(Enum.MALE);
        assertThat(accessor.getUser(Enum.MALE).one().getKey()).isEqualTo(1);

        assertThat(accessor.getUser(Enum.FEMALE).one().getGender()).isEqualTo(Enum.FEMALE);
        assertThat(accessor.getUser(Enum.FEMALE).one().getKey()).isEqualTo(0);
    }

    @Test(groups = "short")
    public void should_allow_enum_as_string_in_accessor_params() {
        UserAccessor accessor = new MappingManager(session)
                .createAccessor(UserAccessor.class);

        accessor.addUserStr(0, Enum.FEMALE);
        accessor.addUserStr(1, Enum.MALE);

        assertThat(accessor.getUserStr(Enum.MALE).one().getGender()).isEqualTo(Enum.MALE);
        assertThat(accessor.getUserStr(Enum.MALE).one().getKey()).isEqualTo(1);

        assertThat(accessor.getUserStr(Enum.FEMALE).one().getGender()).isEqualTo(Enum.FEMALE);
        assertThat(accessor.getUserStr(Enum.FEMALE).one().getKey()).isEqualTo(0);
    }

    @Test(groups = "short")
    public void should_allow_less_parameters_than_bind_markers_if_there_are_repeated_names() {
        UserPhoneAccessor accessor = new MappingManager(session)
            .createAccessor(UserPhoneAccessor.class);

        session.execute("delete from user where key = 0");
        accessor.updatePhones_positional("1111", "2222", 0);
        assertPhonesEqual(0, "1111", "2222");

        session.execute("delete from user where key = 0");
        accessor.updatePhones_named(0, "1111", "2222");
        assertPhonesEqual(0, "1111", "2222");

        session.execute("delete from user where key = 0");
        accessor.updatePhones_fallback("1111", "2222", 0);
        assertPhonesEqual(0, "1111", "2222");

        session.execute("delete from user where key = 0");
        accessor.updateBothPhones(0, "1111");
        assertPhonesEqual(0, "1111", "1111");

        session.execute("delete from user where key = 0");
        accessor.updatePhones_fallback2("1111", "2222", 0);
        assertPhonesEqual(0, "1111", "2222");
    }

    @Test(groups = "short", expectedExceptions = RuntimeException.class)
    public void should_fail_if_not_enough_parameters() {
        new MappingManager(session)
            .createAccessor(UserPhoneAccessor_NotEnoughParams.class);
    }

    @Test(groups = "short", expectedExceptions = RuntimeException.class)
    public void should_fail_if_too_many_parameters() {
        new MappingManager(session)
            .createAccessor(UserPhoneAccessor_TooManyParams.class);
    }

    private void assertPhonesEqual(int key, String home, String work) {
        Row row = session.execute("select * from user where key = " + key).one();
        assertThat(row.getString("home_phone")).isEqualTo(home);
        assertThat(row.getString("work_phone")).isEqualTo(work);
    }

    enum Enum {
        MALE, FEMALE
    }

    @Accessor
    public interface UserAccessor {
        @Query("select * from user where gender=?")
        Result<User> getUser(@Enumerated(EnumType.ORDINAL) Enum value);

        @Query("select * from user_str where gender=?")
        Result<UserStr> getUserStr(@Enumerated(EnumType.STRING) Enum value);

        @Query("insert into user (key, gender) values (?,?)")
        ResultSet addUser(int key, @Enumerated(EnumType.ORDINAL) Enum value);

        @Query("insert into user_str (key, gender) values (?,?)")
        ResultSet addUserStr(int key, @Enumerated(EnumType.STRING) Enum value);
    }

    
    @Accessor
    public interface UserPhoneAccessor {
        
        @Query("update user set home_phone = ?, work_phone = ? where key = ?")
        void updatePhones_positional(String homePhone, String workPhone, int key);

        
        @Query("update user set home_phone = :home, work_phone = :work where key = :key")
        void updatePhones_named(@Param("key") int key, @Param("home") String homePhone, @Param("work") String workPhone);

        
        @Query("update user set home_phone = :home, work_phone = :work where key = :key")
        void updatePhones_fallback(String homePhone, String workPhone, int key);

        
        @Query("update user set home_phone = :phone, work_phone = :phone where key = :key")
        void updateBothPhones(@Param("key") int key, @Param("phone") String uniquePhone);

        
        @Query("update user set home_phone = :phone, work_phone = :phone where key = :key")
        void updatePhones_fallback2(String homePhone, String workPhone, int key);
    }

    @Accessor
    public interface UserPhoneAccessor_NotEnoughParams {
        @SuppressWarnings("unused")
        @Query("update user set home_phone = :phone, work_phone = :phone where key = :key")
        void updateBothPhones(@Param("key") int key);
    }

    public interface UserPhoneAccessor_TooManyParams {
        @SuppressWarnings("unused")
        @Query("update user set home_phone = ?, work_phone = ? where key = ?")
        void updatePhones(String homePhone, String workPhone, int key, int extra);
    }

    @Table(name = "user")
    public static class User {
        @PartitionKey
        private int key;

        @Enumerated(EnumType.ORDINAL)
        private Enum gender;

        public User() {
        }

        public User(int k, Enum val) {
            this.key = k;
            this.gender = val;
        }

        public int getKey() {
            return this.key;
        }

        public void setKey(int pk) {
            this.key = pk;
        }

        public Enum getGender() {
            return this.gender;
        }

        public void setGender(Enum val) {
            this.gender = val;
        }
    }

    @Table(name = "user")
    public static class UserStr {
        @PartitionKey
        private int key;

        private Enum gender;

        public UserStr() {
        }

        public UserStr(int k, Enum val) {
            this.key = k;
            this.gender = val;
        }

        public int getKey() {
            return this.key;
        }

        public void setKey(int pk) {
            this.key = pk;
        }

        public Enum getGender() {
            return this.gender;
        }

        public void setGender(Enum val) {
            this.gender = val;
        }
    }
}
<code block>

package com.datastax.driver.mapping;

import java.lang.reflect.Method;
import java.lang.reflect.ParameterizedType;
import java.lang.reflect.Type;
import java.nio.ByteBuffer;

import com.google.common.util.concurrent.Futures;
import com.google.common.util.concurrent.ListenableFuture;

import com.datastax.driver.core.*;



class MethodMapper {

    public final Method method;
    public final String queryString;
    public final ParamMapper[] paramMappers;

    private final ConsistencyLevel consistency;
    private final int fetchSize;
    private final boolean tracing;

    private Session session;
    private PreparedStatement statement;

    private boolean returnStatement;
    private Mapper<?> returnMapper;
    private boolean mapOne;
    private boolean async;

    MethodMapper(Method method, String queryString, ParamMapper[] paramMappers, ConsistencyLevel consistency, int fetchSize, boolean enableTracing) {
        this.method = method;
        this.queryString = queryString;
        this.paramMappers = paramMappers;
        this.consistency = consistency;
        this.fetchSize = fetchSize;
        this.tracing = enableTracing;
    }

    public void prepare(MappingManager manager, PreparedStatement ps) {
        this.session = manager.getSession();
        this.statement = ps;

        if (method.isVarArgs())
            throw new IllegalArgumentException(String.format("Invalid varargs method %s in @Accessor interface"));
        if (ps.getVariables().size() != method.getParameterTypes().length)
            throw new IllegalArgumentException(String.format("The number of arguments for method %s (%d) does not match the number of bind parameters in the @Query (%d)",
                                                              method.getName(), method.getParameterTypes().length, ps.getVariables().size()));

        

        Class<?> returnType = method.getReturnType();
        if (Void.TYPE.isAssignableFrom(returnType) || ResultSet.class.isAssignableFrom(returnType))
            return;

        if (Statement.class.isAssignableFrom(returnType)) {
            returnStatement = true;
            return;
        }

        if (ResultSetFuture.class.isAssignableFrom(returnType)) {
            this.async = true;
            return;
        }

        if (ListenableFuture.class.isAssignableFrom(returnType)) {
            this.async = true;
            Type k = ((ParameterizedType)method.getGenericReturnType()).getActualTypeArguments()[0];
            if (k instanceof Class && ResultSet.class.isAssignableFrom((Class<?>)k))
                return;

            mapType(manager, returnType, k);
        } else {
            mapType(manager, returnType, method.getGenericReturnType());
        }
    }

    @SuppressWarnings("rawtypes")
    private void mapType(MappingManager manager, Class<?> fullReturnType, Type type) {

        if (type instanceof ParameterizedType) {
            ParameterizedType pt = (ParameterizedType)type;
            Type raw = pt.getRawType();
            if (raw instanceof Class && Result.class.isAssignableFrom((Class)raw)) {
                type = pt.getActualTypeArguments()[0];
            } else {
                mapOne = true;
            }
        } else {
            mapOne = true;
        }

        if (!(type instanceof Class))
            throw new RuntimeException(String.format("Cannot map return of method %s to unsupported type %s", method, type));

        try {
            this.returnMapper = (Mapper<?>)manager.mapper((Class<?>)type);
        } catch (Exception e) {
            throw new RuntimeException("Cannot map return to class " + fullReturnType, e);
        }
    }

    public Object invoke(Object[] args) {

        BoundStatement bs = statement.bind();

        ProtocolVersion protocolVersion = session.getCluster().getConfiguration().getProtocolOptions().getProtocolVersionEnum();
        for (int i = 0; i < args.length; i++) {
            paramMappers[i].setValue(bs, args[i], protocolVersion);
        }

        if (consistency != null)
            bs.setConsistencyLevel(consistency);
        if (fetchSize > 0)
            bs.setFetchSize(fetchSize);
        if (tracing)
            bs.enableTracing();

        if (returnStatement)
            return bs;

        if (async) {
            ListenableFuture<ResultSet> future = session.executeAsync(bs);
            if (returnMapper == null)
                return future;

            return mapOne
                 ? Futures.transform(future, returnMapper.mapOneFunctionWithoutAliases)
                 : Futures.transform(future, returnMapper.mapAllFunctionWithoutAliases);
        } else {
            ResultSet rs = session.execute(bs);
            if (returnMapper == null)
                return rs;

            Result<?> result = returnMapper.map(rs);
            return mapOne ? result.one() : result;
        }
    }

    static class ParamMapper {
        
        private final String paramName;
        private final int paramIdx;
        private final DataType dataType;

        public ParamMapper(String paramName, int paramIdx, DataType dataType) {
            this.paramName = paramName;
            this.paramIdx = paramIdx;
            this.dataType = dataType;
        }

        public ParamMapper(String paramName, int paramIdx) {
            this(paramName, paramIdx, null);
        }

        void setValue(BoundStatement boundStatement, Object arg, ProtocolVersion protocolVersion) {
            ByteBuffer serializedArg = (dataType == null)
                ? DataType.serializeValue(arg, protocolVersion)
                : dataType.serialize(arg, protocolVersion);
            if (paramName == null) {
                if (arg == null)
                    boundStatement.setToNull(paramIdx);
                else
                    boundStatement.setBytesUnsafe(paramIdx, serializedArg);
            } else {
                if (arg == null)
                    boundStatement.setToNull(paramName);
                else
                    boundStatement.setBytesUnsafe(paramName, serializedArg);
            }
        }
    }

    static class UDTParamMapper<V> extends ParamMapper {
        private final UDTMapper<V> udtMapper;

        UDTParamMapper(String paramName, int paramIdx, UDTMapper<V> udtMapper) {
            super(paramName, paramIdx);
            this.udtMapper = udtMapper;
        }

        @Override
        void setValue(BoundStatement boundStatement, Object arg, ProtocolVersion protocolVersion) {
            @SuppressWarnings("unchecked")
            V entity = (V) arg;
            UDTValue udtArg = arg != null ? udtMapper.toUDT(entity) : null;
            super.setValue(boundStatement, udtArg, protocolVersion);
        }
    }

    
    static class NestedUDTParamMapper extends ParamMapper {
        private final InferredCQLType inferredCQLType;

        NestedUDTParamMapper(String paramName, int paramIdx, InferredCQLType inferredCQLType) {
            super(paramName, paramIdx);
            this.inferredCQLType = inferredCQLType;
        }

        @Override
        void setValue(BoundStatement boundStatement, Object arg, ProtocolVersion protocolVersion) {
            super.setValue(boundStatement,
                UDTMapper.convertEntitiesToUDTs(arg, inferredCQLType),
                protocolVersion);
        }
    }

    static class EnumParamMapper extends ParamMapper {

        private final EnumType enumType;

        public EnumParamMapper(String paramName, int paramIdx, EnumType enumType) {
            super(paramName, paramIdx);
            this.enumType = enumType;
        }

        @Override
        void setValue(BoundStatement boundStatement, Object arg, ProtocolVersion protocolVersion) {
            super.setValue(boundStatement, convert(arg), protocolVersion);
        }

        @SuppressWarnings("rawtypes")
        private Object convert(Object arg) {
            if(arg == null)
                return arg;

            switch (enumType) {
            case STRING:
                return arg.toString();
            case ORDINAL:
                return ((Enum) arg).ordinal();
            }
            throw new AssertionError();
        }
    }
}

<code block>

package com.datastax.driver.mapping;

import java.util.Collection;

import com.datastax.driver.core.ResultSet;
import com.google.common.collect.Lists;
import org.testng.annotations.Test;

import static org.assertj.core.api.Assertions.assertThat;

import com.datastax.driver.core.CCMBridge;
import com.datastax.driver.mapping.annotations.*;

public class MapperAccessorParamsTest extends CCMBridge.PerClassSingleNodeCluster {
    @Override
    protected Collection<String> getTableDefinitions() {
        return Lists.newArrayList(
                "CREATE TABLE user ( key int primary key, gender int)",
                "CREATE INDEX on user(gender)",
                "CREATE TABLE user_str ( key int primary key, gender text)",
                "CREATE INDEX on user_str(gender)");
    }

    @Test(groups = "short")
    void should_include_enumtype_in_accessor_ordinal() {
        UserAccessor accessor = new MappingManager(session)
                .createAccessor(UserAccessor.class);

        accessor.addUser(0, Enum.FEMALE);
        accessor.addUser(1, Enum.MALE);

        assertThat(accessor.getUser(Enum.MALE).one().getGender()).isEqualTo(Enum.MALE);
        assertThat(accessor.getUser(Enum.MALE).one().getKey()).isEqualTo(1);

        assertThat(accessor.getUser(Enum.FEMALE).one().getGender()).isEqualTo(Enum.FEMALE);
        assertThat(accessor.getUser(Enum.FEMALE).one().getKey()).isEqualTo(0);
    }

    @Test(groups = "short")
    void should_include_enumtype_in_accessor_string() {
        UserAccessor accessor = new MappingManager(session)
                .createAccessor(UserAccessor.class);

        accessor.addUserStr(0, Enum.FEMALE);
        accessor.addUserStr(1, Enum.MALE);

        assertThat(accessor.getUserStr(Enum.MALE).one().getGender()).isEqualTo(Enum.MALE);
        assertThat(accessor.getUserStr(Enum.MALE).one().getKey()).isEqualTo(1);

        assertThat(accessor.getUserStr(Enum.FEMALE).one().getGender()).isEqualTo(Enum.FEMALE);
        assertThat(accessor.getUserStr(Enum.FEMALE).one().getKey()).isEqualTo(0);
    }

    enum Enum {
        MALE, FEMALE
    }

    @Accessor
    public interface UserAccessor {
        @Query("select * from user where gender=?")
        Result<User> getUser(@Enumerated(EnumType.ORDINAL) Enum value);

        @Query("select * from user_str where gender=?")
        Result<UserStr> getUserStr(@Enumerated(EnumType.STRING) Enum value);

        @Query("insert into user (key, gender) values (?,?)")
        ResultSet addUser(int key, @Enumerated(EnumType.ORDINAL) Enum value);

        @Query("insert into user_str (key, gender) values (?,?)")
        ResultSet addUserStr(int key, @Enumerated(EnumType.STRING) Enum value);
    }

    @Table(name = "user")
    public static class User {
        @PartitionKey
        private int key;

        @Enumerated(EnumType.ORDINAL)
        private Enum gender;

        public User() {
        }

        public User(int k, Enum val) {
            this.key = k;
            this.gender = val;
        }

        public int getKey() {
            return this.key;
        }

        public void setKey(int pk) {
            this.key = pk;
        }

        public Enum getGender() {
            return this.gender;
        }

        public void setGender(Enum val) {
            this.gender = val;
        }
    }

    @Table(name = "user")
    public static class UserStr {
        @PartitionKey
        private int key;

        private Enum gender;

        public UserStr() {
        }

        public UserStr(int k, Enum val) {
            this.key = k;
            this.gender = val;
        }

        public int getKey() {
            return this.key;
        }

        public void setKey(int pk) {
            this.key = pk;
        }

        public Enum getGender() {
            return this.gender;
        }

        public void setGender(Enum val) {
            this.gender = val;
        }
    }
}
<code block>

package com.datastax.driver.core.querybuilder;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import com.datastax.driver.core.TableMetadata;


public class Insert extends BuiltStatement {

    private final String table;
    private final List<Object> names = new ArrayList<Object>();
    private final List<Object> values = new ArrayList<Object>();
    private final Options usings;
    private boolean ifNotExists;

    Insert(String keyspace, String table) {
        super(keyspace);
        this.table = table;
        this.usings = new Options(this);
    }

    Insert(TableMetadata table) {
        super(table);
        this.table = escapeId(table.getName());
        this.usings = new Options(this);
    }

    @Override
    StringBuilder buildQueryString(List<Object> variables) {
        StringBuilder builder = new StringBuilder();

        builder.append("INSERT INTO ");
        if (keyspace != null)
            Utils.appendName(keyspace, builder).append('.');
        Utils.appendName(table, builder);
        builder.append('(');
        Utils.joinAndAppendNames(builder, ",", names);
        builder.append(") VALUES (");
        Utils.joinAndAppendValues(builder, ",", values, variables);
        builder.append(')');

        if (ifNotExists)
            builder.append(" IF NOT EXISTS");

        if (!usings.usings.isEmpty()) {
            builder.append(" USING ");
            Utils.joinAndAppend(builder, " AND ", usings.usings, variables);
        }
        return builder;
    }

    
    public Insert value(String name, Object value) {
        names.add(name);
        values.add(value);
        checkForBindMarkers(value);
        maybeAddRoutingKey(name, value);
        return this;
    }

    
    public Insert values(String[] names, Object[] values) {
        return values(Arrays.asList(names), Arrays.asList(values));
    }

    
    public Insert values(List<String> names, List<Object> values) {
        if (names.size() != values.size())
            throw new IllegalArgumentException(String.format("Got %d names but %d values", names.size(), values.size()));
        this.names.addAll(names);
        this.values.addAll(values);
        for (int i = 0; i < names.size(); i++) {
            checkForBindMarkers(values.get(i));
            maybeAddRoutingKey(names.get(i), values.get(i));
        }
        return this;
    }

    
    public Options using(Using using) {
        return usings.and(using);
    }

    
    public Insert ifNotExists() {
        this.ifNotExists = true;
        return this;
    }

    
    public static class Options extends BuiltStatement.ForwardingStatement<Insert> {

        private final List<Using> usings = new ArrayList<Using>();

        Options(Insert st) {
            super(st);
        }

        
        public Options and(Using using) {
            usings.add(using);
            checkForBindMarkers(using);
            return this;
        }

        
        public Insert value(String name, Object value) {
            return statement.value(name, value);
        }

        
        public Insert values(String[] names, Object[] values) {
            return statement.values(names, values);
        }
    }
}

<code block>

package com.datastax.driver.core.querybuilder;

import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import com.datastax.driver.core.TableMetadata;


public class Insert extends BuiltStatement {

    private final String table;
    private final List<Object> names = new ArrayList<Object>();
    private final List<Object> values = new ArrayList<Object>();
    private final Options usings;
    private boolean ifNotExists;

    Insert(String keyspace, String table) {
        super(keyspace);
        this.table = table;
        this.usings = new Options(this);
    }

    Insert(TableMetadata table) {
        super(table);
        this.table = escapeId(table.getName());
        this.usings = new Options(this);
    }

    @Override
    StringBuilder buildQueryString(List<Object> variables) {
        StringBuilder builder = new StringBuilder();

        builder.append("INSERT INTO ");
        if (keyspace != null)
            Utils.appendName(keyspace, builder).append('.');
        Utils.appendName(table, builder);
        builder.append('(');
        Utils.joinAndAppendNames(builder, ",", names);
        builder.append(") VALUES (");
        Utils.joinAndAppendValues(builder, ",", values, variables);
        builder.append(')');

        if (ifNotExists)
            builder.append(" IF NOT EXISTS");

        if (!usings.usings.isEmpty()) {
            builder.append(" USING ");
            Utils.joinAndAppend(builder, " AND ", usings.usings, variables);
        }
        return builder;
    }

    
    public Insert value(String name, Object value) {
        names.add(name);
        values.add(value);
        checkForBindMarkers(value);
        maybeAddRoutingKey(name, value);
        return this;
    }

    
    public Insert values(String[] names, Object[] values) {
        if (names.length != values.length)
            throw new IllegalArgumentException(String.format("Got %d names but %d values", names.length, values.length));
        this.names.addAll(Arrays.asList(names));
        this.values.addAll(Arrays.asList(values));

        for (int i = 0; i < names.length; i++) {
            checkForBindMarkers(values[i]);
            maybeAddRoutingKey(names[i], values[i]);
        }
        return this;
    }

    
    public Options using(Using using) {
        return usings.and(using);
    }

    
    public Insert ifNotExists() {
        this.ifNotExists = true;
        return this;
    }

    
    public static class Options extends BuiltStatement.ForwardingStatement<Insert> {

        private final List<Using> usings = new ArrayList<Using>();

        Options(Insert st) {
            super(st);
        }

        
        public Options and(Using using) {
            usings.add(using);
            checkForBindMarkers(using);
            return this;
        }

        
        public Insert value(String name, Object value) {
            return statement.value(name, value);
        }

        
        public Insert values(String[] names, Object[] values) {
            return statement.values(names, values);
        }
    }
}
