
package com.addthis.hydra.task.output.tree;

import java.util.ArrayList;
import java.util.List;

import com.addthis.bundle.core.BundleField;
import com.addthis.bundle.util.ValueUtil;
import com.addthis.bundle.value.ValueFactory;
import com.addthis.bundle.value.ValueMap;
import com.addthis.bundle.value.ValueMapEntry;
import com.addthis.bundle.value.ValueObject;
import com.addthis.bundle.value.ValueString;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.hydra.data.filter.value.ValueFilter;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.TreeDataParent;


public class PathValue extends PathElement {

    public PathValue() {
    }

    public PathValue(String value) {
        this.value = value;
    }

    public PathValue(String value, boolean count) {
        this.value = value;
        this.count = count;
    }

    
    @FieldConfig(codable = true)
    protected String value;

    @FieldConfig(codable = true)
    protected String set;

    @FieldConfig(codable = true)
    protected ValueFilter vfilter;

    @FieldConfig(codable = true)
    protected boolean sync;

    @FieldConfig(codable = true)
    protected boolean create = true;

    @FieldConfig(codable = true)
    protected boolean once;

    @FieldConfig(codable = true)
    protected String mapTo;

    
    @FieldConfig protected boolean delete;

    @FieldConfig(codable = true)
    protected boolean push;

    @FieldConfig(codable = true)
    protected PathElement each;

    
    @FieldConfig(codable = true)
    protected int maxNodes = 0;

    private ValueString valueString;
    private BundleField setField;
    private BundleField mapField;

    public final ValueObject value() {
        if (valueString == null) {
            valueString = ValueFactory.create(value);
        }
        return valueString;
    }

    
    public ValueObject getPathValue(final TreeMapState state) {
        return value();
    }

    public final ValueObject getFilteredValue(final TreeMapState state) {
        ValueObject value = getPathValue(state);
        if (vfilter != null) {
            value = vfilter.filter(value, state.getBundle());
        }
        return value;
    }

    @Override
    public void resolve(final TreeMapper mapper) {
        super.resolve(mapper);
        if (set != null) {
            setField = mapper.bindField(set);
        }
        if (mapTo != null) {
            mapField = mapper.bindField(mapTo);
        }
        if (each != null) {
            each.resolve(mapper);
        }
    }

    @Override
    public String toString() {
        return "PathValue[" + value + "]";
    }

    
    @Override
    public final List<DataTreeNode> getNextNodeList(final TreeMapState state) {
        ValueObject value = getFilteredValue(state);
        if (setField != null) {
            state.getBundle().setValue(setField, value);
        }
        if (ValueUtil.isEmpty(value)) {
            return op ? TreeMapState.empty() : null;
        }
        if (op) {
            return TreeMapState.empty();
        }
        List<DataTreeNode> list;
        if (sync) {
            synchronized (this) {
                list = processNodeUpdates(state, value);
            }
        } else {
            list = processNodeUpdates(state, value);
        }
        if (term) {
            if (list != null) {
                list.forEach(DataTreeNode::release);
            }
            return null;
        } else {
            return list;
        }
    }

    
    public DataTreeNode getOrCreateNode(TreeMapState state, String name, TreeDataParent path) {
        if (create && ((maxNodes == 0) || (state.getNodeCount() < maxNodes))) {
            return state.getOrCreateNode(name, state, path);
        } else {
            return state.getLeasedNode(name);
        }
    }

    
    public List<DataTreeNode> processNodeUpdates(TreeMapState state, ValueObject name) {
        List<DataTreeNode> list = new ArrayList<>(1);
        int pushed = 0;
        if (name.getObjectType() == ValueObject.TYPE.ARRAY) {
            for (ValueObject o : name.asArray()) {
                if (o != null) {
                    pushed += processNodeByValue(list, state, o);
                }
            }
        } else if (name.getObjectType() == ValueObject.TYPE.MAP) {
            ValueMap nameAsMap = name.asMap();
            for (ValueMapEntry e : nameAsMap) {
                String key = e.getKey();
                if (mapTo != null) {
                    state.getBundle().setValue(mapField, e.getValue());
                    pushed += processNodeByValue(list, state, ValueFactory.create(key));
                } else {
                    PathValue mapValue = new PathValue(key, count);
                    List<DataTreeNode> tnl = mapValue.processNode(state);
                    if (tnl != null) {
                        state.push(tnl);
                        List<DataTreeNode> children = processNodeUpdates(state, e.getValue());
                        if (children != null) {
                            list.addAll(children);
                        }
                        state.pop().release();
                    }
                }
            }
        } else {
            pushed += processNodeByValue(list, state, name);
        }
        while (pushed-- > 0) {
            state.pop().release();
        }
        if (!list.isEmpty()) {
            return list;
        } else {
            return null;
        }
    }

    
    public final int processNodeByValue(List<DataTreeNode> list, TreeMapState state, ValueObject name) {
        if (each != null) {
            List<DataTreeNode> next = state.processPathElement(each);
            if (push) {
                if (next.size() > 1) {
                    throw new RuntimeException("push and each are incompatible for > 1 return nodes");
                }
                if (next.size() == 1) {
                    state.push(next.get(0));
                    return 1;
                }
            } else if (next != null) {
                list.addAll(next);
            }
            return 0;
        }
        DataTreeNode parent = state.current();
        String sv = ValueUtil.asNativeString(name);
        if (delete) {
            parent.deleteNode(sv);
        }
        
        DataTreeNode child = getOrCreateNode(state, sv, this);
        boolean isnew = state.getAndClearLastWasNew();
        
        if (child == null) {
            return 0;
        }
        
        if (once && !isnew) {
            child.release();
            return 0;
        }
        try {
            
            if (assignHits()) {
                state.setAssignmentValue(hitsField.getLong(state.getBundle()).orElse(0l));
            }
            child.updateChildData(state, this);
            
            parent.updateParentData(state, child, isnew);
            if (push) {
                state.push(child);
                return 1;
            } else {
                list.add(child);
                return 0;
            }
        } catch (Throwable t) {
            child.release();
            throw t;
        }
    }
}

<code block>

package com.addthis.hydra.task.output.tree;

import javax.annotation.Nullable;

import java.util.ArrayList;
import java.util.Collections;
import java.util.LinkedList;
import java.util.List;

import com.addthis.basis.util.LessStrings;

import com.addthis.bundle.core.Bundle;
import com.addthis.bundle.core.BundleFactory;
import com.addthis.bundle.core.BundleFormat;
import com.addthis.bundle.core.BundleFormatted;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeInitializer;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;

import com.addthis.hydra.data.tree.TreeDataParent;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
@SuppressWarnings("serial")
public final class TreeMapState implements DataTreeNodeUpdater, DataTreeNodeInitializer, BundleFactory, BundleFormatted {

    private static final Logger log = LoggerFactory.getLogger(TreeMapState.class);
    private static final int debug = Integer.parseInt(System.getProperty("hydra.process.debug", "0"));
    private static final boolean debugthread = System.getProperty("hydra.process.debugthread", "0").equals("1");
    
    private static final List<DataTreeNode> empty = Collections.unmodifiableList(new ArrayList<>());

    static {
        if (debugthread) {
            log.warn("ENABLED debugthread");
        }
    }

    
    public TreeMapState(Bundle p) {
        this.bundle = p;
        this.path = null;
        this.processor = null;
        this.stack = null;
        this.thread = null;
        this.profiling = false;
    }

    
    public TreeMapState(TreeMapper processor, DataTreeNode rootNode, PathElement[] path, Bundle bundle) {
        this.path = path;
        this.bundle = bundle;
        this.processor = processor;
        this.countValue = 1;
        this.stack = new LinkedList<>();
        this.thread = Thread.currentThread();
        this.profiling = processor != null ? processor.isProfiling() : false;
        push(rootNode);
    }

    private final LinkedList<DataTreeNode> stack;
    private final TreeMapper processor;
    private final PathElement[] path;
    private final Bundle bundle;
    private final Thread thread;
    private final boolean profiling;

    private boolean lastWasNew;
    private int touched;
    private int countValue;
    private long assignmentValue;

    private void checkThread() {
        if (Thread.currentThread() != thread) {
            throw new RuntimeException("invalid accessing thread " + Thread.currentThread() + " != " + thread);
        }
    }

    public static List<DataTreeNode> empty() {
        return empty;
    }

    @Override
    public int getCountValue() {
        return countValue;
    }

    public void setCountValue(int v) {
        countValue = v;
    }

    @Override
    public long getAssignmentValue() {
        return assignmentValue;
    }

    public TreeMapState setAssignmentValue(long assignmentValue) {
        this.assignmentValue = assignmentValue;
        return this;
    }

    public boolean getAndClearLastWasNew() {
        boolean ret = lastWasNew;
        lastWasNew = false;
        return ret;
    }

    public DataTreeNode getLeasedNode(String key) {
        DataTreeNode tn = current().getLeasedNode(key);
        return tn;
    }

    public DataTreeNode getOrCreateNode(String key, DataTreeNodeInitializer init, TreeDataParent path) {
        DataTreeNode tn = current().getOrCreateNode(key, init, path);
        return tn;
    }

    public DataTreeNode pop() {
        if (debugthread) {
            checkThread();
        }
        return stack.pop();
    }

    public int getNodeCount() {
        return current().getNodeCount();
    }

    public void push(List<DataTreeNode> tnl) {
        if (tnl.size() == 1) {
            push(tnl.get(0));
        } else {
            throw new RuntimeException("unexpected response: " + tnl.size() + " -> " + tnl);
        }
    }

    public void push(DataTreeNode tn) {
        if (debugthread) {
            checkThread();
        }
        stack.push(tn);
    }

    
    public long getBundleTime() {
        throw new RuntimeException("fix me");
    }

    public void setBundleTime(long time) {
        throw new RuntimeException("fix me");
    }

    
    public DataTreeNode peek(int back) {
        return (stack.size() > back) ? stack.get(back) : null;
    }

    
    public DataTreeNode current() {
        return stack.peek();
    }

    @Override
    public Bundle getBundle() {
        return bundle;
    }

    
    public int touched() {
        return touched;
    }

    
    public void dispatchRule(TreeMapperPathReference t) {
        if ((t != null) && (bundle != null) && (processor != null)) {
            processor.processBundle(bundle, t);
        } else if (debug > 0) {
            log.warn("Proc Rule Dispatch DROP {} b/c p={} rp={}", t, bundle, processor);
        }
    }

    public void process() {
        List<DataTreeNode> list = processPath(path, 0);
        if ((debug > 0) && ((list == null) || list.isEmpty())) {
            log.warn("proc FAIL {}", list);
            log.warn(".... PATH {}", LessStrings.join(path, " 
            log.warn(".... PACK {}", bundle);
        }
        if (list != null) {
            list.forEach(DataTreeNode::release);
        }
    }

    
    public List<DataTreeNode> processPath(PathElement[] path) {
        return processPath(path, 0);
    }

    
    @Nullable private List<DataTreeNode> processPath(PathElement[] path, int index) {
        if ((path == null) || (path.length <= index)) {
            return null;
        }
        List<DataTreeNode> nodes = processPathElement(path[index]);
        if ((nodes != null) && nodes.isEmpty()) {
            
            if ((index + 1) < path.length) {
                return processPath(path, index + 1);
            }
            return null;
        } else if (nodes == null) {
            return null;
        } else if ((index + 1) < path.length) {
            List<DataTreeNode> childNodes = null;
            for (DataTreeNode tn : nodes) {
                push(tn);
                List<DataTreeNode> childNodesPartition = processPath(path, index + 1);
                if (childNodesPartition != null) {
                    if ((childNodes == null) || (childNodes == empty)) {
                        childNodes = childNodesPartition;
                    } else {
                        childNodes.addAll(childNodesPartition);
                    }
                }
                pop().release();
            }
            return childNodes;
        } else {
            return nodes;
        }
    }

    
    public List<DataTreeNode> processPathElement(PathElement pe) {
        if (profiling) {
            long mark = System.nanoTime();
            List<DataTreeNode> list = processPathElementProfiled(pe);
            processor.updateProfile(pe, System.nanoTime() - mark);
            return list;
        } else {
            return processPathElementProfiled(pe);
        }
    }

    private List<DataTreeNode> processPathElementProfiled(PathElement pe) {
        if (pe.disabled()) {
            return empty();
        }
        if (debugthread) {
            checkThread();
        }
        List<DataTreeNode> list = pe.processNode(this);
        if (list != null) {
            touched += list.size();
        }
        return list;
    }

    @Override
    public void onNewNode(DataTreeNode child) {
        lastWasNew = true;
    }

    @Override
    public Bundle createBundle() {
        return processor.createBundle();
    }

    @Override
    public BundleFormat getFormat() {
        return processor.getFormat();
    }

    public boolean processorClosing() { return processor.isClosing(); }
}

<code block>

package com.addthis.hydra.task.output.tree;

import com.addthis.basis.util.LessStrings;

import com.addthis.bundle.util.ValueUtil;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeInitializer;
import com.addthis.hydra.data.tree.DataTreeUtil;
import com.addthis.hydra.data.tree.TreeDataParent;


public class PathAlias extends PathKeyValue {

    
    @FieldConfig(codable = true, required = true)
    protected PathValue[] path;

    
    @FieldConfig(codable = true)
    protected int relativeUp;

    
    @FieldConfig(codable = true)
    protected boolean peer;

    
    @FieldConfig(codable = true)
    protected boolean hard;

    
    @FieldConfig(codable = true)
    protected int debug;

    
    @FieldConfig(codable = true)
    private String debugKey;

    private int match;
    private int miss;

    public PathAlias() {
    }

    public PathAlias(PathValue[] path) {
        this.path = path;
    }

    @Override
    public void resolve(TreeMapper mapper) {
        super.resolve(mapper);
        for (PathValue pv : path) {
            pv.resolve(mapper);
        }
    }

    @Override
    public DataTreeNode getOrCreateNode(final TreeMapState state, final String name, TreeDataParent parentPath) {
        if (hard) {
            DataTreeNode node = state.getLeasedNode(name);
            if (node != null) {
                return node;
            }
        }
        String[] p = new String[path.length];
        for (int i = 0; i < p.length; i++) {
            p[i] = ValueUtil.asNativeString(path[i].getFilteredValue(state));
        }
        DataTreeNode alias = null;
        if (peer) {
            alias = DataTreeUtil.pathLocateFrom(state.current(), p);
        } else if (relativeUp > 0) {
            alias = DataTreeUtil.pathLocateFrom(state.peek(relativeUp), p);
        } else {
            alias = DataTreeUtil.pathLocateFrom(state.current().getTreeRoot(), p);
        }
        if (alias != null) {
            final DataTreeNode finalAlias = alias;
            DataTreeNodeInitializer init = child -> {
                child.aliasTo(finalAlias);
                state.onNewNode(child);
            };
            if (debug > 0) {
                debug(true);
            }
            return state.getOrCreateNode(name, init, this);
        } else {
            if (debug > 0) {
                debug(false);
            }
            if (log.isDebugEnabled() || debug == 1) {
                log.warn("alias fail, missing " + LessStrings.join(p, " / "));
            }
            return null;
        }
    }

    protected synchronized void debug(boolean hit) {
        if (hit) {
            match++;
        } else {
            miss++;
        }
        if (match + miss >= debug) {
            log.warn("query[" + debugKey + "]: match=" + match + " miss=" + miss);
            match = 0;
            miss = 0;
        }
    }
}

<code block>

package com.addthis.hydra.data.tree;

import java.util.Map;

import com.addthis.basis.util.ClosableIterator;

import com.fasterxml.jackson.annotation.JsonAutoDetect;


@JsonAutoDetect(getterVisibility = JsonAutoDetect.Visibility.NONE,
                isGetterVisibility = JsonAutoDetect.Visibility.NONE,
                setterVisibility = JsonAutoDetect.Visibility.NONE)
public interface DataTreeNode extends Iterable<DataTreeNode> {

    
    public String getName();

    
    public DataTree getTreeRoot();

    
    public int getNodeCount();

    
    public long getCounter();

    
    public DataTreeNodeActor getData(String key);

    
    public DataTreeNode getNode(String name);

    
    public Map<String, TreeNodeData> getDataMap();

    
    public ClosableIterator<DataTreeNode> getIterator();

    
    public ClosableIterator<DataTreeNode> getIterator(String prefix);

    
    public ClosableIterator<DataTreeNode> getIterator(String from, String to);

    

    
    public default void incrementCounter() {
        throw new UnsupportedOperationException("incrementCounter");
    }

    
    public default long incrementCounter(long val) {
        throw new UnsupportedOperationException("incrementCounter");
    }

    
    public default void setCounter(long val) {
        throw new UnsupportedOperationException("setCounter");
    }

    
    public default void updateChildData(DataTreeNodeUpdater state, TreeDataParent path) {
        throw new UnsupportedOperationException("updateChildData");
    }

    
    public default void updateParentData(DataTreeNodeUpdater state, DataTreeNode child, boolean isnew) {
        throw new UnsupportedOperationException("updateParentData");
    }

    
    public default boolean aliasTo(DataTreeNode target) {
        throw new UnsupportedOperationException("aliasTo");
    }

    
    public default boolean deleteNode(String node) {
        throw new UnsupportedOperationException("deleteNode");
    }

    

    
    public default DataTreeNode getOrCreateNode(String name, DataTreeNodeInitializer init, TreeDataParent path) {
        throw new UnsupportedOperationException("getOrCreateNode");
    }

    
    public default DataTreeNode getLeasedNode(String name) {
        throw new UnsupportedOperationException("getLeasedNode");
    }

    
    public default void release() {
        throw new UnsupportedOperationException("release");
    }

    public default void writeLock() {
        throw new UnsupportedOperationException("writeLock");
    }

    public default void writeUnlock() {
        throw new UnsupportedOperationException("writeUnlock");
    }
}

<code block>

package com.addthis.hydra.data.tree.prop;

import java.util.HashMap;
import java.util.NoSuchElementException;

import com.addthis.basis.util.ClosableIterator;

import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.tree.concurrent.ConcurrentTreeNode;
import com.addthis.hydra.data.tree.DataTreeNode;


public final class VirtualTreeNode extends ConcurrentTreeNode {

    public VirtualTreeNode(final String name, final long hits) {
        this(name, hits, null);
    }

    public VirtualTreeNode(final String name, final long hits, final VirtualTreeNode[] children) {
        this.name = name;
        this.hits = hits;
        this.setCounter(hits);
        this.nodes = children != null ? children.length : 0;
        this.children = children;
    }

    private final VirtualTreeNode[] children;

    @Override
    public ClosableIterator<DataTreeNode> getNodeIterator() {
        return new VirtualTreeNodeIterator();
    }

    @Override
    public ClosableIterator<DataTreeNode> getNodeIterator(String prefix) {
        VirtualTreeNodeIterator iter = new VirtualTreeNodeIterator();
        while (true) {
            VirtualTreeNode peek = iter.peek();
            if ((peek == null) || peek.name.startsWith(prefix)) {
                break;
            }
            iter.next();
        }
        return iter;
    }

    @Override
    public ClosableIterator<DataTreeNode> getNodeIterator(String from, String to) {
        VirtualTreeNodeIterator iter = new VirtualTreeNodeIterator();
        iter.end = to;
        while (true) {
            VirtualTreeNode peek = iter.peek();
            if (peek == null || (peek.name.compareTo(from) >= 0) && (to == null || peek.name.compareTo(to) <= 0)) {
                break;
            }
            iter.next();
        }
        return iter;
    }

    @Override
    public ConcurrentTreeNode getNode(String name) {
        if (children == null || children.length == 0) {
            return null;
        }
        for (VirtualTreeNode vtn : children) {
            if (vtn.name.equals(name)) {
                return vtn;
            }
        }
        return null;
    }

    
    @Override
    public HashMap<String, TreeNodeData> createMap(int size) {
        return super.createMap(size);
    }

    private class VirtualTreeNodeIterator implements ClosableIterator<DataTreeNode> {

        int pos;
        String end;

        VirtualTreeNode peek() {
            return children != null && pos < children.length ? children[pos] : null;
        }

        @Override
        public void close() {
        }

        @Override
        public boolean hasNext() {
            if (children != null && pos < children.length) {
                if (end != null) {
                    return children[pos].name.compareTo(end) < 0;
                }
                return true;
            }
            return false;
        }

        @Override
        public VirtualTreeNode next() {
            if (!hasNext()) {
                throw new NoSuchElementException();
            }
            return children[pos++];
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException();
        }
    }
}

<code block>

package com.addthis.hydra.data.tree.prop;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import com.addthis.basis.util.LessStrings;
import com.addthis.basis.util.Varint;

import com.addthis.bundle.util.AutoField;
import com.addthis.bundle.value.ValueFactory;
import com.addthis.bundle.value.ValueObject;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.codec.codables.Codable;
import com.addthis.hydra.data.filter.value.ValueFilter;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;
import com.addthis.hydra.data.tree.ReadTreeNode;
import com.addthis.hydra.data.tree.TreeDataParameters;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.util.KeyTopper;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.PooledByteBufAllocator;
import io.netty.buffer.Unpooled;

public class DataKeyTop extends TreeNodeData<DataKeyTop.Config> implements Codable {

    
    public static final class Config extends TreeDataParameters<DataKeyTop> {

        
        @FieldConfig(codable = true, required = true)
        private AutoField key;

        
        @FieldConfig(codable = true)
        private AutoField weight;

        
        @FieldConfig(codable = true, required = true)
        private int size;

        
        @FieldConfig(codable = true)
        private boolean errors;

        
        @FieldConfig(codable = true)
        private String splitRegex;

        
        @FieldConfig(codable = true)
        private ValueFilter filter;

        @Override
        public DataKeyTop newInstance() {
            DataKeyTop dataKeyTop = new DataKeyTop();
            dataKeyTop.size = size;
            dataKeyTop.top = new KeyTopper().init().setLossy(true).enableErrors(errors);
            dataKeyTop.filter = filter;
            return dataKeyTop;
        }
    }

    @FieldConfig(codable = true, required = true)
    private KeyTopper top;
    @FieldConfig(codable = true, required = true)
    private int size;

    private ValueFilter filter;
    private AutoField keyAccess;
    private AutoField weightAccess;

    @Override
    public boolean updateChildData(DataTreeNodeUpdater state, DataTreeNode childNode, DataKeyTop.Config conf) {
        if (keyAccess == null) {
            keyAccess = conf.key;
            weightAccess = conf.weight;
            filter = conf.filter;
        }
        ValueObject val = keyAccess.getValue(state.getBundle());
        if (val != null) {
            if (filter != null) {
                val = filter.filter(val, state.getBundle());
                if (val == null) {
                    return false;
                }
            }
            int weight = 1;
            if (weightAccess != null) {
                weight = weightAccess.getValue(state.getBundle()).asLong().asNative().intValue();
            }
            if (conf.splitRegex != null) {
                String[] split = val.toString().split(conf.splitRegex);
                for (int i = 0; i < split.length; i++) {
                    top.increment(split[i], weight, size);
                }
            } else {
                if (val.getObjectType() == ValueObject.TYPE.ARRAY) {
                    for (ValueObject obj : val.asArray()) {
                        top.increment(obj.toString(), weight, size);
                    }
                } else {
                    top.increment(val.toString(), weight, size);
                }
            }
            return true;
        } else {
            return false;
        }
    }

    @Override
    public ValueObject getValue(String key) {
        if (key != null && key.length() > 0) {
            if (key.equals("size")) {
                return ValueFactory.create(top.size());
            }
            try {
                if (key.charAt(0) == 'g') {
                    String topKey = key.substring(1);
                    Long val = top.get(topKey);
                    return ValueFactory.create(val != null ? val : 0);
                }
                if (key.charAt(0) == 'v') {
                    int pos = Integer.parseInt(key.substring(1));
                    return pos <= top.size() ? ValueFactory.create(top.getSortedEntries()[pos - 1].getValue()) : null;
                }
                if (key.charAt(0) == 'e') {
                    if (top.hasErrors()) {
                        int pos = Integer.parseInt(key.substring(1));
                        if (pos <= top.size()) {
                            String element = top.getSortedEntries()[pos - 1].getKey();
                            Long error = top.getError(element);
                            return ValueFactory.create(error);
                        }
                    }
                    return null;
                }
                if (key.charAt(0) == 'k') {
                    key = key.substring(1);
                }
                int pos = Integer.parseInt(key);
                return pos <= top.size() ? ValueFactory.create(top.getSortedEntries()[pos - 1].getKey()) : null;
            } catch (Exception e) {
                return ValueFactory.create(e.toString());
            }
        }
        return ValueFactory.create(top.toString());
    }

    
    @Override public List<String> getNodeTypes() {
        return Arrays.asList(new String[]{"#"});
    }

    @Override
    public List<DataTreeNode> getNodes(DataTreeNode parent, String key) {
        if (key != null && key.startsWith("=")) {
            key = key.substring(1);
            if (key.equals("hit") || key.equals("node")) {
                Entry<String, Long>[] list = top.getSortedEntries();
                ArrayList<DataTreeNode> ret = new ArrayList<>(list.length);
                for (Entry<String, Long> e : list) {
                    DataTreeNode node = parent.getNode(e.getKey());
                    if (node != null) {
                        ret.add(node);
                    }
                }
                return ret;
            } else if (key.equals("vhit")) {
                Entry<String, Long>[] list = top.getSortedEntries();
                ArrayList<DataTreeNode> ret = new ArrayList<>(list.length);
                for (Entry<String, Long> e : list) {
                    ret.add(new VirtualTreeNode(e.getKey(), e.getValue()));
                }
                return ret;
            } else if (key.equals("phit")) {
                Entry<String, Long>[] list = top.getSortedEntries();
                ArrayList<DataTreeNode> ret = new ArrayList<>(list.length);
                for (Entry<String, Long> e : list) {
                    DataTreeNode node = parent.getNode(e.getKey());
                    if (node != null) {
                        node = ((ReadTreeNode) node).getCloneWithCount(e.getValue());
                        ret.add(node);
                    }
                }
                return ret;
            } else if (key.equals("guaranteed")) {
                return generateVirtualNodes(true);
            }
        } else if (key != null) {
            String[] keys = LessStrings.splitArray(key, ":");
            ArrayList<DataTreeNode> list = new ArrayList<>(keys.length);
            for (String k : keys) {
                Long v = top.get(k);
                if (v != null) {
                    list.add(new VirtualTreeNode(k, v));
                }
            }
            return list.size() > 0 ? list : null;
        }
        return generateVirtualNodes(false);
    }

    
    private List<DataTreeNode> generateVirtualNodes(boolean onlyGuaranteed) {
        ArrayList<DataTreeNode> list = new ArrayList<>(top.size());
        Entry<String, Long>[] entries = top.getSortedEntries();
        for (int i = 0; i < entries.length; i++) {
            Entry<String,Long> entry = entries[i];
            String name = entry.getKey();
            Long value = entry.getValue();
            VirtualTreeNode node = new VirtualTreeNode(name, value);
            if (top.hasErrors()) {
                Long error = top.getError(name);
                if (onlyGuaranteed && ((i + 1) < entries.length) &&
                    ((value - error) < entries[i + 1].getValue())) {
                    break;
                }
                Map<String, TreeNodeData> data = node.createMap(this.size);
                DataMap dataMap = new DataMap(1);
                dataMap.put("error", ValueFactory.create(error));
                data.put("stats", dataMap);
            }
            list.add(node);
        }
        return list;
    }

    @Override
    public byte[] bytesEncode(long version) {
        byte[] bytes = null;
        ByteBuf buf = PooledByteBufAllocator.DEFAULT.buffer();
        try {
            byte[] topBytes = top.bytesEncode(version);
            Varint.writeUnsignedVarInt(topBytes.length, buf);
            buf.writeBytes(topBytes);
            Varint.writeUnsignedVarInt(size, buf);
            bytes = new byte[buf.readableBytes()];
            buf.readBytes(bytes);
        } finally {
            buf.release();
        }
        return bytes;
    }

    @Override
    public void bytesDecode(byte[] b, long version) {
        top = new KeyTopper();
        ByteBuf buf = Unpooled.wrappedBuffer(b);
        try {
            int topBytesLength = Varint.readUnsignedVarInt(buf);
            if (topBytesLength > 0) {
                byte[] topBytes = new byte[topBytesLength];
                buf.readBytes(topBytes);
                top.bytesDecode(topBytes, version);
            } else {
                top.init().setLossy(true);
            }
            size = Varint.readUnsignedVarInt(buf);
        } finally {
            buf.release();
        }
    }
}

<code block>

package com.addthis.hydra.data.tree.prop;

import java.util.Collections;
import java.util.Comparator;
import java.util.LinkedList;
import java.util.List;

import com.addthis.bundle.core.Bundle;
import com.addthis.bundle.core.BundleField;
import com.addthis.bundle.util.ValueUtil;
import com.addthis.bundle.value.ValueFactory;
import com.addthis.bundle.value.ValueObject;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.codec.codables.Codable;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;
import com.addthis.hydra.data.tree.TreeDataParameters;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.tree.TreeNodeDataDeferredOperation;


public class DataLimitRecent extends TreeNodeData<DataLimitRecent.Config> {

    
    public static final class Config extends TreeDataParameters<DataLimitRecent> {

        
        @FieldConfig(codable = true)
        private long age;

        
        @FieldConfig(codable = true)
        private int size;

        
        @FieldConfig(codable = true)
        private String timeKey;

        
        @FieldConfig(codable = true)
        private boolean sortQueue;

        @Override
        public DataLimitRecent newInstance() {
            DataLimitRecent dc = new DataLimitRecent();
            dc.size = size;
            dc.age = age;
            dc.timeKey = timeKey;
            dc.sortQueue = sortQueue;
            dc.queue = new LinkedList<>();
            return dc;
        }
    }

    
    public static final class KeyTime implements Codable {

        @FieldConfig(codable = true)
        private String key;
        @FieldConfig(codable = true)
        private long time;
    }

    @FieldConfig(codable = true)
    private int size;
    @FieldConfig(codable = true)
    private long age;
    @FieldConfig(codable = true)
    private long deleted;
    @FieldConfig(codable = true)
    private LinkedList<KeyTime> queue;
    @FieldConfig(codable = true)
    private String timeKey;
    @FieldConfig(codable = true)
    private boolean sortQueue;

    private BundleField keyAccess;

    @Override
    public boolean updateChildData(DataTreeNodeUpdater state, DataTreeNode tn, Config conf) {
        return false;
    }

    public static class DataLimitRecentDeferredOperation extends TreeNodeDataDeferredOperation {

        final DataTreeNode parentNode;
        final KeyTime e;

        DataLimitRecentDeferredOperation(DataTreeNode parentNode, KeyTime e) {
            this.parentNode = parentNode;
            this.e = e;
        }

        @Override
        public void run() {
            DataTreeNode check = parentNode.getOrCreateNode(e.key, null, null);
            if (check != null) {
                
                
                
                

                
                parentNode.writeLock();
                long counterVal;
                try {
                    counterVal = check.incrementCounter(-1);
                } finally {
                    parentNode.writeUnlock();
                }
                if (counterVal <= 0) {
                    if (!parentNode.deleteNode(e.key)) {
                        
                    }
                }

            }
        }
    }


    @Override
    public boolean updateParentData(DataTreeNodeUpdater state, DataTreeNode parentNode,
            DataTreeNode childNode,
            List<TreeNodeDataDeferredOperation> deferredOps) {
        try {
            KeyTime e = new KeyTime();
            e.key = childNode.getName();
            if (timeKey != null) {
                Bundle p = state.getBundle();
                if (keyAccess == null) {
                    keyAccess = p.getFormat().getField(timeKey);
                }
                e.time = ValueUtil.asNumber(p.getValue(keyAccess)).asLong().getLong();
            } else {
                e.time = System.currentTimeMillis();
            }
            queue.addFirst(e);
            if ((size > 0 && queue.size() > size) || (age > 0 && e.time - queue.peekLast().time > age)) {
                if (sortQueue) {
                    Collections.sort(queue, new Comparator<KeyTime>() {
                        @Override
                        public int compare(KeyTime o, KeyTime o1) {
                            if (o.time > o1.time) {
                                return -1;
                            } else if (o.time < o1.time) {
                                return 1;
                            } else {
                                return 0;
                            }
                        }
                    });
                }
                e = queue.removeLast();
                deferredOps.add(new DataLimitRecentDeferredOperation(parentNode, e));
            }
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
        return false;
    }

    @Override
    public ValueObject getValue(String key) {
        return ValueFactory.create(deleted);
    }
}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.NoSuchElementException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

import com.addthis.basis.util.ClosableIterator;
import com.addthis.basis.util.MemoryCounter.Mem;

import com.addthis.hydra.data.tree.AbstractTreeNode;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeActor;
import com.addthis.hydra.data.tree.DataTreeNodeInitializer;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;
import com.addthis.hydra.data.tree.TreeDataParameters;
import com.addthis.hydra.data.tree.TreeDataParent;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.tree.TreeNodeDataDeferredOperation;
import com.addthis.hydra.store.db.DBKey;
import com.addthis.hydra.store.db.IPageDB.Range;



public class ConcurrentTreeNode extends AbstractTreeNode {

    public static final int ALIAS = 1 << 1;

    public static ConcurrentTreeNode getTreeRoot(ConcurrentTree tree) {
        ConcurrentTreeNode node = new ConcurrentTreeNode() {
            @Override
            void requireEditable() {

            }
        };
        node.tree = tree;
        node.leases.incrementAndGet();
        node.nodedb = 1L;
        return node;
    }

    
    public ConcurrentTreeNode() {
    }

    protected void initIfDecoded(ConcurrentTree tree, DBKey key, String name) {
        if (decoded.get()) {
            synchronized (initLock) {
                if (initOnce.compareAndSet(false, true)) {
                    this.tree = tree;
                    this.dbkey = key;
                    this.name = name;
                    decoded.set(false);
                }
            }
        }
    }

    protected void init(ConcurrentTree tree, DBKey key, String name, TreeDataParent path) {
        this.tree = tree;
        this.dbkey = key;
        this.name = name;
        
        
        if (path != null && path.dataConfig() != null && !path.dataConfig().isEmpty()) {
            createMap(path.dataConfig().size());
        }
    }

    @Mem(estimate = false, size = 64)
    private ConcurrentTree tree;
    @Mem(estimate = false, size = 64)
    private AtomicInteger leases = new AtomicInteger(0);
    @Mem(estimate = false, size = 64)
    private AtomicBoolean changed = new AtomicBoolean(false);
    @Mem(estimate = false, size = 64)
    private ReadWriteLock lock = new ReentrantReadWriteLock();
    @Mem(estimate = false, size = 64)
    private AtomicLong atomicHits = new AtomicLong();

    private AtomicBoolean decoded = new AtomicBoolean(false);
    private AtomicBoolean initOnce = new AtomicBoolean(false);
    private final Object initLock = new Object();

    protected String name;
    protected DBKey dbkey;

    public String toString() {
        return "TN[k=" + dbkey + ",db=" + nodedb + ",n#=" + nodes + ",h#=" + hits +
               ",nm=" + name + ",le=" + leases + ",ch=" + changed + ",bi=" + bits + "]";
    }

    @Override
    public byte[] bytesEncode(long version) {
        this.hits = atomicHits.get();
        return super.bytesEncode(version);
    }

    @Override public String getName() {
        return name;
    }

    @Override @SuppressWarnings("unchecked")
    public Map<String, TreeNodeData> getDataMap() {
        return data;
    }

    public int getLeaseCount() {
        return leases.get();
    }

    

    protected synchronized int incrementNodeCount() {
        return nodes++;
    }

    protected synchronized int updateNodeCount(int delta) {
        nodes += delta;
        changed.set(true);
        return nodes;
    }

    void requireEditable() {
        int count = leases.get();
        if (!(count == -2 || count > 0)) {
            throw new RuntimeException("fail editable requirement: lease state is " + count);
        }
    }

    public final boolean isBitSet(int bitcheck) {
        return (bits & bitcheck) == bitcheck;
    }

    public boolean isAlias() {
        return isBitSet(ALIAS);
    }

    public boolean isDeleted() {
        int count = leases.get();
        return count == -2;
    }

    public void markChanged() {
        requireEditable();
        changed.set(true);
    }

    protected boolean markDeleted() {
        return leases.getAndSet(-2) != -2;
    }

    protected void evictionComplete() {
        leases.compareAndSet(-1, -3);
    }

    protected synchronized void markAlias() {
        bitSet(ALIAS);
    }

    protected boolean isChanged() {
        return changed.get();
    }

    private final void bitSet(int set) {
        bits |= set;
    }

    private final void bitUnset(int set) {
        bits &= (~set);
    }

    
    void reactivate() {
        while(true) {
            int count = leases.get();
            if (count == -3 && leases.compareAndSet(-3, 0)) {
                return;
            } else if (count == -1 && leases.compareAndSet(-1, 0)) {
                return;
            } else if (count != -3 && count != -1) {
                return;
            }
        }
    }

    
    boolean tryLease() {
        while (true) {
            int count = leases.get();
            if (count < 0) {
                return false;
            }
            if (leases.compareAndSet(count, count + 1)) {
                return true;
            }
        }
    }

    
    boolean trySetEviction() {
        while (true) {
            int count = leases.get();
            if (count == -2) {
                return true;
            } else if (count != 0) {
                return false;
            }
            if (leases.compareAndSet(0, -1)) {
                return true;
            }
        }
    }

    
    @Override
    public void release() {
        while (true) {
            int count = leases.get();
            if (count <= 0) {
                return;
            }
            if (leases.compareAndSet(count, count - 1)) {
                return;
            }
        }
    }

    
    protected void requireNodeDB() {
        if (!hasNodes()) {
            synchronized (this) {
                if (!hasNodes()) {
                    nodedb = tree.getNextNodeDB();
                }
            }
        }
    }

    protected long nodeDB() {
        return nodedb;
    }

    
    public ClosableIterator<DataTreeNode> getNodeIterator() {
        return !hasNodes() || isDeleted() ? new Iter(null, false) : new Iter(tree.fetchNodeRange(nodedb), true);
    }

    
    public ClosableIterator<DataTreeNode> getNodeIterator(String prefix) {
        if (!isDeleted() && prefix != null && prefix.length() > 0) {
            
            StringBuilder sb = new StringBuilder(prefix.substring(0, prefix.length() - 1));
            sb.append((char) (prefix.charAt(prefix.length() - 1) + 1));
            return getNodeIterator(prefix, sb.toString());
        } else {
            return new Iter(null, false);
        }
    }

    
    public ClosableIterator<DataTreeNode> getNodeIterator(String from, String to) {
        if (!hasNodes() || isDeleted()) {
            return new Iter(null, false);
        }
        return new Iter(tree.fetchNodeRange(nodedb, from, to), true);
    }

    @Override public ConcurrentTreeNode getNode(String name) {
        return tree.getNode(this, name, false);
    }

    @Override public ConcurrentTreeNode getLeasedNode(String name) {
        return tree.getNode(this, name, true);
    }

    public DataTreeNode getOrCreateEditableNode(String name) {
        return getOrCreateEditableNode(name, null, null);
    }

    public DataTreeNode getOrCreateEditableNode(String name, DataTreeNodeInitializer creator, TreeDataParent path) {
        return tree.getOrCreateNode(this, name, creator, path);
    }

    @Override public boolean deleteNode(String name) {
        return tree.deleteNode(this, name);
    }

    
    @Override
    public boolean aliasTo(DataTreeNode node) {
        if (node.getClass() != ConcurrentTreeNode.class) {
            return false;
        }
        requireEditable();
        if (hasNodes()) {
            return false;
        }
        ((ConcurrentTreeNode) node).requireNodeDB();
        nodedb = ((ConcurrentTreeNode) node).nodedb;
        markAlias();
        return true;
    }

    protected HashMap<String, TreeNodeData> createMap(int size) {
        if (data == null) {
            data = new HashMap<>(size);
        }
        return data;
    }

    
    @Override @SuppressWarnings("unchecked")
    public void updateChildData(DataTreeNodeUpdater state, TreeDataParent path) {
        requireEditable();
        boolean updated = false;
        HashMap<String, TreeDataParameters> dataconf = path.dataConfig();
        if (data == null || data.isEmpty()) {
            
            updateHits(state, path);
        } else {
            lock.writeLock().lock();
            try {
                updated = updateHits(state, path);
                if (dataconf != null) {
                    if (data == null) {
                        data = new HashMap<>(dataconf.size());
                    }
                    for (Entry<String, TreeDataParameters> el : dataconf.entrySet()) {
                        TreeNodeData tnd = data.get(el.getKey());
                        if (tnd == null) {
                            tnd = el.getValue().newInstance(this);
                            data.put(el.getKey(), tnd);
                            updated = true;
                        }
                        if (tnd.updateChildData(state, this, el.getValue())) {
                            updated = true;
                        }
                    }
                }
            } finally {
                lock.writeLock().unlock();
            }
        }
        if (updated) {
            changed.set(true);
        }
    }

    public boolean updateHits(DataTreeNodeUpdater state, TreeDataParent path) {
        boolean updated = false;
        if (path.assignHits()) {
            atomicHits.set(state.getAssignmentValue());
            updated = true;
        } else if (path.countHits()) {
            atomicHits.addAndGet(state.getCountValue());
            updated = true;
        }
        return updated;
    }

    @Override public void updateParentData(DataTreeNodeUpdater state, DataTreeNode child, boolean isnew) {
        List<TreeNodeDataDeferredOperation> deferredOps = null;
        
        
        
        if (child != null && data != null) {
            requireEditable();
            if (!data.isEmpty()) {
                lock.writeLock().lock();
                try {
                    deferredOps = new ArrayList<>(1);
                    for (TreeNodeData<?> tnd : data.values()) {
                        if (isnew && tnd.updateParentNewChild(state, this, child, deferredOps)) {
                            changed.set(true);
                        }
                        if (tnd.updateParentData(state, this, child, deferredOps)) {
                            changed.set(true);
                        }
                    }
                } finally {
                    lock.writeLock().unlock();
                }
            }
        }
        if (deferredOps != null) {
            for (TreeNodeDataDeferredOperation currentOp : deferredOps) {
                currentOp.run();
            }
        }
    }

    
    
    @Override public DataTreeNodeActor getData(String key) {
        lock.readLock().lock();
        try {
            return data != null ? data.get(key) : null;
        } finally {
            lock.readLock().unlock();
        }
    }

    
    
    public Collection<String> getDataFields() {
        lock.readLock().lock();
        try {
            if (data == null || data.size() == 0) {
                return null;
            }
            return data.keySet();
        } finally {
            lock.readLock().unlock();
        }
    }

    @Override
    public int getNodeCount() {
        return nodes;
    }

    @Override
    public void postDecode() {
        super.postDecode();
        atomicHits.set(hits);
        decoded.set(true);
    }

    
    private final class Iter implements ClosableIterator<DataTreeNode> {

        private Range<DBKey, ConcurrentTreeNode> range;
        private ConcurrentTreeNode next;
        private boolean filterDeleted;

        private Iter(Range<DBKey, ConcurrentTreeNode> range, boolean filterDeleted) {
            this.range = range;
            this.filterDeleted = filterDeleted;
            fetchNext();
        }

        public String toString() {
            return "Iter(" + range + "," + next + ")";
        }

        void fetchNext() {
            if (range != null) {
                next = null;
                while (range.hasNext()) {
                    Entry<DBKey, ConcurrentTreeNode> tne = range.next();
                    next = tree.getNode(ConcurrentTreeNode.this, tne.getKey().rawKey().toString(), false);
                    if (next != null) {
                        if (filterDeleted && next.isDeleted()) {
                            next = null;
                            continue;
                        }
                        break;
                    }
                }
            }
        }

        @Override
        public boolean hasNext() {
            return next != null;
        }

        @Override
        public ConcurrentTreeNode next() {
            if (!hasNext()) {
                throw new NoSuchElementException();
            }
            ConcurrentTreeNode ret = next;
            fetchNext();
            return ret;
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException();
        }

        @Override
        public void close() {
            if (range != null) {
                range.close();
                range = null;
            }
        }
    }

    @Override
    public void encodeLock() {
        lock.readLock().lock();
    }

    @Override
    public void encodeUnlock() {
        lock.readLock().unlock();
    }


    @Override
    public void writeLock() {
        lock.writeLock().lock();
    }

    @Override
    public void writeUnlock() {
        lock.writeLock().unlock();
    }

    @Override
    public Iterator<DataTreeNode> iterator() {
        return getNodeIterator();
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator() {
        return getNodeIterator();
    }

    @Override
    public ConcurrentTree getTreeRoot() {
        return tree;
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator(String begin) {
        return getNodeIterator(begin);
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator(String from, String to) {
        return getNodeIterator(from, to);
    }

    @Override
    public DataTreeNode getOrCreateNode(String name, DataTreeNodeInitializer init, TreeDataParent path) {
        return getOrCreateEditableNode(name, init, path);
    }

    

    @Override
    public long getCounter() {
        return atomicHits.get();
    }

    @Override
    public void incrementCounter() {
        atomicHits.incrementAndGet();
    }

    @Override
    public long incrementCounter(long val) {
        return atomicHits.addAndGet(val);
    }

    @Override
    public void setCounter(long val) {
        atomicHits.set(val);
    }
}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import javax.annotation.concurrent.GuardedBy;

import java.io.File;
import java.io.IOException;
import java.io.UnsupportedEncodingException;

import java.util.Arrays;
import java.util.Iterator;
import java.util.Map;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.function.BooleanSupplier;

import com.addthis.basis.concurrentlinkedhashmap.MediatedEvictionConcurrentHashMap;
import com.addthis.basis.util.LessBytes;
import com.addthis.basis.util.ClosableIterator;
import com.addthis.basis.util.LessFiles;
import com.addthis.basis.util.Meter;
import com.addthis.basis.util.Parameter;

import com.addthis.hydra.common.Configuration;
import com.addthis.hydra.data.tree.DataTree;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeActor;
import com.addthis.hydra.data.tree.DataTreeNodeInitializer;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;
import com.addthis.hydra.data.tree.TreeDataParent;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.store.db.CloseOperation;
import com.addthis.hydra.store.db.DBKey;
import com.addthis.hydra.store.db.IPageDB;
import com.addthis.hydra.store.db.PageDB;
import com.addthis.hydra.store.kv.PagedKeyValueStore;
import com.addthis.hydra.store.skiplist.Page;
import com.addthis.hydra.store.skiplist.PageFactory;
import com.addthis.hydra.store.skiplist.SkipListCache;
import com.addthis.hydra.store.util.MeterFileLogger;
import com.addthis.hydra.store.util.MeterFileLogger.MeterDataSource;
import com.addthis.hydra.store.util.NamedThreadFactory;
import com.addthis.hydra.store.util.Raw;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.util.concurrent.AtomicDouble;

import com.yammer.metrics.Metrics;
import com.yammer.metrics.core.Gauge;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


public final class ConcurrentTree implements DataTree, MeterDataSource {
    static final Logger log = LoggerFactory.getLogger(ConcurrentTree.class);

    
    @Configuration.Parameter
    static final int defaultNumDeletionThreads = Parameter.intValue("hydra.tree.clean.threads", 1);

    
    @Configuration.Parameter
    static final int deletionThreadSleepMillis = Parameter.intValue("hydra.tree.clean.interval", 10);

    
    @Configuration.Parameter
    static final int deletionLogInterval = Parameter.intValue("hydra.tree.clean.logging", 100000);

    private static final AtomicInteger scopeGenerator = new AtomicInteger();

    private final String scope = "ConcurrentTree" + Integer.toString(scopeGenerator.getAndIncrement());

    public static enum METERTREE {
        CACHE_HIT, CACHE_MISS, NODE_PUT, NODE_CREATE, NODE_DELETE, SOURCE_MISS
    }

    static final String keyCacheGet = METERTREE.CACHE_HIT.toString();
    static final String keyCacheMiss = METERTREE.CACHE_MISS.toString();

    private final File root;
    private final File idFile;
    final IPageDB<DBKey, ConcurrentTreeNode> source;
    private final ConcurrentTreeNode treeRootNode;
    final ConcurrentTreeNode treeTrashNode;
    private final AtomicLong nextDBID;
    final AtomicBoolean closed = new AtomicBoolean(false);
    private final Meter<METERTREE> meter;
    private final MeterFileLogger logger;
    private final AtomicDouble cacheHitRate = new AtomicDouble(0.0);
    private final MediatedEvictionConcurrentHashMap<CacheKey, ConcurrentTreeNode> cache;
    private final ScheduledExecutorService deletionThreadPool;

    @GuardedBy("treeTrashNode")
    private IPageDB.Range<DBKey, ConcurrentTreeNode> trashIterator;

    @SuppressWarnings("unused")
    final Gauge<Integer> treeTrashNodeCount = Metrics.newGauge(SkipListCache.class,
            "treeTrashNodeCount", scope,
            new Gauge<Integer>() {
                @Override
                public Integer value() {
                    return treeTrashNode == null ? -1 : treeTrashNode.getNodeCount();
                }
            });

    @SuppressWarnings("unused")
    final Gauge<Long> treeTrashHitsCount = Metrics.newGauge(SkipListCache.class,
            "treeTrashHitsCount", scope,
            new Gauge<Long>() {
                @Override
                public Long value() {
                    return treeTrashNode == null ? -1 : treeTrashNode.getCounter();
                }
            });

    ConcurrentTree(File root, int numDeletionThreads, int cleanQSize, int maxCacheSize,
                   int maxPageSize, PageFactory factory) throws Exception {
        LessFiles.initDirectory(root);
        this.root = root;
        long start = System.currentTimeMillis();

        
        meter = new Meter<>(METERTREE.values());
        for (METERTREE m : METERTREE.values()) {
            meter.addCountMetric(m, m.toString());
        }

        
        if (TreeCommonParameters.meterLogging > 0) {
            logger = new MeterFileLogger(this, root, "tree-metrics",
                                         TreeCommonParameters.meterLogging, TreeCommonParameters.meterLogLines);
        } else {
            logger = null;
        }
        source = new PageDB.Builder<>(root, ConcurrentTreeNode.class, maxPageSize, maxCacheSize)
                .pageFactory(factory).build();
        source.setCacheMem(TreeCommonParameters.maxCacheMem);
        source.setPageMem(TreeCommonParameters.maxPageMem);
        source.setMemSampleInterval(TreeCommonParameters.memSample);
        
        cache = new MediatedEvictionConcurrentHashMap.
                Builder<CacheKey, ConcurrentTreeNode>().
                mediator(new CacheMediator(source)).
                maximumWeightedCapacity(cleanQSize).build();

        
        idFile = new File(root, "nextID");
        if (idFile.exists() && idFile.isFile() && idFile.length() > 0) {
            nextDBID = new AtomicLong(Long.parseLong(LessBytes.toString(LessFiles.read(idFile))));
        } else {
            nextDBID = new AtomicLong(1);
        }

        
        ConcurrentTreeNode dummyRoot = ConcurrentTreeNode.getTreeRoot(this);
        treeRootNode = (ConcurrentTreeNode) dummyRoot.getOrCreateEditableNode("root");
        treeTrashNode = (ConcurrentTreeNode) dummyRoot.getOrCreateEditableNode("trash");
        treeTrashNode.requireNodeDB();
        deletionThreadPool = Executors.newScheduledThreadPool(numDeletionThreads,
                new NamedThreadFactory(scope + "-deletion-", true));

        for (int i = 0; i < numDeletionThreads; i++) {
            deletionThreadPool.scheduleAtFixedRate(
                    new ConcurrentTreeDeletionTask(this, closed::get, LoggerFactory.getLogger(
                            ConcurrentTreeDeletionTask.class.getName() + ".Background")),
                    i, deletionThreadSleepMillis, TimeUnit.MILLISECONDS);
        }

        long openTime = System.currentTimeMillis() - start;
        log.info("dir={} root={} trash={} cache={} nextdb={} openms={}",
                 root, treeRootNode, treeTrashNode, TreeCommonParameters.cleanQMax, nextDBID, openTime);
    }

    public ConcurrentTree(File root) throws Exception {
        this(root, defaultNumDeletionThreads, TreeCommonParameters.cleanQMax,
             TreeCommonParameters.maxCacheSize, TreeCommonParameters.maxPageSize,
             Page.DefaultPageFactory.singleton);
    }

    public void meter(METERTREE meterval) {
        meter.inc(meterval);
    }

    
    @VisibleForTesting
    boolean setNextNodeDB(long id) {
        while (true) {
            long current = nextDBID.get();
            if (current > id) {
                return false;
            } else if (nextDBID.compareAndSet(current, id)) {
                return true;
            }
        }
    }

    long getNextNodeDB() {
        long nextValue = nextDBID.incrementAndGet();
        return nextValue;
    }

    private static boolean setLease(final ConcurrentTreeNode node, final boolean lease) {
        return (!lease || node.tryLease());
    }

    public ConcurrentTreeNode getNode(final ConcurrentTreeNode parent, final String child, final boolean lease) {
        long nodedb = parent.nodeDB();
        if (nodedb <= 0) {
            log.trace("[node.get] {} --> {} NOMAP --> null", parent, child);
            return null;
        }
        CacheKey key = new CacheKey(nodedb, child);

        

        while (true) {
            ConcurrentTreeNode node = cache.get(key);
            if (node != null) {
                if (node.isDeleted()) {
                    cache.remove(key, node);
                } else if (setLease(node, lease)) {
                    reportCacheHit();
                    return node; 
                }
            } else {
                DBKey dbkey = key.dbkey();
                reportCacheMiss();
                node = source.get(dbkey);

                if (node == null) {
                    meter.inc(METERTREE.SOURCE_MISS);
                    return null; 
                }

                if (node.isDeleted()) {
                    source.remove(dbkey);
                } else {
                    node.initIfDecoded(this, dbkey, key.name);

                    ConcurrentTreeNode prev = cache.putIfAbsent(key, node);
                    if (prev == null) {
                        node.reactivate();
                        if (setLease(node, lease)) {
                            return node; 
                        }
                    }
                }
            }
        }
    }

    public ConcurrentTreeNode getOrCreateNode(final ConcurrentTreeNode parent, final String child,
                                              final DataTreeNodeInitializer creator, final TreeDataParent path) {
        parent.requireNodeDB();
        CacheKey key = new CacheKey(parent.nodeDB(), child);
        ConcurrentTreeNode newNode = null;

        while (true) {
            ConcurrentTreeNode node = cache.get(key);
            if (node != null) {
                if (node.isDeleted()) {
                    cache.remove(key, node);
                } else if (setLease(node, true)) {
                    reportCacheHit();
                    return node;
                }
            } else {
                DBKey dbkey = key.dbkey();
                reportCacheMiss();
                node = source.get(dbkey);

                if (node != null) {
                    if (node.isDeleted()) {
                        source.remove(dbkey);
                    } else {
                        node.initIfDecoded(this, dbkey, key.name);
                        ConcurrentTreeNode prev = cache.putIfAbsent(key, node);
                        if (prev == null) {
                            node.reactivate();
                            if (setLease(node, true)) {
                                return node;
                            }
                        }
                    }
                } else { 
                    if (newNode == null) {
                        newNode = new ConcurrentTreeNode();
                        newNode.init(this, dbkey, key.name, path);
                        newNode.tryLease();
                        newNode.markChanged();
                        if (creator != null) {
                            creator.onNewNode(newNode);
                        }
                    }
                    node = newNode;
                    if (cache.putIfAbsent(key, node) == null) {
                        
                        source.put(dbkey, node);
                        parent.updateNodeCount(1);
                        return node;
                    }
                }
            }
        }
    }

    boolean deleteNode(final ConcurrentTreeNode parent, final String child) {
        log.trace("[node.delete] {} --> {}", parent, child);
        long nodedb = parent.nodeDB();
        if (nodedb <= 0) {
            log.debug("parent has no children on delete : {} --> {}", parent, child);
            return false;
        }
        CacheKey key = new CacheKey(nodedb, child);
        
        ConcurrentTreeNode node = getNode(parent, child, true);
        if (node != null) {
            
            source.remove(key.dbkey());
            
            
            
            
            if (node.markDeleted()) {
                
                
                cache.remove(key, node);
                parent.updateNodeCount(-1);
                if (node.hasNodes() && !node.isAlias()) {
                    markForChildDeletion(node);
                }
                return true;
            }
        }
        return false;
    }

    private void markForChildDeletion(final ConcurrentTreeNode node) {
        
        assert node.hasNodes();
        assert !node.isAlias();
        long nodeDB = treeTrashNode.nodeDB();
        int next = treeTrashNode.incrementNodeCount();
        DBKey key = new DBKey(nodeDB, Raw.get(LessBytes.toBytes(next)));
        source.put(key, node);
        log.trace("[trash.mark] {} --> {}", next, treeTrashNode);
    }

    @SuppressWarnings("unchecked") IPageDB.Range<DBKey, ConcurrentTreeNode> fetchNodeRange(long db) {
        return source.range(new DBKey(db), new DBKey(db + 1));
    }

    @SuppressWarnings({"unchecked", "unused"}) private IPageDB.Range<DBKey, ConcurrentTreeNode> fetchNodeRange(long db, String from) {
        return source.range(new DBKey(db, Raw.get(from)), new DBKey(db + 1));
    }

    @SuppressWarnings("unchecked") IPageDB.Range<DBKey, ConcurrentTreeNode> fetchNodeRange(long db, String from, String to) {
        return source.range(new DBKey(db, Raw.get(from)),
                to == null ? new DBKey(db+1, (Raw)null) : new DBKey(db, Raw.get(to)));
    }

    @Override public ConcurrentTreeNode getRootNode() {
        return treeRootNode;
    }

    
    @VisibleForTesting
    void waitOnDeletions() {
        shutdownDeletionThreadPool();
        synchronized (treeTrashNode) {
            if (trashIterator != null) {
                trashIterator.close();
                trashIterator = null;
            }
        }
    }

    
    @VisibleForTesting
    ConcurrentMap<CacheKey, ConcurrentTreeNode> getCache() {
        return cache;
    }

    private void shutdownDeletionThreadPool() {
        if (deletionThreadPool == null)
            return;

        deletionThreadPool.shutdown();

        try {
            if (!deletionThreadPool.awaitTermination(10, TimeUnit.SECONDS)) {
                log.warn("Waiting on outstanding node deletions to complete.");
                deletionThreadPool.awaitTermination(Long.MAX_VALUE, TimeUnit.SECONDS);
            }
        } catch (InterruptedException ignored) {
        }
    }


    
    @Override
    public void foregroundNodeDeletion(BooleanSupplier terminationCondition) {
        ConcurrentTreeDeletionTask deletionTask = new ConcurrentTreeDeletionTask(this, terminationCondition, log);
        deletionTask.run();
    }

    @Override
    public void sync() throws IOException {
        log.debug("[sync] start");
        for (ConcurrentTreeNode node : cache.values()) {
            if (!node.isDeleted() && node.isChanged()) {
                source.put(node.dbkey, node);
            }
        }
        log.debug("[sync] end nextdb={}", nextDBID);
        LessFiles.write(idFile, LessBytes.toBytes(nextDBID.toString()), false);
    }

    @Override
    public long getDBCount() {
        return nextDBID.get();
    }

    @Override
    public int getCacheSize() {
        return cache.size();
    }

    @Override
    public double getCacheHitRate() {
        if (logger == null) {
            getIntervalData();
        }
        return cacheHitRate.get();
    }

    
    @Override
    public void close(boolean cleanLog, CloseOperation operation) throws IOException {
        if (!closed.compareAndSet(false, true)) {
            log.trace("already closed");
            return;
        }
        log.debug("closing {}", this);
        waitOnDeletions();
        if (treeRootNode != null) {
            treeRootNode.markChanged();
            treeRootNode.release();
            if (treeRootNode.getLeaseCount() != 0) {
                throw new IllegalStateException("invalid root state on shutdown : " + treeRootNode);
            }
        }
        if (treeTrashNode != null) {
            treeTrashNode.markChanged();
            treeTrashNode.release();
        }
        sync();
        if (source != null) {
            int status = source.close(cleanLog, operation);
            if (status != 0) {
                throw new RuntimeException("page db close returned a non-zero exit code : " + status);
            }
        }
        if (logger != null) {
            logger.terminate();
        }
    }


    @Override
    public void close() throws IOException {
        close(false, CloseOperation.NONE);
    }

    @Override
    public Map<String, Long> getIntervalData() {
        Map<String, Long> mark = meter.mark();
        Long gets = mark.get(keyCacheGet);
        Long miss = mark.get(keyCacheMiss);
        if (gets == null || miss == null || miss == 0) {
            cacheHitRate.set(0);
        } else {
            cacheHitRate.set(1.0d - ((miss * 1.0d) / ((gets + miss) * 1.0d)));
        }
        return mark;
    }

    private void reportCacheHit() {
        meter.inc(METERTREE.CACHE_HIT);
    }

    private void reportCacheMiss() {
        meter.inc(METERTREE.CACHE_MISS);
    }

    @Override
    public String toString() {
        return "Tree@" + root;
    }

    @Override
    public DataTreeNode getLeasedNode(String name) {
        return getRootNode().getLeasedNode(name);
    }

    @Override
    public DataTreeNode getOrCreateNode(String name, DataTreeNodeInitializer init, TreeDataParent path) {
        return getRootNode().getOrCreateNode(name, init, path);
    }

    @Override
    public boolean deleteNode(String node) {
        return getRootNode().deleteNode(node);
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator() {
        ConcurrentTreeNode rootNode = getRootNode();
        if (rootNode != null) {
            return getRootNode().getIterator();
        }
        return null;
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator(String begin) {
        return getRootNode().getIterator(begin);
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator(String from, String to) {
        return getRootNode().getIterator(from, to);
    }

    @Override
    public Iterator<DataTreeNode> iterator() {
        return getRootNode().iterator();
    }

    @Override
    public String getName() {
        return getRootNode().getName();
    }

    @Override
    public int getNodeCount() {
        return getRootNode().getNodeCount();
    }

    @Override
    public long getCounter() {
        return getRootNode().getCounter();
    }

    @Override
    public void incrementCounter() {
        getRootNode().incrementCounter();
    }

    @Override
    public long incrementCounter(long val) {
        return getRootNode().incrementCounter(val);
    }

    @Override
    public void writeLock() {
        getRootNode().writeLock();
    }

    @Override
    public void writeUnlock() {
        getRootNode().writeUnlock();
    }

    @Override
    public void setCounter(long val) {
        getRootNode().setCounter(val);
    }

    @Override
    public void updateChildData(DataTreeNodeUpdater state, TreeDataParent path) {
        getRootNode().updateChildData(state, path);
    }

    @Override
    public void updateParentData(DataTreeNodeUpdater state, DataTreeNode child, boolean isnew) {
        getRootNode().updateParentData(state, child, isnew);
    }

    @Override
    public boolean aliasTo(DataTreeNode target) {
        throw new RuntimeException("root node cannot be an alias");
    }

    @Override
    public void release() {
        getRootNode().release();
    }

    @Override
    public DataTreeNodeActor getData(String key) {
        return getRootNode().getData(key);
    }

    @Override
    public Map<String, TreeNodeData> getDataMap() {
        return getRootNode().getDataMap();
    }

    private static String keyName(DBKey dbkey) {
        try {
            return new String(dbkey.key(), "UTF-8");
        } catch (UnsupportedEncodingException ex) {
            log.warn("Could not decode the following dbkey bytes into a string: " +
                     Arrays.toString(dbkey.key()));
            return null;
        }
    }

    
    long deleteSubTree(ConcurrentTreeNode rootNode,
                       long counter,
                       BooleanSupplier terminationCondition,
                       Logger deletionLogger) {
        long nodeDB = rootNode.nodeDB();
        IPageDB.Range<DBKey, ConcurrentTreeNode> range = fetchNodeRange(nodeDB);
        DBKey endRange;
        boolean reschedule;
        try {
            while (range.hasNext() && !terminationCondition.getAsBoolean()) {
                if ((++counter % deletionLogInterval) == 0) {
                    deletionLogger.info("Deleted {} nodes from the tree.", counter);
                }
                Map.Entry<DBKey, ConcurrentTreeNode> entry = range.next();
                ConcurrentTreeNode next = entry.getValue();

                if (next.hasNodes() && !next.isAlias()) {
                    counter = deleteSubTree(next, counter, terminationCondition, deletionLogger);
                }
                String name = entry.getKey().rawKey().toString();
                CacheKey key = new CacheKey(nodeDB, name);
                ConcurrentTreeNode cacheNode = cache.remove(key);
                
                if (cacheNode != null) {
                    cacheNode.markDeleted();
                }
            }
            if (range.hasNext()) {
                endRange = range.next().getKey();
                reschedule = true;
            } else {
                endRange = new DBKey(nodeDB + 1);
                reschedule = false;
            }
        } finally {
            range.close();
        }
        source.remove(new DBKey(nodeDB), endRange);
        if (reschedule) {
            markForChildDeletion(rootNode);
        }
        return counter;
    }

    Map.Entry<DBKey, ConcurrentTreeNode> nextTrashNode() {
        synchronized (treeTrashNode) {
            if (trashIterator == null) {
                return recreateTrashIterator();
            } else if (trashIterator.hasNext()) {
                return trashIterator.next();
            } else {
                return recreateTrashIterator();
            }
        }
    }

    @GuardedBy("treeTrashNode")
    private Map.Entry<DBKey, ConcurrentTreeNode> recreateTrashIterator() {
        if (trashIterator != null) {
            trashIterator.close();
        }
        trashIterator = fetchNodeRange(treeTrashNode.nodeDB());
        if (trashIterator.hasNext()) {
            return trashIterator.next();
        } else {
            trashIterator.close();
            trashIterator = null;
            return null;
        }
    }

    
    @VisibleForTesting
    ConcurrentTreeNode getTreeTrashNode() {
        return treeTrashNode;
    }

    public void repairIntegrity() {
        PagedKeyValueStore store = source.getEps();
        if (store instanceof SkipListCache) {
            ((SkipListCache) store).testIntegrity(true);
        }
    }

}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import java.io.File;
import java.io.IOException;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Random;
import java.util.concurrent.CyclicBarrier;

import com.addthis.basis.test.SlowTest;
import com.addthis.basis.util.ClosableIterator;
import com.addthis.basis.util.LessFiles;

import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.store.db.CloseOperation;

import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

public class TestConcurrentTree {

    private static final Logger log = LoggerFactory.getLogger(TestConcurrentTree.class);

    private static final CloseOperation close = CloseOperation.TEST;

    static final int fastNumElements = 10000;
    static final int fastNumThreads = 8;

    static final int slowNumElements = 100000;
    static final int slowNumThreads = 8;

    private File makeTemporaryDirectory() throws IOException {
        final File temp;

        temp = File.createTempFile("temp", Long.toString(System.nanoTime()));

        if (!(temp.delete())) {
            throw new IOException("Could not delete temp file: " + temp.getAbsolutePath());
        }

        if (!(temp.mkdir())) {
            throw new IOException("Could not create temp directory: " + temp.getAbsolutePath());
        }

        return temp;
    }

    static final class InsertionThread extends Thread {

        final CyclicBarrier barrier;
        final List<Integer> values;
        final List<Integer> threadId;
        final int myId;
        final ConcurrentTree cache;
        final ConcurrentTreeNode parent;
        int counter;

        public InsertionThread(CyclicBarrier barrier, List<Integer> values,
                List<Integer> threadId, int id, ConcurrentTree cache,
                ConcurrentTreeNode parent) {
            super("InsertionThread" + id);
            this.barrier = barrier;
            this.values = values;
            this.threadId = threadId;
            this.myId = id;
            this.cache = cache;
            this.counter = 0;
            this.parent = parent;
        }

        @Override
        public void run() {
            try {
                barrier.await();
                int len = threadId.size();
                for (int i = 0; i < len; i++) {
                    if (threadId.get(i) == myId) {
                        Integer val = values.get(i);
                        ConcurrentTreeNode node = cache.getOrCreateNode(parent,
                                Integer.toString(val), null, null);
                        node.release();
                        counter++;
                    }
                }
            } catch (Exception e) {
                e.printStackTrace();
                fail();
            }
        }

    }

    static final class DeletionThread extends Thread {

        final CyclicBarrier barrier;
        final List<Integer> values;
        final List<Integer> threadId;
        final int myId;
        final ConcurrentTree cache;
        final ConcurrentTreeNode parent;
        int counter;

        public DeletionThread(CyclicBarrier barrier, List<Integer> values,
                List<Integer> threadId, int id, ConcurrentTree cache,
                ConcurrentTreeNode parent) {
            super("DeletionThread" + id);
            this.barrier = barrier;
            this.values = values;
            this.threadId = threadId;
            this.myId = id;
            this.cache = cache;
            this.counter = 0;
            this.parent = parent;
        }

        @Override
        public void run() {
            try {
                barrier.await();
                int len = threadId.size();
                for (int i = 0; i < len; i++) {
                    if (threadId.get(i) == myId) {
                        Integer val = values.get(i);
                        cache.deleteNode(parent, Integer.toString(val));
                        counter++;
                    }
                }
            } catch (Exception e) {
                e.printStackTrace();
                fail();
            }
        }
    }

    @Test
    @Category(SlowTest.class)
    public void getOrCreateOneThreadIterations() throws Exception {
        for(int i = 0; i < 100; i++) {
            getOrCreateOneThread();
        }
    }

    @Test
    public void getOrCreateOneThread() throws Exception {
        log.info("getOrCreateOneThread");
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).build();
            ConcurrentTreeNode root = tree.getRootNode();
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null, null);
                assertNotNull(node);
                assertEquals(Integer.toString(i), node.getName());
                node.release();
            }
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                node.release();
            }
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void recursiveDeleteOneThread() throws Exception {
        log.info("recursiveDeleteOneThread");
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).build();
            ConcurrentTreeNode root = tree.getRootNode();
            ConcurrentTreeNode parent = tree.getOrCreateNode(root, "hello", null, null);
            for (int i = 0; i < (TreeCommonParameters.cleanQMax << 1); i++) {
                ConcurrentTreeNode child = tree.getOrCreateNode(parent, Integer.toString(i), null, null);
                assertNotNull(child);
                assertEquals(Integer.toString(i), child.getName());
                parent.release();
                parent = child;
            }
            parent.release();

            assertEquals(1, root.getNodeCount());
            assertEquals(TreeCommonParameters.cleanQMax, tree.getCache().size());

            tree.deleteNode(root, "hello");
            tree = waitForDeletion(tree, dir);
            assertEquals(2, tree.getCache().size());
            assertEquals(0, root.getNodeCount());
            assertTrue(tree.getTreeTrashNode().getCounter() >= 1);
            assertEquals(tree.getTreeTrashNode().getCounter(), tree.getTreeTrashNode().getNodeCount());
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void recursiveDeleteMultiThreads() throws Exception {
        log.info("recursiveDeleteMultiThreads");
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).
                    numDeletionThreads(8).build();
            ConcurrentTreeNode root = tree.getRootNode();
            for (int i = 0; i < fastNumThreads; i++) {
                ConcurrentTreeNode parent = tree.getOrCreateNode(root, Integer.toString(i), null, null);
                for (int j = 0; j < TreeCommonParameters.cleanQMax; j++) {
                    ConcurrentTreeNode child = tree.getOrCreateNode(parent, Integer.toString(j), null, null);
                    assertNotNull(child);
                    assertEquals(Integer.toString(j), child.getName());
                    parent.release();
                    parent = child;
                }
                parent.release();
            }

            assertEquals(TreeCommonParameters.cleanQMax, tree.getCache().size());

            assertEquals(fastNumThreads, root.getNodeCount());

            for (int i = 0; i < fastNumThreads; i++) {
                tree.deleteNode(root, Integer.toString(i));
            }

            tree = waitForDeletion(tree, dir);
            assertEquals(2, tree.getCache().size());
            assertEquals(0, root.getNodeCount());

            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void getOrCreateFast() throws Exception {
        getOrCreateMultiThread(fastNumElements, fastNumThreads);
    }

    @Test
    @Category(SlowTest.class)
    public void getOrCreateSlow() throws Exception {
        getOrCreateMultiThread(slowNumElements, slowNumThreads);
    }

    private void getOrCreateMultiThread(int numElements, int numThreads) throws Exception {
        log.info("getOrCreateMultiThread");
        File dir = makeTemporaryDirectory();
        try {
            ArrayList<Integer> values = new ArrayList<>(numElements);
            final CyclicBarrier barrier = new CyclicBarrier(numThreads);
            ArrayList<Integer> threadId = new ArrayList<>(numElements);
            InsertionThread[] threads = new InsertionThread[numThreads];
            ConcurrentTree tree = new Builder(dir).build();
            ConcurrentTreeNode root = tree.getRootNode();

            for (int i = 0; i < numElements; i++) {
                values.add(i);
                threadId.add(i % numThreads);
            }

            for (int i = 0; i < numThreads; i++) {
                threads[i] = new InsertionThread(barrier, values, threadId, i, tree, root);
            }

            Collections.shuffle(values);

            for (int i = 0; i < numThreads; i++) {
                threads[i].start();
            }

            for (int i = 0; i < numThreads; i++) {
                threads[i].join();
            }

            for (int i = 0; i < numThreads; i++) {
                assertEquals(numElements / numThreads, threads[i].counter);
            }

            for (int i = 0; i < numElements; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                node.release();
            }
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void deleteOneThreadForeground() throws Exception {
        log.info("deleteOneThreadForeground");
        deleteOneThread(0);
    }

    @Test
    public void deleteOneThreadBackground() throws Exception {
        log.info("deleteOneThreadBackground");
        deleteOneThread(fastNumThreads);
    }

    private void deleteOneThread(int numDeletionThreads) throws Exception {
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir)
                    .numDeletionThreads(numDeletionThreads).build();
            ConcurrentTreeNode root = tree.getRootNode();
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null, null);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null, null);
                child.release();
                node.release();
            }
            for (int i = 0; i < 1000; i++) {
                tree.deleteNode(root, Integer.toString(i));
            }
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), false);
                assertNull(node);
            }
            tree = waitForDeletion(tree, dir);
            assertTrue(tree.getTreeTrashNode().getCounter() >= 1000);
            assertEquals(tree.getTreeTrashNode().getCounter(), tree.getTreeTrashNode().getNodeCount());
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    
    private ConcurrentTree waitForDeletion(ConcurrentTree tree, File dir) throws Exception {
        tree.close();
        tree = new Builder(dir).numDeletionThreads(0).build();
        tree.foregroundNodeDeletion(() -> false);
        return tree;
    }

    @Test
    public void deleteFast() throws Exception {
        deleteMultiThread(fastNumElements, fastNumThreads, fastNumThreads);
        deleteMultiThread(fastNumElements, fastNumThreads, 0);
    }

    @Test
    @Category(SlowTest.class)
    public void deleteSlow1() throws Exception {
        deleteMultiThread(slowNumElements, slowNumThreads, slowNumThreads);
        deleteMultiThread(slowNumElements, slowNumThreads, 0);
    }

    @Test
    @Category(SlowTest.class)
    public void deleteSlow2() throws Exception {
        for(int i = 0 ; i < 100; i++) {
            deleteMultiThread(fastNumElements, fastNumThreads, fastNumThreads);
            deleteMultiThread(fastNumElements, fastNumThreads, 0);
        }
    }

    @Test
    @Category(SlowTest.class)
    public void iterateAndDeleteSlow() throws Exception {
        for(int i = 0; i < 100; i++) {
            iterateAndDelete(fastNumThreads, 1000);
        }
    }

    @Test
    public void iterateAndDeleteFast() throws Exception {
        iterateAndDelete(fastNumThreads, 1000);
    }

    private void iterateAndDelete(int numThreads, int numElements) throws Exception {
        log.info("iterateAndDelete {} {}", numThreads, numElements);
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).numDeletionThreads(numThreads).
                    maxPageSize(5).maxCacheSize(500).build();
            ConcurrentTreeNode root = tree.getRootNode();

            for (int i = 0; i < numElements; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null, null);
                assertNotNull(node);
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null, null);
                child.release();
                node.release();
            }

            Random rng = new Random();

            ClosableIterator<DataTreeNode> iterator = tree.getIterator();
            try {
                int counter = 0;
                while(iterator.hasNext()) {
                    DataTreeNode node = iterator.next();
                    if (rng.nextFloat() < 0.8) {
                        String name = node.getName();
                        tree.deleteNode(root, name);
                        counter++;
                    }
                }
                log.info("Deleted " + (((float) counter) / numElements * 100.0) + " % of nodes");
            } finally {
                iterator.close();
            }

            tree.close(false, close);

        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }

    }

    private void deleteMultiThread(int numElements, int numThreads, int numDeletionThreads) throws Exception {
        log.info("deleteMultiThread {} {} {}", numElements, numThreads, numDeletionThreads);
        File dir = makeTemporaryDirectory();
        try {
            ArrayList<Integer> values = new ArrayList<>(numElements);
            final CyclicBarrier barrier = new CyclicBarrier(numThreads);
            ArrayList<Integer> threadId = new ArrayList<>(numElements);
            DeletionThread[] threads = new DeletionThread[numThreads];
            ConcurrentTree tree = new Builder(dir)
                    .numDeletionThreads(numDeletionThreads).build();
            ConcurrentTreeNode root = tree.getRootNode();

            for (int i = 0; i < numElements; i++) {
                values.add(i);
                threadId.add(i % numThreads);
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null, null);
                assertNotNull(node);
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null, null);
                child.release();
                node.release();
            }

            for (int i = 0; i < numThreads; i++) {
                threads[i] = new DeletionThread(barrier, values, threadId, i, tree, root);
            }

            Collections.shuffle(values);

            for (int i = 0; i < numThreads; i++) {
                threads[i].start();
            }

            for (int i = 0; i < numThreads; i++) {
                threads[i].join();
            }

            for (int i = 0; i < numThreads; i++) {
                assertEquals(numElements / numThreads, threads[i].counter);
            }

            for (int i = 0; i < numElements; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNull(node);
            }
            tree = waitForDeletion(tree, dir);
            assertTrue(tree.getTreeTrashNode().getCounter() >= numElements);
            assertEquals(tree.getTreeTrashNode().getCounter(), tree.getTreeTrashNode().getNodeCount());
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void maximumNodeIdentifier() throws Exception {
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).build();
            ConcurrentTreeNode root = tree.getRootNode();
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null, null);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null, null);
                child.release();
                node.release();
            }
            assertTrue(tree.setNextNodeDB(Integer.MAX_VALUE));
            for (int i = 1000; i < 2000; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null, null);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null, null);
                child.release();
                node.release();
            }
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import java.io.File;
import java.io.IOException;

import java.util.Map;

import com.addthis.basis.util.LessFiles;

import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.tree.prop.DataTime;
import com.addthis.hydra.store.db.CloseOperation;
import com.addthis.hydra.store.skiplist.LegacyPage;
import com.addthis.hydra.store.skiplist.Page;

import org.junit.Test;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;

public class TestTreeSerializationVersions {

    private static final CloseOperation close = CloseOperation.TEST;

    private File makeTemporaryDirectory() throws IOException {
        final File temp;

        temp = File.createTempFile("temp", Long.toString(System.nanoTime()));

        if (!(temp.delete())) {
            throw new IOException("Could not delete temp file: " + temp.getAbsolutePath());
        }

        if (!(temp.mkdir())) {
            throw new IOException("Could not create temp directory: " + temp.getAbsolutePath());
        }

        return temp;
    }

    @Test
    public void legacyToSparseUpgradePath() throws Exception {
        File dir = makeTemporaryDirectory();
        try {
            int count = 1000;
            ConcurrentTree tree = new Builder(dir).
                    pageFactory(LegacyPage.LegacyPageFactory.singleton).build();
            ConcurrentTreeNode root = tree.getRootNode();
            
            for (int i = 0; i < count; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null, null);
                assertNotNull(node);
                assertEquals(Integer.toString(i), node.getName());
                DataTime attachment = new DataTime();
                attachment.setFirst(i);
                attachment.setLast(i + count);
                node.createMap(1).put("time", attachment);
                node.markChanged();
                node.release();
            }
            tree.close(false, close);
            tree = new Builder(dir).
                    pageFactory(Page.DefaultPageFactory.singleton).build();
            
            for (int i = 0; i < count; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                Map<String, TreeNodeData> attachments = node.getDataMap();
                assertNotNull(attachments);
                assertTrue(attachments.containsKey("time"));
                DataTime attachment = (DataTime) attachments.get("time");
                assertEquals(i, attachment.first());
                assertEquals(i + count, attachment.last());
                node.release();
            }
            tree.close(false, close);
            tree = new Builder(dir).
                    pageFactory(Page.DefaultPageFactory.singleton).build();
            
            for (int i = 0; i < count; i += 2) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull("i = " + i, node);
                assertEquals(Integer.toString(i), node.getName());
                node.setCounter(1);
                DataTime attachment = new DataTime();
                attachment.setFirst(2 * i);
                attachment.setLast(2 * i + count);
                node.createMap(1).put("time", attachment);
                node.markChanged();
                node.release();
            }
            tree.close(false, close);
            tree = new Builder(dir).
                    pageFactory(Page.DefaultPageFactory.singleton).build();
            
            for (int i = 0; i < count; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                Map<String, TreeNodeData> attachments = node.getDataMap();
                assertNotNull(attachments);
                assertTrue(attachments.containsKey("time"));
                DataTime attachment = (DataTime) attachments.get("time");
                if (i % 2 == 0) {
                    assertEquals(2 * i, attachment.first());
                    assertEquals(2 * i + count, attachment.last());
                } else {
                    assertEquals(i, attachment.first());
                    assertEquals(i + count, attachment.last());
                }
                node.release();
            }
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }


}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import java.io.File;

import java.util.Iterator;
import java.util.Map;

import com.addthis.basis.util.ClosableIterator;

import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.ReadTree;
import com.addthis.hydra.data.tree.ReadTreeNode;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.store.db.CloseOperation;

public class ConcurrentTreeConverter {

    public static void main(String[] args) throws Exception {
        int maxNodes = (args.length >= 3) ? Integer.parseInt(args[2]) : -1;
        new ConcurrentTreeConverter(new File(args[0]), new File(args[1]), maxNodes);
    }

    public ConcurrentTreeConverter(File readRoot, File writeRoot, int maxNodes) throws Exception {
        long mark = System.currentTimeMillis();
        ReadTree readTree = new ReadTree(readRoot);
        ConcurrentTree writeTree = new ConcurrentTree(writeRoot);
        long openTime = System.currentTimeMillis() - mark;
        long testTime = 0;
        try {
            mark += openTime;
            ReadTreeNode readNode = readTree.getRootNode();
            ConcurrentTreeNode writeNode = writeTree.getRootNode();
            explore(writeTree, writeNode, readNode, 0, maxNodes);
            testTime = System.currentTimeMillis() - mark;
        } catch (Exception ex) {
            ex.printStackTrace();
            throw ex;
        } finally {
            readTree.close();
            writeTree.close(true, CloseOperation.NONE);
        }
        System.out.println("nodeCount=" + nodeCount + " hasNodes=" + hasNodes + " maxLeafs=" +
                           maxLeafs + " maxDepth=" + maxDepth + " openTime=" + openTime + " testTime=" + testTime);
    }

    private int nodeCount;
    private int maxLeafs;
    private int hasNodes;
    private int maxDepth;

    private void generateNode(ConcurrentTree writeTree,
            ConcurrentTreeNode writeParent,
            ReadTreeNode readChild) {
        ConcurrentTreeNode writeNode = writeTree.getOrCreateNode(writeParent, readChild.getName(), null, null);
        writeNode.writeLock();
        if (readChild.hasNodes()) {
            writeNode.requireNodeDB();
        }
        writeNode.setCounter(readChild.getCounter());
        Map<String, TreeNodeData> readMap = readChild.getDataMap();
        if (readMap != null) {
            Map<String, TreeNodeData> writeMap = writeNode.createMap(readMap.size());
            for (Map.Entry<String, TreeNodeData> entry : readMap.entrySet()) {
                writeMap.put(entry.getKey(), entry.getValue());
            }
        }
        writeNode.markChanged();
        writeNode.writeUnlock();
        writeNode.release();
    }

    private void explore(ConcurrentTree writeTree,
            ConcurrentTreeNode writeNode,
            ReadTreeNode readNode, int depth,
            int maxNodes) throws Exception {
        int count = 0;
        if (maxNodes > 0 && nodeCount >= maxNodes) {
            return;
        }
        Iterator<DataTreeNode> iter = readNode.iterator();
        if (iter != null) {
            if (iter.hasNext()) {
                hasNodes++;
            }
            try {
                while (iter.hasNext()) {
                    count++;
                    ReadTreeNode readChild = (ReadTreeNode) iter.next();
                    generateNode(writeTree, writeNode, readChild);
                }
            } finally {
                if (iter instanceof ClosableIterator) {
                    ((ClosableIterator<DataTreeNode>) iter).close();
                }
            }
            iter = readNode.iterator();
            try {
                while (iter.hasNext()) {
                    ReadTreeNode readChild = (ReadTreeNode) iter.next();
                    ConcurrentTreeNode writeChild = writeTree.getNode(writeNode, readChild.getName(), false);
                    explore(writeTree, writeChild, readChild, depth + 1, maxNodes);
                }
            } finally {
                if (iter instanceof ClosableIterator) {
                    ((ClosableIterator<DataTreeNode>) iter).close();
                }
            }
        }
        maxLeafs = Math.max(count, maxLeafs);
        maxDepth = Math.max(depth, maxDepth);
        nodeCount++;
        if (nodeCount % 10000000 == 0) {
            System.out.println(".. nodeCount=" + nodeCount + " hasNodes=" + hasNodes + " maxLeafs=" + maxLeafs + " maxDepth=" + maxDepth);
        }
    }
}

<code block>

package com.addthis.hydra.task.output.tree;

import java.util.ArrayList;
import java.util.List;

import com.addthis.bundle.core.BundleField;
import com.addthis.bundle.util.ValueUtil;
import com.addthis.bundle.value.ValueFactory;
import com.addthis.bundle.value.ValueMap;
import com.addthis.bundle.value.ValueMapEntry;
import com.addthis.bundle.value.ValueObject;
import com.addthis.bundle.value.ValueString;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.hydra.data.filter.value.ValueFilter;
import com.addthis.hydra.data.tree.DataTreeNode;


public class PathValue extends PathElement {

    public PathValue() {
    }

    public PathValue(String value) {
        this.value = value;
    }

    public PathValue(String value, boolean count) {
        this.value = value;
        this.count = count;
    }

    
    @FieldConfig(codable = true)
    protected String value;

    @FieldConfig(codable = true)
    protected String set;

    @FieldConfig(codable = true)
    protected ValueFilter vfilter;

    @FieldConfig(codable = true)
    protected boolean sync;

    @FieldConfig(codable = true)
    protected boolean create = true;

    @FieldConfig(codable = true)
    protected boolean once;

    @FieldConfig(codable = true)
    protected String mapTo;

    
    @FieldConfig protected boolean delete;

    @FieldConfig(codable = true)
    protected boolean push;

    @FieldConfig(codable = true)
    protected PathElement each;

    
    @FieldConfig(codable = true)
    protected int maxNodes = 0;

    private ValueString valueString;
    private BundleField setField;
    private BundleField mapField;

    public final ValueObject value() {
        if (valueString == null) {
            valueString = ValueFactory.create(value);
        }
        return valueString;
    }

    
    public ValueObject getPathValue(final TreeMapState state) {
        return value();
    }

    public final ValueObject getFilteredValue(final TreeMapState state) {
        ValueObject value = getPathValue(state);
        if (vfilter != null) {
            value = vfilter.filter(value, state.getBundle());
        }
        return value;
    }

    @Override
    public void resolve(final TreeMapper mapper) {
        super.resolve(mapper);
        if (set != null) {
            setField = mapper.bindField(set);
        }
        if (mapTo != null) {
            mapField = mapper.bindField(mapTo);
        }
        if (each != null) {
            each.resolve(mapper);
        }
    }

    @Override
    public String toString() {
        return "PathValue[" + value + "]";
    }

    
    @Override
    public final List<DataTreeNode> getNextNodeList(final TreeMapState state) {
        ValueObject value = getFilteredValue(state);
        if (setField != null) {
            state.getBundle().setValue(setField, value);
        }
        if (ValueUtil.isEmpty(value)) {
            return op ? TreeMapState.empty() : null;
        }
        if (op) {
            return TreeMapState.empty();
        }
        List<DataTreeNode> list;
        if (sync) {
            synchronized (this) {
                list = processNodeUpdates(state, value);
            }
        } else {
            list = processNodeUpdates(state, value);
        }
        if (term) {
            if (list != null) {
                list.forEach(DataTreeNode::release);
            }
            return null;
        } else {
            return list;
        }
    }

    
    public DataTreeNode getOrCreateNode(TreeMapState state, String name) {
        if (create && ((maxNodes == 0) || (state.getNodeCount() < maxNodes))) {
            return state.getOrCreateNode(name, state);
        } else {
            return state.getLeasedNode(name);
        }
    }

    
    public List<DataTreeNode> processNodeUpdates(TreeMapState state, ValueObject name) {
        List<DataTreeNode> list = new ArrayList<>(1);
        int pushed = 0;
        if (name.getObjectType() == ValueObject.TYPE.ARRAY) {
            for (ValueObject o : name.asArray()) {
                if (o != null) {
                    pushed += processNodeByValue(list, state, o);
                }
            }
        } else if (name.getObjectType() == ValueObject.TYPE.MAP) {
            ValueMap nameAsMap = name.asMap();
            for (ValueMapEntry e : nameAsMap) {
                String key = e.getKey();
                if (mapTo != null) {
                    state.getBundle().setValue(mapField, e.getValue());
                    pushed += processNodeByValue(list, state, ValueFactory.create(key));
                } else {
                    PathValue mapValue = new PathValue(key, count);
                    List<DataTreeNode> tnl = mapValue.processNode(state);
                    if (tnl != null) {
                        state.push(tnl);
                        List<DataTreeNode> children = processNodeUpdates(state, e.getValue());
                        if (children != null) {
                            list.addAll(children);
                        }
                        state.pop().release();
                    }
                }
            }
        } else {
            pushed += processNodeByValue(list, state, name);
        }
        while (pushed-- > 0) {
            state.pop().release();
        }
        if (!list.isEmpty()) {
            return list;
        } else {
            return null;
        }
    }

    
    public final int processNodeByValue(List<DataTreeNode> list, TreeMapState state, ValueObject name) {
        if (each != null) {
            List<DataTreeNode> next = state.processPathElement(each);
            if (push) {
                if (next.size() > 1) {
                    throw new RuntimeException("push and each are incompatible for > 1 return nodes");
                }
                if (next.size() == 1) {
                    state.push(next.get(0));
                    return 1;
                }
            } else if (next != null) {
                list.addAll(next);
            }
            return 0;
        }
        DataTreeNode parent = state.current();
        String sv = ValueUtil.asNativeString(name);
        if (delete) {
            parent.deleteNode(sv);
        }
        
        DataTreeNode child = getOrCreateNode(state, sv);
        boolean isnew = state.getAndClearLastWasNew();
        
        if (child == null) {
            return 0;
        }
        
        if (once && !isnew) {
            child.release();
            return 0;
        }
        try {
            
            if (assignHits()) {
                state.setAssignmentValue(hitsField.getLong(state.getBundle()).orElse(0l));
            }
            child.updateChildData(state, this);
            
            parent.updateParentData(state, child, isnew);
            if (push) {
                state.push(child);
                return 1;
            } else {
                list.add(child);
                return 0;
            }
        } catch (Throwable t) {
            child.release();
            throw t;
        }
    }
}

<code block>

package com.addthis.hydra.task.output.tree;

import javax.annotation.Nullable;

import java.util.ArrayList;
import java.util.Collections;
import java.util.LinkedList;
import java.util.List;

import com.addthis.basis.util.LessStrings;

import com.addthis.bundle.core.Bundle;
import com.addthis.bundle.core.BundleFactory;
import com.addthis.bundle.core.BundleFormat;
import com.addthis.bundle.core.BundleFormatted;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeInitializer;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
@SuppressWarnings("serial")
public final class TreeMapState implements DataTreeNodeUpdater, DataTreeNodeInitializer, BundleFactory, BundleFormatted {

    private static final Logger log = LoggerFactory.getLogger(TreeMapState.class);
    private static final int debug = Integer.parseInt(System.getProperty("hydra.process.debug", "0"));
    private static final boolean debugthread = System.getProperty("hydra.process.debugthread", "0").equals("1");
    
    private static final List<DataTreeNode> empty = Collections.unmodifiableList(new ArrayList<>());

    static {
        if (debugthread) {
            log.warn("ENABLED debugthread");
        }
    }

    
    public TreeMapState(Bundle p) {
        this.bundle = p;
        this.path = null;
        this.processor = null;
        this.stack = null;
        this.thread = null;
        this.profiling = false;
    }

    
    public TreeMapState(TreeMapper processor, DataTreeNode rootNode, PathElement[] path, Bundle bundle) {
        this.path = path;
        this.bundle = bundle;
        this.processor = processor;
        this.countValue = 1;
        this.stack = new LinkedList<>();
        this.thread = Thread.currentThread();
        this.profiling = processor != null ? processor.isProfiling() : false;
        push(rootNode);
    }

    private final LinkedList<DataTreeNode> stack;
    private final TreeMapper processor;
    private final PathElement[] path;
    private final Bundle bundle;
    private final Thread thread;
    private final boolean profiling;

    private boolean lastWasNew;
    private int touched;
    private int countValue;
    private long assignmentValue;

    private void checkThread() {
        if (Thread.currentThread() != thread) {
            throw new RuntimeException("invalid accessing thread " + Thread.currentThread() + " != " + thread);
        }
    }

    public static List<DataTreeNode> empty() {
        return empty;
    }

    @Override
    public int getCountValue() {
        return countValue;
    }

    public void setCountValue(int v) {
        countValue = v;
    }

    @Override
    public long getAssignmentValue() {
        return assignmentValue;
    }

    public TreeMapState setAssignmentValue(long assignmentValue) {
        this.assignmentValue = assignmentValue;
        return this;
    }

    public boolean getAndClearLastWasNew() {
        boolean ret = lastWasNew;
        lastWasNew = false;
        return ret;
    }

    public DataTreeNode getLeasedNode(String key) {
        DataTreeNode tn = current().getLeasedNode(key);
        return tn;
    }

    public DataTreeNode getOrCreateNode(String key, DataTreeNodeInitializer init) {
        DataTreeNode tn = current().getOrCreateNode(key, init);
        return tn;
    }

    public DataTreeNode pop() {
        if (debugthread) {
            checkThread();
        }
        return stack.pop();
    }

    public int getNodeCount() {
        return current().getNodeCount();
    }

    public void push(List<DataTreeNode> tnl) {
        if (tnl.size() == 1) {
            push(tnl.get(0));
        } else {
            throw new RuntimeException("unexpected response: " + tnl.size() + " -> " + tnl);
        }
    }

    public void push(DataTreeNode tn) {
        if (debugthread) {
            checkThread();
        }
        stack.push(tn);
    }

    
    public long getBundleTime() {
        throw new RuntimeException("fix me");
    }

    public void setBundleTime(long time) {
        throw new RuntimeException("fix me");
    }

    
    public DataTreeNode peek(int back) {
        return (stack.size() > back) ? stack.get(back) : null;
    }

    
    public DataTreeNode current() {
        return stack.peek();
    }

    @Override
    public Bundle getBundle() {
        return bundle;
    }

    
    public int touched() {
        return touched;
    }

    
    public void dispatchRule(TreeMapperPathReference t) {
        if ((t != null) && (bundle != null) && (processor != null)) {
            processor.processBundle(bundle, t);
        } else if (debug > 0) {
            log.warn("Proc Rule Dispatch DROP {} b/c p={} rp={}", t, bundle, processor);
        }
    }

    public void process() {
        List<DataTreeNode> list = processPath(path, 0);
        if ((debug > 0) && ((list == null) || list.isEmpty())) {
            log.warn("proc FAIL {}", list);
            log.warn(".... PATH {}", LessStrings.join(path, " 
            log.warn(".... PACK {}", bundle);
        }
        if (list != null) {
            list.forEach(DataTreeNode::release);
        }
    }

    
    public List<DataTreeNode> processPath(PathElement[] path) {
        return processPath(path, 0);
    }

    
    @Nullable private List<DataTreeNode> processPath(PathElement[] path, int index) {
        if ((path == null) || (path.length <= index)) {
            return null;
        }
        List<DataTreeNode> nodes = processPathElement(path[index]);
        if ((nodes != null) && nodes.isEmpty()) {
            
            if ((index + 1) < path.length) {
                return processPath(path, index + 1);
            }
            return null;
        } else if (nodes == null) {
            return null;
        } else if ((index + 1) < path.length) {
            List<DataTreeNode> childNodes = null;
            for (DataTreeNode tn : nodes) {
                push(tn);
                List<DataTreeNode> childNodesPartition = processPath(path, index + 1);
                if (childNodesPartition != null) {
                    if ((childNodes == null) || (childNodes == empty)) {
                        childNodes = childNodesPartition;
                    } else {
                        childNodes.addAll(childNodesPartition);
                    }
                }
                pop().release();
            }
            return childNodes;
        } else {
            return nodes;
        }
    }

    
    public List<DataTreeNode> processPathElement(PathElement pe) {
        if (profiling) {
            long mark = System.nanoTime();
            List<DataTreeNode> list = processPathElementProfiled(pe);
            processor.updateProfile(pe, System.nanoTime() - mark);
            return list;
        } else {
            return processPathElementProfiled(pe);
        }
    }

    private List<DataTreeNode> processPathElementProfiled(PathElement pe) {
        if (pe.disabled()) {
            return empty();
        }
        if (debugthread) {
            checkThread();
        }
        List<DataTreeNode> list = pe.processNode(this);
        if (list != null) {
            touched += list.size();
        }
        return list;
    }

    @Override
    public void onNewNode(DataTreeNode child) {
        lastWasNew = true;
    }

    @Override
    public Bundle createBundle() {
        return processor.createBundle();
    }

    @Override
    public BundleFormat getFormat() {
        return processor.getFormat();
    }

    public boolean processorClosing() { return processor.isClosing(); }
}

<code block>

package com.addthis.hydra.task.output.tree;

import com.addthis.basis.util.LessStrings;

import com.addthis.bundle.util.ValueUtil;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeInitializer;
import com.addthis.hydra.data.tree.DataTreeUtil;


public class PathAlias extends PathKeyValue {

    
    @FieldConfig(codable = true, required = true)
    protected PathValue[] path;

    
    @FieldConfig(codable = true)
    protected int relativeUp;

    
    @FieldConfig(codable = true)
    protected boolean peer;

    
    @FieldConfig(codable = true)
    protected boolean hard;

    
    @FieldConfig(codable = true)
    protected int debug;

    
    @FieldConfig(codable = true)
    private String debugKey;

    private int match;
    private int miss;

    public PathAlias() {
    }

    public PathAlias(PathValue[] path) {
        this.path = path;
    }

    @Override
    public void resolve(TreeMapper mapper) {
        super.resolve(mapper);
        for (PathValue pv : path) {
            pv.resolve(mapper);
        }
    }

    @Override
    public DataTreeNode getOrCreateNode(final TreeMapState state, final String name) {
        if (hard) {
            DataTreeNode node = state.getLeasedNode(name);
            if (node != null) {
                return node;
            }
        }
        String[] p = new String[path.length];
        for (int i = 0; i < p.length; i++) {
            p[i] = ValueUtil.asNativeString(path[i].getFilteredValue(state));
        }
        DataTreeNode alias = null;
        if (peer) {
            alias = DataTreeUtil.pathLocateFrom(state.current(), p);
        } else if (relativeUp > 0) {
            alias = DataTreeUtil.pathLocateFrom(state.peek(relativeUp), p);
        } else {
            alias = DataTreeUtil.pathLocateFrom(state.current().getTreeRoot(), p);
        }
        if (alias != null) {
            final DataTreeNode finalAlias = alias;
            DataTreeNodeInitializer init = new DataTreeNodeInitializer() {
                @Override
                public void onNewNode(DataTreeNode child) {
                    child.aliasTo(finalAlias);
                    state.onNewNode(child);
                }
            };
            if (debug > 0) {
                debug(true);
            }
            return state.getOrCreateNode(name, init);
        } else {
            if (debug > 0) {
                debug(false);
            }
            if (log.isDebugEnabled() || debug == 1) {
                log.warn("alias fail, missing " + LessStrings.join(p, " / "));
            }
            return null;
        }
    }

    protected synchronized void debug(boolean hit) {
        if (hit) {
            match++;
        } else {
            miss++;
        }
        if (match + miss >= debug) {
            log.warn("query[" + debugKey + "]: match=" + match + " miss=" + miss);
            match = 0;
            miss = 0;
        }
    }
}

<code block>

package com.addthis.hydra.data.tree;

import java.util.Map;

import com.addthis.basis.util.ClosableIterator;

import com.fasterxml.jackson.annotation.JsonAutoDetect;


@JsonAutoDetect(getterVisibility = JsonAutoDetect.Visibility.NONE,
                isGetterVisibility = JsonAutoDetect.Visibility.NONE,
                setterVisibility = JsonAutoDetect.Visibility.NONE)
public interface DataTreeNode extends Iterable<DataTreeNode> {

    
    public String getName();

    
    public DataTree getTreeRoot();

    
    public int getNodeCount();

    
    public long getCounter();

    
    public DataTreeNodeActor getData(String key);

    
    public DataTreeNode getNode(String name);

    
    public Map<String, TreeNodeData> getDataMap();

    
    public ClosableIterator<DataTreeNode> getIterator();

    
    public ClosableIterator<DataTreeNode> getIterator(String prefix);

    
    public ClosableIterator<DataTreeNode> getIterator(String from, String to);

    

    
    public default void incrementCounter() {
        throw new UnsupportedOperationException("incrementCounter");
    }

    
    public default long incrementCounter(long val) {
        throw new UnsupportedOperationException("incrementCounter");
    }

    
    public default void setCounter(long val) {
        throw new UnsupportedOperationException("setCounter");
    }

    
    public default void updateChildData(DataTreeNodeUpdater state, TreeDataParent path) {
        throw new UnsupportedOperationException("updateChildData");
    }

    
    public default void updateParentData(DataTreeNodeUpdater state, DataTreeNode child, boolean isnew) {
        throw new UnsupportedOperationException("updateParentData");
    }

    
    public default boolean aliasTo(DataTreeNode target) {
        throw new UnsupportedOperationException("aliasTo");
    }

    
    public default boolean deleteNode(String node) {
        throw new UnsupportedOperationException("deleteNode");
    }

    

    
    public default DataTreeNode getOrCreateNode(String name, DataTreeNodeInitializer init) {
        throw new UnsupportedOperationException("getOrCreateNode");
    }

    
    public default DataTreeNode getLeasedNode(String name) {
        throw new UnsupportedOperationException("getLeasedNode");
    }

    
    public default void release() {
        throw new UnsupportedOperationException("release");
    }

    public default void writeLock() {
        throw new UnsupportedOperationException("writeLock");
    }

    public default void writeUnlock() {
        throw new UnsupportedOperationException("writeUnlock");
    }
}

<code block>

package com.addthis.hydra.data.tree.prop;

import java.util.HashMap;
import java.util.NoSuchElementException;

import com.addthis.basis.util.ClosableIterator;

import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.tree.concurrent.ConcurrentTreeNode;
import com.addthis.hydra.data.tree.DataTreeNode;


public final class VirtualTreeNode extends ConcurrentTreeNode {

    public VirtualTreeNode(final String name, final long hits) {
        this(name, hits, null);
    }

    public VirtualTreeNode(final String name, final long hits, final VirtualTreeNode[] children) {
        this.name = name;
        this.hits = hits;
        this.nodes = children != null ? children.length : 0;
        this.children = children;
    }

    private final VirtualTreeNode[] children;

    @Override
    public ClosableIterator<DataTreeNode> getNodeIterator() {
        return new VirtualTreeNodeIterator();
    }

    @Override
    public ClosableIterator<DataTreeNode> getNodeIterator(String prefix) {
        VirtualTreeNodeIterator iter = new VirtualTreeNodeIterator();
        while (true) {
            VirtualTreeNode peek = iter.peek();
            if ((peek == null) || peek.name.startsWith(prefix)) {
                break;
            }
            iter.next();
        }
        return iter;
    }

    @Override
    public ClosableIterator<DataTreeNode> getNodeIterator(String from, String to) {
        VirtualTreeNodeIterator iter = new VirtualTreeNodeIterator();
        iter.end = to;
        while (true) {
            VirtualTreeNode peek = iter.peek();
            if (peek == null || (peek.name.compareTo(from) >= 0) && (to == null || peek.name.compareTo(to) <= 0)) {
                break;
            }
            iter.next();
        }
        return iter;
    }

    @Override
    public ConcurrentTreeNode getNode(String name) {
        if (children == null || children.length == 0) {
            return null;
        }
        for (VirtualTreeNode vtn : children) {
            if (vtn.name.equals(name)) {
                return vtn;
            }
        }
        return null;
    }

    
    @Override
    public HashMap<String, TreeNodeData> createMap() {
        return super.createMap();
    }

    private class VirtualTreeNodeIterator implements ClosableIterator<DataTreeNode> {

        int pos;
        String end;

        VirtualTreeNode peek() {
            return children != null && pos < children.length ? children[pos] : null;
        }

        @Override
        public void close() {
        }

        @Override
        public boolean hasNext() {
            if (children != null && pos < children.length) {
                if (end != null) {
                    return children[pos].name.compareTo(end) < 0;
                }
                return true;
            }
            return false;
        }

        @Override
        public VirtualTreeNode next() {
            if (!hasNext()) {
                throw new NoSuchElementException();
            }
            return children[pos++];
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException();
        }
    }
}

<code block>

package com.addthis.hydra.data.tree.prop;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import com.addthis.basis.util.LessStrings;
import com.addthis.basis.util.Varint;

import com.addthis.bundle.util.AutoField;
import com.addthis.bundle.value.ValueFactory;
import com.addthis.bundle.value.ValueObject;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.codec.codables.Codable;
import com.addthis.hydra.data.filter.value.ValueFilter;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;
import com.addthis.hydra.data.tree.ReadTreeNode;
import com.addthis.hydra.data.tree.TreeDataParameters;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.util.KeyTopper;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.PooledByteBufAllocator;
import io.netty.buffer.Unpooled;

public class DataKeyTop extends TreeNodeData<DataKeyTop.Config> implements Codable {

    
    public static final class Config extends TreeDataParameters<DataKeyTop> {

        
        @FieldConfig(codable = true, required = true)
        private AutoField key;

        
        @FieldConfig(codable = true)
        private AutoField weight;

        
        @FieldConfig(codable = true, required = true)
        private int size;

        
        @FieldConfig(codable = true)
        private boolean errors;

        
        @FieldConfig(codable = true)
        private String splitRegex;

        
        @FieldConfig(codable = true)
        private ValueFilter filter;

        @Override
        public DataKeyTop newInstance() {
            DataKeyTop dataKeyTop = new DataKeyTop();
            dataKeyTop.size = size;
            dataKeyTop.top = new KeyTopper().init().setLossy(true).enableErrors(errors);
            dataKeyTop.filter = filter;
            return dataKeyTop;
        }
    }

    @FieldConfig(codable = true, required = true)
    private KeyTopper top;
    @FieldConfig(codable = true, required = true)
    private int size;

    private ValueFilter filter;
    private AutoField keyAccess;
    private AutoField weightAccess;

    @Override
    public boolean updateChildData(DataTreeNodeUpdater state, DataTreeNode childNode, DataKeyTop.Config conf) {
        if (keyAccess == null) {
            keyAccess = conf.key;
            weightAccess = conf.weight;
            filter = conf.filter;
        }
        ValueObject val = keyAccess.getValue(state.getBundle());
        if (val != null) {
            if (filter != null) {
                val = filter.filter(val, state.getBundle());
                if (val == null) {
                    return false;
                }
            }
            int weight = 1;
            if (weightAccess != null) {
                weight = weightAccess.getValue(state.getBundle()).asLong().asNative().intValue();
            }
            if (conf.splitRegex != null) {
                String[] split = val.toString().split(conf.splitRegex);
                for (int i = 0; i < split.length; i++) {
                    top.increment(split[i], weight, size);
                }
            } else {
                if (val.getObjectType() == ValueObject.TYPE.ARRAY) {
                    for (ValueObject obj : val.asArray()) {
                        top.increment(obj.toString(), weight, size);
                    }
                } else {
                    top.increment(val.toString(), weight, size);
                }
            }
            return true;
        } else {
            return false;
        }
    }

    @Override
    public ValueObject getValue(String key) {
        if (key != null && key.length() > 0) {
            if (key.equals("size")) {
                return ValueFactory.create(top.size());
            }
            try {
                if (key.charAt(0) == 'g') {
                    String topKey = key.substring(1);
                    Long val = top.get(topKey);
                    return ValueFactory.create(val != null ? val : 0);
                }
                if (key.charAt(0) == 'v') {
                    int pos = Integer.parseInt(key.substring(1));
                    return pos <= top.size() ? ValueFactory.create(top.getSortedEntries()[pos - 1].getValue()) : null;
                }
                if (key.charAt(0) == 'e') {
                    if (top.hasErrors()) {
                        int pos = Integer.parseInt(key.substring(1));
                        if (pos <= top.size()) {
                            String element = top.getSortedEntries()[pos - 1].getKey();
                            Long error = top.getError(element);
                            return ValueFactory.create(error);
                        }
                    }
                    return null;
                }
                if (key.charAt(0) == 'k') {
                    key = key.substring(1);
                }
                int pos = Integer.parseInt(key);
                return pos <= top.size() ? ValueFactory.create(top.getSortedEntries()[pos - 1].getKey()) : null;
            } catch (Exception e) {
                return ValueFactory.create(e.toString());
            }
        }
        return ValueFactory.create(top.toString());
    }

    
    @Override public List<String> getNodeTypes() {
        return Arrays.asList(new String[]{"#"});
    }

    @Override
    public List<DataTreeNode> getNodes(DataTreeNode parent, String key) {
        if (key != null && key.startsWith("=")) {
            key = key.substring(1);
            if (key.equals("hit") || key.equals("node")) {
                Entry<String, Long>[] list = top.getSortedEntries();
                ArrayList<DataTreeNode> ret = new ArrayList<>(list.length);
                for (Entry<String, Long> e : list) {
                    DataTreeNode node = parent.getNode(e.getKey());
                    if (node != null) {
                        ret.add(node);
                    }
                }
                return ret;
            } else if (key.equals("vhit")) {
                Entry<String, Long>[] list = top.getSortedEntries();
                ArrayList<DataTreeNode> ret = new ArrayList<>(list.length);
                for (Entry<String, Long> e : list) {
                    ret.add(new VirtualTreeNode(e.getKey(), e.getValue()));
                }
                return ret;
            } else if (key.equals("phit")) {
                Entry<String, Long>[] list = top.getSortedEntries();
                ArrayList<DataTreeNode> ret = new ArrayList<>(list.length);
                for (Entry<String, Long> e : list) {
                    DataTreeNode node = parent.getNode(e.getKey());
                    if (node != null) {
                        node = ((ReadTreeNode) node).getCloneWithCount(e.getValue());
                        ret.add(node);
                    }
                }
                return ret;
            } else if (key.equals("guaranteed")) {
                return generateVirtualNodes(true);
            }
        } else if (key != null) {
            String[] keys = LessStrings.splitArray(key, ":");
            ArrayList<DataTreeNode> list = new ArrayList<>(keys.length);
            for (String k : keys) {
                Long v = top.get(k);
                if (v != null) {
                    list.add(new VirtualTreeNode(k, v));
                }
            }
            return list.size() > 0 ? list : null;
        }
        return generateVirtualNodes(false);
    }

    
    private List<DataTreeNode> generateVirtualNodes(boolean onlyGuaranteed) {
        ArrayList<DataTreeNode> list = new ArrayList<>(top.size());
        Entry<String, Long>[] entries = top.getSortedEntries();
        for (int i = 0; i < entries.length; i++) {
            Entry<String,Long> entry = entries[i];
            String name = entry.getKey();
            Long value = entry.getValue();
            VirtualTreeNode node = new VirtualTreeNode(name, value);
            if (top.hasErrors()) {
                Long error = top.getError(name);
                if (onlyGuaranteed && ((i + 1) < entries.length) &&
                    ((value - error) < entries[i + 1].getValue())) {
                    break;
                }
                Map<String, TreeNodeData> data = node.createMap();
                DataMap dataMap = new DataMap(1);
                dataMap.put("error", ValueFactory.create(error));
                data.put("stats", dataMap);
            }
            list.add(node);
        }
        return list;
    }

    @Override
    public byte[] bytesEncode(long version) {
        byte[] bytes = null;
        ByteBuf buf = PooledByteBufAllocator.DEFAULT.buffer();
        try {
            byte[] topBytes = top.bytesEncode(version);
            Varint.writeUnsignedVarInt(topBytes.length, buf);
            buf.writeBytes(topBytes);
            Varint.writeUnsignedVarInt(size, buf);
            bytes = new byte[buf.readableBytes()];
            buf.readBytes(bytes);
        } finally {
            buf.release();
        }
        return bytes;
    }

    @Override
    public void bytesDecode(byte[] b, long version) {
        top = new KeyTopper();
        ByteBuf buf = Unpooled.wrappedBuffer(b);
        try {
            int topBytesLength = Varint.readUnsignedVarInt(buf);
            if (topBytesLength > 0) {
                byte[] topBytes = new byte[topBytesLength];
                buf.readBytes(topBytes);
                top.bytesDecode(topBytes, version);
            } else {
                top.init().setLossy(true);
            }
            size = Varint.readUnsignedVarInt(buf);
        } finally {
            buf.release();
        }
    }
}

<code block>

package com.addthis.hydra.data.tree.prop;

import java.util.Collections;
import java.util.Comparator;
import java.util.LinkedList;
import java.util.List;

import com.addthis.bundle.core.Bundle;
import com.addthis.bundle.core.BundleField;
import com.addthis.bundle.util.ValueUtil;
import com.addthis.bundle.value.ValueFactory;
import com.addthis.bundle.value.ValueObject;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.codec.codables.Codable;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;
import com.addthis.hydra.data.tree.TreeDataParameters;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.tree.TreeNodeDataDeferredOperation;


public class DataLimitRecent extends TreeNodeData<DataLimitRecent.Config> {

    
    public static final class Config extends TreeDataParameters<DataLimitRecent> {

        
        @FieldConfig(codable = true)
        private long age;

        
        @FieldConfig(codable = true)
        private int size;

        
        @FieldConfig(codable = true)
        private String timeKey;

        
        @FieldConfig(codable = true)
        private boolean sortQueue;

        @Override
        public DataLimitRecent newInstance() {
            DataLimitRecent dc = new DataLimitRecent();
            dc.size = size;
            dc.age = age;
            dc.timeKey = timeKey;
            dc.sortQueue = sortQueue;
            dc.queue = new LinkedList<>();
            return dc;
        }
    }

    
    public static final class KeyTime implements Codable {

        @FieldConfig(codable = true)
        private String key;
        @FieldConfig(codable = true)
        private long time;
    }

    @FieldConfig(codable = true)
    private int size;
    @FieldConfig(codable = true)
    private long age;
    @FieldConfig(codable = true)
    private long deleted;
    @FieldConfig(codable = true)
    private LinkedList<KeyTime> queue;
    @FieldConfig(codable = true)
    private String timeKey;
    @FieldConfig(codable = true)
    private boolean sortQueue;

    private BundleField keyAccess;

    @Override
    public boolean updateChildData(DataTreeNodeUpdater state, DataTreeNode tn, Config conf) {
        return false;
    }

    public static class DataLimitRecentDeferredOperation extends TreeNodeDataDeferredOperation {

        final DataTreeNode parentNode;
        final KeyTime e;

        DataLimitRecentDeferredOperation(DataTreeNode parentNode, KeyTime e) {
            this.parentNode = parentNode;
            this.e = e;
        }

        @Override
        public void run() {
            DataTreeNode check = parentNode.getOrCreateNode(e.key, null);
            if (check != null) {
                
                
                
                

                
                parentNode.writeLock();
                long counterVal;
                try {
                    counterVal = check.incrementCounter(-1);
                } finally {
                    parentNode.writeUnlock();
                }
                if (counterVal <= 0) {
                    if (!parentNode.deleteNode(e.key)) {
                        
                    }
                }

            }
        }
    }


    @Override
    public boolean updateParentData(DataTreeNodeUpdater state, DataTreeNode parentNode,
            DataTreeNode childNode,
            List<TreeNodeDataDeferredOperation> deferredOps) {
        try {
            KeyTime e = new KeyTime();
            e.key = childNode.getName();
            if (timeKey != null) {
                Bundle p = state.getBundle();
                if (keyAccess == null) {
                    keyAccess = p.getFormat().getField(timeKey);
                }
                e.time = ValueUtil.asNumber(p.getValue(keyAccess)).asLong().getLong();
            } else {
                e.time = System.currentTimeMillis();
            }
            queue.addFirst(e);
            if ((size > 0 && queue.size() > size) || (age > 0 && e.time - queue.peekLast().time > age)) {
                if (sortQueue) {
                    Collections.sort(queue, new Comparator<KeyTime>() {
                        @Override
                        public int compare(KeyTime o, KeyTime o1) {
                            if (o.time > o1.time) {
                                return -1;
                            } else if (o.time < o1.time) {
                                return 1;
                            } else {
                                return 0;
                            }
                        }
                    });
                }
                e = queue.removeLast();
                deferredOps.add(new DataLimitRecentDeferredOperation(parentNode, e));
            }
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
        return false;
    }

    @Override
    public ValueObject getValue(String key) {
        return ValueFactory.create(deleted);
    }
}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.NoSuchElementException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

import com.addthis.basis.util.ClosableIterator;
import com.addthis.basis.util.MemoryCounter.Mem;

import com.addthis.hydra.data.tree.AbstractTreeNode;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeActor;
import com.addthis.hydra.data.tree.DataTreeNodeInitializer;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;
import com.addthis.hydra.data.tree.TreeDataParameters;
import com.addthis.hydra.data.tree.TreeDataParent;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.tree.TreeNodeDataDeferredOperation;
import com.addthis.hydra.store.db.DBKey;
import com.addthis.hydra.store.db.IPageDB.Range;



public class ConcurrentTreeNode extends AbstractTreeNode {

    public static final int ALIAS = 1 << 1;

    public static ConcurrentTreeNode getTreeRoot(ConcurrentTree tree) {
        ConcurrentTreeNode node = new ConcurrentTreeNode() {
            @Override
            void requireEditable() {

            }
        };
        node.tree = tree;
        node.leases.incrementAndGet();
        node.nodedb = 1L;
        return node;
    }

    
    public ConcurrentTreeNode() {
    }

    protected void initIfDecoded(ConcurrentTree tree, DBKey key, String name) {
        if (decoded.get()) {
            synchronized (initLock) {
                if (initOnce.compareAndSet(false, true)) {
                    this.tree = tree;
                    this.dbkey = key;
                    this.name = name;
                    decoded.set(false);
                }
            }
        }
    }

    protected void init(ConcurrentTree tree, DBKey key, String name) {
        this.tree = tree;
        this.dbkey = key;
        this.name = name;
    }

    @Mem(estimate = false, size = 64)
    private ConcurrentTree tree;
    @Mem(estimate = false, size = 64)
    private AtomicInteger leases = new AtomicInteger(0);
    @Mem(estimate = false, size = 64)
    private AtomicBoolean changed = new AtomicBoolean(false);
    @Mem(estimate = false, size = 64)
    private ReadWriteLock lock = new ReentrantReadWriteLock();

    private AtomicBoolean decoded = new AtomicBoolean(false);
    private AtomicBoolean initOnce = new AtomicBoolean(false);
    private final Object initLock = new Object();

    protected String name;
    protected DBKey dbkey;

    public String toString() {
        return "TN[k=" + dbkey + ",db=" + nodedb + ",n#=" + nodes + ",h#=" + hits +
               ",nm=" + name + ",le=" + leases + ",ch=" + changed + ",bi=" + bits + "]";
    }

    @Override public String getName() {
        return name;
    }

    @Override @SuppressWarnings("unchecked")
    public Map<String, TreeNodeData> getDataMap() {
        return data;
    }

    public int getLeaseCount() {
        return leases.get();
    }

    

    protected synchronized int incrementNodeCount() {
        return nodes++;
    }

    protected synchronized int updateNodeCount(int delta) {
        nodes += delta;
        changed.set(true);
        return nodes;
    }

    void requireEditable() {
        int count = leases.get();
        if (!(count == -2 || count > 0)) {
            throw new RuntimeException("fail editable requirement: lease state is " + count);
        }
    }

    public final boolean isBitSet(int bitcheck) {
        return (bits & bitcheck) == bitcheck;
    }

    public boolean isAlias() {
        return isBitSet(ALIAS);
    }

    public boolean isDeleted() {
        int count = leases.get();
        return count == -2;
    }

    public void markChanged() {
        requireEditable();
        changed.set(true);
    }

    protected boolean markDeleted() {
        return leases.getAndSet(-2) != -2;
    }

    protected void evictionComplete() {
        leases.compareAndSet(-1, -3);
    }

    protected synchronized void markAlias() {
        bitSet(ALIAS);
    }

    protected boolean isChanged() {
        return changed.get();
    }

    private final void bitSet(int set) {
        bits |= set;
    }

    private final void bitUnset(int set) {
        bits &= (~set);
    }

    
    void reactivate() {
        while(true) {
            int count = leases.get();
            if (count == -3 && leases.compareAndSet(-3, 0)) {
                return;
            } else if (count == -1 && leases.compareAndSet(-1, 0)) {
                return;
            } else if (count != -3 && count != -1) {
                return;
            }
        }
    }

    
    boolean tryLease() {
        while (true) {
            int count = leases.get();
            if (count < 0) {
                return false;
            }
            if (leases.compareAndSet(count, count + 1)) {
                return true;
            }
        }
    }

    
    boolean trySetEviction() {
        while (true) {
            int count = leases.get();
            if (count == -2) {
                return true;
            } else if (count != 0) {
                return false;
            }
            if (leases.compareAndSet(0, -1)) {
                return true;
            }
        }
    }

    
    @Override
    public void release() {
        while (true) {
            int count = leases.get();
            if (count <= 0) {
                return;
            }
            if (leases.compareAndSet(count, count - 1)) {
                return;
            }
        }
    }

    
    protected void requireNodeDB() {
        if (!hasNodes()) {
            synchronized (this) {
                if (!hasNodes()) {
                    nodedb = tree.getNextNodeDB();
                }
            }
        }
    }

    protected long nodeDB() {
        return nodedb;
    }

    
    public ClosableIterator<DataTreeNode> getNodeIterator() {
        return !hasNodes() || isDeleted() ? new Iter(null, false) : new Iter(tree.fetchNodeRange(nodedb), true);
    }

    
    public ClosableIterator<DataTreeNode> getNodeIterator(String prefix) {
        if (!isDeleted() && prefix != null && prefix.length() > 0) {
            
            StringBuilder sb = new StringBuilder(prefix.substring(0, prefix.length() - 1));
            sb.append((char) (prefix.charAt(prefix.length() - 1) + 1));
            return getNodeIterator(prefix, sb.toString());
        } else {
            return new Iter(null, false);
        }
    }

    
    public ClosableIterator<DataTreeNode> getNodeIterator(String from, String to) {
        if (!hasNodes() || isDeleted()) {
            return new Iter(null, false);
        }
        return new Iter(tree.fetchNodeRange(nodedb, from, to), true);
    }

    @Override public ConcurrentTreeNode getNode(String name) {
        return tree.getNode(this, name, false);
    }

    @Override public ConcurrentTreeNode getLeasedNode(String name) {
        return tree.getNode(this, name, true);
    }

    public DataTreeNode getOrCreateEditableNode(String name) {
        return getOrCreateEditableNode(name, null);
    }

    public DataTreeNode getOrCreateEditableNode(String name, DataTreeNodeInitializer creator) {
        return tree.getOrCreateNode(this, name, creator);
    }

    @Override public boolean deleteNode(String name) {
        return tree.deleteNode(this, name);
    }

    
    @Override
    public boolean aliasTo(DataTreeNode node) {
        if (node.getClass() != ConcurrentTreeNode.class) {
            return false;
        }
        requireEditable();
        if (hasNodes()) {
            return false;
        }
        ((ConcurrentTreeNode) node).requireNodeDB();
        nodedb = ((ConcurrentTreeNode) node).nodedb;
        markAlias();
        return true;
    }

    protected HashMap<String, TreeNodeData> createMap() {
        if (data == null) {
            data = new HashMap<>();
        }
        return data;
    }

    
    @Override @SuppressWarnings("unchecked")
    public void updateChildData(DataTreeNodeUpdater state, TreeDataParent path) {
        requireEditable();
        boolean updated = false;
        HashMap<String, TreeDataParameters> dataconf = path.dataConfig();
        lock.writeLock().lock();
        try {
            if (path.assignHits()) {
                hits = state.getAssignmentValue();
                updated = true;
            } else if (path.countHits()) {
                hits += state.getCountValue();
                updated = true;
            }
            if (dataconf != null) {
                if (data == null) {
                    data = new HashMap<>(dataconf.size());
                }
                for (Entry<String, TreeDataParameters> el : dataconf.entrySet()) {
                    TreeNodeData tnd = data.get(el.getKey());
                    if (tnd == null) {
                        tnd = el.getValue().newInstance(this);
                        data.put(el.getKey(), tnd);
                        updated = true;
                    }
                    if (tnd.updateChildData(state, this, el.getValue())) {
                        updated = true;
                    }
                }
            }
        } finally {
            lock.writeLock().unlock();
        }
        if (updated) {
            changed.set(true);
        }
    }

    
    @Override public void updateParentData(DataTreeNodeUpdater state, DataTreeNode child, boolean isnew) {
        requireEditable();
        List<TreeNodeDataDeferredOperation> deferredOps = null;
        lock.writeLock().lock();
        try {
            if (child != null && data != null) {
                deferredOps = new ArrayList<>(1);
                for (TreeNodeData<?> tnd : data.values()) {
                    if (isnew && tnd.updateParentNewChild(state, this, child, deferredOps)) {
                        changed.set(true);
                    }
                    if (tnd.updateParentData(state, this, child, deferredOps)) {
                        changed.set(true);
                    }
                }
            }
        } finally {
            lock.writeLock().unlock();
        }
        if (deferredOps != null) {
            for (TreeNodeDataDeferredOperation currentOp : deferredOps) {
                currentOp.run();
            }
        }
    }

    
    
    @Override public DataTreeNodeActor getData(String key) {
        lock.readLock().lock();
        try {
            return data != null ? data.get(key) : null;
        } finally {
            lock.readLock().unlock();
        }
    }

    
    
    public Collection<String> getDataFields() {
        lock.readLock().lock();
        try {
            if (data == null || data.size() == 0) {
                return null;
            }
            return data.keySet();
        } finally {
            lock.readLock().unlock();
        }
    }

    @Override
    public int getNodeCount() {
        return nodes;
    }

    @Override
    public void postDecode() {
        super.postDecode();
        decoded.set(true);
    }

    
    private final class Iter implements ClosableIterator<DataTreeNode> {

        private Range<DBKey, ConcurrentTreeNode> range;
        private ConcurrentTreeNode next;
        private boolean filterDeleted;

        private Iter(Range<DBKey, ConcurrentTreeNode> range, boolean filterDeleted) {
            this.range = range;
            this.filterDeleted = filterDeleted;
            fetchNext();
        }

        public String toString() {
            return "Iter(" + range + "," + next + ")";
        }

        void fetchNext() {
            if (range != null) {
                next = null;
                while (range.hasNext()) {
                    Entry<DBKey, ConcurrentTreeNode> tne = range.next();
                    next = tree.getNode(ConcurrentTreeNode.this, tne.getKey().rawKey().toString(), false);
                    if (next != null) {
                        if (filterDeleted && next.isDeleted()) {
                            next = null;
                            continue;
                        }
                        break;
                    }
                }
            }
        }

        @Override
        public boolean hasNext() {
            return next != null;
        }

        @Override
        public ConcurrentTreeNode next() {
            if (!hasNext()) {
                throw new NoSuchElementException();
            }
            ConcurrentTreeNode ret = next;
            fetchNext();
            return ret;
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException();
        }

        @Override
        public void close() {
            if (range != null) {
                range.close();
                range = null;
            }
        }
    }

    @Override
    public void encodeLock() {
        lock.readLock().lock();
    }

    @Override
    public void encodeUnlock() {
        lock.readLock().unlock();
    }


    @Override
    public void writeLock() {
        lock.writeLock().lock();
    }

    @Override
    public void writeUnlock() {
        lock.writeLock().unlock();
    }

    @Override
    public Iterator<DataTreeNode> iterator() {
        return getNodeIterator();
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator() {
        return getNodeIterator();
    }

    @Override
    public ConcurrentTree getTreeRoot() {
        return tree;
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator(String begin) {
        return getNodeIterator(begin);
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator(String from, String to) {
        return getNodeIterator(from, to);
    }

    @Override
    public DataTreeNode getOrCreateNode(String name, DataTreeNodeInitializer init) {
        return getOrCreateEditableNode(name, init);
    }

    

    @Override
    public synchronized long getCounter() {
        return hits;
    }

    @Override
    public synchronized void incrementCounter() {
        hits++;
    }

    @Override
    public synchronized long incrementCounter(long val) {
        hits += val;
        return hits;
    }

    @Override
    public synchronized void setCounter(long val) {
        hits = val;
    }
}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import javax.annotation.concurrent.GuardedBy;

import java.io.File;
import java.io.IOException;
import java.io.UnsupportedEncodingException;

import java.util.Arrays;
import java.util.Iterator;
import java.util.Map;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.function.BooleanSupplier;

import com.addthis.basis.concurrentlinkedhashmap.MediatedEvictionConcurrentHashMap;
import com.addthis.basis.util.LessBytes;
import com.addthis.basis.util.ClosableIterator;
import com.addthis.basis.util.LessFiles;
import com.addthis.basis.util.Meter;
import com.addthis.basis.util.Parameter;

import com.addthis.hydra.common.Configuration;
import com.addthis.hydra.data.tree.DataTree;
import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.DataTreeNodeActor;
import com.addthis.hydra.data.tree.DataTreeNodeInitializer;
import com.addthis.hydra.data.tree.DataTreeNodeUpdater;
import com.addthis.hydra.data.tree.TreeDataParent;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.store.db.CloseOperation;
import com.addthis.hydra.store.db.DBKey;
import com.addthis.hydra.store.db.IPageDB;
import com.addthis.hydra.store.db.PageDB;
import com.addthis.hydra.store.kv.PagedKeyValueStore;
import com.addthis.hydra.store.skiplist.Page;
import com.addthis.hydra.store.skiplist.PageFactory;
import com.addthis.hydra.store.skiplist.SkipListCache;
import com.addthis.hydra.store.util.MeterFileLogger;
import com.addthis.hydra.store.util.MeterFileLogger.MeterDataSource;
import com.addthis.hydra.store.util.NamedThreadFactory;
import com.addthis.hydra.store.util.Raw;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.util.concurrent.AtomicDouble;

import com.yammer.metrics.Metrics;
import com.yammer.metrics.core.Gauge;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


public final class ConcurrentTree implements DataTree, MeterDataSource {
    static final Logger log = LoggerFactory.getLogger(ConcurrentTree.class);

    
    @Configuration.Parameter
    static final int defaultNumDeletionThreads = Parameter.intValue("hydra.tree.clean.threads", 1);

    
    @Configuration.Parameter
    static final int deletionThreadSleepMillis = Parameter.intValue("hydra.tree.clean.interval", 10);

    
    @Configuration.Parameter
    static final int deletionLogInterval = Parameter.intValue("hydra.tree.clean.logging", 100000);

    private static final AtomicInteger scopeGenerator = new AtomicInteger();

    private final String scope = "ConcurrentTree" + Integer.toString(scopeGenerator.getAndIncrement());

    public static enum METERTREE {
        CACHE_HIT, CACHE_MISS, NODE_PUT, NODE_CREATE, NODE_DELETE, SOURCE_MISS
    }

    static final String keyCacheGet = METERTREE.CACHE_HIT.toString();
    static final String keyCacheMiss = METERTREE.CACHE_MISS.toString();

    private final File root;
    private final File idFile;
    final IPageDB<DBKey, ConcurrentTreeNode> source;
    private final ConcurrentTreeNode treeRootNode;
    final ConcurrentTreeNode treeTrashNode;
    private final AtomicLong nextDBID;
    final AtomicBoolean closed = new AtomicBoolean(false);
    private final Meter<METERTREE> meter;
    private final MeterFileLogger logger;
    private final AtomicDouble cacheHitRate = new AtomicDouble(0.0);
    private final MediatedEvictionConcurrentHashMap<CacheKey, ConcurrentTreeNode> cache;
    private final ScheduledExecutorService deletionThreadPool;

    @GuardedBy("treeTrashNode")
    private IPageDB.Range<DBKey, ConcurrentTreeNode> trashIterator;

    @SuppressWarnings("unused")
    final Gauge<Integer> treeTrashNodeCount = Metrics.newGauge(SkipListCache.class,
            "treeTrashNodeCount", scope,
            new Gauge<Integer>() {
                @Override
                public Integer value() {
                    return treeTrashNode == null ? -1 : treeTrashNode.getNodeCount();
                }
            });

    @SuppressWarnings("unused")
    final Gauge<Long> treeTrashHitsCount = Metrics.newGauge(SkipListCache.class,
            "treeTrashHitsCount", scope,
            new Gauge<Long>() {
                @Override
                public Long value() {
                    return treeTrashNode == null ? -1 : treeTrashNode.getCounter();
                }
            });

    ConcurrentTree(File root, int numDeletionThreads, int cleanQSize, int maxCacheSize,
                   int maxPageSize, PageFactory factory) throws Exception {
        LessFiles.initDirectory(root);
        this.root = root;
        long start = System.currentTimeMillis();

        
        meter = new Meter<>(METERTREE.values());
        for (METERTREE m : METERTREE.values()) {
            meter.addCountMetric(m, m.toString());
        }

        
        if (TreeCommonParameters.meterLogging > 0) {
            logger = new MeterFileLogger(this, root, "tree-metrics",
                                         TreeCommonParameters.meterLogging, TreeCommonParameters.meterLogLines);
        } else {
            logger = null;
        }
        source = new PageDB.Builder<>(root, ConcurrentTreeNode.class, maxPageSize, maxCacheSize)
                .pageFactory(factory).build();
        source.setCacheMem(TreeCommonParameters.maxCacheMem);
        source.setPageMem(TreeCommonParameters.maxPageMem);
        source.setMemSampleInterval(TreeCommonParameters.memSample);
        
        cache = new MediatedEvictionConcurrentHashMap.
                Builder<CacheKey, ConcurrentTreeNode>().
                mediator(new CacheMediator(source)).
                maximumWeightedCapacity(cleanQSize).build();

        
        idFile = new File(root, "nextID");
        if (idFile.exists() && idFile.isFile() && idFile.length() > 0) {
            nextDBID = new AtomicLong(Long.parseLong(LessBytes.toString(LessFiles.read(idFile))));
        } else {
            nextDBID = new AtomicLong(1);
        }

        
        ConcurrentTreeNode dummyRoot = ConcurrentTreeNode.getTreeRoot(this);
        treeRootNode = (ConcurrentTreeNode) dummyRoot.getOrCreateEditableNode("root");
        treeTrashNode = (ConcurrentTreeNode) dummyRoot.getOrCreateEditableNode("trash");
        treeTrashNode.requireNodeDB();
        deletionThreadPool = Executors.newScheduledThreadPool(numDeletionThreads,
                new NamedThreadFactory(scope + "-deletion-", true));

        for (int i = 0; i < numDeletionThreads; i++) {
            deletionThreadPool.scheduleAtFixedRate(
                    new ConcurrentTreeDeletionTask(this, closed::get, LoggerFactory.getLogger(
                            ConcurrentTreeDeletionTask.class.getName() + ".Background")),
                    i, deletionThreadSleepMillis, TimeUnit.MILLISECONDS);
        }

        long openTime = System.currentTimeMillis() - start;
        log.info("dir={} root={} trash={} cache={} nextdb={} openms={}",
                 root, treeRootNode, treeTrashNode, TreeCommonParameters.cleanQMax, nextDBID, openTime);
    }

    public ConcurrentTree(File root) throws Exception {
        this(root, defaultNumDeletionThreads, TreeCommonParameters.cleanQMax,
             TreeCommonParameters.maxCacheSize, TreeCommonParameters.maxPageSize,
             Page.DefaultPageFactory.singleton);
    }

    public void meter(METERTREE meterval) {
        meter.inc(meterval);
    }

    
    @VisibleForTesting
    boolean setNextNodeDB(long id) {
        while (true) {
            long current = nextDBID.get();
            if (current > id) {
                return false;
            } else if (nextDBID.compareAndSet(current, id)) {
                return true;
            }
        }
    }

    long getNextNodeDB() {
        long nextValue = nextDBID.incrementAndGet();
        return nextValue;
    }

    private static boolean setLease(final ConcurrentTreeNode node, final boolean lease) {
        return (!lease || node.tryLease());
    }

    public ConcurrentTreeNode getNode(final ConcurrentTreeNode parent, final String child, final boolean lease) {
        long nodedb = parent.nodeDB();
        if (nodedb <= 0) {
            log.trace("[node.get] {} --> {} NOMAP --> null", parent, child);
            return null;
        }
        CacheKey key = new CacheKey(nodedb, child);

        

        while (true) {
            ConcurrentTreeNode node = cache.get(key);
            if (node != null) {
                if (node.isDeleted()) {
                    cache.remove(key, node);
                } else if (setLease(node, lease)) {
                    reportCacheHit();
                    return node; 
                }
            } else {
                DBKey dbkey = key.dbkey();
                reportCacheMiss();
                node = source.get(dbkey);

                if (node == null) {
                    meter.inc(METERTREE.SOURCE_MISS);
                    return null; 
                }

                if (node.isDeleted()) {
                    source.remove(dbkey);
                } else {
                    node.initIfDecoded(this, dbkey, key.name);

                    ConcurrentTreeNode prev = cache.putIfAbsent(key, node);
                    if (prev == null) {
                        node.reactivate();
                        if (setLease(node, lease)) {
                            return node; 
                        }
                    }
                }
            }
        }
    }

    public ConcurrentTreeNode getOrCreateNode(final ConcurrentTreeNode parent, final String child,
                                              final DataTreeNodeInitializer creator) {
        parent.requireNodeDB();
        CacheKey key = new CacheKey(parent.nodeDB(), child);
        ConcurrentTreeNode newNode = null;

        while (true) {
            ConcurrentTreeNode node = cache.get(key);
            if (node != null) {
                if (node.isDeleted()) {
                    cache.remove(key, node);
                } else if (setLease(node, true)) {
                    reportCacheHit();
                    return node;
                }
            } else {
                DBKey dbkey = key.dbkey();
                reportCacheMiss();
                node = source.get(dbkey);

                if (node != null) {
                    if (node.isDeleted()) {
                        source.remove(dbkey);
                    } else {
                        node.initIfDecoded(this, dbkey, key.name);
                        ConcurrentTreeNode prev = cache.putIfAbsent(key, node);
                        if (prev == null) {
                            node.reactivate();
                            if (setLease(node, true)) {
                                return node;
                            }
                        }
                    }
                } else { 
                    if (newNode == null) {
                        newNode = new ConcurrentTreeNode();
                        newNode.init(this, dbkey, key.name);
                        newNode.tryLease();
                        newNode.markChanged();
                        if (creator != null) {
                            creator.onNewNode(newNode);
                        }
                    }
                    node = newNode;
                    if (cache.putIfAbsent(key, node) == null) {
                        
                        source.put(dbkey, node);
                        parent.updateNodeCount(1);
                        return node;
                    }
                }
            }
        }
    }

    boolean deleteNode(final ConcurrentTreeNode parent, final String child) {
        log.trace("[node.delete] {} --> {}", parent, child);
        long nodedb = parent.nodeDB();
        if (nodedb <= 0) {
            log.debug("parent has no children on delete : {} --> {}", parent, child);
            return false;
        }
        CacheKey key = new CacheKey(nodedb, child);
        
        ConcurrentTreeNode node = getNode(parent, child, true);
        if (node != null) {
            
            source.remove(key.dbkey());
            
            
            
            
            if (node.markDeleted()) {
                
                
                cache.remove(key, node);
                parent.updateNodeCount(-1);
                if (node.hasNodes() && !node.isAlias()) {
                    markForChildDeletion(node);
                }
                return true;
            }
        }
        return false;
    }

    private void markForChildDeletion(final ConcurrentTreeNode node) {
        
        assert node.hasNodes();
        assert !node.isAlias();
        long nodeDB = treeTrashNode.nodeDB();
        int next = treeTrashNode.incrementNodeCount();
        DBKey key = new DBKey(nodeDB, Raw.get(LessBytes.toBytes(next)));
        source.put(key, node);
        log.trace("[trash.mark] {} --> {}", next, treeTrashNode);
    }

    @SuppressWarnings("unchecked") IPageDB.Range<DBKey, ConcurrentTreeNode> fetchNodeRange(long db) {
        return source.range(new DBKey(db), new DBKey(db + 1));
    }

    @SuppressWarnings({"unchecked", "unused"}) private IPageDB.Range<DBKey, ConcurrentTreeNode> fetchNodeRange(long db, String from) {
        return source.range(new DBKey(db, Raw.get(from)), new DBKey(db + 1));
    }

    @SuppressWarnings("unchecked") IPageDB.Range<DBKey, ConcurrentTreeNode> fetchNodeRange(long db, String from, String to) {
        return source.range(new DBKey(db, Raw.get(from)),
                to == null ? new DBKey(db+1, (Raw)null) : new DBKey(db, Raw.get(to)));
    }

    @Override public ConcurrentTreeNode getRootNode() {
        return treeRootNode;
    }

    
    @VisibleForTesting
    void waitOnDeletions() {
        shutdownDeletionThreadPool();
        synchronized (treeTrashNode) {
            if (trashIterator != null) {
                trashIterator.close();
                trashIterator = null;
            }
        }
    }

    
    @VisibleForTesting
    ConcurrentMap<CacheKey, ConcurrentTreeNode> getCache() {
        return cache;
    }

    private void shutdownDeletionThreadPool() {
        if (deletionThreadPool == null)
            return;

        deletionThreadPool.shutdown();

        try {
            if (!deletionThreadPool.awaitTermination(10, TimeUnit.SECONDS)) {
                log.warn("Waiting on outstanding node deletions to complete.");
                deletionThreadPool.awaitTermination(Long.MAX_VALUE, TimeUnit.SECONDS);
            }
        } catch (InterruptedException ignored) {
        }
    }


    
    @Override
    public void foregroundNodeDeletion(BooleanSupplier terminationCondition) {
        ConcurrentTreeDeletionTask deletionTask = new ConcurrentTreeDeletionTask(this, terminationCondition, log);
        deletionTask.run();
    }

    @Override
    public void sync() throws IOException {
        log.debug("[sync] start");
        for (ConcurrentTreeNode node : cache.values()) {
            if (!node.isDeleted() && node.isChanged()) {
                source.put(node.dbkey, node);
            }
        }
        log.debug("[sync] end nextdb={}", nextDBID);
        LessFiles.write(idFile, LessBytes.toBytes(nextDBID.toString()), false);
    }

    @Override
    public long getDBCount() {
        return nextDBID.get();
    }

    @Override
    public int getCacheSize() {
        return cache.size();
    }

    @Override
    public double getCacheHitRate() {
        if (logger == null) {
            getIntervalData();
        }
        return cacheHitRate.get();
    }

    
    @Override
    public void close(boolean cleanLog, CloseOperation operation) throws IOException {
        if (!closed.compareAndSet(false, true)) {
            log.trace("already closed");
            return;
        }
        log.debug("closing {}", this);
        waitOnDeletions();
        if (treeRootNode != null) {
            treeRootNode.markChanged();
            treeRootNode.release();
            if (treeRootNode.getLeaseCount() != 0) {
                throw new IllegalStateException("invalid root state on shutdown : " + treeRootNode);
            }
        }
        if (treeTrashNode != null) {
            treeTrashNode.markChanged();
            treeTrashNode.release();
        }
        sync();
        if (source != null) {
            int status = source.close(cleanLog, operation);
            if (status != 0) {
                throw new RuntimeException("page db close returned a non-zero exit code : " + status);
            }
        }
        if (logger != null) {
            logger.terminate();
        }
    }


    @Override
    public void close() throws IOException {
        close(false, CloseOperation.NONE);
    }

    @Override
    public Map<String, Long> getIntervalData() {
        Map<String, Long> mark = meter.mark();
        Long gets = mark.get(keyCacheGet);
        Long miss = mark.get(keyCacheMiss);
        if (gets == null || miss == null || miss == 0) {
            cacheHitRate.set(0);
        } else {
            cacheHitRate.set(1.0d - ((miss * 1.0d) / ((gets + miss) * 1.0d)));
        }
        return mark;
    }

    private void reportCacheHit() {
        meter.inc(METERTREE.CACHE_HIT);
    }

    private void reportCacheMiss() {
        meter.inc(METERTREE.CACHE_MISS);
    }

    @Override
    public String toString() {
        return "Tree@" + root;
    }

    @Override
    public DataTreeNode getLeasedNode(String name) {
        return getRootNode().getLeasedNode(name);
    }

    @Override
    public DataTreeNode getOrCreateNode(String name, DataTreeNodeInitializer init) {
        return getRootNode().getOrCreateNode(name, init);
    }

    @Override
    public boolean deleteNode(String node) {
        return getRootNode().deleteNode(node);
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator() {
        ConcurrentTreeNode rootNode = getRootNode();
        if (rootNode != null) {
            return getRootNode().getIterator();
        }
        return null;
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator(String begin) {
        return getRootNode().getIterator(begin);
    }

    @Override
    public ClosableIterator<DataTreeNode> getIterator(String from, String to) {
        return getRootNode().getIterator(from, to);
    }

    @Override
    public Iterator<DataTreeNode> iterator() {
        return getRootNode().iterator();
    }

    @Override
    public String getName() {
        return getRootNode().getName();
    }

    @Override
    public int getNodeCount() {
        return getRootNode().getNodeCount();
    }

    @Override
    public long getCounter() {
        return getRootNode().getCounter();
    }

    @Override
    public void incrementCounter() {
        getRootNode().incrementCounter();
    }

    @Override
    public long incrementCounter(long val) {
        return getRootNode().incrementCounter(val);
    }

    @Override
    public void writeLock() {
        getRootNode().writeLock();
    }

    @Override
    public void writeUnlock() {
        getRootNode().writeUnlock();
    }

    @Override
    public void setCounter(long val) {
        getRootNode().setCounter(val);
    }

    @Override
    public void updateChildData(DataTreeNodeUpdater state, TreeDataParent path) {
        getRootNode().updateChildData(state, path);
    }

    @Override
    public void updateParentData(DataTreeNodeUpdater state, DataTreeNode child, boolean isnew) {
        getRootNode().updateParentData(state, child, isnew);
    }

    @Override
    public boolean aliasTo(DataTreeNode target) {
        throw new RuntimeException("root node cannot be an alias");
    }

    @Override
    public void release() {
        getRootNode().release();
    }

    @Override
    public DataTreeNodeActor getData(String key) {
        return getRootNode().getData(key);
    }

    @Override
    public Map<String, TreeNodeData> getDataMap() {
        return getRootNode().getDataMap();
    }

    private static String keyName(DBKey dbkey) {
        try {
            return new String(dbkey.key(), "UTF-8");
        } catch (UnsupportedEncodingException ex) {
            log.warn("Could not decode the following dbkey bytes into a string: " +
                     Arrays.toString(dbkey.key()));
            return null;
        }
    }

    
    long deleteSubTree(ConcurrentTreeNode rootNode,
                       long counter,
                       BooleanSupplier terminationCondition,
                       Logger deletionLogger) {
        long nodeDB = rootNode.nodeDB();
        IPageDB.Range<DBKey, ConcurrentTreeNode> range = fetchNodeRange(nodeDB);
        DBKey endRange;
        boolean reschedule;
        try {
            while (range.hasNext() && !terminationCondition.getAsBoolean()) {
                if ((++counter % deletionLogInterval) == 0) {
                    deletionLogger.info("Deleted {} nodes from the tree.", counter);
                }
                Map.Entry<DBKey, ConcurrentTreeNode> entry = range.next();
                ConcurrentTreeNode next = entry.getValue();

                if (next.hasNodes() && !next.isAlias()) {
                    counter = deleteSubTree(next, counter, terminationCondition, deletionLogger);
                }
                String name = entry.getKey().rawKey().toString();
                CacheKey key = new CacheKey(nodeDB, name);
                ConcurrentTreeNode cacheNode = cache.remove(key);
                
                if (cacheNode != null) {
                    cacheNode.markDeleted();
                }
            }
            if (range.hasNext()) {
                endRange = range.next().getKey();
                reschedule = true;
            } else {
                endRange = new DBKey(nodeDB + 1);
                reschedule = false;
            }
        } finally {
            range.close();
        }
        source.remove(new DBKey(nodeDB), endRange);
        if (reschedule) {
            markForChildDeletion(rootNode);
        }
        return counter;
    }

    Map.Entry<DBKey, ConcurrentTreeNode> nextTrashNode() {
        synchronized (treeTrashNode) {
            if (trashIterator == null) {
                return recreateTrashIterator();
            } else if (trashIterator.hasNext()) {
                return trashIterator.next();
            } else {
                return recreateTrashIterator();
            }
        }
    }

    @GuardedBy("treeTrashNode")
    private Map.Entry<DBKey, ConcurrentTreeNode> recreateTrashIterator() {
        if (trashIterator != null) {
            trashIterator.close();
        }
        trashIterator = fetchNodeRange(treeTrashNode.nodeDB());
        if (trashIterator.hasNext()) {
            return trashIterator.next();
        } else {
            trashIterator.close();
            trashIterator = null;
            return null;
        }
    }

    
    @VisibleForTesting
    ConcurrentTreeNode getTreeTrashNode() {
        return treeTrashNode;
    }

    public void repairIntegrity() {
        PagedKeyValueStore store = source.getEps();
        if (store instanceof SkipListCache) {
            ((SkipListCache) store).testIntegrity(true);
        }
    }

}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import java.io.File;
import java.io.IOException;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Random;
import java.util.concurrent.CyclicBarrier;

import com.addthis.basis.test.SlowTest;
import com.addthis.basis.util.ClosableIterator;
import com.addthis.basis.util.LessFiles;

import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.store.db.CloseOperation;

import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

public class TestConcurrentTree {

    private static final Logger log = LoggerFactory.getLogger(TestConcurrentTree.class);

    private static final CloseOperation close = CloseOperation.TEST;

    static final int fastNumElements = 10000;
    static final int fastNumThreads = 8;

    static final int slowNumElements = 100000;
    static final int slowNumThreads = 8;

    private File makeTemporaryDirectory() throws IOException {
        final File temp;

        temp = File.createTempFile("temp", Long.toString(System.nanoTime()));

        if (!(temp.delete())) {
            throw new IOException("Could not delete temp file: " + temp.getAbsolutePath());
        }

        if (!(temp.mkdir())) {
            throw new IOException("Could not create temp directory: " + temp.getAbsolutePath());
        }

        return temp;
    }

    static final class InsertionThread extends Thread {

        final CyclicBarrier barrier;
        final List<Integer> values;
        final List<Integer> threadId;
        final int myId;
        final ConcurrentTree cache;
        final ConcurrentTreeNode parent;
        int counter;

        public InsertionThread(CyclicBarrier barrier, List<Integer> values,
                List<Integer> threadId, int id, ConcurrentTree cache,
                ConcurrentTreeNode parent) {
            super("InsertionThread" + id);
            this.barrier = barrier;
            this.values = values;
            this.threadId = threadId;
            this.myId = id;
            this.cache = cache;
            this.counter = 0;
            this.parent = parent;
        }

        @Override
        public void run() {
            try {
                barrier.await();
                int len = threadId.size();
                for (int i = 0; i < len; i++) {
                    if (threadId.get(i) == myId) {
                        Integer val = values.get(i);
                        ConcurrentTreeNode node = cache.getOrCreateNode(parent,
                                Integer.toString(val), null);
                        node.release();
                        counter++;
                    }
                }
            } catch (Exception e) {
                e.printStackTrace();
                fail();
            }
        }

    }

    static final class DeletionThread extends Thread {

        final CyclicBarrier barrier;
        final List<Integer> values;
        final List<Integer> threadId;
        final int myId;
        final ConcurrentTree cache;
        final ConcurrentTreeNode parent;
        int counter;

        public DeletionThread(CyclicBarrier barrier, List<Integer> values,
                List<Integer> threadId, int id, ConcurrentTree cache,
                ConcurrentTreeNode parent) {
            super("DeletionThread" + id);
            this.barrier = barrier;
            this.values = values;
            this.threadId = threadId;
            this.myId = id;
            this.cache = cache;
            this.counter = 0;
            this.parent = parent;
        }

        @Override
        public void run() {
            try {
                barrier.await();
                int len = threadId.size();
                for (int i = 0; i < len; i++) {
                    if (threadId.get(i) == myId) {
                        Integer val = values.get(i);
                        cache.deleteNode(parent, Integer.toString(val));
                        counter++;
                    }
                }
            } catch (Exception e) {
                e.printStackTrace();
                fail();
            }
        }
    }

    @Test
    @Category(SlowTest.class)
    public void getOrCreateOneThreadIterations() throws Exception {
        for(int i = 0; i < 100; i++) {
            getOrCreateOneThread();
        }
    }

    @Test
    public void getOrCreateOneThread() throws Exception {
        log.info("getOrCreateOneThread");
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).build();
            ConcurrentTreeNode root = tree.getRootNode();
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null);
                assertNotNull(node);
                assertEquals(Integer.toString(i), node.getName());
                node.release();
            }
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                node.release();
            }
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void recursiveDeleteOneThread() throws Exception {
        log.info("recursiveDeleteOneThread");
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).build();
            ConcurrentTreeNode root = tree.getRootNode();
            ConcurrentTreeNode parent = tree.getOrCreateNode(root, "hello", null);
            for (int i = 0; i < (TreeCommonParameters.cleanQMax << 1); i++) {
                ConcurrentTreeNode child = tree.getOrCreateNode(parent, Integer.toString(i), null);
                assertNotNull(child);
                assertEquals(Integer.toString(i), child.getName());
                parent.release();
                parent = child;
            }
            parent.release();

            assertEquals(1, root.getNodeCount());
            assertEquals(TreeCommonParameters.cleanQMax, tree.getCache().size());

            tree.deleteNode(root, "hello");
            tree = waitForDeletion(tree, dir);
            assertEquals(2, tree.getCache().size());
            assertEquals(0, root.getNodeCount());
            assertTrue(tree.getTreeTrashNode().getCounter() >= 1);
            assertEquals(tree.getTreeTrashNode().getCounter(), tree.getTreeTrashNode().getNodeCount());
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void recursiveDeleteMultiThreads() throws Exception {
        log.info("recursiveDeleteMultiThreads");
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).
                    numDeletionThreads(8).build();
            ConcurrentTreeNode root = tree.getRootNode();
            for (int i = 0; i < fastNumThreads; i++) {
                ConcurrentTreeNode parent = tree.getOrCreateNode(root, Integer.toString(i), null);
                for (int j = 0; j < TreeCommonParameters.cleanQMax; j++) {
                    ConcurrentTreeNode child = tree.getOrCreateNode(parent, Integer.toString(j), null);
                    assertNotNull(child);
                    assertEquals(Integer.toString(j), child.getName());
                    parent.release();
                    parent = child;
                }
                parent.release();
            }

            assertEquals(TreeCommonParameters.cleanQMax, tree.getCache().size());

            assertEquals(fastNumThreads, root.getNodeCount());

            for (int i = 0; i < fastNumThreads; i++) {
                tree.deleteNode(root, Integer.toString(i));
            }

            tree = waitForDeletion(tree, dir);
            assertEquals(2, tree.getCache().size());
            assertEquals(0, root.getNodeCount());

            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void getOrCreateFast() throws Exception {
        getOrCreateMultiThread(fastNumElements, fastNumThreads);
    }

    @Test
    @Category(SlowTest.class)
    public void getOrCreateSlow() throws Exception {
        getOrCreateMultiThread(slowNumElements, slowNumThreads);
    }

    private void getOrCreateMultiThread(int numElements, int numThreads) throws Exception {
        log.info("getOrCreateMultiThread");
        File dir = makeTemporaryDirectory();
        try {
            ArrayList<Integer> values = new ArrayList<>(numElements);
            final CyclicBarrier barrier = new CyclicBarrier(numThreads);
            ArrayList<Integer> threadId = new ArrayList<>(numElements);
            InsertionThread[] threads = new InsertionThread[numThreads];
            ConcurrentTree tree = new Builder(dir).build();
            ConcurrentTreeNode root = tree.getRootNode();

            for (int i = 0; i < numElements; i++) {
                values.add(i);
                threadId.add(i % numThreads);
            }

            for (int i = 0; i < numThreads; i++) {
                threads[i] = new InsertionThread(barrier, values, threadId, i, tree, root);
            }

            Collections.shuffle(values);

            for (int i = 0; i < numThreads; i++) {
                threads[i].start();
            }

            for (int i = 0; i < numThreads; i++) {
                threads[i].join();
            }

            for (int i = 0; i < numThreads; i++) {
                assertEquals(numElements / numThreads, threads[i].counter);
            }

            for (int i = 0; i < numElements; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                node.release();
            }
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void deleteOneThreadForeground() throws Exception {
        log.info("deleteOneThreadForeground");
        deleteOneThread(0);
    }

    @Test
    public void deleteOneThreadBackground() throws Exception {
        log.info("deleteOneThreadBackground");
        deleteOneThread(fastNumThreads);
    }

    private void deleteOneThread(int numDeletionThreads) throws Exception {
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir)
                    .numDeletionThreads(numDeletionThreads).build();
            ConcurrentTreeNode root = tree.getRootNode();
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null);
                child.release();
                node.release();
            }
            for (int i = 0; i < 1000; i++) {
                tree.deleteNode(root, Integer.toString(i));
            }
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), false);
                assertNull(node);
            }
            tree = waitForDeletion(tree, dir);
            assertTrue(tree.getTreeTrashNode().getCounter() >= 1000);
            assertEquals(tree.getTreeTrashNode().getCounter(), tree.getTreeTrashNode().getNodeCount());
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    
    private ConcurrentTree waitForDeletion(ConcurrentTree tree, File dir) throws Exception {
        tree.close();
        tree = new Builder(dir).numDeletionThreads(0).build();
        tree.foregroundNodeDeletion(() -> false);
        return tree;
    }

    @Test
    public void deleteFast() throws Exception {
        deleteMultiThread(fastNumElements, fastNumThreads, fastNumThreads);
        deleteMultiThread(fastNumElements, fastNumThreads, 0);
    }

    @Test
    @Category(SlowTest.class)
    public void deleteSlow1() throws Exception {
        deleteMultiThread(slowNumElements, slowNumThreads, slowNumThreads);
        deleteMultiThread(slowNumElements, slowNumThreads, 0);
    }

    @Test
    @Category(SlowTest.class)
    public void deleteSlow2() throws Exception {
        for(int i = 0 ; i < 100; i++) {
            deleteMultiThread(fastNumElements, fastNumThreads, fastNumThreads);
            deleteMultiThread(fastNumElements, fastNumThreads, 0);
        }
    }

    @Test
    @Category(SlowTest.class)
    public void iterateAndDeleteSlow() throws Exception {
        for(int i = 0; i < 100; i++) {
            iterateAndDelete(fastNumThreads, 1000);
        }
    }

    @Test
    public void iterateAndDeleteFast() throws Exception {
        iterateAndDelete(fastNumThreads, 1000);
    }

    private void iterateAndDelete(int numThreads, int numElements) throws Exception {
        log.info("iterateAndDelete {} {}", numThreads, numElements);
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).numDeletionThreads(numThreads).
                    maxPageSize(5).maxCacheSize(500).build();
            ConcurrentTreeNode root = tree.getRootNode();

            for (int i = 0; i < numElements; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null);
                assertNotNull(node);
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null);
                child.release();
                node.release();
            }

            Random rng = new Random();

            ClosableIterator<DataTreeNode> iterator = tree.getIterator();
            try {
                int counter = 0;
                while(iterator.hasNext()) {
                    DataTreeNode node = iterator.next();
                    if (rng.nextFloat() < 0.8) {
                        String name = node.getName();
                        tree.deleteNode(root, name);
                        counter++;
                    }
                }
                log.info("Deleted " + (((float) counter) / numElements * 100.0) + " % of nodes");
            } finally {
                iterator.close();
            }

            tree.close(false, close);

        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }

    }

    private void deleteMultiThread(int numElements, int numThreads, int numDeletionThreads) throws Exception {
        log.info("deleteMultiThread {} {} {}", numElements, numThreads, numDeletionThreads);
        File dir = makeTemporaryDirectory();
        try {
            ArrayList<Integer> values = new ArrayList<>(numElements);
            final CyclicBarrier barrier = new CyclicBarrier(numThreads);
            ArrayList<Integer> threadId = new ArrayList<>(numElements);
            DeletionThread[] threads = new DeletionThread[numThreads];
            ConcurrentTree tree = new Builder(dir)
                    .numDeletionThreads(numDeletionThreads).build();
            ConcurrentTreeNode root = tree.getRootNode();

            for (int i = 0; i < numElements; i++) {
                values.add(i);
                threadId.add(i % numThreads);
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null);
                assertNotNull(node);
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null);
                child.release();
                node.release();
            }

            for (int i = 0; i < numThreads; i++) {
                threads[i] = new DeletionThread(barrier, values, threadId, i, tree, root);
            }

            Collections.shuffle(values);

            for (int i = 0; i < numThreads; i++) {
                threads[i].start();
            }

            for (int i = 0; i < numThreads; i++) {
                threads[i].join();
            }

            for (int i = 0; i < numThreads; i++) {
                assertEquals(numElements / numThreads, threads[i].counter);
            }

            for (int i = 0; i < numElements; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNull(node);
            }
            tree = waitForDeletion(tree, dir);
            assertTrue(tree.getTreeTrashNode().getCounter() >= numElements);
            assertEquals(tree.getTreeTrashNode().getCounter(), tree.getTreeTrashNode().getNodeCount());
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

    @Test
    public void maximumNodeIdentifier() throws Exception {
        File dir = makeTemporaryDirectory();
        try {
            ConcurrentTree tree = new Builder(dir).build();
            ConcurrentTreeNode root = tree.getRootNode();
            for (int i = 0; i < 1000; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null);
                child.release();
                node.release();
            }
            assertTrue(tree.setNextNodeDB(Integer.MAX_VALUE));
            for (int i = 1000; i < 2000; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                ConcurrentTreeNode child = tree.getOrCreateNode(node, Integer.toString(i), null);
                child.release();
                node.release();
            }
            tree.close(false, close);
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }

}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import java.io.File;
import java.io.IOException;

import java.util.Map;

import com.addthis.basis.util.LessFiles;

import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.data.tree.prop.DataTime;
import com.addthis.hydra.store.db.CloseOperation;
import com.addthis.hydra.store.skiplist.LegacyPage;
import com.addthis.hydra.store.skiplist.Page;

import org.junit.Test;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;

public class TestTreeSerializationVersions {

    private static final CloseOperation close = CloseOperation.TEST;

    private File makeTemporaryDirectory() throws IOException {
        final File temp;

        temp = File.createTempFile("temp", Long.toString(System.nanoTime()));

        if (!(temp.delete())) {
            throw new IOException("Could not delete temp file: " + temp.getAbsolutePath());
        }

        if (!(temp.mkdir())) {
            throw new IOException("Could not create temp directory: " + temp.getAbsolutePath());
        }

        return temp;
    }

    @Test
    public void legacyToSparseUpgradePath() throws Exception {
        File dir = makeTemporaryDirectory();
        try {
            int count = 1000;
            ConcurrentTree tree = new Builder(dir).
                    pageFactory(LegacyPage.LegacyPageFactory.singleton).build();
            ConcurrentTreeNode root = tree.getRootNode();
            
            for (int i = 0; i < count; i++) {
                ConcurrentTreeNode node = tree.getOrCreateNode(root, Integer.toString(i), null);
                assertNotNull(node);
                assertEquals(Integer.toString(i), node.getName());
                DataTime attachment = new DataTime();
                attachment.setFirst(i);
                attachment.setLast(i + count);
                node.createMap().put("time", attachment);
                node.markChanged();
                node.release();
            }
            tree.close(false, close);
            tree = new Builder(dir).
                    pageFactory(Page.DefaultPageFactory.singleton).build();
            
            for (int i = 0; i < count; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                Map<String, TreeNodeData> attachments = node.getDataMap();
                assertNotNull(attachments);
                assertTrue(attachments.containsKey("time"));
                DataTime attachment = (DataTime) attachments.get("time");
                assertEquals(i, attachment.first());
                assertEquals(i + count, attachment.last());
                node.release();
            }
            tree.close(false, close);
            tree = new Builder(dir).
                    pageFactory(Page.DefaultPageFactory.singleton).build();
            
            for (int i = 0; i < count; i += 2) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull("i = " + i, node);
                assertEquals(Integer.toString(i), node.getName());
                node.setCounter(1);
                DataTime attachment = new DataTime();
                attachment.setFirst(2 * i);
                attachment.setLast(2 * i + count);
                node.createMap().put("time", attachment);
                node.markChanged();
                node.release();
            }
            tree.close(false, close);
            tree = new Builder(dir).
                    pageFactory(Page.DefaultPageFactory.singleton).build();
            
            for (int i = 0; i < count; i++) {
                ConcurrentTreeNode node = tree.getNode(root, Integer.toString(i), true);
                assertNotNull(node);
                assertEquals(1, node.getLeaseCount());
                assertEquals(Integer.toString(i), node.getName());
                Map<String, TreeNodeData> attachments = node.getDataMap();
                assertNotNull(attachments);
                assertTrue(attachments.containsKey("time"));
                DataTime attachment = (DataTime) attachments.get("time");
                if (i % 2 == 0) {
                    assertEquals(2 * i, attachment.first());
                    assertEquals(2 * i + count, attachment.last());
                } else {
                    assertEquals(i, attachment.first());
                    assertEquals(i + count, attachment.last());
                }
                node.release();
            }
        } finally {
            if (dir != null) {
                LessFiles.deleteDir(dir);
            }
        }
    }


}

<code block>

package com.addthis.hydra.data.tree.concurrent;

import java.io.File;

import java.util.Iterator;
import java.util.Map;

import com.addthis.basis.util.ClosableIterator;

import com.addthis.hydra.data.tree.DataTreeNode;
import com.addthis.hydra.data.tree.ReadTree;
import com.addthis.hydra.data.tree.ReadTreeNode;
import com.addthis.hydra.data.tree.TreeNodeData;
import com.addthis.hydra.store.db.CloseOperation;

public class ConcurrentTreeConverter {

    public static void main(String[] args) throws Exception {
        int maxNodes = (args.length >= 3) ? Integer.parseInt(args[2]) : -1;
        new ConcurrentTreeConverter(new File(args[0]), new File(args[1]), maxNodes);
    }

    public ConcurrentTreeConverter(File readRoot, File writeRoot, int maxNodes) throws Exception {
        long mark = System.currentTimeMillis();
        ReadTree readTree = new ReadTree(readRoot);
        ConcurrentTree writeTree = new ConcurrentTree(writeRoot);
        long openTime = System.currentTimeMillis() - mark;
        long testTime = 0;
        try {
            mark += openTime;
            ReadTreeNode readNode = readTree.getRootNode();
            ConcurrentTreeNode writeNode = writeTree.getRootNode();
            explore(writeTree, writeNode, readNode, 0, maxNodes);
            testTime = System.currentTimeMillis() - mark;
        } catch (Exception ex) {
            ex.printStackTrace();
            throw ex;
        } finally {
            readTree.close();
            writeTree.close(true, CloseOperation.NONE);
        }
        System.out.println("nodeCount=" + nodeCount + " hasNodes=" + hasNodes + " maxLeafs=" +
                           maxLeafs + " maxDepth=" + maxDepth + " openTime=" + openTime + " testTime=" + testTime);
    }

    private int nodeCount;
    private int maxLeafs;
    private int hasNodes;
    private int maxDepth;

    private void generateNode(ConcurrentTree writeTree,
            ConcurrentTreeNode writeParent,
            ReadTreeNode readChild) {
        ConcurrentTreeNode writeNode = writeTree.getOrCreateNode(writeParent, readChild.getName(), null);
        writeNode.writeLock();
        if (readChild.hasNodes()) {
            writeNode.requireNodeDB();
        }
        writeNode.setCounter(readChild.getCounter());
        Map<String, TreeNodeData> readMap = readChild.getDataMap();
        if (readMap != null) {
            Map<String, TreeNodeData> writeMap = writeNode.createMap();
            for (Map.Entry<String, TreeNodeData> entry : readMap.entrySet()) {
                writeMap.put(entry.getKey(), entry.getValue());
            }
        }
        writeNode.markChanged();
        writeNode.writeUnlock();
        writeNode.release();
    }

    private void explore(ConcurrentTree writeTree,
            ConcurrentTreeNode writeNode,
            ReadTreeNode readNode, int depth,
            int maxNodes) throws Exception {
        int count = 0;
        if (maxNodes > 0 && nodeCount >= maxNodes) {
            return;
        }
        Iterator<DataTreeNode> iter = readNode.iterator();
        if (iter != null) {
            if (iter.hasNext()) {
                hasNodes++;
            }
            try {
                while (iter.hasNext()) {
                    count++;
                    ReadTreeNode readChild = (ReadTreeNode) iter.next();
                    generateNode(writeTree, writeNode, readChild);
                }
            } finally {
                if (iter instanceof ClosableIterator) {
                    ((ClosableIterator<DataTreeNode>) iter).close();
                }
            }
            iter = readNode.iterator();
            try {
                while (iter.hasNext()) {
                    ReadTreeNode readChild = (ReadTreeNode) iter.next();
                    ConcurrentTreeNode writeChild = writeTree.getNode(writeNode, readChild.getName(), false);
                    explore(writeTree, writeChild, readChild, depth + 1, maxNodes);
                }
            } finally {
                if (iter instanceof ClosableIterator) {
                    ((ClosableIterator<DataTreeNode>) iter).close();
                }
            }
        }
        maxLeafs = Math.max(count, maxLeafs);
        maxDepth = Math.max(depth, maxDepth);
        nodeCount++;
        if (nodeCount % 10000000 == 0) {
            System.out.println(".. nodeCount=" + nodeCount + " hasNodes=" + hasNodes + " maxLeafs=" + maxLeafs + " maxDepth=" + maxDepth);
        }
    }
}

<code block>

package com.addthis.hydra.job;

import javax.annotation.Nullable;

import com.addthis.hydra.job.mq.JobKey;


public class JobTaskMoveAssignment {

    private final JobKey jobKey;
    private final String sourceUUID;
    private final String targetUUID;
    private final boolean delete;
    private final boolean fromReplica;

    public JobTaskMoveAssignment(JobKey jobKey, String sourceUUID, @Nullable String targetUUID, boolean fromReplica, boolean delete) {
        this.jobKey = jobKey;
        this.sourceUUID = sourceUUID;
        this.targetUUID = targetUUID;
        this.fromReplica = fromReplica;
        this.delete = delete;
    }

    public JobKey getJobKey() {
        return jobKey;
    }

    public String getSourceUUID() {
        return sourceUUID;
    }

    public String getTargetUUID() {
        return targetUUID;
    }

    public boolean isFromReplica() {
        return fromReplica;
    }

    public boolean delete() {
        return delete;
    }

    @Override
    public String toString() {
        return "JobTaskMoveAssignment{" +
               "jobKey=" + jobKey +
               ", sourceUUID='" + sourceUUID + '\'' +
               ", targetUUID='" + targetUUID + '\'' +
               ", fromReplica=" + fromReplica +
               '}';
    }
}

<code block>


package com.addthis.hydra.job.web.resources;

import javax.annotation.Nonnull;
import javax.ws.rs.DefaultValue;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.QueryParam;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;

import com.addthis.codec.jackson.Jackson;
import com.addthis.codec.json.CodecJSON;
import com.addthis.hydra.job.HostFailWorker;
import com.addthis.hydra.job.auth.PermissionsManager;
import com.addthis.hydra.job.spawn.HealthCheckResult;
import com.addthis.hydra.job.spawn.Spawn;
import com.addthis.hydra.job.spawn.balancer.SpawnBalancer;
import com.addthis.hydra.job.spawn.balancer.SpawnBalancerConfig;
import com.addthis.hydra.job.spawn.SystemManager;
import com.addthis.hydra.job.store.DataStoreUtil.DataStoreType;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

@Path("/system")
public class SystemResource {

    private static final Logger log = LoggerFactory.getLogger(SystemResource.class);

    @Nonnull private final SystemManager systemManager;
    @Nonnull private final SpawnBalancer spawnBalancer;
    @Nonnull private final HostFailWorker hostFailWorker;
    @Nonnull private final PermissionsManager permissionsManager;


    public SystemResource(Spawn spawn) {
        this.systemManager = spawn.getSystemManager();
        this.spawnBalancer = spawn.getSpawnBalancer();
        this.hostFailWorker = spawn.getHostFailWorker();
        this.permissionsManager = spawn.getPermissionsManager();
    }

    @GET
    @Path("/quiesce")
    @Produces(MediaType.APPLICATION_JSON)
    public Response quiesceCluster(@QueryParam("quiesce") String quiesce,
                                   @QueryParam("user") String user,
                                   @QueryParam("token") String token,
                                   @QueryParam("sudo") String sudo) {
        try {
            if (permissionsManager.adminAction(user, token, sudo)) {
                boolean quiesced = systemManager.quiesceCluster(quiesce.equals("1"), user);
                String json = Jackson.defaultMapper().createObjectNode()
                        .put("quiesced", (quiesced ? "1" : "0")).toString();
                return Response.ok(json).build();
            } else {
                return Response.status(Response.Status.FORBIDDEN).build();
            }
        } catch (Exception ex) {
            return Response.serverError().entity(ex.getMessage()).build();
        }
    }

    @GET
    @Path("/balance.params.get")
    @Produces(MediaType.APPLICATION_JSON)
    public Response getBalanceParams() {
        try {
            return Response.ok(CodecJSON.encodeString(spawnBalancer.getConfig())).build();
        } catch (Exception e) {
            return Response.serverError().entity("Error getting balance parameters: " + e.getMessage()).build();
        }
    }

    @GET
    @Path("/balance.params.set")
    @Produces(MediaType.APPLICATION_JSON)
    public Response setBalanceParams(@QueryParam("params") String params) {
        try {
            SpawnBalancerConfig config = CodecJSON.decodeString(SpawnBalancerConfig.class, params);
            spawnBalancer.setConfig(config);
            spawnBalancer.saveConfigToDataStore();
            return Response.ok().build();
        } catch (Exception e) {
            String err = "Failed to set SpawnBalanceConfig: " + e.getMessage();
            log.warn(err, e);
            return Response.serverError().entity(err).build();
        }
    }

    @GET
    @Path("/hostfailworker.obeyTaskLimit.set")
    @Produces(MediaType.APPLICATION_JSON)
    public Response setObeyTaskLimit(@QueryParam("obey") boolean obey) {
        hostFailWorker.setObeyTaskSlots(obey);
        return Response.ok().build();
    }

    @GET
    @Path("/git.properties")
    @Produces(MediaType.APPLICATION_JSON)
    public Response getGitProperties() {
        try {
            return Response.ok(CodecJSON.encodeString(systemManager.getGitProperties())).build();
        } catch (Exception e) {
            String err = "Error loading git properties: " + e.getMessage();
            log.warn(err, e);
            return Response.serverError().entity(err).build();
        }
    }

    @GET
    @Path("/datastore.cutover")
    @Produces(MediaType.TEXT_PLAIN)
    public Response datastoreCutover(
            @QueryParam("src") String src,
            @QueryParam("tar") String tar,
            @QueryParam("checkAll") int checkAll) {

        try {
            DataStoreType sourceType = DataStoreType.valueOf(src);
            DataStoreType targetType = DataStoreType.valueOf(tar);
            boolean checkAllWrites = (checkAll == 1);
            systemManager.cutoverDataStore(sourceType, targetType, checkAllWrites);
            return Response.ok("Cut over successfully.").build();
        } catch (IllegalStateException e) {
            return Response.serverError().entity("Spawn must be quiesced to cut over stored data.").build();
        } catch (IllegalArgumentException e) {
            return Response.status(Response.Status.BAD_REQUEST).entity(e.getMessage()).build();
        } catch (Exception e) {
            String err = "Error cutting over data store: " + e.getMessage();
            log.error(err, e);
            return Response.serverError().entity(err).build();
        }
    }

    
    @GET
    @Path("/healthcheck")
    @Produces(MediaType.APPLICATION_JSON)
    public Response healthCheck(
            @QueryParam("retries") @DefaultValue("3") int retries,
            @QueryParam("details") @DefaultValue("false") boolean details) {
        try {
            HealthCheckResult result = systemManager.healthCheck(retries);
            if (details) {
                return Response.ok(CodecJSON.encodeString(result)).build();
            } else {
                return Response.ok(String.valueOf(result.isEverythingOK())).build();
            }
            
        } catch (Exception e) {
            String err = "Error running health check: " + e.getMessage();
            log.error(err, e);
            return Response.serverError().entity(err).build();
        }
    }

}

<code block>

package com.addthis.hydra.job.mq;

import javax.annotation.Nullable;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;

import com.addthis.hydra.minion.Minion;

import com.google.common.base.Objects;

import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonTypeInfo;

@JsonIgnoreProperties({"messageType", "totalLive", "readOnly"})
@JsonTypeInfo(use = JsonTypeInfo.Id.CLASS, include = JsonTypeInfo.As.PROPERTY, defaultImpl = HostState.class)
public class HostState implements HostMessage {

    @JsonProperty private String host;
    @JsonProperty private int port;
    @JsonProperty private String uuid;
    @JsonProperty private String user;
    @JsonProperty private String path;
    @JsonProperty private String group;
    
    
    @JsonProperty private boolean up;
    @JsonProperty private long time;
    @JsonProperty private long uptime;
    @JsonProperty private int availableTaskSlots;
    @JsonProperty private int maxTaskSlots;
    @JsonProperty private JobKey[] running;
    @JsonProperty private JobKey[] replicating;
    @JsonProperty private JobKey[] backingup;
    @JsonProperty private JobKey[] stopped;
    @JsonProperty private JobKey[] replicas;
    @JsonProperty private JobKey[] incompleteReplicas;
    @JsonProperty private JobKey[] queued;
    @JsonProperty private HostCapacity used;
    @JsonProperty private HostCapacity max;
    @JsonProperty private boolean dead;
    @JsonProperty private long lastUpdateTime;
    @JsonProperty private double histQueueSize;
    @JsonProperty private double histWaitTime;
    
    @JsonProperty private HashMap<String, Double> jobRuntimes = new HashMap<>();
    @JsonProperty private boolean diskReadOnly;
    @JsonProperty private boolean disabled;
    @JsonProperty private double meanActiveTasks;
    @JsonProperty private String minionTypes;

    
    private HashMap<String, Integer> jobTaskCountMap;

    @JsonCreator
    private HostState() {}

    public HostState(String hostUuid) {
        this.uuid = hostUuid;
    }

    @Override
    public String getHostUuid() {
        return uuid;
    }

    public void setUuid(String uuid) {
        this.uuid = uuid;
    }

    @JsonProperty
    public void setHostUuid(String uuid) {
        this.uuid = uuid;
    }


    public void setUpdated() {
        lastUpdateTime = System.currentTimeMillis();
    }

    public boolean hasLive(@Nullable JobKey jobKey) {
        if (stopped != null && Arrays.asList(stopped).contains(jobKey)) {
            return true;
        }
        if (queued != null && Arrays.asList(queued).contains(jobKey)) {
            return true;
        }
        if (running != null && Arrays.asList(running).contains(jobKey)) {
            return true;
        }
        if (replicating != null && Arrays.asList(replicating).contains(jobKey)) {
            return true;
        }
        if (backingup != null && Arrays.asList(backingup).contains(jobKey)) {
            return true;
        }
        return false;
    }

    public boolean hasIncompleteReplica(JobKey jobKey) {
        return (incompleteReplicas != null) && Arrays.asList(incompleteReplicas).contains(jobKey);
    }

    public List<JobKey> allJobKeys() {
        List<JobKey> rv = new ArrayList<>();
        for (JobKey[] jobKeys : Arrays.asList(stopped, queued, running, replicating, backingup, replicas)) {
            if (jobKeys != null) {
                rv.addAll(Arrays.asList(jobKeys));
            }
        }
        return rv;
    }

    public Integer addJob(String jobId) {
        if (this.jobTaskCountMap == null) {
            jobTaskCountMap = new HashMap<>();
        }
        int currentCount = 0;
        if (jobTaskCountMap.containsKey(jobId)) {
            currentCount = jobTaskCountMap.get(jobId);
        }
        return jobTaskCountMap.put(jobId, currentCount + 1);
    }

    public void generateJobTaskCountMap() {
        jobTaskCountMap = new HashMap<>();
        List<JobKey[]> activeJobsSources = Arrays.asList(stopped, queued, running, replicas);
        for (JobKey[] source : activeJobsSources) {
            if (source == null) {
                continue;
            }
            for (JobKey jobKey : source) {
                if (jobKey == null) {
                    continue;
                }
                Integer oldCount = jobTaskCountMap.get(jobKey.getJobUuid());
                int newCount;
                if (oldCount != null) {
                    newCount = 1 + oldCount;
                } else {
                    newCount = 1;
                }
                jobTaskCountMap.put(jobKey.getJobUuid(), newCount);
            }
        }
    }

    public Integer getTaskCount(String jobId) {
        if (jobTaskCountMap == null) {
            generateJobTaskCountMap();
        }
        if ((jobTaskCountMap != null) && jobTaskCountMap.containsKey(jobId)) {
            return jobTaskCountMap.get(jobId);
        } else {
            return 0;
        }
    }

    public boolean canMirrorTasks() {
        return up && !dead && !diskReadOnly && !disabled;
    }

    public boolean hasType(String type) {
        if (minionTypes == null) {
            minionTypes = Minion.defaultMinionType;
        }
        if (minionTypes.contains(",")) {
            return Arrays.asList(minionTypes.split(",")).contains(type);
        }
        return type.equals(minionTypes);
    }

    public int countTotalLive() {
        int total = 0;
        for (JobKey[] keys : Arrays.asList(stopped, running, replicating, backingup, queued)) {
            if (keys != null) {
                total += keys.length;
            }
        }
        return total;
    }

    @Override
    public String toString() {
        return Objects.toStringHelper(this)
                .add("uuid", getHostUuid())
                .add("last-update-time", getLastUpdateTime())
                .add("host", getHost())
                .add("port", getPort())
                .add("group", getGroup())
                .add("time", getTime())
                .add("uptime", getUptime())
                        
                        
                        
                        
                        
                .add("used", getUsed())
                .add("user", getUser())
                .add("path", getPath())
                .add("max", getMax())
                .add("up", isUp())
                .add("dead", isDead())
                .add("diskReadOnly", isDiskReadOnly())
                .toString();
    }

    
    
    

    public long getLastUpdateTime() {
        return lastUpdateTime;
    }

    public void setLastUpdateTime(long lastUpdateTime) {
        this.lastUpdateTime = lastUpdateTime;
    }

    public double getHistQueueSize() {
        return histQueueSize;
    }

    public void setHistQueueSize(double size) {
        this.histQueueSize = size;
    }

    public double getHistWaitTime() {
        return histWaitTime;
    }

    public void setHistWaitTime(double seconds) {
        this.histWaitTime = seconds;
    }

    public String getHost() {
        return host;
    }

    public void setHost(String host) {
        this.host = host;
    }

    public int getPort() {
        return port;
    }

    public void setPort(int port) {
        this.port = port;
    }

    public String getGroup() {
        return group;
    }

    public void setGroup(String group) {
        this.group = group;
    }

    public boolean isUp() {
        return up;
    }

    public void setUp(boolean up) {
        this.up = up;
    }

    public long getTime() {
        return time;
    }

    public void setTime(long time) {
        this.time = time;
    }

    public long getUptime() {
        return uptime;
    }

    public void setUptime(long uptime) {
        this.uptime = uptime;
    }

    public JobKey[] getRunning() {
        return running;
    }

    public void setRunning(JobKey[] running) {
        this.running = running;
    }

    
    public JobKey[] getReplicating() {
        return replicating;
    }

    public void setReplicating(JobKey[] replicating) {
        this.replicating = replicating;
    }

    
    public JobKey[] getBackingup() {
        return backingup;
    }

    public void setBackingup(JobKey[] backingup) {
        this.backingup = backingup;
    }

    public void setReplicas(JobKey[] replicas) {
        this.replicas = replicas;
    }

    public JobKey[] getReplicas() {
        return replicas;
    }

    public void setStopped(JobKey[] stopped) {
        this.stopped = stopped;
    }

    public JobKey[] getStopped() {
        return stopped;
    }

    public JobKey[] getQueued() {
        return queued;
    }

    public void setQueued(JobKey[] queued) {
        this.queued = queued;
    }

    public HostCapacity getUsed() {
        return used;
    }

    public void setUsed(HostCapacity used) {
        this.used = used;
    }

    public String getUser() {
        return user;
    }

    public void setUser(String user) {
        this.user = user;
    }

    public String getPath() {
        return path;
    }

    public void setPath(String path) {
        this.path = path;
    }

    public HostCapacity getMax() {
        return max;
    }

    public void setMax(HostCapacity max) {
        this.max = max;
    }

    public void setDead(boolean dead) {
        this.dead = dead;
    }

    public boolean isDead() {
        return dead;
    }

    public boolean isDiskReadOnly() {
        return this.diskReadOnly;
    }

    public void setDiskReadOnly(boolean diskReadOnly) {
        this.diskReadOnly = diskReadOnly;
    }

    public int getAvailableTaskSlots() {
        return availableTaskSlots;
    }

    public void setAvailableTaskSlots(int availableTaskSlots) {
        this.availableTaskSlots = availableTaskSlots;
    }

    public boolean isDisabled() {
        return disabled;
    }

    public void setDisabled(boolean disabled) {
        this.disabled = disabled;
    }

    public double getMeanActiveTasks() {
        return meanActiveTasks;
    }

    public void setMeanActiveTasks(double meanActiveTasks) {
        this.meanActiveTasks = meanActiveTasks;
    }

    public String getMinionTypes() {
        return minionTypes;
    }

    public void setMinionTypes(String minionTypes) {
        this.minionTypes = minionTypes;
    }

    public JobKey[] getIncompleteReplicas() {
        return incompleteReplicas;
    }

    public void setIncompleteReplicas(JobKey[] incompleteReplicas) {
        this.incompleteReplicas = incompleteReplicas;
    }

    public int getMaxTaskSlots() {
        return maxTaskSlots;
    }

    public void setMaxTaskSlots(int maxTaskSlots) {
        this.maxTaskSlots = maxTaskSlots;
    }
}

<code block>

package com.addthis.hydra.job.spawn;

import javax.annotation.Nonnull;
import javax.annotation.Nullable;
import javax.ws.rs.core.Response;

import java.io.File;
import java.io.IOException;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.ListIterator;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.SortedSet;
import java.util.TreeSet;
import java.util.UUID;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

import java.text.ParseException;

import com.addthis.basis.util.JitterClock;
import com.addthis.basis.util.LessFiles;
import com.addthis.basis.util.LessStrings;
import com.addthis.basis.util.Parameter;
import com.addthis.basis.util.RollingLog;
import com.addthis.basis.util.TokenReplacerOverflowException;

import com.addthis.bark.StringSerializer;
import com.addthis.bark.ZkUtil;
import com.addthis.codec.annotations.Time;
import com.addthis.codec.codables.Codable;
import com.addthis.codec.config.Configs;
import com.addthis.codec.jackson.Jackson;
import com.addthis.codec.json.CodecJSON;
import com.addthis.hydra.common.util.CloseTask;
import com.addthis.hydra.job.HostFailWorker;
import com.addthis.hydra.job.IJob;
import com.addthis.hydra.job.Job;
import com.addthis.hydra.job.JobConfigManager;
import com.addthis.hydra.job.JobDefaults;
import com.addthis.hydra.job.JobEvent;
import com.addthis.hydra.job.JobExpand;
import com.addthis.hydra.job.JobParameter;
import com.addthis.hydra.job.JobState;
import com.addthis.hydra.job.JobTask;
import com.addthis.hydra.job.JobTaskDirectoryMatch;
import com.addthis.hydra.job.JobTaskErrorCode;
import com.addthis.hydra.job.JobTaskMoveAssignment;
import com.addthis.hydra.job.JobTaskReplica;
import com.addthis.hydra.job.JobTaskState;
import com.addthis.hydra.job.RebalanceOutcome;
import com.addthis.hydra.job.alert.JobAlertManager;
import com.addthis.hydra.job.alert.JobAlertManagerImpl;
import com.addthis.hydra.job.alias.AliasManager;
import com.addthis.hydra.job.alias.AliasManagerImpl;
import com.addthis.hydra.job.auth.PermissionsManager;
import com.addthis.hydra.job.backup.ScheduledBackupType;
import com.addthis.hydra.job.entity.JobCommand;
import com.addthis.hydra.job.entity.JobCommandManager;
import com.addthis.hydra.job.entity.JobEntityManager;
import com.addthis.hydra.job.entity.JobMacro;
import com.addthis.hydra.job.entity.JobMacroManager;
import com.addthis.hydra.job.mq.CommandTaskDelete;
import com.addthis.hydra.job.mq.CommandTaskKick;
import com.addthis.hydra.job.mq.CommandTaskReplicate;
import com.addthis.hydra.job.mq.CommandTaskRevert;
import com.addthis.hydra.job.mq.CommandTaskStop;
import com.addthis.hydra.job.mq.CoreMessage;
import com.addthis.hydra.job.mq.HostMessage;
import com.addthis.hydra.job.mq.HostState;
import com.addthis.hydra.job.mq.JobKey;
import com.addthis.hydra.job.mq.ReplicaTarget;
import com.addthis.hydra.job.mq.StatusTaskBackup;
import com.addthis.hydra.job.mq.StatusTaskBegin;
import com.addthis.hydra.job.mq.StatusTaskCantBegin;
import com.addthis.hydra.job.mq.StatusTaskEnd;
import com.addthis.hydra.job.mq.StatusTaskPort;
import com.addthis.hydra.job.mq.StatusTaskReplica;
import com.addthis.hydra.job.mq.StatusTaskReplicate;
import com.addthis.hydra.job.mq.StatusTaskRevert;
import com.addthis.hydra.job.spawn.JobOnFinishStateHandler.JobOnFinishState;
import com.addthis.hydra.job.spawn.balancer.RebalanceType;
import com.addthis.hydra.job.spawn.balancer.RebalanceWeight;
import com.addthis.hydra.job.spawn.balancer.SpawnBalancer;
import com.addthis.hydra.job.store.DataStoreUtil;
import com.addthis.hydra.job.store.JobStore;
import com.addthis.hydra.job.store.SpawnDataStore;
import com.addthis.hydra.job.store.SpawnDataStoreKeys;
import com.addthis.hydra.job.web.SpawnService;
import com.addthis.hydra.job.web.SpawnServiceConfiguration;
import com.addthis.hydra.minion.Minion;
import com.addthis.hydra.task.run.TaskExitState;
import com.addthis.hydra.util.DirectedGraph;
import com.addthis.hydra.util.WebSocketManager;
import com.addthis.maljson.JSONArray;
import com.addthis.maljson.JSONObject;
import com.addthis.meshy.service.file.FileReference;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.base.Joiner;
import com.google.common.collect.ImmutableMap;

import com.fasterxml.jackson.annotation.JacksonInject;
import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.yammer.metrics.Metrics;

import org.apache.curator.framework.CuratorFramework;
import org.apache.zookeeper.KeeperException;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import static com.addthis.hydra.job.store.SpawnDataStoreKeys.MINION_DEAD_PATH;
import static com.addthis.hydra.job.store.SpawnDataStoreKeys.SPAWN_QUEUE_PATH;
import static com.google.common.base.Preconditions.checkArgument;
import static java.util.concurrent.TimeUnit.MILLISECONDS;


@JsonAutoDetect(getterVisibility = JsonAutoDetect.Visibility.NONE,
                isGetterVisibility = JsonAutoDetect.Visibility.NONE,
                setterVisibility = JsonAutoDetect.Visibility.NONE)
public class Spawn implements Codable, AutoCloseable {
    private static final Logger log = LoggerFactory.getLogger(Spawn.class);

    

    static final int DEFAULT_REPLICA_COUNT = Parameter.intValue("spawn.defaultReplicaCount", 1);
    static final boolean ENABLE_JOB_FIXDIRS_ONCOMPLETE = Parameter.boolValue("job.fixdirs.oncomplete", true);

    public static final long inputMaxNumberOfCharacters = Parameter.longValue("spawn.input.max.length", 1_000_000);

    private static final int clientDropTimeMillis = Parameter.intValue("spawn.client.drop.time", 60_000);
    private static final int clientDropQueueSize  = Parameter.intValue("spawn.client.drop.queue", 2000);

    

    private static final boolean eventLogCompress = Parameter.boolValue("spawn.eventlog.compress", true);
    private static final int logMaxAge  = Parameter.intValue("spawn.event.log.maxAge", 60 * 60 * 1000);
    private static final int logMaxSize = Parameter.intValue("spawn.event.log.maxSize", 100 * 1024 * 1024);
    private static final String logDir = Parameter.value("spawn.event.log.dir", "log");

    

    public static void main(String[] args) throws Exception {
        Spawn spawn = Configs.newDefault(Spawn.class);
        spawn.startWebInterface();
        
        Runtime.getRuntime().addShutdownHook(new Thread(new CloseTask(spawn), "Spawn Shutdown Hook"));
    }

    SpawnQueuesByPriority taskQueuesByPriority = new SpawnQueuesByPriority();

    private SpawnMQ spawnMQ;
    private SpawnService spawnService;

    private volatile int lastQueueSize = 0;

    final Lock jobLock = new ReentrantLock();
    private final AtomicBoolean shuttingDown = new AtomicBoolean(false);
    private final BlockingQueue<String> jobUpdateQueue = new LinkedBlockingQueue<>();
    private final SpawnJobFixer spawnJobFixer = new SpawnJobFixer(this);
    
    private final WebSocketManager webSocketManager = new WebSocketManager();

    @Nonnull public final HostManager hostManager;

    @Nonnull final SpawnState spawnState;
    @Nonnull final ConcurrentMap<String, ClientEventListener> listeners;
    @Nonnull final SpawnFormattedLogger spawnFormattedLogger;

    @Nonnull final PermissionsManager permissionsManager;
    @Nonnull final JobDefaults jobDefaults;

    @Nonnull private final File stateFile;
    @Nonnull private final ExecutorService expandKickExecutor;
    @Nonnull private final ScheduledExecutorService scheduledExecutor;
    @Nonnull private final CuratorFramework zkClient;
    @Nonnull private final SpawnDataStore spawnDataStore;
    @Nonnull private final JobConfigManager jobConfigManager;
    @Nonnull private final AliasManager aliasManager;
    @Nonnull private final JobAlertManager jobAlertManager;
    @Nonnull private final SpawnMesh spawnMesh;
    @Nonnull private final JobEntityManager<JobMacro> jobMacroManager;
    @Nonnull private final JobEntityManager<JobCommand> jobCommandManager;
    @Nonnull private final JobOnFinishStateHandler jobOnFinishStateHandler;
    @Nonnull private final SpawnBalancer balancer;
    @Nonnull private final HostFailWorker hostFailWorker;
    @Nonnull private final SystemManager systemManager;
    @Nonnull private final RollingLog eventLog;

    @Nullable private final JobStore jobStore;

    @JsonCreator
    private Spawn(@JsonProperty("debug") String debug,
                  @JsonProperty(value = "queryPort", required = true) int queryPort,
                  @JsonProperty("queryHttpHost") String queryHttpHost,
                  @JsonProperty("httpHost") String httpHost,
                  @JsonProperty("dataDir") File dataDir,
                  @JsonProperty("stateFile") File stateFile,
                  @JsonProperty("expandKickExecutor") ExecutorService expandKickExecutor,
                  @JsonProperty("scheduledExecutor") ScheduledExecutorService scheduledExecutor,
                  @Time(MILLISECONDS) @JsonProperty(value = "taskQueueDrainInterval", required = true)
                  int taskQueueDrainInterval,
                  @Time(MILLISECONDS) @JsonProperty(value = "hostStatusRequestInterval", required = true)
                  int hostStatusRequestInterval,
                  @Time(MILLISECONDS) @JsonProperty(value = "queueKickInterval", required = true)
                  int queueKickInterval,
                  @Time(MILLISECONDS) @JsonProperty("jobTaskUpdateHeartbeatInterval")
                  int jobTaskUpdateHeartbeatInterval,
                  @Nullable @JsonProperty("structuredLogDir") File structuredLogDir,
                  @Nullable @JsonProperty("jobStore") JobStore jobStore,
                  @Nullable @JsonProperty("queueType") String queueType,
                  @Nullable @JacksonInject CuratorFramework providedZkClient,
                  @JsonProperty(value = "permissionsManager", required = true) PermissionsManager permissionsManager,
                  @JsonProperty(value = "jobDefaults", required = true) JobDefaults jobDefaults) throws Exception {
        LessFiles.initDirectory(dataDir);
        this.stateFile = stateFile;
        this.permissionsManager = permissionsManager;
        this.jobDefaults = jobDefaults;
        if (stateFile.exists() && stateFile.isFile()) {
            spawnState = Jackson.defaultMapper().readValue(stateFile, SpawnState.class);
        } else {
            spawnState = Jackson.defaultCodec().newDefault(SpawnState.class);
        }
        File webDir = new File("web");
        this.listeners = new ConcurrentHashMap<>();
        this.expandKickExecutor = expandKickExecutor;
        this.scheduledExecutor = scheduledExecutor;
        if (structuredLogDir == null) {
            this.spawnFormattedLogger = SpawnFormattedLogger.createNullLogger();
        } else {
            this.spawnFormattedLogger =  SpawnFormattedLogger.createFileBasedLogger(structuredLogDir);
        }
        if (providedZkClient == null) {
            this.zkClient = ZkUtil.makeStandardClient();
        } else {
            this.zkClient = providedZkClient;
        }
        this.hostManager = new HostManager(zkClient);
        this.spawnDataStore = DataStoreUtil.makeCanonicalSpawnDataStore(true);
        this.systemManager = new SystemManagerImpl(
                this, debug, queryHttpHost + ":" + queryPort,
                httpHost + ":" + SpawnServiceConfiguration.SINGLETON.webPort,
                SpawnServiceConfiguration.SINGLETON.authenticationTimeout,
                SpawnServiceConfiguration.SINGLETON.sudoTimeout);
        this.jobConfigManager = new JobConfigManager(spawnDataStore);
        
        log.info("[init] beginning to load stats from data store");
        aliasManager = new AliasManagerImpl(spawnDataStore);
        jobMacroManager = new JobMacroManager(this);
        jobCommandManager = new JobCommandManager(this);
        jobOnFinishStateHandler = new JobOnFinishStateHandlerImpl(this);
        loadSpawnQueue();
        
        for (Job job : spawnState.jobs.values()) {
            if (job.getSubmitTime() == null) {
                job.setSubmitTime(System.currentTimeMillis());
            }
        }
        loadJobs();
        
        
        
        hostFailWorker = new HostFailWorker(this, hostManager, scheduledExecutor);
        balancer = new SpawnBalancer(this, hostManager);

        
        this.spawnMesh = new SpawnMesh(this);
        
        if ("rabbit".equals(queueType)) {
            log.info("[init] connecting to rabbit message queue");
            this.spawnMQ = new SpawnMQImpl(zkClient, this);
            this.spawnMQ.connectToMQ(getUuid());
        } else if (queueType == null) {
            log.info("[init] skipping message queue");
        } else {
            throw new IllegalArgumentException("queueType (" + queueType +
                                               ") must be either a valid message queue type or null");
        }

        
        
        
        hostFailWorker.initFailHostTaskSchedule();
        
        jobAlertManager = new JobAlertManagerImpl(this, scheduledExecutor);
        
        scheduledExecutor.scheduleWithFixedDelay(new UpdateEventRunnable(this), 0, 1, TimeUnit.MINUTES);
        scheduledExecutor.scheduleWithFixedDelay(new JobRekickTask(this), 0, 500, MILLISECONDS);
        scheduledExecutor.scheduleWithFixedDelay(this::drainJobTaskUpdateQueue,
                                                 taskQueueDrainInterval, taskQueueDrainInterval, MILLISECONDS);
        scheduledExecutor.scheduleWithFixedDelay(this::jobTaskUpdateHeartbeatCheck,
                                                 jobTaskUpdateHeartbeatInterval, jobTaskUpdateHeartbeatInterval,
                                                 MILLISECONDS);
        
        scheduledExecutor.scheduleWithFixedDelay(this::requestHostsUpdate,
                                                 hostStatusRequestInterval, hostStatusRequestInterval, MILLISECONDS);
        scheduledExecutor.scheduleWithFixedDelay(() -> {
            kickJobsOnQueue();
            writeSpawnQueue();
        }, queueKickInterval, queueKickInterval, MILLISECONDS);
        balancer.startAutobalanceTask();
        balancer.startTaskSizePolling();
        this.jobStore = jobStore;
        this.eventLog = new RollingLog(new File(logDir, "events-jobs"), "job",
                                       eventLogCompress, logMaxSize, logMaxAge);
        Metrics.newGauge(Spawn.class, "minionsDown", new DownMinionGauge(hostManager));
        writeState();
    }

    public void startWebInterface() throws Exception {
        spawnService = new SpawnService(this, SpawnServiceConfiguration.SINGLETON);
        spawnService.start();
    }

    void writeState() {
        try {
            LessFiles.write(stateFile, CodecJSON.INSTANCE.encode(spawnState), false);
        } catch (Exception e) {
            log.warn("Failed to write spawn state to log file at {}", stateFile, e);
        }
    }

    @Nonnull
    public HostFailWorker getHostFailWorker() {
        return hostFailWorker;
    }

    public SpawnBalancer getSpawnBalancer() {
        return balancer;
    }

    @Nonnull
    public PermissionsManager getPermissionsManager() { return permissionsManager; }

    @Nonnull
    public AliasManager getAliasManager() {
        return aliasManager;
    }
    
    @Nonnull
    public JobAlertManager getJobAlertManager() {
        return jobAlertManager;
    }
    
    @Nonnull
    public JobEntityManager<JobMacro> getJobMacroManager() {
        return jobMacroManager;
    }
    
    @Nonnull
    public JobEntityManager<JobCommand> getJobCommandManager() {
        return jobCommandManager;
    }
    
    @Nonnull
    public SystemManager getSystemManager() {
        return systemManager;
    }

    public void acquireJobLock() {
        jobLock.lock();
    }

    public void releaseJobLock() {
        jobLock.unlock();
    }

    public String getUuid() {
        return spawnState.uuid;
    }

    private void closeZkClients() {
        spawnDataStore.close();
        zkClient.close();
    }

    public void setSpawnMQ(SpawnMQ spawnMQ) {
        this.spawnMQ = spawnMQ;
    }

    @VisibleForTesting public void loadSpawnQueue() throws Exception {
        String queueFromZk = spawnDataStore.get(SPAWN_QUEUE_PATH);
        if (queueFromZk == null) {
            return;
        }
        try {
            taskQueuesByPriority = new ObjectMapper().readValue(queueFromZk, SpawnQueuesByPriority.class);
        } catch (Exception ex) {
            log.warn("[task.queue] exception during spawn queue deserialization: ", ex);
        }
    }

    @VisibleForTesting public void writeSpawnQueue() {
        ObjectMapper om = new ObjectMapper();
        try {
            taskQueuesByPriority.lock();
            try {
                spawnDataStore.put(SPAWN_QUEUE_PATH, new String(om.writeValueAsBytes(taskQueuesByPriority)));
            } finally {
                taskQueuesByPriority.unlock();
            }
        } catch (Exception ex) {
            log.warn("[task.queue] exception during spawn queue serialization", ex);
        }
    }

    @VisibleForTesting
    protected void loadJobs() {
        jobLock.lock();
        try {
            for (IJob iJob : jobConfigManager.getJobs().values()) {
                if (iJob != null) {
                    putJobInSpawnState(new Job(iJob));
                }
            }
        } finally {
            jobLock.unlock();
        }
        Thread loadDependencies = new Thread(() -> {
            Set<String> jobIds = spawnState.jobs.keySet();
            for (String jobId : jobIds) {
                IJob job = getJob(jobId);
                if (job != null) {
                    updateJobDependencies(jobId);
                }
            }
        }, "spawn job dependency calculator");
        loadDependencies.setDaemon(true);
        loadDependencies.start();
    }

    

    public ClientEventListener getClientEventListener(String id) {
        ClientEventListener listener = listeners.get(id);
        if (listener == null) {
            listener = new ClientEventListener();
            listeners.put(id, listener);
        }
        listener.lastSeen = System.currentTimeMillis();
        return listener;
    }

    public HostState markHostStateDead(String hostUUID) {
        HostState state = hostManager.getHostState(hostUUID);
        if (state != null) {
            state.setDead(true);
            state.setUpdated();
            
            spawnDataStore.delete(Minion.MINION_ZK_PATH + hostUUID);
            try {
                zkClient.create().creatingParentsIfNeeded().forPath(MINION_DEAD_PATH + "/" + hostUUID, null);
            } catch (KeeperException.NodeExistsException ne) {
                
            } catch (Exception e) {
                log.error("Unable to add host: {} to " + MINION_DEAD_PATH, hostUUID, e);
            }
            sendHostUpdateEvent(state);
            hostManager.updateHostState(state);
        }
        return state;
    }

    public Collection<String> listAvailableHostIds() {
        return hostManager.minionMembers.getMemberSet();
    }

    public void requestHostsUpdate() {
        try {
            spawnMQ.sendControlMessage(new HostState(HostMessage.ALL_HOSTS));
        } catch (Exception e) {
            log.warn("unable to request host state update: ", e);
        }
    }

    public Set<String> getDataSources(String jobId) {
        HashSet<String> dataSources = new HashSet<>();
        Job job = this.getJob(jobId);
        if (job == null || job.getParameters() == null) {
            return dataSources;
        }
        jobLock.lock();
        try {
            for (JobParameter param : job.getParameters()) {
                String value = param.getValue();
                if (LessStrings.isEmpty(value)) {
                    value = param.getDefaultValue();
                }
                if (value != null) {
                    try {
                        value = JobExpand.macroExpand(this, value);
                    } catch (TokenReplacerOverflowException ex) {
                        log.error("Token replacement overflow for input '{}'", value);
                    }
                }
                if (value != null && spawnState.jobs.containsKey(value)) {
                    dataSources.add(value);
                }
            }
        } finally {
            jobLock.unlock();
        }
        return dataSources;
    }

    public DirectedGraph<String> getJobDependencies() {
        return spawnState.jobDependencies;
    }

    
    public Map<ScheduledBackupType, SortedSet<Long>> getJobBackups(String jobUUID, int nodeId) throws IOException, ParseException {
        Map<ScheduledBackupType, SortedSet<Long>> fileDates = new HashMap<>();
        for (ScheduledBackupType backupType : ScheduledBackupType.getBackupTypes().values()) {
            final String typePrefix = "*/" + jobUUID + "/" + ((nodeId < 0) ? "*" : Integer.toString(nodeId)) + "/" + backupType.getPrefix() + "*";
            List<FileReference> files = new ArrayList<>(spawnMesh.getClient().listFiles(new String[]{typePrefix}));
            fileDates.put(backupType, new TreeSet<>(Collections.reverseOrder()));
            for (FileReference file : files) {
                String filename = file.name.split("/")[4];
                fileDates.get(backupType).add(backupType.parseDateFromName(filename).getTime());
            }
        }
        return fileDates;
    }

    public boolean isSpawnMeshAvailable() {
        return spawnMesh.getClient() != null;
    }

    public void deleteHost(String hostuuid) {
        HostFailWorker.FailState failState = hostFailWorker.getFailureState(hostuuid);
        if (failState == HostFailWorker.FailState.FAILING_FS_DEAD || failState == HostFailWorker.FailState.FAILING_FS_OKAY) {
            log.warn("Refused to drop host because it was in the process of being failed {}", hostuuid);
            throw new RuntimeException("Cannot drop a host that is in the process of being failed");
        }
        synchronized (hostManager.monitored) {
            HostState state = hostManager.monitored.remove(hostuuid);
            if (state != null) {
                log.info("Deleted host {}", hostuuid);
                sendHostUpdateEvent("host.delete", state);
            } else {
                log.warn("Attempted to delete host {} But it was not found", hostuuid);
            }
        }
    }

    public Collection<Job> listJobs() {
        ArrayList<Job> clones = new ArrayList<>(spawnState.jobs.size());
        jobLock.lock();
        try {
            for (Job job : spawnState.jobs.values()) {
                clones.add(job);
            }
            return clones;
        } finally {
            jobLock.unlock();
        }
    }

    public Collection<Job> listJobsConcurrentImmutable() {
        return Collections.unmodifiableCollection(spawnState.jobs.values());
    }

    public int getTaskQueuedCount() {
        return lastQueueSize;
    }

    public Job getJob(String jobUUID) {
        if (jobUUID == null) {
            return null;
        }
        jobLock.lock();
        try {
            return spawnState.jobs.get(jobUUID);
        } finally {
            jobLock.unlock();
        }
    }

    public void setJobConfig(String jobUUID, String config) throws Exception {
        jobConfigManager.setConfig(jobUUID, config);
    }

    public String getJobConfig(String jobUUID) {
        if (jobUUID == null) {
            return null;
        }
        jobLock.lock();
        try {
            return jobConfigManager.getConfig(jobUUID);
        } finally {
            jobLock.unlock();
        }
    }

    public Job putJobInSpawnState(Job job) {
        if (job == null) {
            return null;
        }
        
        
        job.setConfig(null);
        return spawnState.jobs.put(job.getId(), job);
    }

    public Job getJob(JobKey jobKey) {
        String jobUUID = jobKey.getJobUuid();
        return getJob(jobUUID);
    }

    public JSONArray getJobHistory(String jobId) {
        return jobStore != null ? jobStore.getHistory(jobId) : new JSONArray();
    }

    public String getJobHistoricalConfig(String jobId, String commitId) {
        return jobStore != null ? jobStore.fetchHistoricalConfig(jobId, commitId) : null;
    }

    public String diff(String jobId, String commitId) {
        return jobStore != null ? jobStore.getDiff(jobId, commitId) : null;
    }
    
    public String getDeletedJobConfig(String jobId) throws Exception {
        requireJobStore();
        return jobStore.getDeletedJobConfig(jobId);
    }

    private void requireJobStore() throws Exception {
        if (jobStore == null) {
            throw new Exception("Job history is disabled.");
        }
    }

    public Job createJob(String creator, int taskCount, Collection<String> taskHosts,
                         String minionType, String command, boolean defaults) throws Exception {
        jobLock.lock();
        try {
            Job job = new Job(UUID.randomUUID().toString(), creator);
            job.setMinionType(minionType);
            job.setCommand(command);
            job.setState(JobState.IDLE);
            if (defaults) {
                job.setOwnerWritable(jobDefaults.ownerWritable);
                job.setGroupWritable(jobDefaults.groupWritable);
                job.setWorldWritable(jobDefaults.worldWritable);
                job.setOwnerExecutable(jobDefaults.ownerExecutable);
                job.setGroupExecutable(jobDefaults.groupExecutable);
                job.setWorldExecutable(jobDefaults.worldExecutable);
                job.setDailyBackups(jobDefaults.dailyBackups);
                job.setWeeklyBackups(jobDefaults.weeklyBackups);
                job.setMonthlyBackups(jobDefaults.monthlyBackups);
                job.setHourlyBackups(jobDefaults.hourlyBackups);
                job.setReplicas(jobDefaults.replicas);
                job.setAutoRetry(jobDefaults.autoRetry);
            }
            List<HostState> hostStates = getOrCreateHostStateList(minionType, taskHosts);
            List<JobTask> tasksAssignedToHosts = balancer.generateAssignedTasksForNewJob(job.getId(), taskCount, hostStates);
            job.setTasks(tasksAssignedToHosts);
            for (JobTask task : tasksAssignedToHosts) {
                HostState host = hostManager.getHostState(task.getHostUUID());
                if (host == null) {
                    throw new Exception("Unable to allocate job tasks because no suitable host was found");
                }
                host.addJob(job.getId());
            }
            putJobInSpawnState(job);
            jobConfigManager.addJob(job);
            submitConfigUpdate(job.getId(), creator, null);
            return job;
        } finally {
            jobLock.unlock();
        }
    }

    public Response synchronizeJobState(String jobUUID, String user,
                                       String token, String sudo) {
        if (jobUUID == null) {
            return Response.status(Response.Status.BAD_REQUEST).entity("{error:\"missing id parameter\"}").build();
        }
        if (jobUUID.equals("ALL")) {
            if (!getPermissionsManager().adminAction(user, token, sudo)) {
                return Response.status(Response.Status.UNAUTHORIZED)
                               .entity("{error:\"insufficient priviledges\"}").build();
            }
            Collection<Job> jobList = listJobs();
            for (Job job : jobList) {
                Response status = synchronizeSingleJob(job.getId(), user, token, sudo);
                if (status.getStatus() != 200) {
                    log.warn("Stopping synchronize all jobs to to failure synchronizing job: " + job.getId());
                    return status;
                }
            }
            return Response.ok("{id:'" + jobUUID + "',action:'synchronzied'}").build();
        } else {
            return synchronizeSingleJob(jobUUID, user, token, sudo);
        }
    }

    private Response synchronizeSingleJob(String jobUUID, String user, String token, String sudo) {
        Job job = getJob(jobUUID);
        if (job == null) {
            log.warn("[job.synchronize] job uuid {} not found", jobUUID);
            return Response.status(Response.Status.NOT_FOUND).entity("job " + jobUUID + " not found").build();
        } else if (!permissionsManager.isExecutable(user, token, sudo, job)) {
            return Response.status(Response.Status.UNAUTHORIZED).entity("{error:\"insufficient priviledges\"}").build();
        }
        ObjectMapper mapper = new ObjectMapper();
        for (JobTask task : job.getCopyOfTasks()) {
            String taskHost = task.getHostUUID();
            if (hostManager.deadMinionMembers.getMemberSet().contains(taskHost)) {
                log.warn("task is currently assigned to a dead minion, need to check job: {} host/node:{}/{}",
                         job.getId(), task.getHostUUID(), task.getTaskID());
                continue;
            }
            String hostStateString;
            try {
                hostStateString = StringSerializer.deserialize(zkClient.getData().forPath(Minion.MINION_ZK_PATH + taskHost));
            } catch (Exception e) {
                log.error("Unable to get hostStateString from zookeeper for " + Minion.MINION_ZK_PATH + taskHost, e);
                continue;
            }
            HostState hostState;
            try {
                hostState = mapper.readValue(hostStateString, HostState.class);
            } catch (IOException e) {
                log.warn("Unable to deserialize host state for host: " + hostStateString + " serialized string was\n" + hostStateString);
                return Response.serverError().entity("Serialization error").build();
            }
            boolean matched = matchJobNodeAndId(jobUUID, task, hostState.getRunning(), hostState.getStopped(), hostState.getQueued());
            if (!matched) {
                log.warn("Spawn thinks job: " + jobUUID + " node:" + task.getTaskID() + " is running on host: " + hostState.getHost() + " but that host disagrees.");
                if (matchJobNodeAndId(jobUUID, task, hostState.getReplicas())) {
                    log.warn("Host: " + hostState.getHost() + " has a replica for the task/node: " + jobUUID + "/" + task.getTaskID() + " promoting replica");
                    try {
                        rebalanceReplicas(job);
                    } catch (Exception e) {
                        log.warn("Exception promoting replica during job synchronization on host: " + taskHost + " job/node" + job.getId() + "/" + job.getId());
                    }
                } else {
                    log.warn("Host: " + hostState.getHost() + " does NOT have a replica for the task/node: " + jobUUID + "/" + task.getTaskID());
                }
            } else {
                log.warn("Spawn and minion agree, job/node: " + jobUUID + "/" + task.getTaskID() + " is on host: " + hostState.getHost());
            }
        }
        return Response.ok().entity("success").build();
    }

    private static boolean matchJobNodeAndId(String jobUUID, JobTask task, JobKey[]... jobKeys) {
        for (JobKey[] jobKeyArray : jobKeys) {
            for (JobKey jobKey : jobKeyArray) {
                if (jobKey == null) {
                    log.warn("runningJob was null, this shouldn't happen");
                    continue;
                } else if (jobKey.getJobUuid() == null) {
                    log.warn("JobUUID for jobKey: " + jobKey + " was null");
                    continue;
                } else if (jobKey.getNodeNumber() == null) {
                    log.warn("NodeNumber for jobKey: " + jobKey + " was null");
                    continue;
                }
                if (jobKey.getJobUuid().equals(jobUUID) && jobKey.getNodeNumber().equals(task.getTaskID())) {
                    return true;
                }
            }
        }

        return false;
    }

    
    public List<JobTaskMoveAssignment> reallocateJob(String jobUUID, int tasksToMove) {
        Job job;
        if (jobUUID == null || (job = getJob(jobUUID)) == null) {
            throw new NullPointerException("invalid job uuid");
        }
        if (job.getState() != JobState.IDLE) {
            log.warn("[job.reallocate] can't reallocate non-idle job");
            return Collections.emptyList();
        }
        List<JobTaskMoveAssignment> assignments = balancer.getAssignmentsForJobReallocation(job, tasksToMove,
                                                                                            hostManager.getLiveHosts(
                                                                                                    job.getMinionType()));
        return executeReallocationAssignments(assignments, false);
    }

    
    public boolean swapTask(JobTask task, String replicaHostID, boolean kickOnComplete) {
        if (task == null) {
            log.warn("[task.swap] received null task");
            return false;
        }
        if (!checkHostStatesForSwap(task.getJobKey(), task.getHostUUID(), replicaHostID, true)) {
            log.warn("[swap.task.stopped] failed for {}; exiting", task.getJobKey());
            return false;
        }
        Job job;
        jobLock.lock();
        try {
            job = getJob(task.getJobUUID());
            task.replaceReplica(replicaHostID, task.getHostUUID());
            task.setHostUUID(replicaHostID);
            queueJobTaskUpdateEvent(job);
        } finally {
            jobLock.unlock();
        }
        if (kickOnComplete) {
            try {
                scheduleTask(job, task, expandJob(job));
            } catch (Exception e) {
                log.warn("Warning: failed to kick task {} with: {}", task.getJobKey(), e, e);
                job.errorTask(task, JobTaskErrorCode.KICK_ERROR);
            }
        }
        return true;
    }

    
    private String getReplacementHost(Job job) {
        List<HostState> hosts = hostManager.getLiveHosts(job.getMinionType());
        for (HostState host : hosts) {
            if (host.canMirrorTasks()) {
                return host.getHostUuid();
            }
        }
        return null;
    }

    
    private boolean replaceDownHosts(JobTask task) {
        checkArgument(isNewTask(task), "%s is not a new task, and so this method is not safe to call", task);
        Job job = getJob(task.getJobKey());
        if (job == null) {
            return false;
        }
        HostState host = hostManager.getHostState(task.getHostUUID());
        boolean changed = false;
        if (host == null || !host.canMirrorTasks()) {
            String replacementHost = getReplacementHost(job);
            if (replacementHost != null) {
                task.setHostUUID(replacementHost);
                changed = true;
            }
        }
        if (task.getReplicas() != null) {
            List<JobTaskReplica> tempReplicas = new ArrayList<>(task.getReplicas());
            for (JobTaskReplica replica : tempReplicas) {
                HostState replicaHost = hostManager.getHostState(replica.getHostUUID());
                if (replicaHost == null || !replicaHost.canMirrorTasks()) {
                    changed = true;
                    task.setReplicas(removeReplicasForHost(replica.getHostUUID(), task.getReplicas()));
                }
            }
        }
        if (changed) {
            try {
                updateJob(job);
            } catch (Exception ex) {
                log.warn("Failed to sent replication message for new task " + task.getJobKey() + ": " + ex, ex);
                return false;
            }
        }
        return changed;

    }

    
    private boolean checkHostStatesForSwap(JobKey key, String liveHostID, String replicaHostID, boolean checkTargetReplica) {
        if (key == null || liveHostID == null || replicaHostID == null) {
            log.warn("[task.swap] failed due to null input");
            return false;
        }
        JobTask task = getTask(key.getJobUuid(), key.getNodeNumber());
        if (task == null) {
            log.warn("[task.swap] failed: nonexistent task/replicas");
            return false;
        }
        HostState liveHost = hostManager.getHostState(liveHostID);
        HostState replicaHost = hostManager.getHostState(replicaHostID);
        if (liveHost == null || replicaHost == null || liveHost.isDead() || !liveHost.isUp() || replicaHost.isDead() || !replicaHost.isUp()) {
            log.warn("[task.swap] failed due to invalid host states for " + liveHostID + "," + replicaHostID);
            return false;
        }
        if (checkTargetReplica && !isNewTask(task)) {
            if (!replicaHost.hasLive(key)) {
                log.warn("[task.swap] failed because the replica host " + replicaHostID + " does not have a complete replica of task " + key);
                return false;
            }
        }
        return true;
    }

    
    public RebalanceOutcome rebalanceHost(String hostUUID) {
        HostState host = hostManager.getHostState(hostUUID);
        if (host == null) {
            return new RebalanceOutcome(hostUUID, "missing host", null, null);
        }
        log.info("[job.reallocate] starting reallocation for host: {} host is not a read only host", hostUUID);
        List<JobTaskMoveAssignment> assignments = balancer.getAssignmentsToBalanceHost(host,
                                                                                       hostManager.getLiveHosts(null));
        return new RebalanceOutcome(hostUUID, null, null,
                                    LessStrings.join(executeReallocationAssignments(assignments, false).toArray(), "\n"));
    }

    
    public List<JobTaskMoveAssignment> executeReallocationAssignments(@Nullable List<JobTaskMoveAssignment> assignments, boolean limitToAvailableSlots) {
        List<JobTaskMoveAssignment> executedAssignments = new ArrayList<>();
        if (assignments == null) {
            return executedAssignments;
        }
        HashSet<String> jobsNeedingUpdate = new HashSet<>();
        HashSet<String> hostsAlreadyMovingTasks = new HashSet<>();
        for (JobTaskMoveAssignment assignment : assignments) {
            if (assignment.delete()) {
                log.warn("[job.reallocate] deleting " + assignment.getJobKey() + " off " + assignment.getSourceUUID());
                deleteTask(assignment.getJobKey().getJobUuid(), assignment.getSourceUUID(), assignment.getJobKey().getNodeNumber(), false);
                deleteTask(assignment.getJobKey().getJobUuid(), assignment.getSourceUUID(), assignment.getJobKey().getNodeNumber(), true);
                executedAssignments.add(assignment);
            } else {
                String sourceHostID = assignment.getSourceUUID();
                String targetHostID = assignment.getTargetUUID();
                HostState targetHost = hostManager.getHostState(targetHostID);
                if (sourceHostID == null || targetHostID == null || sourceHostID.equals(targetHostID) || targetHost == null) {
                    log.warn("[job.reallocate] received invalid host assignment: from " + sourceHostID + " to " + targetHostID);
                    continue;
                }
                JobKey key = assignment.getJobKey();
                JobTask task = getTask(key);
                Job job = getJob(key);
                if (job == null || task == null) {
                    log.warn("[job.reallocate] invalid job or task");
                    
                }
                else {
                    HostState liveHost = hostManager.getHostState(task.getHostUUID());
                    if (limitToAvailableSlots && liveHost != null && (liveHost.getAvailableTaskSlots() == 0 || hostsAlreadyMovingTasks.contains(task.getHostUUID()))) {
                        continue;
                    }
                    log.warn("[job.reallocate] replicating task " + key + " onto " + targetHostID + " as " + (assignment.isFromReplica() ? "replica" : "live"));
                    TaskMover tm = new TaskMover(this, hostManager, key, targetHostID, sourceHostID);
                    if (tm.execute()) {
                        hostsAlreadyMovingTasks.add(task.getHostUUID());
                        executedAssignments.add(assignment);
                    }
                }
            }
        }
        for (String jobUUID : jobsNeedingUpdate) {
            try {
                updateJob(getJob(jobUUID));
            } catch (Exception ex) {
                log.warn("WARNING: failed to update job " + jobUUID + ": " + ex, ex);
            }
        }
        return executedAssignments;
    }

    
    public RebalanceOutcome rebalanceJob(String jobUUID, int tasksToMove, String user,
                                         String token, String sudo) throws Exception {
        Job job = getJob(jobUUID);
        if (jobUUID == null || job == null) {
            log.warn("[job.rebalance] job uuid " + jobUUID + " not found");
            return new RebalanceOutcome(jobUUID, "job not found", null, null);
        }
        if (permissionsManager.isExecutable(user, token, sudo, job)) {
            log.warn("[job.rebalance] insufficient priviledges to rebalance " + jobUUID);
            return new RebalanceOutcome(jobUUID, "insufficient priviledges", null, null);
        }
        if (job.getState() != JobState.IDLE && job.getState() != JobState.DEGRADED) {
            log.warn("[job.rebalance] job must be IDLE or DEGRADED to rebalance " + jobUUID);
            return new RebalanceOutcome(jobUUID, "job not idle/degraded", null, null);
        }
        
        if (!rebalanceReplicas(job)) {
            log.warn("[job.rebalance] failed to fill out replica assignments for " + jobUUID);
            return new RebalanceOutcome(jobUUID, "couldn't fill out replicas", null, null);
        }
        try {
            List<JobTaskDirectoryMatch> allMismatches = new ArrayList<>();
            
            for (JobTask task : job.getCopyOfTasks()) {
                List<JobTaskDirectoryMatch> directoryMismatches = matchTaskToDirectories(task, false);
                if (!directoryMismatches.isEmpty()) {
                    
                    resolveJobTaskDirectoryMatches(task, false);
                    allMismatches.addAll(directoryMismatches);
                }
            }
            updateJob(job);
            
            if (!allMismatches.isEmpty()) {
                return new RebalanceOutcome(jobUUID, null, LessStrings.join(allMismatches.toArray(), "\n"), null);
            } else {
                
                return new RebalanceOutcome(jobUUID, null, null, LessStrings.join(
                        reallocateJob(jobUUID, tasksToMove).toArray(), "\n"));
            }
        } catch (Exception ex) {
            log.warn("[job.rebalance] exception during rebalance for " + jobUUID, ex);
            return new RebalanceOutcome(jobUUID, "exception during rebalancing: " + ex, null, null);
        }

    }

    
    public JSONObject fixTaskDir(String jobId, int node, boolean ignoreTaskState, boolean orphansOnly) {
        jobLock.lock();
        try {
            Job job = getJob(jobId);
            int numChanged = 0;
            if (job != null) {
                List<JobTask> tasks = node < 0 ? job.getCopyOfTasks() : Arrays.asList(job.getTask(node));
                for (JobTask task : tasks) {
                    boolean shouldModifyTask = !spawnJobFixer.haveRecentlyFixedTask(task.getJobKey()) &&
                                               (ignoreTaskState
                                                || (task.getState() == JobTaskState.IDLE)
                                                || (!orphansOnly && (task.getState() == JobTaskState.ERROR)));
                    if (log.isDebugEnabled()) {
                        log.debug("[fixTaskDir] considering modifying task " + task.getJobKey() + " shouldModifyTask=" + shouldModifyTask);
                    }
                    if (shouldModifyTask) {
                        try {
                            numChanged += resolveJobTaskDirectoryMatches(task, orphansOnly) ? 1 : 0;
                            spawnJobFixer.markTaskRecentlyFixed(task.getJobKey());
                        } catch (Exception ex) {
                            log.warn("fixTaskDir exception " + ex, ex);
                        }
                    }
                }
            }
            return new JSONObject(ImmutableMap.of("tasksChanged", numChanged));
        } finally {
            jobLock.unlock();
        }

    }

    
    public boolean resolveJobTaskDirectoryMatches(JobTask task, boolean deleteOrphansOnly) {
        Set<String> expectedHostsWithTask = new HashSet<>();
        Set<String> expectedHostsMissingTask = new HashSet<>();
        Set<String> unexpectedHostsWithTask = new HashSet<>();
        for (HostState host : hostManager.listHostStatus(null)) {
            if (hostSuitableForReplica(host)) {
                String hostId = host.getHostUuid();
                if (hostId.equals(task.getHostUUID()) || task.hasReplicaOnHost(hostId)) {
                    if (host.hasLive(task.getJobKey())) {
                        expectedHostsWithTask.add(hostId);
                    } else {
                        expectedHostsMissingTask.add(hostId);
                    }
                } else if (host.hasLive(task.getJobKey()) || host.hasIncompleteReplica(task.getJobKey())) {
                    unexpectedHostsWithTask.add(hostId);
                }
            }
        }
        log.trace("fixTaskDirs found expectedWithTask {} expectedMissingTask {} unexpectedWithTask {} ",
                  expectedHostsWithTask, expectedHostsMissingTask, unexpectedHostsWithTask);
        if (deleteOrphansOnly) {
            
            expectedHostsMissingTask = new HashSet<>();
        }
        return performTaskFixes(task, expectedHostsWithTask, expectedHostsMissingTask, unexpectedHostsWithTask);
    }

    private boolean performTaskFixes(JobTask task, Set<String> expectedHostsWithTask, Set<String> expectedHostsMissingTask, Set<String> unexpectedHostsWithTask) {
        if (expectedHostsWithTask.isEmpty()) {
            
            if (unexpectedHostsWithTask.isEmpty()) {
                
                log.warn("No copies of {} were found. Recreating it on new hosts. ", task.getJobKey());
                recreateTask(task);
                return true;
            }
            
            Iterator<String> unexpectedHostsIter = unexpectedHostsWithTask.iterator();
            List<JobTaskReplica> newReplicas = new ArrayList<>();
            task.setHostUUID(unexpectedHostsIter.next());
            while (unexpectedHostsIter.hasNext()) {
                newReplicas.add(new JobTaskReplica(unexpectedHostsIter.next(), task.getJobUUID(), 0, 0));
            }
            task.setReplicas(newReplicas);
            return true;
        } else {
            
            boolean changed = false;
            if (!expectedHostsMissingTask.isEmpty()) {
                swapTask(task, expectedHostsWithTask.iterator().next(), false);
                copyTaskToReplicas(task);
                changed = true;
            }
            for (String unexpectedHost : unexpectedHostsWithTask) {
                deleteTask(task.getJobUUID(), unexpectedHost, task.getTaskID(), false);
            }
            return changed;
        }
    }

    private static boolean hostSuitableForReplica(HostState host) {
        return host != null && host.isUp() && !host.isDead();
    }

    private void copyTaskToReplicas(JobTask task) {
        sendControlMessage(new CommandTaskReplicate(task.getHostUUID(), task.getJobUUID(), task.getTaskID(), getTaskReplicaTargets(task, task.getReplicas()), null, null, false, false));
    }

    private void recreateTask(JobTask task) {
        Job job = getJob(task.getJobUUID());
        Map<JobTask, String> assignmentMap = balancer.assignTasksFromMultipleJobsToHosts(Arrays.asList(task), getOrCreateHostStateList(job.getMinionType(), null));
        if (assignmentMap != null && assignmentMap.containsKey(task)) {
            String newHostUUID = assignmentMap.get(task);
            log.warn("[job.rebalance] assigning new host for " + task.getJobUUID() + ":" + task.getTaskID() + " all data on previous host will be lost");
            task.setHostUUID(newHostUUID);
            task.resetTaskMetrics();
        } else {
            log.warn("[job.rebalance] unable to assign new host for " + task.getJobUUID() + ":" + task.getTaskID() + " could not find suitable host");
        }
    }

    public JSONArray checkTaskDirJSON(String jobId, int node) {
        JSONArray resultList = new JSONArray();
        jobLock.lock();
        try {
            Job job = getJob(jobId);
            if (job == null) {
                return resultList;
            }
            List<JobTask> tasks = node < 0 ? new ArrayList<>(job.getCopyOfTasksSorted()) : Arrays.asList(job.getTask(node));
            for (JobTask task : tasks) {
                List<JobTaskDirectoryMatch> taskMatches = matchTaskToDirectories(task, true);
                for (JobTaskDirectoryMatch taskMatch : taskMatches) {
                    JSONObject jsonObject = CodecJSON.encodeJSON(taskMatch);
                    resultList.put(jsonObject);
                }
            }
        } catch (Exception ex) {
            log.warn("Error: checking dirs for job: " + jobId + ", node: " + node);
        } finally {
            jobLock.unlock();
        }
        return resultList;
    }

    public List<JobTaskDirectoryMatch> matchTaskToDirectories(JobTask task, boolean includeCorrect) {
        List<JobTaskDirectoryMatch> rv = new ArrayList<>();
        JobTaskDirectoryMatch match = checkHostForTask(task, task.getHostUUID());
        if (includeCorrect || match.getType() != JobTaskDirectoryMatch.MatchType.MATCH) {
            rv.add(match);
        }
        if (task.getAllReplicas() != null) {
            for (JobTaskReplica replica : task.getAllReplicas()) {
                match = checkHostForTask(task, replica.getHostUUID());
                if (match.getType() != JobTaskDirectoryMatch.MatchType.MATCH) {
                    if (task.getState() == JobTaskState.REPLICATE || task.getState() == JobTaskState.FULL_REPLICATE) {
                        
                        rv.add(new JobTaskDirectoryMatch(JobTaskDirectoryMatch.MatchType.REPLICATE_IN_PROGRESS, match.getJobKey(), match.getHostId()));
                    } else {
                        rv.add(match);
                    }
                }
                else if (includeCorrect) {
                    rv.add(match);
                }
            }
        }
        rv.addAll(findOrphansForTask(task));
        return rv;
    }

    private JobTaskDirectoryMatch checkHostForTask(JobTask task, String hostID) {
        JobTaskDirectoryMatch.MatchType type;
        HostState host = hostManager.getHostState(hostID);
        if (host == null || !host.hasLive(task.getJobKey())) {
            type = JobTaskDirectoryMatch.MatchType.MISMATCH_MISSING_LIVE;
        } else {
            type = JobTaskDirectoryMatch.MatchType.MATCH;
        }
        return new JobTaskDirectoryMatch(type, task.getJobKey(), hostID);
    }

    private List<JobTaskDirectoryMatch> findOrphansForTask(JobTask task) {
        List<JobTaskDirectoryMatch> rv = new ArrayList<>();
        Job job = getJob(task.getJobUUID());
        if (job == null) {
            log.warn("got find orphans request for missing job " + task.getJobUUID());
            return rv;
        }
        Set<String> expectedTaskHosts = task.getAllTaskHosts();
        for (HostState host : hostManager.listHostStatus(job.getMinionType())) {
            if (host == null || !host.isUp() || host.isDead() || host.getHostUuid().equals(task.getRebalanceTarget())) {
                continue;
            }
            if (!expectedTaskHosts.contains(host.getHostUuid())) {
                JobTaskDirectoryMatch.MatchType type = null;
                if (host.hasLive(task.getJobKey()) || host.hasIncompleteReplica(task.getJobKey())) {
                    type = JobTaskDirectoryMatch.MatchType.ORPHAN_LIVE;
                }
                if (type != null) {
                    rv.add(new JobTaskDirectoryMatch(type, task.getJobKey(), host.getHostUuid()));
                }
            }
        }
        return rv;
    }

    public boolean checkStatusForMove(String hostID) {
        HostState host = hostManager.getHostState(hostID);
        if (host == null) {
            log.warn("[host.status] received null host for id " + hostID);
            return false;
        }
        if (host.isDead() || !host.isUp()) {
            log.warn("[host.status] host is down: " + hostID);
            return false;
        }
        return true;
    }

    public boolean prepareTaskStatesForRebalance(Job job, JobTask task, boolean isMigration) {
        jobLock.lock();
        try {
            if (!SpawnBalancer.isInMovableState(task)) {
                log.warn("[task.mover] decided not to move non-idle task " + task);
                return false;
            }
            JobTaskState newState = isMigration ? JobTaskState.MIGRATING : JobTaskState.REBALANCE;
            job.setTaskState(task, newState, true);
            queueJobTaskUpdateEvent(job);
            return true;
        } finally {
            jobLock.unlock();
        }
    }

    
    public boolean rebalanceReplicas(Job job) throws Exception {
        return rebalanceReplicas(job, -1);
    }

    
    public boolean rebalanceReplicas(Job job, int taskID) throws Exception {
        if (job == null) {
            return false;
        }
        
        balancer.removeInvalidReplicas(job);
        
        Map<Integer, List<String>> replicaAssignments = balancer.getAssignmentsForNewReplicas(job, taskID);
        List<JobTask> tasks = taskID > 0 ? Arrays.asList(job.getTask(taskID)) : job.getCopyOfTasks();
        for (JobTask task : tasks) {
            List<String> replicasToAdd = replicaAssignments.get(task.getTaskID());
            
            task.setReplicas(addReplicasAndRemoveExcess(task, replicasToAdd, job.getReplicas(), task.getReplicas()));
        }
        return validateReplicas(job);
    }

    
    private boolean validateReplicas(Job job) {
        for (JobTask task : job.getCopyOfTasks()) {
            List<JobTaskReplica> replicas = task.getReplicas();
            if (job.getReplicas() > 0) {
                if ((replicas == null) || (replicas.size() < job.getReplicas())) {
                    HostState currHost = hostManager.getHostState(task.getHostUUID());
                    
                    if (((currHost == null) || currHost.isDead())
                        && ((replicas == null) || replicas.isEmpty())) {
                        job.setState(JobState.DEGRADED);
                    } else {
                        job.setState(JobState.ERROR); 
                        job.setEnabled(false);
                    }
                    log.warn("[replica.add] ERROR - unable to replicate task because there are not enough suitable hosts, job: " + job.getId());
                    return false;
                }
            }
        }
        return true;
    }

    private List<JobTaskReplica> addReplicasAndRemoveExcess(JobTask task,
                                                            List<String> replicaHostsToAdd,
                                                            int desiredNumberOfReplicas,
                                                            List<JobTaskReplica> currentReplicas) throws Exception {
        List<JobTaskReplica> newReplicas;
        if (currentReplicas == null) {
            newReplicas = new ArrayList<>();
        } else {
            newReplicas = new ArrayList<>(currentReplicas);
        }
        if (replicaHostsToAdd != null) {
            newReplicas.addAll(replicateTask(task, replicaHostsToAdd));
        }
        if (!isNewTask(task)) {
            while (newReplicas.size() > desiredNumberOfReplicas) {
                JobTaskReplica replica = newReplicas.remove(newReplicas.size() - 1);
                spawnMQ.sendControlMessage(new CommandTaskDelete(replica.getHostUUID(), task.getJobUUID(), task.getTaskID(), task.getRunCount()));
                log.info("[replica.delete] " + task.getJobUUID() + "/" + task.getTaskID() + " from " + replica
                        .getHostUUID() + " @ " +
                         hostManager.getHostState(replica.getHostUUID()).getHost());
            }
        }
        return newReplicas;
    }

    public List<JobTaskReplica> replicateTask(JobTask task, List<String> targetHosts) {
        List<JobTaskReplica> newReplicas = new ArrayList<>();
        for (String targetHostUUID : targetHosts) {
            JobTaskReplica replica = new JobTaskReplica();
            replica.setHostUUID(targetHostUUID);
            replica.setJobUUID(task.getJobUUID());
            newReplicas.add(replica);
        }
        Job job = getJob(task.getJobUUID());
        JobCommand jobcmd = getJobCommandManager().getEntity(job.getCommand());
        String command = (jobcmd != null && jobcmd.getCommand() != null) ? LessStrings.join(jobcmd.getCommand(), " ") : null;
        spawnMQ.sendControlMessage(new CommandTaskReplicate(task.getHostUUID(), task.getJobUUID(), task.getTaskID(), getTaskReplicaTargets(task, newReplicas), command, null, false, false));
        log.info("[replica.add] " + task.getJobUUID() + "/" + task.getTaskID() + " to " + targetHosts);
        taskQueuesByPriority.markHostTaskActive(task.getHostUUID());
        return newReplicas;
    }


    private void updateJobDependencies(String jobId) {
        DirectedGraph<String> dependencies = spawnState.jobDependencies;
        Set<String> sources = dependencies.getSourceEdges(jobId);
        if (sources != null) {
            for (String source : sources) {
                dependencies.removeEdge(source, jobId);
            }
        } else {
            dependencies.addNode(jobId);
        }
        Set<String> newSources = this.getDataSources(jobId);
        if (newSources != null) {
            for (String source : newSources) {
                dependencies.addEdge(source, jobId);
            }
        }
    }

    
    public void submitConfigUpdate(String jobId, String user, String commitMessage) {
        Job job;
        if (jobId == null || jobId.isEmpty() || (job = getJob(jobId)) == null) {
            return;
        }
        if (jobStore != null) {
            jobStore.submitConfigUpdate(job.getId(), user, getJobConfig(jobId), commitMessage);
        }
    }

    public void updateJob(IJob ijob) throws Exception {
        updateJob(ijob, true);
    }

    
    public void updateJob(IJob ijob, boolean reviseReplicas) throws Exception {
        Job job = new Job(ijob);
        jobLock.lock();
        try {
            checkArgument(getJob(job.getId()) != null, "job " + job.getId() + " does not exist");
            updateJobDependencies(job.getId());
            Job oldjob = putJobInSpawnState(job);
            
            if (oldjob != job && reviseReplicas) {
                int oldReplicaCount = oldjob.getReplicas();
                int newReplicaCount = job.getReplicas();
                checkArgument(oldReplicaCount == newReplicaCount || job.getState() == JobState.IDLE ||
                              job.getState() == JobState.DEGRADED, "job must be IDLE or DEGRADED to change replicas");
                checkArgument(newReplicaCount < hostManager.monitored.size(), "replication factor must be < # live hosts");
                rebalanceReplicas(job);
            }
            queueJobTaskUpdateEvent(job);
        } finally {
            jobLock.unlock();
        }
    }

    public DeleteStatus deleteJob(String jobUUID) throws Exception {
        jobLock.lock();
        try {
            Job job = getJob(jobUUID);
            if (job == null) {
                return DeleteStatus.JOB_MISSING;
            }
            if (job.getDontDeleteMe()) {
                return DeleteStatus.JOB_DO_NOT_DELETE;
            }
            spawnState.jobs.remove(jobUUID);
            spawnState.jobDependencies.removeNode(jobUUID);
            log.warn("[job.delete] {}", job.getId());
            if (spawnMQ != null) {
                spawnMQ.sendControlMessage(
                        new CommandTaskDelete(HostMessage.ALL_HOSTS, job.getId(), null, job.getRunCount()));
            }
            sendJobUpdateEvent("job.delete", job);
            jobConfigManager.deleteJob(job.getId());
            if (jobStore != null) {
                jobStore.delete(jobUUID);
            }
            Job.logJobEvent(job, JobEvent.DELETE, eventLog);
        } finally {
            jobLock.unlock();
        }
        jobAlertManager.removeAlertsForJob(jobUUID);
        return DeleteStatus.SUCCESS;
    }

    public void sendControlMessage(HostMessage hostMessage) {
        spawnMQ.sendControlMessage(hostMessage);
    }

    
    public boolean deleteTask(String jobUUID, String hostUuid, Integer node, boolean isReplica) {
        jobLock.lock();
        try {
            if (jobUUID == null || node == null) {
                return false;
            }
            log.warn("[job.delete.host] " + hostUuid + "/" + jobUUID + " >> " + node);
            spawnMQ.sendControlMessage(new CommandTaskDelete(hostUuid, jobUUID, node, 0));
            Job job = getJob(jobUUID);
            if (isReplica && job != null) {
                JobTask task = job.getTask(node);
                task.setReplicas(removeReplicasForHost(hostUuid, task.getReplicas()));
                queueJobTaskUpdateEvent(job);
            }
            return true;
        } finally {
            jobLock.unlock();
        }
    }

    private static List<JobTaskReplica> removeReplicasForHost(String hostUuid, List<JobTaskReplica> currentReplicas) {
        if (currentReplicas == null || currentReplicas.size() == 0) {
            return new ArrayList<>();
        }
        List<JobTaskReplica> replicasCopy = new ArrayList<>(currentReplicas);
        Iterator<JobTaskReplica> iterator = replicasCopy.iterator();
        while (iterator.hasNext()) {
            JobTaskReplica replica = iterator.next();
            if (replica.getHostUUID().equals(hostUuid)) {
                iterator.remove();
            }
        }
        return replicasCopy;
    }

    
    public void startJob(String jobUUID, int priority) throws Exception {
        Job job = getJob(jobUUID);
        checkArgument(job != null, "job not found");
        checkArgument(job.isEnabled(), "job disabled");
        checkArgument(scheduleJob(job, priority), "unable to schedule job");
        queueJobTaskUpdateEvent(job);
        Job.logJobEvent(job, JobEvent.START, eventLog);
    }

    public String expandJob(String jobUUID) throws Exception {
        Job job = getJob(jobUUID);
        checkArgument(job != null, "job not found");
        return expandJob(job);
    }

    public String expandJob(Job job) throws TokenReplacerOverflowException {
        return expandJob(job.getId(), job.getParameters(), getJobConfig(job.getId()));
    }

    public String expandJob(String id, Collection<JobParameter> parameters, String rawConfig)
            throws TokenReplacerOverflowException {
        
        String pass0 = JobExpand.macroExpand(this, rawConfig);
        
        String pass1 = JobExpand.macroTemplateParams(pass0, parameters);
        
        String pass2 = JobExpand.macroExpand(this, pass1);
        
        String pass3 = JobExpand.macroTemplateParams(pass2, parameters);
        
        return JobExpand.magicMacroExpand(this, pass3, id);
    }

    public void stopJob(String jobUUID) throws Exception {
        Job job = getJob(jobUUID);
        checkArgument(job != null, "job not found");
        for (JobTask task : job.getCopyOfTasks()) {
            if (task.getState() == JobTaskState.QUEUED) {
                removeFromQueue(task);
            }
            stopTask(jobUUID, task.getTaskID());
        }
        Job.logJobEvent(job, JobEvent.STOP, eventLog);
    }

    public void killJob(String jobUUID) throws Exception {
        boolean success = false;
        while (!success & !shuttingDown.get()) {
            try {
                jobLock.lock();
                if (taskQueuesByPriority.tryLock()) {
                    success = true;
                    Job job = getJob(jobUUID);
                    Job.logJobEvent(job, JobEvent.KILL, eventLog);
                    checkArgument(job != null, "job not found");
                    for (JobTask task : job.getCopyOfTasks()) {
                        if (task.getState() == JobTaskState.QUEUED) {
                            removeFromQueue(task);
                        }
                        killTask(jobUUID, task.getTaskID());
                    }
                }
            } finally {
                jobLock.unlock();
                if (success) {
                    taskQueuesByPriority.unlock();
                }
            }
        }
    }

    
    public JobTask getTask(String jobUUID, int taskID) {
        Job job = getJob(jobUUID);
        if (job != null) {
            return job.getTask(taskID);
        }
        return null;
    }

    public JobTask getTask(JobKey jobKey) {
        if (jobKey == null || jobKey.getJobUuid() == null || jobKey.getNodeNumber() == null) {
            return null;
        }
        return getTask(jobKey.getJobUuid(), jobKey.getNodeNumber());
    }

    
    public void startTask(String jobUUID, int taskID, boolean addToQueue, int priority, boolean toQueueHead) throws Exception {
        Job job = getJob(jobUUID);
        checkArgument(job != null, "job not found");
        checkArgument(job.isEnabled(), "job is disabled");
        checkArgument(job.getState() != JobState.DEGRADED, "job in degraded state");
        checkArgument(taskID >= 0, "invalid task id");
        JobTask task = getTask(jobUUID, taskID);
        checkArgument(task != null, "no such task");
        checkArgument(task.getState() != JobTaskState.BUSY && task.getState() != JobTaskState.ALLOCATED &&
                      task.getState() != JobTaskState.QUEUED, "invalid task state");
        if (addToQueue) {
            addToTaskQueue(task.getJobKey(), priority, toQueueHead);
        } else {
            kickIncludingQueue(job, task, expandJob(job), false, priority);
        }
        log.warn("[task.kick] started " + job.getId() + " / " + task.getTaskID() + " = " + job.getDescription());
        queueJobTaskUpdateEvent(job);
    }

    public void stopTask(String jobUUID, int taskID) throws Exception {
        stopTask(jobUUID, taskID, false, false);
    }

    private void stopTask(String jobUUID, int taskID, boolean force, boolean onlyIfQueued) throws Exception {
        Job job = getJob(jobUUID);
        JobTask task = getTask(jobUUID, taskID);
        if (job != null && task != null) {
            taskQueuesByPriority.setStoppedJob(true); 
            HostState host = hostManager.getHostState(task.getHostUUID());
            if (force) {
                task.setRebalanceSource(null);
                task.setRebalanceTarget(null);
            }
            if (task.getState().isQueuedState()) {
                removeFromQueue(task);
                log.warn("[task.stop] stopping queued " + task.getJobKey());
            } else if (task.getState() == JobTaskState.REBALANCE) {
                log.warn("[task.stop] stopping rebalancing " + task.getJobKey() + " with force=" + force);
            } else if (task.getState() == JobTaskState.MIGRATING ) {
                log.warn("[task.stop] stopping migrating " + task.getJobKey());
                task.setRebalanceSource(null);
                task.setRebalanceTarget(null);
            }
            else if (force && (task.getState() == JobTaskState.REVERT)) {
                log.warn("[task.stop] " + task.getJobKey() + " killed in revert state");
                int code  = JobTaskErrorCode.EXIT_REVERT_FAILURE;
                job.errorTask(task, code);
                queueJobTaskUpdateEvent(job);
            } else if (force && (host == null || host.isDead() || !host.isUp())) {
                log.warn("[task.stop] " + task.getJobKey() + " killed on down host");
                job.setTaskState(task, JobTaskState.IDLE);
                queueJobTaskUpdateEvent(job);
                return;
            } else if (host != null && !host.hasLive(task.getJobKey())) {
                log.warn("[task.stop] node that minion doesn't think is running: " + task.getJobKey());
                job.setTaskState(task, JobTaskState.IDLE);
                queueJobTaskUpdateEvent(job);
            }
            else if (task.getState() == JobTaskState.ALLOCATED) {
                log.warn("[task.stop] node in allocated state " + jobUUID + "/" + taskID + " host = " + (host != null ? host.getHost() : "unknown"));
            }

            
            if (host != null) {
                spawnMQ.sendControlMessage(new CommandTaskStop(host.getHostUuid(), jobUUID, taskID, job.getRunCount(), force, onlyIfQueued));
            } else {
                log.warn("[task.stop]" + jobUUID + "/" + taskID + "]: no host monitored for uuid " + task.getHostUUID());
            }
        } else {
            log.warn("[task.stop] job/task {}/{} not found", jobUUID, taskID);
        }
    }

    protected boolean removeFromQueue(JobTask task) {
        boolean removed = false;
        Job job = getJob(task.getJobUUID());
        if (job != null) {
            log.warn("[taskQueuesByPriority] setting " + task.getJobKey() + " as idle and removing from queue");
            job.setTaskState(task, JobTaskState.IDLE, true);
            removed = taskQueuesByPriority.remove(job.getPriority(), task.getJobKey());
            queueJobTaskUpdateEvent(job);
            sendTaskQueueUpdateEvent();
        }
        writeSpawnQueue();
        return removed;

    }

    public void killTask(String jobUUID, int taskID) throws Exception {
        stopTask(jobUUID, taskID, true, false);
    }

    public boolean moveTask(JobKey jobKey, String sourceUUID, String targetUUID) {
        TaskMover tm = new TaskMover(this, hostManager, jobKey, targetUUID, sourceUUID);
        log.info("[task.move] attempting move for " + jobKey);
        return tm.execute();
    }

    public boolean revertJobOrTask(String jobUUID,
                                String user,
                                String token,
                                String sudo,
                                int taskID,
                                String backupType,
                                int rev,
                                long time) throws Exception {
        Job job = getJob(jobUUID);
        if (job == null) {
            return true;
        }
        if (!permissionsManager.isExecutable(user, token, sudo, job)) {
            return false;
        }
        if (taskID == -1) {
            
            Job.logJobEvent(job, JobEvent.REVERT, eventLog);
            int numTasks = job.getTaskCount();
            for (int i = 0; i < numTasks; i++) {
                log.warn("[task.revert] " + jobUUID + "/" + i);
                revert(jobUUID, backupType, rev, time, i);
            }
        } else {
            
            log.warn("[task.revert] " + jobUUID + "/" + taskID);
            revert(jobUUID, backupType, rev, time, taskID);
        }
        return true;
    }

    private void revert(String jobUUID, String backupType, int rev, long time, int taskID) throws Exception {
        JobTask task = getTask(jobUUID, taskID);
        if (task != null) {
            task.setPreFailErrorCode(0);
            HostState host = hostManager.getHostState(task.getHostUUID());
            if (task.getState() == JobTaskState.ALLOCATED || task.getState().isQueuedState()) {
                log.warn("[task.revert] node in allocated state " + jobUUID + "/" + task.getTaskID() + " host = " + host.getHost());
            }
            log.warn("[task.revert] sending revert message to host: " + host.getHost() + "/" + host.getHostUuid());
            spawnMQ.sendControlMessage(new CommandTaskRevert(host.getHostUuid(), jobUUID, task.getTaskID(), backupType, rev, time, getTaskReplicaTargets(task, task.getAllReplicas()), false));
        } else {
            log.warn("[task.revert] task " + jobUUID + "/" + taskID + "] not found");
        }

    }


    

    private List<HostState> getOrCreateHostStateList(String minionType, Collection<String> hostList) {
        List<HostState> hostStateList;
        if (hostList == null || hostList.size() == 0) {
            hostStateList = balancer.sortHostsByActiveTasks(hostManager.listHostStatus(minionType));
        } else {
            hostStateList = new ArrayList<>();
            for (String hostId : hostList) {
                hostStateList.add(hostManager.getHostState(hostId));
            }
        }
        return hostStateList;
    }


    
    protected void handleMessage(CoreMessage core) {
        Job job;
        JobTask task;
        if (hostManager.deadMinionMembers.getMemberSet().contains(core.getHostUuid())) {
            log.warn("[mq.core] ignoring message from host: " + core.getHostUuid() + " because it is dead");
            return;
        }
        if (core instanceof HostState) {
            Set<String> upMinions = hostManager.minionMembers.getMemberSet();
            HostState state = (HostState) core;
            HostState oldState = hostManager.getHostState(state.getHostUuid());
            if (oldState == null) {
                log.warn("[host.status] from unmonitored " + state.getHostUuid() + " = " + state.getHost() + ":" + state.getPort());
                taskQueuesByPriority.updateHostAvailSlots(state);
            }
            boolean hostEnabled = true;
            if (spawnState.disabledHosts.contains(state.getHost()) ||
                spawnState.disabledHosts.contains(state.getHostUuid())) {
                hostEnabled = false;
                state.setDisabled(true);
            } else {
                state.setDisabled(false);
            }
            
            if (upMinions.contains(state.getHostUuid()) && hostEnabled) {
                state.setUp(true);
            }
            state.setUpdated();
            sendHostUpdateEvent(state);
            hostManager.updateHostState(state);
        } else if (core instanceof StatusTaskBegin) {
            StatusTaskBegin begin = (StatusTaskBegin) core;
            SpawnMetrics.tasksStartedPerHour.mark();
            if (systemManager.debug("-begin-")) {
                log.info("[task.begin] :: " + begin.getJobKey());
            }
            try {
                job = getJob(begin.getJobUuid());
                if (job == null) {
                    log.warn("[task.begin] on dead job " + begin.getJobKey() + " from " + begin.getHostUuid());
                } else {
                    if (job.getStartTime() == null) {
                        job.setStartTime(System.currentTimeMillis());
                    }
                    task = job.getTask(begin.getNodeID());
                    if (checkTaskMessage(task, begin.getHostUuid())) {
                        if (task != null) {
                            job.setTaskState(task, JobTaskState.BUSY);
                            task.incrementStarts();
                            queueJobTaskUpdateEvent(job);
                        } else {
                            log.warn("[task.begin] done report for missing node " + begin.getJobKey());
                        }
                    }
                }
            } catch (Exception ex) {
                log.warn("", ex);
            }
        } else if (core instanceof StatusTaskCantBegin) {
            StatusTaskCantBegin cantBegin = (StatusTaskCantBegin) core;
            log.info("[task.cantbegin] received cantbegin from " + cantBegin.getHostUuid() + " for task " + cantBegin.getJobUuid() + "," + cantBegin.getNodeID());
            job = getJob(cantBegin.getJobUuid());
            task = getTask(cantBegin.getJobUuid(), cantBegin.getNodeID());
            if (job != null && task != null) {
                if (checkTaskMessage(task, cantBegin.getHostUuid())) {
                    try {
                        job.setTaskState(task, JobTaskState.IDLE);
                        log.info("[task.cantbegin] kicking " + task.getJobKey());
                        startTask(cantBegin.getJobUuid(), cantBegin.getNodeID(), true, 1, true);
                    } catch (Exception ex) {
                        log.warn("[task.schedule] failed to reschedule task for " + task.getJobKey(), ex);
                    }
                }
            } else {
                log.warn("[task.cantbegin] received cantbegin from " + cantBegin.getHostUuid() + " for nonexistent job " + cantBegin.getJobUuid());
            }
        } else if (core instanceof StatusTaskPort) {
            StatusTaskPort port = (StatusTaskPort) core;
            job = getJob(port.getJobUuid());
            task = getTask(port.getJobUuid(), port.getNodeID());
            if (task != null) {
                log.info("[task.port] " + job.getId() + "/" + task.getTaskID() + " @ " + port.getPort());
                task.setPort(port.getPort());
                queueJobTaskUpdateEvent(job);
            }
        } else if (core instanceof StatusTaskBackup) {
            StatusTaskBackup backup = (StatusTaskBackup) core;
            job = getJob(backup.getJobUuid());
            task = getTask(backup.getJobUuid(), backup.getNodeID());
            if (task != null && task.getState() != JobTaskState.REBALANCE && task.getState() != JobTaskState.MIGRATING) {
                log.info("[task.backup] " + job.getId() + "/" + task.getTaskID());
                job.setTaskState(task, JobTaskState.BACKUP);
                queueJobTaskUpdateEvent(job);
            }
        } else if (core instanceof StatusTaskReplicate) {
            StatusTaskReplicate replicate = (StatusTaskReplicate) core;
            job = getJob(replicate.getJobUuid());
            task = getTask(replicate.getJobUuid(), replicate.getNodeID());
            if (task != null) {
                if (checkTaskMessage(task, replicate.getHostUuid())) {
                    log.info("[task.replicate] " + job.getId() + "/" + task.getTaskID());
                    JobTaskState taskState = task.getState();
                    if (taskState != JobTaskState.REBALANCE && taskState != JobTaskState.MIGRATING) {
                        job.setTaskState(task, replicate.isFullReplication() ? JobTaskState.FULL_REPLICATE : JobTaskState.REPLICATE, true);
                    }
                    queueJobTaskUpdateEvent(job);
                }
            }
        } else if (core instanceof StatusTaskRevert) {
            StatusTaskRevert revert = (StatusTaskRevert) core;
            job = getJob(revert.getJobUuid());
            task = getTask(revert.getJobUuid(), revert.getNodeID());
            if (task != null) {
                if (checkTaskMessage(task, revert.getHostUuid())) {
                    log.info("[task.revert] " + job.getId() + "/" + task.getTaskID());
                    job.setTaskState(task, JobTaskState.REVERT, true);
                    queueJobTaskUpdateEvent(job);
                }
            }
        } else if (core instanceof StatusTaskReplica) {
            StatusTaskReplica replica = (StatusTaskReplica) core;
            job = getJob(replica.getJobUuid());
            task = getTask(replica.getJobUuid(), replica.getNodeID());
            if (task != null) {
                if (task.getReplicas() != null) {
                    for (JobTaskReplica taskReplica : task.getReplicas()) {
                        if (taskReplica.getHostUUID().equals(replica.getHostUuid())) {
                            taskReplica.setVersion(replica.getVersion());
                            taskReplica.setLastUpdate(replica.getUpdateTime());
                        }
                    }
                    log.info("[task.replica] version updated for " + job.getId() + "/" + task.getTaskID() + " ver " + task.getRunCount() + "/" + replica.getVersion());
                    queueJobTaskUpdateEvent(job);
                }
            }
        } else if (core instanceof StatusTaskEnd) {
            StatusTaskEnd end = (StatusTaskEnd) core;
            log.info("[task.end] :: " + end.getJobUuid() + "/" + end.getNodeID() + " exit=" + end.getExitCode());
            SpawnMetrics.tasksCompletedPerHour.mark();
            try {
                job = getJob(end.getJobUuid());
                if (job == null) {
                    log.warn("[task.end] on dead job " + end.getJobKey() + " from " + end.getHostUuid());
                } else {
                    task = job.getTask(end.getNodeID());
                    if (checkTaskMessage(task, end.getHostUuid())) {
                        if (task.isRunning()) {
                            taskQueuesByPriority.incrementHostAvailableSlots(end.getHostUuid());
                        }
                        handleStatusTaskEnd(job, task, end);
                    }
                }
            } catch (Exception ex) {
                log.warn("Failed to handle end message: " + ex, ex);
            }
        } else {
            log.warn("[mq.core] unhandled type = " + core.getClass().toString());
        }
    }

    
    private static boolean checkTaskMessage(JobTask task, String messageSourceUuid) {
        if (task == null || messageSourceUuid == null || !messageSourceUuid.equals(task.getHostUUID())) {
            log.warn("Ignoring task state message from non-live host {}", messageSourceUuid);
            SpawnMetrics.nonHostTaskMessageCounter.inc();
            return false;
        }
        return true;
    }

    
    private void handleStatusTaskEnd(Job job, JobTask task, StatusTaskEnd update) {
        TaskExitState exitState = update.getExitState();
        boolean wasStopped = exitState != null && exitState.getWasStopped();
        task.setFileCount(update.getFileCount());
        task.setByteCount(update.getByteCount());
        boolean errored = update.getExitCode() != 0 && update.getExitCode() != JobTaskErrorCode.REBALANCE_PAUSE;
        if (update.getRebalanceSource() != null) {
            handleRebalanceFinish(job, task, update);
        } else {
            if (exitState != null) {
                task.setInput(exitState.getInput());
                task.setMeanRate(exitState.getMeanRate());
                task.setTotalEmitted(exitState.getTotalEmitted());
            }
            task.setWasStopped(wasStopped);
        }
        if (errored) {
            handleTaskError(job, task, update.getExitCode());
        } else if (!update.wasQueued()) {
            job.setTaskFinished(task);
        }
        if (job.isFinished() && update.getRebalanceSource() == null) {
            finishJob(job, errored);
        }
        queueJobTaskUpdateEvent(job);
    }

    public void handleTaskError(Job job, JobTask task, int exitCode) {
        log.warn("[task.end] " + task.getJobKey() + " exited abnormally with " + exitCode);
        task.incrementErrors();
        try {
            spawnJobFixer.fixTask(job, task, exitCode);
        } catch (Exception ex) {
            job.errorTask(task, exitCode);
        }
    }

    public void handleRebalanceFinish(Job job, JobTask task, StatusTaskEnd update) {
        String rebalanceSource = update.getRebalanceSource();
        String rebalanceTarget = update.getRebalanceTarget();
        if (update.getExitCode() == 0) {
            
            task.setRebalanceSource(null);
            task.setRebalanceTarget(null);
            if (checkHostStatesForSwap(task.getJobKey(), rebalanceSource, rebalanceTarget, false)) {
                if (task.getHostUUID().equals(rebalanceSource)) {
                    task.setHostUUID(rebalanceTarget);
                } else {
                    task.replaceReplica(rebalanceSource, update.getRebalanceTarget());
                }

                deleteTask(job.getId(), rebalanceSource, task.getTaskID(), false);
                if (update.wasQueued()) {
                    addToTaskQueue(task.getJobKey(), 0, false);
                }
            } else {
                
                fixTaskDir(job.getId(), task.getTaskID(), true, true);
            }
        } else if (update.getExitCode() == JobTaskErrorCode.REBALANCE_PAUSE) {
            
            log.warn("[task.move] task rebalance for " + task.getJobKey() + " paused until next run");
        } else {
            
            fixTaskDir(job.getId(), task.getTaskID(), true, true);
        }
    }

    
    private void finishJob(Job job, boolean errored) {
        String callback = errored ? job.getOnErrorURL() : job.getOnCompleteURL();
        log.info("[job.done] {} :: errored={}. callback={}", job.getId(), errored, callback);
        SpawnMetrics.jobsCompletedPerHour.mark();
        job.setFinishTime(System.currentTimeMillis());
        spawnFormattedLogger.finishJob(job);
        if (!systemManager.isQuiesced()) {
            if (job.isEnabled() && !errored) {
                jobOnFinishStateHandler.handle(job, JobOnFinishState.OnComplete);
                if (ENABLE_JOB_FIXDIRS_ONCOMPLETE && job.getRunCount() > 1) {
                    
                    fixTaskDir(job.getId(), -1, false, true);
                }
            } else {
                jobOnFinishStateHandler.handle(job, JobOnFinishState.OnError);
            }
        }
        Job.logJobEvent(job, JobEvent.FINISH, eventLog);
        balancer.requestJobSizeUpdate(job.getId(), 0);
    }

    public JobMacro createJobHostMacro(String job, int port) {
        String sPort = Integer.valueOf(port).toString();
        Set<String> jobHosts = new TreeSet<>();
        jobLock.lock();
        try {
            Collection<HostState> hosts = hostManager.listHostStatus(null);
            Map<String, String> uuid2Host = new HashMap<>();
            for (HostState host : hosts) {
                if (host.isUp()) {
                    uuid2Host.put(host.getHostUuid(), host.getHost());
                }
            }
            if (uuid2Host.size() == 0) {
                log.warn("[createJobHostMacro] warning job was found on no available hosts: " + job);
            }
            IJob ijob = getJob(job);
            if (ijob == null) {
                log.warn("[createJobHostMacro] Unable to get job config for job: " + job);
                throw new RuntimeException("[createJobHostMacro] Unable to get job config for job: " + job);
            }
            for (JobTask task : ijob.getCopyOfTasks()) {
                String host = uuid2Host.get(task.getHostUUID());
                if (host != null) {
                    jobHosts.add(host);
                }
            }
        } finally {
            jobLock.unlock();
        }

        List<String> hostStrings = new ArrayList<>();
        for (String host : jobHosts) {
            hostStrings.add("{host:\"" + host + "\", port:" + sPort + "}");
        }
        return new JobMacro("spawn", "", "createJobHostMacro-" + job, Joiner.on(',').join(hostStrings));
    }

    
    

    
    private void sendJobUpdateEvent(Job job) {
        jobLock.lock();
        try {
            jobConfigManager.updateJob(job);
        } finally {
            jobLock.unlock();
        }
        sendJobUpdateEvent("job.update", job);
    }

    public void queueJobTaskUpdateEvent(Job job) {
        jobLock.lock();
        try {
            jobUpdateQueue.add(job.getId());
        } finally {
            jobLock.unlock();
        }
    }

    private void drainJobTaskUpdateQueue() {
        try {
            long start = System.currentTimeMillis();
            Set<String> jobIds = new HashSet<>();
            jobUpdateQueue.drainTo(jobIds);
            log.trace("[drain] Draining {} jobs from the update queue", jobIds.size());
            for (String jobId : jobIds) {
                try {
                    Job job = getJob(jobId);
                    if (job == null) {
                        log.warn("[drain] Job {} does not exist - it may have been deleted", jobId);
                    } else {
                        sendJobUpdateEvent(job);
                    }
                } catch (Throwable e) {
                    log.error("[drain] Unexpected error when saving job update for {}", jobId, e);
                }
            }
            log.trace("[drain] Finished Draining {} jobs from the update queue in {}ms",
                      jobIds.size(), System.currentTimeMillis() - start);
        } catch (Throwable e) {
            log.error("[drain] Unexpected error when draining job task update queue", e);
        }
    }

    
    public void saveAllJobs() {
        jobLock.lock();
        try {
            for (Job job : listJobs()) {
                if (job != null) {
                    sendJobUpdateEvent(job);
                }
            }
        } finally {
            jobLock.unlock();
        }
    }

    private synchronized void jobTaskUpdateHeartbeatCheck() {
        try {
            String now = Long.toString(System.currentTimeMillis());
            spawnDataStore.put(SpawnDataStoreKeys.SPAWN_JOB_CONFIG_HEARTBEAT_PATH, now);
            String received = spawnDataStore.get(SpawnDataStoreKeys.SPAWN_JOB_CONFIG_HEARTBEAT_PATH);
            if (received != null && received.equals(now)) {
                SpawnMetrics.jobTaskUpdateHeartbeatSuccessMeter.mark();
            } else {
                SpawnMetrics.jobTaskUpdateHeartbeatFailureCounter.inc();
            }
        } catch (Exception e) {
            SpawnMetrics.jobTaskUpdateHeartbeatFailureCounter.inc();
            log.warn("Failed to perform jobtaskupdate heartbeat check", e);
        }

    }

    public void sendJobUpdateEvent(String label, Job job) {
        try {
            sendEventToClientListeners(label, getJobUpdateEvent(job));
        } catch (Exception e) {
            log.warn("", e);
        }
    }

    
    public void sendClusterQuiesceEvent(String username) {
        try {
            JSONObject info = new JSONObject();
            info.put("username", username);
            info.put("date", JitterClock.globalTime());
            info.put("quiesced", systemManager.isQuiesced());
            sendEventToClientListeners("cluster.quiesce", info);
        } catch (Exception e) {
            log.warn("", e);
        }
    }

    
    public void sendTaskQueueUpdateEvent() {
        try {
            int numQueued = 0;
            int numQueuedWaitingOnSlot = 0;
            int numQueuedWaitingOnError = 0;
            taskQueuesByPriority.lock();
            try {
                LinkedList<JobKey>[] queues =
                        taskQueuesByPriority.values().toArray(new LinkedList[taskQueuesByPriority.size()]);

                for (LinkedList<JobKey> queue : queues) {
                    numQueued += queue.size();
                    for (JobKey key : queue) {
                        Job job = getJob(key);
                        if (job != null && !job.isEnabled()) {
                            numQueuedWaitingOnError += 1;
                        } else {
                            JobTask task = job.getTask(key.getNodeNumber());
                            if (task.getState() == JobTaskState.QUEUED_NO_SLOT) {
                                numQueuedWaitingOnSlot += 1;
                            }
                        }
                    }
                }
                lastQueueSize = numQueued;
            } finally {
                taskQueuesByPriority.unlock();
            }
            JSONObject json = new JSONObject("{'size':" + Integer.toString(numQueued) +
                                             ",'sizeErr':" + Integer.toString(numQueuedWaitingOnError) +
                                             ",'sizeSlot':" + Integer.toString(numQueuedWaitingOnSlot) + "}");
            sendEventToClientListeners("task.queue.size", json);
        } catch (Exception e) {
            log.warn("[task.queue.update] received exception while sending task queue update event (this is ok unless" +
                     " it happens repeatedly)", e);
        }
    }

    public int getLastQueueSize() {
        return lastQueueSize;
    }

    public static JSONObject getJobUpdateEvent(IJob job) throws Exception {
        long files = 0;
        long bytes = 0;
        int running = 0;
        int errored = 0;
        int done = 0;
        if (job == null) {
            String errMessage = "getJobUpdateEvent called with null job";
            log.warn(errMessage);
            throw new Exception(errMessage);
        }
        List<JobTask> jobNodes = job.getCopyOfTasks();
        int numNodes = 0;
        if (jobNodes != null) {
            numNodes = jobNodes.size();
            for (JobTask task : jobNodes) {
                files += task.getFileCount();
                bytes += task.getByteCount();
                if (task.getState() != JobTaskState.ALLOCATED && !task.getState().isQueuedState()) {
                    running++;
                }
                switch (task.getState()) {
                    case IDLE:
                        done++;
                        break;
                    case ERROR:
                        done++;
                        errored++;
                        break;
                    default:
                        break;
                }
            }
        }
        JSONObject ojob = job.toJSON().put("config", "").put("parameters", "");
        ojob.put("nodes", numNodes);
        ojob.put("running", running);
        ojob.put("errored", errored);
        ojob.put("done", done);
        ojob.put("files", files);
        ojob.put("bytes", bytes);
        return ojob;
    }

    public void sendHostUpdateEvent(HostState state) {
        sendHostUpdateEvent("host.update", state);
    }

    private void sendHostUpdateEvent(String label, HostState state) {
        try {
            sendEventToClientListeners(label, getHostStateUpdateEvent(state));
        } catch (Exception e) {
            log.warn("", e);
        }
    }

    public JSONObject getHostStateUpdateEvent(HostState state) throws Exception {
        if (state == null) {
            return null;
        }
        JSONObject ohost = CodecJSON.encodeJSON(state);
        ohost.put("spawnState", getSpawnStateString(state));
        ohost.put("stopped", ohost.getJSONArray("stopped").length());
        ohost.put("total", state.countTotalLive());
        double score = 0;
        try {
            score = balancer.getHostScoreCached(state.getHostUuid());
        } catch (NullPointerException npe) {
            log.warn("[host.status] exception in getHostStateUpdateEvent", npe);
        }
        ohost.put("score", score);
        return ohost;
    }

    private String getSpawnStateString(HostState state) {
        if (state.isDead()) {
            return "failed";
        } else if (state.isDisabled()) {
            return "disabled";
        }
        return hostFailWorker.getFailureStateString(state.getHostUuid(), state.isUp());
    }

    
    private void sendEventToClientListeners(final String topic, final JSONObject message) {
        long time = System.currentTimeMillis();
        for (Entry<String, ClientEventListener> ev : listeners.entrySet()) {
            ClientEventListener client = ev.getValue();
            boolean queueTooLarge = clientDropQueueSize > 0 && client.events.size() > clientDropQueueSize;
            
            if (time - client.lastSeen > clientDropTimeMillis || queueTooLarge) {
                ClientEventListener listener = listeners.remove(ev.getKey());
                if (systemManager.debug("-listen-")) {
                    log.warn("[listen] dropping listener queue for " + ev.getKey() + " = " + listener);
                }
                if (queueTooLarge) {
                    SpawnMetrics.nonConsumingClientDropCounter.inc();
                }
                continue;
            }
            try {
                client.events.put(new ClientEvent(topic, message));
            } catch (Exception ex) {
                log.warn("", ex);
            }
        }
        webSocketManager.addEvent(new ClientEvent(topic, message));
    }

    
    @Override public void close() {
        shuttingDown.set(true);
        try {
            expandKickExecutor.shutdown();
            scheduledExecutor.shutdown();
            expandKickExecutor.awaitTermination(120, TimeUnit.SECONDS);
            scheduledExecutor.awaitTermination(120, TimeUnit.SECONDS);
        } catch (Exception ex) {
            log.warn("Exception shutting down background processes", ex);
        }

        try {
            permissionsManager.close();
        } catch (Exception ex) {
            log.warn("Exception closing permissions manager", ex);
        }

        try {
            drainJobTaskUpdateQueue();
        } catch (Exception ex) {
            log.warn("Exception draining job task update queue", ex);
        }

        balancer.close();
        jobOnFinishStateHandler.close();

        try {
            spawnFormattedLogger.close();
        } catch (Exception ex) {
            log.warn("", ex);
        }

        try {
            hostManager.minionMembers.shutdown();
            hostManager.deadMinionMembers.shutdown();
        } catch (IOException ex) {
            log.warn("Unable to cleanly shutdown membership listeners", ex);
        }

        try {
            closeZkClients();
        } catch (Exception ex) {
            log.warn("Exception closing zk clients", ex);
        }
    }

    protected void autobalance(RebalanceType type, RebalanceWeight weight) {
        executeReallocationAssignments(balancer.getAssignmentsForAutoBalance(type, weight), false);
    }

    private boolean schedulePrep(Job job) {
        JobCommand jobCommand = getJobCommandManager().getEntity(job.getCommand());
        if (jobCommand == null) {
            log.warn("[schedule] failed submit : invalid command {}", job.getCommand());
            return false;
        }
        return job.isEnabled();
    }

    private ReplicaTarget[] getTaskReplicaTargets(JobTask task, List<JobTaskReplica> replicaList) {
        ReplicaTarget[] replicas = null;
        if (replicaList != null) {
            int next = 0;
            replicas = new ReplicaTarget[replicaList.size()];
            for (JobTaskReplica replica : replicaList) {
                HostState host = hostManager.getHostState(replica.getHostUUID());
                if (host == null) {
                    log.warn("[getTaskReplicaTargets] error - replica host: " + replica.getHostUUID() + " does not exist!");
                    throw new RuntimeException("[getTaskReplicaTargets] error - replica host: " + replica.getHostUUID() + " does not exist.  Rebalance the job to correct issue");
                }
                replicas[next++] = new ReplicaTarget(host.getHostUuid(), host.getHost(), host.getUser(), host.getPath());
            }
        }
        return replicas;
    }

    
    private void kickIncludingQueue(Job job, JobTask task, String config, boolean inQueue, int priority) throws Exception {
        boolean success = false;
        while (!success && !shuttingDown.get()) {
            jobLock.lock();
            try {
                if (taskQueuesByPriority.tryLock()) {
                    success = true;
                    boolean kicked = kickOnExistingHosts(job, task, config, 0L, true);
                    if (!kicked && !inQueue) {
                        addToTaskQueue(task.getJobKey(), priority, false);
                    }
                }
            } finally {
                jobLock.unlock();
                if (success) {
                    taskQueuesByPriority.unlock();
                }
            }
        }
    }

    
    boolean scheduleJob(Job job, int priority) throws Exception {
        if (!schedulePrep(job)) {
            return false;
        }
        if (job.getCountActiveTasks() == job.getTaskCount()) {
            return false;
        }
        job.setSubmitTime(JitterClock.globalTime());
        job.setStartTime(null);
        job.setEndTime(null);
        job.incrementRunCount();
        Job.logJobEvent(job, JobEvent.SCHEDULED, eventLog);
        log.info("[job.schedule] assigning " + job.getId() + " with " + job.getCopyOfTasks().size() + " tasks");
        SpawnMetrics.jobsStartedPerHour.mark();
        for (JobTask task : job.getCopyOfTasks()) {
            if (task == null || task.getState() != JobTaskState.IDLE) {
                continue;
            }
            addToTaskQueue(task.getJobKey(), priority, false);
        }
        updateJob(job);
        return true;
    }

    
    CommandTaskKick getCommandTaskKick(Job job, JobTask task) {
        JobCommand jobCmd = getJobCommandManager().getEntity(job.getCommand());
        final String expandedJob;
        try {
            expandedJob = expandJob(job);
        } catch (TokenReplacerOverflowException e) {
            return null;
        }
        CommandTaskKick kick = new CommandTaskKick(
                task.getHostUUID(),
                task.getJobKey(),
                job.getOwner(),
                job.getGroup(),
                job.getPriority(),
                job.getCopyOfTasks().size(),
                job.getMaxRunTime() != null ? job.getMaxRunTime() * 60000 : 0,
                job.getRunCount(),
                expandedJob,
                LessStrings.join(jobCmd.getCommand(), " "),
                job.getHourlyBackups(),
                job.getDailyBackups(),
                job.getWeeklyBackups(),
                job.getMonthlyBackups(),
                getTaskReplicaTargets(task, task.getAllReplicas()),
                job.getAutoRetry(),
                task.getStarts()
                );
        return kick;
    }

    
    public boolean scheduleTask(Job job, JobTask task, String config) {
        if (!schedulePrep(job)) {
            return false;
        }
        if (task.getState() != JobTaskState.IDLE && task.getState() != JobTaskState.ERROR && task.getState() != JobTaskState.QUEUED) {
            return false;
        }
        JobState oldState = job.getState();
        if (!job.setTaskState(task, JobTaskState.ALLOCATED)) {
            return false;
        }
        if (oldState == JobState.IDLE && job.getRunCount() <= task.getRunCount()) {
            log.warn("Somehow a task ({}) was ALLOCATED from an IDLE, not queued or running, job ({})", task, job);
            job.incrementRunCount();
            job.setEndTime(null);
        }
        task.setRunCount(job.getRunCount());
        task.setErrorCode(0);
        task.setPreFailErrorCode(0);
        JobCommand jobcmd = getJobCommandManager().getEntity(job.getCommand());

        if (task.getRebalanceSource() != null && task.getRebalanceTarget() != null) {
            
            if (new TaskMover(this, hostManager, task.getJobKey(), task.getRebalanceTarget(), task.getRebalanceSource()).execute()) {
                return true;
            } else {
                
                task.setRebalanceSource(null);
                task.setRebalanceTarget(null);
            }
        }
        final CommandTaskKick kick = new CommandTaskKick(
                task.getHostUUID(),
                task.getJobKey(),
                job.getOwner(),
                job.getGroup(),
                job.getPriority(),
                job.getCopyOfTasks().size(),
                job.getMaxRunTime() != null ? job.getMaxRunTime() * 60000 : 0,
                job.getRunCount(),
                null,
                LessStrings.join(jobcmd.getCommand(), " "),
                job.getHourlyBackups(),
                job.getDailyBackups(),
                job.getWeeklyBackups(),
                job.getMonthlyBackups(),
                getTaskReplicaTargets(task, task.getAllReplicas()),
                job.getAutoRetry(),
                task.getStarts()
        );

        
        
        
        
        ArrayList<JobParameter> jobParameters = new ArrayList<>();          
        for (JobParameter parameter : job.getParameters()) {
            jobParameters.add(new JobParameter(parameter.getName(), parameter.getValue(), parameter.getDefaultValue()));
        }
        ScheduledTaskKick scheduledKick = new ScheduledTaskKick(this, job.getId(), jobParameters, config, getJobConfig(job.getId()), spawnMQ, kick, job, task);
        expandKickExecutor.submit(scheduledKick);
        return true;
    }

    
    private List<HostState> hostsBlockingTaskKick(JobTask task) {
        List<HostState> unavailable = new ArrayList<>();
        HostState liveHost = hostManager.getHostState(task.getHostUUID());
        if (shouldBlockTaskKick(liveHost)) {
            unavailable.add(liveHost);
        }
        List<JobTaskReplica> replicas = (task.getReplicas() != null ? task.getReplicas() : new ArrayList<>());
        for (JobTaskReplica replica : replicas) {
            HostState replicaHost = hostManager.getHostState(replica.getHostUUID());
            if (shouldBlockTaskKick(replicaHost)) {
                unavailable.add(replicaHost);
            }
        }
        return unavailable;
    }

    private boolean shouldBlockTaskKick(HostState host) {
        if (host == null || !host.canMirrorTasks()) {
            return true;
        }
        HostFailWorker.FailState failState = hostFailWorker.getFailureState(host.getHostUuid());
        return failState == HostFailWorker.FailState.DISK_FULL || failState == HostFailWorker.FailState.FAILING_FS_DEAD;
    }

    
    public boolean kickOnExistingHosts(Job job, JobTask task, String config, long timeOnQueue, boolean allowSwap) {
        if (!jobTaskCanKick(job, task)) {
            if (task.getState() == JobTaskState.QUEUED_NO_SLOT) {
                job.setTaskState(task, JobTaskState.QUEUED);
                queueJobTaskUpdateEvent(job);
            }
            return false;
        }
        List<HostState> possibleHosts = new ArrayList<>();
        if (allowSwap && isNewTask(task)) {
            for (HostState state : hostManager.listHostStatus(job.getMinionType())) {
                
                if (hostFailWorker.getFailureState(state.getHostUuid()) == HostFailWorker.FailState.ALIVE) {
                    possibleHosts.add(state);
                }
            }
        }
        else {
            possibleHosts.addAll(getHealthyHostStatesHousingTask(task, allowSwap));
        }
        HostState bestHost = findHostWithAvailableSlot(task, timeOnQueue, possibleHosts, false);
        if (bestHost != null) {
            if (task.getState() == JobTaskState.QUEUED_NO_SLOT) {
                job.setTaskState(task, JobTaskState.QUEUED);
                queueJobTaskUpdateEvent(job);
            }
            String bestHostUuid = bestHost.getHostUuid();
            if (task.getHostUUID().equals(bestHostUuid)) {
                taskQueuesByPriority.markHostTaskActive(bestHostUuid);
                scheduleTask(job, task, config);
                log.info("[taskQueuesByPriority] sending {} to {}", task.getJobKey(), bestHostUuid);
                return true;
            } else if (swapTask(task, bestHostUuid, true)) {
                taskQueuesByPriority.markHostTaskActive(bestHostUuid);
                log.info("[taskQueuesByPriority] swapping {} onto {}", task.getJobKey(), bestHostUuid);
                return true;
            }
        }
        if (taskQueuesByPriority.isMigrationEnabled()
            && !job.getQueryConfig().getCanQuery()
            && !job.getDontAutoBalanceMe()
            && attemptMigrateTask(job, task, timeOnQueue)) {
            return true;
        }
        if (task.getState() != JobTaskState.QUEUED_NO_SLOT) {
            job.setTaskState(task, JobTaskState.QUEUED_NO_SLOT);
            queueJobTaskUpdateEvent(job);
        }
        return false;
    }

    private boolean jobTaskCanKick(Job job, JobTask task) {
        if ((job == null) || !job.isEnabled()) {
            return false;
        }
        boolean isNewTask = isNewTask(task);
        List<HostState> unavailableHosts = hostsBlockingTaskKick(task);
        if (isNewTask && !unavailableHosts.isEmpty()) {
            
            boolean changed = replaceDownHosts(task);
            if (changed) {
                return false; 
            }
        }
        if (!unavailableHosts.isEmpty()) {
            log.warn("[taskQueuesByPriority] cannot kick {} because one or more of its hosts is down or scheduled to " +
                     "be failed: {}", task.getJobKey(), unavailableHosts);
            if (task.getState() != JobTaskState.QUEUED_HOST_UNAVAIL) {
                job.setTaskState(task, JobTaskState.QUEUED_HOST_UNAVAIL);
                queueJobTaskUpdateEvent(job);
            }
            return false;
        } else if (task.getState() == JobTaskState.QUEUED_HOST_UNAVAIL) {
            
            job.setTaskState(task, JobTaskState.QUEUED);
            queueJobTaskUpdateEvent(job);
        }
        
        return !((job.getMaxSimulRunning() > 0) && (job.getCountActiveTasks() >= job.getMaxSimulRunning()));
    }

    List<HostState> getHealthyHostStatesHousingTask(JobTask task, boolean allowReplicas) {
        List<HostState> rv = new ArrayList<>();
        HostState liveHost = hostManager.getHostState(task.getHostUUID());
        if (liveHost != null && hostFailWorker.shouldKickTasks(task.getHostUUID())) {
            rv.add(liveHost);
        }
        if (allowReplicas && task.getReplicas() != null) {
            for (JobTaskReplica replica : task.getReplicas()) {
                HostState replicaHost = replica.getHostUUID() != null ?
                                        hostManager.getHostState(replica.getHostUUID()) : null;
                if (replicaHost != null && replicaHost.hasLive(task.getJobKey()) && hostFailWorker.shouldKickTasks(task.getHostUUID())) {
                    rv.add(replicaHost);
                }
            }
        }
        return rv;
    }

    
    private HostState findHostWithAvailableSlot(JobTask task, long timeOnQueue, List<HostState> hosts, boolean forMigration) {
        if (hosts == null) {
            return null;
        }
        List<HostState> filteredHosts = new ArrayList<>();
        for (HostState host : hosts) {
            if (host == null || (forMigration && hostFailWorker.getFailureState(host.getHostUuid()) != HostFailWorker.FailState.ALIVE)) {
                
                continue;
            }
            if (forMigration && !taskQueuesByPriority.shouldMigrateTaskToHost(task, host.getHostUuid())) {
                
                continue;
            }
            if (isNewTask(task) && !taskQueuesByPriority.shouldKickNewTaskOnHost(timeOnQueue, host)) {
                
                continue;
            }
            if (host.canMirrorTasks()  && taskQueuesByPriority.shouldKickTaskOnHost(host.getHostUuid())) {
                filteredHosts.add(host);
            }
        }
        return taskQueuesByPriority.findBestHostToRunTask(filteredHosts, true);
    }

    
    private boolean attemptMigrateTask(Job job, JobTask task, long timeOnQueue) {
        
        
        
        if (!systemManager.isQuiesced() && 
                taskQueuesByPriority.checkSizeAgeForMigration(task.getByteCount(), timeOnQueue)) {
            HostState target = findHostWithAvailableSlot(task, timeOnQueue,
                                                         hostManager.listHostStatus(job.getMinionType()), true);
            if (target != null) {
                log.warn("Migrating {} to {}", task.getJobKey(), target.getHostUuid());
                taskQueuesByPriority.markMigrationBetweenHosts(task.getHostUUID(), target.getHostUuid());
                taskQueuesByPriority.markHostTaskActive(target.getHostUuid());
                TaskMover tm = new TaskMover(this, hostManager, task.getJobKey(), target.getHostUuid(), task.getHostUUID());
                tm.setMigration(true);
                tm.execute();
                return true;
            }
        }
        return false;
    }

    public boolean isNewTask(JobTask task) {
        HostState liveHost = hostManager.getHostState(task.getHostUUID());
        return (liveHost != null)
               && !liveHost.hasLive(task.getJobKey())
               && (task.getFileCount() == 0)
               && (task.getByteCount() == 0);
    }

    
    public void addToTaskQueue(JobKey jobKey, int priority, boolean toHead) {
        Job job = getJob(jobKey.getJobUuid());
        JobTask task = getTask(jobKey.getJobUuid(), jobKey.getNodeNumber());
        if (job != null && task != null) {
            if (task.getState() == JobTaskState.QUEUED || job.setTaskState(task, JobTaskState.QUEUED)) {
                log.info("[taskQueuesByPriority] adding " + jobKey + " to queue with priority=" + priority);
                taskQueuesByPriority.addTaskToQueue(job.getPriority(), jobKey, priority, toHead);
                queueJobTaskUpdateEvent(job);
                sendTaskQueueUpdateEvent();
            } else {
                log.warn("[task.queue] failed to add task " + jobKey + " with state " + task.getState());
            }
        }
    }

    
    public void kickJobsOnQueue() {
        LinkedList[] queues = null;
        boolean success = false;
        while (!success && !shuttingDown.get()) {
            
            jobLock.lock();
            try {
                if (taskQueuesByPriority.tryLock()) {
                    success = true;
                    taskQueuesByPriority.setStoppedJob(false);
                    taskQueuesByPriority.updateAllHostAvailSlots(hostManager.listHostStatus(null));
                    queues = taskQueuesByPriority.values().toArray(new LinkedList[taskQueuesByPriority.size()]);
                    for (LinkedList<SpawnQueueItem> queue : queues) {
                        iterateThroughTaskQueue(queue);
                    }
                    sendTaskQueueUpdateEvent();
                }
            } finally {
                jobLock.unlock();
                if (success) {
                    taskQueuesByPriority.unlock();
                }
            }
            if (!success) {
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                }
            }
        }
    }

    
    private void iterateThroughTaskQueue(LinkedList<SpawnQueueItem> queue) {
        ListIterator<SpawnQueueItem> iter = queue.listIterator(0);
        int skippedQuiesceCount = 0;
        long now = System.currentTimeMillis();
        
        while (iter.hasNext() && !taskQueuesByPriority.getStoppedJob()) {
            SpawnQueueItem key = iter.next();
            Job job = getJob(key.getJobUuid());
            JobTask task = getTask(key.getJobUuid(), key.getNodeNumber());
            try {
                if ((job == null) || (task == null) || !task.getState().isQueuedState()) {
                    log.warn("[task.queue] removing invalid task {}", key);
                    iter.remove();
                    continue;
                }
                if (systemManager.isQuiesced() && (key.getPriority() < 1)) {
                    skippedQuiesceCount++;
                    log.debug("[task.queue] skipping {} because spawn is quiesced and the kick wasn't manual", key);
                    if (task.getState() == JobTaskState.QUEUED_NO_SLOT) {
                        job.setTaskState(task, JobTaskState.QUEUED);
                        queueJobTaskUpdateEvent(job);
                    }
                } else {
                    boolean kicked = kickOnExistingHosts(job, task, null, now - key.getCreationTime(),
                                                         !job.getDontAutoBalanceMe());
                    if (kicked) {
                        log.info("[task.queue] removing kicked task {}", task.getJobKey());
                        iter.remove();
                    }
                }
            } catch (Exception ex) {
                log.warn("[task.queue] received exception during task kick: ", ex);
                if ((task != null) && (job != null)) {
                    job.errorTask(task, JobTaskErrorCode.KICK_ERROR);
                    iter.remove();
                    queueJobTaskUpdateEvent(job);
                }
            }
        }
        if (skippedQuiesceCount > 0) {
            log.warn("[task.queue] skipped {} queued tasks because spawn is quiesced and the kick wasn't manual",
                     skippedQuiesceCount);
        }
    }

    public WebSocketManager getWebSocketManager() {
        return this.webSocketManager;
    }

    public void toggleHosts(String hosts, boolean disable) {
        if (hosts != null) {
            String[] hostsArray = hosts.split(",");
            for (String host : hostsArray) {
                if (host.isEmpty()) {
                    continue;
                }
                boolean changed;
                changed = disable ? spawnState.disabledHosts.add(host) : spawnState.disabledHosts.remove(host);
                if (changed) {
                    updateToggledHosts(host, disable);
                }
            }
            writeState();
        }
    }

    public void updateToggledHosts(String id, boolean disable) {
        for (HostState host : hostManager.listHostStatus(null)) {
            if (id.equals(host.getHost()) || id.equals(host.getHostUuid())) {
                host.setDisabled(disable);
                sendHostUpdateEvent(host);
                hostManager.updateHostState(host);
            }
        }
    }

    @Nonnull
    public SpawnState getSpawnState() {
        return spawnState;
    }

    @Nonnull
    public JobDefaults getJobDefaults() { return jobDefaults; }

    @Nonnull
    public SpawnDataStore getSpawnDataStore() {
        return spawnDataStore;
    }

}

<code block>

package com.addthis.hydra.job.spawn;

import javax.annotation.Nonnull;
import javax.annotation.Nullable;

import java.util.ArrayList;
import java.util.List;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import com.addthis.hydra.job.mq.HostState;

import org.apache.curator.framework.CuratorFramework;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import static com.addthis.hydra.job.store.SpawnDataStoreKeys.MINION_DEAD_PATH;
import static com.addthis.hydra.job.store.SpawnDataStoreKeys.MINION_UP_PATH;

public class HostManager {
    private static final Logger log = LoggerFactory.getLogger(HostManager.class);

    @Nonnull final ConcurrentMap<String, HostState> monitored;
    @Nonnull final SetMembershipListener minionMembers;
    @Nonnull final SetMembershipListener deadMinionMembers;

    public HostManager(CuratorFramework zkClient) {
        this.monitored = new ConcurrentHashMap<>();
        this.minionMembers = new SetMembershipListener(zkClient, MINION_UP_PATH);
        this.deadMinionMembers = new SetMembershipListener(zkClient, MINION_DEAD_PATH);
    }

    public HostState getHostState(String hostUuid) {
        if (hostUuid == null) {
            return null;
        }
        synchronized (monitored) {
            return monitored.get(hostUuid);
        }
    }

    public void updateHostState(HostState state) {
        synchronized (monitored) {
            if (!deadMinionMembers.getMemberSet().contains(state.getHostUuid())) {
                log.debug("Updating host state for : {}", state.getHost());
                monitored.put(state.getHostUuid(), state);
            }
        }
    }

    
    public List<HostState> listHostStatus(@Nullable String minionType) {
        synchronized (monitored) {
            Set<String> availableMinions = minionMembers.getMemberSet();
            Set<String> deadMinions = deadMinionMembers.getMemberSet();
            List<HostState> allMinions = new ArrayList<>();
            for (HostState minion : monitored.values()) {
                if (availableMinions.contains(minion.getHostUuid()) && !deadMinions.contains(minion.getHostUuid())) {
                    minion.setUp(true);
                } else {
                    minion.setUp(false);
                }
                if ((minionType == null) || minion.hasType(minionType)) {
                    allMinions.add(minion);
                }
            }
            return allMinions;
        }
    }

    public List<HostState> getLiveHosts(@Nullable String minionType) {
        List<HostState> allHosts = listHostStatus(minionType);
        List<HostState> rv = new ArrayList<>(allHosts.size());
        for (HostState host : allHosts) {
            if (host.isUp() && !host.isDead()) {
                rv.add(host);
            }
        }
        return rv;
    }
}
<code block>

package com.addthis.hydra.job.spawn.balancer;

public enum RebalanceWeight {LIGHT, MEDIUM, HEAVY}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import java.util.ArrayList;

import com.addthis.hydra.job.JobTaskMoveAssignment;
import com.addthis.hydra.job.spawn.Spawn;

class MoveAssignmentList extends ArrayList<JobTaskMoveAssignment> {
    private static final long serialVersionUID = -563719566151798849L;

    private final Spawn spawn;
    private final SpawnBalancerTaskSizer taskSizer;

    private long bytesUsed = 0;

    public MoveAssignmentList(Spawn spawn, SpawnBalancerTaskSizer taskSizer) {
        this.spawn = spawn;
        this.taskSizer = taskSizer;
    }

    @Override
    public boolean add(JobTaskMoveAssignment assignment) {
        bytesUsed += taskSizer.estimateTrueSize(spawn.getTask(assignment.getJobKey()));
        return super.add(assignment);
    }

    public long getBytesUsed() {
        return bytesUsed;
    }
}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import java.util.concurrent.TimeUnit;

import com.addthis.basis.util.Parameter;

import com.addthis.codec.annotations.Bytes;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.codec.annotations.Time;
import com.addthis.codec.codables.Codable;

import com.fasterxml.jackson.annotation.JsonAutoDetect;


@JsonAutoDetect(getterVisibility = JsonAutoDetect.Visibility.NONE,
                isGetterVisibility = JsonAutoDetect.Visibility.NONE,
                setterVisibility = JsonAutoDetect.Visibility.NONE)
public class SpawnBalancerConfig implements Codable {

    
    @FieldConfig
    private int autoBalanceLevel = 0;

    
    @FieldConfig
    private int tasksMovedFullRebalance = Parameter.intValue("spawnbalance.tasks.fullbalance", 10);
    
    @Bytes
    @FieldConfig
    private long bytesMovedFullRebalance = Parameter.longValue("spawnbalance.bytes.fullbalance", 300L * 1000 * 1000 * 1000);
    
    private double singleTaskBytesFactor = Double.parseDouble(Parameter.value("spawnbalance.task.factor", ".8"));
    
    private double hostDiskFactor = Double.parseDouble(Parameter.value("spawnbalance.host.factor", ".75"));
    
    private int tasksMovedPerUnspecifiedHost = Parameter.intValue("spawnbalance.host.unspecified", 4);
    
    private int minTaskSizeBytes = Parameter.intValue("spawnbalance.mintaskbytes", 50 * 1000 * 1000);

    
    private double extremeHostRatio = Double.parseDouble(Parameter.value("spawnbalance.extreme.ratio", "1.1"));
    
    private double extremeHostPercentile = Double.parseDouble(Parameter.value("spawnbalance.extreme.perc", ".5"));
    
    
    private double alleviateHostPercentage = Double.parseDouble(Parameter.value("spawnbalance.alleviate.perc", ".2"));

    private int autobalanceCheckInterval = Parameter.intValue("spawnbalance.check.autobalance", 60 * 1000);
    
    @Time(TimeUnit.MILLISECONDS)
    @FieldConfig
    private int jobAutobalanceIntervalMillis = Parameter.intValue("spawnbalance.interval.job.autobalance", 4 * 60 * 60 * 1000);
    
    @Time(TimeUnit.MILLISECONDS)
    @FieldConfig
    private int hostAutobalanceIntervalMillis = Parameter.intValue("spawnbalance.interval.host.autobalance", 6 * 60 * 60 * 1000);
    
    private long lastJobAutobalanceTime = 0L;

    
    private double minDiskPercentAvailToReceiveNewTasks = Double.parseDouble(Parameter.value("spawnbalance.min.disk.percent.avail.newtasks", ".2"));
    
    private double minDiskPercentAvailToRunJobs = Double.parseDouble(Parameter.value("spawnbalance.min.disk.percent.avail.runtasks", ".1"));
    
    private int maxReadonlyReplicas = Parameter.intValue("spawnbalance.max.job.task.replicas.per.host", 5);

    
    private int activeTaskMilliCutoff = Parameter.intValue("spawnbalance.active.task.cutoff", 24 * 60 * 60 * 1000);
    
    private boolean allowSameHostReplica = Parameter.boolValue("spawnbalance.replica.same_host", true);
    
    private int siblingWeight = Parameter.intValue("spawnbalance.sib.wt", 40);
    
    private int activeTaskWeight = Parameter.intValue("spawnbalance.active.task.wt", 30);
    
    private int diskUsedWeight = Parameter.intValue("spawnbalance.disk.used.wt", 70);
    
    private double defaultHostScore = Parameter.intValue("spawnbalance.default.host.score", 100);

    public int getAutoBalanceLevel() {
        return autoBalanceLevel;
    }

    public void setAutoBalanceLevel(int autoBalanceLevel) {
        this.autoBalanceLevel = autoBalanceLevel;
    }

    public int getTasksMovedFullRebalance() {
        return tasksMovedFullRebalance;
    }

    public void setTasksMovedFullRebalance(int tasksMovedFullRebalance) {
        this.tasksMovedFullRebalance = tasksMovedFullRebalance;
    }

    public long getBytesMovedFullRebalance() {
        return bytesMovedFullRebalance;
    }

    public void setBytesMovedFullRebalance(long bytesMovedFullRebalance) {
        this.bytesMovedFullRebalance = bytesMovedFullRebalance;
    }

    public double getSingleTaskBytesFactor() {
        return singleTaskBytesFactor;
    }

    public void setSingleTaskBytesFactor(double singleTaskBytesFactor) {
        this.singleTaskBytesFactor = singleTaskBytesFactor;
    }

    public int getTasksMovedPerUnspecifiedHost() {
        return tasksMovedPerUnspecifiedHost;
    }

    public void setTasksMovedPerUnspecifiedHost(int tasksMovedPerUnspecifiedHost) {
        this.tasksMovedPerUnspecifiedHost = tasksMovedPerUnspecifiedHost;
    }

    public int getMinTaskSizeBytes() {
        return minTaskSizeBytes;
    }

    public void setMinTaskSizeBytes(int minTaskSizeBytes) {
        this.minTaskSizeBytes = minTaskSizeBytes;
    }

    public double getExtremeHostRatio() {
        return extremeHostRatio;
    }

    public void setExtremeHostRatio(double extremeHostRatio) {
        this.extremeHostRatio = extremeHostRatio;
    }

    public double getExtremeHostPercentile() {
        return extremeHostPercentile;
    }

    public void setExtremeHostPercentile(double extremeHostPercentile) {
        this.extremeHostPercentile = extremeHostPercentile;
    }

    public double getAlleviateHostPercentage() {
        return alleviateHostPercentage;
    }

    public void setAlleviateHostPercentage(double alleviateHostPercentage) {
        this.alleviateHostPercentage = alleviateHostPercentage;
    }

    public int getAutobalanceCheckInterval() {
        return autobalanceCheckInterval;
    }

    public int getJobAutobalanceIntervalMillis() {
        return jobAutobalanceIntervalMillis;
    }

    public void setJobAutobalanceIntervalMillis(int jobAutobalanceIntervalMillis) {
        this.jobAutobalanceIntervalMillis = jobAutobalanceIntervalMillis;
    }

    public int getHostAutobalanceIntervalMillis() {
        return hostAutobalanceIntervalMillis;
    }

    public void setHostAutobalanceIntervalMillis(int hostAutobalanceIntervalMillis) {
        this.hostAutobalanceIntervalMillis = hostAutobalanceIntervalMillis;
    }

    public long getLastJobAutobalanceTime() {
        return lastJobAutobalanceTime;
    }

    public void setLastJobAutobalanceTime(long lastJobAutobalanceTime) {
        this.lastJobAutobalanceTime = lastJobAutobalanceTime;
    }

    public double getMinDiskPercentAvailToReceiveNewTasks() {
        return minDiskPercentAvailToReceiveNewTasks;
    }

    public void setMinDiskPercentAvailToReceiveNewTasks(double minDiskPercentAvailToReceiveNewTasks) {
        this.minDiskPercentAvailToReceiveNewTasks = minDiskPercentAvailToReceiveNewTasks;
    }

    public double getMinDiskPercentAvailToRunJobs() {
        return minDiskPercentAvailToRunJobs;
    }

    public void setMinDiskPercentAvailToRunJobs(double minDiskPercentAvailToRunJobs) {
        this.minDiskPercentAvailToRunJobs = minDiskPercentAvailToRunJobs;
    }

    public int getMaxReadonlyReplicas() {
        return maxReadonlyReplicas;
    }

    public void setMaxReadonlyReplicas(int maxReadonlyReplicas) {
        this.maxReadonlyReplicas = maxReadonlyReplicas;
    }

    public int getActiveTaskMilliCutoff() {
        return activeTaskMilliCutoff;
    }

    public void setActiveTaskMilliCutoff(int getActiveTaskMilliCutoff) {
        this.activeTaskMilliCutoff = getActiveTaskMilliCutoff;
    }

    public int getSiblingWeight() {
        return siblingWeight;
    }

    public void setSiblingWeight(int siblingWeight) {
        this.siblingWeight = siblingWeight;
    }

    public int getActiveTaskWeight() {
        return activeTaskWeight;
    }

    public void setActiveTaskWeight(int activeTaskWeight) {
        this.activeTaskWeight = activeTaskWeight;
    }

    public int getDiskUsedWeight() {
        return diskUsedWeight;
    }

    public void setDiskUsedWeight(int diskUsedWeight) {
        this.diskUsedWeight = diskUsedWeight;
    }

    public double getDefaultHostScore() {
        return defaultHostScore;
    }

    public void setDefaultHostScore(double defaultHostScore) {
        this.defaultHostScore = defaultHostScore;
    }

    public boolean allowSameHostReplica() {
        return allowSameHostReplica;
    }

    public void setAllowSameHostReplica(boolean allowSameHostReplica) {
        this.allowSameHostReplica = allowSameHostReplica;
    }

    public double getHostDiskFactor() {
        return hostDiskFactor;
    }

    public void setHostDiskFactor(double hostDiskFactor) {
        this.hostDiskFactor = hostDiskFactor;
    }
}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import com.addthis.hydra.job.mq.HostState;

final class HostAndScore {

    final HostState host;
    final double score;

    HostAndScore(HostState host, double score) {
        this.host = host;
        this.score = score;
    }
}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Set;

import com.addthis.hydra.job.JobTask;
import com.addthis.hydra.job.JobTaskReplica;
import com.addthis.hydra.job.mq.HostState;


class JobTaskItemByHostMap extends HashMap<String, Set<JobTaskItem>> {

    private final SpawnBalancer spawnBalancer;
    private final HashMap<String, Integer> pushedTaskCounts;
    private final HashMap<String, Integer> pulledTaskCounts;
    private final int maxPulledFromHost;
    private final int maxPushedToHost;

    private List<String> hostsSorted = null;

    public JobTaskItemByHostMap(SpawnBalancer spawnBalancer,
                                Iterable<HostState> hosts,
                                int maxPulledFromHost,
                                int maxPushedToHost) {
        this.spawnBalancer = spawnBalancer;
        this.pulledTaskCounts = new HashMap<>();
        this.pushedTaskCounts = new HashMap<>();
        this.maxPulledFromHost = maxPulledFromHost;
        this.maxPushedToHost = maxPushedToHost;
        for (HostState host : hosts) {
            if (host.isUp() && !host.isDead()) {
                put(host.getHostUuid(), new HashSet<>());
            }
        }
    }

    public void add(String hostID, JobTask task) {
        if (containsKey(hostID)) {
            Set<JobTaskItem> current = get(hostID);
            current.add(new JobTaskItem(task));
        }
    }

    public void addLiveAndReplicasForTask(JobTask task) {
        add(task.getHostUUID(), task);
        List<JobTaskReplica> replicas = task.getReplicas();
        if (replicas != null) {
            for (JobTaskReplica replica : replicas) {
                add(replica.getHostUUID(), task);
            }
        }
    }

    public boolean moveTask(JobTaskItem item, String fromHost, String toHost) {
        if (!containsKey(fromHost)
            || !containsKey(toHost)
            || !get(fromHost).contains(item)
            || get(toHost).contains(item)
            || !hasCapacity(pulledTaskCounts, fromHost, maxPulledFromHost)
            || !hasCapacity(pushedTaskCounts, toHost, maxPushedToHost)) {
            return false;
        } else {
            boolean success = get(fromHost).remove(item) && get(toHost).add(item);
            if (success) {
                claimCapacity(pulledTaskCounts, fromHost);
                claimCapacity(pushedTaskCounts, toHost);
            }
            return success;
        }
    }

    public List<String> generateHostsSorted() {
        List<String> rv = new ArrayList<>(this.keySet());
        Collections.sort(rv, (s, s1) -> {
            int count = get(s).size();
            int count1 = get(s1).size();
            if (count == count1) {
                return Double.compare(spawnBalancer.getHostScoreCached(s), spawnBalancer.getHostScoreCached(s1));
            } else {
                return Double.compare(count, count1);
            }
        });
        hostsSorted = rv;
        return new ArrayList<>(rv);
    }


    public Iterator<String> getHostIterator(boolean smallFirst) {
        if (hostsSorted == null) {
            generateHostsSorted();
        }
        List<String> copy = new ArrayList<>(hostsSorted);
        if (!smallFirst) {
            Collections.reverse(copy);
        }
        return copy.iterator();
    }

    private boolean hasCapacity(HashMap<String, Integer> map, String key, int max) {
        return !map.containsKey(key) || (map.get(key) < max);
    }

    private void claimCapacity(HashMap<String, Integer> map, String key) {
        if (map.containsKey(key)) {
            map.put(key, map.get(key) + 1);
        } else {
            map.put(key, 1);
        }
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder("{");
        for (Entry<String, Set<JobTaskItem>> entry : this.entrySet()) {
            sb.append(entry.getKey()).append(":").append(entry.getValue().size()).append("; ");
        }
        return sb.append("}").toString();
    }

    public int findLeastTasksOnHost() {
        if (hostsSorted == null) {
            generateHostsSorted();
        }
        return get(hostsSorted.get(0)).size();
    }

    public int findMostTasksOnHost() {
        if (hostsSorted == null) {
            generateHostsSorted();
        }
        return get(hostsSorted.get(hostsSorted.size() - 1)).size();
    }
}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import com.addthis.basis.util.JitterClock;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


class AggregateStatUpdaterTask implements Runnable {

    private final SpawnBalancer spawnBalancer;

    public AggregateStatUpdaterTask(SpawnBalancer spawnBalancer) {
        this.spawnBalancer = spawnBalancer;
    }

    @Override public void run() {
        if ((JitterClock.globalTime() - spawnBalancer.lastAggregateStatUpdateTime) > SpawnBalancer.AGGREGATE_STAT_UPDATE_INTERVAL) {
            spawnBalancer.updateAggregateStatistics(spawnBalancer.hostManager.listHostStatus(null));
        }
    }
}

<code block>

package com.addthis.hydra.job.spawn.balancer;

final class HostScore {

    private final double meanActiveTasks;
    private final double usedDiskPercent;
    private final double overallScore;

    HostScore(double meanActiveTasks, double usedDiskPercent, double overallScore) {
        this.meanActiveTasks = meanActiveTasks;
        this.usedDiskPercent = usedDiskPercent;
        this.overallScore = overallScore;
    }

    public double getOverallScore() {
        return overallScore;
    }

    public double getScoreValue(boolean diskSpace) {
        return diskSpace ? usedDiskPercent : meanActiveTasks;
    }
}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import javax.annotation.Nullable;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.PriorityQueue;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.ReentrantLock;

import com.addthis.basis.util.JitterClock;
import com.addthis.basis.util.Parameter;

import com.addthis.codec.annotations.FieldConfig;
import com.addthis.codec.codables.Codable;
import com.addthis.codec.config.Configs;
import com.addthis.codec.json.CodecJSON;
import com.addthis.hydra.job.HostFailWorker;
import com.addthis.hydra.job.IJob;
import com.addthis.hydra.job.Job;
import com.addthis.hydra.job.JobState;
import com.addthis.hydra.job.JobTask;
import com.addthis.hydra.job.JobTaskMoveAssignment;
import com.addthis.hydra.job.JobTaskReplica;
import com.addthis.hydra.job.JobTaskState;
import com.addthis.hydra.job.mq.CommandTaskStop;
import com.addthis.hydra.job.mq.CoreMessage;
import com.addthis.hydra.job.mq.HostState;
import com.addthis.hydra.job.mq.JobKey;
import com.addthis.hydra.job.spawn.HostManager;
import com.addthis.hydra.job.spawn.Spawn;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.base.Strings;
import com.google.common.cache.Cache;
import com.google.common.cache.CacheBuilder;
import com.google.common.collect.ImmutableSet;
import com.google.common.collect.Lists;
import com.google.common.util.concurrent.MoreExecutors;
import com.google.common.util.concurrent.ThreadFactoryBuilder;

import com.fasterxml.jackson.annotation.JsonAutoDetect;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import static com.addthis.hydra.job.JobTaskState.IDLE;
import static com.addthis.hydra.job.JobTaskState.QUEUED;
import static com.addthis.hydra.job.JobTaskState.QUEUED_HOST_UNAVAIL;
import static com.addthis.hydra.job.JobTaskState.QUEUED_NO_SLOT;
import static com.addthis.hydra.job.store.SpawnDataStoreKeys.SPAWN_BALANCE_PARAM_PATH;


@JsonAutoDetect(getterVisibility = JsonAutoDetect.Visibility.NONE,
        isGetterVisibility = JsonAutoDetect.Visibility.NONE,
        setterVisibility = JsonAutoDetect.Visibility.NONE)
public class SpawnBalancer implements Codable, AutoCloseable {
    private static final Logger log = LoggerFactory.getLogger(SpawnBalancer.class);

    private static final Set<JobTaskState> movableTaskStates = ImmutableSet.of(
            IDLE, QUEUED, QUEUED_HOST_UNAVAIL, QUEUED_NO_SLOT);

    
    static final long AGGREGATE_STAT_UPDATE_INTERVAL = Parameter.intValue("spawnbalance.stat.update", 15 * 1000);

    private final ConcurrentHashMap<String, HostScore> cachedHostScores;
    private final ReentrantLock aggregateStatisticsLock;
    private final AtomicBoolean autobalanceStarted;
    private final Cache<String, Boolean> recentlyAutobalancedJobs;
    private final Cache<String, Boolean> recentlyBalancedHosts;
    private final Cache<String, Boolean> recentlyReplicatedToHosts;
    private final SpawnBalancerTaskSizer taskSizer;
    private final Comparator<HostAndScore> hostAndScoreComparator;
    private final Comparator<HostState> hostStateScoreComparator;
    private final Comparator<Job> jobAverageTaskSizeComparator;
    private final Comparator<HostState> hostStateReplicationSuitabilityComparator;
    private final ScheduledExecutorService taskExecutor;

    final Spawn spawn;
    final HostManager hostManager;

    private Set<String> activeJobIDs;
    long lastAggregateStatUpdateTime;

    @FieldConfig SpawnBalancerConfig config;

    public SpawnBalancer(Spawn spawn, HostManager hostManager) {
        this.spawn = spawn;
        this.hostManager = hostManager;
        config = loadConfigFromDataStore(new SpawnBalancerConfig());
        taskExecutor = new ScheduledThreadPoolExecutor(
                2, new ThreadFactoryBuilder().setNameFormat("spawnBalancer-%d").build());
        taskExecutor.scheduleAtFixedRate(new AggregateStatUpdaterTask(this), AGGREGATE_STAT_UPDATE_INTERVAL,
                                         AGGREGATE_STAT_UPDATE_INTERVAL, TimeUnit.MILLISECONDS);
        taskSizer = new SpawnBalancerTaskSizer(spawn, hostManager);
        cachedHostScores = new ConcurrentHashMap<>();
        aggregateStatisticsLock = new ReentrantLock();
        lastAggregateStatUpdateTime = 0;
        autobalanceStarted = new AtomicBoolean(false);
        recentlyAutobalancedJobs = CacheBuilder.newBuilder().expireAfterWrite(
                Parameter.intValue("spawnbalance.job.autobalance.interval.mins", 60 * 12), TimeUnit.MINUTES
        ).build();
        recentlyBalancedHosts = CacheBuilder.newBuilder().expireAfterWrite(
                Parameter.intValue("spawnbalance.host.balance.interval.mins", 3), TimeUnit.MINUTES
        ).build();
        recentlyReplicatedToHosts = CacheBuilder.newBuilder().expireAfterWrite(
                Parameter.intValue("spawnbalance.host.replicate.interval.mins", 15), TimeUnit.MINUTES
        ).build();
        hostAndScoreComparator = (firstHAS, secondHAS) -> Double.compare(firstHAS.score, secondHAS.score);
        hostStateScoreComparator = (hostState, hostState1) -> Double.compare(
                getHostScoreCached(hostState.getHostUuid()),
                getHostScoreCached(hostState1.getHostUuid()));
        jobAverageTaskSizeComparator = (job, job1) -> {
            if ((job == null) || (job1 == null)) {
                return 0;
            } else {
                return Double.compare(job.calcAverageTaskSizeBytes(), job1.calcAverageTaskSizeBytes());
            }
        };
        hostStateReplicationSuitabilityComparator = (hostState, hostState1) -> {
            
            long availBytes = getAvailDiskBytes(hostState);
            long availBytes1 = getAvailDiskBytes(hostState1);
            if (recentlyReplicatedToHosts.getIfPresent(hostState.getHostUuid()) != null) {
                availBytes /= 2;
            }
            if (recentlyReplicatedToHosts.getIfPresent(hostState1.getHostUuid()) != null) {
                availBytes1 /= 2;
            }
            return -Double.compare(availBytes, availBytes1);
        };
    }

    
    @VisibleForTesting
    protected SpawnBalancerConfig loadConfigFromDataStore(SpawnBalancerConfig defaultValue) {
        String configString = spawn.getSpawnDataStore().get(SPAWN_BALANCE_PARAM_PATH);
        if (!Strings.isNullOrEmpty(configString)) {
            try {
                return Configs.decodeObject(SpawnBalancerConfig.class, configString);
            } catch (Exception e) {
                log.warn("Failed to decode SpawnBalancerConfig", e);
            }
        }
        return defaultValue;
    }

    
    public double getHostScoreCached(String hostId) {
        double defaultScore = config.getDefaultHostScore();
        if (hostId == null) {
            return defaultScore;
        }
        aggregateStatisticsLock.lock();
        try {
            if (cachedHostScores == null) {
                return defaultScore;
            }
            HostScore score = cachedHostScores.get(hostId);
            if (score != null) {
                return score.getOverallScore();
            } else {
                return defaultScore;
            }
        } finally {
            aggregateStatisticsLock.unlock();
        }
    }

    private static long getAvailDiskBytes(HostState host) {
        if ((host.getMax() == null) || (host.getUsed() == null)) {
            return 1; 
        }
        return host.getMax().getDisk() - host.getUsed().getDisk();
    }

    
    public synchronized void startAutobalanceTask() {
        if (autobalanceStarted.compareAndSet(false, true)) {
            taskExecutor.scheduleWithFixedDelay(new AutobalanceTask(this), config.getAutobalanceCheckInterval(),
                                                config.getAutobalanceCheckInterval(), TimeUnit.MILLISECONDS);
        }
    }

    
    private synchronized boolean shouldAutobalanceJob(Job job, List<HostState> hosts) {
        if ((job == null)
            || (recentlyAutobalancedJobs.getIfPresent(job.getId()) != null)
            || (JobState.IDLE != job.getState())
            || job.getDontAutoBalanceMe()
            || (job.getRunCount() < 1)) {
            return false;
        }
        if (config.getAutoBalanceLevel() >= 2) {
            
            return true;
        }
        JobTaskItemByHostMap tasksByHost = generateTaskCountByHost(hosts, job.getCopyOfTasks());
        int maxPerHost = maxTasksPerHost(job, hosts.size());
        
        return (tasksByHost.findLeastTasksOnHost() <= (maxPerHost - 2)) ||
               (tasksByHost.findMostTasksOnHost() >= (maxPerHost + 1));
    }

    @Override public void close() {
        MoreExecutors.shutdownAndAwaitTermination(taskExecutor, 120, TimeUnit.SECONDS);
    }

    public void saveConfigToDataStore() {
        try {
            spawn.getSpawnDataStore().put(SPAWN_BALANCE_PARAM_PATH, CodecJSON.encodeString(config));
        } catch (Exception e) {
            log.warn("Failed to save SpawnBalancerConfig to data store", e);
        }
    }

    public void startTaskSizePolling() {
        taskSizer.startPolling(taskExecutor);
    }

    
    public Map<JobTask, String> assignTasksFromMultipleJobsToHosts(Collection<JobTask> tasks,
                                                                   Collection<HostState> hosts) {
        
        Map<String, List<JobTask>> tasksByJobID = new HashMap<>();
        for (JobTask task : tasks) {
            if (task.getJobUUID() != null) {
                Job job = spawn.getJob(task.getJobUUID());
                if (job != null) {
                    List<JobTask> taskList = tasksByJobID.computeIfAbsent(job.getId(), key -> new ArrayList<>());
                    taskList.add(task);
                }
            }
        }
        
        Map<HostState, Double> hostScoreMap = generateHostStateScoreMap(hosts, null);
        
        Map<JobTask, String> hostAssignments = new HashMap<>(tasks.size());
        for (Map.Entry<String, List<JobTask>> entry : tasksByJobID.entrySet()) {
            Map<JobTask, String> singleHostAssignments =
                    assignTasksFromSingleJobToHosts(entry.getValue(), hostScoreMap);
            hostAssignments.putAll(singleHostAssignments);
        }
        return hostAssignments;
    }

    
    private Map<HostState, Double> generateHostStateScoreMap(Collection<HostState> hosts, @Nullable String jobID) {
        final Map<HostState, Double> hostScores = new HashMap<>(hosts.size());
        for (HostState host : hosts) {
            if ((host != null) && host.isUp() && !host.isDead()) {
                int siblingScore = (jobID != null) ? (host.getTaskCount(jobID) * config.getSiblingWeight()) : 0;
                double score = getHostScoreCached(host.getHostUuid()) + siblingScore;
                hostScores.put(host, score);
            }
        }
        return hostScores;
    }

    
    private Map<JobTask, String> assignTasksFromSingleJobToHosts(List<JobTask> tasks,
                                                                 Map<HostState, Double> storedHostScores) {
        if ((tasks == null) || tasks.isEmpty()) {
            return new HashMap<>();
        }
        
        PriorityQueue<HostAndScore> hostScores =
                new PriorityQueue<>(1 + storedHostScores.size(), hostAndScoreComparator);
        for (Map.Entry<HostState, Double> hostStateDoubleEntry : storedHostScores.entrySet()) {
            if (canReceiveNewTasks(hostStateDoubleEntry.getKey())) {
                hostScores.add(new HostAndScore(hostStateDoubleEntry.getKey(), hostStateDoubleEntry.getValue()));
            }
        }
        if (hostScores.isEmpty()) {
            log.warn("[spawn.balancer] found no hosts eligible to receive new tasks");
            throw new RuntimeException("no eligible hosts for new task");
        }
        
        Collection<String> hostsToAssign = new ArrayList<>(tasks.size());
        for (JobTask task : tasks) {
            if (task == null) {
                continue;
            }
            
            HostAndScore h = hostScores.poll();
            HostState host = h.host;
            hostsToAssign.add(host.getHostUuid());
            
            hostScores.add(new HostAndScore(host, h.score + config.getSiblingWeight()));
            
            
            storedHostScores.put(host, h.score + config.getActiveTaskWeight());
        }
        return pairTasksAndHosts(tasks, hostsToAssign);
    }

    public boolean canReceiveNewTasks(HostState host) {
        if (host == null) {
            return false;
        }
        if (spawn.getHostFailWorker().getFailureState(host.getHostUuid()) != HostFailWorker.FailState.ALIVE) {
            return false;
        }
        return host.canMirrorTasks() &&
               (getUsedDiskPercent(host) < (1 - config.getMinDiskPercentAvailToReceiveNewTasks()));
    }

    
    private static Map<JobTask, String> pairTasksAndHosts(List<JobTask> tasks, Collection<String> hosts) {
        if ((tasks == null) || (hosts == null) || (tasks.size() != hosts.size())) {
            log.warn("[spawn.balancer] invalid call to pairTasksAndHosts: tasks={} hosts={}", tasks, hosts);
            return new HashMap<>(0);
        }
        Map<JobTask, String> rv = new HashMap<>(tasks.size());
        
        Collection<JobTask> unassignedTasks = new ArrayList<>();
        String jobID = tasks.get(0).getJobUUID();
        for (JobTask task : tasks) {
            if (!task.getJobUUID().equals(jobID)) {
                throw new RuntimeException(
                        "Illegal call to assignTasksFromSingleJobToHosts: not all tasks came from the same job");
            }
            String hostID = task.getHostUUID();
            if ((hostID != null) && hosts.contains(hostID)) {
                hosts.remove(hostID);
            } else {
                unassignedTasks.add(task);
            }
        }
        
        Iterator<String> hostIterator = hosts.iterator();
        for (JobTask task : unassignedTasks) {
            rv.put(task, hostIterator.next());
        }
        return rv;
    }

    private static double getUsedDiskPercent(HostState host) {
        if ((host.getMax() == null) || (host.getUsed() == null) || (host.getMax().getDisk() <= 0)) {
            return 0;
        }
        return (double) host.getUsed().getDisk() / host.getMax().getDisk();
    }

    public List<JobTaskMoveAssignment> pushTasksOffDiskForFilesystemOkayFailure(HostState host, int moveLimit) {
        List<HostState> hosts = hostManager.listHostStatus(null);
        return pushTasksOffHost(host, hosts, false, 1, moveLimit, false);
    }

    
    private List<JobTaskMoveAssignment> pushTasksOffHost(HostState host,
                                                         Collection<HostState> otherHosts,
                                                         boolean limitBytes,
                                                         double byteLimitFactor,
                                                         int moveLimit,
                                                         boolean obeyDontAutobalanceMe) {
        List<JobTaskMoveAssignment> rv = purgeMisplacedTasks(host, moveLimit);
        if (rv.size() <= moveLimit) {
            long byteLimit = (long) (byteLimitFactor * config.getBytesMovedFullRebalance());
            List<HostState> hostsSorted = sortHostsByDiskSpace(otherHosts);
            for (JobTask task : findTasksToMove(host, obeyDontAutobalanceMe)) {
                long taskTrueSize = getTaskTrueSize(task);
                if (limitBytes && (taskTrueSize > byteLimit)) {
                    continue;
                }
                JobTaskMoveAssignment assignment = moveTask(task, host.getHostUuid(), hostsSorted);
                if (assignment != null) {
                    markRecentlyReplicatedTo(assignment.getTargetUUID());
                    rv.add(assignment);
                    byteLimit -= taskTrueSize;
                }
                if (rv.size() >= moveLimit) {
                    break;
                }
            }
        }
        return rv;
    }

    
    private List<JobTaskMoveAssignment> purgeMisplacedTasks(HostState host, int deleteLimit) {
        List<JobTaskMoveAssignment> rv = new ArrayList<>();
        for (JobKey key : host.allJobKeys()) {
            if (spawn.getJob(key) == null) {
                
                rv.add(new JobTaskMoveAssignment(key, host.getHostUuid(), null, false, true));
            } else {
                
                
                JobTask task = spawn.getTask(key);
                if (!host.getHostUuid().equals(task.getHostUUID()) && !task.hasReplicaOnHost(host.getHostUuid())) {
                    spawn.fixTaskDir(key.getJobUuid(), key.getNodeNumber(), false, false);
                    deleteLimit -= 1;
                }
            }
            if (rv.size() >= deleteLimit) {
                break;
            }
        }
        return rv;
    }

    
    @VisibleForTesting
    protected List<HostState> sortHostsByDiskSpace(Collection<HostState> hosts) {
        List<HostState> hostList = new ArrayList<>(hosts);
        removeDownHosts(hostList);
        Collections.sort(hostList, hostStateReplicationSuitabilityComparator);
        return hostList;
    }

    
    private Iterable<JobTask> findTasksToMove(HostState host, boolean obeyDontAutobalanceMe) {
        Collection<JobTask> rv = new ArrayList<>();
        if (host != null) {
            String hostId = host.getHostUuid();
            for (JobKey jobKey : host.allJobKeys()) {
                Job job = spawn.getJob(jobKey);
                JobTask task = spawn.getTask(jobKey);
                if ((job != null) && (task != null) && isInMovableState(task)
                    
                    && (hostId.equals(task.getHostUUID()) || task.hasReplicaOnHost(
                        host.getHostUuid()))) 
                {
                    if (obeyDontAutobalanceMe && job.getDontAutoBalanceMe()) {
                        
                        
                        
                        
                        
                        continue;
                    }
                    rv.add(task);
                }
            }
        }
        return rv;
    }

    public long getTaskTrueSize(JobTask task) {
        return taskSizer.estimateTrueSize(task);
    }

    
    @Nullable private JobTaskMoveAssignment moveTask(JobTask task,
                                                     String fromHostId,
                                                     Collection<HostState> otherHosts) {
        Iterator<HostState> hostStateIterator = otherHosts.iterator();
        String taskHost = task.getHostUUID();
        boolean live = task.getHostUUID().equals(fromHostId);
        if (!live && !task.hasReplicaOnHost(fromHostId)) {
            return null;
        }
        while (hostStateIterator.hasNext()) {
            HostState next = hostStateIterator.next();
            String nextId = next.getHostUuid();
            if (!taskHost.equals(nextId) && !task.hasReplicaOnHost(nextId) && next.canMirrorTasks() &&
                okToPutReplicaOnHost(next, task)) {
                hostStateIterator.remove();
                otherHosts.add(next);
                return new JobTaskMoveAssignment(task.getJobKey(), fromHostId, nextId, !live, false);
            }
        }
        return null;
    }

    @VisibleForTesting
    protected void markRecentlyReplicatedTo(String hostId) {
        if (hostId != null) {
            recentlyReplicatedToHosts.put(hostId, true);
        }
    }

    private static void removeDownHosts(Iterable<HostState> hosts) {
        Iterator<HostState> hostIter = hosts.iterator();
        while (hostIter.hasNext()) {
            HostState host = hostIter.next();
            if (host.isDead() || !host.isUp()) {
                hostIter.remove();
            }
        }
    }

    public static boolean isInMovableState(JobTask task) {
        return (task != null) && movableTaskStates.contains(task.getState());
    }

    
    private boolean okToPutReplicaOnHost(HostState hostCandidate, JobTask task) {
        Job job;
        String hostId;
        if ((hostCandidate == null) || ((hostId = hostCandidate.getHostUuid()) == null) ||
            !canReceiveNewTasks(hostCandidate) || ((job = spawn.getJob(task.getJobKey())) == null) ||
            !hostCandidate.getMinionTypes().contains(job.getMinionType())) {
            return false;
        }
        if (spawn.getHostFailWorker().getFailureState(hostId) != HostFailWorker.FailState.ALIVE) {
            return false;
        }
        HostState taskHost = hostManager.getHostState(task.getHostUUID());
        
        String existingHost = (taskHost != null) ? taskHost.getHost() : null;
        
        if (!config.allowSameHostReplica() && hostCandidate.getHost().equals(existingHost)) {
            return false;
        }
        
        if (task.getHostUUID().equals(hostCandidate.getHostUuid()) ||
            task.hasReplicaOnHost(hostCandidate.getHostUuid())) {
            return false;
        }
        
        if (taskSizer.estimateTrueSize(task) > (config.getHostDiskFactor() * getAvailDiskBytes(hostCandidate))) {
            return false;
        }
        return true;
    }

    
    public boolean okayToAutobalance() {
        
        if ((config.getAutoBalanceLevel() == 0) ||
            spawn.getSystemManager().isQuiesced() ||
            (spawn.getLastQueueSize() > hostManager.listHostStatus(null).size())) {
            return false;
        }
        
        for (Job job : spawn.listJobs()) {
            if (JobState.REBALANCE.equals(job.getState())) {
                return false;
            }
        }
        return true;
    }

    
    @Nullable public List<JobTaskMoveAssignment> getAssignmentsForAutoBalance(RebalanceType type,
                                                                              RebalanceWeight weight) {
        List<HostState> hosts = hostManager.getLiveHosts(null);
        switch (type) {
            case HOST:
                if (hosts.isEmpty()) {
                    return null;
                }
                List<HostState> hostsSorted = new ArrayList<>(hosts);
                Collections.sort(hostsSorted, hostStateScoreComparator);
                HostState hostToBalance = hostsSorted.get(getWeightedElementIndex(hostsSorted.size(), weight));
                return getAssignmentsToBalanceHost(hostToBalance,
                                                   hostManager.listHostStatus(hostToBalance.getMinionTypes()));
            case JOB:
                List<Job> autobalanceJobs = getJobsToAutobalance(hosts);
                if ((autobalanceJobs == null) || autobalanceJobs.isEmpty()) {
                    return null;
                }
                Job jobToBalance = autobalanceJobs.get(getWeightedElementIndex(autobalanceJobs.size(), weight));
                recentlyAutobalancedJobs.put(jobToBalance.getId(), true);
                return getAssignmentsForJobReallocation(jobToBalance, -1,
                                                        hostManager.listHostStatus(jobToBalance.getMinionType()));
            default:
                throw new IllegalArgumentException("unknown rebalance type " + type);
        }
    }

    public List<Job> getJobsToAutobalance(List<HostState> hosts) {
        List<Job> autobalanceJobs = new ArrayList<>();
        for (Job job : spawn.listJobs()) {
            if (shouldAutobalanceJob(job, hosts)) {
                autobalanceJobs.add(job);
            }
        }
        Collections.sort(autobalanceJobs, jobAverageTaskSizeComparator);
        return autobalanceJobs;
    }

    public Map<Integer, List<String>> getAssignmentsForNewReplicas(IJob job) {
        return getAssignmentsForNewReplicas(job, -1);
    }

    
    public Map<Integer, List<String>> getAssignmentsForNewReplicas(IJob job, int taskID) {
        Map<Integer, List<String>> rv = new HashMap<>();
        if (job == null) {
            return rv;
        }
        int replicaCount = job.getReplicas();
        Map<String, Double> scoreMap = generateTaskCountHostScoreMap(job);
        PriorityQueue<HostAndScore> scoreHeap = new PriorityQueue<>(1, hostAndScoreComparator);
        for (Map.Entry<String, Double> entry : scoreMap.entrySet()) {
            scoreHeap.add(new HostAndScore(hostManager.getHostState(entry.getKey()), entry.getValue()));
        }
        Map<String, Integer> allocationMap = new HashMap<>();
        List<JobTask> tasks = (taskID > 0) ? Collections.singletonList(job.getTask(taskID)) : job.getCopyOfTasks();
        for (JobTask task : tasks) {
            int numExistingReplicas = task.getReplicas() != null ? task.getReplicas().size() : 0;
            List<String> hostIDsToAdd = new ArrayList<>(replicaCount);
            
            for (int i = 0; i < (replicaCount - numExistingReplicas); i++) {
                for (HostAndScore hostAndScore : scoreHeap) {
                    HostState candidateHost = hostAndScore.host;
                    if ((candidateHost == null) || !candidateHost.canMirrorTasks()) {
                        continue;
                    }
                    int currentCount;
                    if (allocationMap.containsKey(candidateHost.getHostUuid())) {
                        currentCount = allocationMap.get(candidateHost.getHostUuid());
                    } else {
                        currentCount = 0;
                    }

                    if (okToPutReplicaOnHost(candidateHost, task)) {
                        hostIDsToAdd.add(candidateHost.getHostUuid());
                        scoreHeap.remove(hostAndScore);
                        scoreHeap.add(new HostAndScore(candidateHost, hostAndScore.score + 1));
                        allocationMap.put(candidateHost.getHostUuid(), currentCount + 1);
                        break;
                    }
                }
            }
            if (!hostIDsToAdd.isEmpty()) {
                rv.put(task.getTaskID(), hostIDsToAdd);
            }
        }
        return rv;
    }

    
    private Map<String, Double> generateTaskCountHostScoreMap(IJob job) {
        Map<String, Double> rv = new HashMap<>();
        if (job != null) {
            List<JobTask> tasks = job.getCopyOfTasks();
            for (JobTask task : tasks) {
                rv.put(task.getHostUUID(), addOrIncrement(rv.get(task.getHostUUID()), 1d));
                if (task.getReplicas() == null) {
                    continue;
                }
                for (JobTaskReplica replica : task.getReplicas()) {
                    rv.put(replica.getHostUUID(), addOrIncrement(rv.get(replica.getHostUUID()), 1d));
                }
            }
            for (HostState host : hostManager.listHostStatus(job.getMinionType())) {
                if (host.isUp() && !host.isDead()) {
                    double availDisk = 1 - getUsedDiskPercent(host);
                    rv.put(host.getHostUuid(), addOrIncrement(rv.get(host.getHostUuid()), availDisk));
                }
            }
        }
        return rv;
    }

    private static double addOrIncrement(Double currentValue, Double value) {
        if (currentValue != null) {
            return currentValue + value;
        } else {
            return value;
        }
    }

    public void requestJobSizeUpdate(String jobId, int taskId) {
        taskSizer.requestJobSizeFetch(jobId, taskId);
    }

    public SpawnBalancerConfig getConfig() {
        return config;
    }

    public void setConfig(SpawnBalancerConfig config) {
        this.config = config;
    }

    public void clearRecentlyRebalancedHosts() {
        recentlyBalancedHosts.invalidateAll();
    }

    
    public void fixTasksForFailedHost(List<HostState> hosts, String failedHost) {
        List<JobTask> tasks = findAllTasksAssignedToHost(failedHost);
        List<JobTask> sortedTasks = new ArrayList<>(tasks);
        Collections.sort(sortedTasks,
                         (o1, o2) -> Long.compare(taskSizer.estimateTrueSize(o1), taskSizer.estimateTrueSize(o2)));
        hosts = sortHostsByDiskSpace(hosts);
        Collection<String> modifiedJobIds = new HashSet<>();
        for (JobTask task : sortedTasks) {
            modifiedJobIds.add(task.getJobUUID());
            try {
                attemptFixTaskForFailedHost(task, hosts, failedHost);
            } catch (Exception ex) {
                log.warn("Warning: failed to recover task {}", task.getJobKey(), ex);
            }
        }
        for (String jobId : modifiedJobIds) {
            try {
                spawn.updateJob(spawn.getJob(jobId));
            } catch (Exception e) {
                log.warn("Warning: failed to update job: {}", jobId, e);
            }
        }
    }

    private List<JobTask> findAllTasksAssignedToHost(String failedHostUUID) {
        List<JobTask> rv = new ArrayList<>();
        spawn.acquireJobLock();
        try {
            for (Job job : spawn.listJobs()) {
                if (job != null) {
                    for (JobTask task : job.getCopyOfTasks()) {
                        if ((task != null) &&
                            (task.getHostUUID().equals(failedHostUUID) || task.hasReplicaOnHost(failedHostUUID))) {
                            rv.add(task);
                        }
                    }
                }
            }
            return rv;
        } finally {
            spawn.releaseJobLock();
        }
    }

    
    private void attemptFixTaskForFailedHost(JobTask task, Collection<HostState> hosts, String failedHostUuid) {
        Iterator<HostState> hostIterator = hosts.iterator();
        Job job;
        if ((task == null) || (task.getJobUUID() == null) || ((job = spawn.getJob(task.getJobUUID())) == null)) {
            log.warn("Skipping nonexistent job for task {} during host fail.", task);
            return;
        }
        if (!task.getHostUUID().equals(failedHostUuid) && !task.hasReplicaOnHost(failedHostUuid)) {
            
            return;
        }
        if (!spawn.isNewTask(task) && ((task.getReplicas() == null) || task.getReplicas().isEmpty())) {
            log.warn("Found no replica for task {}", task.getJobKey());
            job.setState(JobState.DEGRADED, true);
            return;
        }
        while (hostIterator.hasNext()) {
            HostState host = hostIterator.next();
            if (host.getHostUuid().equals(failedHostUuid)) {
                continue;
            }
            if (host.canMirrorTasks() && okToPutReplicaOnHost(host, task)) {
                
                hostIterator.remove();
                hosts.add(host);
                executeHostFailureRecovery(task, failedHostUuid, host);
                return;
            }
        }
        log.warn("Failed to find a host that could hold {} after host failure", task.getJobKey());
        job.setState(JobState.DEGRADED, true);
    }

    
    private void executeHostFailureRecovery(JobTask task, String failedHostUuid, CoreMessage newReplicaHost) {
        boolean liveOnFailedHost = task.getHostUUID().equals(failedHostUuid);
        String newReplicaUuid = newReplicaHost.getHostUuid();
        if (liveOnFailedHost) {
            if (spawn.isNewTask(task)) {
                
                task.setHostUUID(newReplicaHost.getHostUuid());
            } else {
                
                spawn.sendControlMessage(
                        new CommandTaskStop(failedHostUuid, task.getJobUUID(), task.getTaskID(), 0, true, false));
                
                String chosenReplica = task.getReplicas().get(0).getHostUUID();
                task.replaceReplica(chosenReplica, newReplicaUuid);
                task.setHostUUID(chosenReplica);
                spawn.replicateTask(task, Collections.singletonList(newReplicaUuid));
            }
        } else {
            
            task.replaceReplica(failedHostUuid, newReplicaUuid);
            if (!spawn.isNewTask(task)) {
                spawn.replicateTask(task, Collections.singletonList(newReplicaUuid));
            }
        }
    }

    
    public List<JobTask> generateAssignedTasksForNewJob(String jobID, int taskCount, Collection<HostState> hosts)
            throws Exception {
        List<JobTask> tasks = generateUnassignedTaskList(jobID, taskCount);
        Map<JobTask, String> hostAssignments =
                assignTasksFromSingleJobToHosts(tasks, generateHostStateScoreMap(hosts, null));
        List<JobTask> rv = new ArrayList<>(tasks.size());
        for (Map.Entry<JobTask, String> entry : hostAssignments.entrySet()) {
            JobTask task = entry.getKey();
            String hostID = entry.getValue();
            if (hostID == null) {
                throw new RuntimeException("Unable to allocate job tasks because no suitable host was found");
            }
            task.setHostUUID(hostID);
            rv.add(task);
        }
        return rv;
    }

    
    private static List<JobTask> generateUnassignedTaskList(String jobID, int taskCount) {
        List<JobTask> rv = new ArrayList<>(Math.max(0, taskCount));
        for (int i = 0; i < taskCount; i++) {
            JobTask task = new JobTask();
            task.setJobUUID(jobID);
            task.setTaskID(i);
            rv.add(task);
        }
        return rv;
    }

    
    public List<JobTaskMoveAssignment> getAssignmentsForJobReallocation(Job job,
                                                                        int tasksToMove,
                                                                        List<HostState> hosts) {
        int maxTasksToMove = (tasksToMove > 0) ? tasksToMove : config.getTasksMovedFullRebalance();
        List<JobTaskMoveAssignment> candidateAssignments = new ArrayList<>();
        
        JobTaskItemByHostMap tasksByHost = generateTaskCountByHost(hosts, job.getCopyOfTasks());
        
        int maxPerHost = maxTasksPerHost(job, tasksByHost.size());
        if (log.isDebugEnabled()) {
            log.debug("Rebalancing job: {} maxTasksToMove={} maxPerHost={}", job.getId(), maxTasksToMove, maxPerHost);
        }
        while (candidateAssignments.size() < maxTasksToMove) {
            MoveAssignmentList moves = null;
            List<String> hostsSorted = tasksByHost.generateHostsSorted();
            String hostWithMost = hostsSorted.get(hostsSorted.size() - 1);
            String hostWithLeast = hostsSorted.get(0);
            int mostTasksOnHost = tasksByHost.findMostTasksOnHost();
            int leastTasksOnHost = tasksByHost.findLeastTasksOnHost();
            boolean isExtremeHost = isExtremeHost(hostWithMost, true, true);
            if (log.isDebugEnabled()) {
                log.debug(
                        "hostsSorted.size={} hostWithMost:{} hostWithLeast:{} mostTasksOnHost: {} leastTasksOnHost: {}",
                        hostsSorted.size(), hostWithMost, hostWithLeast, mostTasksOnHost, leastTasksOnHost);
            }

            
            if (mostTasksOnHost > maxPerHost) {
                moves = moveTasksOffHost(tasksByHost, maxPerHost, 1, -1, hostWithMost);
            } else if (leastTasksOnHost < (maxPerHost -
                                           1)) { 
                
                moves = moveTasksOntoHost(tasksByHost, maxPerHost, 1, -1, hostWithLeast);
            } else if (isExtremeHost) { 
                moves = moveTasksOffHost(tasksByHost, maxPerHost, 1, -1, hostWithMost);
            }
            if ((moves == null) || moves.isEmpty()) {
                break;
            } else {
                candidateAssignments.addAll(moves);
            }
        }
        if (candidateAssignments.size() > maxTasksToMove) {
            candidateAssignments = candidateAssignments.subList(0, maxTasksToMove);
        }
        candidateAssignments = removeDuplicateAssignments(candidateAssignments);
        return pruneTaskReassignments(candidateAssignments);
    }

    
    public List<JobTaskMoveAssignment> getAssignmentsToBalanceHost(HostState host, List<HostState> hosts) {
        String hostID = host.getHostUuid();
        List<JobTaskMoveAssignment> rv = new ArrayList<>();
        if ((hosts == null) || hosts.isEmpty()) {
            log.warn("[spawn.balancer] {} reallocation failed: host list empty", hostID);
            return rv;
        }
        List<HostState> sortedHosts = sortHostsByDiskSpace(hosts);
        HostFailWorker.FailState failState = spawn.getHostFailWorker().getFailureState(hostID);
        int numAlleviateHosts = (int) Math.ceil(sortedHosts.size() * config.getAlleviateHostPercentage());
        if ((failState == HostFailWorker.FailState.FAILING_FS_OKAY) || isExtremeHost(hostID, true, true) ||
            (getUsedDiskPercent(host) > (1 - config.getMinDiskPercentAvailToReceiveNewTasks()))) {
            
            log.info("[spawn.balancer] {} categorized as overloaded host; looking for tasks to push off of it", hostID);
            List<HostState> lightHosts = sortedHosts.subList(0, numAlleviateHosts);
            rv.addAll(pushTasksOffHost(host, lightHosts, true, 1, config.getTasksMovedFullRebalance(), true));
        } else if (isExtremeHost(hostID, true, false)) {
            
            log.info("[spawn.balancer] {} categorized as underloaded host; looking for tasks to pull onto it", hostID);
            List<HostState> heavyHosts =
                    Lists.reverse(sortedHosts.subList(sortedHosts.size() - numAlleviateHosts, sortedHosts.size()));
            pushTasksOntoDisk(host, heavyHosts);
        } else if (isExtremeHost(hostID, false, true)) {
            
            log.info("[spawn.balance] {} categorized as overworked host; looking for tasks to push off it", hostID);
            rv.addAll(balanceActiveJobsOnHost(host, hosts));
        }
        if (rv.isEmpty()) {
            rv.addAll(balanceActiveJobsOnHost(host, hosts));
        }
        return pruneTaskReassignments(rv);
    }

    
    public List<HostState> sortHostsByActiveTasks(Collection<HostState> hosts) {
        List<HostState> hostList = new ArrayList<>(hosts);
        removeDownHosts(hostList);
        Collections.sort(hostList, (hostState, hostState1) ->
                Double.compare(countTotalActiveTasksOnHost(hostState), countTotalActiveTasksOnHost(hostState1)));
        return hostList;
    }

    private int countTotalActiveTasksOnHost(HostState host) {
        int count = 0;
        if (host != null) {
            host.generateJobTaskCountMap();
            aggregateStatisticsLock.lock();
            try {
                if (activeJobIDs == null) {
                    activeJobIDs = findActiveJobIDs();
                }
                for (String jobID : activeJobIDs) {
                    count += host.getTaskCount(jobID);
                }
            } finally {
                aggregateStatisticsLock.unlock();
            }
        }

        return count;
    }

    private Set<String> findActiveJobIDs() {
        aggregateStatisticsLock.lock();
        try {
            activeJobIDs = new HashSet<>();
            Collection<Job> jobs = spawn.listJobs();
            if ((jobs != null) && !jobs.isEmpty()) {
                for (Job job : jobs) {
                    if (isWellFormedAndActiveJob(job)) {
                        activeJobIDs.add(job.getId());
                    }
                }
            }
            return new HashSet<>(activeJobIDs);
        } finally {
            aggregateStatisticsLock.unlock();
        }

    }

    
    private boolean isWellFormedAndActiveJob(IJob job) {
        long earliestActiveTime = JitterClock.globalTime() - config.getActiveTaskMilliCutoff();
        return (job != null) && (job.getStartTime() != null) && (job.getStartTime() > earliestActiveTime);
    }

    
    public void removeInvalidReplicas(IJob job) {
        if ((job != null) && (job.getCopyOfTasks() != null)) {
            List<JobTask> tasks = job.getCopyOfTasks();
            for (JobTask task : tasks) {
                List<JobTaskReplica> newReplicas = new ArrayList<>(job.getReplicas());
                if (task.getReplicas() != null) {
                    Iterable<JobTaskReplica> oldReplicas = new ArrayList<>(task.getReplicas());
                    for (JobTaskReplica replica : oldReplicas) {
                        Collection<String> replicasSeen = new ArrayList<>();
                        String replicaHostID = replica.getHostUUID();
                        if (hostManager.getHostState(replicaHostID) == null) {
                            log.warn("[spawn.balancer] removing replica for missing host {}", replicaHostID);
                        } else if (replicaHostID.equals(task.getHostUUID()) || replicasSeen.contains(replicaHostID)) {
                            log.warn("[spawn.balancer] removing erroneous replica for {} on {}",
                                     task.getJobKey(), replicaHostID);
                        } else if (!config.allowSameHostReplica() && onSameHost(replicaHostID, task.getHostUUID())) {
                            log.warn("[spawn.balancer] removing replica on same host for {}live={} replica={}",
                                     task.getJobKey(), task.getHostUUID(), replicaHostID);
                        } else {
                            replicasSeen.add(replicaHostID);
                            newReplicas.add(replica);
                        }
                    }
                }
                task.setReplicas(newReplicas);
            }
        }
    }

    private boolean onSameHost(String hostID1, String hostID2) {
        HostState host1 = hostManager.getHostState(hostID1);
        HostState host2 = hostManager.getHostState(hostID2);
        if ((host1 == null) || (host2 == null)) {
            return false;
        } else {
            return host1.getHost().equals(host2.getHost());
        }
    }

    
    protected boolean hasFullDiskHost(JobTask task) {
        Collection<HostState> hostsToCheck = new ArrayList<>();
        hostsToCheck.add(hostManager.getHostState(task.getHostUUID()));
        if (task.getReplicas() != null) {
            for (JobTaskReplica replica : task.getReplicas()) {
                if (replica != null) {
                    hostsToCheck.add(hostManager.getHostState(replica.getHostUUID()));
                }
            }
            for (HostState host : hostsToCheck) {
                if ((host != null) && isDiskFull(host)) {
                    return true;
                }
            }
        }
        return false;
    }

    
    public boolean isDiskFull(HostState host) {
        boolean full = (host != null) && (getUsedDiskPercent(host) > (1 - config.getMinDiskPercentAvailToRunJobs()));
        if (full) {
            log.warn("[spawn.balancer] Host {} with uuid {} is nearly full, with used disk {}", host.getHost(),
                     host.getHostUuid(), getUsedDiskPercent(host));
        }
        return full;
    }

    
    protected void updateAggregateStatistics(Iterable<HostState> hosts) {
        spawn.acquireJobLock();
        try {
            aggregateStatisticsLock.lock();
            try {
                lastAggregateStatUpdateTime = JitterClock.globalTime();
                findActiveJobIDs();
                double maxMeanActive = -1;
                double maxDiskPercentUsed = -1;
                for (HostState host : hosts) {
                    maxMeanActive = Math.max(maxMeanActive, host.getMeanActiveTasks());
                    maxDiskPercentUsed = Math.max(maxDiskPercentUsed, getUsedDiskPercent(host));
                }
                for (HostState host : hosts) {
                    cachedHostScores.put(host.getHostUuid(),
                                         calculateHostScore(host, maxMeanActive, maxDiskPercentUsed));
                }
            } finally {
                aggregateStatisticsLock.unlock();
            }
        } finally {
            spawn.releaseJobLock();
        }
    }

    private HostScore calculateHostScore(HostState host, double clusterMaxMeanActive, double clusterMaxDiskUsed) {
        double score = 0;
        double meanActive = host.getMeanActiveTasks();
        double usedDiskPercent = getUsedDiskPercent(host);
        
        if (clusterMaxMeanActive <= 0) {
            meanActive = 1;
            clusterMaxMeanActive = 1;
        }
        if (clusterMaxDiskUsed <= 0) {
            usedDiskPercent = 1;
            clusterMaxDiskUsed = 1;
        }
        int activeTaskWeight = config.getActiveTaskWeight();
        int diskUsedWeight = config.getDiskUsedWeight();
        
        score += activeTaskWeight * Math.pow(meanActive / clusterMaxMeanActive, 2.5);
        score += diskUsedWeight * Math.pow(usedDiskPercent / clusterMaxDiskUsed, 2.5);
        
        score = Math.max(score, (activeTaskWeight + diskUsedWeight) * usedDiskPercent);
        return new HostScore(meanActive, usedDiskPercent, score);
    }

    
    protected boolean isExtremeHost(@Nullable String hostID, boolean diskSpace, boolean high) {
        aggregateStatisticsLock.lock();
        try {
            if ((hostID == null) || (cachedHostScores == null) || !cachedHostScores.containsKey(hostID) ||
                cachedHostScores.isEmpty()) {
                return false;
            }
            double clusterAverage = 0;
            for (HostScore score : cachedHostScores.values()) {
                clusterAverage += score.getScoreValue(diskSpace);
            }
            clusterAverage /= cachedHostScores.size(); 
            double hostValue = cachedHostScores.get(hostID).getScoreValue(diskSpace);
            return (high && (hostValue > (clusterAverage * config.getExtremeHostRatio()))) ||
                   (!high && (hostValue < (clusterAverage / config.getExtremeHostRatio())));
        } finally {
            aggregateStatisticsLock.unlock();
        }

    }

    
    private MoveAssignmentList moveTasksOffHost(JobTaskItemByHostMap tasksByHost,
                                                int maxPerHost,
                                                int numToMove,
                                                long maxBytesToMove,
                                                String pushHost) {
        if (log.isDebugEnabled()) {
            log.debug("received move assignment maxPerHost:{} numToMove:{} pushHost:{}", maxPerHost, numToMove,
                      pushHost);
        }
        MoveAssignmentList rv = new MoveAssignmentList(spawn, taskSizer);
        Collection<JobKey> alreadyMoved = new HashSet<>();
        Iterator<String> otherHosts = tasksByHost.getHostIterator(true);
        while (otherHosts.hasNext() && (rv.size() < numToMove)) {
            String pullHost = otherHosts.next();
            if (pushHost.equals(pullHost)) {
                continue;
            }
            HostState pullHostState = hostManager.getHostState(pullHost);
            Iterator<JobTaskItem> itemIterator = new ArrayList<>(tasksByHost.get(pushHost)).iterator();
            while (itemIterator.hasNext() && (rv.size() < numToMove) &&
                   (tasksByHost.get(pullHost).size() < maxPerHost)) {
                JobTaskItem nextTaskItem = itemIterator.next();
                long trueSizeBytes = taskSizer.estimateTrueSize(nextTaskItem.getTask());
                JobKey jobKey = nextTaskItem.getTask().getJobKey();
                Job job = spawn.getJob(jobKey);
                if ((job == null) || !pullHostState.getMinionTypes().contains(job.getMinionType())) {
                    continue;
                }
                
                
                if (isExtremeHost(pullHost, true, true) || pullHostState.hasLive(jobKey) ||
                    ((maxBytesToMove > 0) && (trueSizeBytes > maxBytesToMove))) {
                    if (log.isDebugEnabled()) {
                        log.debug("Unable to move task to host {} fullDisk={} alreadyLive={} byteCount={}>{} {}",
                                  pullHost, isExtremeHost(pullHost, true, true), pullHostState.hasLive(jobKey),
                                  trueSizeBytes, maxBytesToMove, trueSizeBytes > maxBytesToMove);
                    }
                    continue;
                }
                if (!alreadyMoved.contains(jobKey) && (pullHost != null) &&
                    tasksByHost.moveTask(nextTaskItem, pushHost, pullHost)) {
                    rv.add(new JobTaskMoveAssignment(nextTaskItem.getTask().getJobKey(), pushHost, pullHost, false,
                                                     false));
                    alreadyMoved.add(nextTaskItem.getTask().getJobKey());
                    maxBytesToMove -= trueSizeBytes;
                }
            }
        }
        return rv;
    }

    
    private MoveAssignmentList moveTasksOntoHost(JobTaskItemByHostMap tasksByHost,
                                                 int maxPerHost,
                                                 int numToMove,
                                                 long maxBytesToMove,
                                                 String pullHost) {
        MoveAssignmentList rv = new MoveAssignmentList(spawn, taskSizer);
        Collection<JobKey> alreadyMoved = new HashSet<>();
        Iterator<String> otherHosts = tasksByHost.getHostIterator(false);
        if (isExtremeHost(pullHost, true, true)) {
            return rv;
        }
        if (isExtremeHost(pullHost, false, true)) {
            numToMove = Math.max(1, numToMove / 2); 
        }
        HostState pullHostState = hostManager.getHostState(pullHost);
        if (pullHostState == null) {
            return rv;
        }
        while (otherHosts.hasNext() && (rv.size() < numToMove) && (tasksByHost.get(pullHost).size() < maxPerHost)) {
            String pushHost = otherHosts.next();
            if ((pushHost == null) || pushHost.equals(pullHost)) {
                continue;
            }
            Collection<JobTaskItem> pushHostItems = new ArrayList<>(tasksByHost.get(pushHost));
            if (pushHostItems.size() < maxPerHost) {
                break;
            }
            for (JobTaskItem item : pushHostItems) {
                JobKey jobKey = item.getTask().getJobKey();
                Job job = spawn.getJob(jobKey);
                if ((job == null) || !pullHostState.getMinionTypes().contains(job.getMinionType())) {
                    continue;
                }
                long trueSizeBytes = taskSizer.estimateTrueSize(item.getTask());
                if (pullHostState.hasLive(item.getTask().getJobKey()) ||
                    ((maxBytesToMove > 0) && (trueSizeBytes > maxBytesToMove))) {
                    continue;
                }
                if (!alreadyMoved.contains(jobKey) && tasksByHost.moveTask(item, pushHost, pullHost)) {
                    rv.add(new JobTaskMoveAssignment(item.getTask().getJobKey(), pushHost, pullHost, false, false));
                    alreadyMoved.add(item.getTask().getJobKey());
                    maxBytesToMove -= trueSizeBytes;
                }
                if (rv.size() >= numToMove) {
                    break;
                }
            }
        }
        return rv;
    }

    
    private JobTaskItemByHostMap generateTaskCountByHost(List<HostState> hosts, Iterable<JobTask> tasks) {
        JobTaskItemByHostMap rv = new JobTaskItemByHostMap(this, hosts, config.getTasksMovedPerUnspecifiedHost(),
                                                           config.getTasksMovedPerUnspecifiedHost());
        for (JobTask task : tasks) {
            rv.addLiveAndReplicasForTask(task);
        }
        return rv;
    }

    private List<JobTaskMoveAssignment> pushTasksOntoDisk(HostState host, Iterable<HostState> heavyHosts) {
        MoveAssignmentList moveAssignments = new MoveAssignmentList(spawn, taskSizer);
        for (HostState heavyHost : heavyHosts) {
            double byteLimitFactor =
                    1 - ((double) moveAssignments.getBytesUsed() / config.getBytesMovedFullRebalance());
            moveAssignments.addAll(pushTasksOffHost(heavyHost, Collections.singletonList(host), true, byteLimitFactor,
                                                    config.getTasksMovedFullRebalance(), true));
        }
        moveAssignments.addAll(purgeMisplacedTasks(host, 1));
        return moveAssignments;
    }

    
    private Collection<JobTaskMoveAssignment> balanceActiveJobsOnHost(HostState host, List<HostState> hosts) {
        int totalTasksToMove = config.getTasksMovedFullRebalance();
        long totalBytesToMove = config.getBytesMovedFullRebalance();
        Set<String> activeJobs = findActiveJobIDs();
        List<JobTaskMoveAssignment> rv = purgeMisplacedTasks(host, 1);
        String hostID = host.getHostUuid();
        for (String jobID : activeJobs) {
            spawn.acquireJobLock();
            try {
                Job job = spawn.getJob(jobID);
                if (job != null) {
                    JobTaskItemByHostMap tasksByHost =
                            new JobTaskItemByHostMap(this, hosts, config.getTasksMovedPerUnspecifiedHost(),
                                                     config.getTasksMovedPerUnspecifiedHost());
                    for (JobTask task : job.getCopyOfTasks()) {
                        tasksByHost.addLiveAndReplicasForTask(task);
                    }
                    int maxPerHost = maxTasksPerHost(job, hosts.size());
                    int numExistingTasks = tasksByHost.get(hostID).size();
                    if ((tasksByHost.findLeastTasksOnHost() >= (maxPerHost - 1)) ||
                        (tasksByHost.findMostTasksOnHost() <= maxPerHost)) {
                        continue;
                    }
                    boolean pushFrom = (numExistingTasks > maxPerHost) || ((numExistingTasks == maxPerHost) &&
                                                                           (tasksByHost.findLeastTasksOnHost() <
                                                                            (maxPerHost - 1)));
                    if (totalTasksToMove > 0) {
                        MoveAssignmentList assignments = pushFrom ?
                                                         moveTasksOffHost(tasksByHost, maxPerHost, 1, totalBytesToMove,
                                                                          host.getHostUuid())
                                                                  :
                                                         moveTasksOntoHost(tasksByHost, maxPerHost, 1, totalBytesToMove,
                                                                           host.getHostUuid());
                        rv.addAll(assignments);
                        totalTasksToMove -= assignments.size();
                        totalBytesToMove -= assignments.getBytesUsed();
                    } else {
                        break;
                    }
                }
            } finally {
                spawn.releaseJobLock();
            }
        }
        return rv;
    }

    
    private List<JobTaskMoveAssignment> pruneTaskReassignments(Iterable<JobTaskMoveAssignment> candidateAssignments) {
        List<JobTaskMoveAssignment> rv = new ArrayList<>();
        Map<String, Boolean> snapshot = new HashMap<>(recentlyBalancedHosts.asMap());
        for (JobTaskMoveAssignment assignment : candidateAssignments) {
            String newHostID = assignment.getTargetUUID();
            JobKey jobKey = assignment.getJobKey();
            String jobID = (jobKey == null) ? null : jobKey.getJobUuid();
            if (isExtremeHost(newHostID, true, true)) {
                log.warn("[spawn.balancer] decided not to move task from job {} to host {} " +
                         "because it is already heavily loaded", jobID, newHostID);
                continue;
            }
            HostState newHost = hostManager.getHostState(newHostID);
            if ((newHost == null) || newHost.hasLive(jobKey) ||
                !canReceiveNewTasks(newHost)) {
                log.warn("[spawn.balancer] decided not to move task from job {} to host {} " +
                         "because it cannot receive the new task", jobID, newHostID);
                continue;
            }
            if (snapshot.containsKey(newHostID)) {
                log.warn("[spawn.balancer] decided not to move task from job {} to host {} " +
                         "because it already received a different task recently", jobID, newHostID);
                continue;
            }
            rv.add(assignment);
            recentlyBalancedHosts.put(newHostID, true);
        }
        return rv;
    }

    private static List<JobTaskMoveAssignment> removeDuplicateAssignments(Iterable<JobTaskMoveAssignment>
                                                                                  candidateAssignments) {
        Collection<JobKey> movedTasks = new HashSet<>();
        List<JobTaskMoveAssignment> rv = new ArrayList<>();
        for (JobTaskMoveAssignment assignment : candidateAssignments) {
            JobKey jobKey = assignment.getJobKey();
            if (!movedTasks.contains(jobKey)) {
                rv.add(assignment);
                movedTasks.add(jobKey);
            }
        }
        return rv;
    }

    
    private static int maxTasksPerHost(Job job, int numHosts) {
        if (job == null) {
            return 0;
        }
        numHosts = Math.max(1, numHosts);
        return (int) Math.ceil((double) (job.getTaskCount() * (1 + job.getReplicas())) / numHosts);
    }

    private static int getWeightedElementIndex(int numItems, RebalanceWeight weight) {
        switch (weight) {
            case LIGHT:
                return 0;
            case MEDIUM:
                return numItems / 2;
            case HEAVY:
                return numItems - 1;
            default:
                throw new IllegalArgumentException("unknown weight type " + weight);
        }
    }

}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import java.util.LinkedHashMap;
import java.util.Map;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

import com.addthis.basis.net.HttpUtil;
import com.addthis.basis.util.Parameter;

import com.addthis.hydra.job.Job;
import com.addthis.hydra.job.JobTask;
import com.addthis.hydra.job.mq.HostState;
import com.addthis.hydra.job.spawn.HostManager;
import com.addthis.hydra.job.spawn.Spawn;

import com.google.common.cache.Cache;
import com.google.common.cache.CacheBuilder;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


public class SpawnBalancerTaskSizer {
    private static final Logger log = LoggerFactory.getLogger(SpawnBalancerTaskSizer.class);

    private static final double defaultRatio = Double.parseDouble(Parameter.value("spawn.balancer.task.sizer.defaultratio", "1.5"));
    private static final double maxRatio = Double.parseDouble(Parameter.value("spawn.balancer.task.sizer.maxratio", "10.0"));
    private static final double minRatio = Double.parseDouble(
            Parameter.value("spawn.balancer.task.sizer.minratio", "1.0"));
    private static final long queueConsumptionInterval = Parameter.longValue("spawn.balancer.task.sizer.interval",
                                                                             60 * 1000);
    private static final int ratioExpirationHours = Parameter.intValue("spawn.balancer.task.sizer.ratio.expire", 12);

    private static final AtomicBoolean pollingStarted = new AtomicBoolean(false);

    private final Spawn spawn;
    private final HostManager hostManager;
    private final LinkedHashMap<String, Integer> queuedJobIds;
    private final Cache<String, Double> cachedJobRatios;

    public SpawnBalancerTaskSizer(Spawn spawn, HostManager hostManager) {
        queuedJobIds = new LinkedHashMap<>();
        cachedJobRatios = CacheBuilder.newBuilder().expireAfterWrite(ratioExpirationHours, TimeUnit.HOURS).build();
        this.spawn = spawn;
        this.hostManager = hostManager;
    }

    public void startPolling(ScheduledExecutorService executor) {
        if (pollingStarted.compareAndSet(false, true)) {
            executor.scheduleWithFixedDelay(new QueueConsumer(), queueConsumptionInterval, queueConsumptionInterval, TimeUnit.MILLISECONDS);
        }
    }

    
    public long estimateTrueSize(JobTask task) {
        if (task == null) {
            return 0L;
        }
        long taskReportedSize = getReportedSize(task);
        Double cachedRatio = cachedJobRatios.getIfPresent(task.getJobUUID());
        if (cachedRatio == null) {
            requestJobSizeFetch(task.getJobUUID(), task.getTaskID());
            return (long) (defaultRatio * taskReportedSize);
        }
        return (long) (cachedRatio * taskReportedSize);
    }

    private long getReportedSize(JobTask task) {
        
        long byteCount = task != null ? task.getByteCount() : 0;
        if (task == null || byteCount > 0) {
            return byteCount;
        }
        Job job = spawn.getJob(task.getJobUUID());
        if (job != null) {
            return job.calcAverageTaskSizeBytes();
        }
        return byteCount;
    }

    public void requestJobSizeFetch(String jobId, int taskId) {
        synchronized (queuedJobIds) {
            if (cachedJobRatios.getIfPresent(jobId) != null || queuedJobIds.containsKey(jobId)) {
                return;
            }
            queuedJobIds.put(jobId, taskId);
        }
    }

    
    private long fetchTaskTrueSize(String jobId, int taskId) {
        JobTask task = spawn.getTask(jobId, taskId);
        if (task == null) {
            return -1;
        }
        HostState liveHost = hostManager.getHostState(task.getHostUUID());
        if (liveHost == null) {
            return -1;
        }
        String url = "http:
        try {
            byte[] result = HttpUtil.httpGet(url, 0).getBody();
            return Long.parseLong(new String(result));
        } catch (Exception e) {
            log.warn("Failed to fetch task size for " + task.getJobKey());
        }
        return -1;
    }

    
    private void consumeFromQueue() {
        String jobId;
        int taskId;
        synchronized (queuedJobIds) {
            if (queuedJobIds.isEmpty()) {
                return;
            }
            Map.Entry<String, Integer> entry = queuedJobIds.entrySet().iterator().next();
            queuedJobIds.remove(entry.getKey());
            jobId = entry.getKey();
            taskId = entry.getValue();
        }
        long trueSize = fetchTaskTrueSize(jobId, taskId);
        long reportedSize = getReportedSize(spawn.getTask(jobId, taskId));
        double ratio = getRatio(trueSize, reportedSize);
        log.info("[spawn.balancer.task.sizer] updated ratio for job " + jobId + " reported=" + reportedSize + " true=" + trueSize + " ratio=" + ratio);
        cachedJobRatios.put(jobId, ratio);
    }

    
    private static double getRatio(long trueSize, long reportedSize) {
        if (trueSize <= 0 || reportedSize <= 0) {
            return defaultRatio;
        }
        double rawRatio = (double) trueSize / reportedSize;
        return Math.max(minRatio, Math.min(rawRatio, maxRatio));
    }

    
    private class QueueConsumer implements Runnable {

        @Override
        public void run() {
            try {
                consumeFromQueue();
            } catch (Exception e) {
                log.warn("Failed to consume from TaskSizer queue: " + e, e);
                }
        }
    }
}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


class AutobalanceTask implements Runnable {
    private static final Logger log = LoggerFactory.getLogger(AutobalanceTask.class);

    private final SpawnBalancer spawnBalancer;

    private long lastJobAutobalanceTime = 0L;
    private long lastHostAutobalanceTime = 0L;
    private int numHostRebalances = 0;

    public AutobalanceTask(SpawnBalancer spawnBalancer) {
        this.spawnBalancer = spawnBalancer;
    }

    @Override
    public void run() {
        long now = System.currentTimeMillis();
        
        if (spawnBalancer.okayToAutobalance()) {
            if ((now - lastHostAutobalanceTime) > spawnBalancer.config.getHostAutobalanceIntervalMillis()) {
                numHostRebalances++;
                log.warn("Performing host autobalance.");
                RebalanceWeight weight =
                        ((numHostRebalances % 2) == 0) ? RebalanceWeight.HEAVY : RebalanceWeight.LIGHT;
                spawnBalancer.spawn.executeReallocationAssignments(
                        spawnBalancer.getAssignmentsForAutoBalance(RebalanceType.HOST, weight),
                        false);
                lastHostAutobalanceTime = now;
            } else if ((now - lastJobAutobalanceTime) > spawnBalancer.config.getJobAutobalanceIntervalMillis()) {
                log.warn("Performing job autobalance.");
                spawnBalancer.spawn.executeReallocationAssignments(
                        spawnBalancer.getAssignmentsForAutoBalance(RebalanceType.JOB, RebalanceWeight.HEAVY), false);
                lastJobAutobalanceTime = now;
            }
        }
    }
}

<code block>

package com.addthis.hydra.job.spawn.balancer;

public enum RebalanceType {HOST, JOB}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import com.addthis.hydra.job.JobTask;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


class JobTaskItem {

    private final JobTask task;

    public JobTaskItem(JobTask task) {
        this.task = task;
    }

    public JobTask getTask() {
        return task;
    }

    @Override
    public boolean equals(Object o) {
        if (o.getClass() != getClass()) {
            return false;
        }
        JobTaskItem item2 = (JobTaskItem) o;
        return task.getJobKey().matches(item2.getTask().getJobKey());
    }

    @Override
    public String toString() {
        return "JobTaskItem{task=" + task.getJobKey() + "'";
    }
}

<code block>

package com.addthis.hydra.job.spawn.balancer;

import java.io.File;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashSet;
import java.util.List;
import java.util.Map;

import com.addthis.basis.test.SlowTest;
import com.addthis.basis.util.JitterClock;
import com.addthis.basis.util.LessFiles;

import com.addthis.codec.config.Configs;
import com.addthis.hydra.job.Job;
import com.addthis.hydra.job.JobParameter;
import com.addthis.hydra.job.JobTask;
import com.addthis.hydra.job.JobTaskMoveAssignment;
import com.addthis.hydra.job.JobTaskReplica;
import com.addthis.hydra.job.JobTaskState;
import com.addthis.hydra.job.entity.JobCommand;
import com.addthis.hydra.job.mq.HostCapacity;
import com.addthis.hydra.job.mq.HostState;
import com.addthis.hydra.job.mq.JobKey;
import com.addthis.hydra.job.spawn.HostManager;
import com.addthis.hydra.job.spawn.Spawn;
import com.addthis.hydra.job.spawn.SpawnMQ;
import com.addthis.hydra.minion.Minion;
import com.addthis.hydra.util.ZkCodecStartUtil;

import org.apache.zookeeper.CreateMode;

import org.junit.After;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.mockito.Mockito;

import static org.junit.Assert.*;

@Category(SlowTest.class)
public class SpawnBalancerTest extends ZkCodecStartUtil {

    private Spawn spawn;
    private HostManager hostManager;
    private SpawnBalancer bal;
    private long now = JitterClock.globalTime();
    private String tmpRoot;

    @Before
    public void setup() throws Exception {

        tmpRoot = LessFiles.createTempDir().toString();
        System.setProperty("SPAWN_DATA_DIR", tmpRoot + "/tmp/spawn/data");
        System.setProperty("SPAWN_LOG_DIR", tmpRoot + "/tmp/spawn/log/events");
        if (zkClient.checkExists().forPath("/minion/up") == null) {
            zkClient.create().creatingParentsIfNeeded().forPath("/minon/up");
        }
        if (zkClient.checkExists().forPath("/minion/dead") == null) {
            zkClient.create().creatingParentsIfNeeded().forPath("/minon/dead");
        }
        try {
            Thread.sleep(100);
            spawn = Configs.newDefault(Spawn.class);
            hostManager = spawn.hostManager;
            bal = spawn.getSpawnBalancer();
            spawn.setSpawnMQ(Mockito.mock(SpawnMQ.class));
        } catch (Exception ex) {
        }
    }

    @After
    public void clear() throws Exception {
        if (zkClient.checkExists().forPath("/minion/up") != null) {
            zkClient.delete().forPath("/minon/up");
        }
        if (zkClient.checkExists().forPath("/minion/dead") != null) {
            zkClient.delete().forPath("/minon/dead");
        }
        LessFiles.deleteDir(new File(tmpRoot));
        spawn.close();
    }
    
    @Test
    public void saveLoadConfig() {
        SpawnBalancerConfig config = new SpawnBalancerConfig();
        config.setBytesMovedFullRebalance(123456);
        bal.saveConfigToDataStore();
        SpawnBalancerConfig loadedConfig = bal.loadConfigFromDataStore(null);
        assertNotNull("not null", loadedConfig);
        assertEquals("correct value saved/loaded", 123456, loadedConfig.getBytesMovedFullRebalance());
    }

    @Test
    public void replicaSuitabilityTest() throws Exception {
        List<HostState> hosts = new ArrayList<>();
        int numHosts = 8;
        for (int i = 0; i < numHosts; i++) {
            HostState nextHost = new HostState("id" + i);
            nextHost.setUsed(new HostCapacity(0, 0, 0, i));
            nextHost.setMax(new HostCapacity(0, 0, 0, 2 * numHosts));
            nextHost.setUp(true);
            hosts.add(nextHost);
        }
        bal.markRecentlyReplicatedTo("id4");
        hosts = bal.sortHostsByDiskSpace(hosts);
        assertEquals("should get lightest host first", "id0", hosts.get(0).getHostUuid());
        assertEquals("should get heaviest host second to last", "id" + (numHosts - 1), hosts.get(numHosts - 2).getHostUuid());
        assertEquals("should get recently-replicated-to host last", "id4", hosts.get(numHosts - 1).getHostUuid());
    }

    @Test
    public void replicaAllocationTest() throws Exception {
        
        
        String fullHostID = "full";
        HostState fullHost = installHostStateWithUUID(fullHostID, spawn, true);
        fullHost.setUsed(new HostCapacity(0, 0, 0, 9998));
        fullHost.setMax(new HostCapacity(0, 0, 0, 10_000));
        int numLightHosts = 9;
        ArrayList<String> hostIDs = new ArrayList<>(numLightHosts + 1);
        hostIDs.add(fullHostID);
        for (int i = 0; i < numLightHosts; i++) {
            String hostID = "light" + i;
            hostIDs.add(hostID);
            HostState lightHost = installHostStateWithUUID(hostID, spawn, true);
            lightHost.setUsed(new HostCapacity(0, 0, 0, 30));
            lightHost.setMax(new HostCapacity(0, 0, 0, 10_000));
        }
        Job job = createJobAndUpdateHosts(spawn, numLightHosts + 1, hostIDs, now, 1000, 0);
        job.setReplicas(1);
        Map<Integer, List<String>> assignments = bal.getAssignmentsForNewReplicas(job);
        HashSet<String> usedHosts = new HashSet<>(numLightHosts);
        for (List<String> targets : assignments.values()) {
            assertEquals("should make one replica per task", 1, targets.size());
            assertTrue("should not put replicas on full host", !targets.contains(fullHostID));
            usedHosts.addAll(targets);
        }
        assertTrue("should use many light hosts", numLightHosts > .75 * usedHosts.size());
    }

    @Test
    public void sortHostsTest() throws Exception {
        
        
        
        
        
        
        
        

        String readOnlyHostID = "read_only_host";
        HostState readOnlyHost = installHostStateWithUUID(readOnlyHostID, spawn, true, false, 0, "default");

        String downHostID = "down_host";
        HostState downHost = installHostStateWithUUID(downHostID, spawn, false);

        String deadHostID = "dead_host";
        HostState deadHost = installHostStateWithUUID(deadHostID, spawn, false);
        deadHost.setDead(true);

        String emptyHostID = "empty_host";
        HostState emptyHost = installHostStateWithUUID(emptyHostID, spawn, true);

        String oneOldOneNewHostID = "1old1new";
        HostState oldNewHost = installHostStateWithUUID(oneOldOneNewHostID, spawn, true);

        Job oldJob = createSpawnJob(spawn, 1, Arrays.asList(oneOldOneNewHostID), 0l, 1, 0);
        Job newJob1 = createSpawnJob(spawn, 1, Arrays.asList(oneOldOneNewHostID), now, 1, 0);
        oldNewHost.setStopped(simulateJobKeys(oldJob, newJob1));

        String twoNewHostID = "2new";
        HostState twoNewHost = installHostStateWithUUID(twoNewHostID, spawn, true);
        Job newJob2 = createSpawnJob(spawn, 1, Arrays.asList(twoNewHostID), now, 1, 0);
        Job newJob3 = createSpawnJob(spawn, 1, Arrays.asList(twoNewHostID), now, 1, 0);
        twoNewHost.setStopped(simulateJobKeys(newJob2, newJob3));

        List<HostState> hosts = Arrays.asList(downHost, deadHost, oldNewHost, twoNewHost, emptyHost);
        HostState[] desiredOrder = new HostState[]{emptyHost, oldNewHost, twoNewHost};
        List<HostState> sortedHosts = bal.sortHostsByActiveTasks(hosts);
        assertEquals("shouldn't include read only", false, sortedHosts.contains(readOnlyHost));
        assertEquals("shouldn't include down host", false, sortedHosts.contains(downHost));
        assertEquals("shouldn't include dead host", false, sortedHosts.contains(deadHost));
        assertEquals("three hosts should make it through the sort", 3, sortedHosts.size());
        assertArrayEquals("hosts should be in order [empty, old, new]", desiredOrder, sortedHosts.toArray());
    }

    @Test
    public void allocateTasksAcrossHostsTest() throws Exception {
        
        String firstHostUUID = "first";
        String secondHostUUID = "second";
        String thirdHostUUID = "third";
        installHostStateWithUUID(firstHostUUID, spawn, true);
        installHostStateWithUUID(secondHostUUID, spawn, true);
        installHostStateWithUUID(thirdHostUUID, spawn, true);
        spawn.getJobCommandManager().putEntity("foo", new JobCommand(), false);
        int numTasks = 15;
        Job job = createJobAndUpdateHosts(spawn, numTasks, Arrays.asList(firstHostUUID, secondHostUUID, thirdHostUUID), now, 1, 0);
        assertEquals("should divide tasks evenly", numTasks / 3, numTasksOnHost(job, firstHostUUID));
        assertEquals("should divide tasks evenly", numTasks / 3, numTasksOnHost(job, secondHostUUID));
        assertEquals("should divide tasks evenly", numTasks / 3, numTasksOnHost(job, thirdHostUUID));
    }

    @Test
    public void multiHostJobReallocationTaskSelectionTest() throws Exception {
        
        
        String heavyHostUUID = "heavy";
        String lightHost1UUID = "light1";
        String lightHost2UUID = "light2";
        HostState heavyHost = installHostStateWithUUID(heavyHostUUID, spawn, true);
        HostState lightHost1 = installHostStateWithUUID(lightHost1UUID, spawn, true);
        HostState lightHost2 = installHostStateWithUUID(lightHost2UUID, spawn, true);
        List<HostState> hosts = Arrays.asList(heavyHost, lightHost1, lightHost2);
        Job smallJob = createJobAndUpdateHosts(spawn, 6, Arrays.asList(heavyHostUUID), now, 1000, 0);
        List<JobTaskMoveAssignment> assignments = bal.getAssignmentsForJobReallocation(smallJob, -1, hosts);
        assertEquals("should move 4 tasks total for small job", 4, assignments.size());
        List<String> assignedHosts = new ArrayList<>();
        for (JobTaskMoveAssignment assignment : assignments) {
            assignedHosts.add(assignment.getTargetUUID());
        }
        Collections.sort(assignedHosts);
        assertArrayEquals("should move two tasks to each host",
                new String[]{lightHost1UUID, lightHost1UUID, lightHost2UUID, lightHost2UUID}, assignedHosts.toArray());
        Job job2 = createJobAndUpdateHosts(spawn, 6, Arrays.asList(heavyHostUUID, lightHost1UUID, lightHost2UUID), now, 1000, 0);
        String brandNewHostUUID = "brandnew";
        HostState brandNewHost = installHostStateWithUUID(brandNewHostUUID, spawn, true);
        List<HostState> newHosts = Arrays.asList(heavyHost, lightHost1, lightHost2, brandNewHost);
        bal.updateAggregateStatistics(newHosts);
        List<JobTaskMoveAssignment> assignments2 = bal.getAssignmentsForJobReallocation(job2, -1, newHosts);
        assertEquals("should move one task", 1, assignments2.size());
        assertEquals("should move a task to the new host", brandNewHostUUID, assignments2.get(0).getTargetUUID());
    }

    @Test
    public void assignMoreTasksToLighterHostsTest() throws Exception {
        
        
        String heavyHostUUID = "heavy";
        String lightHost1UUID = "light1";
        String lightHost2UUID = "light2";
        HostState heavyHost = installHostStateWithUUID(heavyHostUUID, spawn, true);
        HostState lightHost1 = installHostStateWithUUID(lightHost1UUID, spawn, true);
        HostState lightHost2 = installHostStateWithUUID(lightHost2UUID, spawn, true);
        Job weightJob = createJobAndUpdateHosts(spawn, 10, Arrays.asList(heavyHostUUID), now, 1000, 0);
        bal.updateAggregateStatistics(hostManager.listHostStatus(null));
        Job otherJob = createJobAndUpdateHosts(spawn, 5, Arrays.asList(heavyHostUUID, lightHost1UUID, lightHost2UUID), now, 500, 0);
        assertEquals("should put two tasks on lightHost1", 2, numTasksOnHost(otherJob, lightHost1UUID));
        assertEquals("should put two tasks on lightHost2", 2, numTasksOnHost(otherJob, lightHost2UUID));
        assertEquals("should put one task on heavyHost", 1, numTasksOnHost(otherJob, heavyHostUUID));
    }

    @Test
    public void multiJobHostReallocationTaskSelectionTest() throws Exception {
        
        
        String heavyHostUUID = "heavy";
        String lightHostUUID = "light";
        HostState heavyHost = installHostStateWithUUID(heavyHostUUID, spawn, true);
        HostState lightHost = installHostStateWithUUID(lightHostUUID, spawn, true);
        spawn.getJobCommandManager().putEntity("foo", new JobCommand(), false);
        int numTasks = 3;
        Job job1 = createJobAndUpdateHosts(spawn, numTasks, Arrays.asList(heavyHostUUID), now, 1, 0);
        Job job2 = createJobAndUpdateHosts(spawn, numTasks, Arrays.asList(heavyHostUUID), now, 1, 0);
        bal.updateAggregateStatistics(hostManager.listHostStatus(null));
        List<HostState> hosts = Arrays.asList(heavyHost, lightHost);
        List<JobTaskMoveAssignment> heavyHostTaskAssignments = bal.getAssignmentsToBalanceHost(heavyHost, hosts);
        assertEquals("should move 2 tasks", 2, heavyHostTaskAssignments.size());
        for (JobTaskMoveAssignment assignment : heavyHostTaskAssignments) {
            assertEquals("should move task from heavy host", heavyHostUUID, assignment.getSourceUUID());
            assertEquals("should move task to light host", lightHostUUID, assignment.getTargetUUID());
        }
        bal.clearRecentlyRebalancedHosts();
        List<JobTaskMoveAssignment> lightHostTaskAssignments = bal.getAssignmentsToBalanceHost(lightHost, hosts);
        assertEquals("should move 2 tasks", 2, lightHostTaskAssignments.size());
        for (JobTaskMoveAssignment assignment : lightHostTaskAssignments) {
            assertEquals("should move task from heavy host", heavyHostUUID, assignment.getSourceUUID());
            assertEquals("should move task to light host", lightHostUUID, assignment.getTargetUUID());
        }
    }

    @Test
    public void diskSpaceBalancingTest() throws Exception {
        
        
        String heavyHostUUID = "heavy";
        String lightHostUUID = "light";
        String lightHost2UUID = "light2";
        String readOnlyHostUUID = "readOnlyHost";
        HostState heavyHost = installHostStateWithUUID(heavyHostUUID, spawn, true);
        HostState lightHost = installHostStateWithUUID(lightHostUUID, spawn, true);
        HostState lightHost2 = installHostStateWithUUID(lightHost2UUID, spawn, true);
        HostState readOnlyHost = installHostStateWithUUID(readOnlyHostUUID, spawn, true, true, 0, "default");
        List<HostState> hosts = Arrays.asList(heavyHost, lightHost, lightHost2, readOnlyHost);
        spawn.getJobCommandManager().putEntity("foo", new JobCommand(), false);
        Job gargantuanJob = createSpawnJob(spawn, 1, Arrays.asList(heavyHostUUID), now, 8_000_000_000l, 0);
        Job movableJob1 = createSpawnJob(spawn, 1, Arrays.asList(heavyHostUUID), now, 850_000_000l, 0);
        Job movableJob2 = createSpawnJob(spawn, 1, Arrays.asList(heavyHostUUID), now, 820_000_000l, 0);
        heavyHost.setStopped(simulateJobKeys(gargantuanJob, movableJob1, movableJob2));
        heavyHost.setMax(new HostCapacity(10, 10, 10, 10_000_000_000l));
        heavyHost.setUsed(new HostCapacity(10, 10, 10, 9_900_000_000l));
        lightHost.setMax(new HostCapacity(10, 10, 10, 10_000_000_000l));
        lightHost.setUsed(new HostCapacity(10, 10, 10, 20_000_0000l));
        lightHost2.setMax(new HostCapacity(10, 10, 10, 10_000_000_000l));
        lightHost2.setUsed(new HostCapacity(10, 10, 10, 20_000_000l));
        readOnlyHost.setMax(new HostCapacity(10, 10, 10, 10_000_000_000l));
        readOnlyHost.setUsed(new HostCapacity(10, 10, 10, 20_000_000l));
        hostManager.updateHostState(heavyHost);
        hostManager.updateHostState(lightHost);
        hostManager.updateHostState(lightHost2);
        hostManager.updateHostState(readOnlyHost);
        bal.updateAggregateStatistics(hostManager.listHostStatus(null));
        List<JobTaskMoveAssignment> assignments = bal.getAssignmentsToBalanceHost(heavyHost, hosts);
        long bytesMoved = 0;
        for (JobTaskMoveAssignment assignment : assignments) {
            assertTrue("shouldn't move gargantuan task", !assignment.getJobKey().getJobUuid().equals(gargantuanJob.getId()));
            assertTrue("shouldn't move to read-only host", !(assignment.getTargetUUID().equals(readOnlyHostUUID)));
        }
        assertTrue("should move something", !assignments.isEmpty());
    }

    @Test
    public void dontDoPointlessMovesTest() throws Exception {
        
        int numHosts = 3;
        List<HostState> hosts = new ArrayList<>(numHosts);
        List<String> hostNames = new ArrayList<>(numHosts);
        for (int i = 0; i < numHosts; i++) {
            String hostName = "host" + i;
            hostNames.add(hostName);
            hosts.add(installHostStateWithUUID(hostName, spawn, true));
        }
        Job job1 = createJobAndUpdateHosts(spawn, numHosts, hostNames, now, 1000, 0);
        Job job2 = createJobAndUpdateHosts(spawn, numHosts - 1, hostNames, now, 1000, 0);
        for (HostState host : hosts) {
            assertEquals("shouldn't move anything for " + host.getHostUuid(), 0,
                    bal.getAssignmentsToBalanceHost(host, hosts).size());
        }
        assertEquals("shouldn't move anything for " + job1.getId(), 0,
                bal.getAssignmentsForJobReallocation(job1, -1, hosts).size());
        assertEquals("shouldn't move anything for " + job2.getId(), 0,
                bal.getAssignmentsForJobReallocation(job2, -1, hosts).size());

    }

    @Test
    public void kickOnSuitableHosts() throws Exception {
        String availHostID = "host2";
        HostState avail = installHostStateWithUUID(availHostID, spawn, true, false, 1, "default");
        assertTrue("available host should be able to run task", avail.canMirrorTasks());
    }

    @Ignore("Alwawys fail")
    @Test
    public void queuePersist() throws Exception {
        spawn.getJobCommandManager().putEntity("foo", new JobCommand(), false);
        spawn.getSystemManager().quiesceCluster(true, "unknown");
        installHostStateWithUUID("host", spawn, true);
        Job job = createJobAndUpdateHosts(spawn, 4, Arrays.asList("host"), now, 1000, 0);
        JobKey myKey = new JobKey(job.getId(), 0);
        spawn.addToTaskQueue(myKey, 0, false);
        spawn.writeSpawnQueue();
        
        try (Spawn spawn2 = Configs.newDefault(Spawn.class)) {
            spawn2.getSystemManager().quiesceCluster(true, "unknown");
            spawn2.loadSpawnQueue();
            assertEquals("should have one queued task", 1, spawn.getTaskQueuedCount());
        }
    }

    @Test
    public void multipleMinionsPerHostReplicaTest() throws Exception {
        bal.getConfig().setAllowSameHostReplica(true);
        HostState host1m1 = installHostStateWithUUID("m1", spawn, true);
        host1m1.setHost("h1");
        hostManager.updateHostState(host1m1);
        HostState host1m2 = installHostStateWithUUID("m2", spawn, true);
        host1m2.setHost("h1");
        hostManager.updateHostState(host1m2);
        Job job = createJobAndUpdateHosts(spawn, 1, Arrays.asList("m1", "m2"), now, 1000, 0);
        job.setReplicas(1);
        spawn.updateJob(job);
        assertEquals("should get one replica when we allow same host replicas", 1, spawn.getTask(job.getId(), 0).getAllReplicas().size(), 1);
        bal.getConfig().setAllowSameHostReplica(false);
        spawn.updateJob(job);
        assertEquals("should get no replicas when we disallow same host replicas", 0, spawn.getTask(job.getId(), 0).getAllReplicas().size());
    }

    @Test
    public void rebalanceOntoNewHostsTest() throws Exception {
        
        
        spawn.setSpawnMQ(Mockito.mock(SpawnMQ.class));
        bal.getConfig().setAllowSameHostReplica(true);
        ArrayList<String> hosts = new ArrayList<>();
        for (int i = 0; i < 8; i++) {
            installHostStateWithUUID("h" + i, spawn, true);
            hosts.add("h" + i);
        }
        Job myJob = createJobAndUpdateHosts(spawn, 20, hosts, JitterClock.globalTime(), 2000l, 0);
        installHostStateWithUUID("hNEW1", spawn, true);
        installHostStateWithUUID("hNEW2", spawn, true);
        int tries = 50;
        while (spawn.listAvailableHostIds().size() < 10 && tries-- > 0) {
            
            Thread.sleep(100);
        }
        List<HostState> hostStates = hostManager.listHostStatus(null);
        bal.updateAggregateStatistics(hostStates);
        List<JobTaskMoveAssignment> assignments = bal.getAssignmentsForJobReallocation(myJob, -1, hostStates);
        int h1count = 0;
        int h2count = 0;
        for (JobTaskMoveAssignment assignment : assignments) {
            if (assignment.getTargetUUID().equals("hNEW1")) {
                h1count++;
            } else if (assignment.getTargetUUID().equals("hNEW2")) {
                h2count++;
            } else {
                throw new RuntimeException("should not push anything onto host " + assignment.getTargetUUID());
            }
        }
        assertTrue("should move tasks onto first new host", h1count > 1);
        assertTrue("should move tasks onto second new host", h2count > 1);

    }

    @Test
    public void hostScoreTest() throws Exception {
        
        
        long[] used = new long[]{1000, 9900, 10000, 10500, 20000};
        int i = 0;
        for (long usedVal : used) {
            HostState hostState = installHostStateWithUUID("host" + (i++), spawn, true);
            hostState.setUsed(new HostCapacity(0, 0, 0, usedVal));
            hostState.setMax(new HostCapacity(0, 0, 0, 25000));
        }
        bal.updateAggregateStatistics(hostManager.listHostStatus(null));
        assertTrue("should correctly identify light host", bal.isExtremeHost("host0", true, false));
        assertTrue("should not identify light host as heavy", !bal.isExtremeHost("host0", true, true));
        assertTrue("should not identify medium host as light", !bal.isExtremeHost("host1", true, false));
        assertTrue("should not identify medium host as heavy", !bal.isExtremeHost("host1", true, true));
        assertTrue("should correctly identify heavy host", bal.isExtremeHost("host4", true, true));
        assertTrue("should not identify heavy host as light", !bal.isExtremeHost("host4", true, false));
    }

    @Test
    public void jobStateChangeTest() throws Exception
    {
        
        List<String> hosts = Arrays.asList("h1", "h2", "h3");
        for (String host : hosts)
        {
            installHostStateWithUUID(host, spawn, true);
        }
        spawn.getJobCommandManager().putEntity("a", new JobCommand(), true);
        Job job = spawn.createJob("fsm", 3, hosts, "default", "a", false);
        JobTask task0 = job.getTask(0);
        JobTask task1 = job.getTask(1);
        job.setTaskState(task0, JobTaskState.BUSY);
        
        assertTrue("job should not be finished", !job.isFinished());
        job.setTaskState(task0, JobTaskState.IDLE);
        assertTrue("job should be finished", job.isFinished());
        job.setTaskState(task1, JobTaskState.MIGRATING, true);
        
        assertTrue("job should not be finished", !job.isFinished());
        job.setTaskState(task1, JobTaskState.IDLE, true);
        job.setTaskState(task0, JobTaskState.REBALANCE);
        
        
        assertTrue("job should be finished", job.isFinished());
    }

    @Test
    public void jobDependencyTest() throws Exception {
        installHostStateWithUUID("a", spawn, true);
        installHostStateWithUUID("b", spawn, true);
        Job sourceJob = createSpawnJob(spawn, 1, Arrays.asList("a", "b"), 1l, 1l, 0);
        Job downstreamJob = createSpawnJob(spawn, 1, Arrays.asList("a", "b"), 1l, 1l, 0);
        downstreamJob.setParameters(Arrays.asList(new JobParameter("param", sourceJob.getId(), "DEFAULT")));
        spawn.updateJob(downstreamJob);
        assertEquals("dependency graph should have two nodes", 2, spawn.getJobDependencies().getNodes().size());
    }

    private Job createSpawnJob(Spawn spawn, int numTasks, List<String> hosts, long startTime, long taskSizeBytes, int numReplicas) throws Exception {

        Job job = spawn.createJob("fsm", numTasks, hosts, Minion.defaultMinionType, "foo", false);
        job.setReplicas(numReplicas);
        for (JobTask task : job.getCopyOfTasks()) {
            task.setByteCount(taskSizeBytes);
        }
        job.setStartTime(startTime);
        return job;
    }

    private Job createJobAndUpdateHosts(Spawn spawn, int numTasks, List<String> hosts, long startTime, long taskSizeBytes, int numReplicas) throws Exception {
        Job job = createSpawnJob(spawn, numTasks, hosts, startTime, taskSizeBytes, numReplicas);
        spawn.updateJob(job);
        for (JobTask task : job.getCopyOfTasks()) {
            task.setFileCount(1L);
            HostState host = hostManager.getHostState(task.getHostUUID());
            host.setStopped(updateJobKeyArray(host.getStopped(), task.getJobKey()));
            host.setMeanActiveTasks(1);
            hostManager.updateHostState(host);
            if (task.getReplicas() != null) {
                for (JobTaskReplica replica : task.getReplicas()) {
                    HostState rHost = hostManager.getHostState(replica.getHostUUID());
                    rHost.setStopped(updateJobKeyArray(rHost.getStopped(), task.getJobKey()));
                    hostManager.updateHostState(host);
                }
            }
        }
        return job;
    }

    private JobKey[] updateJobKeyArray(JobKey[] keys, JobKey newKey) {
        List<JobKey> keyList = keys == null ? new ArrayList<>() : new ArrayList<>(Arrays.asList(keys));
        keyList.add(newKey);
        return keyList.toArray(new JobKey[]{});
    }

    private int numTasksOnHost(Job job, String hostID) {
        int count = 0;
        for (JobTask task : job.getCopyOfTasks()) {
            if (task.getHostUUID().equals(hostID)) count++;
        }
        return count;
    }

    private JobKey[] simulateJobKeys(Job... jobs) {
        ArrayList<JobKey> keyList = new ArrayList<>();
        JobKey[] sampleArray = {new JobKey("", 0)};
        for (Job job : jobs) {
            for (int i = 0; i < job.getCopyOfTasks().size(); i++) {
                keyList.add(new JobKey(job.getId(), i));
            }
        }
        return keyList.toArray(sampleArray);
    }

    private HostState installHostStateWithUUID(String hostUUID, Spawn spawn, boolean isUp) throws Exception {
        return installHostStateWithUUID(hostUUID, spawn, isUp, false, 1, "default");
    }

    private HostState installHostStateWithUUID(String hostUUID, Spawn spawn, boolean isUp, boolean readOnly, int availableSlots, String minionType) throws Exception {
        String zkPath = isUp ? "/minion/up/" + hostUUID : "/minion/dead/" + hostUUID;
        zkClient.create().withMode(CreateMode.EPHEMERAL).forPath(zkPath);
        HostState newHostState = new HostState(hostUUID);
        newHostState.setMax(new HostCapacity(10, 10, 10, 1000));
        newHostState.setUsed(new HostCapacity(0, 0, 0, 100));
        newHostState.setHost("hostname-for:" + hostUUID);
        newHostState.setUp(isUp);
        newHostState.setAvailableTaskSlots(availableSlots);
        newHostState.setMinionTypes(minionType);
        hostManager.updateHostState(newHostState);
        return newHostState;
    }
}

<code block>

package com.addthis.hydra.job;

import com.addthis.hydra.job.mq.JobKey;


public class JobTaskMoveAssignment {

    private final JobKey jobKey;
    private final String sourceUUID;
    private final String targetUUID;
    private final boolean delete;
    private final boolean fromReplica;

    public JobTaskMoveAssignment(JobKey jobKey, String sourceUUID, String targetUUID, boolean fromReplica, boolean delete) {
        this.jobKey = jobKey;
        this.sourceUUID = sourceUUID;
        this.targetUUID = targetUUID;
        this.fromReplica = fromReplica;
        this.delete = delete;
    }

    public JobKey getJobKey() {
        return jobKey;
    }

    public String getSourceUUID() {
        return sourceUUID;
    }

    public String getTargetUUID() {
        return targetUUID;
    }

    public boolean isFromReplica() {
        return fromReplica;
    }

    public boolean delete() {
        return delete;
    }

    @Override
    public String toString() {
        return "JobTaskMoveAssignment{" +
               "jobKey=" + jobKey +
               ", sourceUUID='" + sourceUUID + '\'' +
               ", targetUUID='" + targetUUID + '\'' +
               ", fromReplica=" + fromReplica +
               '}';
    }
}

<code block>


package com.addthis.hydra.job.web.resources;

import javax.annotation.Nonnull;
import javax.ws.rs.DefaultValue;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.QueryParam;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;

import com.addthis.codec.jackson.Jackson;
import com.addthis.codec.json.CodecJSON;
import com.addthis.hydra.job.HostFailWorker;
import com.addthis.hydra.job.auth.PermissionsManager;
import com.addthis.hydra.job.spawn.HealthCheckResult;
import com.addthis.hydra.job.spawn.Spawn;
import com.addthis.hydra.job.spawn.SpawnBalancer;
import com.addthis.hydra.job.spawn.SpawnBalancerConfig;
import com.addthis.hydra.job.spawn.SystemManager;
import com.addthis.hydra.job.store.DataStoreUtil.DataStoreType;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

@Path("/system")
public class SystemResource {

    private static final Logger log = LoggerFactory.getLogger(SystemResource.class);

    @Nonnull private final SystemManager systemManager;
    @Nonnull private final SpawnBalancer spawnBalancer;
    @Nonnull private final HostFailWorker hostFailWorker;
    @Nonnull private final PermissionsManager permissionsManager;


    public SystemResource(Spawn spawn) {
        this.systemManager = spawn.getSystemManager();
        this.spawnBalancer = spawn.getSpawnBalancer();
        this.hostFailWorker = spawn.getHostFailWorker();
        this.permissionsManager = spawn.getPermissionsManager();
    }

    @GET
    @Path("/quiesce")
    @Produces(MediaType.APPLICATION_JSON)
    public Response quiesceCluster(@QueryParam("quiesce") String quiesce,
                                   @QueryParam("user") String user,
                                   @QueryParam("token") String token,
                                   @QueryParam("sudo") String sudo) {
        try {
            if (permissionsManager.adminAction(user, token, sudo)) {
                boolean quiesced = systemManager.quiesceCluster(quiesce.equals("1"), user);
                String json = Jackson.defaultMapper().createObjectNode()
                        .put("quiesced", (quiesced ? "1" : "0")).toString();
                return Response.ok(json).build();
            } else {
                return Response.status(Response.Status.FORBIDDEN).build();
            }
        } catch (Exception ex) {
            return Response.serverError().entity(ex.getMessage()).build();
        }
    }

    @GET
    @Path("/balance.params.get")
    @Produces(MediaType.APPLICATION_JSON)
    public Response getBalanceParams() {
        try {
            return Response.ok(CodecJSON.encodeString(spawnBalancer.getConfig())).build();
        } catch (Exception e) {
            return Response.serverError().entity("Error getting balance parameters: " + e.getMessage()).build();
        }
    }

    @GET
    @Path("/balance.params.set")
    @Produces(MediaType.APPLICATION_JSON)
    public Response setBalanceParams(@QueryParam("params") String params) {
        try {
            SpawnBalancerConfig config = CodecJSON.decodeString(SpawnBalancerConfig.class, params);
            spawnBalancer.setConfig(config);
            spawnBalancer.saveConfigToDataStore();
            return Response.ok().build();
        } catch (Exception e) {
            String err = "Failed to set SpawnBalanceConfig: " + e.getMessage();
            log.warn(err, e);
            return Response.serverError().entity(err).build();
        }
    }

    @GET
    @Path("/hostfailworker.obeyTaskLimit.set")
    @Produces(MediaType.APPLICATION_JSON)
    public Response setObeyTaskLimit(@QueryParam("obey") boolean obey) {
        hostFailWorker.setObeyTaskSlots(obey);
        return Response.ok().build();
    }

    @GET
    @Path("/git.properties")
    @Produces(MediaType.APPLICATION_JSON)
    public Response getGitProperties() {
        try {
            return Response.ok(CodecJSON.encodeString(systemManager.getGitProperties())).build();
        } catch (Exception e) {
            String err = "Error loading git properties: " + e.getMessage();
            log.warn(err, e);
            return Response.serverError().entity(err).build();
        }
    }

    @GET
    @Path("/datastore.cutover")
    @Produces(MediaType.TEXT_PLAIN)
    public Response datastoreCutover(
            @QueryParam("src") String src,
            @QueryParam("tar") String tar,
            @QueryParam("checkAll") int checkAll) {

        try {
            DataStoreType sourceType = DataStoreType.valueOf(src);
            DataStoreType targetType = DataStoreType.valueOf(tar);
            boolean checkAllWrites = (checkAll == 1);
            systemManager.cutoverDataStore(sourceType, targetType, checkAllWrites);
            return Response.ok("Cut over successfully.").build();
        } catch (IllegalStateException e) {
            return Response.serverError().entity("Spawn must be quiesced to cut over stored data.").build();
        } catch (IllegalArgumentException e) {
            return Response.status(Response.Status.BAD_REQUEST).entity(e.getMessage()).build();
        } catch (Exception e) {
            String err = "Error cutting over data store: " + e.getMessage();
            log.error(err, e);
            return Response.serverError().entity(err).build();
        }
    }

    
    @GET
    @Path("/healthcheck")
    @Produces(MediaType.APPLICATION_JSON)
    public Response healthCheck(
            @QueryParam("retries") @DefaultValue("3") int retries,
            @QueryParam("details") @DefaultValue("false") boolean details) {
        try {
            HealthCheckResult result = systemManager.healthCheck(retries);
            if (details) {
                return Response.ok(CodecJSON.encodeString(result)).build();
            } else {
                return Response.ok(String.valueOf(result.isEverythingOK())).build();
            }
            
        } catch (Exception e) {
            String err = "Error running health check: " + e.getMessage();
            log.error(err, e);
            return Response.serverError().entity(err).build();
        }
    }

}

<code block>

package com.addthis.hydra.job.mq;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;

import com.addthis.hydra.minion.Minion;

import com.google.common.base.Objects;

import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonTypeInfo;

@JsonIgnoreProperties({"messageType", "totalLive", "readOnly"})
@JsonTypeInfo(use = JsonTypeInfo.Id.CLASS, include = JsonTypeInfo.As.PROPERTY, defaultImpl = HostState.class)
public class HostState implements HostMessage {

    @JsonProperty private String host;
    @JsonProperty private int port;
    @JsonProperty private String uuid;
    @JsonProperty private String user;
    @JsonProperty private String path;
    @JsonProperty private String group;
    
    
    @JsonProperty private boolean up;
    @JsonProperty private long time;
    @JsonProperty private long uptime;
    @JsonProperty private int availableTaskSlots;
    @JsonProperty private int maxTaskSlots;
    @JsonProperty private JobKey[] running;
    @JsonProperty private JobKey[] replicating;
    @JsonProperty private JobKey[] backingup;
    @JsonProperty private JobKey[] stopped;
    @JsonProperty private JobKey[] replicas;
    @JsonProperty private JobKey[] incompleteReplicas;
    @JsonProperty private JobKey[] queued;
    @JsonProperty private HostCapacity used;
    @JsonProperty private HostCapacity max;
    @JsonProperty private boolean dead;
    @JsonProperty private long lastUpdateTime;
    @JsonProperty private double histQueueSize;
    @JsonProperty private double histWaitTime;
    
    @JsonProperty private HashMap<String, Double> jobRuntimes = new HashMap<>();
    @JsonProperty private boolean diskReadOnly;
    @JsonProperty private boolean disabled;
    @JsonProperty private double meanActiveTasks;
    @JsonProperty private String minionTypes;

    
    private HashMap<String, Integer> jobTaskCountMap;

    @JsonCreator
    private HostState() {}

    public HostState(String hostUuid) {
        this.uuid = hostUuid;
    }

    @Override
    public String getHostUuid() {
        return uuid;
    }

    public void setUuid(String uuid) {
        this.uuid = uuid;
    }

    @JsonProperty
    public void setHostUuid(String uuid) {
        this.uuid = uuid;
    }


    public void setUpdated() {
        lastUpdateTime = System.currentTimeMillis();
    }

    public boolean hasLive(JobKey jobKey) {
        if (stopped != null && Arrays.asList(stopped).contains(jobKey)) {
            return true;
        }
        if (queued != null && Arrays.asList(queued).contains(jobKey)) {
            return true;
        }
        if (running != null && Arrays.asList(running).contains(jobKey)) {
            return true;
        }
        if (replicating != null && Arrays.asList(replicating).contains(jobKey)) {
            return true;
        }
        if (backingup != null && Arrays.asList(backingup).contains(jobKey)) {
            return true;
        }
        return false;
    }

    public boolean hasIncompleteReplica(JobKey jobKey) {
        return (incompleteReplicas != null) && Arrays.asList(incompleteReplicas).contains(jobKey);
    }

    public List<JobKey> allJobKeys() {
        List<JobKey> rv = new ArrayList<>();
        for (JobKey[] jobKeys : Arrays.asList(stopped, queued, running, replicating, backingup, replicas)) {
            if (jobKeys != null) {
                rv.addAll(Arrays.asList(jobKeys));
            }
        }
        return rv;
    }

    public Integer addJob(String jobId) {
        if (this.jobTaskCountMap == null) {
            jobTaskCountMap = new HashMap<>();
        }
        int currentCount = 0;
        if (jobTaskCountMap.containsKey(jobId)) {
            currentCount = jobTaskCountMap.get(jobId);
        }
        return jobTaskCountMap.put(jobId, currentCount + 1);
    }

    public void generateJobTaskCountMap() {
        jobTaskCountMap = new HashMap<>();
        List<JobKey[]> activeJobsSources = Arrays.asList(stopped, queued, running, replicas);
        for (JobKey[] source : activeJobsSources) {
            if (source == null) {
                continue;
            }
            for (JobKey jobKey : source) {
                if (jobKey == null) {
                    continue;
                }
                Integer oldCount = jobTaskCountMap.get(jobKey.getJobUuid());
                int newCount;
                if (oldCount != null) {
                    newCount = 1 + oldCount;
                } else {
                    newCount = 1;
                }
                jobTaskCountMap.put(jobKey.getJobUuid(), newCount);
            }
        }
    }

    public Integer getTaskCount(String jobId) {
        if (jobTaskCountMap == null) {
            generateJobTaskCountMap();
        }
        if ((jobTaskCountMap != null) && jobTaskCountMap.containsKey(jobId)) {
            return jobTaskCountMap.get(jobId);
        } else {
            return 0;
        }
    }

    public boolean canMirrorTasks() {
        return up && !dead && !diskReadOnly && !disabled;
    }

    public boolean hasType(String type) {
        if (minionTypes == null) {
            minionTypes = Minion.defaultMinionType;
        }
        if (minionTypes.contains(",")) {
            return Arrays.asList(minionTypes.split(",")).contains(type);
        }
        return type.equals(minionTypes);
    }

    public int countTotalLive() {
        int total = 0;
        for (JobKey[] keys : Arrays.asList(stopped, running, replicating, backingup, queued)) {
            if (keys != null) {
                total += keys.length;
            }
        }
        return total;
    }

    @Override
    public String toString() {
        return Objects.toStringHelper(this)
                .add("uuid", getHostUuid())
                .add("last-update-time", getLastUpdateTime())
                .add("host", getHost())
                .add("port", getPort())
                .add("group", getGroup())
                .add("time", getTime())
                .add("uptime", getUptime())
                        
                        
                        
                        
                        
                .add("used", getUsed())
                .add("user", getUser())
                .add("path", getPath())
                .add("max", getMax())
                .add("up", isUp())
                .add("dead", isDead())
                .add("diskReadOnly", isDiskReadOnly())
                .toString();
    }

    
    
    

    public long getLastUpdateTime() {
        return lastUpdateTime;
    }

    public void setLastUpdateTime(long lastUpdateTime) {
        this.lastUpdateTime = lastUpdateTime;
    }

    public double getHistQueueSize() {
        return histQueueSize;
    }

    public void setHistQueueSize(double size) {
        this.histQueueSize = size;
    }

    public double getHistWaitTime() {
        return histWaitTime;
    }

    public void setHistWaitTime(double seconds) {
        this.histWaitTime = seconds;
    }

    public String getHost() {
        return host;
    }

    public void setHost(String host) {
        this.host = host;
    }

    public int getPort() {
        return port;
    }

    public void setPort(int port) {
        this.port = port;
    }

    public String getGroup() {
        return group;
    }

    public void setGroup(String group) {
        this.group = group;
    }

    public boolean isUp() {
        return up;
    }

    public void setUp(boolean up) {
        this.up = up;
    }

    public long getTime() {
        return time;
    }

    public void setTime(long time) {
        this.time = time;
    }

    public long getUptime() {
        return uptime;
    }

    public void setUptime(long uptime) {
        this.uptime = uptime;
    }

    public JobKey[] getRunning() {
        return running;
    }

    public void setRunning(JobKey[] running) {
        this.running = running;
    }

    
    public JobKey[] getReplicating() {
        return replicating;
    }

    public void setReplicating(JobKey[] replicating) {
        this.replicating = replicating;
    }

    
    public JobKey[] getBackingup() {
        return backingup;
    }

    public void setBackingup(JobKey[] backingup) {
        this.backingup = backingup;
    }

    public void setReplicas(JobKey[] replicas) {
        this.replicas = replicas;
    }

    public JobKey[] getReplicas() {
        return replicas;
    }

    public void setStopped(JobKey[] stopped) {
        this.stopped = stopped;
    }

    public JobKey[] getStopped() {
        return stopped;
    }

    public JobKey[] getQueued() {
        return queued;
    }

    public void setQueued(JobKey[] queued) {
        this.queued = queued;
    }

    public HostCapacity getUsed() {
        return used;
    }

    public void setUsed(HostCapacity used) {
        this.used = used;
    }

    public String getUser() {
        return user;
    }

    public void setUser(String user) {
        this.user = user;
    }

    public String getPath() {
        return path;
    }

    public void setPath(String path) {
        this.path = path;
    }

    public HostCapacity getMax() {
        return max;
    }

    public void setMax(HostCapacity max) {
        this.max = max;
    }

    public void setDead(boolean dead) {
        this.dead = dead;
    }

    public boolean isDead() {
        return dead;
    }

    public boolean isDiskReadOnly() {
        return this.diskReadOnly;
    }

    public void setDiskReadOnly(boolean diskReadOnly) {
        this.diskReadOnly = diskReadOnly;
    }

    public int getAvailableTaskSlots() {
        return availableTaskSlots;
    }

    public void setAvailableTaskSlots(int availableTaskSlots) {
        this.availableTaskSlots = availableTaskSlots;
    }

    public boolean isDisabled() {
        return disabled;
    }

    public void setDisabled(boolean disabled) {
        this.disabled = disabled;
    }

    public double getMeanActiveTasks() {
        return meanActiveTasks;
    }

    public void setMeanActiveTasks(double meanActiveTasks) {
        this.meanActiveTasks = meanActiveTasks;
    }

    public String getMinionTypes() {
        return minionTypes;
    }

    public void setMinionTypes(String minionTypes) {
        this.minionTypes = minionTypes;
    }

    public JobKey[] getIncompleteReplicas() {
        return incompleteReplicas;
    }

    public void setIncompleteReplicas(JobKey[] incompleteReplicas) {
        this.incompleteReplicas = incompleteReplicas;
    }

    public int getMaxTaskSlots() {
        return maxTaskSlots;
    }

    public void setMaxTaskSlots(int maxTaskSlots) {
        this.maxTaskSlots = maxTaskSlots;
    }
}

<code block>

package com.addthis.hydra.job.spawn;

import javax.annotation.Nonnull;
import javax.annotation.Nullable;
import javax.ws.rs.core.Response;

import java.io.File;
import java.io.IOException;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.ListIterator;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.SortedSet;
import java.util.TreeSet;
import java.util.UUID;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

import java.text.ParseException;

import com.addthis.basis.util.JitterClock;
import com.addthis.basis.util.LessFiles;
import com.addthis.basis.util.LessStrings;
import com.addthis.basis.util.Parameter;
import com.addthis.basis.util.RollingLog;
import com.addthis.basis.util.TokenReplacerOverflowException;

import com.addthis.bark.StringSerializer;
import com.addthis.bark.ZkUtil;
import com.addthis.codec.annotations.Time;
import com.addthis.codec.codables.Codable;
import com.addthis.codec.config.Configs;
import com.addthis.codec.jackson.Jackson;
import com.addthis.codec.json.CodecJSON;
import com.addthis.hydra.common.util.CloseTask;
import com.addthis.hydra.job.HostFailWorker;
import com.addthis.hydra.job.IJob;
import com.addthis.hydra.job.Job;
import com.addthis.hydra.job.JobConfigManager;
import com.addthis.hydra.job.JobDefaults;
import com.addthis.hydra.job.JobEvent;
import com.addthis.hydra.job.JobExpand;
import com.addthis.hydra.job.JobParameter;
import com.addthis.hydra.job.JobState;
import com.addthis.hydra.job.JobTask;
import com.addthis.hydra.job.JobTaskDirectoryMatch;
import com.addthis.hydra.job.JobTaskErrorCode;
import com.addthis.hydra.job.JobTaskMoveAssignment;
import com.addthis.hydra.job.JobTaskReplica;
import com.addthis.hydra.job.JobTaskState;
import com.addthis.hydra.job.RebalanceOutcome;
import com.addthis.hydra.job.alert.JobAlertManager;
import com.addthis.hydra.job.alert.JobAlertManagerImpl;
import com.addthis.hydra.job.alias.AliasManager;
import com.addthis.hydra.job.alias.AliasManagerImpl;
import com.addthis.hydra.job.auth.PermissionsManager;
import com.addthis.hydra.job.backup.ScheduledBackupType;
import com.addthis.hydra.job.entity.JobCommand;
import com.addthis.hydra.job.entity.JobCommandManager;
import com.addthis.hydra.job.entity.JobEntityManager;
import com.addthis.hydra.job.entity.JobMacro;
import com.addthis.hydra.job.entity.JobMacroManager;
import com.addthis.hydra.job.mq.CommandTaskDelete;
import com.addthis.hydra.job.mq.CommandTaskKick;
import com.addthis.hydra.job.mq.CommandTaskReplicate;
import com.addthis.hydra.job.mq.CommandTaskRevert;
import com.addthis.hydra.job.mq.CommandTaskStop;
import com.addthis.hydra.job.mq.CoreMessage;
import com.addthis.hydra.job.mq.HostMessage;
import com.addthis.hydra.job.mq.HostState;
import com.addthis.hydra.job.mq.JobKey;
import com.addthis.hydra.job.mq.ReplicaTarget;
import com.addthis.hydra.job.mq.StatusTaskBackup;
import com.addthis.hydra.job.mq.StatusTaskBegin;
import com.addthis.hydra.job.mq.StatusTaskCantBegin;
import com.addthis.hydra.job.mq.StatusTaskEnd;
import com.addthis.hydra.job.mq.StatusTaskPort;
import com.addthis.hydra.job.mq.StatusTaskReplica;
import com.addthis.hydra.job.mq.StatusTaskReplicate;
import com.addthis.hydra.job.mq.StatusTaskRevert;
import com.addthis.hydra.job.spawn.JobOnFinishStateHandler.JobOnFinishState;
import com.addthis.hydra.job.store.DataStoreUtil;
import com.addthis.hydra.job.store.JobStore;
import com.addthis.hydra.job.store.SpawnDataStore;
import com.addthis.hydra.job.store.SpawnDataStoreKeys;
import com.addthis.hydra.job.web.SpawnService;
import com.addthis.hydra.job.web.SpawnServiceConfiguration;
import com.addthis.hydra.minion.Minion;
import com.addthis.hydra.task.run.TaskExitState;
import com.addthis.hydra.util.DirectedGraph;
import com.addthis.hydra.util.WebSocketManager;
import com.addthis.maljson.JSONArray;
import com.addthis.maljson.JSONObject;
import com.addthis.meshy.service.file.FileReference;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.base.Joiner;
import com.google.common.collect.ImmutableMap;

import com.fasterxml.jackson.annotation.JacksonInject;
import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.yammer.metrics.Metrics;

import org.apache.curator.framework.CuratorFramework;
import org.apache.zookeeper.KeeperException;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import static com.addthis.hydra.job.store.SpawnDataStoreKeys.MINION_DEAD_PATH;
import static com.addthis.hydra.job.store.SpawnDataStoreKeys.SPAWN_QUEUE_PATH;
import static com.google.common.base.Preconditions.checkArgument;
import static java.util.concurrent.TimeUnit.MILLISECONDS;


@JsonAutoDetect(getterVisibility = JsonAutoDetect.Visibility.NONE,
                isGetterVisibility = JsonAutoDetect.Visibility.NONE,
                setterVisibility = JsonAutoDetect.Visibility.NONE)
public class Spawn implements Codable, AutoCloseable {
    private static final Logger log = LoggerFactory.getLogger(Spawn.class);

    

    static final int DEFAULT_REPLICA_COUNT = Parameter.intValue("spawn.defaultReplicaCount", 1);
    static final boolean ENABLE_JOB_FIXDIRS_ONCOMPLETE = Parameter.boolValue("job.fixdirs.oncomplete", true);

    public static final long inputMaxNumberOfCharacters = Parameter.longValue("spawn.input.max.length", 1_000_000);

    private static final int clientDropTimeMillis = Parameter.intValue("spawn.client.drop.time", 60_000);
    private static final int clientDropQueueSize  = Parameter.intValue("spawn.client.drop.queue", 2000);

    

    private static final boolean eventLogCompress = Parameter.boolValue("spawn.eventlog.compress", true);
    private static final int logMaxAge  = Parameter.intValue("spawn.event.log.maxAge", 60 * 60 * 1000);
    private static final int logMaxSize = Parameter.intValue("spawn.event.log.maxSize", 100 * 1024 * 1024);
    private static final String logDir = Parameter.value("spawn.event.log.dir", "log");

    

    public static void main(String[] args) throws Exception {
        Spawn spawn = Configs.newDefault(Spawn.class);
        spawn.startWebInterface();
        
        Runtime.getRuntime().addShutdownHook(new Thread(new CloseTask(spawn), "Spawn Shutdown Hook"));
    }

    SpawnQueuesByPriority taskQueuesByPriority = new SpawnQueuesByPriority();

    private SpawnMQ spawnMQ;
    private SpawnService spawnService;

    private volatile int lastQueueSize = 0;

    final Lock jobLock = new ReentrantLock();
    private final AtomicBoolean shuttingDown = new AtomicBoolean(false);
    private final BlockingQueue<String> jobUpdateQueue = new LinkedBlockingQueue<>();
    private final SpawnJobFixer spawnJobFixer = new SpawnJobFixer(this);
    
    private final WebSocketManager webSocketManager = new WebSocketManager();

    @Nonnull public final HostManager hostManager;

    @Nonnull final SpawnState spawnState;
    @Nonnull final ConcurrentMap<String, ClientEventListener> listeners;
    @Nonnull final SpawnFormattedLogger spawnFormattedLogger;

    @Nonnull final PermissionsManager permissionsManager;
    @Nonnull final JobDefaults jobDefaults;

    @Nonnull private final File stateFile;
    @Nonnull private final ExecutorService expandKickExecutor;
    @Nonnull private final ScheduledExecutorService scheduledExecutor;
    @Nonnull private final CuratorFramework zkClient;
    @Nonnull private final SpawnDataStore spawnDataStore;
    @Nonnull private final JobConfigManager jobConfigManager;
    @Nonnull private final AliasManager aliasManager;
    @Nonnull private final JobAlertManager jobAlertManager;
    @Nonnull private final SpawnMesh spawnMesh;
    @Nonnull private final JobEntityManager<JobMacro> jobMacroManager;
    @Nonnull private final JobEntityManager<JobCommand> jobCommandManager;
    @Nonnull private final JobOnFinishStateHandler jobOnFinishStateHandler;
    @Nonnull private final SpawnBalancer balancer;
    @Nonnull private final HostFailWorker hostFailWorker;
    @Nonnull private final SystemManager systemManager;
    @Nonnull private final RollingLog eventLog;

    @Nullable private final JobStore jobStore;

    @JsonCreator
    private Spawn(@JsonProperty("debug") String debug,
                  @JsonProperty(value = "queryPort", required = true) int queryPort,
                  @JsonProperty("queryHttpHost") String queryHttpHost,
                  @JsonProperty("httpHost") String httpHost,
                  @JsonProperty("dataDir") File dataDir,
                  @JsonProperty("stateFile") File stateFile,
                  @JsonProperty("expandKickExecutor") ExecutorService expandKickExecutor,
                  @JsonProperty("scheduledExecutor") ScheduledExecutorService scheduledExecutor,
                  @Time(MILLISECONDS) @JsonProperty(value = "taskQueueDrainInterval", required = true)
                  int taskQueueDrainInterval,
                  @Time(MILLISECONDS) @JsonProperty(value = "hostStatusRequestInterval", required = true)
                  int hostStatusRequestInterval,
                  @Time(MILLISECONDS) @JsonProperty(value = "queueKickInterval", required = true)
                  int queueKickInterval,
                  @Time(MILLISECONDS) @JsonProperty("jobTaskUpdateHeartbeatInterval")
                  int jobTaskUpdateHeartbeatInterval,
                  @Nullable @JsonProperty("structuredLogDir") File structuredLogDir,
                  @Nullable @JsonProperty("jobStore") JobStore jobStore,
                  @Nullable @JsonProperty("queueType") String queueType,
                  @Nullable @JacksonInject CuratorFramework providedZkClient,
                  @JsonProperty(value = "permissionsManager", required = true) PermissionsManager permissionsManager,
                  @JsonProperty(value = "jobDefaults", required = true) JobDefaults jobDefaults) throws Exception {
        LessFiles.initDirectory(dataDir);
        this.stateFile = stateFile;
        this.permissionsManager = permissionsManager;
        this.jobDefaults = jobDefaults;
        if (stateFile.exists() && stateFile.isFile()) {
            spawnState = Jackson.defaultMapper().readValue(stateFile, SpawnState.class);
        } else {
            spawnState = Jackson.defaultCodec().newDefault(SpawnState.class);
        }
        File webDir = new File("web");
        this.listeners = new ConcurrentHashMap<>();
        this.expandKickExecutor = expandKickExecutor;
        this.scheduledExecutor = scheduledExecutor;
        if (structuredLogDir == null) {
            this.spawnFormattedLogger = SpawnFormattedLogger.createNullLogger();
        } else {
            this.spawnFormattedLogger =  SpawnFormattedLogger.createFileBasedLogger(structuredLogDir);
        }
        if (providedZkClient == null) {
            this.zkClient = ZkUtil.makeStandardClient();
        } else {
            this.zkClient = providedZkClient;
        }
        this.hostManager = new HostManager(zkClient);
        this.spawnDataStore = DataStoreUtil.makeCanonicalSpawnDataStore(true);
        this.systemManager = new SystemManagerImpl(
                this, debug, queryHttpHost + ":" + queryPort,
                httpHost + ":" + SpawnServiceConfiguration.SINGLETON.webPort,
                SpawnServiceConfiguration.SINGLETON.authenticationTimeout,
                SpawnServiceConfiguration.SINGLETON.sudoTimeout);
        this.jobConfigManager = new JobConfigManager(spawnDataStore);
        
        log.info("[init] beginning to load stats from data store");
        aliasManager = new AliasManagerImpl(spawnDataStore);
        jobMacroManager = new JobMacroManager(this);
        jobCommandManager = new JobCommandManager(this);
        jobOnFinishStateHandler = new JobOnFinishStateHandlerImpl(this);
        loadSpawnQueue();
        
        for (Job job : spawnState.jobs.values()) {
            if (job.getSubmitTime() == null) {
                job.setSubmitTime(System.currentTimeMillis());
            }
        }
        loadJobs();
        
        
        
        hostFailWorker = new HostFailWorker(this, hostManager, scheduledExecutor);
        balancer = new SpawnBalancer(this, hostManager);

        
        this.spawnMesh = new SpawnMesh(this);
        
        if ("rabbit".equals(queueType)) {
            log.info("[init] connecting to rabbit message queue");
            this.spawnMQ = new SpawnMQImpl(zkClient, this);
            this.spawnMQ.connectToMQ(getUuid());
        } else if (queueType == null) {
            log.info("[init] skipping message queue");
        } else {
            throw new IllegalArgumentException("queueType (" + queueType +
                                               ") must be either a valid message queue type or null");
        }

        
        
        
        hostFailWorker.initFailHostTaskSchedule();
        
        jobAlertManager = new JobAlertManagerImpl(this, scheduledExecutor);
        
        scheduledExecutor.scheduleWithFixedDelay(new UpdateEventRunnable(this), 0, 1, TimeUnit.MINUTES);
        scheduledExecutor.scheduleWithFixedDelay(new JobRekickTask(this), 0, 500, MILLISECONDS);
        scheduledExecutor.scheduleWithFixedDelay(this::drainJobTaskUpdateQueue,
                                                 taskQueueDrainInterval, taskQueueDrainInterval, MILLISECONDS);
        scheduledExecutor.scheduleWithFixedDelay(this::jobTaskUpdateHeartbeatCheck,
                                                 jobTaskUpdateHeartbeatInterval, jobTaskUpdateHeartbeatInterval,
                                                 MILLISECONDS);
        
        scheduledExecutor.scheduleWithFixedDelay(this::requestHostsUpdate,
                                                 hostStatusRequestInterval, hostStatusRequestInterval, MILLISECONDS);
        scheduledExecutor.scheduleWithFixedDelay(() -> {
            kickJobsOnQueue();
            writeSpawnQueue();
        }, queueKickInterval, queueKickInterval, MILLISECONDS);
        balancer.startAutobalanceTask();
        balancer.startTaskSizePolling();
        this.jobStore = jobStore;
        this.eventLog = new RollingLog(new File(logDir, "events-jobs"), "job",
                                       eventLogCompress, logMaxSize, logMaxAge);
        Metrics.newGauge(Spawn.class, "minionsDown", new DownMinionGauge(hostManager));
        writeState();
    }

    public void startWebInterface() throws Exception {
        spawnService = new SpawnService(this, SpawnServiceConfiguration.SINGLETON);
        spawnService.start();
    }

    void writeState() {
        try {
            LessFiles.write(stateFile, CodecJSON.INSTANCE.encode(spawnState), false);
        } catch (Exception e) {
            log.warn("Failed to write spawn state to log file at {}", stateFile, e);
        }
    }

    @Nonnull
    public HostFailWorker getHostFailWorker() {
        return hostFailWorker;
    }

    public SpawnBalancer getSpawnBalancer() {
        return balancer;
    }

    @Nonnull
    public PermissionsManager getPermissionsManager() { return permissionsManager; }

    @Nonnull
    public AliasManager getAliasManager() {
        return aliasManager;
    }
    
    @Nonnull
    public JobAlertManager getJobAlertManager() {
        return jobAlertManager;
    }
    
    @Nonnull
    public JobEntityManager<JobMacro> getJobMacroManager() {
        return jobMacroManager;
    }
    
    @Nonnull
    public JobEntityManager<JobCommand> getJobCommandManager() {
        return jobCommandManager;
    }
    
    @Nonnull
    public SystemManager getSystemManager() {
        return systemManager;
    }

    public void acquireJobLock() {
        jobLock.lock();
    }

    public void releaseJobLock() {
        jobLock.unlock();
    }

    public String getUuid() {
        return spawnState.uuid;
    }

    private void closeZkClients() {
        spawnDataStore.close();
        zkClient.close();
    }

    public void setSpawnMQ(SpawnMQ spawnMQ) {
        this.spawnMQ = spawnMQ;
    }

    @VisibleForTesting
    protected void loadSpawnQueue() throws Exception {
        String queueFromZk = spawnDataStore.get(SPAWN_QUEUE_PATH);
        if (queueFromZk == null) {
            return;
        }
        try {
            taskQueuesByPriority = new ObjectMapper().readValue(queueFromZk, SpawnQueuesByPriority.class);
        } catch (Exception ex) {
            log.warn("[task.queue] exception during spawn queue deserialization: ", ex);
        }
    }

    protected void writeSpawnQueue() {
        ObjectMapper om = new ObjectMapper();
        try {
            taskQueuesByPriority.lock();
            try {
                spawnDataStore.put(SPAWN_QUEUE_PATH, new String(om.writeValueAsBytes(taskQueuesByPriority)));
            } finally {
                taskQueuesByPriority.unlock();
            }
        } catch (Exception ex) {
            log.warn("[task.queue] exception during spawn queue serialization", ex);
        }
    }

    @VisibleForTesting
    protected void loadJobs() {
        jobLock.lock();
        try {
            for (IJob iJob : jobConfigManager.getJobs().values()) {
                if (iJob != null) {
                    putJobInSpawnState(new Job(iJob));
                }
            }
        } finally {
            jobLock.unlock();
        }
        Thread loadDependencies = new Thread(() -> {
            Set<String> jobIds = spawnState.jobs.keySet();
            for (String jobId : jobIds) {
                IJob job = getJob(jobId);
                if (job != null) {
                    updateJobDependencies(jobId);
                }
            }
        }, "spawn job dependency calculator");
        loadDependencies.setDaemon(true);
        loadDependencies.start();
    }

    

    public ClientEventListener getClientEventListener(String id) {
        ClientEventListener listener = listeners.get(id);
        if (listener == null) {
            listener = new ClientEventListener();
            listeners.put(id, listener);
        }
        listener.lastSeen = System.currentTimeMillis();
        return listener;
    }

    public HostState markHostStateDead(String hostUUID) {
        HostState state = hostManager.getHostState(hostUUID);
        if (state != null) {
            state.setDead(true);
            state.setUpdated();
            
            spawnDataStore.delete(Minion.MINION_ZK_PATH + hostUUID);
            try {
                zkClient.create().creatingParentsIfNeeded().forPath(MINION_DEAD_PATH + "/" + hostUUID, null);
            } catch (KeeperException.NodeExistsException ne) {
                
            } catch (Exception e) {
                log.error("Unable to add host: {} to " + MINION_DEAD_PATH, hostUUID, e);
            }
            sendHostUpdateEvent(state);
            hostManager.updateHostState(state);
        }
        return state;
    }

    public Collection<String> listAvailableHostIds() {
        return hostManager.minionMembers.getMemberSet();
    }

    public void requestHostsUpdate() {
        try {
            spawnMQ.sendControlMessage(new HostState(HostMessage.ALL_HOSTS));
        } catch (Exception e) {
            log.warn("unable to request host state update: ", e);
        }
    }

    public Set<String> getDataSources(String jobId) {
        HashSet<String> dataSources = new HashSet<>();
        Job job = this.getJob(jobId);
        if (job == null || job.getParameters() == null) {
            return dataSources;
        }
        jobLock.lock();
        try {
            for (JobParameter param : job.getParameters()) {
                String value = param.getValue();
                if (LessStrings.isEmpty(value)) {
                    value = param.getDefaultValue();
                }
                if (value != null) {
                    try {
                        value = JobExpand.macroExpand(this, value);
                    } catch (TokenReplacerOverflowException ex) {
                        log.error("Token replacement overflow for input '{}'", value);
                    }
                }
                if (value != null && spawnState.jobs.containsKey(value)) {
                    dataSources.add(value);
                }
            }
        } finally {
            jobLock.unlock();
        }
        return dataSources;
    }

    public DirectedGraph<String> getJobDependencies() {
        return spawnState.jobDependencies;
    }

    
    public Map<ScheduledBackupType, SortedSet<Long>> getJobBackups(String jobUUID, int nodeId) throws IOException, ParseException {
        Map<ScheduledBackupType, SortedSet<Long>> fileDates = new HashMap<>();
        for (ScheduledBackupType backupType : ScheduledBackupType.getBackupTypes().values()) {
            final String typePrefix = "*/" + jobUUID + "/" + ((nodeId < 0) ? "*" : Integer.toString(nodeId)) + "/" + backupType.getPrefix() + "*";
            List<FileReference> files = new ArrayList<>(spawnMesh.getClient().listFiles(new String[]{typePrefix}));
            fileDates.put(backupType, new TreeSet<>(Collections.reverseOrder()));
            for (FileReference file : files) {
                String filename = file.name.split("/")[4];
                fileDates.get(backupType).add(backupType.parseDateFromName(filename).getTime());
            }
        }
        return fileDates;
    }

    public boolean isSpawnMeshAvailable() {
        return spawnMesh.getClient() != null;
    }

    public void deleteHost(String hostuuid) {
        HostFailWorker.FailState failState = hostFailWorker.getFailureState(hostuuid);
        if (failState == HostFailWorker.FailState.FAILING_FS_DEAD || failState == HostFailWorker.FailState.FAILING_FS_OKAY) {
            log.warn("Refused to drop host because it was in the process of being failed {}", hostuuid);
            throw new RuntimeException("Cannot drop a host that is in the process of being failed");
        }
        synchronized (hostManager.monitored) {
            HostState state = hostManager.monitored.remove(hostuuid);
            if (state != null) {
                log.info("Deleted host {}", hostuuid);
                sendHostUpdateEvent("host.delete", state);
            } else {
                log.warn("Attempted to delete host {} But it was not found", hostuuid);
            }
        }
    }

    public Collection<Job> listJobs() {
        ArrayList<Job> clones = new ArrayList<>(spawnState.jobs.size());
        jobLock.lock();
        try {
            for (Job job : spawnState.jobs.values()) {
                clones.add(job);
            }
            return clones;
        } finally {
            jobLock.unlock();
        }
    }

    public Collection<Job> listJobsConcurrentImmutable() {
        return Collections.unmodifiableCollection(spawnState.jobs.values());
    }

    public int getTaskQueuedCount() {
        return lastQueueSize;
    }

    public Job getJob(String jobUUID) {
        if (jobUUID == null) {
            return null;
        }
        jobLock.lock();
        try {
            return spawnState.jobs.get(jobUUID);
        } finally {
            jobLock.unlock();
        }
    }

    public void setJobConfig(String jobUUID, String config) throws Exception {
        jobConfigManager.setConfig(jobUUID, config);
    }

    public String getJobConfig(String jobUUID) {
        if (jobUUID == null) {
            return null;
        }
        jobLock.lock();
        try {
            return jobConfigManager.getConfig(jobUUID);
        } finally {
            jobLock.unlock();
        }
    }

    public Job putJobInSpawnState(Job job) {
        if (job == null) {
            return null;
        }
        
        
        job.setConfig(null);
        return spawnState.jobs.put(job.getId(), job);
    }

    public Job getJob(JobKey jobKey) {
        String jobUUID = jobKey.getJobUuid();
        return getJob(jobUUID);
    }

    public JSONArray getJobHistory(String jobId) {
        return jobStore != null ? jobStore.getHistory(jobId) : new JSONArray();
    }

    public String getJobHistoricalConfig(String jobId, String commitId) {
        return jobStore != null ? jobStore.fetchHistoricalConfig(jobId, commitId) : null;
    }

    public String diff(String jobId, String commitId) {
        return jobStore != null ? jobStore.getDiff(jobId, commitId) : null;
    }
    
    public String getDeletedJobConfig(String jobId) throws Exception {
        requireJobStore();
        return jobStore.getDeletedJobConfig(jobId);
    }

    private void requireJobStore() throws Exception {
        if (jobStore == null) {
            throw new Exception("Job history is disabled.");
        }
    }

    public Job createJob(String creator, int taskCount, Collection<String> taskHosts,
                         String minionType, String command, boolean defaults) throws Exception {
        jobLock.lock();
        try {
            Job job = new Job(UUID.randomUUID().toString(), creator);
            job.setMinionType(minionType);
            job.setCommand(command);
            job.setState(JobState.IDLE);
            if (defaults) {
                job.setOwnerWritable(jobDefaults.ownerWritable);
                job.setGroupWritable(jobDefaults.groupWritable);
                job.setWorldWritable(jobDefaults.worldWritable);
                job.setOwnerExecutable(jobDefaults.ownerExecutable);
                job.setGroupExecutable(jobDefaults.groupExecutable);
                job.setWorldExecutable(jobDefaults.worldExecutable);
                job.setDailyBackups(jobDefaults.dailyBackups);
                job.setWeeklyBackups(jobDefaults.weeklyBackups);
                job.setMonthlyBackups(jobDefaults.monthlyBackups);
                job.setHourlyBackups(jobDefaults.hourlyBackups);
                job.setReplicas(jobDefaults.replicas);
                job.setAutoRetry(jobDefaults.autoRetry);
            }
            List<HostState> hostStates = getOrCreateHostStateList(minionType, taskHosts);
            List<JobTask> tasksAssignedToHosts = balancer.generateAssignedTasksForNewJob(job.getId(), taskCount, hostStates);
            job.setTasks(tasksAssignedToHosts);
            for (JobTask task : tasksAssignedToHosts) {
                HostState host = hostManager.getHostState(task.getHostUUID());
                if (host == null) {
                    throw new Exception("Unable to allocate job tasks because no suitable host was found");
                }
                host.addJob(job.getId());
            }
            putJobInSpawnState(job);
            jobConfigManager.addJob(job);
            submitConfigUpdate(job.getId(), creator, null);
            return job;
        } finally {
            jobLock.unlock();
        }
    }

    public Response synchronizeJobState(String jobUUID, String user,
                                       String token, String sudo) {
        if (jobUUID == null) {
            return Response.status(Response.Status.BAD_REQUEST).entity("{error:\"missing id parameter\"}").build();
        }
        if (jobUUID.equals("ALL")) {
            if (!getPermissionsManager().adminAction(user, token, sudo)) {
                return Response.status(Response.Status.UNAUTHORIZED)
                               .entity("{error:\"insufficient priviledges\"}").build();
            }
            Collection<Job> jobList = listJobs();
            for (Job job : jobList) {
                Response status = synchronizeSingleJob(job.getId(), user, token, sudo);
                if (status.getStatus() != 200) {
                    log.warn("Stopping synchronize all jobs to to failure synchronizing job: " + job.getId());
                    return status;
                }
            }
            return Response.ok("{id:'" + jobUUID + "',action:'synchronzied'}").build();
        } else {
            return synchronizeSingleJob(jobUUID, user, token, sudo);
        }
    }

    private Response synchronizeSingleJob(String jobUUID, String user, String token, String sudo) {
        Job job = getJob(jobUUID);
        if (job == null) {
            log.warn("[job.synchronize] job uuid {} not found", jobUUID);
            return Response.status(Response.Status.NOT_FOUND).entity("job " + jobUUID + " not found").build();
        } else if (!permissionsManager.isExecutable(user, token, sudo, job)) {
            return Response.status(Response.Status.UNAUTHORIZED).entity("{error:\"insufficient priviledges\"}").build();
        }
        ObjectMapper mapper = new ObjectMapper();
        for (JobTask task : job.getCopyOfTasks()) {
            String taskHost = task.getHostUUID();
            if (hostManager.deadMinionMembers.getMemberSet().contains(taskHost)) {
                log.warn("task is currently assigned to a dead minion, need to check job: {} host/node:{}/{}",
                         job.getId(), task.getHostUUID(), task.getTaskID());
                continue;
            }
            String hostStateString;
            try {
                hostStateString = StringSerializer.deserialize(zkClient.getData().forPath(Minion.MINION_ZK_PATH + taskHost));
            } catch (Exception e) {
                log.error("Unable to get hostStateString from zookeeper for " + Minion.MINION_ZK_PATH + taskHost, e);
                continue;
            }
            HostState hostState;
            try {
                hostState = mapper.readValue(hostStateString, HostState.class);
            } catch (IOException e) {
                log.warn("Unable to deserialize host state for host: " + hostStateString + " serialized string was\n" + hostStateString);
                return Response.serverError().entity("Serialization error").build();
            }
            boolean matched = matchJobNodeAndId(jobUUID, task, hostState.getRunning(), hostState.getStopped(), hostState.getQueued());
            if (!matched) {
                log.warn("Spawn thinks job: " + jobUUID + " node:" + task.getTaskID() + " is running on host: " + hostState.getHost() + " but that host disagrees.");
                if (matchJobNodeAndId(jobUUID, task, hostState.getReplicas())) {
                    log.warn("Host: " + hostState.getHost() + " has a replica for the task/node: " + jobUUID + "/" + task.getTaskID() + " promoting replica");
                    try {
                        rebalanceReplicas(job);
                    } catch (Exception e) {
                        log.warn("Exception promoting replica during job synchronization on host: " + taskHost + " job/node" + job.getId() + "/" + job.getId());
                    }
                } else {
                    log.warn("Host: " + hostState.getHost() + " does NOT have a replica for the task/node: " + jobUUID + "/" + task.getTaskID());
                }
            } else {
                log.warn("Spawn and minion agree, job/node: " + jobUUID + "/" + task.getTaskID() + " is on host: " + hostState.getHost());
            }
        }
        return Response.ok().entity("success").build();
    }

    private static boolean matchJobNodeAndId(String jobUUID, JobTask task, JobKey[]... jobKeys) {
        for (JobKey[] jobKeyArray : jobKeys) {
            for (JobKey jobKey : jobKeyArray) {
                if (jobKey == null) {
                    log.warn("runningJob was null, this shouldn't happen");
                    continue;
                } else if (jobKey.getJobUuid() == null) {
                    log.warn("JobUUID for jobKey: " + jobKey + " was null");
                    continue;
                } else if (jobKey.getNodeNumber() == null) {
                    log.warn("NodeNumber for jobKey: " + jobKey + " was null");
                    continue;
                }
                if (jobKey.getJobUuid().equals(jobUUID) && jobKey.getNodeNumber().equals(task.getTaskID())) {
                    return true;
                }
            }
        }

        return false;
    }

    
    public List<JobTaskMoveAssignment> reallocateJob(String jobUUID, int tasksToMove) {
        Job job;
        if (jobUUID == null || (job = getJob(jobUUID)) == null) {
            throw new NullPointerException("invalid job uuid");
        }
        if (job.getState() != JobState.IDLE) {
            log.warn("[job.reallocate] can't reallocate non-idle job");
            return Collections.emptyList();
        }
        List<JobTaskMoveAssignment> assignments = balancer.getAssignmentsForJobReallocation(job, tasksToMove,
                                                                                            hostManager.getLiveHosts(
                                                                                                    job.getMinionType()));
        return executeReallocationAssignments(assignments, false);
    }

    
    public boolean swapTask(JobTask task, String replicaHostID, boolean kickOnComplete) {
        if (task == null) {
            log.warn("[task.swap] received null task");
            return false;
        }
        if (!checkHostStatesForSwap(task.getJobKey(), task.getHostUUID(), replicaHostID, true)) {
            log.warn("[swap.task.stopped] failed for {}; exiting", task.getJobKey());
            return false;
        }
        Job job;
        jobLock.lock();
        try {
            job = getJob(task.getJobUUID());
            task.replaceReplica(replicaHostID, task.getHostUUID());
            task.setHostUUID(replicaHostID);
            queueJobTaskUpdateEvent(job);
        } finally {
            jobLock.unlock();
        }
        if (kickOnComplete) {
            try {
                scheduleTask(job, task, expandJob(job));
            } catch (Exception e) {
                log.warn("Warning: failed to kick task {} with: {}", task.getJobKey(), e, e);
                job.errorTask(task, JobTaskErrorCode.KICK_ERROR);
            }
        }
        return true;
    }

    
    private String getReplacementHost(Job job) {
        List<HostState> hosts = hostManager.getLiveHosts(job.getMinionType());
        for (HostState host : hosts) {
            if (host.canMirrorTasks()) {
                return host.getHostUuid();
            }
        }
        return null;
    }

    
    private boolean replaceDownHosts(JobTask task) {
        checkArgument(isNewTask(task), "%s is not a new task, and so this method is not safe to call", task);
        Job job = getJob(task.getJobKey());
        if (job == null) {
            return false;
        }
        HostState host = hostManager.getHostState(task.getHostUUID());
        boolean changed = false;
        if (host == null || !host.canMirrorTasks()) {
            String replacementHost = getReplacementHost(job);
            if (replacementHost != null) {
                task.setHostUUID(replacementHost);
                changed = true;
            }
        }
        if (task.getReplicas() != null) {
            List<JobTaskReplica> tempReplicas = new ArrayList<>(task.getReplicas());
            for (JobTaskReplica replica : tempReplicas) {
                HostState replicaHost = hostManager.getHostState(replica.getHostUUID());
                if (replicaHost == null || !replicaHost.canMirrorTasks()) {
                    changed = true;
                    task.setReplicas(removeReplicasForHost(replica.getHostUUID(), task.getReplicas()));
                }
            }
        }
        if (changed) {
            try {
                updateJob(job);
            } catch (Exception ex) {
                log.warn("Failed to sent replication message for new task " + task.getJobKey() + ": " + ex, ex);
                return false;
            }
        }
        return changed;

    }

    
    private boolean checkHostStatesForSwap(JobKey key, String liveHostID, String replicaHostID, boolean checkTargetReplica) {
        if (key == null || liveHostID == null || replicaHostID == null) {
            log.warn("[task.swap] failed due to null input");
            return false;
        }
        JobTask task = getTask(key.getJobUuid(), key.getNodeNumber());
        if (task == null) {
            log.warn("[task.swap] failed: nonexistent task/replicas");
            return false;
        }
        HostState liveHost = hostManager.getHostState(liveHostID);
        HostState replicaHost = hostManager.getHostState(replicaHostID);
        if (liveHost == null || replicaHost == null || liveHost.isDead() || !liveHost.isUp() || replicaHost.isDead() || !replicaHost.isUp()) {
            log.warn("[task.swap] failed due to invalid host states for " + liveHostID + "," + replicaHostID);
            return false;
        }
        if (checkTargetReplica && !isNewTask(task)) {
            if (!replicaHost.hasLive(key)) {
                log.warn("[task.swap] failed because the replica host " + replicaHostID + " does not have a complete replica of task " + key);
                return false;
            }
        }
        return true;
    }

    
    public RebalanceOutcome rebalanceHost(String hostUUID) {
        HostState host = hostManager.getHostState(hostUUID);
        if (host == null) {
            return new RebalanceOutcome(hostUUID, "missing host", null, null);
        }
        log.info("[job.reallocate] starting reallocation for host: {} host is not a read only host", hostUUID);
        List<JobTaskMoveAssignment> assignments = balancer.getAssignmentsToBalanceHost(host,
                                                                                       hostManager.getLiveHosts(null));
        return new RebalanceOutcome(hostUUID, null, null,
                                    LessStrings.join(executeReallocationAssignments(assignments, false).toArray(), "\n"));
    }

    
    public List<JobTaskMoveAssignment> executeReallocationAssignments(List<JobTaskMoveAssignment> assignments, boolean limitToAvailableSlots) {
        List<JobTaskMoveAssignment> executedAssignments = new ArrayList<>();
        if (assignments == null) {
            return executedAssignments;
        }
        HashSet<String> jobsNeedingUpdate = new HashSet<>();
        HashSet<String> hostsAlreadyMovingTasks = new HashSet<>();
        for (JobTaskMoveAssignment assignment : assignments) {
            if (assignment.delete()) {
                log.warn("[job.reallocate] deleting " + assignment.getJobKey() + " off " + assignment.getSourceUUID());
                deleteTask(assignment.getJobKey().getJobUuid(), assignment.getSourceUUID(), assignment.getJobKey().getNodeNumber(), false);
                deleteTask(assignment.getJobKey().getJobUuid(), assignment.getSourceUUID(), assignment.getJobKey().getNodeNumber(), true);
                executedAssignments.add(assignment);
            } else {
                String sourceHostID = assignment.getSourceUUID();
                String targetHostID = assignment.getTargetUUID();
                HostState targetHost = hostManager.getHostState(targetHostID);
                if (sourceHostID == null || targetHostID == null || sourceHostID.equals(targetHostID) || targetHost == null) {
                    log.warn("[job.reallocate] received invalid host assignment: from " + sourceHostID + " to " + targetHostID);
                    continue;
                }
                JobKey key = assignment.getJobKey();
                JobTask task = getTask(key);
                Job job = getJob(key);
                if (job == null || task == null) {
                    log.warn("[job.reallocate] invalid job or task");
                    
                }
                else {
                    HostState liveHost = hostManager.getHostState(task.getHostUUID());
                    if (limitToAvailableSlots && liveHost != null && (liveHost.getAvailableTaskSlots() == 0 || hostsAlreadyMovingTasks.contains(task.getHostUUID()))) {
                        continue;
                    }
                    log.warn("[job.reallocate] replicating task " + key + " onto " + targetHostID + " as " + (assignment.isFromReplica() ? "replica" : "live"));
                    TaskMover tm = new TaskMover(this, hostManager, key, targetHostID, sourceHostID);
                    if (tm.execute()) {
                        hostsAlreadyMovingTasks.add(task.getHostUUID());
                        executedAssignments.add(assignment);
                    }
                }
            }
        }
        for (String jobUUID : jobsNeedingUpdate) {
            try {
                updateJob(getJob(jobUUID));
            } catch (Exception ex) {
                log.warn("WARNING: failed to update job " + jobUUID + ": " + ex, ex);
            }
        }
        return executedAssignments;
    }

    
    public RebalanceOutcome rebalanceJob(String jobUUID, int tasksToMove, String user,
                                         String token, String sudo) throws Exception {
        Job job = getJob(jobUUID);
        if (jobUUID == null || job == null) {
            log.warn("[job.rebalance] job uuid " + jobUUID + " not found");
            return new RebalanceOutcome(jobUUID, "job not found", null, null);
        }
        if (permissionsManager.isExecutable(user, token, sudo, job)) {
            log.warn("[job.rebalance] insufficient priviledges to rebalance " + jobUUID);
            return new RebalanceOutcome(jobUUID, "insufficient priviledges", null, null);
        }
        if (job.getState() != JobState.IDLE && job.getState() != JobState.DEGRADED) {
            log.warn("[job.rebalance] job must be IDLE or DEGRADED to rebalance " + jobUUID);
            return new RebalanceOutcome(jobUUID, "job not idle/degraded", null, null);
        }
        
        if (!rebalanceReplicas(job)) {
            log.warn("[job.rebalance] failed to fill out replica assignments for " + jobUUID);
            return new RebalanceOutcome(jobUUID, "couldn't fill out replicas", null, null);
        }
        try {
            List<JobTaskDirectoryMatch> allMismatches = new ArrayList<>();
            
            for (JobTask task : job.getCopyOfTasks()) {
                List<JobTaskDirectoryMatch> directoryMismatches = matchTaskToDirectories(task, false);
                if (!directoryMismatches.isEmpty()) {
                    
                    resolveJobTaskDirectoryMatches(task, false);
                    allMismatches.addAll(directoryMismatches);
                }
            }
            updateJob(job);
            
            if (!allMismatches.isEmpty()) {
                return new RebalanceOutcome(jobUUID, null, LessStrings.join(allMismatches.toArray(), "\n"), null);
            } else {
                
                return new RebalanceOutcome(jobUUID, null, null, LessStrings.join(
                        reallocateJob(jobUUID, tasksToMove).toArray(), "\n"));
            }
        } catch (Exception ex) {
            log.warn("[job.rebalance] exception during rebalance for " + jobUUID, ex);
            return new RebalanceOutcome(jobUUID, "exception during rebalancing: " + ex, null, null);
        }

    }

    
    public JSONObject fixTaskDir(String jobId, int node, boolean ignoreTaskState, boolean orphansOnly) {
        jobLock.lock();
        try {
            Job job = getJob(jobId);
            int numChanged = 0;
            if (job != null) {
                List<JobTask> tasks = node < 0 ? job.getCopyOfTasks() : Arrays.asList(job.getTask(node));
                for (JobTask task : tasks) {
                    boolean shouldModifyTask = !spawnJobFixer.haveRecentlyFixedTask(task.getJobKey()) &&
                                               (ignoreTaskState
                                                || (task.getState() == JobTaskState.IDLE)
                                                || (!orphansOnly && (task.getState() == JobTaskState.ERROR)));
                    if (log.isDebugEnabled()) {
                        log.debug("[fixTaskDir] considering modifying task " + task.getJobKey() + " shouldModifyTask=" + shouldModifyTask);
                    }
                    if (shouldModifyTask) {
                        try {
                            numChanged += resolveJobTaskDirectoryMatches(task, orphansOnly) ? 1 : 0;
                            spawnJobFixer.markTaskRecentlyFixed(task.getJobKey());
                        } catch (Exception ex) {
                            log.warn("fixTaskDir exception " + ex, ex);
                        }
                    }
                }
            }
            return new JSONObject(ImmutableMap.of("tasksChanged", numChanged));
        } finally {
            jobLock.unlock();
        }

    }

    
    public boolean resolveJobTaskDirectoryMatches(JobTask task, boolean deleteOrphansOnly) {
        Set<String> expectedHostsWithTask = new HashSet<>();
        Set<String> expectedHostsMissingTask = new HashSet<>();
        Set<String> unexpectedHostsWithTask = new HashSet<>();
        for (HostState host : hostManager.listHostStatus(null)) {
            if (hostSuitableForReplica(host)) {
                String hostId = host.getHostUuid();
                if (hostId.equals(task.getHostUUID()) || task.hasReplicaOnHost(hostId)) {
                    if (host.hasLive(task.getJobKey())) {
                        expectedHostsWithTask.add(hostId);
                    } else {
                        expectedHostsMissingTask.add(hostId);
                    }
                } else if (host.hasLive(task.getJobKey()) || host.hasIncompleteReplica(task.getJobKey())) {
                    unexpectedHostsWithTask.add(hostId);
                }
            }
        }
        log.trace("fixTaskDirs found expectedWithTask {} expectedMissingTask {} unexpectedWithTask {} ",
                  expectedHostsWithTask, expectedHostsMissingTask, unexpectedHostsWithTask);
        if (deleteOrphansOnly) {
            
            expectedHostsMissingTask = new HashSet<>();
        }
        return performTaskFixes(task, expectedHostsWithTask, expectedHostsMissingTask, unexpectedHostsWithTask);
    }

    private boolean performTaskFixes(JobTask task, Set<String> expectedHostsWithTask, Set<String> expectedHostsMissingTask, Set<String> unexpectedHostsWithTask) {
        if (expectedHostsWithTask.isEmpty()) {
            
            if (unexpectedHostsWithTask.isEmpty()) {
                
                log.warn("No copies of {} were found. Recreating it on new hosts. ", task.getJobKey());
                recreateTask(task);
                return true;
            }
            
            Iterator<String> unexpectedHostsIter = unexpectedHostsWithTask.iterator();
            List<JobTaskReplica> newReplicas = new ArrayList<>();
            task.setHostUUID(unexpectedHostsIter.next());
            while (unexpectedHostsIter.hasNext()) {
                newReplicas.add(new JobTaskReplica(unexpectedHostsIter.next(), task.getJobUUID(), 0, 0));
            }
            task.setReplicas(newReplicas);
            return true;
        } else {
            
            boolean changed = false;
            if (!expectedHostsMissingTask.isEmpty()) {
                swapTask(task, expectedHostsWithTask.iterator().next(), false);
                copyTaskToReplicas(task);
                changed = true;
            }
            for (String unexpectedHost : unexpectedHostsWithTask) {
                deleteTask(task.getJobUUID(), unexpectedHost, task.getTaskID(), false);
            }
            return changed;
        }
    }

    private static boolean hostSuitableForReplica(HostState host) {
        return host != null && host.isUp() && !host.isDead();
    }

    private void copyTaskToReplicas(JobTask task) {
        sendControlMessage(new CommandTaskReplicate(task.getHostUUID(), task.getJobUUID(), task.getTaskID(), getTaskReplicaTargets(task, task.getReplicas()), null, null, false, false));
    }

    private void recreateTask(JobTask task) {
        Job job = getJob(task.getJobUUID());
        Map<JobTask, String> assignmentMap = balancer.assignTasksFromMultipleJobsToHosts(Arrays.asList(task), getOrCreateHostStateList(job.getMinionType(), null));
        if (assignmentMap != null && assignmentMap.containsKey(task)) {
            String newHostUUID = assignmentMap.get(task);
            log.warn("[job.rebalance] assigning new host for " + task.getJobUUID() + ":" + task.getTaskID() + " all data on previous host will be lost");
            task.setHostUUID(newHostUUID);
            task.resetTaskMetrics();
        } else {
            log.warn("[job.rebalance] unable to assign new host for " + task.getJobUUID() + ":" + task.getTaskID() + " could not find suitable host");
        }
    }

    public JSONArray checkTaskDirJSON(String jobId, int node) {
        JSONArray resultList = new JSONArray();
        jobLock.lock();
        try {
            Job job = getJob(jobId);
            if (job == null) {
                return resultList;
            }
            List<JobTask> tasks = node < 0 ? new ArrayList<>(job.getCopyOfTasksSorted()) : Arrays.asList(job.getTask(node));
            for (JobTask task : tasks) {
                List<JobTaskDirectoryMatch> taskMatches = matchTaskToDirectories(task, true);
                for (JobTaskDirectoryMatch taskMatch : taskMatches) {
                    JSONObject jsonObject = CodecJSON.encodeJSON(taskMatch);
                    resultList.put(jsonObject);
                }
            }
        } catch (Exception ex) {
            log.warn("Error: checking dirs for job: " + jobId + ", node: " + node);
        } finally {
            jobLock.unlock();
        }
        return resultList;
    }

    public List<JobTaskDirectoryMatch> matchTaskToDirectories(JobTask task, boolean includeCorrect) {
        List<JobTaskDirectoryMatch> rv = new ArrayList<>();
        JobTaskDirectoryMatch match = checkHostForTask(task, task.getHostUUID());
        if (includeCorrect || match.getType() != JobTaskDirectoryMatch.MatchType.MATCH) {
            rv.add(match);
        }
        if (task.getAllReplicas() != null) {
            for (JobTaskReplica replica : task.getAllReplicas()) {
                match = checkHostForTask(task, replica.getHostUUID());
                if (match.getType() != JobTaskDirectoryMatch.MatchType.MATCH) {
                    if (task.getState() == JobTaskState.REPLICATE || task.getState() == JobTaskState.FULL_REPLICATE) {
                        
                        rv.add(new JobTaskDirectoryMatch(JobTaskDirectoryMatch.MatchType.REPLICATE_IN_PROGRESS, match.getJobKey(), match.getHostId()));
                    } else {
                        rv.add(match);
                    }
                }
                else if (includeCorrect) {
                    rv.add(match);
                }
            }
        }
        rv.addAll(findOrphansForTask(task));
        return rv;
    }

    private JobTaskDirectoryMatch checkHostForTask(JobTask task, String hostID) {
        JobTaskDirectoryMatch.MatchType type;
        HostState host = hostManager.getHostState(hostID);
        if (host == null || !host.hasLive(task.getJobKey())) {
            type = JobTaskDirectoryMatch.MatchType.MISMATCH_MISSING_LIVE;
        } else {
            type = JobTaskDirectoryMatch.MatchType.MATCH;
        }
        return new JobTaskDirectoryMatch(type, task.getJobKey(), hostID);
    }

    private List<JobTaskDirectoryMatch> findOrphansForTask(JobTask task) {
        List<JobTaskDirectoryMatch> rv = new ArrayList<>();
        Job job = getJob(task.getJobUUID());
        if (job == null) {
            log.warn("got find orphans request for missing job " + task.getJobUUID());
            return rv;
        }
        Set<String> expectedTaskHosts = task.getAllTaskHosts();
        for (HostState host : hostManager.listHostStatus(job.getMinionType())) {
            if (host == null || !host.isUp() || host.isDead() || host.getHostUuid().equals(task.getRebalanceTarget())) {
                continue;
            }
            if (!expectedTaskHosts.contains(host.getHostUuid())) {
                JobTaskDirectoryMatch.MatchType type = null;
                if (host.hasLive(task.getJobKey()) || host.hasIncompleteReplica(task.getJobKey())) {
                    type = JobTaskDirectoryMatch.MatchType.ORPHAN_LIVE;
                }
                if (type != null) {
                    rv.add(new JobTaskDirectoryMatch(type, task.getJobKey(), host.getHostUuid()));
                }
            }
        }
        return rv;
    }

    public boolean checkStatusForMove(String hostID) {
        HostState host = hostManager.getHostState(hostID);
        if (host == null) {
            log.warn("[host.status] received null host for id " + hostID);
            return false;
        }
        if (host.isDead() || !host.isUp()) {
            log.warn("[host.status] host is down: " + hostID);
            return false;
        }
        return true;
    }

    public boolean prepareTaskStatesForRebalance(Job job, JobTask task, boolean isMigration) {
        jobLock.lock();
        try {
            if (!balancer.isInMovableState(task)) {
                log.warn("[task.mover] decided not to move non-idle task " + task);
                return false;
            }
            JobTaskState newState = isMigration ? JobTaskState.MIGRATING : JobTaskState.REBALANCE;
            job.setTaskState(task, newState, true);
            queueJobTaskUpdateEvent(job);
            return true;
        } finally {
            jobLock.unlock();
        }
    }

    
    public boolean rebalanceReplicas(Job job) throws Exception {
        return rebalanceReplicas(job, -1);
    }

    
    public boolean rebalanceReplicas(Job job, int taskID) throws Exception {
        if (job == null) {
            return false;
        }
        
        balancer.removeInvalidReplicas(job);
        
        Map<Integer, List<String>> replicaAssignments = balancer.getAssignmentsForNewReplicas(job, taskID);
        List<JobTask> tasks = taskID > 0 ? Arrays.asList(job.getTask(taskID)) : job.getCopyOfTasks();
        for (JobTask task : tasks) {
            List<String> replicasToAdd = replicaAssignments.get(task.getTaskID());
            
            task.setReplicas(addReplicasAndRemoveExcess(task, replicasToAdd, job.getReplicas(), task.getReplicas()));
        }
        return validateReplicas(job);
    }

    
    private boolean validateReplicas(Job job) {
        for (JobTask task : job.getCopyOfTasks()) {
            List<JobTaskReplica> replicas = task.getReplicas();
            if (job.getReplicas() > 0) {
                if ((replicas == null) || (replicas.size() < job.getReplicas())) {
                    HostState currHost = hostManager.getHostState(task.getHostUUID());
                    
                    if (((currHost == null) || currHost.isDead())
                        && ((replicas == null) || replicas.isEmpty())) {
                        job.setState(JobState.DEGRADED);
                    } else {
                        job.setState(JobState.ERROR); 
                        job.setEnabled(false);
                    }
                    log.warn("[replica.add] ERROR - unable to replicate task because there are not enough suitable hosts, job: " + job.getId());
                    return false;
                }
            }
        }
        return true;
    }

    private List<JobTaskReplica> addReplicasAndRemoveExcess(JobTask task,
                                                            List<String> replicaHostsToAdd,
                                                            int desiredNumberOfReplicas,
                                                            List<JobTaskReplica> currentReplicas) throws Exception {
        List<JobTaskReplica> newReplicas;
        if (currentReplicas == null) {
            newReplicas = new ArrayList<>();
        } else {
            newReplicas = new ArrayList<>(currentReplicas);
        }
        if (replicaHostsToAdd != null) {
            newReplicas.addAll(replicateTask(task, replicaHostsToAdd));
        }
        if (!isNewTask(task)) {
            while (newReplicas.size() > desiredNumberOfReplicas) {
                JobTaskReplica replica = newReplicas.remove(newReplicas.size() - 1);
                spawnMQ.sendControlMessage(new CommandTaskDelete(replica.getHostUUID(), task.getJobUUID(), task.getTaskID(), task.getRunCount()));
                log.info("[replica.delete] " + task.getJobUUID() + "/" + task.getTaskID() + " from " + replica
                        .getHostUUID() + " @ " +
                         hostManager.getHostState(replica.getHostUUID()).getHost());
            }
        }
        return newReplicas;
    }

    protected List<JobTaskReplica> replicateTask(JobTask task, List<String> targetHosts) {
        List<JobTaskReplica> newReplicas = new ArrayList<>();
        for (String targetHostUUID : targetHosts) {
            JobTaskReplica replica = new JobTaskReplica();
            replica.setHostUUID(targetHostUUID);
            replica.setJobUUID(task.getJobUUID());
            newReplicas.add(replica);
        }
        Job job = getJob(task.getJobUUID());
        JobCommand jobcmd = getJobCommandManager().getEntity(job.getCommand());
        String command = (jobcmd != null && jobcmd.getCommand() != null) ? LessStrings.join(jobcmd.getCommand(), " ") : null;
        spawnMQ.sendControlMessage(new CommandTaskReplicate(task.getHostUUID(), task.getJobUUID(), task.getTaskID(), getTaskReplicaTargets(task, newReplicas), command, null, false, false));
        log.info("[replica.add] " + task.getJobUUID() + "/" + task.getTaskID() + " to " + targetHosts);
        taskQueuesByPriority.markHostTaskActive(task.getHostUUID());
        return newReplicas;
    }


    private void updateJobDependencies(String jobId) {
        DirectedGraph<String> dependencies = spawnState.jobDependencies;
        Set<String> sources = dependencies.getSourceEdges(jobId);
        if (sources != null) {
            for (String source : sources) {
                dependencies.removeEdge(source, jobId);
            }
        } else {
            dependencies.addNode(jobId);
        }
        Set<String> newSources = this.getDataSources(jobId);
        if (newSources != null) {
            for (String source : newSources) {
                dependencies.addEdge(source, jobId);
            }
        }
    }

    
    public void submitConfigUpdate(String jobId, String user, String commitMessage) {
        Job job;
        if (jobId == null || jobId.isEmpty() || (job = getJob(jobId)) == null) {
            return;
        }
        if (jobStore != null) {
            jobStore.submitConfigUpdate(job.getId(), user, getJobConfig(jobId), commitMessage);
        }
    }

    public void updateJob(IJob ijob) throws Exception {
        updateJob(ijob, true);
    }

    
    public void updateJob(IJob ijob, boolean reviseReplicas) throws Exception {
        Job job = new Job(ijob);
        jobLock.lock();
        try {
            checkArgument(getJob(job.getId()) != null, "job " + job.getId() + " does not exist");
            updateJobDependencies(job.getId());
            Job oldjob = putJobInSpawnState(job);
            
            if (oldjob != job && reviseReplicas) {
                int oldReplicaCount = oldjob.getReplicas();
                int newReplicaCount = job.getReplicas();
                checkArgument(oldReplicaCount == newReplicaCount || job.getState() == JobState.IDLE ||
                              job.getState() == JobState.DEGRADED, "job must be IDLE or DEGRADED to change replicas");
                checkArgument(newReplicaCount < hostManager.monitored.size(), "replication factor must be < # live hosts");
                rebalanceReplicas(job);
            }
            queueJobTaskUpdateEvent(job);
        } finally {
            jobLock.unlock();
        }
    }

    public DeleteStatus deleteJob(String jobUUID) throws Exception {
        jobLock.lock();
        try {
            Job job = getJob(jobUUID);
            if (job == null) {
                return DeleteStatus.JOB_MISSING;
            }
            if (job.getDontDeleteMe()) {
                return DeleteStatus.JOB_DO_NOT_DELETE;
            }
            spawnState.jobs.remove(jobUUID);
            spawnState.jobDependencies.removeNode(jobUUID);
            log.warn("[job.delete] {}", job.getId());
            if (spawnMQ != null) {
                spawnMQ.sendControlMessage(
                        new CommandTaskDelete(HostMessage.ALL_HOSTS, job.getId(), null, job.getRunCount()));
            }
            sendJobUpdateEvent("job.delete", job);
            jobConfigManager.deleteJob(job.getId());
            if (jobStore != null) {
                jobStore.delete(jobUUID);
            }
            Job.logJobEvent(job, JobEvent.DELETE, eventLog);
        } finally {
            jobLock.unlock();
        }
        jobAlertManager.removeAlertsForJob(jobUUID);
        return DeleteStatus.SUCCESS;
    }

    public void sendControlMessage(HostMessage hostMessage) {
        spawnMQ.sendControlMessage(hostMessage);
    }

    
    public boolean deleteTask(String jobUUID, String hostUuid, Integer node, boolean isReplica) {
        jobLock.lock();
        try {
            if (jobUUID == null || node == null) {
                return false;
            }
            log.warn("[job.delete.host] " + hostUuid + "/" + jobUUID + " >> " + node);
            spawnMQ.sendControlMessage(new CommandTaskDelete(hostUuid, jobUUID, node, 0));
            Job job = getJob(jobUUID);
            if (isReplica && job != null) {
                JobTask task = job.getTask(node);
                task.setReplicas(removeReplicasForHost(hostUuid, task.getReplicas()));
                queueJobTaskUpdateEvent(job);
            }
            return true;
        } finally {
            jobLock.unlock();
        }
    }

    private static List<JobTaskReplica> removeReplicasForHost(String hostUuid, List<JobTaskReplica> currentReplicas) {
        if (currentReplicas == null || currentReplicas.size() == 0) {
            return new ArrayList<>();
        }
        List<JobTaskReplica> replicasCopy = new ArrayList<>(currentReplicas);
        Iterator<JobTaskReplica> iterator = replicasCopy.iterator();
        while (iterator.hasNext()) {
            JobTaskReplica replica = iterator.next();
            if (replica.getHostUUID().equals(hostUuid)) {
                iterator.remove();
            }
        }
        return replicasCopy;
    }

    
    public void startJob(String jobUUID, int priority) throws Exception {
        Job job = getJob(jobUUID);
        checkArgument(job != null, "job not found");
        checkArgument(job.isEnabled(), "job disabled");
        checkArgument(scheduleJob(job, priority), "unable to schedule job");
        queueJobTaskUpdateEvent(job);
        Job.logJobEvent(job, JobEvent.START, eventLog);
    }

    public String expandJob(String jobUUID) throws Exception {
        Job job = getJob(jobUUID);
        checkArgument(job != null, "job not found");
        return expandJob(job);
    }

    public String expandJob(Job job) throws TokenReplacerOverflowException {
        return expandJob(job.getId(), job.getParameters(), getJobConfig(job.getId()));
    }

    public String expandJob(String id, Collection<JobParameter> parameters, String rawConfig)
            throws TokenReplacerOverflowException {
        
        String pass0 = JobExpand.macroExpand(this, rawConfig);
        
        String pass1 = JobExpand.macroTemplateParams(pass0, parameters);
        
        String pass2 = JobExpand.macroExpand(this, pass1);
        
        String pass3 = JobExpand.macroTemplateParams(pass2, parameters);
        
        return JobExpand.magicMacroExpand(this, pass3, id);
    }

    public void stopJob(String jobUUID) throws Exception {
        Job job = getJob(jobUUID);
        checkArgument(job != null, "job not found");
        for (JobTask task : job.getCopyOfTasks()) {
            if (task.getState() == JobTaskState.QUEUED) {
                removeFromQueue(task);
            }
            stopTask(jobUUID, task.getTaskID());
        }
        Job.logJobEvent(job, JobEvent.STOP, eventLog);
    }

    public void killJob(String jobUUID) throws Exception {
        boolean success = false;
        while (!success & !shuttingDown.get()) {
            try {
                jobLock.lock();
                if (taskQueuesByPriority.tryLock()) {
                    success = true;
                    Job job = getJob(jobUUID);
                    Job.logJobEvent(job, JobEvent.KILL, eventLog);
                    checkArgument(job != null, "job not found");
                    for (JobTask task : job.getCopyOfTasks()) {
                        if (task.getState() == JobTaskState.QUEUED) {
                            removeFromQueue(task);
                        }
                        killTask(jobUUID, task.getTaskID());
                    }
                }
            } finally {
                jobLock.unlock();
                if (success) {
                    taskQueuesByPriority.unlock();
                }
            }
        }
    }

    
    public JobTask getTask(String jobUUID, int taskID) {
        Job job = getJob(jobUUID);
        if (job != null) {
            return job.getTask(taskID);
        }
        return null;
    }

    public JobTask getTask(JobKey jobKey) {
        if (jobKey == null || jobKey.getJobUuid() == null || jobKey.getNodeNumber() == null) {
            return null;
        }
        return getTask(jobKey.getJobUuid(), jobKey.getNodeNumber());
    }

    
    public void startTask(String jobUUID, int taskID, boolean addToQueue, int priority, boolean toQueueHead) throws Exception {
        Job job = getJob(jobUUID);
        checkArgument(job != null, "job not found");
        checkArgument(job.isEnabled(), "job is disabled");
        checkArgument(job.getState() != JobState.DEGRADED, "job in degraded state");
        checkArgument(taskID >= 0, "invalid task id");
        JobTask task = getTask(jobUUID, taskID);
        checkArgument(task != null, "no such task");
        checkArgument(task.getState() != JobTaskState.BUSY && task.getState() != JobTaskState.ALLOCATED &&
                      task.getState() != JobTaskState.QUEUED, "invalid task state");
        if (addToQueue) {
            addToTaskQueue(task.getJobKey(), priority, toQueueHead);
        } else {
            kickIncludingQueue(job, task, expandJob(job), false, priority);
        }
        log.warn("[task.kick] started " + job.getId() + " / " + task.getTaskID() + " = " + job.getDescription());
        queueJobTaskUpdateEvent(job);
    }

    public void stopTask(String jobUUID, int taskID) throws Exception {
        stopTask(jobUUID, taskID, false, false);
    }

    private void stopTask(String jobUUID, int taskID, boolean force, boolean onlyIfQueued) throws Exception {
        Job job = getJob(jobUUID);
        JobTask task = getTask(jobUUID, taskID);
        if (job != null && task != null) {
            taskQueuesByPriority.setStoppedJob(true); 
            HostState host = hostManager.getHostState(task.getHostUUID());
            if (force) {
                task.setRebalanceSource(null);
                task.setRebalanceTarget(null);
            }
            if (task.getState().isQueuedState()) {
                removeFromQueue(task);
                log.warn("[task.stop] stopping queued " + task.getJobKey());
            } else if (task.getState() == JobTaskState.REBALANCE) {
                log.warn("[task.stop] stopping rebalancing " + task.getJobKey() + " with force=" + force);
            } else if (task.getState() == JobTaskState.MIGRATING ) {
                log.warn("[task.stop] stopping migrating " + task.getJobKey());
                task.setRebalanceSource(null);
                task.setRebalanceTarget(null);
            }
            else if (force && (task.getState() == JobTaskState.REVERT)) {
                log.warn("[task.stop] " + task.getJobKey() + " killed in revert state");
                int code  = JobTaskErrorCode.EXIT_REVERT_FAILURE;
                job.errorTask(task, code);
                queueJobTaskUpdateEvent(job);
            } else if (force && (host == null || host.isDead() || !host.isUp())) {
                log.warn("[task.stop] " + task.getJobKey() + " killed on down host");
                job.setTaskState(task, JobTaskState.IDLE);
                queueJobTaskUpdateEvent(job);
                return;
            } else if (host != null && !host.hasLive(task.getJobKey())) {
                log.warn("[task.stop] node that minion doesn't think is running: " + task.getJobKey());
                job.setTaskState(task, JobTaskState.IDLE);
                queueJobTaskUpdateEvent(job);
            }
            else if (task.getState() == JobTaskState.ALLOCATED) {
                log.warn("[task.stop] node in allocated state " + jobUUID + "/" + taskID + " host = " + (host != null ? host.getHost() : "unknown"));
            }

            
            if (host != null) {
                spawnMQ.sendControlMessage(new CommandTaskStop(host.getHostUuid(), jobUUID, taskID, job.getRunCount(), force, onlyIfQueued));
            } else {
                log.warn("[task.stop]" + jobUUID + "/" + taskID + "]: no host monitored for uuid " + task.getHostUUID());
            }
        } else {
            log.warn("[task.stop] job/task {}/{} not found", jobUUID, taskID);
        }
    }

    protected boolean removeFromQueue(JobTask task) {
        boolean removed = false;
        Job job = getJob(task.getJobUUID());
        if (job != null) {
            log.warn("[taskQueuesByPriority] setting " + task.getJobKey() + " as idle and removing from queue");
            job.setTaskState(task, JobTaskState.IDLE, true);
            removed = taskQueuesByPriority.remove(job.getPriority(), task.getJobKey());
            queueJobTaskUpdateEvent(job);
            sendTaskQueueUpdateEvent();
        }
        writeSpawnQueue();
        return removed;

    }

    public void killTask(String jobUUID, int taskID) throws Exception {
        stopTask(jobUUID, taskID, true, false);
    }

    public boolean moveTask(JobKey jobKey, String sourceUUID, String targetUUID) {
        TaskMover tm = new TaskMover(this, hostManager, jobKey, targetUUID, sourceUUID);
        log.info("[task.move] attempting move for " + jobKey);
        return tm.execute();
    }

    public boolean revertJobOrTask(String jobUUID,
                                String user,
                                String token,
                                String sudo,
                                int taskID,
                                String backupType,
                                int rev,
                                long time) throws Exception {
        Job job = getJob(jobUUID);
        if (job == null) {
            return true;
        }
        if (!permissionsManager.isExecutable(user, token, sudo, job)) {
            return false;
        }
        if (taskID == -1) {
            
            Job.logJobEvent(job, JobEvent.REVERT, eventLog);
            int numTasks = job.getTaskCount();
            for (int i = 0; i < numTasks; i++) {
                log.warn("[task.revert] " + jobUUID + "/" + i);
                revert(jobUUID, backupType, rev, time, i);
            }
        } else {
            
            log.warn("[task.revert] " + jobUUID + "/" + taskID);
            revert(jobUUID, backupType, rev, time, taskID);
        }
        return true;
    }

    private void revert(String jobUUID, String backupType, int rev, long time, int taskID) throws Exception {
        JobTask task = getTask(jobUUID, taskID);
        if (task != null) {
            task.setPreFailErrorCode(0);
            HostState host = hostManager.getHostState(task.getHostUUID());
            if (task.getState() == JobTaskState.ALLOCATED || task.getState().isQueuedState()) {
                log.warn("[task.revert] node in allocated state " + jobUUID + "/" + task.getTaskID() + " host = " + host.getHost());
            }
            log.warn("[task.revert] sending revert message to host: " + host.getHost() + "/" + host.getHostUuid());
            spawnMQ.sendControlMessage(new CommandTaskRevert(host.getHostUuid(), jobUUID, task.getTaskID(), backupType, rev, time, getTaskReplicaTargets(task, task.getAllReplicas()), false));
        } else {
            log.warn("[task.revert] task " + jobUUID + "/" + taskID + "] not found");
        }

    }


    

    private List<HostState> getOrCreateHostStateList(String minionType, Collection<String> hostList) {
        List<HostState> hostStateList;
        if (hostList == null || hostList.size() == 0) {
            hostStateList = balancer.sortHostsByActiveTasks(hostManager.listHostStatus(minionType));
        } else {
            hostStateList = new ArrayList<>();
            for (String hostId : hostList) {
                hostStateList.add(hostManager.getHostState(hostId));
            }
        }
        return hostStateList;
    }


    
    protected void handleMessage(CoreMessage core) {
        Job job;
        JobTask task;
        if (hostManager.deadMinionMembers.getMemberSet().contains(core.getHostUuid())) {
            log.warn("[mq.core] ignoring message from host: " + core.getHostUuid() + " because it is dead");
            return;
        }
        if (core instanceof HostState) {
            Set<String> upMinions = hostManager.minionMembers.getMemberSet();
            HostState state = (HostState) core;
            HostState oldState = hostManager.getHostState(state.getHostUuid());
            if (oldState == null) {
                log.warn("[host.status] from unmonitored " + state.getHostUuid() + " = " + state.getHost() + ":" + state.getPort());
                taskQueuesByPriority.updateHostAvailSlots(state);
            }
            boolean hostEnabled = true;
            if (spawnState.disabledHosts.contains(state.getHost()) ||
                spawnState.disabledHosts.contains(state.getHostUuid())) {
                hostEnabled = false;
                state.setDisabled(true);
            } else {
                state.setDisabled(false);
            }
            
            if (upMinions.contains(state.getHostUuid()) && hostEnabled) {
                state.setUp(true);
            }
            state.setUpdated();
            sendHostUpdateEvent(state);
            hostManager.updateHostState(state);
        } else if (core instanceof StatusTaskBegin) {
            StatusTaskBegin begin = (StatusTaskBegin) core;
            SpawnMetrics.tasksStartedPerHour.mark();
            if (systemManager.debug("-begin-")) {
                log.info("[task.begin] :: " + begin.getJobKey());
            }
            try {
                job = getJob(begin.getJobUuid());
                if (job == null) {
                    log.warn("[task.begin] on dead job " + begin.getJobKey() + " from " + begin.getHostUuid());
                } else {
                    if (job.getStartTime() == null) {
                        job.setStartTime(System.currentTimeMillis());
                    }
                    task = job.getTask(begin.getNodeID());
                    if (checkTaskMessage(task, begin.getHostUuid())) {
                        if (task != null) {
                            job.setTaskState(task, JobTaskState.BUSY);
                            task.incrementStarts();
                            queueJobTaskUpdateEvent(job);
                        } else {
                            log.warn("[task.begin] done report for missing node " + begin.getJobKey());
                        }
                    }
                }
            } catch (Exception ex) {
                log.warn("", ex);
            }
        } else if (core instanceof StatusTaskCantBegin) {
            StatusTaskCantBegin cantBegin = (StatusTaskCantBegin) core;
            log.info("[task.cantbegin] received cantbegin from " + cantBegin.getHostUuid() + " for task " + cantBegin.getJobUuid() + "," + cantBegin.getNodeID());
            job = getJob(cantBegin.getJobUuid());
            task = getTask(cantBegin.getJobUuid(), cantBegin.getNodeID());
            if (job != null && task != null) {
                if (checkTaskMessage(task, cantBegin.getHostUuid())) {
                    try {
                        job.setTaskState(task, JobTaskState.IDLE);
                        log.info("[task.cantbegin] kicking " + task.getJobKey());
                        startTask(cantBegin.getJobUuid(), cantBegin.getNodeID(), true, 1, true);
                    } catch (Exception ex) {
                        log.warn("[task.schedule] failed to reschedule task for " + task.getJobKey(), ex);
                    }
                }
            } else {
                log.warn("[task.cantbegin] received cantbegin from " + cantBegin.getHostUuid() + " for nonexistent job " + cantBegin.getJobUuid());
            }
        } else if (core instanceof StatusTaskPort) {
            StatusTaskPort port = (StatusTaskPort) core;
            job = getJob(port.getJobUuid());
            task = getTask(port.getJobUuid(), port.getNodeID());
            if (task != null) {
                log.info("[task.port] " + job.getId() + "/" + task.getTaskID() + " @ " + port.getPort());
                task.setPort(port.getPort());
                queueJobTaskUpdateEvent(job);
            }
        } else if (core instanceof StatusTaskBackup) {
            StatusTaskBackup backup = (StatusTaskBackup) core;
            job = getJob(backup.getJobUuid());
            task = getTask(backup.getJobUuid(), backup.getNodeID());
            if (task != null && task.getState() != JobTaskState.REBALANCE && task.getState() != JobTaskState.MIGRATING) {
                log.info("[task.backup] " + job.getId() + "/" + task.getTaskID());
                job.setTaskState(task, JobTaskState.BACKUP);
                queueJobTaskUpdateEvent(job);
            }
        } else if (core instanceof StatusTaskReplicate) {
            StatusTaskReplicate replicate = (StatusTaskReplicate) core;
            job = getJob(replicate.getJobUuid());
            task = getTask(replicate.getJobUuid(), replicate.getNodeID());
            if (task != null) {
                if (checkTaskMessage(task, replicate.getHostUuid())) {
                    log.info("[task.replicate] " + job.getId() + "/" + task.getTaskID());
                    JobTaskState taskState = task.getState();
                    if (taskState != JobTaskState.REBALANCE && taskState != JobTaskState.MIGRATING) {
                        job.setTaskState(task, replicate.isFullReplication() ? JobTaskState.FULL_REPLICATE : JobTaskState.REPLICATE, true);
                    }
                    queueJobTaskUpdateEvent(job);
                }
            }
        } else if (core instanceof StatusTaskRevert) {
            StatusTaskRevert revert = (StatusTaskRevert) core;
            job = getJob(revert.getJobUuid());
            task = getTask(revert.getJobUuid(), revert.getNodeID());
            if (task != null) {
                if (checkTaskMessage(task, revert.getHostUuid())) {
                    log.info("[task.revert] " + job.getId() + "/" + task.getTaskID());
                    job.setTaskState(task, JobTaskState.REVERT, true);
                    queueJobTaskUpdateEvent(job);
                }
            }
        } else if (core instanceof StatusTaskReplica) {
            StatusTaskReplica replica = (StatusTaskReplica) core;
            job = getJob(replica.getJobUuid());
            task = getTask(replica.getJobUuid(), replica.getNodeID());
            if (task != null) {
                if (task.getReplicas() != null) {
                    for (JobTaskReplica taskReplica : task.getReplicas()) {
                        if (taskReplica.getHostUUID().equals(replica.getHostUuid())) {
                            taskReplica.setVersion(replica.getVersion());
                            taskReplica.setLastUpdate(replica.getUpdateTime());
                        }
                    }
                    log.info("[task.replica] version updated for " + job.getId() + "/" + task.getTaskID() + " ver " + task.getRunCount() + "/" + replica.getVersion());
                    queueJobTaskUpdateEvent(job);
                }
            }
        } else if (core instanceof StatusTaskEnd) {
            StatusTaskEnd end = (StatusTaskEnd) core;
            log.info("[task.end] :: " + end.getJobUuid() + "/" + end.getNodeID() + " exit=" + end.getExitCode());
            SpawnMetrics.tasksCompletedPerHour.mark();
            try {
                job = getJob(end.getJobUuid());
                if (job == null) {
                    log.warn("[task.end] on dead job " + end.getJobKey() + " from " + end.getHostUuid());
                } else {
                    task = job.getTask(end.getNodeID());
                    if (checkTaskMessage(task, end.getHostUuid())) {
                        if (task.isRunning()) {
                            taskQueuesByPriority.incrementHostAvailableSlots(end.getHostUuid());
                        }
                        handleStatusTaskEnd(job, task, end);
                    }
                }
            } catch (Exception ex) {
                log.warn("Failed to handle end message: " + ex, ex);
            }
        } else {
            log.warn("[mq.core] unhandled type = " + core.getClass().toString());
        }
    }

    
    private static boolean checkTaskMessage(JobTask task, String messageSourceUuid) {
        if (task == null || messageSourceUuid == null || !messageSourceUuid.equals(task.getHostUUID())) {
            log.warn("Ignoring task state message from non-live host {}", messageSourceUuid);
            SpawnMetrics.nonHostTaskMessageCounter.inc();
            return false;
        }
        return true;
    }

    
    private void handleStatusTaskEnd(Job job, JobTask task, StatusTaskEnd update) {
        TaskExitState exitState = update.getExitState();
        boolean wasStopped = exitState != null && exitState.getWasStopped();
        task.setFileCount(update.getFileCount());
        task.setByteCount(update.getByteCount());
        boolean errored = update.getExitCode() != 0 && update.getExitCode() != JobTaskErrorCode.REBALANCE_PAUSE;
        if (update.getRebalanceSource() != null) {
            handleRebalanceFinish(job, task, update);
        } else {
            if (exitState != null) {
                task.setInput(exitState.getInput());
                task.setMeanRate(exitState.getMeanRate());
                task.setTotalEmitted(exitState.getTotalEmitted());
            }
            task.setWasStopped(wasStopped);
        }
        if (errored) {
            handleTaskError(job, task, update.getExitCode());
        } else if (!update.wasQueued()) {
            job.setTaskFinished(task);
        }
        if (job.isFinished() && update.getRebalanceSource() == null) {
            finishJob(job, errored);
        }
        queueJobTaskUpdateEvent(job);
    }

    public void handleTaskError(Job job, JobTask task, int exitCode) {
        log.warn("[task.end] " + task.getJobKey() + " exited abnormally with " + exitCode);
        task.incrementErrors();
        try {
            spawnJobFixer.fixTask(job, task, exitCode);
        } catch (Exception ex) {
            job.errorTask(task, exitCode);
        }
    }

    public void handleRebalanceFinish(Job job, JobTask task, StatusTaskEnd update) {
        String rebalanceSource = update.getRebalanceSource();
        String rebalanceTarget = update.getRebalanceTarget();
        if (update.getExitCode() == 0) {
            
            task.setRebalanceSource(null);
            task.setRebalanceTarget(null);
            if (checkHostStatesForSwap(task.getJobKey(), rebalanceSource, rebalanceTarget, false)) {
                if (task.getHostUUID().equals(rebalanceSource)) {
                    task.setHostUUID(rebalanceTarget);
                } else {
                    task.replaceReplica(rebalanceSource, update.getRebalanceTarget());
                }

                deleteTask(job.getId(), rebalanceSource, task.getTaskID(), false);
                if (update.wasQueued()) {
                    addToTaskQueue(task.getJobKey(), 0, false);
                }
            } else {
                
                fixTaskDir(job.getId(), task.getTaskID(), true, true);
            }
        } else if (update.getExitCode() == JobTaskErrorCode.REBALANCE_PAUSE) {
            
            log.warn("[task.move] task rebalance for " + task.getJobKey() + " paused until next run");
        } else {
            
            fixTaskDir(job.getId(), task.getTaskID(), true, true);
        }
    }

    
    private void finishJob(Job job, boolean errored) {
        String callback = errored ? job.getOnErrorURL() : job.getOnCompleteURL();
        log.info("[job.done] {} :: errored={}. callback={}", job.getId(), errored, callback);
        SpawnMetrics.jobsCompletedPerHour.mark();
        job.setFinishTime(System.currentTimeMillis());
        spawnFormattedLogger.finishJob(job);
        if (!systemManager.isQuiesced()) {
            if (job.isEnabled() && !errored) {
                jobOnFinishStateHandler.handle(job, JobOnFinishState.OnComplete);
                if (ENABLE_JOB_FIXDIRS_ONCOMPLETE && job.getRunCount() > 1) {
                    
                    fixTaskDir(job.getId(), -1, false, true);
                }
            } else {
                jobOnFinishStateHandler.handle(job, JobOnFinishState.OnError);
            }
        }
        Job.logJobEvent(job, JobEvent.FINISH, eventLog);
        balancer.requestJobSizeUpdate(job.getId(), 0);
    }

    public JobMacro createJobHostMacro(String job, int port) {
        String sPort = Integer.valueOf(port).toString();
        Set<String> jobHosts = new TreeSet<>();
        jobLock.lock();
        try {
            Collection<HostState> hosts = hostManager.listHostStatus(null);
            Map<String, String> uuid2Host = new HashMap<>();
            for (HostState host : hosts) {
                if (host.isUp()) {
                    uuid2Host.put(host.getHostUuid(), host.getHost());
                }
            }
            if (uuid2Host.size() == 0) {
                log.warn("[createJobHostMacro] warning job was found on no available hosts: " + job);
            }
            IJob ijob = getJob(job);
            if (ijob == null) {
                log.warn("[createJobHostMacro] Unable to get job config for job: " + job);
                throw new RuntimeException("[createJobHostMacro] Unable to get job config for job: " + job);
            }
            for (JobTask task : ijob.getCopyOfTasks()) {
                String host = uuid2Host.get(task.getHostUUID());
                if (host != null) {
                    jobHosts.add(host);
                }
            }
        } finally {
            jobLock.unlock();
        }

        List<String> hostStrings = new ArrayList<>();
        for (String host : jobHosts) {
            hostStrings.add("{host:\"" + host + "\", port:" + sPort + "}");
        }
        return new JobMacro("spawn", "", "createJobHostMacro-" + job, Joiner.on(',').join(hostStrings));
    }

    
    

    
    private void sendJobUpdateEvent(Job job) {
        jobLock.lock();
        try {
            jobConfigManager.updateJob(job);
        } finally {
            jobLock.unlock();
        }
        sendJobUpdateEvent("job.update", job);
    }

    public void queueJobTaskUpdateEvent(Job job) {
        jobLock.lock();
        try {
            jobUpdateQueue.add(job.getId());
        } finally {
            jobLock.unlock();
        }
    }

    private void drainJobTaskUpdateQueue() {
        try {
            long start = System.currentTimeMillis();
            Set<String> jobIds = new HashSet<>();
            jobUpdateQueue.drainTo(jobIds);
            log.trace("[drain] Draining {} jobs from the update queue", jobIds.size());
            for (String jobId : jobIds) {
                try {
                    Job job = getJob(jobId);
                    if (job == null) {
                        log.warn("[drain] Job {} does not exist - it may have been deleted", jobId);
                    } else {
                        sendJobUpdateEvent(job);
                    }
                } catch (Throwable e) {
                    log.error("[drain] Unexpected error when saving job update for {}", jobId, e);
                }
            }
            log.trace("[drain] Finished Draining {} jobs from the update queue in {}ms",
                      jobIds.size(), System.currentTimeMillis() - start);
        } catch (Throwable e) {
            log.error("[drain] Unexpected error when draining job task update queue", e);
        }
    }

    
    public void saveAllJobs() {
        jobLock.lock();
        try {
            for (Job job : listJobs()) {
                if (job != null) {
                    sendJobUpdateEvent(job);
                }
            }
        } finally {
            jobLock.unlock();
        }
    }

    private synchronized void jobTaskUpdateHeartbeatCheck() {
        try {
            String now = Long.toString(System.currentTimeMillis());
            spawnDataStore.put(SpawnDataStoreKeys.SPAWN_JOB_CONFIG_HEARTBEAT_PATH, now);
            String received = spawnDataStore.get(SpawnDataStoreKeys.SPAWN_JOB_CONFIG_HEARTBEAT_PATH);
            if (received != null && received.equals(now)) {
                SpawnMetrics.jobTaskUpdateHeartbeatSuccessMeter.mark();
            } else {
                SpawnMetrics.jobTaskUpdateHeartbeatFailureCounter.inc();
            }
        } catch (Exception e) {
            SpawnMetrics.jobTaskUpdateHeartbeatFailureCounter.inc();
            log.warn("Failed to perform jobtaskupdate heartbeat check", e);
        }

    }

    public void sendJobUpdateEvent(String label, Job job) {
        try {
            sendEventToClientListeners(label, getJobUpdateEvent(job));
        } catch (Exception e) {
            log.warn("", e);
        }
    }

    
    public void sendClusterQuiesceEvent(String username) {
        try {
            JSONObject info = new JSONObject();
            info.put("username", username);
            info.put("date", JitterClock.globalTime());
            info.put("quiesced", systemManager.isQuiesced());
            sendEventToClientListeners("cluster.quiesce", info);
        } catch (Exception e) {
            log.warn("", e);
        }
    }

    
    public void sendTaskQueueUpdateEvent() {
        try {
            int numQueued = 0;
            int numQueuedWaitingOnSlot = 0;
            int numQueuedWaitingOnError = 0;
            taskQueuesByPriority.lock();
            try {
                LinkedList<JobKey>[] queues =
                        taskQueuesByPriority.values().toArray(new LinkedList[taskQueuesByPriority.size()]);

                for (LinkedList<JobKey> queue : queues) {
                    numQueued += queue.size();
                    for (JobKey key : queue) {
                        Job job = getJob(key);
                        if (job != null && !job.isEnabled()) {
                            numQueuedWaitingOnError += 1;
                        } else {
                            JobTask task = job.getTask(key.getNodeNumber());
                            if (task.getState() == JobTaskState.QUEUED_NO_SLOT) {
                                numQueuedWaitingOnSlot += 1;
                            }
                        }
                    }
                }
                lastQueueSize = numQueued;
            } finally {
                taskQueuesByPriority.unlock();
            }
            JSONObject json = new JSONObject("{'size':" + Integer.toString(numQueued) +
                                             ",'sizeErr':" + Integer.toString(numQueuedWaitingOnError) +
                                             ",'sizeSlot':" + Integer.toString(numQueuedWaitingOnSlot) + "}");
            sendEventToClientListeners("task.queue.size", json);
        } catch (Exception e) {
            log.warn("[task.queue.update] received exception while sending task queue update event (this is ok unless" +
                     " it happens repeatedly)", e);
        }
    }

    public int getLastQueueSize() {
        return lastQueueSize;
    }

    public static JSONObject getJobUpdateEvent(IJob job) throws Exception {
        long files = 0;
        long bytes = 0;
        int running = 0;
        int errored = 0;
        int done = 0;
        if (job == null) {
            String errMessage = "getJobUpdateEvent called with null job";
            log.warn(errMessage);
            throw new Exception(errMessage);
        }
        List<JobTask> jobNodes = job.getCopyOfTasks();
        int numNodes = 0;
        if (jobNodes != null) {
            numNodes = jobNodes.size();
            for (JobTask task : jobNodes) {
                files += task.getFileCount();
                bytes += task.getByteCount();
                if (task.getState() != JobTaskState.ALLOCATED && !task.getState().isQueuedState()) {
                    running++;
                }
                switch (task.getState()) {
                    case IDLE:
                        done++;
                        break;
                    case ERROR:
                        done++;
                        errored++;
                        break;
                    default:
                        break;
                }
            }
        }
        JSONObject ojob = job.toJSON().put("config", "").put("parameters", "");
        ojob.put("nodes", numNodes);
        ojob.put("running", running);
        ojob.put("errored", errored);
        ojob.put("done", done);
        ojob.put("files", files);
        ojob.put("bytes", bytes);
        return ojob;
    }

    public void sendHostUpdateEvent(HostState state) {
        sendHostUpdateEvent("host.update", state);
    }

    private void sendHostUpdateEvent(String label, HostState state) {
        try {
            sendEventToClientListeners(label, getHostStateUpdateEvent(state));
        } catch (Exception e) {
            log.warn("", e);
        }
    }

    public JSONObject getHostStateUpdateEvent(HostState state) throws Exception {
        if (state == null) {
            return null;
        }
        JSONObject ohost = CodecJSON.encodeJSON(state);
        ohost.put("spawnState", getSpawnStateString(state));
        ohost.put("stopped", ohost.getJSONArray("stopped").length());
        ohost.put("total", state.countTotalLive());
        double score = 0;
        try {
            score = balancer.getHostScoreCached(state.getHostUuid());
        } catch (NullPointerException npe) {
            log.warn("[host.status] exception in getHostStateUpdateEvent", npe);
        }
        ohost.put("score", score);
        return ohost;
    }

    private String getSpawnStateString(HostState state) {
        if (state.isDead()) {
            return "failed";
        } else if (state.isDisabled()) {
            return "disabled";
        }
        return hostFailWorker.getFailureStateString(state.getHostUuid(), state.isUp());
    }

    
    private void sendEventToClientListeners(final String topic, final JSONObject message) {
        long time = System.currentTimeMillis();
        for (Entry<String, ClientEventListener> ev : listeners.entrySet()) {
            ClientEventListener client = ev.getValue();
            boolean queueTooLarge = clientDropQueueSize > 0 && client.events.size() > clientDropQueueSize;
            
            if (time - client.lastSeen > clientDropTimeMillis || queueTooLarge) {
                ClientEventListener listener = listeners.remove(ev.getKey());
                if (systemManager.debug("-listen-")) {
                    log.warn("[listen] dropping listener queue for " + ev.getKey() + " = " + listener);
                }
                if (queueTooLarge) {
                    SpawnMetrics.nonConsumingClientDropCounter.inc();
                }
                continue;
            }
            try {
                client.events.put(new ClientEvent(topic, message));
            } catch (Exception ex) {
                log.warn("", ex);
            }
        }
        webSocketManager.addEvent(new ClientEvent(topic, message));
    }

    
    @Override public void close() {
        shuttingDown.set(true);
        try {
            expandKickExecutor.shutdown();
            scheduledExecutor.shutdown();
            expandKickExecutor.awaitTermination(120, TimeUnit.SECONDS);
            scheduledExecutor.awaitTermination(120, TimeUnit.SECONDS);
        } catch (Exception ex) {
            log.warn("Exception shutting down background processes", ex);
        }

        try {
            permissionsManager.close();
        } catch (Exception ex) {
            log.warn("Exception closing permissions manager", ex);
        }

        try {
            drainJobTaskUpdateQueue();
        } catch (Exception ex) {
            log.warn("Exception draining job task update queue", ex);
        }

        try {
            spawnFormattedLogger.close();
        } catch (Exception ex) {
            log.warn("", ex);
        }

        try {
            hostManager.minionMembers.shutdown();
            hostManager.deadMinionMembers.shutdown();
        } catch (IOException ex) {
            log.warn("Unable to cleanly shutdown membership listeners", ex);
        }

        jobOnFinishStateHandler.close();

        try {
            closeZkClients();
        } catch (Exception ex) {
            log.warn("Exception closing zk clients", ex);
        }
    }

    protected void autobalance(SpawnBalancer.RebalanceType type, SpawnBalancer.RebalanceWeight weight) {
        executeReallocationAssignments(balancer.getAssignmentsForAutoBalance(type, weight), false);
    }

    private boolean schedulePrep(Job job) {
        JobCommand jobCommand = getJobCommandManager().getEntity(job.getCommand());
        if (jobCommand == null) {
            log.warn("[schedule] failed submit : invalid command {}", job.getCommand());
            return false;
        }
        return job.isEnabled();
    }

    private ReplicaTarget[] getTaskReplicaTargets(JobTask task, List<JobTaskReplica> replicaList) {
        ReplicaTarget[] replicas = null;
        if (replicaList != null) {
            int next = 0;
            replicas = new ReplicaTarget[replicaList.size()];
            for (JobTaskReplica replica : replicaList) {
                HostState host = hostManager.getHostState(replica.getHostUUID());
                if (host == null) {
                    log.warn("[getTaskReplicaTargets] error - replica host: " + replica.getHostUUID() + " does not exist!");
                    throw new RuntimeException("[getTaskReplicaTargets] error - replica host: " + replica.getHostUUID() + " does not exist.  Rebalance the job to correct issue");
                }
                replicas[next++] = new ReplicaTarget(host.getHostUuid(), host.getHost(), host.getUser(), host.getPath());
            }
        }
        return replicas;
    }

    
    private void kickIncludingQueue(Job job, JobTask task, String config, boolean inQueue, int priority) throws Exception {
        boolean success = false;
        while (!success && !shuttingDown.get()) {
            jobLock.lock();
            try {
                if (taskQueuesByPriority.tryLock()) {
                    success = true;
                    boolean kicked = kickOnExistingHosts(job, task, config, 0L, true);
                    if (!kicked && !inQueue) {
                        addToTaskQueue(task.getJobKey(), priority, false);
                    }
                }
            } finally {
                jobLock.unlock();
                if (success) {
                    taskQueuesByPriority.unlock();
                }
            }
        }
    }

    
    boolean scheduleJob(Job job, int priority) throws Exception {
        if (!schedulePrep(job)) {
            return false;
        }
        if (job.getCountActiveTasks() == job.getTaskCount()) {
            return false;
        }
        job.setSubmitTime(JitterClock.globalTime());
        job.setStartTime(null);
        job.setEndTime(null);
        job.incrementRunCount();
        Job.logJobEvent(job, JobEvent.SCHEDULED, eventLog);
        log.info("[job.schedule] assigning " + job.getId() + " with " + job.getCopyOfTasks().size() + " tasks");
        SpawnMetrics.jobsStartedPerHour.mark();
        for (JobTask task : job.getCopyOfTasks()) {
            if (task == null || task.getState() != JobTaskState.IDLE) {
                continue;
            }
            addToTaskQueue(task.getJobKey(), priority, false);
        }
        updateJob(job);
        return true;
    }

    
    CommandTaskKick getCommandTaskKick(Job job, JobTask task) {
        JobCommand jobCmd = getJobCommandManager().getEntity(job.getCommand());
        final String expandedJob;
        try {
            expandedJob = expandJob(job);
        } catch (TokenReplacerOverflowException e) {
            return null;
        }
        CommandTaskKick kick = new CommandTaskKick(
                task.getHostUUID(),
                task.getJobKey(),
                job.getOwner(),
                job.getGroup(),
                job.getPriority(),
                job.getCopyOfTasks().size(),
                job.getMaxRunTime() != null ? job.getMaxRunTime() * 60000 : 0,
                job.getRunCount(),
                expandedJob,
                LessStrings.join(jobCmd.getCommand(), " "),
                job.getHourlyBackups(),
                job.getDailyBackups(),
                job.getWeeklyBackups(),
                job.getMonthlyBackups(),
                getTaskReplicaTargets(task, task.getAllReplicas()),
                job.getAutoRetry(),
                task.getStarts()
                );
        return kick;
    }

    
    public boolean scheduleTask(Job job, JobTask task, String config) {
        if (!schedulePrep(job)) {
            return false;
        }
        if (task.getState() != JobTaskState.IDLE && task.getState() != JobTaskState.ERROR && task.getState() != JobTaskState.QUEUED) {
            return false;
        }
        JobState oldState = job.getState();
        if (!job.setTaskState(task, JobTaskState.ALLOCATED)) {
            return false;
        }
        if (oldState == JobState.IDLE && job.getRunCount() <= task.getRunCount()) {
            log.warn("Somehow a task ({}) was ALLOCATED from an IDLE, not queued or running, job ({})", task, job);
            job.incrementRunCount();
            job.setEndTime(null);
        }
        task.setRunCount(job.getRunCount());
        task.setErrorCode(0);
        task.setPreFailErrorCode(0);
        JobCommand jobcmd = getJobCommandManager().getEntity(job.getCommand());

        if (task.getRebalanceSource() != null && task.getRebalanceTarget() != null) {
            
            if (new TaskMover(this, hostManager, task.getJobKey(), task.getRebalanceTarget(), task.getRebalanceSource()).execute()) {
                return true;
            } else {
                
                task.setRebalanceSource(null);
                task.setRebalanceTarget(null);
            }
        }
        final CommandTaskKick kick = new CommandTaskKick(
                task.getHostUUID(),
                task.getJobKey(),
                job.getOwner(),
                job.getGroup(),
                job.getPriority(),
                job.getCopyOfTasks().size(),
                job.getMaxRunTime() != null ? job.getMaxRunTime() * 60000 : 0,
                job.getRunCount(),
                null,
                LessStrings.join(jobcmd.getCommand(), " "),
                job.getHourlyBackups(),
                job.getDailyBackups(),
                job.getWeeklyBackups(),
                job.getMonthlyBackups(),
                getTaskReplicaTargets(task, task.getAllReplicas()),
                job.getAutoRetry(),
                task.getStarts()
        );

        
        
        
        
        ArrayList<JobParameter> jobParameters = new ArrayList<>();          
        for (JobParameter parameter : job.getParameters()) {
            jobParameters.add(new JobParameter(parameter.getName(), parameter.getValue(), parameter.getDefaultValue()));
        }
        ScheduledTaskKick scheduledKick = new ScheduledTaskKick(this, job.getId(), jobParameters, config, getJobConfig(job.getId()), spawnMQ, kick, job, task);
        expandKickExecutor.submit(scheduledKick);
        return true;
    }

    
    private List<HostState> hostsBlockingTaskKick(JobTask task) {
        List<HostState> unavailable = new ArrayList<>();
        HostState liveHost = hostManager.getHostState(task.getHostUUID());
        if (shouldBlockTaskKick(liveHost)) {
            unavailable.add(liveHost);
        }
        List<JobTaskReplica> replicas = (task.getReplicas() != null ? task.getReplicas() : new ArrayList<>());
        for (JobTaskReplica replica : replicas) {
            HostState replicaHost = hostManager.getHostState(replica.getHostUUID());
            if (shouldBlockTaskKick(replicaHost)) {
                unavailable.add(replicaHost);
            }
        }
        return unavailable;
    }

    private boolean shouldBlockTaskKick(HostState host) {
        if (host == null || !host.canMirrorTasks()) {
            return true;
        }
        HostFailWorker.FailState failState = hostFailWorker.getFailureState(host.getHostUuid());
        return failState == HostFailWorker.FailState.DISK_FULL || failState == HostFailWorker.FailState.FAILING_FS_DEAD;
    }

    
    public boolean kickOnExistingHosts(Job job, JobTask task, String config, long timeOnQueue, boolean allowSwap) {
        if (!jobTaskCanKick(job, task)) {
            if (task.getState() == JobTaskState.QUEUED_NO_SLOT) {
                job.setTaskState(task, JobTaskState.QUEUED);
                queueJobTaskUpdateEvent(job);
            }
            return false;
        }
        List<HostState> possibleHosts = new ArrayList<>();
        if (allowSwap && isNewTask(task)) {
            for (HostState state : hostManager.listHostStatus(job.getMinionType())) {
                
                if (hostFailWorker.getFailureState(state.getHostUuid()) == HostFailWorker.FailState.ALIVE) {
                    possibleHosts.add(state);
                }
            }
        }
        else {
            possibleHosts.addAll(getHealthyHostStatesHousingTask(task, allowSwap));
        }
        HostState bestHost = findHostWithAvailableSlot(task, timeOnQueue, possibleHosts, false);
        if (bestHost != null) {
            if (task.getState() == JobTaskState.QUEUED_NO_SLOT) {
                job.setTaskState(task, JobTaskState.QUEUED);
                queueJobTaskUpdateEvent(job);
            }
            String bestHostUuid = bestHost.getHostUuid();
            if (task.getHostUUID().equals(bestHostUuid)) {
                taskQueuesByPriority.markHostTaskActive(bestHostUuid);
                scheduleTask(job, task, config);
                log.info("[taskQueuesByPriority] sending {} to {}", task.getJobKey(), bestHostUuid);
                return true;
            } else if (swapTask(task, bestHostUuid, true)) {
                taskQueuesByPriority.markHostTaskActive(bestHostUuid);
                log.info("[taskQueuesByPriority] swapping {} onto {}", task.getJobKey(), bestHostUuid);
                return true;
            }
        }
        if (taskQueuesByPriority.isMigrationEnabled()
            && !job.getQueryConfig().getCanQuery()
            && !job.getDontAutoBalanceMe()
            && attemptMigrateTask(job, task, timeOnQueue)) {
            return true;
        }
        if (task.getState() != JobTaskState.QUEUED_NO_SLOT) {
            job.setTaskState(task, JobTaskState.QUEUED_NO_SLOT);
            queueJobTaskUpdateEvent(job);
        }
        return false;
    }

    private boolean jobTaskCanKick(Job job, JobTask task) {
        if ((job == null) || !job.isEnabled()) {
            return false;
        }
        boolean isNewTask = isNewTask(task);
        List<HostState> unavailableHosts = hostsBlockingTaskKick(task);
        if (isNewTask && !unavailableHosts.isEmpty()) {
            
            boolean changed = replaceDownHosts(task);
            if (changed) {
                return false; 
            }
        }
        if (!unavailableHosts.isEmpty()) {
            log.warn("[taskQueuesByPriority] cannot kick {} because one or more of its hosts is down or scheduled to " +
                     "be failed: {}", task.getJobKey(), unavailableHosts);
            if (task.getState() != JobTaskState.QUEUED_HOST_UNAVAIL) {
                job.setTaskState(task, JobTaskState.QUEUED_HOST_UNAVAIL);
                queueJobTaskUpdateEvent(job);
            }
            return false;
        } else if (task.getState() == JobTaskState.QUEUED_HOST_UNAVAIL) {
            
            job.setTaskState(task, JobTaskState.QUEUED);
            queueJobTaskUpdateEvent(job);
        }
        
        return !((job.getMaxSimulRunning() > 0) && (job.getCountActiveTasks() >= job.getMaxSimulRunning()));
    }

    List<HostState> getHealthyHostStatesHousingTask(JobTask task, boolean allowReplicas) {
        List<HostState> rv = new ArrayList<>();
        HostState liveHost = hostManager.getHostState(task.getHostUUID());
        if (liveHost != null && hostFailWorker.shouldKickTasks(task.getHostUUID())) {
            rv.add(liveHost);
        }
        if (allowReplicas && task.getReplicas() != null) {
            for (JobTaskReplica replica : task.getReplicas()) {
                HostState replicaHost = replica.getHostUUID() != null ?
                                        hostManager.getHostState(replica.getHostUUID()) : null;
                if (replicaHost != null && replicaHost.hasLive(task.getJobKey()) && hostFailWorker.shouldKickTasks(task.getHostUUID())) {
                    rv.add(replicaHost);
                }
            }
        }
        return rv;
    }

    
    private HostState findHostWithAvailableSlot(JobTask task, long timeOnQueue, List<HostState> hosts, boolean forMigration) {
        if (hosts == null) {
            return null;
        }
        List<HostState> filteredHosts = new ArrayList<>();
        for (HostState host : hosts) {
            if (host == null || (forMigration && hostFailWorker.getFailureState(host.getHostUuid()) != HostFailWorker.FailState.ALIVE)) {
                
                continue;
            }
            if (forMigration && !taskQueuesByPriority.shouldMigrateTaskToHost(task, host.getHostUuid())) {
                
                continue;
            }
            if (isNewTask(task) && !taskQueuesByPriority.shouldKickNewTaskOnHost(timeOnQueue, host)) {
                
                continue;
            }
            if (host.canMirrorTasks()  && taskQueuesByPriority.shouldKickTaskOnHost(host.getHostUuid())) {
                filteredHosts.add(host);
            }
        }
        return taskQueuesByPriority.findBestHostToRunTask(filteredHosts, true);
    }

    
    private boolean attemptMigrateTask(Job job, JobTask task, long timeOnQueue) {
        
        
        
        if (!systemManager.isQuiesced() && 
                taskQueuesByPriority.checkSizeAgeForMigration(task.getByteCount(), timeOnQueue)) {
            HostState target = findHostWithAvailableSlot(task, timeOnQueue,
                                                         hostManager.listHostStatus(job.getMinionType()), true);
            if (target != null) {
                log.warn("Migrating {} to {}", task.getJobKey(), target.getHostUuid());
                taskQueuesByPriority.markMigrationBetweenHosts(task.getHostUUID(), target.getHostUuid());
                taskQueuesByPriority.markHostTaskActive(target.getHostUuid());
                TaskMover tm = new TaskMover(this, hostManager, task.getJobKey(), target.getHostUuid(), task.getHostUUID());
                tm.setMigration(true);
                tm.execute();
                return true;
            }
        }
        return false;
    }

    protected boolean isNewTask(JobTask task) {
        HostState liveHost = hostManager.getHostState(task.getHostUUID());
        return (liveHost != null)
               && !liveHost.hasLive(task.getJobKey())
               && (task.getFileCount() == 0)
               && (task.getByteCount() == 0);
    }

    
    public void addToTaskQueue(JobKey jobKey, int priority, boolean toHead) {
        Job job = getJob(jobKey.getJobUuid());
        JobTask task = getTask(jobKey.getJobUuid(), jobKey.getNodeNumber());
        if (job != null && task != null) {
            if (task.getState() == JobTaskState.QUEUED || job.setTaskState(task, JobTaskState.QUEUED)) {
                log.info("[taskQueuesByPriority] adding " + jobKey + " to queue with priority=" + priority);
                taskQueuesByPriority.addTaskToQueue(job.getPriority(), jobKey, priority, toHead);
                queueJobTaskUpdateEvent(job);
                sendTaskQueueUpdateEvent();
            } else {
                log.warn("[task.queue] failed to add task " + jobKey + " with state " + task.getState());
            }
        }
    }

    
    public void kickJobsOnQueue() {
        LinkedList[] queues = null;
        boolean success = false;
        while (!success && !shuttingDown.get()) {
            
            jobLock.lock();
            try {
                if (taskQueuesByPriority.tryLock()) {
                    success = true;
                    taskQueuesByPriority.setStoppedJob(false);
                    taskQueuesByPriority.updateAllHostAvailSlots(hostManager.listHostStatus(null));
                    queues = taskQueuesByPriority.values().toArray(new LinkedList[taskQueuesByPriority.size()]);
                    for (LinkedList<SpawnQueueItem> queue : queues) {
                        iterateThroughTaskQueue(queue);
                    }
                    sendTaskQueueUpdateEvent();
                }
            } finally {
                jobLock.unlock();
                if (success) {
                    taskQueuesByPriority.unlock();
                }
            }
            if (!success) {
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                }
            }
        }
    }

    
    private void iterateThroughTaskQueue(LinkedList<SpawnQueueItem> queue) {
        ListIterator<SpawnQueueItem> iter = queue.listIterator(0);
        int skippedQuiesceCount = 0;
        long now = System.currentTimeMillis();
        
        while (iter.hasNext() && !taskQueuesByPriority.getStoppedJob()) {
            SpawnQueueItem key = iter.next();
            Job job = getJob(key.getJobUuid());
            JobTask task = getTask(key.getJobUuid(), key.getNodeNumber());
            try {
                if ((job == null) || (task == null) || !task.getState().isQueuedState()) {
                    log.warn("[task.queue] removing invalid task {}", key);
                    iter.remove();
                    continue;
                }
                if (systemManager.isQuiesced() && (key.getPriority() < 1)) {
                    skippedQuiesceCount++;
                    log.debug("[task.queue] skipping {} because spawn is quiesced and the kick wasn't manual", key);
                    if (task.getState() == JobTaskState.QUEUED_NO_SLOT) {
                        job.setTaskState(task, JobTaskState.QUEUED);
                        queueJobTaskUpdateEvent(job);
                    }
                } else {
                    boolean kicked = kickOnExistingHosts(job, task, null, now - key.getCreationTime(),
                                                         !job.getDontAutoBalanceMe());
                    if (kicked) {
                        log.info("[task.queue] removing kicked task {}", task.getJobKey());
                        iter.remove();
                    }
                }
            } catch (Exception ex) {
                log.warn("[task.queue] received exception during task kick: ", ex);
                if ((task != null) && (job != null)) {
                    job.errorTask(task, JobTaskErrorCode.KICK_ERROR);
                    iter.remove();
                    queueJobTaskUpdateEvent(job);
                }
            }
        }
        if (skippedQuiesceCount > 0) {
            log.warn("[task.queue] skipped {} queued tasks because spawn is quiesced and the kick wasn't manual",
                     skippedQuiesceCount);
        }
    }

    public WebSocketManager getWebSocketManager() {
        return this.webSocketManager;
    }

    public void toggleHosts(String hosts, boolean disable) {
        if (hosts != null) {
            String[] hostsArray = hosts.split(",");
            for (String host : hostsArray) {
                if (host.isEmpty()) {
                    continue;
                }
                boolean changed;
                changed = disable ? spawnState.disabledHosts.add(host) : spawnState.disabledHosts.remove(host);
                if (changed) {
                    updateToggledHosts(host, disable);
                }
            }
            writeState();
        }
    }

    public void updateToggledHosts(String id, boolean disable) {
        for (HostState host : hostManager.listHostStatus(null)) {
            if (id.equals(host.getHost()) || id.equals(host.getHostUuid())) {
                host.setDisabled(disable);
                sendHostUpdateEvent(host);
                hostManager.updateHostState(host);
            }
        }
    }

    @Nonnull
    public SpawnState getSpawnState() {
        return spawnState;
    }

    @Nonnull
    public JobDefaults getJobDefaults() { return jobDefaults; }

    @Nonnull
    public SpawnDataStore getSpawnDataStore() {
        return spawnDataStore;
    }

}

<code block>

package com.addthis.hydra.job.spawn;

import java.util.concurrent.TimeUnit;

import com.addthis.basis.util.Parameter;

import com.addthis.codec.annotations.Bytes;
import com.addthis.codec.annotations.FieldConfig;
import com.addthis.codec.annotations.Time;
import com.addthis.codec.codables.Codable;

import com.fasterxml.jackson.annotation.JsonAutoDetect;


@JsonAutoDetect(getterVisibility = JsonAutoDetect.Visibility.NONE,
                isGetterVisibility = JsonAutoDetect.Visibility.NONE,
                setterVisibility = JsonAutoDetect.Visibility.NONE)
public class SpawnBalancerConfig implements Codable {

    
    @FieldConfig
    private int autoBalanceLevel = 0;

    
    @FieldConfig
    private int tasksMovedFullRebalance = Parameter.intValue("spawnbalance.tasks.fullbalance", 10);
    
    @Bytes
    @FieldConfig
    private long bytesMovedFullRebalance = Parameter.longValue("spawnbalance.bytes.fullbalance", 300L * 1000 * 1000 * 1000);
    
    private double singleTaskBytesFactor = Double.parseDouble(Parameter.value("spawnbalance.task.factor", ".8"));
    
    private double hostDiskFactor = Double.parseDouble(Parameter.value("spawnbalance.host.factor", ".75"));
    
    private int tasksMovedPerUnspecifiedHost = Parameter.intValue("spawnbalance.host.unspecified", 4);
    
    private int minTaskSizeBytes = Parameter.intValue("spawnbalance.mintaskbytes", 50 * 1000 * 1000);

    
    private double extremeHostRatio = Double.parseDouble(Parameter.value("spawnbalance.extreme.ratio", "1.1"));
    
    private double extremeHostPercentile = Double.parseDouble(Parameter.value("spawnbalance.extreme.perc", ".5"));
    
    
    private double alleviateHostPercentage = Double.parseDouble(Parameter.value("spawnbalance.alleviate.perc", ".2"));

    private int autobalanceCheckInterval = Parameter.intValue("spawnbalance.check.autobalance", 60 * 1000);
    
    @Time(TimeUnit.MILLISECONDS)
    @FieldConfig
    private int jobAutobalanceIntervalMillis = Parameter.intValue("spawnbalance.interval.job.autobalance", 4 * 60 * 60 * 1000);
    
    @Time(TimeUnit.MILLISECONDS)
    @FieldConfig
    private int hostAutobalanceIntervalMillis = Parameter.intValue("spawnbalance.interval.host.autobalance", 6 * 60 * 60 * 1000);
    
    private long lastJobAutobalanceTime = 0L;

    
    private double minDiskPercentAvailToReceiveNewTasks = Double.parseDouble(Parameter.value("spawnbalance.min.disk.percent.avail.newtasks", ".2"));
    
    private double minDiskPercentAvailToRunJobs = Double.parseDouble(Parameter.value("spawnbalance.min.disk.percent.avail.runtasks", ".1"));
    
    private int maxReadonlyReplicas = Parameter.intValue("spawnbalance.max.job.task.replicas.per.host", 5);

    
    private int activeTaskMilliCutoff = Parameter.intValue("spawnbalance.active.task.cutoff", 24 * 60 * 60 * 1000);
    
    private boolean allowSameHostReplica = Parameter.boolValue("spawnbalance.replica.same_host", true);
    
    private int siblingWeight = Parameter.intValue("spawnbalance.sib.wt", 40);
    
    private int activeTaskWeight = Parameter.intValue("spawnbalance.active.task.wt", 30);
    
    private int diskUsedWeight = Parameter.intValue("spawnbalance.disk.used.wt", 70);
    
    private double defaultHostScore = Parameter.intValue("spawnbalance.default.host.score", 100);

    public int getAutoBalanceLevel() {
        return autoBalanceLevel;
    }

    public void setAutoBalanceLevel(int autoBalanceLevel) {
        this.autoBalanceLevel = autoBalanceLevel;
    }

    public int getTasksMovedFullRebalance() {
        return tasksMovedFullRebalance;
    }

    public void setTasksMovedFullRebalance(int tasksMovedFullRebalance) {
        this.tasksMovedFullRebalance = tasksMovedFullRebalance;
    }

    public long getBytesMovedFullRebalance() {
        return bytesMovedFullRebalance;
    }

    public void setBytesMovedFullRebalance(long bytesMovedFullRebalance) {
        this.bytesMovedFullRebalance = bytesMovedFullRebalance;
    }

    public double getSingleTaskBytesFactor() {
        return singleTaskBytesFactor;
    }

    public void setSingleTaskBytesFactor(double singleTaskBytesFactor) {
        this.singleTaskBytesFactor = singleTaskBytesFactor;
    }

    public int getTasksMovedPerUnspecifiedHost() {
        return tasksMovedPerUnspecifiedHost;
    }

    public void setTasksMovedPerUnspecifiedHost(int tasksMovedPerUnspecifiedHost) {
        this.tasksMovedPerUnspecifiedHost = tasksMovedPerUnspecifiedHost;
    }

    public int getMinTaskSizeBytes() {
        return minTaskSizeBytes;
    }

    public void setMinTaskSizeBytes(int minTaskSizeBytes) {
        this.minTaskSizeBytes = minTaskSizeBytes;
    }

    public double getExtremeHostRatio() {
        return extremeHostRatio;
    }

    public void setExtremeHostRatio(double extremeHostRatio) {
        this.extremeHostRatio = extremeHostRatio;
    }

    public double getExtremeHostPercentile() {
        return extremeHostPercentile;
    }

    public void setExtremeHostPercentile(double extremeHostPercentile) {
        this.extremeHostPercentile = extremeHostPercentile;
    }

    public double getAlleviateHostPercentage() {
        return alleviateHostPercentage;
    }

    public void setAlleviateHostPercentage(double alleviateHostPercentage) {
        this.alleviateHostPercentage = alleviateHostPercentage;
    }

    public int getAutobalanceCheckInterval() {
        return autobalanceCheckInterval;
    }

    public int getJobAutobalanceIntervalMillis() {
        return jobAutobalanceIntervalMillis;
    }

    public void setJobAutobalanceIntervalMillis(int jobAutobalanceIntervalMillis) {
        this.jobAutobalanceIntervalMillis = jobAutobalanceIntervalMillis;
    }

    public int getHostAutobalanceIntervalMillis() {
        return hostAutobalanceIntervalMillis;
    }

    public void setHostAutobalanceIntervalMillis(int hostAutobalanceIntervalMillis) {
        this.hostAutobalanceIntervalMillis = hostAutobalanceIntervalMillis;
    }

    public long getLastJobAutobalanceTime() {
        return lastJobAutobalanceTime;
    }

    public void setLastJobAutobalanceTime(long lastJobAutobalanceTime) {
        this.lastJobAutobalanceTime = lastJobAutobalanceTime;
    }

    public double getMinDiskPercentAvailToReceiveNewTasks() {
        return minDiskPercentAvailToReceiveNewTasks;
    }

    public void setMinDiskPercentAvailToReceiveNewTasks(double minDiskPercentAvailToReceiveNewTasks) {
        this.minDiskPercentAvailToReceiveNewTasks = minDiskPercentAvailToReceiveNewTasks;
    }

    public double getMinDiskPercentAvailToRunJobs() {
        return minDiskPercentAvailToRunJobs;
    }

    public void setMinDiskPercentAvailToRunJobs(double minDiskPercentAvailToRunJobs) {
        this.minDiskPercentAvailToRunJobs = minDiskPercentAvailToRunJobs;
    }

    public int getMaxReadonlyReplicas() {
        return maxReadonlyReplicas;
    }

    public void setMaxReadonlyReplicas(int maxReadonlyReplicas) {
        this.maxReadonlyReplicas = maxReadonlyReplicas;
    }

    public int getActiveTaskMilliCutoff() {
        return activeTaskMilliCutoff;
    }

    public void setActiveTaskMilliCutoff(int getActiveTaskMilliCutoff) {
        this.activeTaskMilliCutoff = getActiveTaskMilliCutoff;
    }

    public int getSiblingWeight() {
        return siblingWeight;
    }

    public void setSiblingWeight(int siblingWeight) {
        this.siblingWeight = siblingWeight;
    }

    public int getActiveTaskWeight() {
        return activeTaskWeight;
    }

    public void setActiveTaskWeight(int activeTaskWeight) {
        this.activeTaskWeight = activeTaskWeight;
    }

    public int getDiskUsedWeight() {
        return diskUsedWeight;
    }

    public void setDiskUsedWeight(int diskUsedWeight) {
        this.diskUsedWeight = diskUsedWeight;
    }

    public double getDefaultHostScore() {
        return defaultHostScore;
    }

    public void setDefaultHostScore(double defaultHostScore) {
        this.defaultHostScore = defaultHostScore;
    }

    public boolean allowSameHostReplica() {
        return allowSameHostReplica;
    }

    public void setAllowSameHostReplica(boolean allowSameHostReplica) {
        this.allowSameHostReplica = allowSameHostReplica;
    }

    public double getHostDiskFactor() {
        return hostDiskFactor;
    }

    public void setHostDiskFactor(double hostDiskFactor) {
        this.hostDiskFactor = hostDiskFactor;
    }
}

<code block>

package com.addthis.hydra.job.spawn;

import javax.annotation.Nonnull;
import javax.annotation.Nullable;

import java.util.ArrayList;
import java.util.List;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import com.addthis.hydra.job.mq.HostState;

import org.apache.curator.framework.CuratorFramework;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import static com.addthis.hydra.job.store.SpawnDataStoreKeys.MINION_DEAD_PATH;
import static com.addthis.hydra.job.store.SpawnDataStoreKeys.MINION_UP_PATH;

public class HostManager {
    private static final Logger log = LoggerFactory.getLogger(HostManager.class);

    @Nonnull final ConcurrentMap<String, HostState> monitored;
    @Nonnull final SetMembershipListener minionMembers;
    @Nonnull final SetMembershipListener deadMinionMembers;

    public HostManager(CuratorFramework zkClient) {
        this.monitored = new ConcurrentHashMap<>();
        this.minionMembers = new SetMembershipListener(zkClient, MINION_UP_PATH);
        this.deadMinionMembers = new SetMembershipListener(zkClient, MINION_DEAD_PATH);
    }

    public HostState getHostState(String hostUuid) {
        if (hostUuid == null) {
            return null;
        }
        synchronized (monitored) {
            return monitored.get(hostUuid);
        }
    }

    public void updateHostState(HostState state) {
        synchronized (monitored) {
            if (!deadMinionMembers.getMemberSet().contains(state.getHostUuid())) {
                log.debug("Updating host state for : {}", state.getHost());
                monitored.put(state.getHostUuid(), state);
            }
        }
    }

    
    public List<HostState> listHostStatus(@Nullable String minionType) {
        synchronized (monitored) {
            Set<String> availableMinions = minionMembers.getMemberSet();
            Set<String> deadMinions = deadMinionMembers.getMemberSet();
            List<HostState> allMinions = new ArrayList<>();
            for (HostState minion : monitored.values()) {
                if (availableMinions.contains(minion.getHostUuid()) && !deadMinions.contains(minion.getHostUuid())) {
                    minion.setUp(true);
                } else {
                    minion.setUp(false);
                }
                if ((minionType == null) || minion.hasType(minionType)) {
                    allMinions.add(minion);
                }
            }
            return allMinions;
        }
    }

    public List<HostState> getLiveHosts(String minionType) {
        List<HostState> allHosts = listHostStatus(minionType);
        List<HostState> rv = new ArrayList<>(allHosts.size());
        for (HostState host : allHosts) {
            if (host.isUp() && !host.isDead()) {
                rv.add(host);
            }
        }
        return rv;
    }
}
<code block>

package com.addthis.hydra.job.spawn;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.PriorityQueue;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.ReentrantLock;

import com.addthis.basis.util.JitterClock;
import com.addthis.basis.util.Parameter;

import com.addthis.codec.annotations.FieldConfig;
import com.addthis.codec.codables.Codable;
import com.addthis.codec.config.Configs;
import com.addthis.codec.json.CodecJSON;
import com.addthis.hydra.job.HostFailWorker;
import com.addthis.hydra.job.Job;
import com.addthis.hydra.job.JobState;
import com.addthis.hydra.job.JobTask;
import com.addthis.hydra.job.JobTaskMoveAssignment;
import com.addthis.hydra.job.JobTaskReplica;
import com.addthis.hydra.job.JobTaskState;
import com.addthis.hydra.job.mq.CommandTaskStop;
import com.addthis.hydra.job.mq.HostState;
import com.addthis.hydra.job.mq.JobKey;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.base.Strings;
import com.google.common.cache.Cache;
import com.google.common.cache.CacheBuilder;
import com.google.common.collect.ImmutableSet;
import com.google.common.collect.Lists;
import com.google.common.util.concurrent.MoreExecutors;
import com.google.common.util.concurrent.ThreadFactoryBuilder;

import com.fasterxml.jackson.annotation.JsonAutoDetect;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import static com.addthis.hydra.job.store.SpawnDataStoreKeys.SPAWN_BALANCE_PARAM_PATH;


@JsonAutoDetect(getterVisibility = JsonAutoDetect.Visibility.NONE,
                isGetterVisibility = JsonAutoDetect.Visibility.NONE,
                setterVisibility = JsonAutoDetect.Visibility.NONE)
public class SpawnBalancer implements Codable {
    private static final Logger log = LoggerFactory.getLogger(SpawnBalancer.class);

    private final Spawn spawn;
    private final HostManager hostManager;

    @FieldConfig(codable = true)
    private SpawnBalancerConfig config;

    
    private static final long AGGREGATE_STAT_UPDATE_INTERVAL = Parameter.intValue("spawnbalance.stat.update", 15 * 1000);

    private ConcurrentHashMap<String, HostScore> cachedHostScores = new ConcurrentHashMap<>();
    private Set<String> activeJobIDs;
    private ReentrantLock aggregateStatisticsLock = new ReentrantLock();
    private long lastAggregateStatUpdateTime = 0;

    private static final Set<JobTaskState> movableTaskStates = ImmutableSet.of(JobTaskState.IDLE, JobTaskState.QUEUED, JobTaskState.QUEUED_HOST_UNAVAIL, JobTaskState.QUEUED_NO_SLOT);

    private AtomicBoolean autobalanceStarted = new AtomicBoolean(false);

    private Cache<String, Boolean> recentlyAutobalancedJobs = CacheBuilder.newBuilder().expireAfterWrite(
            Parameter.intValue("spawnbalance.job.autobalance.interval.mins", 60 * 12), TimeUnit.MINUTES
    ).build();

    private Cache<String, Boolean> recentlyBalancedHosts = CacheBuilder.newBuilder().expireAfterWrite(
            Parameter.intValue("spawnbalance.host.balance.interval.mins", 3), TimeUnit.MINUTES
    ).build();

    private Cache<String, Boolean> recentlyReplicatedToHosts = CacheBuilder.newBuilder().expireAfterWrite(
            Parameter.intValue("spawnbalance.host.replicate.interval.mins", 15), TimeUnit.MINUTES
    ).build();

    private final SpawnBalancerTaskSizer taskSizer;

    private final Comparator<HostAndScore> hostAndScoreComparator =
            (firstHAS, secondHAS) -> Double.compare(firstHAS.score, secondHAS.score);

    private final Comparator<HostState> hostStateScoreComparator = (hostState, hostState1) -> Double.compare(
            getHostScoreCached(hostState.getHostUuid()),
            getHostScoreCached(hostState1.getHostUuid()));

    private final Comparator<Job> jobAverageTaskSizeComparator = (job, job1) -> {
        if (job == null || job1 == null) {
            return 0;
        } else {
            return Double.compare(job.calcAverageTaskSizeBytes(), job1.calcAverageTaskSizeBytes());
        }
    };

    private final Comparator<HostState> hostStateReplicationSuitabilityComparator = (hostState, hostState1) -> {
        
        long availBytes = getAvailDiskBytes(hostState);
        long availBytes1 = getAvailDiskBytes(hostState1);
        if (recentlyReplicatedToHosts.getIfPresent(hostState.getHostUuid()) != null) {
            availBytes /= 2;
        }
        if (recentlyReplicatedToHosts.getIfPresent(hostState1.getHostUuid()) != null) {
            availBytes1 /= 2;
        }
        return -Double.compare(availBytes, availBytes1);
    };

    private final ScheduledExecutorService taskExecutor;

    public SpawnBalancer(Spawn spawn, HostManager hostManager) {
        this.spawn = spawn;
        this.hostManager = hostManager;
        this.config = loadConfigFromDataStore(new SpawnBalancerConfig());
        taskExecutor = MoreExecutors.getExitingScheduledExecutorService(
                new ScheduledThreadPoolExecutor(2, new ThreadFactoryBuilder().setNameFormat("spawnBalancer-%d").build()));
        taskExecutor.scheduleAtFixedRate(new AggregateStatUpdaterTask(), AGGREGATE_STAT_UPDATE_INTERVAL, AGGREGATE_STAT_UPDATE_INTERVAL, TimeUnit.MILLISECONDS);
        this.taskSizer = new SpawnBalancerTaskSizer(spawn, hostManager);
    }
    
    
    @VisibleForTesting
    protected SpawnBalancerConfig loadConfigFromDataStore(SpawnBalancerConfig defaultValue) {
        String configString = spawn.getSpawnDataStore().get(SPAWN_BALANCE_PARAM_PATH);
        if (!Strings.isNullOrEmpty(configString)) {
            try {
                return Configs.decodeObject(SpawnBalancerConfig.class, configString);
            } catch (Exception e) {
                log.warn("Failed to decode SpawnBalancerConfig: {}", e.getMessage(), e);
            }
        }
        return defaultValue;
    }
    
    public void saveConfigToDataStore() {
        try {
            spawn.getSpawnDataStore().put(SPAWN_BALANCE_PARAM_PATH, CodecJSON.encodeString(config));
        } catch (Exception e) {
            log.warn("Failed to save SpawnBalancerConfig to data store: {}", e.getMessage(), e);
        }
    }

    public void startTaskSizePolling() {
        taskSizer.startPolling(taskExecutor);
    }

    
    private boolean isWellFormedAndActiveJob(Job job) {
        long earliestActiveTime = JitterClock.globalTime() - config.getActiveTaskMilliCutoff();
        return job != null && job.getStartTime() != null && job.getStartTime() > earliestActiveTime;
    }

    
    protected List<JobTask> generateAssignedTasksForNewJob(String jobID, int taskCount, List<HostState> hosts) throws Exception {
        List<JobTask> tasks = generateUnassignedTaskList(jobID, taskCount);
        Map<JobTask, String> hostAssignments = assignTasksFromSingleJobToHosts(tasks, generateHostStateScoreMap(hosts, null));
        List<JobTask> rv = new ArrayList<>(tasks.size());
        for (Entry<JobTask, String> entry : hostAssignments.entrySet()) {
            JobTask task = entry.getKey();
            String hostID = entry.getValue();
            if (hostID == null) {
                throw new RuntimeException("Unable to allocate job tasks because no suitable host was found");
            }
            task.setHostUUID(hostID);
            rv.add(task);
        }
        return rv;
    }

    
    private List<JobTask> generateUnassignedTaskList(String jobID, int taskCount) {
        List<JobTask> rv = new ArrayList<>(Math.max(0, taskCount));
        for (int i = 0; i < taskCount; i++) {
            JobTask task = new JobTask();
            task.setJobUUID(jobID);
            task.setTaskID(i);
            rv.add(task);
        }
        return rv;
    }

    
    private Map<JobTask, String> assignTasksFromSingleJobToHosts(List<JobTask> tasks, Map<HostState, Double> storedHostScores) {
        if (tasks == null || tasks.isEmpty()) {
            return new HashMap<>();
        }
        
        PriorityQueue<HostAndScore> hostScores = new PriorityQueue<>(1 + storedHostScores.size(), hostAndScoreComparator);
        for (HostState host : storedHostScores.keySet()) {
            if (canReceiveNewTasks(host, false)) {
                hostScores.add(new HostAndScore(host, storedHostScores.get(host)));
            }
        }
        if (hostScores.isEmpty()) {
            log.warn("[spawn.balancer] found no hosts eligible to receive new tasks");
            throw new RuntimeException("no eligible hosts for new task");
        }
        
        List<String> hostsToAssign = new ArrayList<>(tasks.size());
        for (JobTask task : tasks) {
            if (task == null) {
                continue;
            }
            
            HostAndScore h = hostScores.poll();
            HostState host = h.host;
            hostsToAssign.add(host.getHostUuid());
            
            hostScores.add(new HostAndScore(host, h.score + config.getSiblingWeight()));
            
            storedHostScores.put(host, h.score + config.getActiveTaskWeight());
        }
        return pairTasksAndHosts(tasks, hostsToAssign);
    }

    
    private Map<JobTask, String> pairTasksAndHosts(List<JobTask> tasks, List<String> hosts) {
        if (tasks == null || hosts == null || tasks.size() != hosts.size()) {
            log.warn("[spawn.balancer] invalid call to pairTasksAndHosts: tasks=" + tasks + " hosts=" + hosts);
            return new HashMap<>(0);
        }
        Map<JobTask, String> rv = new HashMap<>(tasks.size());
        
        List<JobTask> unassignedTasks = new ArrayList<>();
        String jobID = tasks.get(0).getJobUUID();
        for (JobTask task : tasks) {
            if (!(task.getJobUUID().equals(jobID))) {
                throw new RuntimeException("Illegal call to assignTasksFromSingleJobToHosts: not all tasks came from the same job");
            }
            String hostID = task.getHostUUID();
            if (hostID != null && hosts.contains(hostID)) {
                hosts.remove(hostID);
            } else {
                unassignedTasks.add(task);
            }
        }
        
        Iterator<String> hostIterator = hosts.iterator();
        for (JobTask task : unassignedTasks) {
            rv.put(task, hostIterator.next());
        }
        return rv;
    }

    
    public Map<JobTask, String> assignTasksFromMultipleJobsToHosts(List<JobTask> tasks, List<HostState> hosts) {
        
        HashMap<String, List<JobTask>> tasksByJobID = new HashMap<>();
        for (JobTask task : tasks) {
            Job job;
            if (task.getJobUUID() != null && (job = spawn.getJob(task.getJobUUID())) != null) {
                List<JobTask> taskList = tasksByJobID.get(job.getId()) != null ? tasksByJobID.get(job.getId()) : new ArrayList<>();
                taskList.add(task);
                tasksByJobID.put(job.getId(), taskList);
            }
        }
        
        Map<HostState, Double> hostScoreMap = generateHostStateScoreMap(hosts, null);
        
        HashMap<JobTask, String> hostAssignments = new HashMap<>(tasks.size());
        for (Entry<String, List<JobTask>> entry : tasksByJobID.entrySet()) {
            Map<JobTask, String> singleHostAssignments = assignTasksFromSingleJobToHosts(entry.getValue(), hostScoreMap);
            hostAssignments.putAll(singleHostAssignments);
        }
        return hostAssignments;
    }

    
    protected List<JobTaskMoveAssignment> getAssignmentsForJobReallocation(Job job, int tasksToMove, List<HostState> hosts) {
        int maxTasksToMove = tasksToMove > 0 ? tasksToMove : config.getTasksMovedFullRebalance();
        List<JobTaskMoveAssignment> candidateAssignments = new ArrayList<>();
        
        JobTaskItemByHostMap tasksByHost = generateTaskCountByHost(hosts, job.getCopyOfTasks());
        
        int maxPerHost = maxTasksPerHost(job, tasksByHost.size());
        if (log.isDebugEnabled()) {
            log.debug("Rebalancing job: " + job.getId() + " maxTasksToMove=" + maxTasksToMove + " maxPerHost=" + maxPerHost);
        }
        while (candidateAssignments.size() < maxTasksToMove) {
            MoveAssignmentList moves = null;
            List<String> hostsSorted = tasksByHost.generateHostsSorted();
            String hostWithMost = hostsSorted.get(hostsSorted.size() - 1);
            String hostWithLeast = hostsSorted.get(0);
            int mostTasksOnHost = tasksByHost.findMostTasksOnHost();
            int leastTasksOnHost = tasksByHost.findLeastTasksOnHost();
            boolean isExtremeHost = isExtremeHost(hostWithMost, true, true);
            if (log.isDebugEnabled()) {
                log.debug("hostsSorted.size=" + hostsSorted.size() +
                          " hostWithMost:" + hostWithMost + " hostWithLeast:" + hostWithLeast +
                          " mostTasksOnHost: " + mostTasksOnHost + " leastTasksOnHost: " + leastTasksOnHost);
            }

            
            if (mostTasksOnHost > maxPerHost) {
                moves = moveTasksOffHost(tasksByHost, maxPerHost, 1, -1, hostWithMost);
            } else if (leastTasksOnHost < maxPerHost - 1) { 
                moves = moveTasksOntoHost(tasksByHost, maxPerHost, 1, -1, hostWithLeast);
            } else if (isExtremeHost) { 
                moves = moveTasksOffHost(tasksByHost, maxPerHost, 1, -1, hostWithMost);
            }
            if (moves == null || moves.isEmpty()) {
                break;
            } else {
                candidateAssignments.addAll(moves);
            }
        }
        if (candidateAssignments.size() > maxTasksToMove) {
            candidateAssignments = candidateAssignments.subList(0, maxTasksToMove);
        }
        candidateAssignments = removeDuplicateAssignments(candidateAssignments);
        return pruneTaskReassignments(candidateAssignments);
    }

    private List<JobTaskMoveAssignment> removeDuplicateAssignments(List<JobTaskMoveAssignment> candidateAssignments) {
        HashSet<JobKey> movedTasks = new HashSet<>();
        List<JobTaskMoveAssignment> rv = new ArrayList<>();
        for (JobTaskMoveAssignment assignment : candidateAssignments) {
            JobKey jobKey = assignment.getJobKey();
            if (!movedTasks.contains(jobKey)) {
                rv.add(assignment);
                movedTasks.add(jobKey);
            }
        }
        return rv;
    }

    
    private MoveAssignmentList moveTasksOffHost(JobTaskItemByHostMap tasksByHost, int maxPerHost, int numToMove, long maxBytesToMove, String pushHost) {
        if (log.isDebugEnabled()) {
            log.debug("received move assignment maxPerHost:" + maxPerHost + " numToMove:" + numToMove + " pushHost:" + pushHost);
        }
        MoveAssignmentList rv = new MoveAssignmentList();
        Set<JobKey> alreadyMoved = new HashSet<>();
        Iterator<String> otherHosts = tasksByHost.getHostIterator(true);
        while (otherHosts.hasNext() && rv.size() < numToMove) {
            String pullHost = otherHosts.next();
            if (pushHost.equals(pullHost)) {
                continue;
            }
            HostState pullHostState = hostManager.getHostState(pullHost);
            Iterator<JobTaskItem> itemIterator = new ArrayList<>(tasksByHost.get(pushHost)).iterator();
            while (itemIterator.hasNext() && rv.size() < numToMove && tasksByHost.get(pullHost).size() < maxPerHost) {
                JobTaskItem nextTaskItem = itemIterator.next();
                long trueSizeBytes = taskSizer.estimateTrueSize(nextTaskItem.getTask());
                JobKey jobKey = nextTaskItem.getTask().getJobKey();
                Job job = spawn.getJob(jobKey);
                if (job == null || !pullHostState.getMinionTypes().contains(job.getMinionType())) {
                    continue;
                }
                
                if (isExtremeHost(pullHost, true, true) || pullHostState.hasLive(jobKey) || (maxBytesToMove > 0 && trueSizeBytes > maxBytesToMove)) {
                    if (log.isDebugEnabled()) {
                        log.debug("Unable to move task to host " + pullHost + " fullDisk=" + isExtremeHost(pullHost, true, true)
                                 + " alreadyLive=" + pullHostState.hasLive(jobKey)
                                 + " byteCount=" + trueSizeBytes + ">" + maxBytesToMove + " "
                                 + (trueSizeBytes > maxBytesToMove));
                    }
                    continue;
                }
                if (!alreadyMoved.contains(jobKey) && pullHost != null && tasksByHost.moveTask(nextTaskItem, pushHost, pullHost)) {
                    rv.add(new JobTaskMoveAssignment(nextTaskItem.getTask().getJobKey(), pushHost, pullHost, false, false));
                    alreadyMoved.add(nextTaskItem.getTask().getJobKey());
                    maxBytesToMove -= trueSizeBytes;
                }
            }
        }
        return rv;
    }

    
    private MoveAssignmentList moveTasksOntoHost(JobTaskItemByHostMap tasksByHost, int maxPerHost, int numToMove, long maxBytesToMove, String pullHost) {
        MoveAssignmentList rv = new MoveAssignmentList();
        Set<JobKey> alreadyMoved = new HashSet<>();
        Iterator<String> otherHosts = tasksByHost.getHostIterator(false);
        if (isExtremeHost(pullHost, true, true)) {
            return rv;
        }
        if (isExtremeHost(pullHost, false, true)) {
            numToMove = Math.max(1, numToMove / 2); 
        }
        HostState pullHostState = hostManager.getHostState(pullHost);
        if (pullHostState == null) {
            return rv;
        }
        while (otherHosts.hasNext() && rv.size() < numToMove && tasksByHost.get(pullHost).size() < maxPerHost) {
            String pushHost = otherHosts.next();
            if (pushHost == null || pushHost.equals(pullHost)) {
                continue;
            }
            List<JobTaskItem> pushHostItems = new ArrayList<>(tasksByHost.get(pushHost));
            if (pushHostItems.size() < maxPerHost) {
                break;
            }
            for (JobTaskItem item : pushHostItems) {
                JobKey jobKey = item.getTask().getJobKey();
                Job job = spawn.getJob(jobKey);
                if (job == null || !pullHostState.getMinionTypes().contains(job.getMinionType())) {
                    continue;
                }
                long trueSizeBytes = taskSizer.estimateTrueSize(item.getTask());
                if (pullHostState.hasLive(item.getTask().getJobKey()) || (maxBytesToMove > 0 && trueSizeBytes > maxBytesToMove)) {
                    continue;
                }
                if (!alreadyMoved.contains(jobKey) && tasksByHost.moveTask(item, pushHost, pullHost)) {
                    rv.add(new JobTaskMoveAssignment(item.getTask().getJobKey(), pushHost, pullHost, false, false));
                    alreadyMoved.add(item.getTask().getJobKey());
                    maxBytesToMove -= trueSizeBytes;
                }
                if (rv.size() >= numToMove) {
                    break;
                }
            }
        }
        return rv;
    }

    
    private JobTaskItemByHostMap generateTaskCountByHost(List<HostState> hosts, List<JobTask> tasks) {
        JobTaskItemByHostMap rv = new JobTaskItemByHostMap(hosts, config.getTasksMovedPerUnspecifiedHost(), config.getTasksMovedPerUnspecifiedHost());
        for (JobTask task : tasks) {
            rv.addLiveAndReplicasForTask(task);
        }
        return rv;
    }

    
    private class JobTaskItemByHostMap extends HashMap<String, Set<JobTaskItem>> {

        private final HashMap<String, Integer> pushedTaskCounts;
        private final HashMap<String, Integer> pulledTaskCounts;
        private List<String> hostsSorted = null;
        private final int maxPulledFromHost;
        private final int maxPushedToHost;

        public JobTaskItemByHostMap(List<HostState> hosts, int maxPulledFromHost, int maxPushedToHost) {
            this.pulledTaskCounts = new HashMap<>();
            this.pushedTaskCounts = new HashMap<>();
            this.maxPulledFromHost = maxPulledFromHost;
            this.maxPushedToHost = maxPushedToHost;
            for (HostState host : hosts) {
                if (host.isUp() && !host.isDead()) {
                    put(host.getHostUuid(), new HashSet<>());
                }
            }
        }

        public void add(String hostID, JobTask task) {
            if (containsKey(hostID)) {
                Set<JobTaskItem> current = get(hostID);
                current.add(new JobTaskItem(task));
            }
        }

        public void addLiveAndReplicasForTask(JobTask task) {
            add(task.getHostUUID(), task);
            List<JobTaskReplica> replicas = task.getReplicas();
            if (replicas != null) {
                for (JobTaskReplica replica : replicas) {
                    add(replica.getHostUUID(), task);
                }
            }
        }

        public boolean moveTask(JobTaskItem item, String fromHost, String toHost) {
            if (!containsKey(fromHost) || !containsKey(toHost)) {
                return false;
            } else if (!get(fromHost).contains(item) || get(toHost).contains(item)) {
                return false;
            } else if (!hasCapacity(pulledTaskCounts, fromHost, maxPulledFromHost) || !hasCapacity(pushedTaskCounts, toHost, maxPushedToHost)) {
                return false;
            } else {
                boolean success = get(fromHost).remove(item) && get(toHost).add(item);
                if (success) {
                    claimCapacity(pulledTaskCounts, fromHost);
                    claimCapacity(pushedTaskCounts, toHost);
                }
                return success;
            }
        }

        public List<String> generateHostsSorted() {
            List<String> rv = new ArrayList<>(this.keySet());
            Collections.sort(rv, (s, s1) -> {
                int count = get(s).size();
                int count1 = get(s1).size();
                if (count != count1) {
                    return Double.compare(count, count1);
                } else {
                    return Double.compare(getHostScoreCached(s), getHostScoreCached(s1));
                }
            });
            hostsSorted = rv;
            return new ArrayList<>(rv);
        }


        public Iterator<String> getHostIterator(boolean smallFirst) {
            if (hostsSorted == null) {
                generateHostsSorted();
            }
            ArrayList<String> copy = new ArrayList<>(hostsSorted);
            if (!smallFirst) {
                Collections.reverse(copy);
            }
            return copy.iterator();
        }

        private boolean hasCapacity(HashMap<String, Integer> map, String key, int max) {
            return !map.containsKey(key) || map.get(key) < max;
        }

        private void claimCapacity(HashMap<String, Integer> map, String key) {
            if (map.containsKey(key)) {
                map.put(key, map.get(key) + 1);
            } else {
                map.put(key, 1);
            }
        }

        @Override
        public String toString() {
            StringBuilder sb = new StringBuilder("{");
            for (Entry<String, Set<JobTaskItem>> entry : this.entrySet()) {
                sb.append(entry.getKey()).append(":").append(entry.getValue().size()).append("; ");
            }
            return sb.append("}").toString();
        }

        public int findLeastTasksOnHost() {
            if (hostsSorted == null) {
                generateHostsSorted();
            }
            return get(hostsSorted.get(0)).size();
        }

        public int findMostTasksOnHost() {
            if (hostsSorted == null) {
                generateHostsSorted();
            }
            return get(hostsSorted.get(hostsSorted.size() - 1)).size();
        }
    }

    
    private static class JobTaskItem {

        private final JobTask task;

        public JobTaskItem(JobTask task) {
            this.task = task;
        }

        public JobTask getTask() {
            return task;
        }

        @Override
        public boolean equals(Object o) {
            if (o.getClass() != getClass()) {
                return false;
            }
            JobTaskItem item2 = (JobTaskItem) o;
            return task.getJobKey().matches(item2.getTask().getJobKey());
        }

        @Override
        public String toString() {
            return "JobTaskItem{task=" + task.getJobKey() + "'";
        }
    }

    
    private static int maxTasksPerHost(Job job, int numHosts) {
        if (job == null) {
            return 0;
        }
        numHosts = Math.max(1, numHosts);
        return (int) Math.ceil((double) (job.getTaskCount() * (1 + job.getReplicas())) / numHosts);
    }

    
    protected List<JobTaskMoveAssignment> getAssignmentsToBalanceHost(HostState host, List<HostState> hosts) {
        String hostID = host.getHostUuid();
        List<JobTaskMoveAssignment> rv = new ArrayList<>();
        if (hosts == null || hosts.isEmpty()) {
            log.warn("[spawn.balancer] " + hostID + " reallocation failed: host list empty");
            return rv;
        }
        List<HostState> sortedHosts = sortHostsByDiskSpace(hosts);
        HostFailWorker.FailState failState = spawn.getHostFailWorker().getFailureState(hostID);
        int numAlleviateHosts = (int) Math.ceil(sortedHosts.size() * config.getAlleviateHostPercentage());
        if (failState == HostFailWorker.FailState.FAILING_FS_OKAY || isExtremeHost(hostID, true, true) || getUsedDiskPercent(host) > 1 - config.getMinDiskPercentAvailToReceiveNewTasks()) {
            
            log.info("[spawn.balancer] " + hostID + " categorized as overloaded host; looking for tasks to push off of it");
            List<HostState> lightHosts = sortedHosts.subList(0, numAlleviateHosts);
            rv.addAll(pushTasksOffHost(host, lightHosts, true, 1, config.getTasksMovedFullRebalance(), true));
        } else if (isExtremeHost(hostID, true, false)) {
            
            log.info("[spawn.balancer] " + hostID + " categorized as underloaded host; looking for tasks to pull onto it");
            List<HostState> heavyHosts = Lists.reverse(sortedHosts.subList(sortedHosts.size() - numAlleviateHosts, sortedHosts.size()));
            pushTasksOntoDisk(host, heavyHosts);
        } else if (isExtremeHost(hostID, false, true)) {
            
            log.info("[spawn.balance] " + hostID + " categorized as overworked host; looking for tasks to push off it");
            rv.addAll(balanceActiveJobsOnHost(host, hosts));
        }
        if (rv.isEmpty()) {
            rv.addAll(balanceActiveJobsOnHost(host, hosts));
        }
        return pruneTaskReassignments(rv);
    }

    
    private List<JobTask> findTasksToMove(HostState host, boolean obeyDontAutobalanceMe) {
        List<JobTask> rv = new ArrayList<>();
        if (host != null) {
            String hostId = host.getHostUuid();
            for (JobKey jobKey : host.allJobKeys()) {
                Job job = spawn.getJob(jobKey);
                JobTask task = spawn.getTask(jobKey);
                if (job != null && task != null && isInMovableState(task) 
                    && (hostId.equals(task.getHostUUID()) || task.hasReplicaOnHost(host.getHostUuid()))) 
                {
                    if (obeyDontAutobalanceMe && job.getDontAutoBalanceMe()) {
                        
                        
                        
                        
                        continue;
                    }
                    rv.add(task);
                }
            }
        }
        return rv;
    }

    public boolean isInMovableState(JobTask task) {
        return task != null && movableTaskStates.contains(task.getState());
    }

    private List<JobTaskMoveAssignment> pushTasksOntoDisk(HostState host, List<HostState> heavyHosts) {
        MoveAssignmentList moveAssignments = new MoveAssignmentList();
        for (HostState heavyHost : heavyHosts) {
            double byteLimitFactor = 1 - ((double) (moveAssignments.getBytesUsed())) / config.getBytesMovedFullRebalance();
            moveAssignments.addAll(pushTasksOffHost(heavyHost, Arrays.asList(host), true, byteLimitFactor, config.getTasksMovedFullRebalance(), true));
        }
        moveAssignments.addAll(purgeMisplacedTasks(host, 1));
        return moveAssignments;
    }

    public List<JobTaskMoveAssignment> pushTasksOffDiskForFilesystemOkayFailure(HostState host, int moveLimit) {
        List<HostState> hosts = hostManager.listHostStatus(null);
        return pushTasksOffHost(host, hosts, false, 1, moveLimit, false);
    }

    
    private List<JobTaskMoveAssignment> pushTasksOffHost(HostState host, List<HostState> otherHosts, boolean limitBytes, double byteLimitFactor, int moveLimit, boolean obeyDontAutobalanceMe) {
        List<JobTaskMoveAssignment> rv = purgeMisplacedTasks(host, moveLimit);
        if (rv.size() <= moveLimit) {
            long byteLimit = (long) (byteLimitFactor * config.getBytesMovedFullRebalance());
            List<HostState> hostsSorted = sortHostsByDiskSpace(otherHosts);
            for (JobTask task : findTasksToMove(host, obeyDontAutobalanceMe)) {
                long taskTrueSize = getTaskTrueSize(task);
                if (limitBytes && taskTrueSize > byteLimit) {
                    continue;
                }
                JobTaskMoveAssignment assignment = moveTask(task, host.getHostUuid(), hostsSorted);
                if (assignment != null) {
                    markRecentlyReplicatedTo(assignment.getTargetUUID());
                    rv.add(assignment);
                    byteLimit -= taskTrueSize;
                }
                if (rv.size() >= moveLimit) {
                    break;
                }
            }
        }
        return rv;
    }

    
    private List<JobTaskMoveAssignment> purgeMisplacedTasks(HostState host, int deleteLimit) {
        List<JobTaskMoveAssignment> rv = new ArrayList<>();
        for (JobKey key : host.allJobKeys()) {
            if (spawn.getJob(key) == null) {
                
                rv.add(new JobTaskMoveAssignment(key, host.getHostUuid(), null, false, true));
            } else  {
                
                JobTask task = spawn.getTask(key);
                if (!host.getHostUuid().equals(task.getHostUUID()) && !task.hasReplicaOnHost(host.getHostUuid())) {
                    spawn.fixTaskDir(key.getJobUuid(), key.getNodeNumber(), false, false);
                    deleteLimit -= 1;
                }
            }
            if (rv.size() >= deleteLimit) {
                break;
            }
        }
        return rv;
    }

    @VisibleForTesting
    protected void markRecentlyReplicatedTo(String hostId) {
        if (hostId != null) {
            recentlyReplicatedToHosts.put(hostId, true);
        }
    }

    
    private JobTaskMoveAssignment moveTask(JobTask task, String fromHostId, List<HostState> otherHosts) {
        Iterator<HostState> hostStateIterator = otherHosts.iterator();
        String taskHost = task.getHostUUID();
        boolean live = task.getHostUUID().equals(fromHostId);
        if (!live && !task.hasReplicaOnHost(fromHostId)) {
            return null;
        }
        while (hostStateIterator.hasNext()) {
            HostState next = hostStateIterator.next();
            String nextId = next.getHostUuid();
            if (!taskHost.equals(nextId) && !task.hasReplicaOnHost(nextId) && next.canMirrorTasks() && okToPutReplicaOnHost(next, task)) {
                hostStateIterator.remove();
                otherHosts.add(next);
                return new JobTaskMoveAssignment(task.getJobKey(), fromHostId, nextId, !live, false);
            }
        }
        return null;
    }

    
    private List<JobTaskMoveAssignment> balanceActiveJobsOnHost(HostState host, List<HostState> hosts) {
        int totalTasksToMove = config.getTasksMovedFullRebalance();
        long totalBytesToMove = config.getBytesMovedFullRebalance();
        Set<String> activeJobs = findActiveJobIDs();
        List<JobTaskMoveAssignment> rv = purgeMisplacedTasks(host, 1);
        String hostID = host.getHostUuid();
        for (String jobID : activeJobs) {
            spawn.acquireJobLock();
            try {
                Job job = spawn.getJob(jobID);
                if (job != null) {
                    JobTaskItemByHostMap tasksByHost = new JobTaskItemByHostMap(hosts, config.getTasksMovedPerUnspecifiedHost(), config.getTasksMovedPerUnspecifiedHost());
                    for (JobTask task : job.getCopyOfTasks()) {
                        tasksByHost.addLiveAndReplicasForTask(task);
                    }
                    int maxPerHost = maxTasksPerHost(job, hosts.size());
                    int numExistingTasks = tasksByHost.get(hostID).size();
                    if ((tasksByHost.findLeastTasksOnHost() >= maxPerHost - 1 || tasksByHost.findMostTasksOnHost() <= maxPerHost)) {
                        continue;
                    }
                    boolean pushFrom = numExistingTasks > maxPerHost || numExistingTasks == maxPerHost && tasksByHost.findLeastTasksOnHost() < maxPerHost - 1;
                    if (totalTasksToMove > 0) {
                        MoveAssignmentList assignments = pushFrom ? moveTasksOffHost(tasksByHost, maxPerHost, 1, totalBytesToMove, host.getHostUuid())
                                                                  : moveTasksOntoHost(tasksByHost, maxPerHost, 1, totalBytesToMove, host.getHostUuid());
                        rv.addAll(assignments);
                        totalTasksToMove -= assignments.size();
                        totalBytesToMove -= assignments.getBytesUsed();
                    } else {
                        break;
                    }
                }
            } finally {
                spawn.releaseJobLock();
            }
        }
        return rv;
    }

    public long getTaskTrueSize(JobTask task) {
        return taskSizer.estimateTrueSize(task);
    }

    private static long getAvailDiskBytes(HostState host) {
        if (host.getMax() == null || host.getUsed() == null) {
            return 1; 
        }
        return host.getMax().getDisk() - host.getUsed().getDisk();
    }

    private static double getUsedDiskPercent(HostState host) {
        if (host.getMax() == null || host.getUsed() == null || host.getMax().getDisk() <= 0) {
            return 0;
        }
        return ((double) (host.getUsed().getDisk()) / host.getMax().getDisk());
    }

    
    private List<JobTaskMoveAssignment> pruneTaskReassignments(List<JobTaskMoveAssignment> candidateAssignments) {
        List<JobTaskMoveAssignment> rv = new ArrayList<>();
        HashMap<String, Boolean> snapshot = new HashMap<>(recentlyBalancedHosts.asMap());
        for (JobTaskMoveAssignment assignment : candidateAssignments) {
            String newHostID = assignment.getTargetUUID();
            JobKey jobKey = assignment.getJobKey();
            String jobID = (jobKey == null) ? null : jobKey.getJobUuid();
            if (isExtremeHost(newHostID, true, true)) {
                log.warn("[spawn.balancer] decided not to move task from job {} to host {} " +
                         "because it is already heavily loaded", jobID, newHostID);
                continue;
            }
            HostState newHost = hostManager.getHostState(newHostID);
            if (newHost == null || newHost.hasLive(jobKey) || !canReceiveNewTasks(newHost, assignment.isFromReplica())) {
                log.warn("[spawn.balancer] decided not to move task from job {} to host {} " +
                         "because it cannot receive the new task", jobID, newHostID);
                continue;
            }
            if (snapshot.containsKey(newHostID)) {
                log.warn("[spawn.balancer] decided not to move task from job {} to host {} " +
                         "because it already received a different task recently", jobID, newHostID);
                continue;
            }
            rv.add(assignment);
            recentlyBalancedHosts.put(newHostID, true);
        }
        return rv;
    }

    
    @VisibleForTesting
    protected List<HostState> sortHostsByActiveTasks(Collection<HostState> hosts) {
        List<HostState> hostList = new ArrayList<>(hosts);
        removeDownHosts(hostList);
        Collections.sort(hostList,
                         (hostState, hostState1) -> Double.compare(countTotalActiveTasksOnHost(hostState), countTotalActiveTasksOnHost(hostState1)));
        return hostList;
    }

    
    @VisibleForTesting
    protected List<HostState> sortHostsByDiskSpace(Collection<HostState> hosts) {
        List<HostState> hostList = new ArrayList<>(hosts);
        removeDownHosts(hostList);
        Collections.sort(hostList, hostStateReplicationSuitabilityComparator);
        return hostList;
    }

    private void removeDownHosts(List<HostState> hosts) {
        Iterator<HostState> hostIter = hosts.iterator();
        while (hostIter.hasNext()) {
            HostState host = hostIter.next();
            if (host.isDead() || !host.isUp()) {
                hostIter.remove();
            }
        }
    }

    
    private Map<HostState, Double> generateHostStateScoreMap(Collection<HostState> hosts, String jobID) {
        final Map<HostState, Double> hostScores = new HashMap<>(hosts.size());
        for (HostState host : hosts) {
            if (host != null && host.isUp() && !host.isDead()) {
                int siblingScore = jobID != null ? host.getTaskCount(jobID) * config.getSiblingWeight() : 0;
                double score = getHostScoreCached(host.getHostUuid()) + siblingScore;
                hostScores.put(host, score);
            }
        }
        return hostScores;
    }

    
    private Map<String, Double> generateTaskCountHostScoreMap(Job job) {
        Map<String, Double> rv = new HashMap<>();
        if (job != null) {
            List<JobTask> tasks = job.getCopyOfTasks();
            for (JobTask task : tasks) {
                rv.put(task.getHostUUID(), addOrIncrement(rv.get(task.getHostUUID()), 1d));
                if (task.getReplicas() == null) {
                    continue;
                }
                for (JobTaskReplica replica : task.getReplicas()) {
                    rv.put(replica.getHostUUID(), addOrIncrement(rv.get(replica.getHostUUID()), 1d));
                }
            }
            for (HostState host : hostManager.listHostStatus(job.getMinionType())) {
                if (host.isUp() && !host.isDead()) {
                    double availDisk = 1 - getUsedDiskPercent(host);
                    rv.put(host.getHostUuid(), addOrIncrement(rv.get(host.getHostUuid()), availDisk));
                }
            }
        }
        return rv;
    }

    private static double addOrIncrement(Double currentValue, Double value) {
        if (currentValue != null) {
            return currentValue + value;
        } else {
            return value;
        }
    }

    
    public boolean okayToAutobalance() {
        
        if (config.getAutoBalanceLevel() == 0 ||
                spawn.getSystemManager().isQuiesced() ||
                spawn.getLastQueueSize() > hostManager.listHostStatus(null).size()) {
            return false;
        }
        
        for (Job job : spawn.listJobs()) {
            if (JobState.REBALANCE.equals(job.getState())) {
                return false;
            }
        }
        return true;
    }

    
    private synchronized boolean shouldAutobalanceJob(Job job, List<HostState> hosts) {
        if (job == null || recentlyAutobalancedJobs.getIfPresent(job.getId()) != null || !JobState.IDLE.equals(job.getState())
            || job.getDontAutoBalanceMe() || job.getRunCount() < 1) {
            return false;
        }
        if (config.getAutoBalanceLevel() >= 2) {
            
            return true;
        }
        JobTaskItemByHostMap tasksByHost = generateTaskCountByHost(hosts, job.getCopyOfTasks());
        int maxPerHost = maxTasksPerHost(job, hosts.size());
        
        return tasksByHost.findLeastTasksOnHost() <= maxPerHost - 2 || tasksByHost.findMostTasksOnHost() >= maxPerHost + 1;
    }

    protected enum RebalanceType {HOST, JOB}

    protected enum RebalanceWeight {LIGHT, MEDIUM, HEAVY}

    
    public List<JobTaskMoveAssignment> getAssignmentsForAutoBalance(RebalanceType type, RebalanceWeight weight) {
        List<HostState> hosts = hostManager.getLiveHosts(null);
        switch (type) {
            case HOST:
                if (hosts.isEmpty()) {
                    return null;
                }
                List<HostState> hostsSorted = new ArrayList<>(hosts);
                Collections.sort(hostsSorted, hostStateScoreComparator);
                HostState hostToBalance = hostsSorted.get(getWeightedElementIndex(hostsSorted.size(), weight));
                return getAssignmentsToBalanceHost(hostToBalance,
                                                   hostManager.listHostStatus(hostToBalance.getMinionTypes()));
            case JOB:
                List<Job> autobalanceJobs = getJobsToAutobalance(hosts);
                if (autobalanceJobs == null || autobalanceJobs.isEmpty()) {
                    return null;
                }
                Job jobToBalance = autobalanceJobs.get(getWeightedElementIndex(autobalanceJobs.size(), weight));
                recentlyAutobalancedJobs.put(jobToBalance.getId(), true);
                return getAssignmentsForJobReallocation(jobToBalance, -1,
                                                        hostManager.listHostStatus(jobToBalance.getMinionType()));
            default:
                return null;
        }
    }

    public List<Job> getJobsToAutobalance(List<HostState> hosts) {
        List<Job> autobalanceJobs = new ArrayList<>();
        for (Job job : spawn.listJobs()) {
            if (shouldAutobalanceJob(job, hosts)) {
                autobalanceJobs.add(job);
            }
        }
        Collections.sort(autobalanceJobs, jobAverageTaskSizeComparator);
        return autobalanceJobs;
    }

    private static int getWeightedElementIndex(int numItems, RebalanceWeight weight) {
        switch (weight) {
            case LIGHT:
                return 0;
            case MEDIUM:
                return numItems / 2;
            case HEAVY:
                return numItems - 1;
            default:
                return 0;
        }
    }

    
    protected double getHostScoreCached(String hostId) {
        double defaultScore = config.getDefaultHostScore();
        if (hostId == null) {
            return defaultScore;
        }
        aggregateStatisticsLock.lock();
        try {
            if (cachedHostScores == null) {
                return defaultScore;
            }
            HostScore score = cachedHostScores.get(hostId);
            if (score != null) {
                return score.getOverallScore();
            } else {
                return defaultScore;
            }
        } finally {
            aggregateStatisticsLock.unlock();
        }
    }

    
    protected boolean hasFullDiskHost(JobTask task) {
        List<HostState> hostsToCheck = new ArrayList<>();
        hostsToCheck.add(hostManager.getHostState(task.getHostUUID()));
        if (task.getReplicas() != null) {
            for (JobTaskReplica replica : task.getReplicas()) {
                if (replica != null) {
                    hostsToCheck.add(hostManager.getHostState(replica.getHostUUID()));
                }
            }
            for (HostState host : hostsToCheck) {
                if (host != null && isDiskFull(host)) {
                    return true;
                }
            }
        }
        return false;
    }

    
    protected void removeInvalidReplicas(Job job) {
        if ((job != null) && (job.getCopyOfTasks() != null)) {
            List<JobTask> tasks = job.getCopyOfTasks();
            for (JobTask task : tasks) {
                List<JobTaskReplica> newReplicas = new ArrayList<>(job.getReplicas());
                if (task.getReplicas() != null) {
                    List<JobTaskReplica> oldReplicas = new ArrayList<>(task.getReplicas());
                    for (JobTaskReplica replica : oldReplicas) {
                        List<String> replicasSeen = new ArrayList<>();
                        String replicaHostID = replica.getHostUUID();
                        if (hostManager.getHostState(replicaHostID) == null) {
                            log.warn("[spawn.balancer] removing replica for missing host {}", replicaHostID);
                        } else if (replicaHostID.equals(task.getHostUUID()) || replicasSeen.contains(replicaHostID)) {
                            log.warn("[spawn.balancer] removing erroneous replica for {} on {}",
                                     task.getJobKey(), replicaHostID);
                        } else if (false) {
                            log.warn("[spawn.balancer] removing non-readonly replica for {} from readonly host {}",
                                     task.getJobKey(), replicaHostID);
                        } else if (!config.allowSameHostReplica() && onSameHost(replicaHostID, task.getHostUUID())) {
                            log.warn("[spawn.balancer] removing replica on same host for {}live={} replica={}",
                                     task.getJobKey(), task.getHostUUID(), replicaHostID);
                        } else {
                            replicasSeen.add(replicaHostID);
                            newReplicas.add(replica);
                        }
                    }
                }
                task.setReplicas(newReplicas);
            }
        }
    }

    private boolean onSameHost(String hostID1, String hostID2) {
        HostState host1 = hostManager.getHostState(hostID1);
        HostState host2 = hostManager.getHostState(hostID2);
        if (host1 == null || host2 == null) {
            return false;
        } else {
            return host1.getHost().equals(host2.getHost());
        }
    }

    public boolean canReceiveNewTasks(HostState host, boolean isReplica) {
        if (host == null) {
            return false;
        }
        if (spawn.getHostFailWorker().getFailureState(host.getHostUuid()) != HostFailWorker.FailState.ALIVE) {
            return false;
        }
        return host.canMirrorTasks() && getUsedDiskPercent(host) < 1 - config.getMinDiskPercentAvailToReceiveNewTasks();
    }

    
    public boolean isDiskFull(HostState host) {
        boolean full = host != null && getUsedDiskPercent(host) > 1 - config.getMinDiskPercentAvailToRunJobs();
        if (full) {
            log.warn("[spawn.balancer] Host " + host.getHost() + " with uuid " + host.getHostUuid() + " is nearly full, with used disk " + getUsedDiskPercent(host));
        }
        return full;
    }

    
    protected Map<Integer, List<String>> getAssignmentsForNewReplicas(Job job, int taskID) {
        Map<Integer, List<String>> rv = new HashMap<>();
        if (job == null) {
            return rv;
        }
        int replicaCount = job.getReplicas();
        Map<String, Double> scoreMap = generateTaskCountHostScoreMap(job);
        PriorityQueue<HostAndScore> scoreHeap = new PriorityQueue<>(1, hostAndScoreComparator);
        for (Entry<String, Double> entry : scoreMap.entrySet()) {
            scoreHeap.add(new HostAndScore(hostManager.getHostState(entry.getKey()), entry.getValue()));
        }
        Map<String, Integer> allocationMap = new HashMap<>();
        List<JobTask> tasks = taskID > 0 ? Arrays.asList(job.getTask(taskID)) : job.getCopyOfTasks();
        for (JobTask task : tasks) {
            int numExistingReplicas = (task.getReplicas() != null ? task.getReplicas().size() : 0);
            List<String> hostIDsToAdd = new ArrayList<>(replicaCount);
            
            for (int i = 0; i < replicaCount - numExistingReplicas; i++) {
                for (HostAndScore hostAndScore : scoreHeap) {
                    HostState candidateHost = hostAndScore.host;
                    if (candidateHost == null || !candidateHost.canMirrorTasks()) {
                        continue;
                    }
                    int currentCount;
                    if (allocationMap.containsKey(candidateHost.getHostUuid())) {
                        currentCount = allocationMap.get(candidateHost.getHostUuid());
                    } else {
                        currentCount = 0;
                    }

                    if (okToPutReplicaOnHost(candidateHost, task)) {
                        hostIDsToAdd.add(candidateHost.getHostUuid());
                        scoreHeap.remove(hostAndScore);
                        scoreHeap.add(new HostAndScore(candidateHost, hostAndScore.score + 1));
                        allocationMap.put(candidateHost.getHostUuid(), currentCount + 1);
                        break;
                    }
                }
            }
            if (!hostIDsToAdd.isEmpty()) {
                rv.put(task.getTaskID(), hostIDsToAdd);
            }
        }
        return rv;
    }

    public Map<Integer, List<String>> getAssignmentsForNewReplicas(Job job) {
        return getAssignmentsForNewReplicas(job, -1);
    }

    
    private boolean okToPutReplicaOnHost(HostState hostCandidate, JobTask task) {
        Job job;
        String hostId;
        if (hostCandidate == null || ((hostId = hostCandidate.getHostUuid()) == null) || !canReceiveNewTasks(hostCandidate, true) || ((job = spawn.getJob(task.getJobKey())) == null) || !hostCandidate.getMinionTypes().contains(job.getMinionType())) {
            return false;
        }
        if (spawn.getHostFailWorker().getFailureState(hostId) != HostFailWorker.FailState.ALIVE) {
            return false;
        }
        HostState taskHost = hostManager.getHostState(task.getHostUUID());
        
        String existingHost = taskHost != null ? taskHost.getHost() : null;
        
        if (!config.allowSameHostReplica() && hostCandidate.getHost().equals(existingHost)) {
            return false;
        }
        
        if (task.getHostUUID().equals(hostCandidate.getHostUuid()) || task.hasReplicaOnHost(hostCandidate.getHostUuid())) {
            return false;
        }
        
        if (taskSizer.estimateTrueSize(task) > config.getHostDiskFactor() * getAvailDiskBytes(hostCandidate)) {
            return false;
        }
        return true;
    }

    private static class HostAndScore {

        private final HostState host;
        private final double score;

        private HostAndScore(HostState host, double score) {
            this.host = host;
            this.score = score;
        }
    }

    
    private class AggregateStatUpdaterTask implements Runnable {

        @Override
        public void run() {
            if (JitterClock.globalTime() - lastAggregateStatUpdateTime > AGGREGATE_STAT_UPDATE_INTERVAL) {
                updateAggregateStatistics(hostManager.listHostStatus(null));
            }
        }
    }

    private Set<String> findActiveJobIDs() {
        aggregateStatisticsLock.lock();
        try {
            activeJobIDs = new HashSet<>();
            Collection<Job> jobs = spawn.listJobs();
            if (jobs != null && !jobs.isEmpty()) {
                for (Job job : jobs) {
                    if (isWellFormedAndActiveJob(job)) {
                        activeJobIDs.add(job.getId());
                    }
                }
            }
            return new HashSet<>(activeJobIDs);
        } finally {
            aggregateStatisticsLock.unlock();
        }

    }

    private int countTotalActiveTasksOnHost(HostState host) {
        int count = 0;
        if (host != null) {
            host.generateJobTaskCountMap();
            aggregateStatisticsLock.lock();
            try {
                if (activeJobIDs == null) {
                    activeJobIDs = findActiveJobIDs();
                }
                for (String jobID : activeJobIDs) {
                    count += host.getTaskCount(jobID);
                }
            } finally {
                aggregateStatisticsLock.unlock();
            }
        }

        return count;
    }

    
    protected void updateAggregateStatistics(List<HostState> hosts) {
        spawn.acquireJobLock();
        try {
            aggregateStatisticsLock.lock();
            try {
                lastAggregateStatUpdateTime = JitterClock.globalTime();
                findActiveJobIDs();
                double maxMeanActive = -1;
                double maxDiskPercentUsed = -1;
                for (HostState host : hosts) {
                    maxMeanActive = Math.max(maxMeanActive, host.getMeanActiveTasks());
                    maxDiskPercentUsed = Math.max(maxDiskPercentUsed, getUsedDiskPercent(host));
                }
                for (HostState host : hosts) {
                    cachedHostScores.put(host.getHostUuid(), calculateHostScore(host, maxMeanActive, maxDiskPercentUsed));
                }
            } finally {
                aggregateStatisticsLock.unlock();
            }
        } finally {
            spawn.releaseJobLock();
        }
    }

    public void requestJobSizeUpdate(String jobId, int taskId) {
        taskSizer.requestJobSizeFetch(jobId, taskId);
    }

    
    protected boolean isExtremeHost(String hostID, boolean diskSpace, boolean high) {
        aggregateStatisticsLock.lock();
        try {
            if (hostID == null || cachedHostScores == null || !cachedHostScores.containsKey(hostID) || cachedHostScores.isEmpty()) {
                return false;
            }
            double clusterAverage = 0;
            for (HostScore score : cachedHostScores.values()) {
                clusterAverage += score.getScoreValue(diskSpace);
            }
            clusterAverage /= cachedHostScores.size(); 
            double hostValue = cachedHostScores.get(hostID).getScoreValue(diskSpace);
            return ((high && hostValue > clusterAverage * config.getExtremeHostRatio()) ||
                    (!high && hostValue < clusterAverage / config.getExtremeHostRatio()));
        } finally {
            aggregateStatisticsLock.unlock();
        }

    }

    private HostScore calculateHostScore(HostState host, double clusterMaxMeanActive, double clusterMaxDiskUsed) {
        double score = 0;
        double meanActive = host.getMeanActiveTasks();
        double usedDiskPercent = getUsedDiskPercent(host);
        
        if (clusterMaxMeanActive <= 0) {
            meanActive = 1;
            clusterMaxMeanActive = 1;
        }
        if (clusterMaxDiskUsed <= 0) {
            usedDiskPercent = 1;
            clusterMaxDiskUsed = 1;
        }
        int activeTaskWeight = config.getActiveTaskWeight();
        int diskUsedWeight = config.getDiskUsedWeight();
        
        score += activeTaskWeight * Math.pow(meanActive / clusterMaxMeanActive, 2.5);
        score += diskUsedWeight * Math.pow(usedDiskPercent / clusterMaxDiskUsed, 2.5);
        
        score = Math.max(score, (activeTaskWeight + diskUsedWeight) * usedDiskPercent);
        return new HostScore(meanActive, usedDiskPercent, score);
    }

    private static class HostScore {

        private final double meanActiveTasks;
        private final double usedDiskPercent;
        private final double overallScore;

        private HostScore(double meanActiveTasks, double usedDiskPercent, double overallScore) {
            this.meanActiveTasks = meanActiveTasks;
            this.usedDiskPercent = usedDiskPercent;
            this.overallScore = overallScore;
        }

        public double getOverallScore() {
            return overallScore;
        }

        public double getScoreValue(boolean diskSpace) {
            return diskSpace ? usedDiskPercent : meanActiveTasks;
        }

    }

    private class MoveAssignmentList extends ArrayList<JobTaskMoveAssignment> {

        private long bytesUsed = 0;

        @Override
        public boolean add(JobTaskMoveAssignment assignment) {
            bytesUsed += taskSizer.estimateTrueSize(spawn.getTask(assignment.getJobKey()));
            return super.add(assignment);
        }

        public long getBytesUsed() {
            return bytesUsed;
        }
    }

    public SpawnBalancerConfig getConfig() {
        return config;
    }

    public void setConfig(SpawnBalancerConfig config) {
        this.config = config;
    }

    
    public synchronized void startAutobalanceTask() {
        if (autobalanceStarted.compareAndSet(false, true)) {
            taskExecutor.scheduleWithFixedDelay(new AutobalanceTask(), config.getAutobalanceCheckInterval(), config.getAutobalanceCheckInterval(), TimeUnit.MILLISECONDS);
        }
    }

    public void clearRecentlyRebalancedHosts() {
        recentlyBalancedHosts.invalidateAll();
    }

    
    public void fixTasksForFailedHost(List<HostState> hosts, String failedHost) {
        List<JobTask> tasks = findAllTasksAssignedToHost(failedHost);
        ArrayList<JobTask> sortedTasks = new ArrayList<>(tasks);
        Collections.sort(sortedTasks,
                         (o1, o2) -> Long.compare(taskSizer.estimateTrueSize(o1), taskSizer.estimateTrueSize(o2)));
        hosts = sortHostsByDiskSpace(hosts);
        HashSet<String> modifiedJobIds = new HashSet<>();
        for (JobTask task : sortedTasks) {
            modifiedJobIds.add(task.getJobUUID());
            try {
                attemptFixTaskForFailedHost(task, hosts, failedHost);
            } catch (Exception ex) {
                log.warn("Warning: failed to recover task " + task.getJobKey() + ": " + ex, ex);
                }
        }
        for (String jobId : modifiedJobIds) {
            try {
                spawn.updateJob(spawn.getJob(jobId));
            } catch (Exception e) {
                log.warn("Warning: failed to update job " + jobId + ": " + e, e);
            }
        }
    }

    private List<JobTask> findAllTasksAssignedToHost(String failedHostUUID) {
        List<JobTask> rv = new ArrayList<>();
        spawn.acquireJobLock();
        try {
            for (Job job : spawn.listJobs()) {
                if (job != null) {
                    for (JobTask task : job.getCopyOfTasks()) {
                        if (task != null && (task.getHostUUID().equals(failedHostUUID) || task.hasReplicaOnHost(failedHostUUID))) {
                            rv.add(task);
                        }
                    }
                }
            }
            return rv;
        } finally {
            spawn.releaseJobLock();
        }
    }

    
    private void attemptFixTaskForFailedHost(JobTask task, List<HostState> hosts, String failedHostUuid) {
        Iterator<HostState> hostIterator = hosts.iterator();
        Job job;
        if (task == null || task.getJobUUID() == null || (job = spawn.getJob(task.getJobUUID())) == null) {
            log.warn("Skipping nonexistent job for task " + task + " during host fail.");
            return;
        }
        if (!task.getHostUUID().equals(failedHostUuid) && !task.hasReplicaOnHost(failedHostUuid)) {
            
            return;
        }
        if (!spawn.isNewTask(task) && (task.getReplicas() == null || task.getReplicas().isEmpty())) {
            log.warn("Found no replica for task " + task.getJobKey());
            job.setState(JobState.DEGRADED, true);
            return;
        }
        while (hostIterator.hasNext()) {
            HostState host = hostIterator.next();
            if (host.getHostUuid().equals(failedHostUuid)) {
                continue;
            }
            if (host.canMirrorTasks() && okToPutReplicaOnHost(host, task)) {
                
                hostIterator.remove();
                hosts.add(host);
                executeHostFailureRecovery(task, failedHostUuid, host);
                return;
            }
        }
        log.warn("Failed to find a host that could hold " + task.getJobKey() + " after host failure");
        job.setState(JobState.DEGRADED, true);
    }

    
    private void executeHostFailureRecovery(JobTask task, String failedHostUuid, HostState newReplicaHost) {
        boolean liveOnFailedHost = task.getHostUUID().equals(failedHostUuid);
        String newReplicaUuid = newReplicaHost.getHostUuid();
        if (liveOnFailedHost) {
            if (spawn.isNewTask(task)) {
                
                task.setHostUUID(newReplicaHost.getHostUuid());
            } else {
                
                spawn.sendControlMessage(new CommandTaskStop(failedHostUuid, task.getJobUUID(), task.getTaskID(), 0, true, false));
                
                String chosenReplica = task.getReplicas().get(0).getHostUUID();
                task.replaceReplica(chosenReplica, newReplicaUuid);
                task.setHostUUID(chosenReplica);
                spawn.replicateTask(task, Arrays.asList(newReplicaUuid));
            }
        } else {
            
            task.replaceReplica(failedHostUuid, newReplicaUuid);
            if (!spawn.isNewTask(task)) {
                spawn.replicateTask(task, Arrays.asList(newReplicaUuid));
            }
        }
    }

    
    private class AutobalanceTask implements Runnable {

        private long lastJobAutobalanceTime = 0L;
        private long lastHostAutobalanceTime = 0L;
        private int numHostRebalances = 0;

        @Override
        public void run() {
            long now = System.currentTimeMillis();
            
            if (okayToAutobalance()) {
                if (now - lastHostAutobalanceTime > config.getHostAutobalanceIntervalMillis()) {
                    numHostRebalances++;
                    log.warn("Performing host autobalance.");
                    RebalanceWeight weight = numHostRebalances % 2 == 0 ? RebalanceWeight.HEAVY : RebalanceWeight.LIGHT;
                    spawn.executeReallocationAssignments(getAssignmentsForAutoBalance(RebalanceType.HOST, weight), false);
                    lastHostAutobalanceTime = now;
                } else if (now - lastJobAutobalanceTime > config.getJobAutobalanceIntervalMillis()) {
                    log.warn("Performing job autobalance.");
                    spawn.executeReallocationAssignments(getAssignmentsForAutoBalance(RebalanceType.JOB, RebalanceWeight.HEAVY), false);
                    lastJobAutobalanceTime = now;
                }
            }
        }
    }
}

<code block>

package com.addthis.hydra.job.spawn;

import java.util.LinkedHashMap;
import java.util.Map;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

import com.addthis.basis.net.HttpUtil;
import com.addthis.basis.util.Parameter;

import com.addthis.hydra.job.Job;
import com.addthis.hydra.job.JobTask;
import com.addthis.hydra.job.mq.HostState;

import com.google.common.cache.Cache;
import com.google.common.cache.CacheBuilder;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


public class SpawnBalancerTaskSizer {
    private static final Logger log = LoggerFactory.getLogger(SpawnBalancerTaskSizer.class);

    private static final double defaultRatio = Double.parseDouble(Parameter.value("spawn.balancer.task.sizer.defaultratio", "1.5"));
    private static final double maxRatio = Double.parseDouble(Parameter.value("spawn.balancer.task.sizer.maxratio", "10.0"));
    private static final double minRatio = Double.parseDouble(
            Parameter.value("spawn.balancer.task.sizer.minratio", "1.0"));
    private static final long queueConsumptionInterval = Parameter.longValue("spawn.balancer.task.sizer.interval",
                                                                             60 * 1000);
    private static final int ratioExpirationHours = Parameter.intValue("spawn.balancer.task.sizer.ratio.expire", 12);

    private static final AtomicBoolean pollingStarted = new AtomicBoolean(false);

    private final Spawn spawn;
    private final HostManager hostManager;
    private final LinkedHashMap<String, Integer> queuedJobIds;
    private final Cache<String, Double> cachedJobRatios;

    public SpawnBalancerTaskSizer(Spawn spawn, HostManager hostManager) {
        queuedJobIds = new LinkedHashMap<>();
        cachedJobRatios = CacheBuilder.newBuilder().expireAfterWrite(ratioExpirationHours, TimeUnit.HOURS).build();
        this.spawn = spawn;
        this.hostManager = hostManager;
    }

    public void startPolling(ScheduledExecutorService executor) {
        if (pollingStarted.compareAndSet(false, true)) {
            executor.scheduleWithFixedDelay(new QueueConsumer(), queueConsumptionInterval, queueConsumptionInterval, TimeUnit.MILLISECONDS);
        }
    }

    
    public long estimateTrueSize(JobTask task) {
        if (task == null) {
            return 0L;
        }
        long taskReportedSize = getReportedSize(task);
        Double cachedRatio = cachedJobRatios.getIfPresent(task.getJobUUID());
        if (cachedRatio == null) {
            requestJobSizeFetch(task.getJobUUID(), task.getTaskID());
            return (long) (defaultRatio * taskReportedSize);
        }
        return (long) (cachedRatio * taskReportedSize);
    }

    private long getReportedSize(JobTask task) {
        
        long byteCount = task != null ? task.getByteCount() : 0;
        if (task == null || byteCount > 0) {
            return byteCount;
        }
        Job job = spawn.getJob(task.getJobUUID());
        if (job != null) {
            return job.calcAverageTaskSizeBytes();
        }
        return byteCount;
    }

    public void requestJobSizeFetch(String jobId, int taskId) {
        synchronized (queuedJobIds) {
            if (cachedJobRatios.getIfPresent(jobId) != null || queuedJobIds.containsKey(jobId)) {
                return;
            }
            queuedJobIds.put(jobId, taskId);
        }
    }

    
    private long fetchTaskTrueSize(String jobId, int taskId) {
        JobTask task = spawn.getTask(jobId, taskId);
        if (task == null) {
            return -1;
        }
        HostState liveHost = hostManager.getHostState(task.getHostUUID());
        if (liveHost == null) {
            return -1;
        }
        String url = "http:
        try {
            byte[] result = HttpUtil.httpGet(url, 0).getBody();
            return Long.parseLong(new String(result));
        } catch (Exception e) {
            log.warn("Failed to fetch task size for " + task.getJobKey());
        }
        return -1;
    }

    
    private void consumeFromQueue() {
        String jobId;
        int taskId;
        synchronized (queuedJobIds) {
            if (queuedJobIds.isEmpty()) {
                return;
            }
            Map.Entry<String, Integer> entry = queuedJobIds.entrySet().iterator().next();
            queuedJobIds.remove(entry.getKey());
            jobId = entry.getKey();
            taskId = entry.getValue();
        }
        long trueSize = fetchTaskTrueSize(jobId, taskId);
        long reportedSize = getReportedSize(spawn.getTask(jobId, taskId));
        double ratio = getRatio(trueSize, reportedSize);
        log.info("[spawn.balancer.task.sizer] updated ratio for job " + jobId + " reported=" + reportedSize + " true=" + trueSize + " ratio=" + ratio);
        cachedJobRatios.put(jobId, ratio);
    }

    
    private static double getRatio(long trueSize, long reportedSize) {
        if (trueSize <= 0 || reportedSize <= 0) {
            return defaultRatio;
        }
        double rawRatio = (double) trueSize / reportedSize;
        return Math.max(minRatio, Math.min(rawRatio, maxRatio));
    }

    
    private class QueueConsumer implements Runnable {

        @Override
        public void run() {
            try {
                consumeFromQueue();
            } catch (Exception e) {
                log.warn("Failed to consume from TaskSizer queue: " + e, e);
                }
        }
    }
}

<code block>

package com.addthis.hydra.job.spawn;

import java.io.File;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashSet;
import java.util.List;
import java.util.Map;

import com.addthis.basis.test.SlowTest;
import com.addthis.basis.util.LessFiles;
import com.addthis.basis.util.JitterClock;

import com.addthis.codec.config.Configs;
import com.addthis.hydra.job.Job;
import com.addthis.hydra.job.JobParameter;
import com.addthis.hydra.job.JobTask;
import com.addthis.hydra.job.JobTaskMoveAssignment;
import com.addthis.hydra.job.JobTaskReplica;
import com.addthis.hydra.job.JobTaskState;
import com.addthis.hydra.job.entity.JobCommand;
import com.addthis.hydra.minion.Minion;
import com.addthis.hydra.job.mq.HostCapacity;
import com.addthis.hydra.job.mq.HostState;
import com.addthis.hydra.job.mq.JobKey;
import com.addthis.hydra.util.ZkCodecStartUtil;

import org.apache.zookeeper.CreateMode;

import org.junit.After;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.mockito.Mockito;

import static org.junit.Assert.assertArrayEquals;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;

@Category(SlowTest.class)
public class SpawnBalancerTest extends ZkCodecStartUtil {

    private Spawn spawn;
    private HostManager hostManager;
    private SpawnBalancer bal;
    private long now = JitterClock.globalTime();
    private String tmpRoot;

    @Before
    public void setup() throws Exception {

        tmpRoot = LessFiles.createTempDir().toString();
        System.setProperty("SPAWN_DATA_DIR", tmpRoot + "/tmp/spawn/data");
        System.setProperty("SPAWN_LOG_DIR", tmpRoot + "/tmp/spawn/log/events");
        if (zkClient.checkExists().forPath("/minion/up") == null) {
            zkClient.create().creatingParentsIfNeeded().forPath("/minon/up");
        }
        if (zkClient.checkExists().forPath("/minion/dead") == null) {
            zkClient.create().creatingParentsIfNeeded().forPath("/minon/dead");
        }
        try {
            Thread.sleep(100);
            spawn = Configs.newDefault(Spawn.class);
            hostManager = spawn.hostManager;
            bal = spawn.getSpawnBalancer();
            spawn.setSpawnMQ(Mockito.mock(SpawnMQ.class));
        } catch (Exception ex) {
        }
    }

    @After
    public void clear() throws Exception {
        if (zkClient.checkExists().forPath("/minion/up") != null) {
            zkClient.delete().forPath("/minon/up");
        }
        if (zkClient.checkExists().forPath("/minion/dead") != null) {
            zkClient.delete().forPath("/minon/dead");
        }
        LessFiles.deleteDir(new File(tmpRoot));
        spawn.close();
    }
    
    @Test
    public void saveLoadConfig() {
        SpawnBalancerConfig config = new SpawnBalancerConfig();
        config.setBytesMovedFullRebalance(123456);
        bal.saveConfigToDataStore();
        SpawnBalancerConfig loadedConfig = bal.loadConfigFromDataStore(null);
        assertNotNull("not null", loadedConfig);
        assertEquals("correct value saved/loaded", 123456, loadedConfig.getBytesMovedFullRebalance());
    }

    @Test
    public void replicaSuitabilityTest() throws Exception {
        List<HostState> hosts = new ArrayList<>();
        int numHosts = 8;
        for (int i = 0; i < numHosts; i++) {
            HostState nextHost = new HostState("id" + i);
            nextHost.setUsed(new HostCapacity(0, 0, 0, i));
            nextHost.setMax(new HostCapacity(0, 0, 0, 2 * numHosts));
            nextHost.setUp(true);
            hosts.add(nextHost);
        }
        bal.markRecentlyReplicatedTo("id4");
        hosts = bal.sortHostsByDiskSpace(hosts);
        assertEquals("should get lightest host first", "id0", hosts.get(0).getHostUuid());
        assertEquals("should get heaviest host second to last", "id" + (numHosts - 1), hosts.get(numHosts - 2).getHostUuid());
        assertEquals("should get recently-replicated-to host last", "id4", hosts.get(numHosts - 1).getHostUuid());
    }

    @Test
    public void replicaAllocationTest() throws Exception {
        
        
        String fullHostID = "full";
        HostState fullHost = installHostStateWithUUID(fullHostID, spawn, true);
        fullHost.setUsed(new HostCapacity(0, 0, 0, 9998));
        fullHost.setMax(new HostCapacity(0, 0, 0, 10_000));
        int numLightHosts = 9;
        ArrayList<String> hostIDs = new ArrayList<>(numLightHosts + 1);
        hostIDs.add(fullHostID);
        for (int i = 0; i < numLightHosts; i++) {
            String hostID = "light" + i;
            hostIDs.add(hostID);
            HostState lightHost = installHostStateWithUUID(hostID, spawn, true);
            lightHost.setUsed(new HostCapacity(0, 0, 0, 30));
            lightHost.setMax(new HostCapacity(0, 0, 0, 10_000));
        }
        Job job = createJobAndUpdateHosts(spawn, numLightHosts + 1, hostIDs, now, 1000, 0);
        job.setReplicas(1);
        Map<Integer, List<String>> assignments = bal.getAssignmentsForNewReplicas(job);
        HashSet<String> usedHosts = new HashSet<>(numLightHosts);
        for (List<String> targets : assignments.values()) {
            assertEquals("should make one replica per task", 1, targets.size());
            assertTrue("should not put replicas on full host", !targets.contains(fullHostID));
            usedHosts.addAll(targets);
        }
        assertTrue("should use many light hosts", numLightHosts > .75 * usedHosts.size());
    }

    @Test
    public void sortHostsTest() throws Exception {
        
        
        
        
        
        
        
        

        String readOnlyHostID = "read_only_host";
        HostState readOnlyHost = installHostStateWithUUID(readOnlyHostID, spawn, true, false, 0, "default");

        String downHostID = "down_host";
        HostState downHost = installHostStateWithUUID(downHostID, spawn, false);

        String deadHostID = "dead_host";
        HostState deadHost = installHostStateWithUUID(deadHostID, spawn, false);
        deadHost.setDead(true);

        String emptyHostID = "empty_host";
        HostState emptyHost = installHostStateWithUUID(emptyHostID, spawn, true);

        String oneOldOneNewHostID = "1old1new";
        HostState oldNewHost = installHostStateWithUUID(oneOldOneNewHostID, spawn, true);

        Job oldJob = createSpawnJob(spawn, 1, Arrays.asList(oneOldOneNewHostID), 0l, 1, 0);
        Job newJob1 = createSpawnJob(spawn, 1, Arrays.asList(oneOldOneNewHostID), now, 1, 0);
        oldNewHost.setStopped(simulateJobKeys(oldJob, newJob1));

        String twoNewHostID = "2new";
        HostState twoNewHost = installHostStateWithUUID(twoNewHostID, spawn, true);
        Job newJob2 = createSpawnJob(spawn, 1, Arrays.asList(twoNewHostID), now, 1, 0);
        Job newJob3 = createSpawnJob(spawn, 1, Arrays.asList(twoNewHostID), now, 1, 0);
        twoNewHost.setStopped(simulateJobKeys(newJob2, newJob3));

        List<HostState> hosts = Arrays.asList(downHost, deadHost, oldNewHost, twoNewHost, emptyHost);
        HostState[] desiredOrder = new HostState[]{emptyHost, oldNewHost, twoNewHost};
        List<HostState> sortedHosts = bal.sortHostsByActiveTasks(hosts);
        assertEquals("shouldn't include read only", false, sortedHosts.contains(readOnlyHost));
        assertEquals("shouldn't include down host", false, sortedHosts.contains(downHost));
        assertEquals("shouldn't include dead host", false, sortedHosts.contains(deadHost));
        assertEquals("three hosts should make it through the sort", 3, sortedHosts.size());
        assertArrayEquals("hosts should be in order [empty, old, new]", desiredOrder, sortedHosts.toArray());
    }

    @Test
    public void allocateTasksAcrossHostsTest() throws Exception {
        
        String firstHostUUID = "first";
        String secondHostUUID = "second";
        String thirdHostUUID = "third";
        installHostStateWithUUID(firstHostUUID, spawn, true);
        installHostStateWithUUID(secondHostUUID, spawn, true);
        installHostStateWithUUID(thirdHostUUID, spawn, true);
        spawn.getJobCommandManager().putEntity("foo", new JobCommand(), false);
        int numTasks = 15;
        Job job = createJobAndUpdateHosts(spawn, numTasks, Arrays.asList(firstHostUUID, secondHostUUID, thirdHostUUID), now, 1, 0);
        assertEquals("should divide tasks evenly", numTasks / 3, numTasksOnHost(job, firstHostUUID));
        assertEquals("should divide tasks evenly", numTasks / 3, numTasksOnHost(job, secondHostUUID));
        assertEquals("should divide tasks evenly", numTasks / 3, numTasksOnHost(job, thirdHostUUID));
    }

    @Test
    public void multiHostJobReallocationTaskSelectionTest() throws Exception {
        
        
        String heavyHostUUID = "heavy";
        String lightHost1UUID = "light1";
        String lightHost2UUID = "light2";
        HostState heavyHost = installHostStateWithUUID(heavyHostUUID, spawn, true);
        HostState lightHost1 = installHostStateWithUUID(lightHost1UUID, spawn, true);
        HostState lightHost2 = installHostStateWithUUID(lightHost2UUID, spawn, true);
        List<HostState> hosts = Arrays.asList(heavyHost, lightHost1, lightHost2);
        Job smallJob = createJobAndUpdateHosts(spawn, 6, Arrays.asList(heavyHostUUID), now, 1000, 0);
        List<JobTaskMoveAssignment> assignments = bal.getAssignmentsForJobReallocation(smallJob, -1, hosts);
        assertEquals("should move 4 tasks total for small job", 4, assignments.size());
        List<String> assignedHosts = new ArrayList<>();
        for (JobTaskMoveAssignment assignment : assignments) {
            assignedHosts.add(assignment.getTargetUUID());
        }
        Collections.sort(assignedHosts);
        assertArrayEquals("should move two tasks to each host",
                new String[]{lightHost1UUID, lightHost1UUID, lightHost2UUID, lightHost2UUID}, assignedHosts.toArray());
        Job job2 = createJobAndUpdateHosts(spawn, 6, Arrays.asList(heavyHostUUID, lightHost1UUID, lightHost2UUID), now, 1000, 0);
        String brandNewHostUUID = "brandnew";
        HostState brandNewHost = installHostStateWithUUID(brandNewHostUUID, spawn, true);
        List<HostState> newHosts = Arrays.asList(heavyHost, lightHost1, lightHost2, brandNewHost);
        bal.updateAggregateStatistics(newHosts);
        List<JobTaskMoveAssignment> assignments2 = bal.getAssignmentsForJobReallocation(job2, -1, newHosts);
        assertEquals("should move one task", 1, assignments2.size());
        assertEquals("should move a task to the new host", brandNewHostUUID, assignments2.get(0).getTargetUUID());
    }

    @Test
    public void assignMoreTasksToLighterHostsTest() throws Exception {
        
        
        String heavyHostUUID = "heavy";
        String lightHost1UUID = "light1";
        String lightHost2UUID = "light2";
        HostState heavyHost = installHostStateWithUUID(heavyHostUUID, spawn, true);
        HostState lightHost1 = installHostStateWithUUID(lightHost1UUID, spawn, true);
        HostState lightHost2 = installHostStateWithUUID(lightHost2UUID, spawn, true);
        Job weightJob = createJobAndUpdateHosts(spawn, 10, Arrays.asList(heavyHostUUID), now, 1000, 0);
        bal.updateAggregateStatistics(hostManager.listHostStatus(null));
        Job otherJob = createJobAndUpdateHosts(spawn, 5, Arrays.asList(heavyHostUUID, lightHost1UUID, lightHost2UUID), now, 500, 0);
        assertEquals("should put two tasks on lightHost1", 2, numTasksOnHost(otherJob, lightHost1UUID));
        assertEquals("should put two tasks on lightHost2", 2, numTasksOnHost(otherJob, lightHost2UUID));
        assertEquals("should put one task on heavyHost", 1, numTasksOnHost(otherJob, heavyHostUUID));
    }

    @Test
    public void multiJobHostReallocationTaskSelectionTest() throws Exception {
        
        
        String heavyHostUUID = "heavy";
        String lightHostUUID = "light";
        HostState heavyHost = installHostStateWithUUID(heavyHostUUID, spawn, true);
        HostState lightHost = installHostStateWithUUID(lightHostUUID, spawn, true);
        spawn.getJobCommandManager().putEntity("foo", new JobCommand(), false);
        int numTasks = 3;
        Job job1 = createJobAndUpdateHosts(spawn, numTasks, Arrays.asList(heavyHostUUID), now, 1, 0);
        Job job2 = createJobAndUpdateHosts(spawn, numTasks, Arrays.asList(heavyHostUUID), now, 1, 0);
        bal.updateAggregateStatistics(hostManager.listHostStatus(null));
        List<HostState> hosts = Arrays.asList(heavyHost, lightHost);
        List<JobTaskMoveAssignment> heavyHostTaskAssignments = bal.getAssignmentsToBalanceHost(heavyHost, hosts);
        assertEquals("should move 2 tasks", 2, heavyHostTaskAssignments.size());
        for (JobTaskMoveAssignment assignment : heavyHostTaskAssignments) {
            assertEquals("should move task from heavy host", heavyHostUUID, assignment.getSourceUUID());
            assertEquals("should move task to light host", lightHostUUID, assignment.getTargetUUID());
        }
        bal.clearRecentlyRebalancedHosts();
        List<JobTaskMoveAssignment> lightHostTaskAssignments = bal.getAssignmentsToBalanceHost(lightHost, hosts);
        assertEquals("should move 2 tasks", 2, lightHostTaskAssignments.size());
        for (JobTaskMoveAssignment assignment : lightHostTaskAssignments) {
            assertEquals("should move task from heavy host", heavyHostUUID, assignment.getSourceUUID());
            assertEquals("should move task to light host", lightHostUUID, assignment.getTargetUUID());
        }
    }

    @Test
    public void diskSpaceBalancingTest() throws Exception {
        
        
        String heavyHostUUID = "heavy";
        String lightHostUUID = "light";
        String lightHost2UUID = "light2";
        String readOnlyHostUUID = "readOnlyHost";
        HostState heavyHost = installHostStateWithUUID(heavyHostUUID, spawn, true);
        HostState lightHost = installHostStateWithUUID(lightHostUUID, spawn, true);
        HostState lightHost2 = installHostStateWithUUID(lightHost2UUID, spawn, true);
        HostState readOnlyHost = installHostStateWithUUID(readOnlyHostUUID, spawn, true, true, 0, "default");
        List<HostState> hosts = Arrays.asList(heavyHost, lightHost, lightHost2, readOnlyHost);
        spawn.getJobCommandManager().putEntity("foo", new JobCommand(), false);
        Job gargantuanJob = createSpawnJob(spawn, 1, Arrays.asList(heavyHostUUID), now, 8_000_000_000l, 0);
        Job movableJob1 = createSpawnJob(spawn, 1, Arrays.asList(heavyHostUUID), now, 850_000_000l, 0);
        Job movableJob2 = createSpawnJob(spawn, 1, Arrays.asList(heavyHostUUID), now, 820_000_000l, 0);
        heavyHost.setStopped(simulateJobKeys(gargantuanJob, movableJob1, movableJob2));
        heavyHost.setMax(new HostCapacity(10, 10, 10, 10_000_000_000l));
        heavyHost.setUsed(new HostCapacity(10, 10, 10, 9_900_000_000l));
        lightHost.setMax(new HostCapacity(10, 10, 10, 10_000_000_000l));
        lightHost.setUsed(new HostCapacity(10, 10, 10, 20_000_0000l));
        lightHost2.setMax(new HostCapacity(10, 10, 10, 10_000_000_000l));
        lightHost2.setUsed(new HostCapacity(10, 10, 10, 20_000_000l));
        readOnlyHost.setMax(new HostCapacity(10, 10, 10, 10_000_000_000l));
        readOnlyHost.setUsed(new HostCapacity(10, 10, 10, 20_000_000l));
        hostManager.updateHostState(heavyHost);
        hostManager.updateHostState(lightHost);
        hostManager.updateHostState(lightHost2);
        hostManager.updateHostState(readOnlyHost);
        bal.updateAggregateStatistics(hostManager.listHostStatus(null));
        List<JobTaskMoveAssignment> assignments = bal.getAssignmentsToBalanceHost(heavyHost, hosts);
        long bytesMoved = 0;
        for (JobTaskMoveAssignment assignment : assignments) {
            assertTrue("shouldn't move gargantuan task", !assignment.getJobKey().getJobUuid().equals(gargantuanJob.getId()));
            assertTrue("shouldn't move to read-only host", !(assignment.getTargetUUID().equals(readOnlyHostUUID)));
        }
        assertTrue("should move something", !assignments.isEmpty());
    }

    @Test
    public void dontDoPointlessMovesTest() throws Exception {
        
        int numHosts = 3;
        List<HostState> hosts = new ArrayList<>(numHosts);
        List<String> hostNames = new ArrayList<>(numHosts);
        for (int i = 0; i < numHosts; i++) {
            String hostName = "host" + i;
            hostNames.add(hostName);
            hosts.add(installHostStateWithUUID(hostName, spawn, true));
        }
        Job job1 = createJobAndUpdateHosts(spawn, numHosts, hostNames, now, 1000, 0);
        Job job2 = createJobAndUpdateHosts(spawn, numHosts - 1, hostNames, now, 1000, 0);
        for (HostState host : hosts) {
            assertEquals("shouldn't move anything for " + host.getHostUuid(), 0,
                    bal.getAssignmentsToBalanceHost(host, hosts).size());
        }
        assertEquals("shouldn't move anything for " + job1.getId(), 0,
                bal.getAssignmentsForJobReallocation(job1, -1, hosts).size());
        assertEquals("shouldn't move anything for " + job2.getId(), 0,
                bal.getAssignmentsForJobReallocation(job2, -1, hosts).size());

    }

    @Test
    public void kickOnSuitableHosts() throws Exception {
        String availHostID = "host2";
        HostState avail = installHostStateWithUUID(availHostID, spawn, true, false, 1, "default");
        assertTrue("available host should be able to run task", avail.canMirrorTasks());
    }

    @Ignore("Alwawys fail")
    @Test
    public void queuePersist() throws Exception {
        spawn.getJobCommandManager().putEntity("foo", new JobCommand(), false);
        spawn.getSystemManager().quiesceCluster(true, "unknown");
        installHostStateWithUUID("host", spawn, true);
        Job job = createJobAndUpdateHosts(spawn, 4, Arrays.asList("host"), now, 1000, 0);
        JobKey myKey = new JobKey(job.getId(), 0);
        spawn.addToTaskQueue(myKey, 0, false);
        spawn.writeSpawnQueue();
        
        try (Spawn spawn2 = Configs.newDefault(Spawn.class)) {
            spawn2.getSystemManager().quiesceCluster(true, "unknown");
            spawn2.loadSpawnQueue();
            assertEquals("should have one queued task", 1, spawn.getTaskQueuedCount());
        }
    }

    @Test
    public void multipleMinionsPerHostReplicaTest() throws Exception {
        bal.getConfig().setAllowSameHostReplica(true);
        HostState host1m1 = installHostStateWithUUID("m1", spawn, true);
        host1m1.setHost("h1");
        hostManager.updateHostState(host1m1);
        HostState host1m2 = installHostStateWithUUID("m2", spawn, true);
        host1m2.setHost("h1");
        hostManager.updateHostState(host1m2);
        Job job = createJobAndUpdateHosts(spawn, 1, Arrays.asList("m1", "m2"), now, 1000, 0);
        job.setReplicas(1);
        spawn.updateJob(job);
        assertEquals("should get one replica when we allow same host replicas", 1, spawn.getTask(job.getId(), 0).getAllReplicas().size(), 1);
        bal.getConfig().setAllowSameHostReplica(false);
        spawn.updateJob(job);
        assertEquals("should get no replicas when we disallow same host replicas", 0, spawn.getTask(job.getId(), 0).getAllReplicas().size());
    }

    @Test
    public void rebalanceOntoNewHostsTest() throws Exception {
        
        
        spawn.setSpawnMQ(Mockito.mock(SpawnMQ.class));
        bal.getConfig().setAllowSameHostReplica(true);
        ArrayList<String> hosts = new ArrayList<>();
        for (int i = 0; i < 8; i++) {
            installHostStateWithUUID("h" + i, spawn, true);
            hosts.add("h" + i);
        }
        Job myJob = createJobAndUpdateHosts(spawn, 20, hosts, JitterClock.globalTime(), 2000l, 0);
        installHostStateWithUUID("hNEW1", spawn, true);
        installHostStateWithUUID("hNEW2", spawn, true);
        int tries = 50;
        while (spawn.listAvailableHostIds().size() < 10 && tries-- > 0) {
            
            Thread.sleep(100);
        }
        List<HostState> hostStates = hostManager.listHostStatus(null);
        bal.updateAggregateStatistics(hostStates);
        List<JobTaskMoveAssignment> assignments = bal.getAssignmentsForJobReallocation(myJob, -1, hostStates);
        int h1count = 0;
        int h2count = 0;
        for (JobTaskMoveAssignment assignment : assignments) {
            if (assignment.getTargetUUID().equals("hNEW1")) {
                h1count++;
            } else if (assignment.getTargetUUID().equals("hNEW2")) {
                h2count++;
            } else {
                throw new RuntimeException("should not push anything onto host " + assignment.getTargetUUID());
            }
        }
        assertTrue("should move tasks onto first new host", h1count > 1);
        assertTrue("should move tasks onto second new host", h2count > 1);

    }

    @Test
    public void hostScoreTest() throws Exception {
        
        
        long[] used = new long[]{1000, 9900, 10000, 10500, 20000};
        int i = 0;
        for (long usedVal : used) {
            HostState hostState = installHostStateWithUUID("host" + (i++), spawn, true);
            hostState.setUsed(new HostCapacity(0, 0, 0, usedVal));
            hostState.setMax(new HostCapacity(0, 0, 0, 25000));
        }
        bal.updateAggregateStatistics(hostManager.listHostStatus(null));
        assertTrue("should correctly identify light host", bal.isExtremeHost("host0", true, false));
        assertTrue("should not identify light host as heavy", !bal.isExtremeHost("host0", true, true));
        assertTrue("should not identify medium host as light", !bal.isExtremeHost("host1", true, false));
        assertTrue("should not identify medium host as heavy", !bal.isExtremeHost("host1", true, true));
        assertTrue("should correctly identify heavy host", bal.isExtremeHost("host4", true, true));
        assertTrue("should not identify heavy host as light", !bal.isExtremeHost("host4", true, false));
    }

    @Test
    public void jobStateChangeTest() throws Exception
    {
        
        List<String> hosts = Arrays.asList("h1", "h2", "h3");
        for (String host : hosts)
        {
            installHostStateWithUUID(host, spawn, true);
        }
        spawn.getJobCommandManager().putEntity("a", new JobCommand(), true);
        Job job = spawn.createJob("fsm", 3, hosts, "default", "a", false);
        JobTask task0 = job.getTask(0);
        JobTask task1 = job.getTask(1);
        job.setTaskState(task0, JobTaskState.BUSY);
        
        assertTrue("job should not be finished", !job.isFinished());
        job.setTaskState(task0, JobTaskState.IDLE);
        assertTrue("job should be finished", job.isFinished());
        job.setTaskState(task1, JobTaskState.MIGRATING, true);
        
        assertTrue("job should not be finished", !job.isFinished());
        job.setTaskState(task1, JobTaskState.IDLE, true);
        job.setTaskState(task0, JobTaskState.REBALANCE);
        
        
        assertTrue("job should be finished", job.isFinished());
    }

    @Test
    public void jobDependencyTest() throws Exception {
        installHostStateWithUUID("a", spawn, true);
        installHostStateWithUUID("b", spawn, true);
        Job sourceJob = createSpawnJob(spawn, 1, Arrays.asList("a", "b"), 1l, 1l, 0);
        Job downstreamJob = createSpawnJob(spawn, 1, Arrays.asList("a", "b"), 1l, 1l, 0);
        downstreamJob.setParameters(Arrays.asList(new JobParameter("param", sourceJob.getId(), "DEFAULT")));
        spawn.updateJob(downstreamJob);
        assertEquals("dependency graph should have two nodes", 2, spawn.getJobDependencies().getNodes().size());
    }

    private Job createSpawnJob(Spawn spawn, int numTasks, List<String> hosts, long startTime, long taskSizeBytes, int numReplicas) throws Exception {

        Job job = spawn.createJob("fsm", numTasks, hosts, Minion.defaultMinionType, "foo", false);
        job.setReplicas(numReplicas);
        for (JobTask task : job.getCopyOfTasks()) {
            task.setByteCount(taskSizeBytes);
        }
        job.setStartTime(startTime);
        return job;
    }

    private Job createJobAndUpdateHosts(Spawn spawn, int numTasks, List<String> hosts, long startTime, long taskSizeBytes, int numReplicas) throws Exception {
        Job job = createSpawnJob(spawn, numTasks, hosts, startTime, taskSizeBytes, numReplicas);
        spawn.updateJob(job);
        for (JobTask task : job.getCopyOfTasks()) {
            task.setFileCount(1L);
            HostState host = hostManager.getHostState(task.getHostUUID());
            host.setStopped(updateJobKeyArray(host.getStopped(), task.getJobKey()));
            host.setMeanActiveTasks(1);
            hostManager.updateHostState(host);
            if (task.getReplicas() != null) {
                for (JobTaskReplica replica : task.getReplicas()) {
                    HostState rHost = hostManager.getHostState(replica.getHostUUID());
                    rHost.setStopped(updateJobKeyArray(rHost.getStopped(), task.getJobKey()));
                    hostManager.updateHostState(host);
                }
            }
        }
        return job;
    }

    private JobKey[] updateJobKeyArray(JobKey[] keys, JobKey newKey) {
        List<JobKey> keyList = keys == null ? new ArrayList<>() : new ArrayList<>(Arrays.asList(keys));
        keyList.add(newKey);
        return keyList.toArray(new JobKey[]{});
    }

    private int numTasksOnHost(Job job, String hostID) {
        int count = 0;
        for (JobTask task : job.getCopyOfTasks()) {
            if (task.getHostUUID().equals(hostID)) count++;
        }
        return count;
    }

    private JobKey[] simulateJobKeys(Job... jobs) {
        ArrayList<JobKey> keyList = new ArrayList<>();
        JobKey[] sampleArray = {new JobKey("", 0)};
        for (Job job : jobs) {
            for (int i = 0; i < job.getCopyOfTasks().size(); i++) {
                keyList.add(new JobKey(job.getId(), i));
            }
        }
        return keyList.toArray(sampleArray);
    }

    private HostState installHostStateWithUUID(String hostUUID, Spawn spawn, boolean isUp) throws Exception {
        return installHostStateWithUUID(hostUUID, spawn, isUp, false, 1, "default");
    }

    private HostState installHostStateWithUUID(String hostUUID, Spawn spawn, boolean isUp, boolean readOnly, int availableSlots, String minionType) throws Exception {
        String zkPath = isUp ? "/minion/up/" + hostUUID : "/minion/dead/" + hostUUID;
        zkClient.create().withMode(CreateMode.EPHEMERAL).forPath(zkPath);
        HostState newHostState = new HostState(hostUUID);
        newHostState.setMax(new HostCapacity(10, 10, 10, 1000));
        newHostState.setUsed(new HostCapacity(0, 0, 0, 100));
        newHostState.setHost("hostname-for:" + hostUUID);
        newHostState.setUp(isUp);
        newHostState.setAvailableTaskSlots(availableSlots);
        newHostState.setMinionTypes(minionType);
        hostManager.updateHostState(newHostState);
        return newHostState;
    }
}
