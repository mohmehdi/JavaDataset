

package com.hazelcast.instance;

import com.hazelcast.config.Config;
import com.hazelcast.core.IMap;
import com.hazelcast.internal.monitors.HealthMonitorLevel;
import com.hazelcast.map.QueryResultSizeExceededException;
import com.hazelcast.map.impl.QueryResultSizeLimiter;
import com.hazelcast.query.TruePredicate;


public class GroupProperties {

    
    public static final String PROP_APPLICATION_VALIDATION_TOKEN = "hazelcast.application.validation.token";

    public static final String PROP_HEALTH_MONITORING_LEVEL = "hazelcast.health.monitoring.level";
    public static final String PROP_HEALTH_MONITORING_DELAY_SECONDS = "hazelcast.health.monitoring.delay.seconds";

    
    public static final String PROP_PERFORMANCE_MONITOR_ENABLED = "hazelcast.performance.monitoring.enabled";

    
    public static final String PROP_PERFORMANCE_MONITOR_DELAY_SECONDS
            = "hazelcast.performance.monitor.delay.seconds";

    
    public static final String PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE_MB
            = "hazelcast.performance.monitor.max.rolled.file.size.mb";

    
    public static final String PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT
            = "hazelcast.performance.monitor.max.rolled.file.count";

    
    public static final String PROP_PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT
            = "hazelcast.performance.monitor.human.friendly.format";

    public static final String PROP_VERSION_CHECK_ENABLED = "hazelcast.version.check.enabled";
    public static final String PROP_PREFER_IPv4_STACK = "hazelcast.prefer.ipv4.stack";
    public static final String PROP_IO_THREAD_COUNT = "hazelcast.io.thread.count";

    
    public static final String PROP_IO_BALANCER_INTERVAL_SECONDS = "hazelcast.io.balancer.interval.seconds";
    
    public static final String PROP_PARTITION_OPERATION_THREAD_COUNT = "hazelcast.operation.thread.count";
    public static final String PROP_GENERIC_OPERATION_THREAD_COUNT = "hazelcast.operation.generic.thread.count";
    public static final String PROP_EVENT_THREAD_COUNT = "hazelcast.event.thread.count";
    public static final String PROP_EVENT_QUEUE_CAPACITY = "hazelcast.event.queue.capacity";
    public static final String PROP_EVENT_QUEUE_TIMEOUT_MILLIS = "hazelcast.event.queue.timeout.millis";
    public static final String PROP_CONNECT_ALL_WAIT_SECONDS = "hazelcast.connect.all.wait.seconds";
    public static final String PROP_MEMCACHE_ENABLED = "hazelcast.memcache.enabled";
    public static final String PROP_REST_ENABLED = "hazelcast.rest.enabled";
    public static final String PROP_MAP_LOAD_CHUNK_SIZE = "hazelcast.map.load.chunk.size";
    public static final String PROP_MERGE_FIRST_RUN_DELAY_SECONDS = "hazelcast.merge.first.run.delay.seconds";
    public static final String PROP_MERGE_NEXT_RUN_DELAY_SECONDS = "hazelcast.merge.next.run.delay.seconds";
    public static final String PROP_OPERATION_CALL_TIMEOUT_MILLIS = "hazelcast.operation.call.timeout.millis";

    
    public static final String PROP_OPERATION_BACKUP_TIMEOUT_MILLIS = "hazelcast.operation.backup.timeout.millis";

    public static final String PROP_SOCKET_BIND_ANY = "hazelcast.socket.bind.any";
    public static final String PROP_SOCKET_SERVER_BIND_ANY = "hazelcast.socket.server.bind.any";
    public static final String PROP_SOCKET_CLIENT_BIND_ANY = "hazelcast.socket.client.bind.any";
    public static final String PROP_SOCKET_CLIENT_BIND = "hazelcast.socket.client.bind";
    
    public static final String PROP_CLIENT_ENGINE_THREAD_COUNT = "hazelcast.clientengine.thread.count";
    public static final String PROP_SOCKET_RECEIVE_BUFFER_SIZE = "hazelcast.socket.receive.buffer.size";
    public static final String PROP_SOCKET_SEND_BUFFER_SIZE = "hazelcast.socket.send.buffer.size";

    
    public static final String PROP_SOCKET_CLIENT_RECEIVE_BUFFER_SIZE = "hazelcast.socket.client.receive.buffer.size";

    
    public static final String PROP_SOCKET_CLIENT_SEND_BUFFER_SIZE = "hazelcast.socket.client.send.buffer.size";

    public static final String PROP_SOCKET_LINGER_SECONDS = "hazelcast.socket.linger.seconds";
    public static final String PROP_SOCKET_CONNECT_TIMEOUT_SECONDS = "hazelcast.socket.connect.timeout.seconds";
    public static final String PROP_SOCKET_KEEP_ALIVE = "hazelcast.socket.keep.alive";
    public static final String PROP_SOCKET_NO_DELAY = "hazelcast.socket.no.delay";
    public static final String PROP_SHUTDOWNHOOK_ENABLED = "hazelcast.shutdownhook.enabled";
    public static final String PROP_WAIT_SECONDS_BEFORE_JOIN = "hazelcast.wait.seconds.before.join";
    public static final String PROP_MAX_WAIT_SECONDS_BEFORE_JOIN = "hazelcast.max.wait.seconds.before.join";
    public static final String PROP_MAX_JOIN_SECONDS = "hazelcast.max.join.seconds";
    public static final String PROP_MAX_JOIN_MERGE_TARGET_SECONDS = "hazelcast.max.join.merge.target.seconds";
    public static final String PROP_HEARTBEAT_INTERVAL_SECONDS = "hazelcast.heartbeat.interval.seconds";
    public static final String PROP_MAX_NO_HEARTBEAT_SECONDS = "hazelcast.max.no.heartbeat.seconds";
    public static final String PROP_MAX_NO_MASTER_CONFIRMATION_SECONDS = "hazelcast.max.no.master.confirmation.seconds";
    public static final String PROP_MASTER_CONFIRMATION_INTERVAL_SECONDS
            = "hazelcast.master.confirmation.interval.seconds";
    public static final String PROP_MEMBER_LIST_PUBLISH_INTERVAL_SECONDS
            = "hazelcast.member.list.publish.interval.seconds";
    public static final String PROP_ICMP_ENABLED = "hazelcast.icmp.enabled";
    public static final String PROP_ICMP_TIMEOUT = "hazelcast.icmp.timeout";
    public static final String PROP_ICMP_TTL = "hazelcast.icmp.ttl";
    public static final String PROP_INITIAL_MIN_CLUSTER_SIZE = "hazelcast.initial.min.cluster.size";
    public static final String PROP_INITIAL_WAIT_SECONDS = "hazelcast.initial.wait.seconds";

    
    public static final String PROP_TCP_JOIN_PORT_TRY_COUNT = "hazelcast.tcp.join.port.try.count";
    public static final String PROP_MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS
            = "hazelcast.map.replica.scheduled.task.delay.seconds";
    
    public static final String PROP_MAP_EXPIRY_DELAY_SECONDS = "hazelcast.map.expiry.delay.seconds";
    public static final String PROP_PARTITION_COUNT = "hazelcast.partition.count";
    public static final String PROP_LOGGING_TYPE = "hazelcast.logging.type";
    public static final String PROP_ENABLE_JMX = "hazelcast.jmx";
    public static final String PROP_ENABLE_JMX_DETAILED = "hazelcast.jmx.detailed";
    public static final String PROP_MC_MAX_VISIBLE_INSTANCE_COUNT = "hazelcast.mc.max.visible.instance.count";
    public static final String PROP_MC_MAX_VISIBLE_SLOW_OPERATION_COUNT = "hazelcast.mc.max.visible.slow.operations.count";
    public static final String PROP_MC_URL_CHANGE_ENABLED = "hazelcast.mc.url.change.enabled";
    public static final String PROP_CONNECTION_MONITOR_INTERVAL = "hazelcast.connection.monitor.interval";
    public static final String PROP_CONNECTION_MONITOR_MAX_FAULTS = "hazelcast.connection.monitor.max.faults";
    public static final String PROP_PARTITION_MIGRATION_INTERVAL = "hazelcast.partition.migration.interval";
    public static final String PROP_PARTITION_MIGRATION_TIMEOUT = "hazelcast.partition.migration.timeout";
    public static final String PROP_PARTITION_MIGRATION_ZIP_ENABLED = "hazelcast.partition.migration.zip.enabled";
    public static final String PROP_PARTITION_TABLE_SEND_INTERVAL = "hazelcast.partition.table.send.interval";
    public static final String PROP_PARTITION_BACKUP_SYNC_INTERVAL = "hazelcast.partition.backup.sync.interval";
    public static final String PROP_PARTITION_MAX_PARALLEL_REPLICATIONS
            = "hazelcast.partition.max.parallel.replications";
    public static final String PROP_PARTITIONING_STRATEGY_CLASS = "hazelcast.partitioning.strategy.class";
    public static final String PROP_GRACEFUL_SHUTDOWN_MAX_WAIT = "hazelcast.graceful.shutdown.max.wait";
    public static final String PROP_SYSTEM_LOG_ENABLED = "hazelcast.system.log.enabled";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_ENABLED = "hazelcast.slow.operation.detector.enabled";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS
            = "hazelcast.slow.operation.detector.threshold.millis";


    
    public static final String PROP_SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS
            = "hazelcast.slow.invocation.detector.threshold.millis";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS
            = "hazelcast.slow.operation.detector.log.retention.seconds";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS
            = "hazelcast.slow.operation.detector.log.purge.interval.seconds";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED
            = "hazelcast.slow.operation.detector.stacktrace.logging.enabled";

    
    public static final String PROP_ELASTIC_MEMORY_ENABLED = "hazelcast.elastic.memory.enabled";
    public static final String PROP_ELASTIC_MEMORY_TOTAL_SIZE = "hazelcast.elastic.memory.total.size";
    public static final String PROP_ELASTIC_MEMORY_CHUNK_SIZE = "hazelcast.elastic.memory.chunk.size";
    public static final String PROP_ELASTIC_MEMORY_SHARED_STORAGE = "hazelcast.elastic.memory.shared.storage";
    public static final String PROP_ELASTIC_MEMORY_UNSAFE_ENABLED = "hazelcast.elastic.memory.unsafe.enabled";
    public static final String PROP_ENTERPRISE_LICENSE_KEY = "hazelcast.enterprise.license.key";
    public static final String PROP_MAP_WRITE_BEHIND_QUEUE_CAPACITY = "hazelcast.map.write.behind.queue.capacity";

    
    public static final String PROP_ENTERPRISE_WAN_REP_QUEUE_CAPACITY = "hazelcast.enterprise.wanrep.queue.capacity";

    
    public static final String PROP_ENTERPRISE_WAN_REP_BATCH_SIZE = "hazelcast.enterprise.wanrep.batch.size";

    
    public static final String PROP_ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS
            = "hazelcast.enterprise.wanrep.batchfrequency.seconds";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED
            = "hazelcast.cache.invalidation.batch.enabled";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_SIZE
            = "hazelcast.cache.invalidation.batch.size";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS
            = "hazelcast.cache.invalidation.batchfrequency.seconds";

    
    public static final String PROP_ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS
            = "hazelcast.enterprise.wanrep.optimeout.millis";

    public static final String PROP_CLIENT_MAX_NO_HEARTBEAT_SECONDS = "hazelcast.client.max.no.heartbeat.seconds";
    public static final String PROP_MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS
            = "hazelcast.migration.min.delay.on.member.removed.seconds";

    
    public static final String PROP_BACKPRESSURE_ENABLED = "hazelcast.backpressure.enabled";

    
    public static final String PROP_BACKPRESSURE_SYNCWINDOW = "hazelcast.backpressure.syncwindow";

    
    public static final String PROP_BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS
            = "hazelcast.backpressure.backoff.timeout.millis";

    
    public static final String PROP_BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION
            = "hazelcast.backpressure.max.concurrent.invocations.per.partition";


    
    public static final String PROP_QUERY_PREDICATE_PARALLEL_EVALUATION = "hazelcast.query.predicate.parallel.evaluation";


    
    public static final String PROP_JCACHE_PROVIDER_TYPE = "hazelcast.jcache.provider.type";

    
    public static final String PROP_QUERY_RESULT_SIZE_LIMIT = "hazelcast.query.result.size.limit";

    
    public static final String PROP_QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK
            = "hazelcast.query.max.local.partition.limit.for.precheck";

    public final GroupProperty CLIENT_ENGINE_THREAD_COUNT;

    public final GroupProperty PARTITION_OPERATION_THREAD_COUNT;

    public final GroupProperty GENERIC_OPERATION_THREAD_COUNT;

    public final GroupProperty EVENT_THREAD_COUNT;

    public final GroupProperty HEALTH_MONITORING_LEVEL;

    public final GroupProperty HEALTH_MONITORING_DELAY_SECONDS;

    public final GroupProperty PERFORMANCE_MONITOR_ENABLED;

    public final GroupProperty PERFORMANCE_MONITOR_DELAY_SECONDS;

    public final GroupProperty PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE;

    public final GroupProperty PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT;

    public final GroupProperty PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT;

    public final GroupProperty IO_THREAD_COUNT;

    public final GroupProperty IO_BALANCER_INTERVAL_SECONDS;

    public final GroupProperty EVENT_QUEUE_CAPACITY;

    public final GroupProperty EVENT_QUEUE_TIMEOUT_MILLIS;

    public final GroupProperty PREFER_IPv4_STACK;

    public final GroupProperty CONNECT_ALL_WAIT_SECONDS;

    public final GroupProperty VERSION_CHECK_ENABLED;

    public final GroupProperty MEMCACHE_ENABLED;

    public final GroupProperty REST_ENABLED;

    public final GroupProperty MAP_LOAD_CHUNK_SIZE;

    public final GroupProperty MERGE_FIRST_RUN_DELAY_SECONDS;

    public final GroupProperty MERGE_NEXT_RUN_DELAY_SECONDS;

    public final GroupProperty OPERATION_CALL_TIMEOUT_MILLIS;

    public final GroupProperty OPERATION_BACKUP_TIMEOUT_MILLIS;

    public final GroupProperty SOCKET_SERVER_BIND_ANY;

    public final GroupProperty SOCKET_CLIENT_BIND_ANY;

    public final GroupProperty SOCKET_CLIENT_BIND;

    
    public final GroupProperty SOCKET_RECEIVE_BUFFER_SIZE;

    
    public final GroupProperty SOCKET_SEND_BUFFER_SIZE;

    
    public final GroupProperty SOCKET_CLIENT_RECEIVE_BUFFER_SIZE;

    
    public final GroupProperty SOCKET_CLIENT_SEND_BUFFER_SIZE;

    public final GroupProperty SOCKET_LINGER_SECONDS;

    public final GroupProperty SOCKET_CONNECT_TIMEOUT_SECONDS;

    public final GroupProperty SOCKET_KEEP_ALIVE;

    public final GroupProperty SOCKET_NO_DELAY;

    public final GroupProperty SHUTDOWNHOOK_ENABLED;

    public final GroupProperty WAIT_SECONDS_BEFORE_JOIN;

    public final GroupProperty MAX_WAIT_SECONDS_BEFORE_JOIN;

    public final GroupProperty MAX_JOIN_SECONDS;

    public final GroupProperty MAX_JOIN_MERGE_TARGET_SECONDS;

    public final GroupProperty MAX_NO_HEARTBEAT_SECONDS;

    public final GroupProperty HEARTBEAT_INTERVAL_SECONDS;

    public final GroupProperty MASTER_CONFIRMATION_INTERVAL_SECONDS;

    public final GroupProperty MAX_NO_MASTER_CONFIRMATION_SECONDS;

    public final GroupProperty MEMBER_LIST_PUBLISH_INTERVAL_SECONDS;

    public final GroupProperty ICMP_ENABLED;

    public final GroupProperty ICMP_TIMEOUT;

    public final GroupProperty ICMP_TTL;

    public final GroupProperty INITIAL_WAIT_SECONDS;

    public final GroupProperty INITIAL_MIN_CLUSTER_SIZE;

    public final GroupProperty TCP_JOIN_PORT_TRY_COUNT;

    public final GroupProperty MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS;

    public final GroupProperty MAP_EXPIRY_DELAY_SECONDS;

    public final GroupProperty PARTITION_COUNT;

    public final GroupProperty LOGGING_TYPE;

    public final GroupProperty ENABLE_JMX;

    public final GroupProperty ENABLE_JMX_DETAILED;

    public final GroupProperty MC_MAX_INSTANCE_COUNT;

    public final GroupProperty MC_MAX_SLOW_OPERATION_COUNT;

    public final GroupProperty MC_URL_CHANGE_ENABLED;

    public final GroupProperty CONNECTION_MONITOR_INTERVAL;

    public final GroupProperty CONNECTION_MONITOR_MAX_FAULTS;

    public final GroupProperty PARTITION_MIGRATION_INTERVAL;

    public final GroupProperty PARTITION_MIGRATION_TIMEOUT;

    public final GroupProperty PARTITION_MIGRATION_ZIP_ENABLED;

    public final GroupProperty PARTITION_TABLE_SEND_INTERVAL;

    public final GroupProperty PARTITION_BACKUP_SYNC_INTERVAL;

    public final GroupProperty PARTITION_MAX_PARALLEL_REPLICATIONS;

    public final GroupProperty PARTITIONING_STRATEGY_CLASS;

    public final GroupProperty GRACEFUL_SHUTDOWN_MAX_WAIT;

    public final GroupProperty SYSTEM_LOG_ENABLED;

    public final GroupProperty SLOW_OPERATION_DETECTOR_ENABLED;
    public final GroupProperty SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED;

    public final GroupProperty SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS;

    public final GroupProperty ELASTIC_MEMORY_ENABLED;

    public final GroupProperty ELASTIC_MEMORY_TOTAL_SIZE;

    public final GroupProperty ELASTIC_MEMORY_CHUNK_SIZE;

    public final GroupProperty ELASTIC_MEMORY_SHARED_STORAGE;

    public final GroupProperty ELASTIC_MEMORY_UNSAFE_ENABLED;

    public final GroupProperty ENTERPRISE_LICENSE_KEY;

    
    public final GroupProperty MAP_WRITE_BEHIND_QUEUE_CAPACITY;

    public final GroupProperty ENTERPRISE_WAN_REP_QUEUE_CAPACITY;
    public final GroupProperty ENTERPRISE_WAN_REP_BATCH_SIZE;
    public final GroupProperty ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS;
    public final GroupProperty ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS;

    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED;
    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_SIZE;
    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS;

    public final GroupProperty CLIENT_HEARTBEAT_TIMEOUT_SECONDS;

    public final GroupProperty MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS;

    public final GroupProperty BACKPRESSURE_ENABLED;
    public final GroupProperty BACKPRESSURE_SYNCWINDOW;
    public final GroupProperty BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS;
    public final GroupProperty BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION;

    public final GroupProperty QUERY_RESULT_SIZE_LIMIT;
    public final GroupProperty QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK;

    public final GroupProperty QUERY_PREDICATE_PARALLEL_EVALUATION;

    public GroupProperties(Config config) {
        HEALTH_MONITORING_LEVEL
                = new GroupProperty(config, PROP_HEALTH_MONITORING_LEVEL, HealthMonitorLevel.SILENT.toString());
        HEALTH_MONITORING_DELAY_SECONDS
                = new GroupProperty(config, PROP_HEALTH_MONITORING_DELAY_SECONDS, "30");

        PERFORMANCE_MONITOR_ENABLED
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_ENABLED, "false");
        PERFORMANCE_MONITOR_DELAY_SECONDS
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_DELAY_SECONDS, "30");
        PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE_MB, "10");
        PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT, "10");
        PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT, "true");

        VERSION_CHECK_ENABLED = new GroupProperty(config, PROP_VERSION_CHECK_ENABLED, "true");
        PREFER_IPv4_STACK = new GroupProperty(config, PROP_PREFER_IPv4_STACK, "true");
        IO_THREAD_COUNT = new GroupProperty(config, PROP_IO_THREAD_COUNT, "3");
        IO_BALANCER_INTERVAL_SECONDS = new GroupProperty(config, PROP_IO_BALANCER_INTERVAL_SECONDS, "20");

        
        PARTITION_OPERATION_THREAD_COUNT = new GroupProperty(config, PROP_PARTITION_OPERATION_THREAD_COUNT, "-1");
        GENERIC_OPERATION_THREAD_COUNT = new GroupProperty(config, PROP_GENERIC_OPERATION_THREAD_COUNT, "-1");
        EVENT_THREAD_COUNT = new GroupProperty(config, PROP_EVENT_THREAD_COUNT, "5");
        EVENT_QUEUE_CAPACITY = new GroupProperty(config, PROP_EVENT_QUEUE_CAPACITY, "1000000");
        EVENT_QUEUE_TIMEOUT_MILLIS = new GroupProperty(config, PROP_EVENT_QUEUE_TIMEOUT_MILLIS, "250");
        CLIENT_ENGINE_THREAD_COUNT = new GroupProperty(config, PROP_CLIENT_ENGINE_THREAD_COUNT, "-1");

        CONNECT_ALL_WAIT_SECONDS = new GroupProperty(config, PROP_CONNECT_ALL_WAIT_SECONDS, "120");
        MEMCACHE_ENABLED = new GroupProperty(config, PROP_MEMCACHE_ENABLED, "true");
        REST_ENABLED = new GroupProperty(config, PROP_REST_ENABLED, "true");
        MAP_LOAD_CHUNK_SIZE = new GroupProperty(config, PROP_MAP_LOAD_CHUNK_SIZE, "1000");
        MERGE_FIRST_RUN_DELAY_SECONDS = new GroupProperty(config, PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "300");
        MERGE_NEXT_RUN_DELAY_SECONDS = new GroupProperty(config, PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "120");
        OPERATION_CALL_TIMEOUT_MILLIS = new GroupProperty(config, PROP_OPERATION_CALL_TIMEOUT_MILLIS, "60000");
        OPERATION_BACKUP_TIMEOUT_MILLIS = new GroupProperty(config, PROP_OPERATION_BACKUP_TIMEOUT_MILLIS, "5000");

        final GroupProperty SOCKET_BIND_ANY = new GroupProperty(config, PROP_SOCKET_BIND_ANY, "true");
        SOCKET_SERVER_BIND_ANY = new GroupProperty(config, PROP_SOCKET_SERVER_BIND_ANY, SOCKET_BIND_ANY);
        SOCKET_CLIENT_BIND_ANY = new GroupProperty(config, PROP_SOCKET_CLIENT_BIND_ANY, SOCKET_BIND_ANY);
        SOCKET_CLIENT_BIND = new GroupProperty(config, PROP_SOCKET_CLIENT_BIND, "true");
        SOCKET_RECEIVE_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_RECEIVE_BUFFER_SIZE, "32");
        SOCKET_SEND_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_SEND_BUFFER_SIZE, "32");
        SOCKET_CLIENT_RECEIVE_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_CLIENT_RECEIVE_BUFFER_SIZE, "-1");
        SOCKET_CLIENT_SEND_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_CLIENT_SEND_BUFFER_SIZE, "-1");
        SOCKET_LINGER_SECONDS = new GroupProperty(config, PROP_SOCKET_LINGER_SECONDS, "0");
        SOCKET_CONNECT_TIMEOUT_SECONDS = new GroupProperty(config, PROP_SOCKET_CONNECT_TIMEOUT_SECONDS, "0");
        SOCKET_KEEP_ALIVE = new GroupProperty(config, PROP_SOCKET_KEEP_ALIVE, "true");
        SOCKET_NO_DELAY = new GroupProperty(config, PROP_SOCKET_NO_DELAY, "true");
        SHUTDOWNHOOK_ENABLED = new GroupProperty(config, PROP_SHUTDOWNHOOK_ENABLED, "true");
        WAIT_SECONDS_BEFORE_JOIN = new GroupProperty(config, PROP_WAIT_SECONDS_BEFORE_JOIN, "5");
        MAX_WAIT_SECONDS_BEFORE_JOIN = new GroupProperty(config, PROP_MAX_WAIT_SECONDS_BEFORE_JOIN, "20");
        MAX_JOIN_SECONDS = new GroupProperty(config, PROP_MAX_JOIN_SECONDS, "300");
        MAX_JOIN_MERGE_TARGET_SECONDS = new GroupProperty(config, PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "20");
        HEARTBEAT_INTERVAL_SECONDS = new GroupProperty(config, PROP_HEARTBEAT_INTERVAL_SECONDS, "5");
        MAX_NO_HEARTBEAT_SECONDS = new GroupProperty(config, PROP_MAX_NO_HEARTBEAT_SECONDS, "300");
        MASTER_CONFIRMATION_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_MASTER_CONFIRMATION_INTERVAL_SECONDS, "30");
        MAX_NO_MASTER_CONFIRMATION_SECONDS = new GroupProperty(config, PROP_MAX_NO_MASTER_CONFIRMATION_SECONDS, "300");
        MEMBER_LIST_PUBLISH_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_MEMBER_LIST_PUBLISH_INTERVAL_SECONDS, "300");
        ICMP_ENABLED = new GroupProperty(config, PROP_ICMP_ENABLED, "false");
        ICMP_TIMEOUT = new GroupProperty(config, PROP_ICMP_TIMEOUT, "1000");
        ICMP_TTL = new GroupProperty(config, PROP_ICMP_TTL, "0");
        INITIAL_MIN_CLUSTER_SIZE = new GroupProperty(config, PROP_INITIAL_MIN_CLUSTER_SIZE, "0");
        INITIAL_WAIT_SECONDS = new GroupProperty(config, PROP_INITIAL_WAIT_SECONDS, "0");
        TCP_JOIN_PORT_TRY_COUNT = new GroupProperty(config, PROP_TCP_JOIN_PORT_TRY_COUNT, "3");
        MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS
                = new GroupProperty(config, PROP_MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS, "10");
        MAP_EXPIRY_DELAY_SECONDS = new GroupProperty(config, PROP_MAP_EXPIRY_DELAY_SECONDS, "10");
        PARTITION_COUNT = new GroupProperty(config, PROP_PARTITION_COUNT, "271");
        LOGGING_TYPE = new GroupProperty(config, PROP_LOGGING_TYPE, "jdk");
        ENABLE_JMX = new GroupProperty(config, PROP_ENABLE_JMX, "false");
        ENABLE_JMX_DETAILED = new GroupProperty(config, PROP_ENABLE_JMX_DETAILED, "false");
        MC_MAX_INSTANCE_COUNT = new GroupProperty(config, PROP_MC_MAX_VISIBLE_INSTANCE_COUNT, "100");
        MC_MAX_SLOW_OPERATION_COUNT = new GroupProperty(config, PROP_MC_MAX_VISIBLE_SLOW_OPERATION_COUNT, "10");
        MC_URL_CHANGE_ENABLED = new GroupProperty(config, PROP_MC_URL_CHANGE_ENABLED, "true");
        CONNECTION_MONITOR_INTERVAL = new GroupProperty(config, PROP_CONNECTION_MONITOR_INTERVAL, "100");
        CONNECTION_MONITOR_MAX_FAULTS = new GroupProperty(config, PROP_CONNECTION_MONITOR_MAX_FAULTS, "3");
        PARTITION_MIGRATION_INTERVAL = new GroupProperty(config, PROP_PARTITION_MIGRATION_INTERVAL, "0");
        PARTITION_MIGRATION_TIMEOUT = new GroupProperty(config, PROP_PARTITION_MIGRATION_TIMEOUT, "300");
        PARTITION_MIGRATION_ZIP_ENABLED = new GroupProperty(config, PROP_PARTITION_MIGRATION_ZIP_ENABLED, "true");
        PARTITION_TABLE_SEND_INTERVAL = new GroupProperty(config, PROP_PARTITION_TABLE_SEND_INTERVAL, "15");
        PARTITION_BACKUP_SYNC_INTERVAL = new GroupProperty(config, PROP_PARTITION_BACKUP_SYNC_INTERVAL, "30");
        PARTITION_MAX_PARALLEL_REPLICATIONS = new GroupProperty(config, PROP_PARTITION_MAX_PARALLEL_REPLICATIONS, "5");
        PARTITIONING_STRATEGY_CLASS = new GroupProperty(config, PROP_PARTITIONING_STRATEGY_CLASS, "");
        GRACEFUL_SHUTDOWN_MAX_WAIT = new GroupProperty(config, PROP_GRACEFUL_SHUTDOWN_MAX_WAIT, "600");
        SYSTEM_LOG_ENABLED = new GroupProperty(config, PROP_SYSTEM_LOG_ENABLED, "true");

        SLOW_OPERATION_DETECTOR_ENABLED
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_ENABLED, "true");
        SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS, "10000");
        SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS, "3600");
        SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS, "300");
        SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED, "false");
        SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS
                = new GroupProperty(config, PROP_SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS, "-1");

        ELASTIC_MEMORY_ENABLED = new GroupProperty(config, PROP_ELASTIC_MEMORY_ENABLED, "false");
        ELASTIC_MEMORY_TOTAL_SIZE = new GroupProperty(config, PROP_ELASTIC_MEMORY_TOTAL_SIZE, "128M");
        ELASTIC_MEMORY_CHUNK_SIZE = new GroupProperty(config, PROP_ELASTIC_MEMORY_CHUNK_SIZE, "1K");
        ELASTIC_MEMORY_SHARED_STORAGE = new GroupProperty(config, PROP_ELASTIC_MEMORY_SHARED_STORAGE, "false");
        ELASTIC_MEMORY_UNSAFE_ENABLED = new GroupProperty(config, PROP_ELASTIC_MEMORY_UNSAFE_ENABLED, "false");
        ENTERPRISE_LICENSE_KEY = new GroupProperty(config, PROP_ENTERPRISE_LICENSE_KEY);
        MAP_WRITE_BEHIND_QUEUE_CAPACITY
                = new GroupProperty(config, PROP_MAP_WRITE_BEHIND_QUEUE_CAPACITY, "50000");

        ENTERPRISE_WAN_REP_QUEUE_CAPACITY = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_QUEUE_CAPACITY, "100000");
        ENTERPRISE_WAN_REP_BATCH_SIZE = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_BATCH_SIZE, "50");
        ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS
                = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS, "5");
        ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS, "60000");

        CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED, "true");
        CACHE_INVALIDATION_MESSAGE_BATCH_SIZE
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_SIZE, "100");
        CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS, "10");

        CLIENT_HEARTBEAT_TIMEOUT_SECONDS = new GroupProperty(config, PROP_CLIENT_MAX_NO_HEARTBEAT_SECONDS, "300");
        MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS
                = new GroupProperty(config, PROP_MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS, "5");
        BACKPRESSURE_ENABLED
                = new GroupProperty(config, PROP_BACKPRESSURE_ENABLED, "false");
        BACKPRESSURE_SYNCWINDOW
                = new GroupProperty(config, PROP_BACKPRESSURE_SYNCWINDOW, "100");
        BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION
                = new GroupProperty(config, PROP_BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION, "100");
        BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS
                = new GroupProperty(config, PROP_BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS, "60000");

        QUERY_RESULT_SIZE_LIMIT = new GroupProperty(config, PROP_QUERY_RESULT_SIZE_LIMIT, "-1");
        QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK
                = new GroupProperty(config, PROP_QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK, "3");

        QUERY_PREDICATE_PARALLEL_EVALUATION
                = new GroupProperty(config, PROP_QUERY_PREDICATE_PARALLEL_EVALUATION, "false");
    }

    public static class GroupProperty {

        private final String name;
        private final String value;

        GroupProperty(Config config, String name) {
            this(config, name, (String) null);
        }

        GroupProperty(Config config, String name, GroupProperty defaultValue) {
            this(config, name, defaultValue != null ? defaultValue.getString() : null);
        }

        GroupProperty(Config config, String name, String defaultValue) {
            this.name = name;
            String configValue = (config != null) ? config.getProperty(name) : null;
            if (configValue != null) {
                value = configValue;
            } else if (System.getProperty(name) != null) {
                value = System.getProperty(name);
            } else {
                value = defaultValue;
            }
        }

        public String getName() {
            return this.name;
        }

        public String getValue() {
            return value;
        }

        public int getInteger() {
            return Integer.parseInt(this.value);
        }

        public byte getByte() {
            return Byte.parseByte(this.value);
        }

        public boolean getBoolean() {
            return Boolean.valueOf(this.value);
        }

        public float getFloat() {
            return Float.valueOf(this.value);
        }

        public String getString() {
            return value;
        }

        public long getLong() {
            return Long.parseLong(this.value);
        }

        @Override
        public String toString() {
            return "GroupProperty [name=" + this.name + ", value=" + this.value + "]";
        }
    }
}

<code block>


package com.hazelcast.instance;

import com.hazelcast.cluster.impl.ClusterDataSerializerHook;
import com.hazelcast.cluster.impl.operations.MemberAttributeChangedOperation;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.HazelcastInstanceAware;
import com.hazelcast.core.Member;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.ExceptionUtil;

import java.util.Map;

import static com.hazelcast.cluster.MemberAttributeOperationType.PUT;
import static com.hazelcast.cluster.MemberAttributeOperationType.REMOVE;
import static com.hazelcast.util.Preconditions.isNotNull;

public final class MemberImpl
        extends AbstractMember
        implements Member, HazelcastInstanceAware, IdentifiedDataSerializable {

    private boolean localMember;
    private volatile HazelcastInstanceImpl instance;
    private volatile ILogger logger;

    public MemberImpl() {
    }

    public MemberImpl(Address address, boolean localMember) {
        this(address, localMember, null, null);
    }

    public MemberImpl(Address address, boolean localMember, String uuid, HazelcastInstanceImpl instance) {
        this(address, localMember, uuid, instance, null);
    }

    public MemberImpl(Address address, boolean localMember, String uuid, HazelcastInstanceImpl instance,
                      Map<String, Object> attributes) {
        super(address, uuid, attributes);
        this.localMember = localMember;
        this.instance = instance;
    }

    public MemberImpl(MemberImpl member) {
        super(member);
        this.localMember = member.localMember;
    }

    @Override
    protected ILogger getLogger() {
        return logger;
    }

    @Override
    public void setHazelcastInstance(HazelcastInstance hazelcastInstance) {
        if (hazelcastInstance instanceof HazelcastInstanceImpl) {
            instance = (HazelcastInstanceImpl) hazelcastInstance;
            localMember = instance.node.address.equals(address);
            logger = instance.node.getLogger(this.getClass().getName());
        }
    }

    @Override
    public boolean localMember() {
        return localMember;
    }

    @Override
    public String getStringAttribute(String key) {
        return (String) getAttribute(key);
    }

    @Override
    public void setStringAttribute(String key, String value) {
        setAttribute(key, value);
    }

    @Override
    public Boolean getBooleanAttribute(String key) {
        return (Boolean) getAttribute(key);
    }

    @Override
    public void setBooleanAttribute(String key, boolean value) {
        setAttribute(key, value);
    }

    @Override
    public Byte getByteAttribute(String key) {
        return (Byte) getAttribute(key);
    }

    @Override
    public void setByteAttribute(String key, byte value) {
        setAttribute(key, value);
    }

    @Override
    public Short getShortAttribute(String key) {
        return (Short) getAttribute(key);
    }

    @Override
    public void setShortAttribute(String key, short value) {
        setAttribute(key, value);
    }

    @Override
    public Integer getIntAttribute(String key) {
        return (Integer) getAttribute(key);
    }

    @Override
    public void setIntAttribute(String key, int value) {
        setAttribute(key, value);
    }

    @Override
    public Long getLongAttribute(String key) {
        return (Long) getAttribute(key);
    }

    @Override
    public void setLongAttribute(String key, long value) {
        setAttribute(key, value);
    }

    @Override
    public Float getFloatAttribute(String key) {
        return (Float) getAttribute(key);
    }

    @Override
    public void setFloatAttribute(String key, float value) {
        setAttribute(key, value);
    }

    @Override
    public Double getDoubleAttribute(String key) {
        return (Double) getAttribute(key);
    }

    @Override
    public void setDoubleAttribute(String key, double value) {
        setAttribute(key, value);
    }

    @Override
    public void removeAttribute(String key) {
        isLocalMember();
        isNotNull(key, "key");

        Object value = attributes.remove(key);
        if (value == null) {
            return;
        }

        if (instance != null) {
            MemberAttributeChangedOperation operation = new MemberAttributeChangedOperation(REMOVE, key, null);
            invokeOnAllMembers(operation);
        }
    }

    private void isLocalMember() {
        if (!localMember) {
            throw new UnsupportedOperationException("Attributes on remote members must not be changed");
        }
    }

    private void setAttribute(String key, Object value) {
        isLocalMember();
        isNotNull(key, "key");
        isNotNull(value, "value");

        Object oldValue = attributes.put(key, value);
        if (value.equals(oldValue)) {
            return;
        }

        if (instance != null) {
            MemberAttributeChangedOperation operation = new MemberAttributeChangedOperation(PUT, key, value);
            invokeOnAllMembers(operation);
        }
    }

    private void invokeOnAllMembers(Operation operation) {
        NodeEngineImpl nodeEngine = instance.node.nodeEngine;
        OperationService os = nodeEngine.getOperationService();
        String uuid = nodeEngine.getLocalMember().getUuid();
        operation.setCallerUuid(uuid).setNodeEngine(nodeEngine);
        try {
            for (MemberImpl member : nodeEngine.getClusterService().getMemberList()) {
                if (!member.localMember()) {
                    os.send(operation, member.getAddress());
                } else {
                    os.executeOperation(operation);
                }
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public int getFactoryId() {
        return ClusterDataSerializerHook.F_ID;
    }

    @Override
    public int getId() {
        return ClusterDataSerializerHook.MEMBER;
    }

}

<code block>


package com.hazelcast.instance;

import com.hazelcast.client.impl.ClientEngineImpl;
import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.cluster.impl.ConfigCheck;
import com.hazelcast.cluster.impl.JoinMessage;
import com.hazelcast.cluster.impl.JoinRequest;
import com.hazelcast.cluster.impl.MulticastJoiner;
import com.hazelcast.cluster.impl.MulticastService;
import com.hazelcast.cluster.impl.NodeMulticastListener;
import com.hazelcast.cluster.impl.TcpIpJoiner;
import com.hazelcast.config.Config;
import com.hazelcast.config.JoinConfig;
import com.hazelcast.config.ListenerConfig;
import com.hazelcast.config.MemberAttributeConfig;
import com.hazelcast.config.MulticastConfig;
import com.hazelcast.core.ClientListener;
import com.hazelcast.core.DistributedObjectListener;
import com.hazelcast.core.HazelcastInstanceAware;
import com.hazelcast.core.LifecycleListener;
import com.hazelcast.core.MembershipListener;
import com.hazelcast.core.MigrationListener;
import com.hazelcast.internal.ascii.TextCommandService;
import com.hazelcast.internal.ascii.TextCommandServiceImpl;
import com.hazelcast.internal.management.ManagementCenterService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingServiceImpl;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ClassLoaderUtil;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.PartitionLostListener;
import com.hazelcast.partition.impl.InternalPartitionServiceImpl;
import com.hazelcast.security.Credentials;
import com.hazelcast.security.SecurityContext;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.proxyservice.impl.ProxyServiceImpl;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.UuidUtil;
import com.hazelcast.util.VersionCheck;

import java.lang.reflect.Constructor;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.MulticastSocket;
import java.nio.channels.ServerSocketChannel;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

import static com.hazelcast.cluster.impl.MulticastService.createMulticastService;
import static com.hazelcast.instance.NodeShutdownHelper.shutdownNodeByFiringEvents;
import static com.hazelcast.util.UuidUtil.createMemberUuid;

public class Node {

    private final ILogger logger;

    private final AtomicBoolean joined = new AtomicBoolean(false);

    private volatile boolean active;

    private volatile boolean completelyShutdown;

    private final NodeShutdownHookThread shutdownHookThread = new NodeShutdownHookThread("hz.ShutdownThread");

    private final SerializationService serializationService;

    public final NodeEngineImpl nodeEngine;

    public final ClientEngineImpl clientEngine;

    public final InternalPartitionServiceImpl partitionService;

    public final ClusterServiceImpl clusterService;

    public final MulticastService multicastService;

    public final ConnectionManager connectionManager;

    public final TextCommandServiceImpl textCommandService;

    public final Config config;

    public final GroupProperties groupProperties;

    public final Address address;

    public final MemberImpl localMember;

    private volatile Address masterAddress = null;

    public final HazelcastInstanceImpl hazelcastInstance;

    public final LoggingServiceImpl loggingService;

    private final Joiner joiner;

    private final NodeExtension nodeExtension;

    private ManagementCenterService managementCenterService;

    public final SecurityContext securityContext;

    private final ClassLoader configClassLoader;

    private final BuildInfo buildInfo;

    private final VersionCheck versionCheck = new VersionCheck();

    private final HazelcastThreadGroup hazelcastThreadGroup;

    public Node(HazelcastInstanceImpl hazelcastInstance, Config config, NodeContext nodeContext) {
        this.hazelcastInstance = hazelcastInstance;
        this.config = config;
        this.configClassLoader = config.getClassLoader();
        this.groupProperties = new GroupProperties(config);
        this.buildInfo = BuildInfoProvider.getBuildInfo();

        String loggingType = groupProperties.LOGGING_TYPE.getString();
        loggingService = new LoggingServiceImpl(config.getGroupConfig().getName(), loggingType, buildInfo);
        final AddressPicker addressPicker = nodeContext.createAddressPicker(this);
        try {
            addressPicker.pickAddress();
        } catch (Throwable e) {
            throw ExceptionUtil.rethrow(e);
        }

        final ServerSocketChannel serverSocketChannel = addressPicker.getServerSocketChannel();
        try {
            address = addressPicker.getPublicAddress();
            final Map<String, Object> memberAttributes = findMemberAttributes(config.getMemberAttributeConfig().asReadOnly());
            localMember = new MemberImpl(address, true, createMemberUuid(address), hazelcastInstance, memberAttributes);
            loggingService.setThisMember(localMember);
            logger = loggingService.getLogger(Node.class.getName());
            hazelcastThreadGroup = new HazelcastThreadGroup(
                    hazelcastInstance.getName(), logger, configClassLoader);
            nodeExtension = NodeExtensionFactory.create(configClassLoader);
            nodeExtension.beforeStart(this);

            serializationService = nodeExtension.createSerializationService();
            securityContext = config.getSecurityConfig().isEnabled() ? nodeExtension.getSecurityContext() : null;

            nodeEngine = new NodeEngineImpl(this);

            clientEngine = new ClientEngineImpl(this);
            connectionManager = nodeContext.createConnectionManager(this, serverSocketChannel);
            partitionService = new InternalPartitionServiceImpl(this);
            clusterService = new ClusterServiceImpl(this);
            textCommandService = new TextCommandServiceImpl(this);
            nodeExtension.printNodeInfo(this);
            this.multicastService = createMulticastService(addressPicker.getBindAddress(), this, config, logger);
            initializeListeners(config);
            joiner = nodeContext.createJoiner(this);
        } catch (Throwable e) {
            try {
                serverSocketChannel.close();
            } catch (Throwable ignored) {
            }
            throw ExceptionUtil.rethrow(e);
        }
    }

    public HazelcastThreadGroup getHazelcastThreadGroup() {
        return hazelcastThreadGroup;
    }

    private void initializeListeners(Config config) {
        for (final ListenerConfig listenerCfg : config.getListenerConfigs()) {
            Object listener = listenerCfg.getImplementation();
            if (listener == null) {
                try {
                    listener = ClassLoaderUtil.newInstance(configClassLoader, listenerCfg.getClassName());
                } catch (Exception e) {
                    logger.severe(e);
                }
            }
            if (listener instanceof HazelcastInstanceAware) {
                ((HazelcastInstanceAware) listener).setHazelcastInstance(hazelcastInstance);
            }
            boolean known = false;
            if (listener instanceof DistributedObjectListener) {
                final ProxyServiceImpl proxyService = (ProxyServiceImpl) nodeEngine.getProxyService();
                proxyService.addProxyListener((DistributedObjectListener) listener);
                known = true;
            }
            if (listener instanceof MembershipListener) {
                clusterService.addMembershipListener((MembershipListener) listener);
                known = true;
            }
            if (listener instanceof MigrationListener) {
                partitionService.addMigrationListener((MigrationListener) listener);
                known = true;
            }
            if (listener instanceof PartitionLostListener) {
                partitionService.addPartitionLostListener((PartitionLostListener) listener);
                known = true;
            }
            if (listener instanceof LifecycleListener) {
                hazelcastInstance.lifecycleService.addLifecycleListener((LifecycleListener) listener);
                known = true;
            }
            if (listener instanceof ClientListener) {
                String serviceName = ClientEngineImpl.SERVICE_NAME;
                nodeEngine.getEventService().registerLocalListener(serviceName, serviceName, listener);
                known = true;
            }
            if (listener != null && !known) {
                final String error = "Unknown listener type: " + listener.getClass();
                Throwable t = new IllegalArgumentException(error);
                logger.warning(error, t);
            }
        }
    }

    public ManagementCenterService getManagementCenterService() {
        return managementCenterService;
    }

    public SerializationService getSerializationService() {
        return serializationService;
    }

    public ClusterServiceImpl getClusterService() {
        return clusterService;
    }

    public InternalPartitionService getPartitionService() {
        return partitionService;
    }

    public Address getMasterAddress() {
        return masterAddress;
    }

    public Address getThisAddress() {
        return address;
    }

    public MemberImpl getLocalMember() {
        return localMember;
    }

    public boolean joined() {
        return joined.get();
    }

    public boolean isMaster() {
        return address != null && address.equals(masterAddress);
    }

    public void setMasterAddress(final Address master) {
        if (master != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("** setting master address to " + master);
            }
        }
        masterAddress = master;
    }

    public void start() {
        if (logger.isFinestEnabled()) {
            logger.finest("We are asked to start and completelyShutdown is " + String.valueOf(completelyShutdown));
        }
        if (completelyShutdown) return;
        nodeEngine.start();
        connectionManager.start();
        if (config.getNetworkConfig().getJoin().getMulticastConfig().isEnabled()) {
            final Thread multicastServiceThread = new Thread(
                    hazelcastThreadGroup.getInternalThreadGroup(), multicastService,
                    hazelcastThreadGroup.getThreadNamePrefix("MulticastThread"));
            multicastServiceThread.start();
        }
        setActive(true);
        if (!completelyShutdown && groupProperties.SHUTDOWNHOOK_ENABLED.getBoolean()) {
            logger.finest("Adding ShutdownHook");
            Runtime.getRuntime().addShutdownHook(shutdownHookThread);
        }
        logger.finest("finished starting threads, calling join");
        join();
        int clusterSize = clusterService.getSize();
        if (config.getNetworkConfig().isPortAutoIncrement()
                && address.getPort() >= config.getNetworkConfig().getPort() + clusterSize) {
            StringBuilder sb = new StringBuilder("Config seed port is ");
            sb.append(config.getNetworkConfig().getPort());
            sb.append(" and cluster size is ");
            sb.append(clusterSize);
            sb.append(". Some of the ports seem occupied!");
            logger.warning(sb.toString());
        }
        try {
            managementCenterService = new ManagementCenterService(hazelcastInstance);
        } catch (Exception e) {
            logger.warning("ManagementCenterService could not be constructed!", e);
        }
        nodeExtension.afterStart(this);
        versionCheck.check(this, getBuildInfo().getVersion(), buildInfo.isEnterprise());
    }

    public void shutdown(final boolean terminate) {
        long start = Clock.currentTimeMillis();
        if (logger.isFinestEnabled()) {
            logger.finest("** we are being asked to shutdown when active = " + String.valueOf(active));
        }
        if (!terminate && isActive() && joined()) {
            final int maxWaitSeconds = groupProperties.GRACEFUL_SHUTDOWN_MAX_WAIT.getInteger();
            if (!partitionService.prepareToSafeShutdown(maxWaitSeconds, TimeUnit.SECONDS)) {
                logger.warning("Graceful shutdown could not be completed in " + maxWaitSeconds + " seconds!");
            }
        }
        if (isActive()) {
            if (!terminate) {
                final int maxWaitSeconds = groupProperties.GRACEFUL_SHUTDOWN_MAX_WAIT.getInteger();
                if (!partitionService.prepareToSafeShutdown(maxWaitSeconds, TimeUnit.SECONDS)) {
                    logger.warning("Graceful shutdown could not be completed in " + maxWaitSeconds + " seconds!");
                }
                clusterService.sendShutdownMessage();
            } else {
                logger.warning("Terminating forcefully...");
            }
            
            
            
            joined.set(false);
            setActive(false);
            setMasterAddress(null);
            try {
                if (groupProperties.SHUTDOWNHOOK_ENABLED.getBoolean())
                    Runtime.getRuntime().removeShutdownHook(shutdownHookThread);
            } catch (Throwable ignored) {
            }
            versionCheck.shutdown();
            if (managementCenterService != null) {
                managementCenterService.shutdown();
            }

            textCommandService.stop();
            if (multicastService != null) {
                logger.info("Shutting down multicast service...");
                multicastService.stop();
            }
            logger.info("Shutting down connection manager...");
            connectionManager.shutdown();

            logger.info("Shutting down node engine...");
            nodeEngine.shutdown(terminate);

            if (securityContext != null) {
                securityContext.destroy();
            }
            nodeExtension.destroy();
            logger.finest("Destroying serialization service...");
            serializationService.destroy();

            hazelcastThreadGroup.destroy();
            logger.info("Hazelcast Shutdown is completed in " + (Clock.currentTimeMillis() - start) + " ms.");
        }
    }

    
    public void reset() {
        setMasterAddress(null);
        joined.set(false);
        joiner.reset();
    }

    public ILogger getLogger(String name) {
        return loggingService.getLogger(name);
    }

    public ILogger getLogger(Class clazz) {
        return loggingService.getLogger(clazz);
    }

    public GroupProperties getGroupProperties() {
        return groupProperties;
    }

    public TextCommandService getTextCommandService() {
        return textCommandService;
    }

    public ConnectionManager getConnectionManager() {
        return connectionManager;
    }

    public void inactivate() {
        joined.set(false);
        setActive(false);
    }

    public ClassLoader getConfigClassLoader() {
        return configClassLoader;
    }

    public NodeEngineImpl getNodeEngine() {
        return nodeEngine;
    }

    public NodeExtension getNodeExtension() {
        return nodeExtension;
    }

    public class NodeShutdownHookThread extends Thread {

        NodeShutdownHookThread(String name) {
            super(name);
        }

        @Override
        public void run() {
            try {
                if (isActive() && !completelyShutdown) {
                    completelyShutdown = true;
                    hazelcastInstance.getLifecycleService().terminate();
                } else {
                    logger.finest(
                            "shutdown hook - we are not --> active and not completely down so we are not calling shutdown");
                }
            } catch (Exception e) {
                logger.warning(e);
            }
        }
    }

    public void setJoined() {
        joined.set(true);
    }

    public JoinMessage createSplitBrainJoinMessage() {
        return new JoinMessage(Packet.VERSION, buildInfo.getBuildNumber(), address, localMember.getUuid(),
                createConfigCheck(), clusterService.getMemberAddresses());
    }

    public JoinRequest createJoinRequest(boolean withCredentials) {
        final Credentials credentials = (withCredentials && securityContext != null)
                ? securityContext.getCredentialsFactory().newCredentials() : null;

        return new JoinRequest(Packet.VERSION, buildInfo.getBuildNumber(), address,
                localMember.getUuid(), createConfigCheck(), credentials,
                config.getMemberAttributeConfig().getAttributes());
    }

    public ConfigCheck createConfigCheck() {
        String joinerType = joiner == null ? "" : joiner.getType();
        return new ConfigCheck(config, joinerType);
    }

    public void rejoin() {
        prepareForJoin();
        join();
    }

    private void prepareForJoin() {
        masterAddress = null;
        joined.set(false);
        clusterService.reset();
    }

    public void join() {
        if (joiner == null) {
            logger.warning("No join method is enabled! Starting standalone.");
            setAsMaster();
            return;
        }

        try {
            prepareForJoin();
            joiner.join();
        } catch (Throwable e) {
            logger.severe("Error while joining the cluster!", e);
        }

        if (!joined()) {
            long maxJoinTime = groupProperties.MAX_JOIN_SECONDS.getInteger() * 1000L;
            logger.severe("Could not join cluster in " + maxJoinTime + " ms. Shutting down now!");
            shutdownNodeByFiringEvents(Node.this, true);
        }
    }

    public Joiner getJoiner() {
        return joiner;
    }

    Joiner createJoiner() {
        JoinConfig join = config.getNetworkConfig().getJoin();
        join.verify();

        if (join.getMulticastConfig().isEnabled() && multicastService != null) {
            logger.info("Creating MulticastJoiner");
            return new MulticastJoiner(this);
        } else if (join.getTcpIpConfig().isEnabled()) {
            logger.info("Creating TcpIpJoiner");
            return new TcpIpJoiner(this);
        } else if (join.getAwsConfig().isEnabled()) {
            Class clazz;
            try {
                logger.info("Creating AWSJoiner");
                clazz = Class.forName("com.hazelcast.cluster.impl.TcpIpJoinerOverAWS");
                Constructor constructor = clazz.getConstructor(Node.class);
                return (Joiner) constructor.newInstance(this);
            } catch (Exception e) {
                throw ExceptionUtil.rethrow(e);
            }
        }
        return null;
    }


    public void setAsMaster() {
        logger.finest("This node is being set as the master");
        masterAddress = address;
        setJoined();
        this.getClusterService().getClusterClock().
                setClusterStartTime(Clock.currentTimeMillis());
        this.getClusterService().setClusterId(
                UuidUtil.createClusterUuid()
        );
    }

    public Config getConfig() {
        return config;
    }

    
    public void setActive(boolean active) {
        this.active = active;
    }

    
    public boolean isActive() {
        return active;
    }

    @Override
    public String toString() {
        return "Node[" + hazelcastInstance.getName() + "]";
    }

    public BuildInfo getBuildInfo() {
        return buildInfo;
    }

    private Map<String, Object> findMemberAttributes(MemberAttributeConfig attributeConfig) {
        Map<String, Object> attributes = new HashMap<String, Object>(attributeConfig.getAttributes());
        Properties properties = System.getProperties();
        for (String key : properties.stringPropertyNames()) {
            if (key.startsWith("hazelcast.member.attribute.")) {
                String shortKey = key.substring("hazelcast.member.attribute.".length());
                String value = properties.getProperty(key);
                attributes.put(shortKey, value);
            }
        }
        return attributes;
    }
}

<code block>


package com.hazelcast.spi.impl.packettransceiver.impl;

import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.Packet;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.PacketHandler;
import com.hazelcast.spi.impl.packettransceiver.PacketTransceiver;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.util.concurrent.TimeUnit;

import static com.hazelcast.instance.OutOfMemoryErrorDispatcher.inspectOutputMemoryError;


public class PacketTransceiverImpl implements PacketTransceiver {

    private static final int RETRY_NUMBER = 5;
    private static final int DELAY_FACTOR = 100;

    private final Node node;
    private final ExecutionService executionService;
    private final ILogger logger;
    private final PacketHandler eventService;
    private final PacketHandler wanReplicationService;
    private final PacketHandler operationService;

    public PacketTransceiverImpl(Node node,
                                 ILogger logger,
                                 PacketHandler operationService,
                                 PacketHandler eventService,
                                 PacketHandler wanReplicationService,
                                 ExecutionService executionService) {
        this.node = node;
        this.executionService = executionService;
        this.operationService = operationService;
        this.eventService = eventService;
        this.wanReplicationService = wanReplicationService;
        this.logger = logger;
    }

    @Override
    public boolean transmit(Packet packet, Connection connection) {
        if (connection == null || !connection.isAlive()) {
            return false;
        }
        return connection.write(packet);
    }

    @Override
    public void receive(Packet packet) {
        try {
            if (packet.isHeaderSet(Packet.HEADER_OP)) {
                operationService.handle(packet);
            } else if (packet.isHeaderSet(Packet.HEADER_EVENT)) {
                eventService.handle(packet);
            } else if (packet.isHeaderSet(Packet.HEADER_WAN_REPLICATION)) {
                wanReplicationService.handle(packet);
            } else {
                logger.severe("Unknown packet type! Header: " + packet.getHeader());
            }
        } catch (Throwable t) {
            inspectOutputMemoryError(t);
            logger.severe("Failed to process packet:" + packet, t);
        }
    }

    
    @Override
    public boolean transmit(Packet packet, Address target) {
        return send(packet, target, null);
    }

    private boolean send(Packet packet, Address target, SendTask sendTask) {
        ConnectionManager connectionManager = node.getConnectionManager();
        Connection connection = connectionManager.getConnection(target);
        if (connection != null) {
            return transmit(packet, connection);
        }

        if (sendTask == null) {
            sendTask = new SendTask(packet, target);
        }

        final int retries = sendTask.retries;
        if (retries < RETRY_NUMBER && node.isActive()) {
            connectionManager.getOrConnect(target, true);
            
            executionService.schedule(sendTask, (retries + 1) * DELAY_FACTOR, TimeUnit.MILLISECONDS);
            return true;
        }
        return false;
    }

    private final class SendTask implements Runnable {
        private final Packet packet;
        private final Address target;
        private volatile int retries;

        private SendTask(Packet packet, Address target) {
            this.packet = packet;
            this.target = target;
        }

        @SuppressFBWarnings(value = "VO_VOLATILE_INCREMENT", justification = "single-writer, many-reader")
        @Override
        public void run() {
            retries++;
            if (logger.isFinestEnabled()) {
                logger.finest("Retrying[" + retries + "] packet send operation to: " + target);
            }
            send(packet, target, this);
        }
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.operations.JoinCheckOperation;
import com.hazelcast.cluster.impl.operations.MemberRemoveOperation;
import com.hazelcast.cluster.impl.operations.MergeClustersOperation;
import com.hazelcast.cluster.impl.operations.PrepareMergeOperation;
import com.hazelcast.config.Config;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.OperationResponseHandlerFactory;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;

import java.util.ArrayList;
import java.util.Collection;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.logging.Level;

import static com.hazelcast.spi.impl.OperationResponseHandlerFactory.*;
import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;

public abstract class AbstractJoiner implements Joiner {

    private static final int SPLIT_BRAIN_CONN_TIMEOUT = 5000;
    private static final int SPLIT_BRAIN_SLEEP_TIME = 10;

    private final ExceptionHandler whileWaitMergeExceptionHandler;
    private final AtomicLong joinStartTime = new AtomicLong(Clock.currentTimeMillis());
    private final AtomicInteger tryCount = new AtomicInteger(0);
    
    protected final ConcurrentMap<Address, Boolean> blacklistedAddresses = new ConcurrentHashMap<Address, Boolean>();
    protected final Config config;
    protected final Node node;
    protected final ILogger logger;

    private volatile Address targetAddress;

    public AbstractJoiner(Node node) {
        this.node = node;
        this.logger = node.loggingService.getLogger(getClass());
        this.config = node.config;
        whileWaitMergeExceptionHandler =
                logAllExceptions(logger, "While waiting merge response...", Level.FINEST);
    }

    @Override
    public void blacklist(Address address, boolean permanent) {
        logger.info(address + " is added to the blacklist.");
        blacklistedAddresses.putIfAbsent(address, permanent);
    }

    @Override
    public boolean unblacklist(Address address) {
        if (blacklistedAddresses.remove(address, Boolean.FALSE)) {
            logger.info(address + " is removed from the blacklist.");
            return true;
        }
        return false;
    }

    @Override
    public boolean isBlacklisted(Address address) {
        return blacklistedAddresses.containsKey(address);
    }

    public abstract void doJoin();

    @Override
    public final void join() {
        blacklistedAddresses.clear();
        doJoin();
        postJoin();
    }

    private void postJoin() {
        blacklistedAddresses.clear();

        if (logger.isFinestEnabled()) {
            logger.finest("PostJoin master: " + node.getMasterAddress() + ", isMaster: " + node.isMaster());
        }
        if (!node.isActive()) {
            return;
        }
        if (tryCount.incrementAndGet() == 5) {
            logger.warning("Join try count exceed limit, setting this node as master!");
            node.setAsMaster();
        }

        if (node.joined()) {
            if (!node.isMaster()) {
                ensureConnectionToAllMembers();
            }

            if (node.getClusterService().getSize() == 1) {
                final StringBuilder sb = new StringBuilder("\n");
                sb.append(node.clusterService.membersString());
                logger.info(sb.toString());
            }
        }
    }

    private void ensureConnectionToAllMembers() {
        boolean allConnected = false;
        if (node.joined()) {
            logger.finest("Waiting for all connections");
            int connectAllWaitSeconds = node.groupProperties.CONNECT_ALL_WAIT_SECONDS.getInteger();
            int checkCount = 0;
            while (checkCount++ < connectAllWaitSeconds && !allConnected) {
                try {
                    
                    Thread.sleep(1000);
                } catch (InterruptedException ignored) {
                }

                allConnected = true;
                Collection<MemberImpl> members = node.getClusterService().getMemberList();
                for (MemberImpl member : members) {
                    if (!member.localMember() && node.connectionManager.getOrConnect(member.getAddress()) == null) {
                        allConnected = false;
                        if (logger.isFinestEnabled()) {
                            logger.finest("Not-connected to " + member.getAddress());
                        }
                    }
                }
            }
        }
    }

    protected final long getMaxJoinMillis() {return node.getGroupProperties().MAX_JOIN_SECONDS.getInteger() * 1000L;}

    protected final long getMaxJoinTimeToMasterNode() {
        
        
        
        return (node.getGroupProperties().MAX_WAIT_SECONDS_BEFORE_JOIN.getInteger() + 10) * 1000L;
    }

    boolean shouldMerge(JoinMessage joinMessage) {
        if (joinMessage == null) {
            return false;
        }

        ClusterServiceImpl clusterService = node.getClusterService();
        try {
            boolean validJoinRequest = clusterService.validateJoinMessage(joinMessage);
            if (!validJoinRequest) {
                logger.finest("Cannot process split brain merge message from " + joinMessage.getAddress()
                        + ", since join-message could not be validated.");
                return false;
            }
        } catch (Exception e) {
            logger.finest(e.getMessage());
            return false;
        }

        try {
            if (clusterService.getMember(joinMessage.getAddress()) != null) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Should not merge to " + joinMessage.getAddress()
                            + ", because it is already member of this cluster.");
                }
                return false;
            }

            Collection<Address> targetMemberAddresses = joinMessage.getMemberAddresses();
            if (targetMemberAddresses.contains(node.getThisAddress())) {
                node.nodeEngine.getOperationService()
                        .send(new MemberRemoveOperation(node.getThisAddress()), joinMessage.getAddress());
                logger.info(node.getThisAddress() + " CANNOT merge to " + joinMessage.getAddress()
                    + ", because it thinks this-node as its member.");
                return false;
            }

            Collection<Address> thisMemberAddresses = clusterService.getMemberAddresses();
            for (Address address : thisMemberAddresses) {
                if (targetMemberAddresses.contains(address)) {
                    logger.info(node.getThisAddress() + " CANNOT merge to " + joinMessage.getAddress()
                            + ", because it thinks " + address + " as its member. "
                            + "But " + address + " is member of this cluster.");
                    return false;
                }
            }

            int currentMemberCount = clusterService.getSize();
            if (joinMessage.getMemberCount() > currentMemberCount) {
                
                logger.info(node.getThisAddress() + " is merging to " + joinMessage.getAddress()
                        + ", because : joinMessage.getMemberCount() > currentMemberCount ["
                        + (joinMessage.getMemberCount() + " > " + currentMemberCount) + "]");
                if (logger.isFinestEnabled()) {
                    logger.finest(joinMessage.toString());
                }
                return true;
            } else if (joinMessage.getMemberCount() == currentMemberCount) {
                
                if (node.getThisAddress().hashCode() > joinMessage.getAddress().hashCode()) {
                    logger.info(node.getThisAddress() + " is merging to " + joinMessage.getAddress()
                            + ", because : node.getThisAddress().hashCode() > joinMessage.address.hashCode() "
                            + ", this node member count: " + currentMemberCount);
                    if (logger.isFinestEnabled()) {
                        logger.finest(joinMessage.toString());
                    }
                    return true;
                } else {
                    logger.info(joinMessage.getAddress() + " should merge to this node "
                            + ", because : node.getThisAddress().hashCode() < joinMessage.address.hashCode() "
                            + ", this node member count: " + currentMemberCount);
                }
            } else {
                logger.info(joinMessage.getAddress() + " should merge to this node "
                        + ", because : currentMemberCount > joinMessage.getMemberCount() ["
                        + (currentMemberCount + " > " + joinMessage.getMemberCount()) + "]");
            }
        } catch (Throwable e) {
            logger.severe(e);
        }
        return false;
    }

    JoinMessage sendSplitBrainJoinMessage(Address target) {
        if (logger.isFinestEnabled()) {
            logger.finest(node.getThisAddress() + " is connecting to " + target);
        }

        Connection conn = node.connectionManager.getOrConnect(target, true);
        int timeout = SPLIT_BRAIN_CONN_TIMEOUT;
        while (conn == null) {
            if ((timeout -= SPLIT_BRAIN_SLEEP_TIME) < 0) {
                return null;
            }
            try {
                
                Thread.sleep(SPLIT_BRAIN_SLEEP_TIME);
            } catch (InterruptedException e) {
                EmptyStatement.ignore(e);
                return null;
            }
            conn = node.connectionManager.getConnection(target);
        }

        NodeEngine nodeEngine = node.nodeEngine;
        Future f = nodeEngine.getOperationService().createInvocationBuilder(ClusterServiceImpl.SERVICE_NAME,
                new JoinCheckOperation(node.createSplitBrainJoinMessage()), target)
                .setTryCount(1).invoke();
        try {
            return (JoinMessage) f.get(5, TimeUnit.SECONDS);
        } catch (TimeoutException e) {
            logger.finest("Timeout during join check!", e);
        } catch (Exception e) {
            logger.warning("Error during join check!", e);
        }
        return null;
    }

    @Override
    public void reset() {
        joinStartTime.set(Clock.currentTimeMillis());
        tryCount.set(0);
    }

    protected void startClusterMerge(final Address targetAddress) {
        final OperationService operationService = node.nodeEngine.getOperationService();
        final Collection<MemberImpl> memberList = node.getClusterService().getMemberList();
        final Collection<Future> calls = new ArrayList<Future>();
        for (MemberImpl member : memberList) {
            if (!member.localMember()) {
                Operation operation = new PrepareMergeOperation(targetAddress);
                Future f = operationService.createInvocationBuilder(ClusterServiceImpl.SERVICE_NAME,
                        operation, member.getAddress()).setTryCount(3).invoke();
                calls.add(f);
            }
        }

        waitWithDeadline(calls, 3, TimeUnit.SECONDS, whileWaitMergeExceptionHandler);

        final PrepareMergeOperation prepareMergeOperation = new PrepareMergeOperation(targetAddress);
        prepareMergeOperation.setNodeEngine(node.nodeEngine).setService(node.getClusterService())
                .setOperationResponseHandler(createEmptyResponseHandler());
        operationService.runOperationOnCallingThread(prepareMergeOperation);


        for (MemberImpl member : memberList) {
            if (!member.localMember()) {
                operationService.createInvocationBuilder(ClusterServiceImpl.SERVICE_NAME,
                        new MergeClustersOperation(targetAddress), member.getAddress())
                        .setTryCount(1).invoke();
            }
        }

        final MergeClustersOperation mergeClustersOperation = new MergeClustersOperation(targetAddress);
        mergeClustersOperation.setNodeEngine(node.nodeEngine).setService(node.getClusterService())
                .setOperationResponseHandler(createEmptyResponseHandler());
        operationService.runOperationOnCallingThread(mergeClustersOperation);
    }

    @Override
    public final long getStartTime() {
        return joinStartTime.get();
    }

    @Override
    public void setTargetAddress(Address targetAddress) {
        this.targetAddress = targetAddress;
    }

    public Address getTargetAddress() {
        final Address target = targetAddress;
        targetAddress = null;
        return target;
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;

public class JoinMessage implements DataSerializable {

    protected byte packetVersion;
    protected int buildNumber;
    protected Address address;
    protected String uuid;
    protected ConfigCheck configCheck;
    protected Collection<Address> memberAddresses;

    public JoinMessage() {
    }

    public JoinMessage(byte packetVersion, int buildNumber, Address address,
            String uuid, ConfigCheck configCheck) {
        this(packetVersion, buildNumber, address, uuid, configCheck, Collections.<Address>emptySet());
    }

    public JoinMessage(byte packetVersion, int buildNumber, Address address,
            String uuid, ConfigCheck configCheck, Collection<Address> memberAddresses) {
        this.packetVersion = packetVersion;
        this.buildNumber = buildNumber;
        this.address = address;
        this.uuid = uuid;
        this.configCheck = configCheck;
        this.memberAddresses = memberAddresses;
    }

    public byte getPacketVersion() {
        return packetVersion;
    }

    public int getBuildNumber() {
        return buildNumber;
    }

    public Address getAddress() {
        return address;
    }

    public String getUuid() {
        return uuid;
    }

    public ConfigCheck getConfigCheck() {
        return configCheck;
    }

    public int getMemberCount() {
        return memberAddresses != null ? memberAddresses.size() : 0;
    }

    public Collection<Address> getMemberAddresses() {
        return memberAddresses != null ? memberAddresses : Collections.<Address>emptySet();
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        packetVersion = in.readByte();
        buildNumber = in.readInt();
        address = new Address();
        address.readData(in);
        uuid = in.readUTF();
        configCheck = new ConfigCheck();
        configCheck.readData(in);

        int memberCount = in.readInt();
        memberAddresses = new ArrayList<Address>(memberCount);
        for (int i = 0; i < memberCount; i++) {
            Address member = new Address();
            member.readData(in);
            memberAddresses.add(member);
        }

    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeByte(packetVersion);
        out.writeInt(buildNumber);
        address.writeData(out);
        out.writeUTF(uuid);
        configCheck.writeData(out);

        int memberCount = getMemberCount();
        out.writeInt(memberCount);
        if (memberCount > 0) {
            for (Address member : memberAddresses) {
                member.writeData(out);
            }
        }
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("JoinMessage");
        sb.append("{packetVersion=").append(packetVersion);
        sb.append(", buildNumber=").append(buildNumber);
        sb.append(", address=").append(address);
        sb.append(", uuid='").append(uuid).append('\'');
        sb.append(", memberCount=").append(getMemberCount());
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.config.NetworkConfig;
import com.hazelcast.instance.Node;
import com.hazelcast.nio.Address;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.RandomPicker;

import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

public class MulticastJoiner extends AbstractJoiner {

    private static final int PUBLISH_INTERVAL = 100;
    private static final long JOIN_RETRY_INTERVAL = 1000L;

    private final AtomicInteger currentTryCount = new AtomicInteger(0);
    private final AtomicInteger maxTryCount;

    public MulticastJoiner(Node node) {
        super(node);
        maxTryCount = new AtomicInteger(calculateTryCount());
    }

    @Override
    public void doJoin() {
        long joinStartTime = Clock.currentTimeMillis();
        long maxJoinMillis = getMaxJoinMillis();
        Address thisAddress = node.getThisAddress();

        while (node.isActive() && !node.joined() && (Clock.currentTimeMillis() - joinStartTime < maxJoinMillis)) {
            
            node.setMasterAddress(null);

            Address masterAddress = getTargetAddress();
            if (masterAddress == null) {
                masterAddress = findMasterWithMulticast();
            }
            node.setMasterAddress(masterAddress);

            if (masterAddress == null || thisAddress.equals(masterAddress)) {
                node.setAsMaster();
                return;
            }

            logger.info("Trying to join to discovered node: " + masterAddress);
            joinMaster();
        }
    }

    private void joinMaster() {
        long maxMasterJoinTime = getMaxJoinTimeToMasterNode();
        long start = Clock.currentTimeMillis();

        while (node.isActive() && !node.joined() && Clock.currentTimeMillis() - start < maxMasterJoinTime) {
            Address master = node.getMasterAddress();
            if (master != null) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Joining to master " + master);
                }
                node.clusterService.sendJoinRequest(master, true);
            } else {
                break;
            }

            try {
                Thread.sleep(JOIN_RETRY_INTERVAL);
            } catch (InterruptedException e) {
                EmptyStatement.ignore(e);
            }

            if (isBlacklisted(master)) {
                node.setMasterAddress(null);
                return;
            }
        }
    }

    @Override
    public void searchForOtherClusters() {
        final BlockingQueue<JoinMessage> q = new LinkedBlockingQueue<JoinMessage>();
        MulticastListener listener = new MulticastListener() {
            public void onMessage(Object msg) {
                if (msg != null && msg instanceof JoinMessage) {
                    JoinMessage joinRequest = (JoinMessage) msg;
                    if (node.getThisAddress() != null && !node.getThisAddress().equals(joinRequest.getAddress())) {
                        q.add(joinRequest);
                    }
                }
            }
        };
        node.multicastService.addMulticastListener(listener);
        node.multicastService.send(node.createJoinRequest(false));
        try {
            JoinMessage joinInfo = q.poll(3, TimeUnit.SECONDS);
            if (joinInfo != null) {
                if (node.clusterService.getMember(joinInfo.getAddress()) != null) {
                    if (logger.isFinestEnabled()) {
                        logger.finest("Ignoring merge join response, since " + joinInfo.getAddress()
                            + " is already a member.");
                    }
                    return;
                }

                if (joinInfo.getMemberCount() == 1) {
                    
                    
                    
                    Thread.sleep(node.groupProperties.WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L * 2);
                }

                JoinMessage response = sendSplitBrainJoinMessage(joinInfo.getAddress());
                if (shouldMerge(response)) {
                    logger.warning(node.getThisAddress() + " is merging [multicast] to " + joinInfo.getAddress());
                    startClusterMerge(joinInfo.getAddress());
                }
            }
        } catch (InterruptedException ignored) {
        } catch (Exception e) {
            if (logger != null) {
                logger.warning(e);
            }
        } finally {
            node.multicastService.removeMulticastListener(listener);
        }
    }

    @Override
    public String getType() {
        return "multicast";
    }

    private Address findMasterWithMulticast() {
        try {
            if (logger.isFinestEnabled()) {
                logger.finest("Searching for master node. Max tries: " + maxTryCount.get());
            }
            JoinRequest joinRequest = node.createJoinRequest(false);
            while (node.isActive() && currentTryCount.incrementAndGet() <= maxTryCount.get()) {
                joinRequest.setTryCount(currentTryCount.get());
                node.multicastService.send(joinRequest);
                if (node.getMasterAddress() == null) {
                    
                    Thread.sleep(PUBLISH_INTERVAL);
                } else {
                    return node.getMasterAddress();
                }
            }
        } catch (final Exception e) {
            if (logger != null) {
                logger.warning(e);
            }
        } finally {
            currentTryCount.set(0);
        }
        return null;
    }

    private int calculateTryCount() {
        final NetworkConfig networkConfig = config.getNetworkConfig();
        int timeoutSeconds = networkConfig.getJoin().getMulticastConfig().getMulticastTimeoutSeconds();
        int tryCountCoefficient = 1000 / PUBLISH_INTERVAL;
        int tryCount = timeoutSeconds * tryCountCoefficient;
        String host = node.getThisAddress().getHost();
        int lastDigits;
        try {
            lastDigits = Integer.parseInt(host.substring(host.lastIndexOf('.') + 1));
        } catch (NumberFormatException e) {
            lastDigits = RandomPicker.getInt(512);
        }
        lastDigits = lastDigits % 100;
        int portDiff = node.getThisAddress().getPort() - networkConfig.getPort();
        tryCount += lastDigits + portDiff * timeoutSeconds * 3;
        return tryCount;
    }

    public void onReceivedJoinRequest(JoinRequest joinRequest) {
        if (joinRequest.getUuid().compareTo(node.localMember.getUuid()) < 0) {
            maxTryCount.incrementAndGet();
        }
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.core.Member;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Packet;

import java.util.Set;

import static com.hazelcast.util.AddressUtil.matchAnyInterface;
import static java.lang.String.format;

public class NodeMulticastListener implements MulticastListener {

    private final Node node;
    private final Set<String> trustedInterfaces;
    private final ILogger logger;
    private ConfigCheck ourConfig;

    public NodeMulticastListener(Node node) {
        this.node = node;
        this.trustedInterfaces = node.getConfig().getNetworkConfig()
                .getJoin().getMulticastConfig().getTrustedInterfaces();
        this.logger = node.getLogger(NodeMulticastListener.class.getName());
        this.ourConfig = node.createConfigCheck();
    }

    @Override
    public void onMessage(Object msg) {
        if (!isValidJoinMessage(msg)) {
            logDroppedMessage(msg);
            return;
        }

        JoinMessage joinMessage = (JoinMessage) msg;
        if (node.isActive() && node.joined()) {
            handleActiveAndJoined(joinMessage);
        } else {
            handleNotActiveOrNotJoined(joinMessage);
        }
    }

    private void logDroppedMessage(Object msg) {
        if (logger.isFinestEnabled()) {
            logger.finest("Dropped: " + msg);
        }
    }

    private void handleActiveAndJoined(JoinMessage joinMessage) {
        if (!(joinMessage instanceof JoinRequest)) {
            logDroppedMessage(joinMessage);
            return;
        }

        if (node.isMaster()) {
            JoinMessage response = new JoinMessage(Packet.VERSION, node.getBuildInfo().getBuildNumber(),
                    node.getThisAddress(), node.localMember.getUuid(), node.createConfigCheck());
            node.multicastService.send(response);
        } else if (isMasterNode(joinMessage.getAddress()) && !checkMasterUuid(joinMessage.getUuid())) {
            logger.warning("New join request has been received from current master. "
                    + "Removing " + node.getMasterAddress());
            node.getClusterService().removeAddress(node.getMasterAddress());
        }
    }

    private void handleNotActiveOrNotJoined(JoinMessage joinMessage) {
        if (isJoinRequest(joinMessage)) {
            Joiner joiner = node.getJoiner();
            if (joiner instanceof MulticastJoiner) {
                MulticastJoiner multicastJoiner = (MulticastJoiner) joiner;
                multicastJoiner.onReceivedJoinRequest((JoinRequest) joinMessage);
            } else {
                logDroppedMessage(joinMessage);
            }
        } else {
            Address address = joinMessage.getAddress();
            if (node.getJoiner().isBlacklisted(address)) {
                logDroppedMessage(joinMessage);
                return;
            }

            if (!node.joined() && node.getMasterAddress() == null) {
                String masterHost = joinMessage.getAddress().getHost();
                if (trustedInterfaces.isEmpty() || matchAnyInterface(masterHost, trustedInterfaces)) {
                    
                    Address masterAddress = new Address(joinMessage.getAddress());
                    node.setMasterAddress(masterAddress);
                } else {
                    logJoinMessageDropped(masterHost);
                }
            } else {
                logDroppedMessage(joinMessage);
            }
        }
    }

    private boolean isJoinRequest(JoinMessage joinMessage) {
        return joinMessage instanceof JoinRequest;
    }

    private void logJoinMessageDropped(String masterHost) {
        if (logger.isFinestEnabled()) {
            logger.finest(format(
                    "JoinMessage from %s is dropped because its sender is not a trusted interface", masterHost));
        }
    }

    private boolean isJoinMessage(Object msg) {
        return msg != null && msg instanceof JoinMessage;
    }

    private boolean isValidJoinMessage(Object msg) {
        if (!isJoinMessage(msg)) {
            return false;
        }

        JoinMessage joinMessage = (JoinMessage) msg;

        if (isMessageToSelf(joinMessage)) {
            return false;
        }

        ConfigCheck theirConfig = joinMessage.getConfigCheck();
        if (!ourConfig.isSameGroup(theirConfig)) {
            return false;
        }
        return true;
    }

    private boolean isMessageToSelf(JoinMessage joinMessage) {
        Address thisAddress = node.getThisAddress();
        return thisAddress == null || thisAddress.equals(joinMessage.getAddress());
    }

    private boolean isMasterNode(Address address) {
        return address.equals(node.getMasterAddress());
    }

    private boolean checkMasterUuid(String uuid) {
        Member masterMember = getMasterMember(node.getClusterService().getMembers());
        return masterMember == null || masterMember.getUuid().equals(uuid);
    }

    private Member getMasterMember(Set<Member> members) {
        if (members.isEmpty()) {
            return null;
        }

        return members.iterator().next();
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.impl.operations.MasterClaimOperation;
import com.hazelcast.config.Config;
import com.hazelcast.config.InterfacesConfig;
import com.hazelcast.config.NetworkConfig;
import com.hazelcast.config.TcpIpConfig;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.Node;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.util.AddressUtil;
import com.hazelcast.util.AddressUtil.AddressMatcher;
import com.hazelcast.util.AddressUtil.InvalidAddressException;
import com.hazelcast.util.Clock;

import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.Set;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.util.AddressUtil.AddressHolder;

public class TcpIpJoiner extends AbstractJoiner {

    private static final long JOIN_RETRY_WAIT_TIME = 1000L;

    private final int maxPortTryCount;
    private volatile boolean claimingMaster;

    public TcpIpJoiner(Node node) {
        super(node);
        int tryCount = node.groupProperties.TCP_JOIN_PORT_TRY_COUNT.getInteger();
        if (tryCount <= 0) {
            throw new IllegalArgumentException(GroupProperties.PROP_TCP_JOIN_PORT_TRY_COUNT
                    + " should be greater than zero! Current value: " + tryCount);
        }
        maxPortTryCount = tryCount;
    }

    public boolean isClaimingMaster() {
        return claimingMaster;
    }

    protected int getConnTimeoutSeconds() {
        return config.getNetworkConfig().getJoin().getTcpIpConfig().getConnectionTimeoutSeconds();
    }

    @Override
    public void doJoin() {
        final Address targetAddress = getTargetAddress();
        if (targetAddress != null) {
            long maxJoinMergeTargetMillis = node.getGroupProperties().MAX_JOIN_MERGE_TARGET_SECONDS.getInteger() * 1000L;
            joinViaTargetMember(targetAddress, maxJoinMergeTargetMillis);
            if (!node.joined()) {
                joinViaPossibleMembers();
            }
        } else if (config.getNetworkConfig().getJoin().getTcpIpConfig().getRequiredMember() != null) {
            Address requiredMember = getRequiredMemberAddress();
            long maxJoinMillis = getMaxJoinMillis();
            joinViaTargetMember(requiredMember, maxJoinMillis);
        } else {
            joinViaPossibleMembers();
        }
    }

    private void joinViaTargetMember(Address targetAddress, long maxJoinMillis) {
        try {
            if (targetAddress == null) {
                throw new IllegalArgumentException("Invalid target address -> NULL");
            }
            if (logger.isFinestEnabled()) {
                logger.finest("Joining over target member " + targetAddress);
            }
            if (targetAddress.equals(node.getThisAddress()) || isLocalAddress(targetAddress)) {
                node.setAsMaster();
                return;
            }
            long joinStartTime = Clock.currentTimeMillis();
            Connection connection;
            while (node.isActive() && !node.joined() && (Clock.currentTimeMillis() - joinStartTime < maxJoinMillis)) {
                connection = node.connectionManager.getOrConnect(targetAddress);
                if (connection == null) {
                    
                    Thread.sleep(JOIN_RETRY_WAIT_TIME);
                    continue;
                }
                if (logger.isFinestEnabled()) {
                    logger.finest("Sending joinRequest " + targetAddress);
                }
                node.clusterService.sendJoinRequest(targetAddress, true);
                
                Thread.sleep(JOIN_RETRY_WAIT_TIME);
            }
        } catch (final Exception e) {
            logger.warning(e);
        }
    }

    private void joinViaPossibleMembers() {
        try {
            blacklistedAddresses.clear();
            Collection<Address> possibleAddresses = getPossibleAddresses();

            boolean foundConnection = tryInitialConnection(possibleAddresses);
            if (!foundConnection) {
                logger.finest("This node will assume master role since no possible member where connected to.");
                node.setAsMaster();
                return;
            }

            long maxJoinMillis = getMaxJoinMillis();
            long startTime = Clock.currentTimeMillis();

            while (node.isActive() && !node.joined() && (Clock.currentTimeMillis() - startTime < maxJoinMillis)) {

                tryToJoinPossibleAddresses(possibleAddresses);
                if (node.joined()) {
                    return;
                }

                if (isAllBlacklisted(possibleAddresses)) {
                    logger.finest(
                            "This node will assume master role since none of the possible members accepted join request.");
                    node.setAsMaster();
                    return;
                }

                boolean masterCandidate = isThisNodeMasterCandidate(possibleAddresses);
                if (masterCandidate) {
                    boolean consensus = claimMastership(possibleAddresses);
                    if (consensus) {
                        if (logger.isFinestEnabled()) {
                            Set<Address> votingEndpoints = new HashSet<Address>(possibleAddresses);
                            votingEndpoints.removeAll(blacklistedAddresses.keySet());
                            logger.finest("Setting myself as master after consensus! " +
                                    "Voting endpoints: " + votingEndpoints);
                        }
                        node.setAsMaster();
                        claimingMaster = false;
                        return;
                    }
                } else {
                    if (logger.isFinestEnabled()) {
                        logger.finest("Cannot claim myself as master! Will try to connect a possible master...");
                    }
                }

                claimingMaster = false;
                lookForMaster(possibleAddresses);
            }
        } catch (Throwable t) {
            logger.severe(t);
        }
    }

    private boolean claimMastership(Collection<Address> possibleAddresses) {
        if (logger.isFinestEnabled()) {
            Set<Address> votingEndpoints = new HashSet<Address>(possibleAddresses);
            votingEndpoints.removeAll(blacklistedAddresses.keySet());
            logger.finest("Claiming myself as master node! Asking to endpoints: " + votingEndpoints);
        }
        claimingMaster = true;
        Collection<Future<Boolean>> responses = new LinkedList<Future<Boolean>>();
        for (Address address : possibleAddresses) {
            if (isBlacklisted(address)) {
                continue;
            }
            if (node.getConnectionManager().getConnection(address) != null) {
                Future future = node.nodeEngine.getOperationService()
                        .createInvocationBuilder(ClusterServiceImpl.SERVICE_NAME,
                                new MasterClaimOperation(), address).setTryCount(1).invoke();
                responses.add(future);
            }
        }

        final long maxWait = TimeUnit.SECONDS.toMillis(10);
        long waitTime = 0L;
        boolean consensus = true;
        for (Future<Boolean> response : responses) {
            long t = Clock.currentTimeMillis();
            try {
                consensus = response.get(1, TimeUnit.SECONDS);
            } catch (Exception e) {
                logger.finest(e);
                consensus = false;
            } finally {
                waitTime += (Clock.currentTimeMillis() - t);
            }

            if (!consensus) {
                break;
            }

            if (waitTime > maxWait) {
                consensus = false;
                break;
            }
        }
        return consensus;
    }

    private boolean isThisNodeMasterCandidate(Collection<Address> possibleAddresses) {
        int thisHashCode = node.getThisAddress().hashCode();
        for (Address address : possibleAddresses) {
            if (isBlacklisted(address)) {
                continue;
            }
            if (node.connectionManager.getConnection(address) != null) {
                if (thisHashCode > address.hashCode()) {
                    return false;
                }
            }
        }
        return true;
    }

    private void tryToJoinPossibleAddresses(Collection<Address> possibleAddresses) throws InterruptedException {
        long connectionTimeoutMillis = getConnTimeoutSeconds() * 1000L;
        long start = Clock.currentTimeMillis();

        while (!node.joined() && Clock.currentTimeMillis() - start < connectionTimeoutMillis) {
            Address masterAddress = node.getMasterAddress();
            if (isAllBlacklisted(possibleAddresses) && masterAddress == null) {
                return;
            }

            if (masterAddress != null) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Sending join request to " + masterAddress);
                }
                node.clusterService.sendJoinRequest(masterAddress, true);
            } else {
                sendMasterQuestion(possibleAddresses);
            }

            if (!node.joined()) {
                Thread.sleep(JOIN_RETRY_WAIT_TIME);
            }
        }
    }

    private boolean tryInitialConnection(Collection<Address> possibleAddresses) throws InterruptedException {
        long connectionTimeoutMillis = getConnTimeoutSeconds() * 1000L;
        long start = Clock.currentTimeMillis();
        while (Clock.currentTimeMillis() - start < connectionTimeoutMillis) {
            if (isAllBlacklisted(possibleAddresses)) {
                return false;
            }
            if (logger.isFinestEnabled()) {
                logger.finest("Will send master question to each address in: " + possibleAddresses);
            }
            if (sendMasterQuestion(possibleAddresses)) {
                return true;
            }
            Thread.sleep(JOIN_RETRY_WAIT_TIME);
        }
        return false;
    }

    private boolean isAllBlacklisted(Collection<Address> possibleAddresses) {
        return blacklistedAddresses.keySet().containsAll(possibleAddresses);
    }

    private void lookForMaster(Collection<Address> possibleAddresses) throws InterruptedException {
        int tryCount = 0;
        while (node.getMasterAddress() == null && tryCount++ < 20) {
            sendMasterQuestion(possibleAddresses);
            
            Thread.sleep(JOIN_RETRY_WAIT_TIME);
            if (isAllBlacklisted(possibleAddresses)) {
                break;
            }
        }

        if (node.joined()) {
            return;
        }

        if (isAllBlacklisted(possibleAddresses) && node.getMasterAddress() == null) {
            if (logger.isFinestEnabled()) {
                logger.finest("Setting myself as master! No possible addresses remaining to connect...");
            }
            node.setAsMaster();
            return;
        }

        long maxMasterJoinTime = getMaxJoinTimeToMasterNode();
        long start = Clock.currentTimeMillis();

        while (node.isActive() && !node.joined() && Clock.currentTimeMillis() - start < maxMasterJoinTime) {
            Address master = node.getMasterAddress();
            if (master != null) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Joining to master " + master);
                }
                node.clusterService.sendJoinRequest(master, true);
            } else {
                break;
            }

            
            Thread.sleep(JOIN_RETRY_WAIT_TIME);
        }

        if (!node.joined()) {
            Address master = node.getMasterAddress();
            if (master != null) {
                logger.warning("Couldn't join to the master : " + master);
            } else {
                if (logger.isFinestEnabled()) {
                    logger.finest("Couldn't find a master! But there was connections available: " + possibleAddresses);
                }
            }
        }
    }

    private boolean sendMasterQuestion(Collection<Address> possibleAddresses) {
        if (logger.isFinestEnabled()) {
            logger.finest("NOT sending master question to blacklisted endpoints: " + blacklistedAddresses);
        }
        boolean sent = false;
        for (Address address : possibleAddresses) {
            if (isBlacklisted(address)) {
                continue;
            }
            if (logger.isFinestEnabled()) {
                logger.finest("Sending master question to " + address);
            }
            if (node.clusterService.sendMasterQuestion(address)) {
                sent = true;
            }
        }
        return sent;
    }

    private Address getRequiredMemberAddress() {
        final TcpIpConfig tcpIpConfig = config.getNetworkConfig().getJoin().getTcpIpConfig();
        final String host = tcpIpConfig.getRequiredMember();
        try {
            final AddressHolder addressHolder = AddressUtil.getAddressHolder(host, config.getNetworkConfig().getPort());
            if (AddressUtil.isIpAddress(addressHolder.getAddress())) {
                return new Address(addressHolder.getAddress(), addressHolder.getPort());
            } else {
                final InterfacesConfig interfaces = config.getNetworkConfig().getInterfaces();
                if (interfaces.isEnabled()) {
                    final InetAddress[] inetAddresses = InetAddress.getAllByName(addressHolder.getAddress());
                    if (inetAddresses.length > 1) {
                        for (InetAddress inetAddress : inetAddresses) {
                            if (AddressUtil.matchAnyInterface(inetAddress.getHostAddress(),
                                    interfaces.getInterfaces())) {
                                return new Address(inetAddress, addressHolder.getPort());
                            }
                        }
                    } else {
                        final InetAddress inetAddress = inetAddresses[0];
                        if (AddressUtil.matchAnyInterface(inetAddress.getHostAddress(),
                                interfaces.getInterfaces())) {
                            return new Address(addressHolder.getAddress(), addressHolder.getPort());
                        }
                    }
                } else {
                    return new Address(addressHolder.getAddress(), addressHolder.getPort());
                }
            }
        } catch (final Exception e) {
            logger.warning(e);
        }
        return null;
    }

    private Collection<Address> getPossibleAddresses() {
        final Collection<String> possibleMembers = getMembers();
        final Set<Address> possibleAddresses = new HashSet<Address>();
        final NetworkConfig networkConfig = config.getNetworkConfig();
        for (String possibleMember : possibleMembers) {
            AddressHolder addressHolder = AddressUtil.getAddressHolder(possibleMember);
            try {
                boolean portIsDefined = addressHolder.getPort() != -1 || !networkConfig.isPortAutoIncrement();
                int count = portIsDefined ? 1 : maxPortTryCount;
                int port = addressHolder.getPort() != -1 ? addressHolder.getPort() : networkConfig.getPort();
                AddressMatcher addressMatcher = null;
                try {
                    addressMatcher = AddressUtil.getAddressMatcher(addressHolder.getAddress());
                } catch (InvalidAddressException ignore) {
                }
                if (addressMatcher != null) {
                    final Collection<String> matchedAddresses;
                    if (addressMatcher.isIPv4()) {
                        matchedAddresses = AddressUtil.getMatchingIpv4Addresses(addressMatcher);
                    } else {
                        
                        matchedAddresses = Collections.singleton(addressHolder.getAddress());
                    }
                    for (String matchedAddress : matchedAddresses) {
                        addPossibleAddresses(possibleAddresses, null, InetAddress.getByName(matchedAddress), port, count);
                    }
                } else {
                    final String host = addressHolder.getAddress();
                    final InterfacesConfig interfaces = networkConfig.getInterfaces();
                    if (interfaces.isEnabled()) {
                        final InetAddress[] inetAddresses = InetAddress.getAllByName(host);
                        if (inetAddresses.length > 1) {
                            for (InetAddress inetAddress : inetAddresses) {
                                if (AddressUtil.matchAnyInterface(inetAddress.getHostAddress(),
                                        interfaces.getInterfaces())) {
                                    addPossibleAddresses(possibleAddresses, null, inetAddress, port, count);
                                }
                            }
                        } else {
                            final InetAddress inetAddress = inetAddresses[0];
                            if (AddressUtil.matchAnyInterface(inetAddress.getHostAddress(),
                                    interfaces.getInterfaces())) {
                                addPossibleAddresses(possibleAddresses, host, null, port, count);
                            }
                        }
                    } else {
                        addPossibleAddresses(possibleAddresses, host, null, port, count);
                    }
                }
            } catch (UnknownHostException e) {
                logger.warning("Cannot resolve hostname '" + addressHolder.getAddress()
                        + "'. Please make sure host is valid and reachable.");
                if (logger.isFinestEnabled()) {
                    logger.finest("Error during resolving possible target!", e);
                }
            }
        }

        possibleAddresses.remove(node.getThisAddress());
        return possibleAddresses;
    }

    private void addPossibleAddresses(final Set<Address> possibleAddresses,
                                      final String host, final InetAddress inetAddress,
                                      final int port, final int count) throws UnknownHostException {
        for (int i = 0; i < count; i++) {
            int currentPort = port + i;
            Address address = host != null ? new Address(host, currentPort) : new Address(inetAddress, currentPort);
            if (!isLocalAddress(address)) {
                possibleAddresses.add(address);
            }
        }
    }

    private boolean isLocalAddress(final Address address) throws UnknownHostException {
        final Address thisAddress = node.getThisAddress();
        final boolean local = thisAddress.getInetSocketAddress().equals(address.getInetSocketAddress());
        if (logger.isFinestEnabled()) {
            logger.finest(address + " is local? " + local);
        }
        return local;
    }

    protected Collection<String> getMembers() {
        return getConfigurationMembers(config);
    }

    public static Collection<String> getConfigurationMembers(Config config) {
        final TcpIpConfig tcpIpConfig = config.getNetworkConfig().getJoin().getTcpIpConfig();
        final Collection<String> configMembers = tcpIpConfig.getMembers();
        final Set<String> possibleMembers = new HashSet<String>();
        for (String member : configMembers) {
            
            String[] members = member.split("[,; ]");
            Collections.addAll(possibleMembers, members);
        }
        return possibleMembers;
    }

    @Override
    public void searchForOtherClusters() {
        final Collection<Address> possibleAddresses;
        try {
            possibleAddresses = getPossibleAddresses();
        } catch (Throwable e) {
            logger.severe(e);
            return;
        }
        possibleAddresses.remove(node.getThisAddress());
        possibleAddresses.removeAll(node.getClusterService().getMemberAddresses());

        if (possibleAddresses.isEmpty()) {
            return;
        }
        for (Address address : possibleAddresses) {
            JoinMessage response = sendSplitBrainJoinMessage(address);
            if (shouldMerge(response)) {
                logger.warning(node.getThisAddress() + " is merging [tcp/ip] to " + address);
                setTargetAddress(address);
                startClusterMerge(address);
                return;
            }
        }
    }

    @Override
    public String getType() {
        return "tcp-ip";
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.cluster.MemberAttributeOperationType;
import com.hazelcast.cluster.MemberInfo;
import com.hazelcast.cluster.impl.operations.AuthenticationFailureOperation;
import com.hazelcast.cluster.impl.operations.BeforeJoinCheckFailureOperation;
import com.hazelcast.cluster.impl.operations.ConfigMismatchOperation;
import com.hazelcast.cluster.impl.operations.FinalizeJoinOperation;
import com.hazelcast.cluster.impl.operations.GroupMismatchOperation;
import com.hazelcast.cluster.impl.operations.HeartbeatOperation;
import com.hazelcast.cluster.impl.operations.JoinRequestOperation;
import com.hazelcast.cluster.impl.operations.MasterConfirmationOperation;
import com.hazelcast.cluster.impl.operations.MasterDiscoveryOperation;
import com.hazelcast.cluster.impl.operations.MemberInfoUpdateOperation;
import com.hazelcast.cluster.impl.operations.MemberRemoveOperation;
import com.hazelcast.cluster.impl.operations.PostJoinOperation;
import com.hazelcast.cluster.impl.operations.SetMasterOperation;
import com.hazelcast.cluster.impl.operations.TriggerMemberListPublishOperation;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.InitialMembershipEvent;
import com.hazelcast.core.InitialMembershipListener;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberAttributeEvent;
import com.hazelcast.core.MembershipEvent;
import com.hazelcast.core.MembershipListener;
import com.hazelcast.instance.BuildInfo;
import com.hazelcast.instance.HazelcastInstanceImpl;
import com.hazelcast.instance.LifecycleServiceImpl;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.Packet;
import com.hazelcast.security.Credentials;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.MemberAttributeServiceEvent;
import com.hazelcast.spi.MembershipAwareService;
import com.hazelcast.spi.MembershipServiceEvent;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.SplitBrainHandlerService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.executor.ExecutorType;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import javax.security.auth.login.LoginContext;
import javax.security.auth.login.LoginException;
import java.net.ConnectException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.Date;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.LinkedHashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;

import static com.hazelcast.cluster.impl.operations.FinalizeJoinOperation.FINALIZE_JOIN_MAX_TIMEOUT;
import static com.hazelcast.cluster.impl.operations.FinalizeJoinOperation.FINALIZE_JOIN_TIMEOUT_FACTOR;
import static com.hazelcast.core.LifecycleEvent.LifecycleState.MERGED;
import static com.hazelcast.core.LifecycleEvent.LifecycleState.MERGING;
import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;
import static com.hazelcast.util.Preconditions.checkNotNull;
import static com.hazelcast.util.Preconditions.isNotNull;
import static java.util.Collections.unmodifiableMap;
import static java.util.Collections.unmodifiableSet;

public final class ClusterServiceImpl implements ClusterService, ConnectionListener, ManagedService,
        EventPublishingService<MembershipEvent, MembershipListener> {

    public static final String SERVICE_NAME = "hz:core:clusterService";

    private static final String EXECUTOR_NAME = "hz:cluster";
    private static final long HEARTBEAT_LOG_THRESHOLD = 10000L;

    private final Node node;

    private final NodeEngineImpl nodeEngine;

    private final ILogger logger;

    protected final Address thisAddress;

    protected final MemberImpl thisMember;

    private final long waitMillisBeforeJoin;

    private final long maxWaitMillisBeforeJoin;

    private final long heartbeatInterval;

    private final long maxNoHeartbeatMillis;

    private final long maxNoMasterConfirmationMillis;

    private final long heartbeatIntervalMillis;

    private final long pingIntervalMillis;

    private final boolean icmpEnabled;

    private final int icmpTtl;

    private final int icmpTimeout;

    private final Lock lock = new ReentrantLock();

    private final Set<MemberInfo> setJoins = new LinkedHashSet<MemberInfo>(100);

    private final AtomicReference<Map<Address, MemberImpl>> membersMapRef
            = new AtomicReference<Map<Address, MemberImpl>>(Collections.<Address, MemberImpl>emptyMap());

    private final AtomicReference<Set<MemberImpl>> membersRef = new AtomicReference<Set<MemberImpl>>(Collections.<MemberImpl>emptySet());

    private final AtomicBoolean preparingToMerge = new AtomicBoolean(false);

    private volatile boolean joinInProgress;

    private long timeToStartJoin;

    @Probe(name = "lastHeartBeat")
    private volatile long lastHeartBeat;

    private long firstJoinRequest;

    private final ConcurrentMap<MemberImpl, Long> heartbeatTimes = new ConcurrentHashMap<MemberImpl, Long>();

    private final ConcurrentMap<MemberImpl, Long> masterConfirmationTimes = new ConcurrentHashMap<MemberImpl, Long>();

    private final ExceptionHandler whileFinalizeJoinsExceptionHandler;

    private final ClusterClockImpl clusterClock;

    private String clusterId = null;

    public ClusterServiceImpl(final Node node) {
        this.node = node;
        nodeEngine = node.nodeEngine;
        logger = node.getLogger(ClusterService.class.getName());
        clusterClock = new ClusterClockImpl(logger);
        whileFinalizeJoinsExceptionHandler =
                logAllExceptions(logger, "While waiting finalize join calls...", Level.WARNING);
        thisAddress = node.getThisAddress();
        thisMember = node.getLocalMember();
        setMembers(thisMember);
        waitMillisBeforeJoin = node.groupProperties.WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L;
        maxWaitMillisBeforeJoin = node.groupProperties.MAX_WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L;
        long heartbeatIntervalSeconds = node.groupProperties.HEARTBEAT_INTERVAL_SECONDS.getInteger();
        heartbeatIntervalSeconds = heartbeatIntervalSeconds <= 0 ? 1 : heartbeatIntervalSeconds;
        heartbeatInterval = heartbeatIntervalSeconds;
        maxNoHeartbeatMillis = node.groupProperties.MAX_NO_HEARTBEAT_SECONDS.getInteger() * 1000L;
        maxNoMasterConfirmationMillis = node.groupProperties.MAX_NO_MASTER_CONFIRMATION_SECONDS.getInteger() * 1000L;
        icmpEnabled = node.groupProperties.ICMP_ENABLED.getBoolean();
        icmpTtl = node.groupProperties.ICMP_TTL.getInteger();
        icmpTimeout = node.groupProperties.ICMP_TIMEOUT.getInteger();
        long heartbeatInterval = node.groupProperties.HEARTBEAT_INTERVAL_SECONDS.getInteger();
        heartbeatIntervalMillis = heartbeatInterval > 0 ? heartbeatInterval * 1000L : 1000L;
        pingIntervalMillis = heartbeatIntervalMillis * 5;
        node.connectionManager.addConnectionListener(this);

        registerMetrics();
    }

    void registerMetrics() {
        MetricsRegistry metricsRegistry = node.nodeEngine.getMetricsRegistry();
        metricsRegistry.scanAndRegister(clusterClock, "cluster.clock");
        metricsRegistry.scanAndRegister(this, "cluster");
    }

    @Override
    public ClusterClockImpl getClusterClock() {
        return clusterClock;
    }

    @Override
    public String getClusterId() {
        return clusterId;
    }

    public void setClusterId(String clusterId) {
        if (this.clusterId == null) {
            this.clusterId = clusterId;
        }
    }

    @Override
    public void init(final NodeEngine nodeEngine, Properties properties) {
        long mergeFirstRunDelay = node.getGroupProperties().MERGE_FIRST_RUN_DELAY_SECONDS.getLong() * 1000;
        mergeFirstRunDelay = mergeFirstRunDelay <= 0 ? 100 : mergeFirstRunDelay; 

        ExecutionService executionService = nodeEngine.getExecutionService();
        executionService.register(EXECUTOR_NAME, 2, 1000, ExecutorType.CACHED);

        long mergeNextRunDelay = node.getGroupProperties().MERGE_NEXT_RUN_DELAY_SECONDS.getLong() * 1000;
        mergeNextRunDelay = mergeNextRunDelay <= 0 ? 100 : mergeNextRunDelay; 
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new SplitBrainHandler(node),
                mergeFirstRunDelay, mergeNextRunDelay, TimeUnit.MILLISECONDS);

        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                heartBeater();
            }
        }, heartbeatIntervalMillis, heartbeatIntervalMillis, TimeUnit.MILLISECONDS);

        long masterConfirmationInterval = node.groupProperties.MASTER_CONFIRMATION_INTERVAL_SECONDS.getInteger();
        masterConfirmationInterval = masterConfirmationInterval <= 0 ? 1 : masterConfirmationInterval;
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                sendMasterConfirmation();
            }
        }, masterConfirmationInterval, masterConfirmationInterval, TimeUnit.SECONDS);

        long memberListPublishInterval = node.groupProperties.MEMBER_LIST_PUBLISH_INTERVAL_SECONDS.getInteger();
        memberListPublishInterval = memberListPublishInterval <= 0 ? 1 : memberListPublishInterval;
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                sendMemberListToOthers();
            }
        }, memberListPublishInterval, memberListPublishInterval, TimeUnit.SECONDS);
    }

    public boolean isJoinInProgress() {
        if (joinInProgress) {
            return true;
        }

        lock.lock();
        try {
            return joinInProgress || !setJoins.isEmpty();
        } finally {
            lock.unlock();
        }
    }

    public boolean validateJoinMessage(JoinMessage joinMessage) throws Exception {
        boolean valid = Packet.VERSION == joinMessage.getPacketVersion();
        if (valid) {
            try {
                ConfigCheck newMemberConfigCheck = joinMessage.getConfigCheck();
                ConfigCheck clusterConfigCheck = node.createConfigCheck();
                valid = clusterConfigCheck.isCompatible(newMemberConfigCheck);
            } catch (Exception e) {
                final String message = "Invalid join request from: " + joinMessage.getAddress() + ", reason:" + e.getMessage();
                logger.warning(message);
                throw e;
            }
        }
        return valid;
    }

    private boolean isValidJoinMessage(JoinMessage joinMessage) {
        boolean validJoinRequest;
        try {
            validJoinRequest = validateJoinMessage(joinMessage);
        } catch (ConfigMismatchException e) {
            throw e;
        } catch (Exception e) {
            validJoinRequest = false;
        }
        return validJoinRequest;
    }

    private void logIfConnectionToEndpointIsMissing(long now, MemberImpl member) {
        long heartbeatTime = getHeartbeatTime(member);
        if ((now - heartbeatTime) >= pingIntervalMillis) {
            Connection conn = node.connectionManager.getOrConnect(member.getAddress());
            if (conn == null || !conn.isAlive()) {
                logger.warning("This node does not have a connection to " + member);
            }
        }
    }

    private long getHeartbeatTime(MemberImpl member) {
        Long heartbeatTime = heartbeatTimes.get(member);
        return heartbeatTime != null ? heartbeatTime : 0L;
    }

    private void heartBeater() {
        if (!node.joined() || !node.isActive()) {
            return;
        }

        long now = Clock.currentTimeMillis();

        
        long clockJump = 0L;
        if (lastHeartBeat != 0L) {
            clockJump = now - lastHeartBeat - TimeUnit.SECONDS.toMillis(heartbeatInterval);
            if (Math.abs(clockJump) > HEARTBEAT_LOG_THRESHOLD) {
                SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS");
                logger.info("System clock apparently jumped from " + sdf.format(new Date(lastHeartBeat)) + " to " +
                        sdf.format(new Date(now)) + " since last heartbeat (" + String.format("%+d", clockJump) + "ms).");
            }
            clockJump = Math.max(0L, clockJump);

            if (clockJump >= maxNoMasterConfirmationMillis / 2) {
                logger.warning(
                        "Resetting master confirmation timestamps because of huge system clock jump! " + "Clock-Jump: "
                                + clockJump + "ms, Master-Confirmation-Timeout: " + maxNoMasterConfirmationMillis
                                + "ms.");
                resetMemberMasterConfirmations();
            }
        }
        lastHeartBeat = now;

        if (node.isMaster()) {
            heartBeaterMaster(now, clockJump);
        } else {
            heartBeaterSlave(now, clockJump);
        }
    }

    private void heartBeaterMaster(long now, long clockJump) {
        Collection<MemberImpl> members = getMemberList();
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    logIfConnectionToEndpointIsMissing(now, member);
                    if (removeMemberIfNotHeartBeating(now - clockJump, member)) {
                        continue;
                    }

                    if (removeMemberIfMasterConfirmationExpired(now - clockJump, member)) {
                        continue;
                    }

                    pingMemberIfRequired(now, member);
                    sendHeartbeat(member.getAddress());
                } catch (Throwable e) {
                    logger.severe(e);
                }
            }
        }
    }

    private boolean removeMemberIfNotHeartBeating(long now, MemberImpl member) {
        long heartbeatTime = getHeartbeatTime(member);
        if ((now - heartbeatTime) > maxNoHeartbeatMillis) {
            logger.warning("Removing " + member + " because it has not sent any heartbeats for " +
                    maxNoHeartbeatMillis + " ms. Last heartbeat time was " + new Date(heartbeatTime));
            removeAddress(member.getAddress());
            return true;
        }
        return false;
    }

    private boolean removeMemberIfMasterConfirmationExpired(long now, MemberImpl member) {
        Long lastConfirmation = masterConfirmationTimes.get(member);
        if (lastConfirmation == null) {
            lastConfirmation = 0L;
        }
        if (now - lastConfirmation > maxNoMasterConfirmationMillis) {
            logger.warning("Removing " + member + " because it has not sent any master confirmation " +
                    " for " + maxNoMasterConfirmationMillis + " ms. Last confirmation time was "
                    + new Date(lastConfirmation));
            removeAddress(member.getAddress());
            return true;
        }
        return false;
    }

    private void heartBeaterSlave(long now, long clockJump) {
        Collection<MemberImpl> members = getMemberList();

        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    logIfConnectionToEndpointIsMissing(now, member);

                    if (isMaster(member)) {
                        if (removeMemberIfNotHeartBeating(now - clockJump, member)) {
                            continue;
                        }
                    }

                    pingMemberIfRequired(now, member);
                    sendHeartbeat(member.getAddress());
                } catch (Throwable e) {
                    logger.severe(e);
                }
            }
        }
    }

    private boolean isMaster(MemberImpl member) {
        return member.getAddress().equals(getMasterAddress());
    }

    private void pingMemberIfRequired(long now, MemberImpl member) {
        if (!icmpEnabled) {
            return;
        }
        if ((now - getHeartbeatTime(member)) >= pingIntervalMillis) {
            ping(member);
        }
    }

    private void ping(final MemberImpl memberImpl) {
        nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
            public void run() {
                try {
                    final Address address = memberImpl.getAddress();
                    logger.warning(thisAddress + " will ping " + address);
                    for (int i = 0; i < 5; i++) {
                        try {
                            if (address.getInetAddress().isReachable(null, icmpTtl, icmpTimeout)) {
                                logger.info(thisAddress + " pings successfully. Target: " + address);
                                return;
                            }
                        } catch (ConnectException ignored) {
                            
                            
                        }
                    }
                    logger.warning(thisAddress + " couldn't ping " + address);
                    
                    removeAddress(address);
                } catch (Throwable ignored) {
                }
            }
        });
    }

    private void sendHeartbeat(Address target) {
        if (target == null) {
            return;
        }
        try {
            node.nodeEngine.getOperationService().send(new HeartbeatOperation(), target);
        } catch (Exception e) {
            if (logger.isFinestEnabled()) {
                logger.finest("Error while sending heartbeat -> "
                        + e.getClass().getName() + "[" + e.getMessage() + "]");
            }
        }
    }

    public void sendMasterConfirmation() {
        if (!node.joined() || !node.isActive() || isMaster()) {
            return;
        }
        final Address masterAddress = getMasterAddress();
        if (masterAddress == null) {
            logger.finest("Could not send MasterConfirmation, master is null!");
            return;
        }
        final MemberImpl masterMember = getMember(masterAddress);
        if (masterMember == null) {
            logger.finest("Could not send MasterConfirmation, master is null!");
            return;
        }
        if (logger.isFinestEnabled()) {
            logger.finest("Sending MasterConfirmation to " + masterMember);
        }
        nodeEngine.getOperationService().send(new MasterConfirmationOperation(), masterAddress);
    }

    
    private void resetMemberMasterConfirmations() {
        long now = Clock.currentTimeMillis();
        Collection<MemberImpl> memberList = getMemberList();
        for (MemberImpl member : memberList) {
            masterConfirmationTimes.put(member, now);
        }
    }


    public void sendMemberListToMember(Address target) {
        if (!isMaster()) {
            return;
        }
        if (thisAddress.equals(target)) {
            return;
        }
        final Collection<MemberImpl> members = getMemberList();
        MemberInfoUpdateOperation op = new MemberInfoUpdateOperation(
                createMemberInfoList(members), clusterClock.getClusterTime(), false);
        nodeEngine.getOperationService().send(op, target);
    }

    private void sendMemberListToOthers() {
        if (!isMaster()) {
            return;
        }
        final Collection<MemberImpl> members = getMemberList();
        MemberInfoUpdateOperation op = new MemberInfoUpdateOperation(
                createMemberInfoList(members), clusterClock.getClusterTime(), false);
        for (MemberImpl member : members) {
            if (member.equals(thisMember)) {
                continue;
            }
            nodeEngine.getOperationService().send(op, member.getAddress());
        }
    }

    public void removeAddress(Address deadAddress) {
        doRemoveAddress(deadAddress, true);
    }

    private void doRemoveAddress(Address deadAddress, boolean destroyConnection) {
        if (preparingToMerge.get()) {
            logger.warning("Cluster-merge process is ongoing, won't process member removal: " + deadAddress);
            return;
        }
        if (!node.joined()) {
            return;
        }
        if (deadAddress.equals(thisAddress)) {
            return;
        }
        lock.lock();
        try {
            if (deadAddress.equals(node.getMasterAddress())) {
                assignNewMaster();
            }
            if (node.isMaster()) {
                setJoins.remove(new MemberInfo(deadAddress));
            }
            final Connection conn = node.connectionManager.getConnection(deadAddress);
            if (destroyConnection && conn != null) {
                node.connectionManager.destroyConnection(conn);
            }
            MemberImpl deadMember = getMember(deadAddress);
            if (deadMember != null) {
                removeMember(deadMember);
                logger.info(membersString());
            }
        } finally {
            lock.unlock();
        }
    }

    private void assignNewMaster() {
        final Address oldMasterAddress = node.getMasterAddress();
        if (node.joined()) {
            final Collection<MemberImpl> members = getMemberList();
            MemberImpl newMaster = null;
            final int size = members.size();
            if (size > 1) {
                final Iterator<MemberImpl> iter = members.iterator();
                final MemberImpl member = iter.next();
                if (member.getAddress().equals(oldMasterAddress)) {
                    newMaster = iter.next();
                } else {
                    logger.severe("Old master " + oldMasterAddress
                            + " is dead but the first of member list is a different member " +
                            member + "!");
                    newMaster = member;
                }
            } else {
                logger.warning("Old master is dead and this node is not master " +
                        "but member list contains only " + size + " members! -> " + members);
            }
            logger.info("Master " + oldMasterAddress + " left the cluster. Assigning new master " + newMaster);
            if (newMaster != null) {
                node.setMasterAddress(newMaster.getAddress());
            } else {
                node.setMasterAddress(null);
            }
        } else {
            node.setMasterAddress(null);
        }

        if (logger.isFinestEnabled()) {
            logger.finest("Now Master " + node.getMasterAddress());
        }

        if (node.isMaster()) {
            resetMemberMasterConfirmations();
        } else {
            sendMasterConfirmation();
        }
    }

    public void answerMasterQuestion(JoinMessage joinMessage, Connection connection) {
        if (!ensureValidConfiguration(joinMessage)) {
            return;
        }

        if (node.getMasterAddress() != null) {
            if (!checkIfJoinRequestFromAnExistingMember(joinMessage, connection)) {
                sendMasterAnswer(joinMessage.getAddress());
            }
        } else {
            if (logger.isFinestEnabled()) {
                logger.finest("Received a master question from " + joinMessage.getAddress()
                        + ", but this node is not master itself or doesn't have a master yet!");
            }
        }
    }

    public void handleJoinRequest(JoinRequest joinRequest, Connection connection) {
        if (!node.joined() || !node.isActive()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Node is not ready to process join request...");
            }
            return;
        }

        if (!ensureValidConfiguration(joinRequest)) {
            return;
        }

        Address target = joinRequest.getAddress();
        boolean isRequestFromCurrentMaster = target.equals(node.getMasterAddress());
        
        
        if (!node.isMaster() && !isRequestFromCurrentMaster) {
            sendMasterAnswer(target);
            return;
        }

        if (joinInProgress) {
            if (logger.isFinestEnabled()) {
                logger.finest("Join is in-progress. Cannot handle join request from "
                        + target + " at the moment.");
            }
            return;
        }

        lock.lock();
        try {
            if (checkIfJoinRequestFromAnExistingMember(joinRequest, connection)) {
                return;
            }

            long now = Clock.currentTimeMillis();
            if (logger.isFinestEnabled()) {
                String msg = "Handling join from " + target + ", inProgress: " + joinInProgress
                        + (timeToStartJoin > 0 ? ", timeToStart: " + (timeToStartJoin - now) : "");
                logger.finest(msg);
            }

            MemberInfo memberInfo = new MemberInfo(target, joinRequest.getUuid(),
                    joinRequest.getAttributes());

            if (!setJoins.contains(memberInfo)) {
                try {
                    checkSecureLogin(joinRequest, memberInfo);
                } catch (Exception e) {
                    ILogger securityLogger = node.loggingService.getLogger("com.hazelcast.security");
                    sendAuthenticationFailure(target);
                    securityLogger.severe(e);
                    return;
                }
            }

            if (node.isMaster()) {
                try {
                    node.getNodeExtension().beforeJoin();
                } catch (Exception e) {
                    logger.warning(e.getMessage());
                    sendBeforeJoinCheckFailure(target, e.getMessage());
                    return;
                }
            }

            if (firstJoinRequest == 0) {
                firstJoinRequest = now;
            }

            if (setJoins.add(memberInfo)) {
                sendMasterAnswer(target);
                if (now - firstJoinRequest < maxWaitMillisBeforeJoin) {
                    timeToStartJoin = now + waitMillisBeforeJoin;
                }
            }
            if (now > timeToStartJoin) {
                startJoin();
            }
        } finally {
            lock.unlock();
        }
    }

    private boolean ensureValidConfiguration(JoinMessage joinMessage) {
        try {
            if (isValidJoinMessage(joinMessage)) {
                return true;
            }

            logger.warning("Received an invalid join request from " + joinMessage.getAddress()
                    + ", cause: clusters part of different cluster-groups");

            nodeEngine.getOperationService().send(new GroupMismatchOperation(), joinMessage.getAddress());
        } catch (ConfigMismatchException e) {
            logger.warning("Received an invalid join request from " + joinMessage.getAddress()
                    + ", cause:" + e.getMessage());
            sendConfigurationMismatchFailure(joinMessage.getAddress(), e.getMessage());
        }
        return false;
    }

    private void sendAuthenticationFailure(Address target) {
        nodeEngine.getOperationService().send(new AuthenticationFailureOperation(), target);
    }

    private void sendBeforeJoinCheckFailure(Address target, String message) {
        nodeEngine.getOperationService().send(new BeforeJoinCheckFailureOperation(message), target);
    }

    private void sendConfigurationMismatchFailure(Address target, String msg) {
        OperationService operationService = nodeEngine.getOperationService();
        operationService.send(new ConfigMismatchOperation(msg), target);
    }

    private void checkSecureLogin(JoinRequest joinRequest, MemberInfo newMemberInfo) {
        if (node.securityContext != null && !setJoins.contains(newMemberInfo)) {
            Credentials cr = joinRequest.getCredentials();
            if (cr == null) {
                throw new SecurityException("Expecting security credentials " +
                        "but credentials could not be found in JoinRequest!");
            }

            try {
                LoginContext lc = node.securityContext.createMemberLoginContext(cr);
                lc.login();
            } catch (LoginException e) {
                throw new SecurityException(
                        "Authentication has failed for " + cr.getPrincipal() + '@' + cr.getEndpoint()
                                + " => (" + e.getMessage() + ")");
            }
        }
    }

    private boolean checkIfJoinRequestFromAnExistingMember(JoinMessage joinMessage, Connection connection) {
        MemberImpl member = getMember(joinMessage.getAddress());
        if (member == null) {
            return false;
        }

        Address target = member.getAddress();
        if (joinMessage.getUuid().equals(member.getUuid())) {
            if (node.isMaster()) {
                if (logger.isFinestEnabled()) {
                    String message = "Ignoring join request, member already exists.. => " + joinMessage;
                    logger.finest(message);
                }
                
                final Operation[] postJoinOps = nodeEngine.getPostJoinOperations();
                final PostJoinOperation postJoinOp = postJoinOps != null && postJoinOps.length > 0
                        ? new PostJoinOperation(postJoinOps) : null;

                Operation op = new FinalizeJoinOperation(createMemberInfoList(getMemberList()), postJoinOp,
                        clusterClock.getClusterTime(), false);
                nodeEngine.getOperationService().send(op, target);
            } else {
                sendMasterAnswer(target);
            }
            return true;
        }

        
        
        
        
        if (node.isMaster() || target.equals(node.getMasterAddress())) {
            logger.warning("New join request has been received from an existing endpoint! => " + member
                    + " Removing old member and processing join request...");

            doRemoveAddress(target, false);
            Connection existing = node.connectionManager.getConnection(target);
            if (existing != connection) {
                node.connectionManager.destroyConnection(existing);
                node.connectionManager.registerConnection(target, connection);
            }
            return false;
        }
        return true;
    }

    private void sendMasterAnswer(Address target) {
        Address masterAddress = node.getMasterAddress();
        if (masterAddress == null) {
            logger.info("Cannot send master answer to " + target + " since master node is not known yet");
            return;
        }
        SetMasterOperation op = new SetMasterOperation(masterAddress);
        nodeEngine.getOperationService().send(op, target);
    }

    public void handleMaster(Address masterAddress, Address callerAddress) {
        if (node.joined()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Ignoring master response: " + masterAddress + " from: " + callerAddress
                        + ". This node is already joined...");
            }
            return;
        }

        if (node.getThisAddress().equals(masterAddress)) {
            if (node.isMaster()) {
                logger.finest("Ignoring master response: " + masterAddress + " from: " + callerAddress
                        + ". This node is already master...");
            } else {
                node.setAsMaster();
            }
            return;
        }

        lock.lock();
        try {
            if (logger.isFinestEnabled()) {
                logger.finest("Handling master response: " + masterAddress + " from: " + callerAddress);
            }
            final Address currentMaster = node.getMasterAddress();
            if (currentMaster == null || currentMaster.equals(masterAddress)) {
                setMasterAndJoin(masterAddress);
            } else if (currentMaster.equals(callerAddress)) {
                logger.info("Setting master to: " + masterAddress + ", since "
                        + currentMaster + " says it's not master anymore.");
                setMasterAndJoin(masterAddress);
            } else {
                final Connection conn = node.connectionManager.getConnection(currentMaster);
                if (conn != null && conn.isAlive()) {
                    logger.info("Ignoring master response: " + masterAddress + " from: " + callerAddress
                            + ", since this node has an active master: " + currentMaster);
                    sendJoinRequest(currentMaster, true);
                } else {
                    logger.warning("Ambiguous master response, this node has a master: " + currentMaster
                            + ", but doesn't have a connection to. " + callerAddress + " sent master response as: "
                            + masterAddress + ". Master field will be unset now...");
                    node.setMasterAddress(null);
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void setMasterAndJoin(Address masterAddress) {
        node.setMasterAddress(masterAddress);
        node.connectionManager.getOrConnect(masterAddress);
        if (!sendJoinRequest(masterAddress, true)) {
            logger.warning("Could not create connection to possible master " + masterAddress);
        }
    }

    public void acceptMasterConfirmation(MemberImpl member) {
        if (member != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("MasterConfirmation has been received from " + member);
            }
            masterConfirmationTimes.put(member, Clock.currentTimeMillis());
        }
    }

    public void prepareToMerge(final Address newTargetAddress) {
        preparingToMerge.set(true);
        node.getJoiner().setTargetAddress(newTargetAddress);
        nodeEngine.getExecutionService().schedule(new Runnable() {
            public void run() {
                merge(newTargetAddress);
            }
        }, 10, TimeUnit.SECONDS);
    }

    public void merge(final Address newTargetAddress) {
        if (preparingToMerge.compareAndSet(true, false)) {
            node.getJoiner().setTargetAddress(newTargetAddress);
            LifecycleServiceImpl lifecycleService = node.hazelcastInstance.getLifecycleService();
            lifecycleService.runUnderLifecycleLock(new MergeTask());
        }
    }

    private <V> V waitOnFutureInterruptible(Future<V> future, long timeout, TimeUnit timeUnit)
            throws ExecutionException, InterruptedException, TimeoutException {

        isNotNull(timeUnit, "timeUnit");
        long deadline = Clock.currentTimeMillis() + timeUnit.toMillis(timeout);
        while (true) {
            long localTimeout = Math.min(1000 * 10, deadline);
            try {
                return future.get(localTimeout, TimeUnit.MILLISECONDS);
            } catch (TimeoutException te) {
                deadline -= localTimeout;
                if (deadline <= 0) {
                    throw te;
                }
                if (!node.isActive()) {
                    future.cancel(true);
                    throw new HazelcastInstanceNotActiveException();
                }
            }
        }
    }

    private void joinReset() {
        lock.lock();
        try {
            joinInProgress = false;
            setJoins.clear();
            timeToStartJoin = Clock.currentTimeMillis() + waitMillisBeforeJoin;
            firstJoinRequest = 0;
        } finally {
            lock.unlock();
        }
    }

    @Override
    public void reset() {
        lock.lock();
        try {
            joinInProgress = false;
            setJoins.clear();
            timeToStartJoin = 0;
            setMembersRef(Collections.singletonMap(thisAddress, thisMember));
            masterConfirmationTimes.clear();
        } finally {
            lock.unlock();
        }
    }

    private void startJoin() {
        logger.finest("Starting Join.");
        lock.lock();
        try {
            try {
                joinInProgress = true;
                
                node.getPartitionService().pauseMigration();
                final Collection<MemberImpl> members = getMemberList();
                final Collection<MemberInfo> memberInfos = createMemberInfoList(members);
                for (MemberInfo memberJoining : setJoins) {
                    memberInfos.add(memberJoining);
                }
                final long time = clusterClock.getClusterTime();
                
                
                final Operation[] postJoinOps = nodeEngine.getPostJoinOperations();
                final PostJoinOperation postJoinOp = postJoinOps != null && postJoinOps.length > 0
                        ? new PostJoinOperation(postJoinOps) : null;
                final int count = members.size() - 1 + setJoins.size();
                final List<Future> calls = new ArrayList<Future>(count);
                for (MemberInfo member : setJoins) {
                    final long startTime = clusterClock.getClusterStartTime();
                    calls.add(invokeClusterOperation(new FinalizeJoinOperation(memberInfos, postJoinOp, time,
                            clusterId, startTime), member.getAddress()));
                }
                for (MemberImpl member : members) {
                    if (!member.getAddress().equals(thisAddress)) {
                        calls.add(invokeClusterOperation(new MemberInfoUpdateOperation(memberInfos, time, true), member.getAddress()));
                    }
                }
                updateMembers(memberInfos);
                int timeout = Math.min(calls.size() * FINALIZE_JOIN_TIMEOUT_FACTOR, FINALIZE_JOIN_MAX_TIMEOUT);
                waitWithDeadline(calls, timeout, TimeUnit.SECONDS, whileFinalizeJoinsExceptionHandler);
            } finally {
                node.getPartitionService().resumeMigration();
            }
        } finally {
            lock.unlock();
        }
    }

    private static List<MemberInfo> createMemberInfoList(Collection<MemberImpl> members) {
        final List<MemberInfo> memberInfos = new LinkedList<MemberInfo>();
        for (MemberImpl member : members) {
            memberInfos.add(new MemberInfo(member));
        }
        return memberInfos;
    }

    private static Set<MemberInfo> createMemberInfoSet(Collection<MemberImpl> members) {
        final Set<MemberInfo> memberInfos = new HashSet<MemberInfo>();
        for (MemberImpl member : members) {
            memberInfos.add(new MemberInfo(member));
        }
        return memberInfos;
    }

    public void updateMembers(Collection<MemberInfo> members) {
        lock.lock();
        try {
            Map<Address, MemberImpl> currentMemberMap = membersMapRef.get();

            if (!shouldProcessMemberUpdate(currentMemberMap, members)) {
                return;
            }

            MemberImpl[] newMembers = new MemberImpl[members.size()];
            int k = 0;
            for (MemberInfo memberInfo : members) {
                MemberImpl member = currentMemberMap.get(memberInfo.getAddress());
                if (member == null) {
                    member = createMember(memberInfo.getAddress(), memberInfo.getUuid(),
                            thisAddress.getScopeId(), memberInfo.getAttributes());
                    onHeartbeat(member);
                }
                newMembers[k++] = member;
            }
            setMembers(newMembers);
            if (!getMemberList().contains(thisMember)) {
                throw new HazelcastException("Member list doesn't contain local member!");
            }
            joinReset();
            heartBeater();
            node.setJoined();
            logger.info(membersString());
        } finally {
            lock.unlock();
        }
    }

    private boolean shouldProcessMemberUpdate(Map<Address, MemberImpl> currentMembers,
                                              Collection<MemberInfo> newMemberInfos) {

        int currentMembersSize = currentMembers.size();
        int newMembersSize = newMemberInfos.size();

        if (currentMembersSize > newMembersSize) {
            logger.warning("Received an older member update, no need to process...");
            nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            return false;
        }

        
        if (currentMembersSize == newMembersSize) {
            Set<MemberInfo> currentMemberInfos = createMemberInfoSet(currentMembers.values());
            if (currentMemberInfos.containsAll(newMemberInfos)) {
                logger.finest("Received a periodic member update, no need to process...");
            } else {
                logger.warning("Received an inconsistent member update "
                        + "which contains new members and removes some of the current members! "
                        + "Ignoring and requesting a new member update...");
                nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            }
            return false;
        }

        Set<MemberInfo> currentMemberInfos = createMemberInfoSet(currentMembers.values());
        currentMemberInfos.removeAll(newMemberInfos);
        if (currentMemberInfos.isEmpty()) {
            return true;
        } else {
            logger.warning("Received an inconsistent member update, it has more members but "
                    + "but also removes some of the current members! "
                    + "Ignoring and requesting a new member update...");
            nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            return false;
        }
    }

    public void updateMemberAttribute(String uuid, MemberAttributeOperationType operationType, String key, Object value) {
        lock.lock();
        try {
            Map<Address, MemberImpl> memberMap = membersMapRef.get();
            for (MemberImpl member : memberMap.values()) {
                if (member.getUuid().equals(uuid)) {
                    if (!member.equals(getLocalMember())) {
                        member.updateAttribute(operationType, key, value);
                    }
                    sendMemberAttributeEvent(member, operationType, key, value);
                    break;
                }
            }
        } finally {
            lock.unlock();
        }
    }

    public boolean sendJoinRequest(Address toAddress, boolean withCredentials) {
        if (toAddress == null) {
            toAddress = node.getMasterAddress();
        }
        JoinRequestOperation joinRequest = new JoinRequestOperation(node.createJoinRequest(withCredentials));
        return nodeEngine.getOperationService().send(joinRequest, toAddress);
    }

    public boolean sendMasterQuestion(Address toAddress) {
        checkNotNull(toAddress, "No endpoint is specified!");

        BuildInfo buildInfo = node.getBuildInfo();
        JoinMessage joinMessage = new JoinMessage(Packet.VERSION, buildInfo.getBuildNumber(), thisAddress,
                thisMember.getUuid(), node.createConfigCheck());
        return nodeEngine.getOperationService().send(new MasterDiscoveryOperation(joinMessage), toAddress);
    }

    @Override
    public void connectionAdded(final Connection connection) {
        MemberImpl member = getMember(connection.getEndPoint());
        onHeartbeat(member);
    }

    public void onHeartbeat(MemberImpl member) {
        if (member != null) {
            heartbeatTimes.put(member, Clock.currentTimeMillis());
        }
    }

    @Override
    public void connectionRemoved(Connection connection) {
        if (logger.isFinestEnabled()) {
            logger.finest("Connection is removed " + connection.getEndPoint());
        }
        if (!node.joined()) {
            final Address masterAddress = node.getMasterAddress();
            if (masterAddress != null && masterAddress.equals(connection.getEndPoint())) {
                node.setMasterAddress(null);
            }
        }
    }

    private Future invokeClusterOperation(Operation op, Address target) {
        return nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, op, target)
                .setTryCount(100).invoke();
    }

    public NodeEngineImpl getNodeEngine() {
        return nodeEngine;
    }

    private void setMembers(MemberImpl... members) {
        if (members == null || members.length == 0) {
            return;
        }
        if (logger.isFinestEnabled()) {
            logger.finest("Updating members -> " + Arrays.toString(members));
        }
        lock.lock();
        try {
            Map<Address, MemberImpl> oldMemberMap = membersMapRef.get();
            final Map<Address, MemberImpl> memberMap = new LinkedHashMap<Address, MemberImpl>();  
            final Collection<MemberImpl> newMembers = new LinkedList<MemberImpl>();
            for (MemberImpl member : members) {
                MemberImpl currentMember = oldMemberMap.get(member.getAddress());
                if (currentMember == null) {
                    newMembers.add(member);
                    masterConfirmationTimes.put(member, Clock.currentTimeMillis());
                }
                memberMap.put(member.getAddress(), member);
            }
            setMembersRef(memberMap);

            if (!newMembers.isEmpty()) {
                Set<Member> eventMembers = new LinkedHashSet<Member>(oldMemberMap.values());
                if (newMembers.size() == 1) {
                    MemberImpl newMember = newMembers.iterator().next();
                    node.getPartitionService().memberAdded(newMember); 
                    eventMembers.add(newMember);
                    sendMembershipEventNotifications(newMember, unmodifiableSet(eventMembers), true); 
                } else {
                    for (MemberImpl newMember : newMembers) {
                        node.getPartitionService().memberAdded(newMember); 
                        eventMembers.add(newMember);
                        sendMembershipEventNotifications(newMember, unmodifiableSet(new LinkedHashSet<Member>(eventMembers)), true); 
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void removeMember(MemberImpl deadMember) {
        logger.info("Removing " + deadMember);
        lock.lock();
        try {
            final Map<Address, MemberImpl> members = membersMapRef.get();
            if (members.containsKey(deadMember.getAddress())) {
                Map<Address, MemberImpl> newMembers = new LinkedHashMap<Address, MemberImpl>(members);  
                newMembers.remove(deadMember.getAddress());
                masterConfirmationTimes.remove(deadMember);
                setMembersRef(newMembers);
                node.getPartitionService().memberRemoved(deadMember); 
                nodeEngine.onMemberLeft(deadMember);                  
                if (node.isMaster()) {
                    if (logger.isFinestEnabled()) {
                        logger.finest(deadMember + " is dead. Sending remove to all other members.");
                    }
                    invokeMemberRemoveOperation(deadMember.getAddress());
                }
                
                sendMembershipEventNotifications(deadMember, unmodifiableSet(new LinkedHashSet<Member>(newMembers.values())), false);
            }
        } finally {
            lock.unlock();
        }
    }

    private void invokeMemberRemoveOperation(final Address deadAddress) {
        for (MemberImpl member : getMemberList()) {
            Address address = member.getAddress();
            if (!thisAddress.equals(address) && !address.equals(deadAddress)) {
                nodeEngine.getOperationService().send(new MemberRemoveOperation(deadAddress), address);
            }
        }
    }

    public void sendShutdownMessage() {
        invokeMemberRemoveOperation(thisAddress);
    }

    private void sendMembershipEventNotifications(final MemberImpl member, Set<Member> members, final boolean added) {
        final int eventType = added ? MembershipEvent.MEMBER_ADDED : MembershipEvent.MEMBER_REMOVED;
        final MembershipEvent membershipEvent = new MembershipEvent(getClusterProxy(), member, eventType, members);
        final Collection<MembershipAwareService> membershipAwareServices = nodeEngine.getServices(MembershipAwareService.class);
        if (membershipAwareServices != null && !membershipAwareServices.isEmpty()) {
            final MembershipServiceEvent event = new MembershipServiceEvent(membershipEvent);
            for (final MembershipAwareService service : membershipAwareServices) {
                
                nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                    public void run() {
                        if (added) {
                            service.memberAdded(event);
                        } else {
                            service.memberRemoved(event);
                        }
                    }
                });
            }
        }
        final EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        for (EventRegistration reg : registrations) {
            eventService.publishEvent(SERVICE_NAME, reg, membershipEvent, reg.getId().hashCode());
        }
    }

    private void sendMemberAttributeEvent(MemberImpl member, MemberAttributeOperationType operationType, String key, Object value) {
        final MemberAttributeEvent memberAttributeEvent = new MemberAttributeEvent(getClusterProxy(), member, operationType, key, value);
        final Collection<MembershipAwareService> membershipAwareServices = nodeEngine.getServices(MembershipAwareService.class);
        final MemberAttributeServiceEvent event = new MemberAttributeServiceEvent(getClusterProxy(), member, operationType, key, value);
        if (membershipAwareServices != null && !membershipAwareServices.isEmpty()) {
            for (final MembershipAwareService service : membershipAwareServices) {
                
                nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                    public void run() {
                        service.memberAttributeChanged(event);
                    }
                });
            }
        }
        final EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        for (EventRegistration reg : registrations) {
            eventService.publishEvent(SERVICE_NAME, reg, memberAttributeEvent, reg.getId().hashCode());
        }
    }

    protected MemberImpl createMember(Address address, String nodeUuid, String ipV6ScopeId, Map<String, Object> attributes) {
        address.setScopeId(ipV6ScopeId);
        return new MemberImpl(address, thisAddress.equals(address), nodeUuid,
                (HazelcastInstanceImpl) nodeEngine.getHazelcastInstance(), attributes);
    }

    @Override
    public MemberImpl getMember(Address address) {
        if (address == null) {
            return null;
        }
        Map<Address, MemberImpl> memberMap = membersMapRef.get();
        return memberMap.get(address);
    }

    @Override
    public MemberImpl getMember(String uuid) {
        if (uuid == null) {
            return null;
        }

        Map<Address, MemberImpl> memberMap = membersMapRef.get();
        for (MemberImpl member : memberMap.values()) {
            if (uuid.equals(member.getUuid())) {
                return member;
            }
        }
        return null;
    }

    private void setMembersRef(Map<Address, MemberImpl> memberMap) {
        memberMap = unmodifiableMap(memberMap);
        
        memberMap.values();
        memberMap.keySet();
        memberMap.entrySet();
        membersMapRef.set(memberMap);
        membersRef.set(unmodifiableSet(new LinkedHashSet<MemberImpl>(memberMap.values())));
    }

    @Override
    public Collection<MemberImpl> getMemberList() {
        return membersRef.get();
    }

    public Collection<Address> getMemberAddresses() {
        Map<Address, MemberImpl> map = membersMapRef.get();
        return map.keySet();
    }

    @Override
    public Set<Member> getMembers() {
        return (Set) membersRef.get();
    }

    @Override
    public void shutdown(boolean terminate) {
        reset();
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public boolean isMaster() {
        return node.isMaster();
    }

    @Override
    public Address getThisAddress() {
        return thisAddress;
    }

    public Member getLocalMember() {
        return node.getLocalMember();
    }

    @Probe(name = "size")
    @Override
    public int getSize() {
        final Collection<MemberImpl> members = getMemberList();
        return members != null ? members.size() : 0;
    }

    public String addMembershipListener(MembershipListener listener) {
        checkNotNull(listener, "listener can't be null");

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration;
        if (listener instanceof InitialMembershipListener) {
            lock.lock();
            try {
                ((InitialMembershipListener) listener).init(new InitialMembershipEvent(getClusterProxy(), getMembers()));
                registration = eventService.registerLocalListener(SERVICE_NAME, SERVICE_NAME, listener);
            } finally {
                lock.unlock();
            }
        } else {
            registration = eventService.registerLocalListener(SERVICE_NAME, SERVICE_NAME, listener);
        }

        return registration.getId();
    }

    public boolean removeMembershipListener(String registrationId) {
        checkNotNull(registrationId, "registrationId can't be null");

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, SERVICE_NAME, registrationId);
    }

    @SuppressFBWarnings("BC_UNCONFIRMED_CAST")
    @Override
    public void dispatchEvent(MembershipEvent event, MembershipListener listener) {
        switch (event.getEventType()) {
            case MembershipEvent.MEMBER_ADDED:
                listener.memberAdded(event);
                break;
            case MembershipEvent.MEMBER_REMOVED:
                listener.memberRemoved(event);
                break;
            case MembershipEvent.MEMBER_ATTRIBUTE_CHANGED:
                MemberAttributeEvent memberAttributeEvent = (MemberAttributeEvent) event;
                listener.memberAttributeChanged(memberAttributeEvent);
                break;
            default:
                throw new IllegalArgumentException("Unhandled event:" + event);
        }
    }

    public Cluster getClusterProxy() {
        return new ClusterProxy(this);
    }

    public String membersString() {
        StringBuilder sb = new StringBuilder("\n\nMembers [");
        final Collection<MemberImpl> members = getMemberList();
        sb.append(members != null ? members.size() : 0);
        sb.append("] {");
        if (members != null) {
            for (Member member : members) {
                sb.append("\n\t").append(member);
            }
        }
        sb.append("\n}\n");
        return sb.toString();
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("ClusterService");
        sb.append("{address=").append(thisAddress);
        sb.append('}');
        return sb.toString();
    }

    private class MergeTask implements Runnable {

        public void run() {
            LifecycleServiceImpl lifecycleService = node.hazelcastInstance.getLifecycleService();
            lifecycleService.fireLifecycleEvent(MERGING);

            resetState();

            Collection<Runnable> tasks = collectMergeTasks();

            resetServices();

            rejoin();

            executeMergeTasks(tasks);

            if (node.isActive() && node.joined()) {
                lifecycleService.fireLifecycleEvent(MERGED);
            }
        }

        private void resetState() {
            
            
            
            node.reset();
            ClusterServiceImpl.this.reset();
            
            
            
            
            node.connectionManager.stop();

            
            
            nodeEngine.reset();
        }

        private Collection<Runnable> collectMergeTasks() {
            
            Collection<SplitBrainHandlerService> services = nodeEngine.getServices(SplitBrainHandlerService.class);
            Collection<Runnable> tasks = new LinkedList<Runnable>();
            for (SplitBrainHandlerService service : services) {
                final Runnable runnable = service.prepareMergeRunnable();
                if (runnable != null) {
                    tasks.add(runnable);
                }
            }
            return tasks;
        }

        private void resetServices() {
            
            Collection<ManagedService> managedServices = nodeEngine.getServices(ManagedService.class);
            for (ManagedService service : managedServices) {
                service.reset();
            }
        }

        private void rejoin() {
            
            node.connectionManager.start();
            
            node.rejoin();
        }

        private void executeMergeTasks(Collection<Runnable> tasks) {
            
            Collection<Future> futures = new LinkedList<Future>();
            for (Runnable task : tasks) {
                Future f = nodeEngine.getExecutionService().submit("hz:system", task);
                futures.add(f);
            }
            long callTimeout = node.groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong();
            for (Future f : futures) {
                try {
                    waitOnFutureInterruptible(f, callTimeout, TimeUnit.MILLISECONDS);
                } catch (HazelcastInstanceNotActiveException e) {
                    EmptyStatement.ignore(e);
                } catch (Exception e) {
                    logger.severe("While merging...", e);
                }
            }
        }
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.security.Credentials;

import java.io.IOException;
import java.util.HashMap;
import java.util.Map;

public class JoinRequest extends JoinMessage implements DataSerializable {

    private Credentials credentials;
    private int tryCount;
    private Map<String, Object> attributes;

    public JoinRequest() {
    }

    public JoinRequest(byte packetVersion, int buildNumber, Address address, String uuid, ConfigCheck config,
                       Credentials credentials, Map<String, Object> attributes) {
        super(packetVersion, buildNumber, address, uuid, config);
        this.credentials = credentials;
        this.attributes = attributes;
    }

    public Credentials getCredentials() {
        return credentials;
    }

    public int getTryCount() {
        return tryCount;
    }

    public void setTryCount(int tryCount) {
        this.tryCount = tryCount;
    }

    public Map<String, Object> getAttributes() {
        return attributes;
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        super.readData(in);
        credentials = in.readObject();
        if (credentials != null) {
            credentials.setEndpoint(getAddress().getHost());
        }
        tryCount = in.readInt();
        int size = in.readInt();
        attributes = new HashMap<String, Object>();
        for (int i = 0; i < size; i++) {
            String key = in.readUTF();
            Object value = in.readObject();
            attributes.put(key, value);
        }
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        super.writeData(out);
        out.writeObject(credentials);
        out.writeInt(tryCount);
        out.writeInt(attributes.size());
        for (Map.Entry<String, Object> entry : attributes.entrySet()) {
            out.writeUTF(entry.getKey());
            out.writeObject(entry.getValue());
        }
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("JoinRequest");
        sb.append("{packetVersion=").append(packetVersion);
        sb.append(", buildNumber=").append(buildNumber);
        sb.append(", address=").append(address);
        sb.append(", uuid='").append(uuid).append('\'');
        sb.append(", credentials=").append(credentials);
        sb.append(", memberCount=").append(getMemberCount());
        sb.append(", tryCount=").append(tryCount);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.cluster.impl.JoinMessage;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.spi.AbstractOperation;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;

public class JoinCheckOperation extends AbstractOperation implements JoinOperation {

    private JoinMessage request;
    private JoinMessage response;

    private transient boolean removeCaller;

    public JoinCheckOperation() {
    }

    public JoinCheckOperation(JoinMessage request) {
        this.request = request;
    }

    @Override
    public void run() {
        ClusterServiceImpl service = getService();
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        Node node = nodeEngine.getNode();

        if (!preCheck(node)) {
            return;
        }

        if (!masterCheck(node)) {
            return;
        }

        if (request != null) {
            ILogger logger = getLogger();
            try {
                if (service.validateJoinMessage(request)) {
                    response = node.createSplitBrainJoinMessage();
                }
                if (logger.isFinestEnabled()) {
                    logger.finest("Returning " + response + " to " + getCallerAddress());
                }
            } catch (Exception e) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Could not validate split-brain join message! -> " + e.getMessage());
                }
            }
        }
    }

    private boolean masterCheck(Node node) {
        ILogger logger = getLogger();
        Address caller = getCallerAddress();
        ClusterServiceImpl service = getService();

        if (node.isMaster()) {
            if (service.getMember(caller) != null) {
                logger.info("Removing " + caller + ", since it thinks it's already split from this cluster "
                        + "and looking to merge.");
                removeCaller = true;
            }
            return true;
        } else {
            
            service.sendMasterConfirmation();
            logger.info("Ignoring join check from " + caller
                    + ", because this node is not master...");
            return false;
        }
    }

    @Override
    public void afterRun() throws Exception {
        if (removeCaller) {
            ClusterServiceImpl service = getService();
            Address caller = getCallerAddress();
            service.removeAddress(caller);
        }
    }

    private boolean preCheck(Node node) {
        ILogger logger = getLogger();
        if (!node.joined()) {
            logger.info("Ignoring join check from " + getCallerAddress()
                    + ", because this node is not joined to a cluster yet...");
            return false;
        }

        if (!node.isActive()) {
            logger.info("Ignoring join check from " + getCallerAddress() + ", because this node is not active...");
            return false;
        }
        return true;
    }

    @Override
    public Object getResponse() {
        return response;
    }

    @Override
    protected void readInternal(final ObjectDataInput in) throws IOException {
        request = new JoinMessage();
        request.readData(in);
    }

    @Override
    protected void writeInternal(final ObjectDataOutput out) throws IOException {
        request.writeData(out);
    }
}


<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.ClusterDataSerializerHook;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.serialization.IdentifiedDataSerializable;

public final class HeartbeatOperation extends AbstractClusterOperation
        implements JoinOperation, IdentifiedDataSerializable {

    @Override
    public void run() {
        ClusterServiceImpl service = getService();
        MemberImpl member = service.getMember(getCallerAddress());
        ILogger logger = getLogger();
        if (logger.isFinestEnabled()) {
            logger.finest("Heartbeat received from " + (member != null ? member : getCallerAddress()));
        }
        service.onHeartbeat(member);
    }

    @Override
    public int getFactoryId() {
        return ClusterDataSerializerHook.F_ID;
    }

    @Override
    public int getId() {
        return ClusterDataSerializerHook.HEARTBEAT;
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.cluster.impl.JoinMessage;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;

import java.io.IOException;

public class MasterDiscoveryOperation extends AbstractClusterOperation implements JoinOperation {

    private JoinMessage joinMessage;

    public MasterDiscoveryOperation() {
    }

    public MasterDiscoveryOperation(JoinMessage joinMessage) {
        this.joinMessage = joinMessage;
    }

    @Override
    public void run() {
        ClusterServiceImpl cm = getService();
        cm.answerMasterQuestion(joinMessage, getConnection());
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        joinMessage = new JoinMessage();
        joinMessage.readData(in);
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        joinMessage.writeData(out);
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("MasterDiscoveryOperation");
        sb.append("{message=").append(joinMessage);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.OperationService;

public class MasterConfirmationOperation extends AbstractClusterOperation {

    @Override
    public void run() {
        final Address endpoint = getCallerAddress();
        if (endpoint == null) {
            return;
        }

        final ClusterServiceImpl clusterService = getService();
        final ILogger logger = getLogger();
        final MemberImpl member = clusterService.getMember(endpoint);
        if (member == null) {
            logger.warning("MasterConfirmation has been received from " + endpoint
                    + ", but it is not a member of this cluster!");
            OperationService operationService = getNodeEngine().getOperationService();
            operationService.send(new MemberRemoveOperation(clusterService.getThisAddress()), endpoint);
        } else {
            if (clusterService.isMaster()) {
                clusterService.acceptMasterConfirmation(member);
            } else {
                logger.warning(endpoint + " has sent MasterConfirmation, but this node is not master!");
            }
        }
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;

import java.io.IOException;

public class MemberRemoveOperation extends AbstractClusterOperation {

    private Address deadAddress;

    public MemberRemoveOperation() {
    }

    public MemberRemoveOperation(Address deadAddress) {
        this.deadAddress = deadAddress;
    }

    @Override
    public void run() {
        final ClusterServiceImpl clusterService = getService();
        final Address caller = getCallerAddress();
        ILogger logger = getLogger();
        if (caller != null
                && (caller.equals(deadAddress) || caller.equals(clusterService.getMasterAddress()))) {
            if (logger.isFinestEnabled()) {
                logger.finest("Removing " + deadAddress + ", called from " + caller);
            }
            clusterService.removeAddress(deadAddress);
        } else {
            if (logger.isFinestEnabled()) {
                logger.finest("Ignoring removal request of " + deadAddress + ", because sender is neither dead-member "
                        + "nor master, called from " + caller);
            }
        }
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        deadAddress = new Address();
        deadAddress.readData(in);
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        deadAddress.writeData(out);
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;

public class PrepareMergeOperation extends AbstractClusterOperation {

    private Address newTargetAddress;

    public PrepareMergeOperation() {
    }

    public PrepareMergeOperation(Address newTargetAddress) {
        this.newTargetAddress = newTargetAddress;
    }

    @Override
    public void run() {
        final Address caller = getCallerAddress();
        final NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        final Node node = nodeEngine.getNode();
        final Address masterAddress = node.getMasterAddress();
        final ILogger logger = node.loggingService.getLogger(this.getClass().getName());
        boolean local = caller == null;
        if (!local && !caller.equals(masterAddress)) {
            logger.warning("Ignoring prepare-merge instruction sent from non-master endpoint: " + caller);
            return;
        }
        logger.warning("Preparing to merge... Waiting for merge instruction...");
        node.getClusterService().prepareToMerge(newTargetAddress);
    }

    @Override
    public Object getResponse() {
        return Boolean.TRUE;
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        super.readInternal(in);
        newTargetAddress = new Address();
        newTargetAddress.readData(in);
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        super.writeInternal(out);
        newTargetAddress.writeData(out);
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;

public class MergeClustersOperation extends AbstractClusterOperation {

    private Address newTargetAddress;

    public MergeClustersOperation() {
    }

    public MergeClustersOperation(Address newTargetAddress) {
        this.newTargetAddress = newTargetAddress;
    }

    @Override
    public void run() {
        final Address caller = getCallerAddress();
        final NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        final Node node = nodeEngine.getNode();
        final Address masterAddress = node.getMasterAddress();
        final ILogger logger = node.loggingService.getLogger(this.getClass().getName());
        boolean local = caller == null;
        if (!local && !caller.equals(masterAddress)) {
            logger.warning("Ignoring merge instruction sent from non-master endpoint: " + caller);
            return;
        }
        logger.warning(node.getThisAddress() + " is merging to " + newTargetAddress
                + ", because: instructed by master " + masterAddress);
        node.getClusterService().merge(newTargetAddress);
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        super.readInternal(in);
        newTargetAddress = new Address();
        newTargetAddress.readData(in);
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        super.writeInternal(out);
        newTargetAddress.writeData(out);
    }
}

<code block>


package com.hazelcast.nio;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.config.NetworkConfig;
import com.hazelcast.config.SSLConfig;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.config.SymmetricEncryptionConfig;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.ascii.TextCommandService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.PacketReader;
import com.hazelcast.nio.tcp.PacketWriter;
import com.hazelcast.nio.tcp.SocketChannelWrapperFactory;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.packettransceiver.PacketTransceiver;

import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.Set;

public class NodeIOService implements IOService {

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final PacketTransceiver packetTransceiver;

    public NodeIOService(Node node, NodeEngineImpl nodeEngine) {
        this.node = node;
        this.nodeEngine = nodeEngine;
        this.packetTransceiver = nodeEngine.getPacketTransceiver();
    }

    @Override
    public MetricsRegistry getMetricRegistry() {
        return nodeEngine.getMetricsRegistry();
    }

    @Override
    public boolean isActive() {
        return node.isActive();
    }

    @Override
    public ILogger getLogger(String name) {
        return node.getLogger(name);
    }

    @Override
    public void onOutOfMemory(OutOfMemoryError oom) {
        OutOfMemoryErrorDispatcher.onOutOfMemory(oom);
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public void onFatalError(Exception e) {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        new Thread(threadGroup.getInternalThreadGroup(), threadGroup.getThreadNamePrefix("io.error.shutdown")) {
            public void run() {
                node.shutdown(false);
            }
        } .start();
    }

    @Override
    public SocketInterceptorConfig getSocketInterceptorConfig() {
        return node.getConfig().getNetworkConfig().getSocketInterceptorConfig();
    }

    @Override
    public SymmetricEncryptionConfig getSymmetricEncryptionConfig() {
        return node.getConfig().getNetworkConfig().getSymmetricEncryptionConfig();
    }

    @Override
    public SSLConfig getSSLConfig() {
        return node.getConfig().getNetworkConfig().getSSLConfig();
    }

    @Override
    public void handleMemberPacket(final Packet packet) {
        packetTransceiver.receive(packet);
    }

    @Override
    public void handleClientPacket(Packet p) {
        node.clientEngine.handlePacket(p);
    }

    @Override
    public void handleClientMessage(ClientMessage cm, Connection connection) {
        node.clientEngine.handleClientMessage(cm, connection);
    }

    @Override
    public TextCommandService getTextCommandService() {
        return node.getTextCommandService();
    }

    @Override
    public boolean isMemcacheEnabled() {
        return node.groupProperties.MEMCACHE_ENABLED.getBoolean();
    }

    @Override
    public boolean isRestEnabled() {
        return node.groupProperties.REST_ENABLED.getBoolean();
    }

    @Override
    public void removeEndpoint(final Address endPoint) {
        nodeEngine.getExecutionService().execute(ExecutionService.IO_EXECUTOR, new Runnable() {
            @Override
            public void run() {
                node.clusterService.removeAddress(endPoint);
            }
        });
    }

    @Override
    public String getThreadPrefix() {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        return threadGroup.getThreadPoolNamePrefix("IO");
    }

    @Override
    public ThreadGroup getThreadGroup() {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        return threadGroup.getInternalThreadGroup();
    }

    @Override
    public void onSuccessfulConnection(Address address) {
        if (!node.joined()) {
            node.getJoiner().unblacklist(address);
        }
    }

    @Override
    public void onFailedConnection(Address address) {
        if (!node.joined()) {
            node.getJoiner().blacklist(address, false);
        }
    }

    @Override
    public void shouldConnectTo(Address address) {
        if (node.getThisAddress().equals(address)) {
            throw new RuntimeException("Connecting to self! " + address);
        }
    }

    @Override
    public boolean isSocketBind() {
        return node.groupProperties.SOCKET_CLIENT_BIND.getBoolean();
    }

    @Override
    public boolean isSocketBindAny() {
        return node.groupProperties.SOCKET_CLIENT_BIND_ANY.getBoolean();
    }

    @Override
    public int getSocketReceiveBufferSize() {
        return this.node.getGroupProperties().SOCKET_RECEIVE_BUFFER_SIZE.getInteger();
    }

    @Override
    public int getSocketSendBufferSize() {
        return this.node.getGroupProperties().SOCKET_SEND_BUFFER_SIZE.getInteger();
    }

    @Override
    public int getSocketClientReceiveBufferSize() {
        int clientSendBuffer = this.node.getGroupProperties().SOCKET_CLIENT_RECEIVE_BUFFER_SIZE.getInteger();
        return clientSendBuffer != -1 ? clientSendBuffer : getSocketReceiveBufferSize();
    }

    @Override
    public int getSocketClientSendBufferSize() {
        int clientReceiveBuffer = this.node.getGroupProperties().SOCKET_CLIENT_SEND_BUFFER_SIZE.getInteger();
        return clientReceiveBuffer != -1 ? clientReceiveBuffer : getSocketReceiveBufferSize();
    }

    @Override
    public int getSocketLingerSeconds() {
        return this.node.getGroupProperties().SOCKET_LINGER_SECONDS.getInteger();
    }

    @Override
    public int getSocketConnectTimeoutSeconds() {
        return this.node.getGroupProperties().SOCKET_CONNECT_TIMEOUT_SECONDS.getInteger();
    }

    @Override
    public boolean getSocketKeepAlive() {
        return this.node.getGroupProperties().SOCKET_KEEP_ALIVE.getBoolean();
    }

    @Override
    public boolean getSocketNoDelay() {
        return this.node.getGroupProperties().SOCKET_NO_DELAY.getBoolean();
    }

    @Override
    public int getSelectorThreadCount() {
        return node.groupProperties.IO_THREAD_COUNT.getInteger();
    }

    @Override
    public void onDisconnect(final Address endpoint) {
    }

    @Override
    public boolean isClient() {
        return false;
    }

    @Override
    public long getConnectionMonitorInterval() {
        return node.groupProperties.CONNECTION_MONITOR_INTERVAL.getLong();
    }

    @Override
    public int getConnectionMonitorMaxFaults() {
        return node.groupProperties.CONNECTION_MONITOR_MAX_FAULTS.getInteger();
    }

    @Override
    public int getBalancerIntervalSeconds() {
        return node.groupProperties.IO_BALANCER_INTERVAL_SECONDS.getInteger();
    }

    @Override
    public void executeAsync(final Runnable runnable) {
        nodeEngine.getExecutionService().execute(ExecutionService.IO_EXECUTOR, runnable);
    }

    @Override
    public EventService getEventService() {
        return nodeEngine.getEventService();
    }

    @Override
    public Data toData(Object obj) {
        return nodeEngine.toData(obj);
    }

    @Override
    public Object toObject(Data data) {
        return nodeEngine.toObject(data);
    }

    @Override
    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    @Override
    public SocketChannelWrapperFactory getSocketChannelWrapperFactory() {
        return node.getNodeExtension().getSocketChannelWrapperFactory();
    }

    @Override
    public MemberSocketInterceptor getMemberSocketInterceptor() {
        return node.getNodeExtension().getMemberSocketInterceptor();
    }

    @Override
    public PacketReader createPacketReader(TcpIpConnection connection) {
        return node.getNodeExtension().createPacketReader(connection, this);
    }

    @Override
    public PacketWriter createPacketWriter(TcpIpConnection connection) {
        return node.getNodeExtension().createPacketWriter(connection, this);
    }

    @Override
    public Collection<Integer> getOutboundPorts() {
        final NetworkConfig networkConfig = node.getConfig().getNetworkConfig();
        final Collection<String> portDefinitions = getPortDefinitions(networkConfig);
        final Set<Integer> ports = getPorts(networkConfig);
        if (portDefinitions.isEmpty() && ports.isEmpty()) {
            
            return Collections.emptySet();
        }
        if (portDefinitions.contains("*") || portDefinitions.contains("0")) {
            
            return Collections.emptySet();
        }
        transformPortDefinitionsToPorts(portDefinitions, ports);
        if (ports.contains(0)) {
            
            return Collections.emptySet();
        }
        return ports;
    }

    private void transformPortDefinitionsToPorts(Collection<String> portDefinitions, Set<Integer> ports) {
        
        for (String portDef : portDefinitions) {
            String[] portDefs = portDef.split("[,; ]");
            for (String def : portDefs) {
                def = def.trim();
                if (def.isEmpty()) {
                    continue;
                }
                final int dashPos = def.indexOf('-');
                if (dashPos > 0) {
                    final int start = Integer.parseInt(def.substring(0, dashPos));
                    final int end = Integer.parseInt(def.substring(dashPos + 1));
                    for (int port = start; port <= end; port++) {
                        ports.add(port);
                    }
                } else {
                    ports.add(Integer.parseInt(def));
                }
            }
        }
    }

    private Set<Integer> getPorts(NetworkConfig networkConfig) {
        return networkConfig.getOutboundPorts() == null
                ? new HashSet<Integer>() : new HashSet<Integer>(networkConfig.getOutboundPorts());
    }

    private Collection<String> getPortDefinitions(NetworkConfig networkConfig) {
        return networkConfig.getOutboundPortDefinitions() == null
                ? Collections.<String>emptySet() : networkConfig.getOutboundPortDefinitions();
    }
}


<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.config.Config;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.MemberLeftException;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.TestUtil;
import com.hazelcast.spi.AbstractOperation;
import com.hazelcast.spi.AbstractWaitNotifyKey;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.WaitNotifyKey;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.waitnotifyservice.impl.WaitNotifyServiceImpl;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.TestHazelcastInstanceFactory;
import com.hazelcast.test.annotation.QuickTest;
import com.hazelcast.util.EmptyStatement;
import org.junit.Assert;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.concurrent.Callable;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.fail;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class InvocationNetworkSplitTest extends HazelcastTestSupport {

    @Test
    public void testWaitingInvocations_whenNodeSplitFromCluster() throws Exception {
        SplitAction action = new FullSplitAction();
        testWaitingInvocations_whenNodeSplitFromCluster(action);
    }

    @Test
    public void testWaitingInvocations_whenNodePartiallySplitFromCluster_scenario1() throws Exception {
        SplitAction action = new PartialSplitAction();
        testWaitingInvocations_whenNodeSplitFromCluster(action);
    }

    @Test
    public void testWaitingInvocations_whenNodePartiallySplitFromCluster_scenario2() throws Exception {
        SplitAction action = new HalfPartialSplitAction();
        testWaitingInvocations_whenNodeSplitFromCluster(action);
    }

    private void testWaitingInvocations_whenNodeSplitFromCluster(SplitAction splitAction) throws Exception {
        Config config = createConfig();
        TestHazelcastInstanceFactory factory = createHazelcastInstanceFactory(3);
        HazelcastInstance hz1 = factory.newHazelcastInstance(config);
        HazelcastInstance hz2 = factory.newHazelcastInstance(config);
        HazelcastInstance hz3 = factory.newHazelcastInstance(config);

        Node node1 = TestUtil.getNode(hz1);
        Node node2 = TestUtil.getNode(hz2);
        Node node3 = TestUtil.getNode(hz3);

        warmUpPartitions(hz1, hz2, hz3);
        int partitionId = getPartitionId(hz2);

        NodeEngineImpl nodeEngine3 = node3.getNodeEngine();
        OperationService operationService3 = nodeEngine3.getOperationService();
        Operation op = new AlwaysBlockingOperation();
        Future<Object> future = operationService3.invokeOnPartition("", op, partitionId);

        
        
        sleepSeconds(1);

        
        splitAction.run(node1, node2, node3);

        
        ClusterServiceImpl clusterService3 = node3.getClusterService();
        clusterService3.prepareToMerge(node1.address);
        clusterService3.merge(node1.address);

        assertEquals(3, node1.getClusterService().getSize());
        assertEquals(3, node2.getClusterService().getSize());
        assertEquals(3, node3.getClusterService().getSize());

        try {
            future.get(1, TimeUnit.MINUTES);
            fail("Future.get() should fail with a MemberLeftException!");
        } catch (MemberLeftException e) {
            
            EmptyStatement.ignore(e);
        } catch (Exception e) {
            fail(e.getClass().getName() + ": " + e.getMessage());
        }
    }

    @Test
    public void testWaitNotifyService_whenNodeSplitFromCluster() throws Exception {
        SplitAction action = new FullSplitAction();
        testWaitNotifyService_whenNodeSplitFromCluster(action);
    }

    @Test
    public void testWaitNotifyService_whenNodePartiallySplitFromCluster() throws Exception {
        SplitAction action = new PartialSplitAction();
        testWaitNotifyService_whenNodeSplitFromCluster(action);
    }

    private void testWaitNotifyService_whenNodeSplitFromCluster(SplitAction action) throws Exception {
        Config config = createConfig();
        TestHazelcastInstanceFactory factory = createHazelcastInstanceFactory(5);
        HazelcastInstance hz1 = factory.newHazelcastInstance(config);
        HazelcastInstance hz2 = factory.newHazelcastInstance(config);
        HazelcastInstance hz3 = factory.newHazelcastInstance(config);

        final Node node1 = TestUtil.getNode(hz1);
        Node node2 = TestUtil.getNode(hz2);
        Node node3 = TestUtil.getNode(hz3);

        warmUpPartitions(hz1, hz2, hz3);
        int partitionId = getPartitionId(hz3);

        NodeEngineImpl nodeEngine1 = node1.getNodeEngine();
        OperationService operationService1 = nodeEngine1.getOperationService();
        operationService1.invokeOnPartition("", new AlwaysBlockingOperation(), partitionId);

        final WaitNotifyServiceImpl waitNotifyService3 = (WaitNotifyServiceImpl) node3.getNodeEngine().getWaitNotifyService();
        assertEqualsEventually(new Callable<Integer>() {
            @Override
            public Integer call() throws Exception {
                return waitNotifyService3.getTotalWaitingOperationCount();
            }
        }, 1);

        action.run(node1, node2, node3);

        
        
        factory.newHazelcastInstance(config);

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                Assert.assertEquals(0, node1.partitionService.getMigrationQueueSize());
            }
        });

        
        ClusterServiceImpl clusterService3 = node3.getClusterService();
        clusterService3.prepareToMerge(node1.address);
        clusterService3.merge(node1.address);

        assertEquals(4, node1.getClusterService().getSize());
        assertEquals(4, node2.getClusterService().getSize());
        assertEquals(4, node3.getClusterService().getSize());

        assertEquals(0, waitNotifyService3.getTotalWaitingOperationCount());
    }

    private Config createConfig() {
        Config config = new Config();
        config.getGroupConfig().setName(generateRandomString(10));
        config.setProperty(GroupProperties.PROP_MASTER_CONFIRMATION_INTERVAL_SECONDS, "1");
        return config;
    }

    private static class AlwaysBlockingOperation extends AbstractOperation implements WaitSupport {

        @Override
        public void run() throws Exception {
        }

        @Override
        public WaitNotifyKey getWaitKey() {
            return new AbstractWaitNotifyKey(getServiceName(), "test") {
            };
        }

        @Override
        public boolean shouldWait() {
            return true;
        }

        @Override
        public void onWaitExpire() {
            sendResponse(new TimeoutException());
        }

        @Override
        public String getServiceName() {
            return "AlwaysBlockingOperationService";
        }

        @Override
        public ExceptionAction onException(Throwable throwable) {
            return ExceptionAction.THROW_EXCEPTION;
        }
    }

    private interface SplitAction {
        void run(Node node1, Node node2, Node node3);
    }

    private static class FullSplitAction implements SplitAction {
        @Override
        public void run(final Node node1, final Node node2, final Node node3) {
            
            node1.clusterService.removeAddress(node3.address);

            node3.clusterService.removeAddress(node1.address);
            node3.clusterService.removeAddress(node2.address);

            assertTrueEventually(new AssertTask() {
                @Override
                public void run() throws Exception {
                    assertEquals(2, node1.getClusterService().getSize());
                    assertEquals(2, node2.getClusterService().getSize());
                    assertEquals(1, node3.getClusterService().getSize());
                }
            }, 10);
        }
    }

    private static class PartialSplitAction implements SplitAction {
        @Override
        public void run(final Node node1, final Node node2, final Node node3) {
            
            
            
            node1.clusterService.removeAddress(node3.address);

            assertTrueEventually(new AssertTask() {
                @Override
                public void run() throws Exception {
                    assertEquals(2, node1.getClusterService().getSize());
                    assertEquals(2, node2.getClusterService().getSize());
                    assertEquals(1, node3.getClusterService().getSize());
                }
            }, 10);
        }
    }

    private static class HalfPartialSplitAction implements SplitAction {
        @Override
        public void run(final Node node1, final Node node2, final Node node3) {
            
            
            
            node1.clusterService.removeAddress(node3.address);
            node3.clusterService.removeAddress(node1.address);

            assertTrueEventually(new AssertTask() {
                @Override
                public void run() throws Exception {
                    assertEquals(2, node1.getClusterService().getSize());
                    assertEquals(2, node2.getClusterService().getSize());
                    assertEquals(1, node3.getClusterService().getSize());
                }
            }, 10);
        }
    }
}

<code block>


package com.hazelcast.cluster;

import com.hazelcast.config.Config;
import com.hazelcast.config.JoinConfig;
import com.hazelcast.config.ListenerConfig;
import com.hazelcast.config.NetworkConfig;
import com.hazelcast.core.Hazelcast;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.LifecycleEvent;
import com.hazelcast.core.LifecycleEvent.LifecycleState;
import com.hazelcast.core.LifecycleListener;
import com.hazelcast.core.MemberAttributeEvent;
import com.hazelcast.core.MembershipAdapter;
import com.hazelcast.core.MembershipEvent;
import com.hazelcast.core.MembershipListener;
import com.hazelcast.instance.DefaultNodeContext;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastInstanceFactory;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.TestUtil;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.NodeIOService;
import com.hazelcast.nio.tcp.FirewallingTcpIpConnectionManager;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.NightlyTest;
import com.hazelcast.util.Clock;
import java.io.IOException;
import java.nio.channels.ServerSocketChannel;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static com.hazelcast.instance.HazelcastInstanceFactory.newHazelcastInstance;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(NightlyTest.class)
public class SplitBrainHandlerTest extends HazelcastTestSupport {

    @Before
    @After
    public void killAllHazelcastInstances() throws IOException {
        HazelcastInstanceFactory.terminateAll();
    }

    @Test
    public void testMulticast_ClusterMerge() throws Exception {
        testClusterMerge(true);
    }

    @Test
    public void testTcpIp_ClusterMerge() throws Exception {
        testClusterMerge(false);
    }

    private void testClusterMerge(boolean multicast) throws Exception {
        Config config1 = new Config();
        config1.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config1.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String firstGroupName = generateRandomString(10);
        config1.getGroupConfig().setName(firstGroupName);

        NetworkConfig networkConfig1 = config1.getNetworkConfig();
        JoinConfig join1 = networkConfig1.getJoin();
        join1.getMulticastConfig().setEnabled(multicast);
        join1.getTcpIpConfig().setEnabled(!multicast);
        join1.getTcpIpConfig().addMember("127.0.0.1");

        Config config2 = new Config();
        config2.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config2.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String secondGroupName = generateRandomString(10);
        config2.getGroupConfig().setName(secondGroupName);

        NetworkConfig networkConfig2 = config2.getNetworkConfig();
        JoinConfig join2 = networkConfig2.getJoin();
        join2.getMulticastConfig().setEnabled(multicast);
        join2.getTcpIpConfig().setEnabled(!multicast);
        join2.getTcpIpConfig().addMember("127.0.0.1");

        HazelcastInstance h1 = Hazelcast.newHazelcastInstance(config1);
        HazelcastInstance h2 = Hazelcast.newHazelcastInstance(config2);
        LifecycleCountingListener l = new LifecycleCountingListener();
        h2.getLifecycleService().addLifecycleListener(l);

        assertEquals(1, h1.getCluster().getMembers().size());
        assertEquals(1, h2.getCluster().getMembers().size());

        
        config1.getGroupConfig().setName(secondGroupName);
        assertTrue(l.waitFor(LifecycleState.MERGED, 30));

        assertEquals(1, l.getCount(LifecycleState.MERGING));
        assertEquals(1, l.getCount(LifecycleState.MERGED));
        assertEquals(2, h1.getCluster().getMembers().size());
        assertEquals(2, h2.getCluster().getMembers().size());
    }

    @Test
    public void testClusterShouldNotMergeDifferentGroupName() throws Exception {
        Config config1 = new Config();
        config1.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config1.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String firstGroupName = generateRandomString(10);
        config1.getGroupConfig().setName(firstGroupName);

        NetworkConfig networkConfig1 = config1.getNetworkConfig();
        JoinConfig join1 = networkConfig1.getJoin();
        join1.getMulticastConfig().setEnabled(true);
        join1.getTcpIpConfig().addMember("127.0.0.1");

        Config config2 = new Config();
        config2.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config2.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String secondGroupName = generateRandomString(10);
        config2.getGroupConfig().setName(secondGroupName);

        NetworkConfig networkConfig2 = config2.getNetworkConfig();
        JoinConfig join2 = networkConfig2.getJoin();
        join2.getMulticastConfig().setEnabled(true);
        join2.getTcpIpConfig().addMember("127.0.0.1");

        HazelcastInstance h1 = Hazelcast.newHazelcastInstance(config1);
        HazelcastInstance h2 = Hazelcast.newHazelcastInstance(config2);
        LifecycleCountingListener l = new LifecycleCountingListener();
        h2.getLifecycleService().addLifecycleListener(l);

        assertEquals(1, h1.getCluster().getMembers().size());
        assertEquals(1, h2.getCluster().getMembers().size());

        HazelcastTestSupport.sleepSeconds(10);

        assertEquals(0, l.getCount(LifecycleState.MERGING));
        assertEquals(0, l.getCount(LifecycleState.MERGED));
        assertEquals(1, h1.getCluster().getMembers().size());
        assertEquals(1, h2.getCluster().getMembers().size());
    }

    private static class LifecycleCountingListener implements LifecycleListener {
        Map<LifecycleState, AtomicInteger> counter = new ConcurrentHashMap<LifecycleState, AtomicInteger>();
        BlockingQueue<LifecycleState> eventQueue = new LinkedBlockingQueue<LifecycleState>();

        LifecycleCountingListener() {
            for (LifecycleEvent.LifecycleState state : LifecycleEvent.LifecycleState.values()) {
                counter.put(state, new AtomicInteger(0));
            }
        }

        public void stateChanged(LifecycleEvent event) {
            counter.get(event.getState()).incrementAndGet();
            eventQueue.offer(event.getState());
        }

        int getCount(LifecycleEvent.LifecycleState state) {
            return counter.get(state).get();
        }

        boolean waitFor(LifecycleEvent.LifecycleState state, int seconds) {
            long remainingMillis = TimeUnit.SECONDS.toMillis(seconds);
            while (remainingMillis >= 0) {
                LifecycleEvent.LifecycleState received = null;
                try {
                    long now = Clock.currentTimeMillis();
                    received = eventQueue.poll(remainingMillis, TimeUnit.MILLISECONDS);
                    remainingMillis -= (Clock.currentTimeMillis() - now);
                } catch (InterruptedException e) {
                    return false;
                }
                if (received != null && received == state) {
                    return true;
                }
            }
            return false;
        }
    }

    @Test
    public void testMulticast_MergeAfterSplitBrain() throws InterruptedException {
        testMergeAfterSplitBrain(true);
    }

    @Test
    public void testTcpIp_MergeAfterSplitBrain() throws InterruptedException {
        testMergeAfterSplitBrain(false);
    }

    private void testMergeAfterSplitBrain(boolean multicast) throws InterruptedException {
        Config config = new Config();
        config.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String groupName = generateRandomString(10);
        config.getGroupConfig().setName(groupName);

        NetworkConfig networkConfig = config.getNetworkConfig();
        JoinConfig join = networkConfig.getJoin();
        join.getMulticastConfig().setEnabled(multicast);
        join.getTcpIpConfig().setEnabled(!multicast);
        join.getTcpIpConfig().addMember("127.0.0.1");

        HazelcastInstance h1 = Hazelcast.newHazelcastInstance(config);
        HazelcastInstance h2 = Hazelcast.newHazelcastInstance(config);
        HazelcastInstance h3 = Hazelcast.newHazelcastInstance(config);

        final CountDownLatch splitLatch = new CountDownLatch(2);
        h3.getCluster().addMembershipListener(new MembershipListener() {
            @Override
            public void memberAdded(MembershipEvent membershipEvent) {
            }

            @Override
            public void memberRemoved(MembershipEvent membershipEvent) {
                splitLatch.countDown();
            }

            @Override
            public void memberAttributeChanged(MemberAttributeEvent memberAttributeEvent) {
            }
        });

        final CountDownLatch mergeLatch = new CountDownLatch(1);
        h3.getLifecycleService().addLifecycleListener(new LifecycleListener() {
            public void stateChanged(LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    mergeLatch.countDown();
                }
            }
        });

        closeConnectionBetween(h1, h3);
        closeConnectionBetween(h2, h3);

        assertTrue(splitLatch.await(10, TimeUnit.SECONDS));
        assertEquals(2, h1.getCluster().getMembers().size());
        assertEquals(2, h2.getCluster().getMembers().size());
        assertEquals(1, h3.getCluster().getMembers().size());

        assertTrue(mergeLatch.await(30, TimeUnit.SECONDS));
        assertEquals(3, h1.getCluster().getMembers().size());
        assertEquals(3, h2.getCluster().getMembers().size());
        assertEquals(3, h3.getCluster().getMembers().size());
    }

    @Test
    public void testTcpIpSplitBrainJoinsCorrectCluster() throws Exception {

        
        Config c1 = buildConfig(false, 15702);
        Config c2 = buildConfig(false, 15704);
        Config c3 = buildConfig(false, 15703);
        Config c4 = buildConfig(false, 15701);

        List<String> clusterOneMembers = Arrays.asList("127.0.0.1:15702", "127.0.0.1:15704");
        List<String> clusterTwoMembers = Arrays.asList("127.0.0.1:15703", "127.0.0.1:15701");

        c1.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterOneMembers);
        c2.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterOneMembers);
        c3.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterTwoMembers);
        c4.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterTwoMembers);


        final CountDownLatch latch = new CountDownLatch(2);
        c3.addListenerConfig(new ListenerConfig(new LifecycleListener() {
            public void stateChanged(final LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    latch.countDown();
                }
            }
        }));

        c4.addListenerConfig(new ListenerConfig(new LifecycleListener() {
            public void stateChanged(final LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    latch.countDown();
                }
            }
        }));

        HazelcastInstance h1 = Hazelcast.newHazelcastInstance(c1);
        HazelcastInstance h2 = Hazelcast.newHazelcastInstance(c2);
        HazelcastInstance h3 = Hazelcast.newHazelcastInstance(c3);
        HazelcastInstance h4 = Hazelcast.newHazelcastInstance(c4);

        
        assertEquals(2, h1.getCluster().getMembers().size());
        assertEquals(2, h2.getCluster().getMembers().size());
        assertEquals(2, h3.getCluster().getMembers().size());
        assertEquals(2, h4.getCluster().getMembers().size());

        List<String> allMembers = Arrays.asList("127.0.0.1:15701", "127.0.0.1:15704", "127.0.0.1:15703",
                "127.0.0.1:15702");

        
        h3.getConfig().getNetworkConfig().getJoin().getTcpIpConfig().setMembers(allMembers);
        h4.getConfig().getNetworkConfig().getJoin().getTcpIpConfig().clear().setMembers(Collections.<String>emptyList());

        assertTrue(latch.await(60, TimeUnit.SECONDS));

        
        assertEquals(4, h1.getCluster().getMembers().size());
        assertEquals(4, h2.getCluster().getMembers().size());
        assertEquals(4, h3.getCluster().getMembers().size());
        assertEquals(4, h4.getCluster().getMembers().size());
    }

    @Test
    public void testTcpIpSplitBrainStillWorks_WhenTargetDisappears() throws Exception {
        
        Config c1 = buildConfig(false, 25701);
        Config c2 = buildConfig(false, 25704);
        Config c3 = buildConfig(false, 25703);

        List<String> clusterOneMembers = Arrays.asList("127.0.0.1:25701");
        List<String> clusterTwoMembers = Arrays.asList("127.0.0.1:25704");
        List<String> clusterThreeMembers = Arrays.asList("127.0.0.1:25703");

        c1.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterOneMembers);
        c2.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterTwoMembers);
        c3.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterThreeMembers);

        final HazelcastInstance h1 = Hazelcast.newHazelcastInstance(c1);
        final HazelcastInstance h2 = Hazelcast.newHazelcastInstance(c2);

        final CountDownLatch latch = new CountDownLatch(1);
        c3.addListenerConfig(new ListenerConfig(new LifecycleListener() {
            public void stateChanged(final LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGING) {
                    h1.shutdown();
                } else if (event.getState() == LifecycleState.MERGED) {
                    latch.countDown();
                }
            }
        }));

        final HazelcastInstance h3 = Hazelcast.newHazelcastInstance(c3);

        
        assertEquals(1, h1.getCluster().getMembers().size());
        assertEquals(1, h2.getCluster().getMembers().size());
        assertEquals(1, h3.getCluster().getMembers().size());

        List<String> allMembers = Arrays.asList("127.0.0.1:25701", "127.0.0.1:25704", "127.0.0.1:25703");

        h3.getConfig().getNetworkConfig().getJoin().getTcpIpConfig().setMembers(allMembers);

        assertTrue(latch.await(60, TimeUnit.SECONDS));

        
        assertFalse(h1.getLifecycleService().isRunning());
        assertEquals(2, h2.getCluster().getMembers().size());
        assertEquals(2, h3.getCluster().getMembers().size());
    }

    private static Config buildConfig(boolean multicastEnabled, int port) {
        Config c = new Config();
        c.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        c.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");

        NetworkConfig networkConfig = c.getNetworkConfig();
        networkConfig.setPort(port).setPortAutoIncrement(false);
        networkConfig.getJoin().getMulticastConfig().setEnabled(multicastEnabled);
        networkConfig.getJoin().getTcpIpConfig().setEnabled(!multicastEnabled);
        return c;
    }

    @Test
    public void testMulticastJoin_DuringSplitBrainHandlerRunning() throws InterruptedException {
        Properties props = new Properties();
        props.setProperty(GroupProperties.PROP_WAIT_SECONDS_BEFORE_JOIN, "5");
        props.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "0");
        props.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "0");

        String groupName = generateRandomString(10);
        final CountDownLatch latch = new CountDownLatch(1);
        Config config1 = new Config();
        
        config1.getNetworkConfig().setPort(5901);
        config1.getGroupConfig().setName(groupName);
        config1.setProperties(props);
        config1.addListenerConfig(new ListenerConfig(new LifecycleListener() {
            public void stateChanged(final LifecycleEvent event) {
                switch (event.getState()) {
                    case MERGING:
                    case MERGED:
                        latch.countDown();
                    default:
                        break;
                }
            }
        }));
        Hazelcast.newHazelcastInstance(config1);
        Thread.sleep(5000);

        Config config2 = new Config();
        config2.getGroupConfig().setName(groupName);
        config2.getNetworkConfig().setPort(5701);
        config2.setProperties(props);
        Hazelcast.newHazelcastInstance(config2);

        assertFalse("Latch should not be countdown!", latch.await(3, TimeUnit.SECONDS));
    }

    @Test
    public void testMulticast_ClusterMerge_when_split_not_detected_by_master() throws InterruptedException {
        testClusterMerge_when_split_not_detected_by_master(true);
    }

    @Test
    public void testTcpIp_ClusterMerge_when_split_not_detected_by_master() throws InterruptedException {
        testClusterMerge_when_split_not_detected_by_master(false);
    }

    private void testClusterMerge_when_split_not_detected_by_master(boolean multicastEnabled)
            throws InterruptedException {
        Config config = new Config();
        String groupName = generateRandomString(10);
        config.getGroupConfig().setName(groupName);
        config.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MAX_NO_HEARTBEAT_SECONDS, "15");
        config.setProperty(GroupProperties.PROP_MAX_JOIN_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "10");

        NetworkConfig networkConfig = config.getNetworkConfig();
        networkConfig.getJoin().getMulticastConfig().setEnabled(multicastEnabled);
        networkConfig.getJoin().getTcpIpConfig()
                .setEnabled(!multicastEnabled).addMember("127.0.0.1");

        HazelcastInstance hz1 = newHazelcastInstance(config, "test-node1", new FirewallingNodeContext());
        HazelcastInstance hz2 = newHazelcastInstance(config, "test-node2", new FirewallingNodeContext());
        HazelcastInstance hz3 = newHazelcastInstance(config, "test-node3", new FirewallingNodeContext());

        final Node n1 = TestUtil.getNode(hz1);
        Node n2 = TestUtil.getNode(hz2);
        Node n3 = TestUtil.getNode(hz3);

        final CountDownLatch splitLatch = new CountDownLatch(2);
        MembershipAdapter membershipAdapter = new MembershipAdapter() {
            @Override
            public void memberRemoved(MembershipEvent event) {
                if (n1.getLocalMember().equals(event.getMember())) {
                    splitLatch.countDown();
                }
            }
        };

        hz2.getCluster().addMembershipListener(membershipAdapter);
        hz3.getCluster().addMembershipListener(membershipAdapter);

        final CountDownLatch mergeLatch = new CountDownLatch(1);
        LifecycleListener lifecycleListener = new LifecycleListener() {
            @Override
            public void stateChanged(LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    mergeLatch.countDown();
                }
            }
        };
        hz1.getLifecycleService().addLifecycleListener(lifecycleListener);

        FirewallingTcpIpConnectionManager cm1 = getFireWalledConnectionManager(hz1);
        FirewallingTcpIpConnectionManager cm2 = getFireWalledConnectionManager(hz2);
        FirewallingTcpIpConnectionManager cm3 = getFireWalledConnectionManager(hz3);

        
        cm1.block(n2.address);
        cm1.block(n3.address);

        
        n2.clusterService.removeAddress(n1.address);
        n3.clusterService.removeAddress(n1.address);
        cm2.block(n1.address);
        cm3.block(n1.address);

        assertTrue(splitLatch.await(120, TimeUnit.SECONDS));
        assertEquals(3, hz1.getCluster().getMembers().size());
        assertEquals(2, hz2.getCluster().getMembers().size());
        assertEquals(2, hz3.getCluster().getMembers().size());

        
        
        cm1.unblock(n2.address);
        cm2.unblock(n1.address);
        cm3.unblock(n1.address);

        assertTrue(mergeLatch.await(120, TimeUnit.SECONDS));
        assertEquals(3, hz1.getCluster().getMembers().size());
        assertEquals(3, hz2.getCluster().getMembers().size());
        assertEquals(3, hz3.getCluster().getMembers().size());

        assertEquals(n2.getThisAddress(), n1.getMasterAddress());
        assertEquals(n2.getThisAddress(), n2.getMasterAddress());
        assertEquals(n2.getThisAddress(), n3.getMasterAddress());
    }

    @Test
    public void testClusterMerge_when_split_not_detected_by_slave() throws InterruptedException {
        Config config = new Config();
        String groupName = generateRandomString(10);
        config.getGroupConfig().setName(groupName);
        config.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MAX_NO_HEARTBEAT_SECONDS, "15");
        config.setProperty(GroupProperties.PROP_MAX_JOIN_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "10");

        NetworkConfig networkConfig = config.getNetworkConfig();
        networkConfig.getJoin().getMulticastConfig().setEnabled(false);
        networkConfig.getJoin().getTcpIpConfig()
                .setEnabled(true).addMember("127.0.0.1");

        HazelcastInstance hz1 = newHazelcastInstance(config, "test-node1", new FirewallingNodeContext());
        HazelcastInstance hz2 = newHazelcastInstance(config, "test-node2", new FirewallingNodeContext());
        HazelcastInstance hz3 = newHazelcastInstance(config, "test-node3", new FirewallingNodeContext());

        Node n1 = TestUtil.getNode(hz1);
        Node n2 = TestUtil.getNode(hz2);
        final Node n3 = TestUtil.getNode(hz3);

        final CountDownLatch splitLatch = new CountDownLatch(2);
        MembershipAdapter membershipAdapter = new MembershipAdapter() {
            @Override
            public void memberRemoved(MembershipEvent event) {
                if (n3.getLocalMember().equals(event.getMember())) {
                    splitLatch.countDown();
                }
            }
        };

        hz1.getCluster().addMembershipListener(membershipAdapter);
        hz2.getCluster().addMembershipListener(membershipAdapter);

        final CountDownLatch mergeLatch = new CountDownLatch(1);
        LifecycleListener lifecycleListener = new LifecycleListener() {
            @Override
            public void stateChanged(LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    mergeLatch.countDown();
                }
            }
        };
        hz3.getLifecycleService().addLifecycleListener(lifecycleListener);

        FirewallingTcpIpConnectionManager cm1 = getFireWalledConnectionManager(hz1);
        FirewallingTcpIpConnectionManager cm2 = getFireWalledConnectionManager(hz2);
        FirewallingTcpIpConnectionManager cm3 = getFireWalledConnectionManager(hz3);

        cm3.block(n1.address);
        cm3.block(n2.address);

        n1.clusterService.removeAddress(n3.address);
        n2.clusterService.removeAddress(n3.address);
        cm1.block(n3.address);
        cm2.block(n3.address);

        assertTrue(splitLatch.await(30, TimeUnit.SECONDS));
        assertEquals(2, hz1.getCluster().getMembers().size());
        assertEquals(2, hz2.getCluster().getMembers().size());
        assertEquals(3, hz3.getCluster().getMembers().size());

        cm3.unblock(n1.address);
        cm1.unblock(n3.address);
        cm2.unblock(n3.address);

        assertTrue(mergeLatch.await(120, TimeUnit.SECONDS));
        assertEquals(3, hz1.getCluster().getMembers().size());
        assertEquals(3, hz2.getCluster().getMembers().size());
        assertEquals(3, hz3.getCluster().getMembers().size());

        assertEquals(n1.getThisAddress(), n1.getMasterAddress());
        assertEquals(n1.getThisAddress(), n2.getMasterAddress());
        assertEquals(n1.getThisAddress(), n3.getMasterAddress());
    }


    @Test
    public void testClusterMerge_when_split_not_detected_by_slave_and_restart_during_merge() throws InterruptedException {
        Config config = new Config();
        String groupName = generateRandomString(10);
        config.getGroupConfig().setName(groupName);
        config.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MAX_NO_HEARTBEAT_SECONDS, "15");
        config.setProperty(GroupProperties.PROP_MAX_JOIN_SECONDS, "40");
        config.setProperty(GroupProperties.PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "10");

        NetworkConfig networkConfig = config.getNetworkConfig();
        networkConfig.getJoin().getMulticastConfig().setEnabled(false);
        networkConfig.getJoin().getTcpIpConfig()
                .setEnabled(true).addMember("127.0.0.1:5701").addMember("127.0.0.1:5702").addMember("127.0.0.1:5703");

        networkConfig.setPort(5702);
        HazelcastInstance hz2 = newHazelcastInstance(config, "test-node2", new FirewallingNodeContext());
        networkConfig.setPort(5703);
        HazelcastInstance hz3 = newHazelcastInstance(config, "test-node3", new FirewallingNodeContext());
        networkConfig.setPort(5701);
        HazelcastInstance hz1 = newHazelcastInstance(config, "test-node1", new FirewallingNodeContext());

        final Node n1 = TestUtil.getNode(hz1);
        Node n2 = TestUtil.getNode(hz2);
        Node n3 = TestUtil.getNode(hz3);

        final CountDownLatch splitLatch = new CountDownLatch(2);
        MembershipAdapter membershipAdapter = new MembershipAdapter() {
            @Override
            public void memberRemoved(MembershipEvent event) {
                if (n1.getLocalMember().equals(event.getMember())) {
                    splitLatch.countDown();
                }
            }
        };

        hz2.getCluster().addMembershipListener(membershipAdapter);
        hz3.getCluster().addMembershipListener(membershipAdapter);

        final CountDownLatch mergingLatch = new CountDownLatch(1);
        final CountDownLatch mergeLatch = new CountDownLatch(1);
        LifecycleListener lifecycleListener = new LifecycleListener() {
            @Override
            public void stateChanged(LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGING) {
                    mergingLatch.countDown();
                }
                if (event.getState() == LifecycleState.MERGED) {
                    mergeLatch.countDown();
                }
            }
        };
        hz1.getLifecycleService().addLifecycleListener(lifecycleListener);

        FirewallingTcpIpConnectionManager cm1 = getFireWalledConnectionManager(hz1);
        FirewallingTcpIpConnectionManager cm2 = getFireWalledConnectionManager(hz2);
        FirewallingTcpIpConnectionManager cm3 = getFireWalledConnectionManager(hz3);

        cm1.block(n2.address);
        cm1.block(n3.address);

        n2.clusterService.removeAddress(n1.address);
        n3.clusterService.removeAddress(n1.address);
        cm2.block(n1.address);
        cm3.block(n1.address);

        assertTrue(splitLatch.await(20, TimeUnit.SECONDS));
        assertEquals(2, hz2.getCluster().getMembers().size());
        assertEquals(2, hz3.getCluster().getMembers().size());
        assertEquals(3, hz1.getCluster().getMembers().size());

        cm1.unblock(n2.address);
        cm1.unblock(n3.address);
        cm2.unblock(n1.address);
        cm3.unblock(n1.address);

        assertTrue(mergingLatch.await(60, TimeUnit.SECONDS));
        hz2.getLifecycleService().terminate();
        hz2 = newHazelcastInstance(config, "test-node2", new FirewallingNodeContext());
        n2 = TestUtil.getNode(hz2);

        assertTrue(mergeLatch.await(120, TimeUnit.SECONDS));
        assertEquals(3, hz1.getCluster().getMembers().size());
        assertEquals(3, hz2.getCluster().getMembers().size());
        assertEquals(3, hz3.getCluster().getMembers().size());

        assertEquals(n3.getThisAddress(), n1.getMasterAddress());
        assertEquals(n3.getThisAddress(), n2.getMasterAddress());
        assertEquals(n3.getThisAddress(), n3.getMasterAddress());
    }

    private static class FirewallingNodeContext extends DefaultNodeContext {
        @Override
        public ConnectionManager createConnectionManager(Node node, ServerSocketChannel serverSocketChannel) {
            NodeIOService ioService = new NodeIOService(node, node.nodeEngine);
            return new FirewallingTcpIpConnectionManager(node.loggingService,
                    node.getHazelcastThreadGroup(), ioService, serverSocketChannel);
        }
    }

    private static FirewallingTcpIpConnectionManager getFireWalledConnectionManager(HazelcastInstance hz) {
        return (FirewallingTcpIpConnectionManager) getConnectionManager(hz);
    }
}

<code block>


package com.hazelcast.test;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.AbstractJoiner;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.AddressPicker;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.NodeContext;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.IOService;
import com.hazelcast.nio.NodeIOService;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.executor.StripedRunnable;

import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.nio.channels.ServerSocketChannel;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.CopyOnWriteArraySet;

public final class TestNodeRegistry {

    private final ConcurrentMap<Address, NodeEngineImpl> nodes = new ConcurrentHashMap<Address, NodeEngineImpl>(10);
    private final Object joinerLock = new Object();
    private final CopyOnWriteArrayList<Address> joinAddresses;

    TestNodeRegistry(CopyOnWriteArrayList<Address> addresses) {
        this.joinAddresses = addresses;
    }

    public NodeContext createNodeContext(Address address) {
        return new MockNodeContext(joinAddresses, nodes, address, joinerLock);
    }

    public HazelcastInstance getInstance(Address address) {
        NodeEngineImpl nodeEngine = nodes.get(address);
        return nodeEngine != null && nodeEngine.isActive() ? nodeEngine.getHazelcastInstance() : null;
    }

    Collection<HazelcastInstance> getAllHazelcastInstances() {
        Collection<HazelcastInstance> all = new LinkedList<HazelcastInstance>();
        for (NodeEngineImpl nodeEngine : nodes.values()) {
            if (nodeEngine.isActive()) {
                all.add(nodeEngine.getHazelcastInstance());
            }
        }
        return all;
    }

    void shutdown() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            value.getHazelcastInstance().shutdown();
        }
    }

    void terminate() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            HazelcastInstance hz = value.getHazelcastInstance();
            hz.getLifecycleService().terminate();
        }
    }

    private static class MockNodeContext implements NodeContext {

        final CopyOnWriteArrayList<Address> joinAddresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Address thisAddress;
        final Object joinerLock;

        public MockNodeContext(CopyOnWriteArrayList<Address> addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Address thisAddress, Object joinerLock) {
            this.joinAddresses = addresses;
            this.nodes = nodes;
            this.thisAddress = thisAddress;
            this.joinerLock = joinerLock;
        }

        public AddressPicker createAddressPicker(Node node) {
            return new StaticAddressPicker(thisAddress);
        }

        public Joiner createJoiner(Node node) {
            return new MockJoiner(node, joinAddresses, nodes, joinerLock);
        }

        public ConnectionManager createConnectionManager(Node node, ServerSocketChannel serverSocketChannel) {
            NodeIOService ioService = new NodeIOService(node, node.nodeEngine);
            return new MockConnectionManager(ioService, nodes, node, joinerLock);
        }
    }

    private static class StaticAddressPicker implements AddressPicker {
        final Address thisAddress;

        private StaticAddressPicker(Address thisAddress) {
            this.thisAddress = thisAddress;
        }

        public void pickAddress() throws Exception {
        }

        public Address getBindAddress() {
            return thisAddress;
        }

        public Address getPublicAddress() {
            return thisAddress;
        }

        public ServerSocketChannel getServerSocketChannel() {
            return null;
        }
    }

    private static class MockJoiner extends AbstractJoiner {

        final CopyOnWriteArrayList<Address> joinAddresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Object joinerLock;

        MockJoiner(Node node, CopyOnWriteArrayList<Address> addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Object joinerLock) {
            super(node);
            this.joinAddresses = addresses;
            this.nodes = nodes;
            this.joinerLock = joinerLock;
        }

        public void doJoin() {
            NodeEngineImpl nodeEngine = null;
            synchronized (joinerLock) {
                for (Address address : joinAddresses) {
                    NodeEngineImpl ne = nodes.get(address);
                    if (ne != null && ne.getNode().isActive() && ne.getNode().joined()) {
                        nodeEngine = ne;
                        break;
                    }
                }
                Address master = null;
                if (nodeEngine != null) {
                    if (nodeEngine.getNode().isMaster()) {
                        master = nodeEngine.getThisAddress();
                    } else {
                        master = nodeEngine.getMasterAddress();
                    }
                }
                if (master == null) {
                    master = node.getThisAddress();
                }
                node.setMasterAddress(master);
                if (node.getMasterAddress().equals(node.getThisAddress())) {
                    node.setJoined();
                    node.setAsMaster();
                } else {
                    for (int i = 0; !node.joined() && i < 2000; i++) {
                        try {
                            node.clusterService.sendJoinRequest(node.getMasterAddress(), true);
                            Thread.sleep(50);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    if (!node.joined()) {
                        throw new AssertionError("Node[" + node.getThisAddress()
                                + "] should have been joined to " + node.getMasterAddress());
                    }
                }
            }
        }

        public void searchForOtherClusters() {
        }

        @Override
        public String getType() {
            return "mock";
        }

        public String toString() {
            return "MockJoiner";
        }

        @Override
        public void blacklist(Address address, boolean permanent) {
        }

        @Override
        public boolean unblacklist(Address address) {
            return false;
        }

        @Override
        public boolean isBlacklisted(Address address) {
            return false;
        }
    }

    private static class MockConnectionManager implements ConnectionManager {
        private final Set<ConnectionListener> connectionListeners = new CopyOnWriteArraySet<ConnectionListener>();
        private final IOService ioService;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Map<Address, MockConnection> mapConnections = new ConcurrentHashMap<Address, MockConnection>(10);
        final Node node;
        final Object joinerLock;

        MockConnectionManager(IOService ioService, ConcurrentMap<Address, NodeEngineImpl> nodes,
                              Node node, Object joinerLock) {
            this.ioService = ioService;
            this.nodes = nodes;
            this.node = node;
            this.joinerLock = joinerLock;
            synchronized (this.joinerLock) {
                this.nodes.put(node.getThisAddress(), node.nodeEngine);
            }
        }

      @Override
      public Connection getConnection(Address address) {
            MockConnection conn = mapConnections.get(address);
            if (conn == null) {
                NodeEngineImpl nodeEngine = nodes.get(address);
                MockConnection thisConnection = new MockConnection(address, node.getThisAddress(), node.nodeEngine);
                conn = new MockConnection(node.getThisAddress(), address, nodeEngine);
                conn.localConnection = thisConnection;
                thisConnection.localConnection = conn;
                mapConnections.put(address, conn);
            }
            return conn;
        }

        @Override
        public Connection getOrConnect(Address address) {
            return getConnection(address);
        }

        @Override
        public Connection getOrConnect(Address address, boolean silent) {
            return getConnection(address);
        }

        @Override
        public void shutdown() {
            for (Address address : nodes.keySet()) {
                if (address.equals(node.getThisAddress())) continue;

                final NodeEngineImpl nodeEngine = nodes.get(address);
                if (nodeEngine != null && nodeEngine.isActive()) {
                    nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                        public void run() {
                            final ClusterServiceImpl clusterService = (ClusterServiceImpl) nodeEngine.getClusterService();
                            clusterService.removeAddress(node.getThisAddress());
                        }
                    });
                }
            }
        }

        @Override
        public boolean registerConnection(final Address remoteEndpoint, final Connection connection) {
            mapConnections.put(remoteEndpoint, (MockConnection) connection);
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionAdded(connection);
                    }
                }

                @Override
                public int getKey() {
                    return remoteEndpoint.hashCode();
                }
            });
            return true;
        }

        @Override
        public void start() {
        }

        @Override
        public void addConnectionListener(ConnectionListener connectionListener) {
            connectionListeners.add(connectionListener);
        }

        public void destroyConnection(final Connection connection) {
            final Address endPoint = connection.getEndPoint();
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionRemoved(connection);
                    }
                }

                @Override
                public int getKey() {
                    return endPoint.hashCode();
                }
            });
        }

        @Override
        public void stop() {
        }

        @Override
        public int getActiveConnectionCount() {
            return 0;
        }

        @Override
        public int getCurrentClientConnections() {
            return 0;
        }

        @Override
        public int getConnectionCount() {
            return 0;
        }

        @Override
        public int getAllTextConnections() {
            return 0;
        }
    }

    public static class MockConnection implements Connection {
        protected final Address localEndpoint;
        volatile Connection localConnection;
        final Address remoteEndpoint;
        protected final NodeEngineImpl nodeEngine;
        private volatile boolean live = true;

        public MockConnection(Address localEndpoint, Address remoteEndpoint, NodeEngineImpl nodeEngine) {
            this.localEndpoint = localEndpoint;
            this.remoteEndpoint = remoteEndpoint;
            this.nodeEngine = nodeEngine;
        }

        public Address getEndPoint() {
            return remoteEndpoint;
        }

        public boolean live() {
            return live;
        }

        public boolean write(SocketWritable socketWritable) {
            final Packet packet = (Packet) socketWritable;
            if (nodeEngine.getNode().isActive()) {
                Packet newPacket = readFromPacket(packet);
                nodeEngine.getPacketTransceiver().receive(newPacket);
                return true;
            }
            return false;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }

            newPacket.setConn(localConnection);
            return newPacket;
        }

        public long lastReadTime() {
            return System.currentTimeMillis();
        }

        public long lastWriteTime() {
            return System.currentTimeMillis();
        }

        public void close() {
            if (!live) {
                return;
            }
            live = false;
            nodeEngine.getNode().connectionManager.destroyConnection(this);
        }

        public boolean isClient() {
            return false;
        }

        @Override
        public ConnectionType getType() {
            return ConnectionType.MEMBER;
        }

        public InetAddress getInetAddress() {
            try {
                return localEndpoint.getInetAddress();
            } catch (UnknownHostException e) {
                throw ExceptionUtil.rethrow(e);
            }
        }

        public InetSocketAddress getRemoteSocketAddress() {
            return new InetSocketAddress(getInetAddress(), getPort());
        }

        public int getPort() {
            return localEndpoint.getPort();
        }

        @Override
        public boolean isAlive() {
            return true;
        }

        @Override
        public String toString() {
            return "MockConnection{" +
                    "localEndpoint=" + localEndpoint +
                    ", remoteEndpoint=" + remoteEndpoint +
                    '}';
        }
    }
}

<code block>


package com.hazelcast.client.test;

import com.hazelcast.client.HazelcastClient;
import com.hazelcast.client.config.ClientAwsConfig;
import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.connection.AddressTranslator;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.connection.nio.ClientConnection;
import com.hazelcast.client.connection.nio.ClientConnectionManagerImpl;
import com.hazelcast.client.impl.ClientConnectionManagerFactory;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.spi.impl.AwsAddressTranslator;
import com.hazelcast.client.spi.impl.DefaultAddressTranslator;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.TestUtil;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.test.TestNodeRegistry;
import com.hazelcast.util.ExceptionUtil;

import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.util.logging.Level;

public class TestClientRegistry {

    private static final ILogger LOGGER = Logger.getLogger(HazelcastClient.class);
    private final TestNodeRegistry nodeRegistry;

    public TestClientRegistry(TestNodeRegistry nodeRegistry) {
        this.nodeRegistry = nodeRegistry;
    }


    ClientConnectionManagerFactory createClientServiceFactory(Address clientAddress) {
        return new MockClientConnectionManagerFactory(clientAddress);
    }

    private class MockClientConnectionManagerFactory implements ClientConnectionManagerFactory {

        private final Address clientAddress;

        public MockClientConnectionManagerFactory(Address clientAddress) {
            this.clientAddress = clientAddress;
        }

        @Override
        public ClientConnectionManager createConnectionManager(ClientConfig config, HazelcastClientInstanceImpl client) {
            final ClientAwsConfig awsConfig = config.getNetworkConfig().getAwsConfig();
            AddressTranslator addressTranslator;
            if (awsConfig != null && awsConfig.isEnabled()) {
                try {
                    addressTranslator = new AwsAddressTranslator(awsConfig);
                } catch (NoClassDefFoundError e) {
                    LOGGER.log(Level.WARNING, "hazelcast-cloud.jar might be missing!");
                    throw e;
                }
            } else {
                addressTranslator = new DefaultAddressTranslator();
            }
            return new MockClientConnectionManager(client, addressTranslator, clientAddress);
        }
    }


    private class MockClientConnectionManager extends ClientConnectionManagerImpl {

        private final Address clientAddress;
        private final HazelcastClientInstanceImpl client;

        public MockClientConnectionManager(HazelcastClientInstanceImpl client, AddressTranslator addressTranslator,
                                           Address clientAddress) {
            super(client, addressTranslator);
            this.client = client;
            this.clientAddress = clientAddress;
        }

        @Override
        protected void initializeSelectors(HazelcastClientInstanceImpl client) {

        }

        @Override
        protected void startSelectors() {

        }

        @Override
        protected void shutdownSelectors() {

        }

        @Override
        protected ClientConnection createSocketConnection(Address address) throws IOException {
            if (!alive) {
                throw new HazelcastException("ConnectionManager is not active!!!");
            }
            try {
                HazelcastInstance instance = nodeRegistry.getInstance(address);
                if (instance == null) {
                    throw new IOException("Can not connected to " + address + ": instance does not exist");
                }
                Node node = TestUtil.getNode(instance);
                return new MockedClientConnection(client, connectionIdGen.incrementAndGet(),
                        node.nodeEngine, address, clientAddress);
            } catch (Exception e) {
                throw ExceptionUtil.rethrow(e, IOException.class);
            }
        }


    }


    private class MockedClientConnection extends ClientConnection {
        private volatile long lastReadTime;
        private volatile long lastWriteTime;
        private final NodeEngineImpl serverNodeEngine;
        private final Address remoteAddress;
        private final Address localAddress;
        private final Connection serverSideConnection;

        public MockedClientConnection(HazelcastClientInstanceImpl client, int connectionId, NodeEngineImpl serverNodeEngine,
                                      Address address, Address localAddress) throws IOException {
            super(client, connectionId);
            this.serverNodeEngine = serverNodeEngine;
            this.remoteAddress = address;
            this.localAddress = localAddress;
            this.serverSideConnection = new MockedNodeConnection(connectionId, remoteAddress,
                    localAddress, serverNodeEngine, this);
        }

        void handlePacket(Packet packet) {
            lastReadTime = System.currentTimeMillis();
            getConnectionManager().handlePacket(packet);
        }

        @Override
        public boolean write(SocketWritable socketWritable) {
            Packet newPacket = readFromPacket((Packet) socketWritable);
            lastWriteTime = System.currentTimeMillis();
            serverNodeEngine.getNode().clientEngine.handlePacket(newPacket);
            return true;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }


            newPacket.setConn(serverSideConnection);
            return newPacket;
        }

        @Override
        public void init() throws IOException {

        }

        @Override
        public long lastReadTime() {
            return lastReadTime;
        }

        @Override
        public long lastWriteTime() {
            return lastWriteTime;
        }

        @Override
        public InetAddress getInetAddress() {
            try {
                return remoteAddress.getInetAddress();
            } catch (UnknownHostException e) {
                e.printStackTrace();
                return null;
            }
        }

        @Override
        public InetSocketAddress getRemoteSocketAddress() {
            try {
                return remoteAddress.getInetSocketAddress();
            } catch (UnknownHostException e) {
                e.printStackTrace();
                return null;
            }
        }

        @Override
        public int getPort() {
            return remoteAddress.getPort();
        }

        @Override
        public InetSocketAddress getLocalSocketAddress() {
            try {
                return localAddress.getInetSocketAddress();
            } catch (UnknownHostException e) {
                e.printStackTrace();
            }
            return null;
        }

        @Override
        protected void innerClose() throws IOException {
            serverSideConnection.close();
        }
    }

    private class MockedNodeConnection extends TestNodeRegistry.MockConnection {

        private final MockedClientConnection responseConnection;
        private final int connectionId;

        public MockedNodeConnection(int connectionId, Address localEndpoint, Address remoteEndpoint, NodeEngineImpl nodeEngine
                , MockedClientConnection responseConnection) {
            super(localEndpoint, remoteEndpoint, nodeEngine);
            this.responseConnection = responseConnection;
            this.connectionId = connectionId;
        }

        @Override
        public boolean write(SocketWritable socketWritable) {
            final Packet packet = (Packet) socketWritable;
            if (nodeEngine.getNode().isActive()) {
                Packet newPacket = readFromPacket(packet);
                responseConnection.handlePacket(newPacket);
                return true;
            }
            return false;
        }

        @Override
        public boolean isClient() {
            return true;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }

            newPacket.setConn(responseConnection);
            return newPacket;
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (o == null || getClass() != o.getClass()) return false;

            MockedNodeConnection that = (MockedNodeConnection) o;

            if (connectionId != that.connectionId) return false;
            Address remoteEndpoint = getEndPoint();
            return !(remoteEndpoint != null ? !remoteEndpoint.equals(that.getEndPoint()) : that.getEndPoint() != null);

        }

        @Override
        public void close() {
            super.close();
            ClientConnectionManager connectionManager = responseConnection.getConnectionManager();
            connectionManager.destroyConnection(responseConnection);
        }

        @Override
        public int hashCode() {
            int result = connectionId;
            Address remoteEndpoint = getEndPoint();
            result = 31 * result + (remoteEndpoint != null ? remoteEndpoint.hashCode() : 0);
            return result;
        }

        @Override
        public ConnectionType getType() {
            return ConnectionType.JAVA_CLIENT;
        }

        @Override
        public String toString() {
            return "MockedNodeConnection{" +
                    " remoteEndpoint = " + getEndPoint() +
                    ", localEndpoint = " + localEndpoint +
                    ", connectionId = " + connectionId +
                    '}';
        }
    }
}

<code block>


package com.hazelcast.instance;

import com.hazelcast.config.Config;
import com.hazelcast.core.IMap;
import com.hazelcast.internal.monitors.HealthMonitorLevel;
import com.hazelcast.map.QueryResultSizeExceededException;
import com.hazelcast.map.impl.QueryResultSizeLimiter;
import com.hazelcast.query.TruePredicate;


public class GroupProperties {

    
    public static final String PROP_APPLICATION_VALIDATION_TOKEN = "hazelcast.application.validation.token";

    public static final String PROP_HEALTH_MONITORING_LEVEL = "hazelcast.health.monitoring.level";
    public static final String PROP_HEALTH_MONITORING_DELAY_SECONDS = "hazelcast.health.monitoring.delay.seconds";

    
    public static final String PROP_PERFORMANCE_MONITOR_ENABLED = "hazelcast.performance.monitoring.enabled";

    
    public static final String PROP_PERFORMANCE_MONITOR_DELAY_SECONDS
            = "hazelcast.performance.monitor.delay.seconds";

    
    public static final String PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE_MB
            = "hazelcast.performance.monitor.max.rolled.file.size.mb";

    
    public static final String PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT
            = "hazelcast.performance.monitor.max.rolled.file.count";

    
    public static final String PROP_PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT
            = "hazelcast.performance.monitor.human.friendly.format";

    public static final String PROP_VERSION_CHECK_ENABLED = "hazelcast.version.check.enabled";
    public static final String PROP_PREFER_IPv4_STACK = "hazelcast.prefer.ipv4.stack";
    public static final String PROP_IO_THREAD_COUNT = "hazelcast.io.thread.count";

    
    public static final String PROP_IO_BALANCER_INTERVAL_SECONDS = "hazelcast.io.balancer.interval.seconds";
    
    public static final String PROP_PARTITION_OPERATION_THREAD_COUNT = "hazelcast.operation.thread.count";
    public static final String PROP_GENERIC_OPERATION_THREAD_COUNT = "hazelcast.operation.generic.thread.count";
    public static final String PROP_EVENT_THREAD_COUNT = "hazelcast.event.thread.count";
    public static final String PROP_EVENT_QUEUE_CAPACITY = "hazelcast.event.queue.capacity";
    public static final String PROP_EVENT_QUEUE_TIMEOUT_MILLIS = "hazelcast.event.queue.timeout.millis";
    public static final String PROP_CONNECT_ALL_WAIT_SECONDS = "hazelcast.connect.all.wait.seconds";
    public static final String PROP_MEMCACHE_ENABLED = "hazelcast.memcache.enabled";
    public static final String PROP_REST_ENABLED = "hazelcast.rest.enabled";
    public static final String PROP_MAP_LOAD_CHUNK_SIZE = "hazelcast.map.load.chunk.size";
    public static final String PROP_MERGE_FIRST_RUN_DELAY_SECONDS = "hazelcast.merge.first.run.delay.seconds";
    public static final String PROP_MERGE_NEXT_RUN_DELAY_SECONDS = "hazelcast.merge.next.run.delay.seconds";
    public static final String PROP_OPERATION_CALL_TIMEOUT_MILLIS = "hazelcast.operation.call.timeout.millis";

    
    public static final String PROP_OPERATION_BACKUP_TIMEOUT_MILLIS = "hazelcast.operation.backup.timeout.millis";

    public static final String PROP_SOCKET_BIND_ANY = "hazelcast.socket.bind.any";
    public static final String PROP_SOCKET_SERVER_BIND_ANY = "hazelcast.socket.server.bind.any";
    public static final String PROP_SOCKET_CLIENT_BIND_ANY = "hazelcast.socket.client.bind.any";
    public static final String PROP_SOCKET_CLIENT_BIND = "hazelcast.socket.client.bind";
    
    public static final String PROP_CLIENT_ENGINE_THREAD_COUNT = "hazelcast.clientengine.thread.count";
    public static final String PROP_SOCKET_RECEIVE_BUFFER_SIZE = "hazelcast.socket.receive.buffer.size";
    public static final String PROP_SOCKET_SEND_BUFFER_SIZE = "hazelcast.socket.send.buffer.size";

    
    public static final String PROP_SOCKET_CLIENT_RECEIVE_BUFFER_SIZE = "hazelcast.socket.client.receive.buffer.size";

    
    public static final String PROP_SOCKET_CLIENT_SEND_BUFFER_SIZE = "hazelcast.socket.client.send.buffer.size";

    public static final String PROP_SOCKET_LINGER_SECONDS = "hazelcast.socket.linger.seconds";
    public static final String PROP_SOCKET_CONNECT_TIMEOUT_SECONDS = "hazelcast.socket.connect.timeout.seconds";
    public static final String PROP_SOCKET_KEEP_ALIVE = "hazelcast.socket.keep.alive";
    public static final String PROP_SOCKET_NO_DELAY = "hazelcast.socket.no.delay";
    public static final String PROP_SHUTDOWNHOOK_ENABLED = "hazelcast.shutdownhook.enabled";
    public static final String PROP_WAIT_SECONDS_BEFORE_JOIN = "hazelcast.wait.seconds.before.join";
    public static final String PROP_MAX_WAIT_SECONDS_BEFORE_JOIN = "hazelcast.max.wait.seconds.before.join";
    public static final String PROP_MAX_JOIN_SECONDS = "hazelcast.max.join.seconds";
    public static final String PROP_MAX_JOIN_MERGE_TARGET_SECONDS = "hazelcast.max.join.merge.target.seconds";
    public static final String PROP_HEARTBEAT_INTERVAL_SECONDS = "hazelcast.heartbeat.interval.seconds";
    public static final String PROP_MAX_NO_HEARTBEAT_SECONDS = "hazelcast.max.no.heartbeat.seconds";
    public static final String PROP_MAX_NO_MASTER_CONFIRMATION_SECONDS = "hazelcast.max.no.master.confirmation.seconds";
    public static final String PROP_MASTER_CONFIRMATION_INTERVAL_SECONDS
            = "hazelcast.master.confirmation.interval.seconds";
    public static final String PROP_MEMBER_LIST_PUBLISH_INTERVAL_SECONDS
            = "hazelcast.member.list.publish.interval.seconds";
    public static final String PROP_ICMP_ENABLED = "hazelcast.icmp.enabled";
    public static final String PROP_ICMP_TIMEOUT = "hazelcast.icmp.timeout";
    public static final String PROP_ICMP_TTL = "hazelcast.icmp.ttl";
    public static final String PROP_INITIAL_MIN_CLUSTER_SIZE = "hazelcast.initial.min.cluster.size";
    public static final String PROP_INITIAL_WAIT_SECONDS = "hazelcast.initial.wait.seconds";

    
    public static final String PROP_TCP_JOIN_PORT_TRY_COUNT = "hazelcast.tcp.join.port.try.count";
    public static final String PROP_MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS
            = "hazelcast.map.replica.scheduled.task.delay.seconds";
    
    public static final String PROP_MAP_EXPIRY_DELAY_SECONDS = "hazelcast.map.expiry.delay.seconds";
    public static final String PROP_PARTITION_COUNT = "hazelcast.partition.count";
    public static final String PROP_LOGGING_TYPE = "hazelcast.logging.type";
    public static final String PROP_ENABLE_JMX = "hazelcast.jmx";
    public static final String PROP_ENABLE_JMX_DETAILED = "hazelcast.jmx.detailed";
    public static final String PROP_MC_MAX_VISIBLE_INSTANCE_COUNT = "hazelcast.mc.max.visible.instance.count";
    public static final String PROP_MC_MAX_VISIBLE_SLOW_OPERATION_COUNT = "hazelcast.mc.max.visible.slow.operations.count";
    public static final String PROP_MC_URL_CHANGE_ENABLED = "hazelcast.mc.url.change.enabled";
    public static final String PROP_CONNECTION_MONITOR_INTERVAL = "hazelcast.connection.monitor.interval";
    public static final String PROP_CONNECTION_MONITOR_MAX_FAULTS = "hazelcast.connection.monitor.max.faults";
    public static final String PROP_PARTITION_MIGRATION_INTERVAL = "hazelcast.partition.migration.interval";
    public static final String PROP_PARTITION_MIGRATION_TIMEOUT = "hazelcast.partition.migration.timeout";
    public static final String PROP_PARTITION_MIGRATION_ZIP_ENABLED = "hazelcast.partition.migration.zip.enabled";
    public static final String PROP_PARTITION_TABLE_SEND_INTERVAL = "hazelcast.partition.table.send.interval";
    public static final String PROP_PARTITION_BACKUP_SYNC_INTERVAL = "hazelcast.partition.backup.sync.interval";
    public static final String PROP_PARTITION_MAX_PARALLEL_REPLICATIONS
            = "hazelcast.partition.max.parallel.replications";
    public static final String PROP_PARTITIONING_STRATEGY_CLASS = "hazelcast.partitioning.strategy.class";
    public static final String PROP_GRACEFUL_SHUTDOWN_MAX_WAIT = "hazelcast.graceful.shutdown.max.wait";
    public static final String PROP_SYSTEM_LOG_ENABLED = "hazelcast.system.log.enabled";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_ENABLED = "hazelcast.slow.operation.detector.enabled";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS
            = "hazelcast.slow.operation.detector.threshold.millis";


    
    public static final String PROP_SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS
            = "hazelcast.slow.invocation.detector.threshold.millis";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS
            = "hazelcast.slow.operation.detector.log.retention.seconds";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS
            = "hazelcast.slow.operation.detector.log.purge.interval.seconds";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED
            = "hazelcast.slow.operation.detector.stacktrace.logging.enabled";

    
    public static final String PROP_ELASTIC_MEMORY_ENABLED = "hazelcast.elastic.memory.enabled";
    public static final String PROP_ELASTIC_MEMORY_TOTAL_SIZE = "hazelcast.elastic.memory.total.size";
    public static final String PROP_ELASTIC_MEMORY_CHUNK_SIZE = "hazelcast.elastic.memory.chunk.size";
    public static final String PROP_ELASTIC_MEMORY_SHARED_STORAGE = "hazelcast.elastic.memory.shared.storage";
    public static final String PROP_ELASTIC_MEMORY_UNSAFE_ENABLED = "hazelcast.elastic.memory.unsafe.enabled";
    public static final String PROP_ENTERPRISE_LICENSE_KEY = "hazelcast.enterprise.license.key";
    public static final String PROP_MAP_WRITE_BEHIND_QUEUE_CAPACITY = "hazelcast.map.write.behind.queue.capacity";

    
    public static final String PROP_ENTERPRISE_WAN_REP_QUEUE_CAPACITY = "hazelcast.enterprise.wanrep.queue.capacity";

    
    public static final String PROP_ENTERPRISE_WAN_REP_BATCH_SIZE = "hazelcast.enterprise.wanrep.batch.size";

    
    public static final String PROP_ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS
            = "hazelcast.enterprise.wanrep.batchfrequency.seconds";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED
            = "hazelcast.cache.invalidation.batch.enabled";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_SIZE
            = "hazelcast.cache.invalidation.batch.size";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS
            = "hazelcast.cache.invalidation.batchfrequency.seconds";

    
    public static final String PROP_ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS
            = "hazelcast.enterprise.wanrep.optimeout.millis";

    public static final String PROP_CLIENT_MAX_NO_HEARTBEAT_SECONDS = "hazelcast.client.max.no.heartbeat.seconds";
    public static final String PROP_MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS
            = "hazelcast.migration.min.delay.on.member.removed.seconds";

    
    public static final String PROP_BACKPRESSURE_ENABLED = "hazelcast.backpressure.enabled";

    
    public static final String PROP_BACKPRESSURE_SYNCWINDOW = "hazelcast.backpressure.syncwindow";

    
    public static final String PROP_BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS
            = "hazelcast.backpressure.backoff.timeout.millis";

    
    public static final String PROP_BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION
            = "hazelcast.backpressure.max.concurrent.invocations.per.partition";


    
    public static final String PROP_QUERY_PREDICATE_PARALLEL_EVALUATION = "hazelcast.query.predicate.parallel.evaluation";


    
    public static final String PROP_JCACHE_PROVIDER_TYPE = "hazelcast.jcache.provider.type";

    
    public static final String PROP_QUERY_RESULT_SIZE_LIMIT = "hazelcast.query.result.size.limit";

    
    public static final String PROP_QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK
            = "hazelcast.query.max.local.partition.limit.for.precheck";

    public final GroupProperty CLIENT_ENGINE_THREAD_COUNT;

    public final GroupProperty PARTITION_OPERATION_THREAD_COUNT;

    public final GroupProperty GENERIC_OPERATION_THREAD_COUNT;

    public final GroupProperty EVENT_THREAD_COUNT;

    public final GroupProperty HEALTH_MONITORING_LEVEL;

    public final GroupProperty HEALTH_MONITORING_DELAY_SECONDS;

    public final GroupProperty PERFORMANCE_MONITOR_ENABLED;

    public final GroupProperty PERFORMANCE_MONITOR_DELAY_SECONDS;

    public final GroupProperty PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE;

    public final GroupProperty PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT;

    public final GroupProperty PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT;

    public final GroupProperty IO_THREAD_COUNT;

    public final GroupProperty IO_BALANCER_INTERVAL_SECONDS;

    public final GroupProperty EVENT_QUEUE_CAPACITY;

    public final GroupProperty EVENT_QUEUE_TIMEOUT_MILLIS;

    public final GroupProperty PREFER_IPv4_STACK;

    public final GroupProperty CONNECT_ALL_WAIT_SECONDS;

    public final GroupProperty VERSION_CHECK_ENABLED;

    public final GroupProperty MEMCACHE_ENABLED;

    public final GroupProperty REST_ENABLED;

    public final GroupProperty MAP_LOAD_CHUNK_SIZE;

    public final GroupProperty MERGE_FIRST_RUN_DELAY_SECONDS;

    public final GroupProperty MERGE_NEXT_RUN_DELAY_SECONDS;

    public final GroupProperty OPERATION_CALL_TIMEOUT_MILLIS;

    public final GroupProperty OPERATION_BACKUP_TIMEOUT_MILLIS;

    public final GroupProperty SOCKET_SERVER_BIND_ANY;

    public final GroupProperty SOCKET_CLIENT_BIND_ANY;

    public final GroupProperty SOCKET_CLIENT_BIND;

    
    public final GroupProperty SOCKET_RECEIVE_BUFFER_SIZE;

    
    public final GroupProperty SOCKET_SEND_BUFFER_SIZE;

    
    public final GroupProperty SOCKET_CLIENT_RECEIVE_BUFFER_SIZE;

    
    public final GroupProperty SOCKET_CLIENT_SEND_BUFFER_SIZE;

    public final GroupProperty SOCKET_LINGER_SECONDS;

    public final GroupProperty SOCKET_CONNECT_TIMEOUT_SECONDS;

    public final GroupProperty SOCKET_KEEP_ALIVE;

    public final GroupProperty SOCKET_NO_DELAY;

    public final GroupProperty SHUTDOWNHOOK_ENABLED;

    public final GroupProperty WAIT_SECONDS_BEFORE_JOIN;

    public final GroupProperty MAX_WAIT_SECONDS_BEFORE_JOIN;

    public final GroupProperty MAX_JOIN_SECONDS;

    public final GroupProperty MAX_JOIN_MERGE_TARGET_SECONDS;

    public final GroupProperty MAX_NO_HEARTBEAT_SECONDS;

    public final GroupProperty HEARTBEAT_INTERVAL_SECONDS;

    public final GroupProperty MASTER_CONFIRMATION_INTERVAL_SECONDS;

    public final GroupProperty MAX_NO_MASTER_CONFIRMATION_SECONDS;

    public final GroupProperty MEMBER_LIST_PUBLISH_INTERVAL_SECONDS;

    public final GroupProperty ICMP_ENABLED;

    public final GroupProperty ICMP_TIMEOUT;

    public final GroupProperty ICMP_TTL;

    public final GroupProperty INITIAL_WAIT_SECONDS;

    public final GroupProperty INITIAL_MIN_CLUSTER_SIZE;

    public final GroupProperty TCP_JOIN_PORT_TRY_COUNT;

    public final GroupProperty MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS;

    public final GroupProperty MAP_EXPIRY_DELAY_SECONDS;

    public final GroupProperty PARTITION_COUNT;

    public final GroupProperty LOGGING_TYPE;

    public final GroupProperty ENABLE_JMX;

    public final GroupProperty ENABLE_JMX_DETAILED;

    public final GroupProperty MC_MAX_INSTANCE_COUNT;

    public final GroupProperty MC_MAX_SLOW_OPERATION_COUNT;

    public final GroupProperty MC_URL_CHANGE_ENABLED;

    public final GroupProperty CONNECTION_MONITOR_INTERVAL;

    public final GroupProperty CONNECTION_MONITOR_MAX_FAULTS;

    public final GroupProperty PARTITION_MIGRATION_INTERVAL;

    public final GroupProperty PARTITION_MIGRATION_TIMEOUT;

    public final GroupProperty PARTITION_MIGRATION_ZIP_ENABLED;

    public final GroupProperty PARTITION_TABLE_SEND_INTERVAL;

    public final GroupProperty PARTITION_BACKUP_SYNC_INTERVAL;

    public final GroupProperty PARTITION_MAX_PARALLEL_REPLICATIONS;

    public final GroupProperty PARTITIONING_STRATEGY_CLASS;

    public final GroupProperty GRACEFUL_SHUTDOWN_MAX_WAIT;

    public final GroupProperty SYSTEM_LOG_ENABLED;

    public final GroupProperty SLOW_OPERATION_DETECTOR_ENABLED;
    public final GroupProperty SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED;

    public final GroupProperty SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS;

    public final GroupProperty ELASTIC_MEMORY_ENABLED;

    public final GroupProperty ELASTIC_MEMORY_TOTAL_SIZE;

    public final GroupProperty ELASTIC_MEMORY_CHUNK_SIZE;

    public final GroupProperty ELASTIC_MEMORY_SHARED_STORAGE;

    public final GroupProperty ELASTIC_MEMORY_UNSAFE_ENABLED;

    public final GroupProperty ENTERPRISE_LICENSE_KEY;

    
    public final GroupProperty MAP_WRITE_BEHIND_QUEUE_CAPACITY;

    public final GroupProperty ENTERPRISE_WAN_REP_QUEUE_CAPACITY;
    public final GroupProperty ENTERPRISE_WAN_REP_BATCH_SIZE;
    public final GroupProperty ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS;
    public final GroupProperty ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS;

    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED;
    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_SIZE;
    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS;

    public final GroupProperty CLIENT_HEARTBEAT_TIMEOUT_SECONDS;

    public final GroupProperty MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS;

    public final GroupProperty BACKPRESSURE_ENABLED;
    public final GroupProperty BACKPRESSURE_SYNCWINDOW;
    public final GroupProperty BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS;
    public final GroupProperty BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION;

    public final GroupProperty QUERY_RESULT_SIZE_LIMIT;
    public final GroupProperty QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK;

    public final GroupProperty QUERY_PREDICATE_PARALLEL_EVALUATION;

    public GroupProperties(Config config) {
        HEALTH_MONITORING_LEVEL
                = new GroupProperty(config, PROP_HEALTH_MONITORING_LEVEL, HealthMonitorLevel.SILENT.toString());
        HEALTH_MONITORING_DELAY_SECONDS
                = new GroupProperty(config, PROP_HEALTH_MONITORING_DELAY_SECONDS, "30");

        PERFORMANCE_MONITOR_ENABLED
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_ENABLED, "false");
        PERFORMANCE_MONITOR_DELAY_SECONDS
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_DELAY_SECONDS, "30");
        PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE_MB, "10");
        PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT, "10");
        PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT, "true");

        VERSION_CHECK_ENABLED = new GroupProperty(config, PROP_VERSION_CHECK_ENABLED, "true");
        PREFER_IPv4_STACK = new GroupProperty(config, PROP_PREFER_IPv4_STACK, "true");
        IO_THREAD_COUNT = new GroupProperty(config, PROP_IO_THREAD_COUNT, "3");
        IO_BALANCER_INTERVAL_SECONDS = new GroupProperty(config, PROP_IO_BALANCER_INTERVAL_SECONDS, "20");

        
        PARTITION_OPERATION_THREAD_COUNT = new GroupProperty(config, PROP_PARTITION_OPERATION_THREAD_COUNT, "-1");
        GENERIC_OPERATION_THREAD_COUNT = new GroupProperty(config, PROP_GENERIC_OPERATION_THREAD_COUNT, "-1");
        EVENT_THREAD_COUNT = new GroupProperty(config, PROP_EVENT_THREAD_COUNT, "5");
        EVENT_QUEUE_CAPACITY = new GroupProperty(config, PROP_EVENT_QUEUE_CAPACITY, "1000000");
        EVENT_QUEUE_TIMEOUT_MILLIS = new GroupProperty(config, PROP_EVENT_QUEUE_TIMEOUT_MILLIS, "250");
        CLIENT_ENGINE_THREAD_COUNT = new GroupProperty(config, PROP_CLIENT_ENGINE_THREAD_COUNT, "-1");

        CONNECT_ALL_WAIT_SECONDS = new GroupProperty(config, PROP_CONNECT_ALL_WAIT_SECONDS, "120");
        MEMCACHE_ENABLED = new GroupProperty(config, PROP_MEMCACHE_ENABLED, "true");
        REST_ENABLED = new GroupProperty(config, PROP_REST_ENABLED, "true");
        MAP_LOAD_CHUNK_SIZE = new GroupProperty(config, PROP_MAP_LOAD_CHUNK_SIZE, "1000");
        MERGE_FIRST_RUN_DELAY_SECONDS = new GroupProperty(config, PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "300");
        MERGE_NEXT_RUN_DELAY_SECONDS = new GroupProperty(config, PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "120");
        OPERATION_CALL_TIMEOUT_MILLIS = new GroupProperty(config, PROP_OPERATION_CALL_TIMEOUT_MILLIS, "60000");
        OPERATION_BACKUP_TIMEOUT_MILLIS = new GroupProperty(config, PROP_OPERATION_BACKUP_TIMEOUT_MILLIS, "5000");

        final GroupProperty SOCKET_BIND_ANY = new GroupProperty(config, PROP_SOCKET_BIND_ANY, "true");
        SOCKET_SERVER_BIND_ANY = new GroupProperty(config, PROP_SOCKET_SERVER_BIND_ANY, SOCKET_BIND_ANY);
        SOCKET_CLIENT_BIND_ANY = new GroupProperty(config, PROP_SOCKET_CLIENT_BIND_ANY, SOCKET_BIND_ANY);
        SOCKET_CLIENT_BIND = new GroupProperty(config, PROP_SOCKET_CLIENT_BIND, "true");
        SOCKET_RECEIVE_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_RECEIVE_BUFFER_SIZE, "32");
        SOCKET_SEND_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_SEND_BUFFER_SIZE, "32");
        SOCKET_CLIENT_RECEIVE_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_CLIENT_RECEIVE_BUFFER_SIZE, "-1");
        SOCKET_CLIENT_SEND_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_CLIENT_SEND_BUFFER_SIZE, "-1");
        SOCKET_LINGER_SECONDS = new GroupProperty(config, PROP_SOCKET_LINGER_SECONDS, "0");
        SOCKET_CONNECT_TIMEOUT_SECONDS = new GroupProperty(config, PROP_SOCKET_CONNECT_TIMEOUT_SECONDS, "0");
        SOCKET_KEEP_ALIVE = new GroupProperty(config, PROP_SOCKET_KEEP_ALIVE, "true");
        SOCKET_NO_DELAY = new GroupProperty(config, PROP_SOCKET_NO_DELAY, "true");
        SHUTDOWNHOOK_ENABLED = new GroupProperty(config, PROP_SHUTDOWNHOOK_ENABLED, "true");
        WAIT_SECONDS_BEFORE_JOIN = new GroupProperty(config, PROP_WAIT_SECONDS_BEFORE_JOIN, "5");
        MAX_WAIT_SECONDS_BEFORE_JOIN = new GroupProperty(config, PROP_MAX_WAIT_SECONDS_BEFORE_JOIN, "20");
        MAX_JOIN_SECONDS = new GroupProperty(config, PROP_MAX_JOIN_SECONDS, "300");
        MAX_JOIN_MERGE_TARGET_SECONDS = new GroupProperty(config, PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "20");
        HEARTBEAT_INTERVAL_SECONDS = new GroupProperty(config, PROP_HEARTBEAT_INTERVAL_SECONDS, "1");
        MAX_NO_HEARTBEAT_SECONDS = new GroupProperty(config, PROP_MAX_NO_HEARTBEAT_SECONDS, "300");
        MASTER_CONFIRMATION_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_MASTER_CONFIRMATION_INTERVAL_SECONDS, "30");
        MAX_NO_MASTER_CONFIRMATION_SECONDS = new GroupProperty(config, PROP_MAX_NO_MASTER_CONFIRMATION_SECONDS, "500");
        MEMBER_LIST_PUBLISH_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_MEMBER_LIST_PUBLISH_INTERVAL_SECONDS, "300");
        ICMP_ENABLED = new GroupProperty(config, PROP_ICMP_ENABLED, "false");
        ICMP_TIMEOUT = new GroupProperty(config, PROP_ICMP_TIMEOUT, "1000");
        ICMP_TTL = new GroupProperty(config, PROP_ICMP_TTL, "0");
        INITIAL_MIN_CLUSTER_SIZE = new GroupProperty(config, PROP_INITIAL_MIN_CLUSTER_SIZE, "0");
        INITIAL_WAIT_SECONDS = new GroupProperty(config, PROP_INITIAL_WAIT_SECONDS, "0");
        TCP_JOIN_PORT_TRY_COUNT = new GroupProperty(config, PROP_TCP_JOIN_PORT_TRY_COUNT, "3");
        MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS
                = new GroupProperty(config, PROP_MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS, "10");
        MAP_EXPIRY_DELAY_SECONDS = new GroupProperty(config, PROP_MAP_EXPIRY_DELAY_SECONDS, "10");
        PARTITION_COUNT = new GroupProperty(config, PROP_PARTITION_COUNT, "271");
        LOGGING_TYPE = new GroupProperty(config, PROP_LOGGING_TYPE, "jdk");
        ENABLE_JMX = new GroupProperty(config, PROP_ENABLE_JMX, "false");
        ENABLE_JMX_DETAILED = new GroupProperty(config, PROP_ENABLE_JMX_DETAILED, "false");
        MC_MAX_INSTANCE_COUNT = new GroupProperty(config, PROP_MC_MAX_VISIBLE_INSTANCE_COUNT, "100");
        MC_MAX_SLOW_OPERATION_COUNT = new GroupProperty(config, PROP_MC_MAX_VISIBLE_SLOW_OPERATION_COUNT, "10");
        MC_URL_CHANGE_ENABLED = new GroupProperty(config, PROP_MC_URL_CHANGE_ENABLED, "true");
        CONNECTION_MONITOR_INTERVAL = new GroupProperty(config, PROP_CONNECTION_MONITOR_INTERVAL, "100");
        CONNECTION_MONITOR_MAX_FAULTS = new GroupProperty(config, PROP_CONNECTION_MONITOR_MAX_FAULTS, "3");
        PARTITION_MIGRATION_INTERVAL = new GroupProperty(config, PROP_PARTITION_MIGRATION_INTERVAL, "0");
        PARTITION_MIGRATION_TIMEOUT = new GroupProperty(config, PROP_PARTITION_MIGRATION_TIMEOUT, "300");
        PARTITION_MIGRATION_ZIP_ENABLED = new GroupProperty(config, PROP_PARTITION_MIGRATION_ZIP_ENABLED, "true");
        PARTITION_TABLE_SEND_INTERVAL = new GroupProperty(config, PROP_PARTITION_TABLE_SEND_INTERVAL, "15");
        PARTITION_BACKUP_SYNC_INTERVAL = new GroupProperty(config, PROP_PARTITION_BACKUP_SYNC_INTERVAL, "30");
        PARTITION_MAX_PARALLEL_REPLICATIONS = new GroupProperty(config, PROP_PARTITION_MAX_PARALLEL_REPLICATIONS, "5");
        PARTITIONING_STRATEGY_CLASS = new GroupProperty(config, PROP_PARTITIONING_STRATEGY_CLASS, "");
        GRACEFUL_SHUTDOWN_MAX_WAIT = new GroupProperty(config, PROP_GRACEFUL_SHUTDOWN_MAX_WAIT, "600");
        SYSTEM_LOG_ENABLED = new GroupProperty(config, PROP_SYSTEM_LOG_ENABLED, "true");

        SLOW_OPERATION_DETECTOR_ENABLED
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_ENABLED, "true");
        SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS, "10000");
        SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS, "3600");
        SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS, "300");
        SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED, "false");
        SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS
                = new GroupProperty(config, PROP_SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS, "-1");

        ELASTIC_MEMORY_ENABLED = new GroupProperty(config, PROP_ELASTIC_MEMORY_ENABLED, "false");
        ELASTIC_MEMORY_TOTAL_SIZE = new GroupProperty(config, PROP_ELASTIC_MEMORY_TOTAL_SIZE, "128M");
        ELASTIC_MEMORY_CHUNK_SIZE = new GroupProperty(config, PROP_ELASTIC_MEMORY_CHUNK_SIZE, "1K");
        ELASTIC_MEMORY_SHARED_STORAGE = new GroupProperty(config, PROP_ELASTIC_MEMORY_SHARED_STORAGE, "false");
        ELASTIC_MEMORY_UNSAFE_ENABLED = new GroupProperty(config, PROP_ELASTIC_MEMORY_UNSAFE_ENABLED, "false");
        ENTERPRISE_LICENSE_KEY = new GroupProperty(config, PROP_ENTERPRISE_LICENSE_KEY);
        MAP_WRITE_BEHIND_QUEUE_CAPACITY
                = new GroupProperty(config, PROP_MAP_WRITE_BEHIND_QUEUE_CAPACITY, "50000");

        ENTERPRISE_WAN_REP_QUEUE_CAPACITY = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_QUEUE_CAPACITY, "100000");
        ENTERPRISE_WAN_REP_BATCH_SIZE = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_BATCH_SIZE, "50");
        ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS
                = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS, "5");
        ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS, "60000");

        CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED, "true");
        CACHE_INVALIDATION_MESSAGE_BATCH_SIZE
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_SIZE, "100");
        CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS, "10");

        CLIENT_HEARTBEAT_TIMEOUT_SECONDS = new GroupProperty(config, PROP_CLIENT_MAX_NO_HEARTBEAT_SECONDS, "300");
        MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS
                = new GroupProperty(config, PROP_MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS, "5");
        BACKPRESSURE_ENABLED
                = new GroupProperty(config, PROP_BACKPRESSURE_ENABLED, "false");
        BACKPRESSURE_SYNCWINDOW
                = new GroupProperty(config, PROP_BACKPRESSURE_SYNCWINDOW, "100");
        BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION
                = new GroupProperty(config, PROP_BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION, "100");
        BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS
                = new GroupProperty(config, PROP_BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS, "60000");

        QUERY_RESULT_SIZE_LIMIT = new GroupProperty(config, PROP_QUERY_RESULT_SIZE_LIMIT, "-1");
        QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK
                = new GroupProperty(config, PROP_QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK, "3");

        QUERY_PREDICATE_PARALLEL_EVALUATION
                = new GroupProperty(config, PROP_QUERY_PREDICATE_PARALLEL_EVALUATION, "false");
    }

    public static class GroupProperty {

        private final String name;
        private final String value;

        GroupProperty(Config config, String name) {
            this(config, name, (String) null);
        }

        GroupProperty(Config config, String name, GroupProperty defaultValue) {
            this(config, name, defaultValue != null ? defaultValue.getString() : null);
        }

        GroupProperty(Config config, String name, String defaultValue) {
            this.name = name;
            String configValue = (config != null) ? config.getProperty(name) : null;
            if (configValue != null) {
                value = configValue;
            } else if (System.getProperty(name) != null) {
                value = System.getProperty(name);
            } else {
                value = defaultValue;
            }
        }

        public String getName() {
            return this.name;
        }

        public String getValue() {
            return value;
        }

        public int getInteger() {
            return Integer.parseInt(this.value);
        }

        public byte getByte() {
            return Byte.parseByte(this.value);
        }

        public boolean getBoolean() {
            return Boolean.valueOf(this.value);
        }

        public float getFloat() {
            return Float.valueOf(this.value);
        }

        public String getString() {
            return value;
        }

        public long getLong() {
            return Long.parseLong(this.value);
        }

        @Override
        public String toString() {
            return "GroupProperty [name=" + this.name + ", value=" + this.value + "]";
        }
    }
}

<code block>


package com.hazelcast.instance;

import com.hazelcast.cluster.impl.ClusterDataSerializerHook;
import com.hazelcast.cluster.impl.operations.MemberAttributeChangedOperation;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.HazelcastInstanceAware;
import com.hazelcast.core.Member;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;

import java.util.Map;

import static com.hazelcast.cluster.MemberAttributeOperationType.PUT;
import static com.hazelcast.cluster.MemberAttributeOperationType.REMOVE;
import static com.hazelcast.util.Preconditions.isNotNull;

public final class MemberImpl
        extends AbstractMember
        implements Member, HazelcastInstanceAware, IdentifiedDataSerializable {

    private boolean localMember;
    private volatile HazelcastInstanceImpl instance;
    private volatile long lastRead;
    private volatile long lastWrite;
    private volatile long lastPing;
    private volatile ILogger logger;

    public MemberImpl() {
    }

    public MemberImpl(Address address, boolean localMember) {
        this(address, localMember, null, null);
    }

    public MemberImpl(Address address, boolean localMember, String uuid, HazelcastInstanceImpl instance) {
        this(address, localMember, uuid, instance, null);
    }

    public MemberImpl(Address address, boolean localMember, String uuid, HazelcastInstanceImpl instance,
                      Map<String, Object> attributes) {
        super(address, uuid, attributes);
        this.localMember = localMember;
        this.lastRead = Clock.currentTimeMillis();
        this.instance = instance;
    }

    public MemberImpl(MemberImpl member) {
        super(member);
        this.localMember = member.localMember;
        this.lastRead = member.lastRead;
    }

    @Override
    protected ILogger getLogger() {
        return logger;
    }

    @Override
    public void setHazelcastInstance(HazelcastInstance hazelcastInstance) {
        if (hazelcastInstance instanceof HazelcastInstanceImpl) {
            instance = (HazelcastInstanceImpl) hazelcastInstance;
            localMember = instance.node.address.equals(address);
            logger = instance.node.getLogger(this.getClass().getName());
        }
    }

    @Override
    public boolean localMember() {
        return localMember;
    }

    public void didWrite() {
        lastWrite = Clock.currentTimeMillis();
    }

    public void didRead() {
        lastRead = Clock.currentTimeMillis();
    }

    public void didPing() {
        lastPing = Clock.currentTimeMillis();
    }

    public long getLastPing() {
        return lastPing;
    }

    public long getLastRead() {
        return lastRead;
    }

    public long getLastWrite() {
        return lastWrite;
    }

    @Override
    public String getStringAttribute(String key) {
        return (String) getAttribute(key);
    }

    @Override
    public void setStringAttribute(String key, String value) {
        setAttribute(key, value);
    }

    @Override
    public Boolean getBooleanAttribute(String key) {
        return (Boolean) getAttribute(key);
    }

    @Override
    public void setBooleanAttribute(String key, boolean value) {
        setAttribute(key, value);
    }

    @Override
    public Byte getByteAttribute(String key) {
        return (Byte) getAttribute(key);
    }

    @Override
    public void setByteAttribute(String key, byte value) {
        setAttribute(key, value);
    }

    @Override
    public Short getShortAttribute(String key) {
        return (Short) getAttribute(key);
    }

    @Override
    public void setShortAttribute(String key, short value) {
        setAttribute(key, value);
    }

    @Override
    public Integer getIntAttribute(String key) {
        return (Integer) getAttribute(key);
    }

    @Override
    public void setIntAttribute(String key, int value) {
        setAttribute(key, value);
    }

    @Override
    public Long getLongAttribute(String key) {
        return (Long) getAttribute(key);
    }

    @Override
    public void setLongAttribute(String key, long value) {
        setAttribute(key, value);
    }

    @Override
    public Float getFloatAttribute(String key) {
        return (Float) getAttribute(key);
    }

    @Override
    public void setFloatAttribute(String key, float value) {
        setAttribute(key, value);
    }

    @Override
    public Double getDoubleAttribute(String key) {
        return (Double) getAttribute(key);
    }

    @Override
    public void setDoubleAttribute(String key, double value) {
        setAttribute(key, value);
    }

    @Override
    public void removeAttribute(String key) {
        isLocalMember();
        isNotNull(key, "key");

        Object value = attributes.remove(key);
        if (value == null) {
            return;
        }

        if (instance != null) {
            MemberAttributeChangedOperation operation = new MemberAttributeChangedOperation(REMOVE, key, null);
            invokeOnAllMembers(operation);
        }
    }

    private void isLocalMember() {
        if (!localMember) {
            throw new UnsupportedOperationException("Attributes on remote members must not be changed");
        }
    }

    private void setAttribute(String key, Object value) {
        isLocalMember();
        isNotNull(key, "key");
        isNotNull(value, "value");

        Object oldValue = attributes.put(key, value);
        if (value.equals(oldValue)) {
            return;
        }

        if (instance != null) {
            MemberAttributeChangedOperation operation = new MemberAttributeChangedOperation(PUT, key, value);
            invokeOnAllMembers(operation);
        }
    }

    private void invokeOnAllMembers(Operation operation) {
        NodeEngineImpl nodeEngine = instance.node.nodeEngine;
        OperationService os = nodeEngine.getOperationService();
        String uuid = nodeEngine.getLocalMember().getUuid();
        operation.setCallerUuid(uuid).setNodeEngine(nodeEngine);
        try {
            for (MemberImpl member : nodeEngine.getClusterService().getMemberList()) {
                if (!member.localMember()) {
                    os.send(operation, member.getAddress());
                } else {
                    os.executeOperation(operation);
                }
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public int getFactoryId() {
        return ClusterDataSerializerHook.F_ID;
    }

    @Override
    public int getId() {
        return ClusterDataSerializerHook.MEMBER;
    }

}

<code block>


package com.hazelcast.instance;

import com.hazelcast.client.impl.ClientEngineImpl;
import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.cluster.impl.ConfigCheck;
import com.hazelcast.cluster.impl.JoinRequest;
import com.hazelcast.cluster.impl.MulticastJoiner;
import com.hazelcast.cluster.impl.MulticastService;
import com.hazelcast.cluster.impl.NodeMulticastListener;
import com.hazelcast.cluster.impl.TcpIpJoiner;
import com.hazelcast.config.Config;
import com.hazelcast.config.JoinConfig;
import com.hazelcast.config.ListenerConfig;
import com.hazelcast.config.MemberAttributeConfig;
import com.hazelcast.config.MulticastConfig;
import com.hazelcast.core.ClientListener;
import com.hazelcast.core.DistributedObjectListener;
import com.hazelcast.core.HazelcastInstanceAware;
import com.hazelcast.core.LifecycleListener;
import com.hazelcast.core.MembershipListener;
import com.hazelcast.core.MigrationListener;
import com.hazelcast.internal.ascii.TextCommandService;
import com.hazelcast.internal.ascii.TextCommandServiceImpl;
import com.hazelcast.internal.management.ManagementCenterService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingServiceImpl;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ClassLoaderUtil;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.PartitionLostListener;
import com.hazelcast.partition.impl.InternalPartitionServiceImpl;
import com.hazelcast.security.Credentials;
import com.hazelcast.security.SecurityContext;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.proxyservice.impl.ProxyServiceImpl;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.UuidUtil;
import com.hazelcast.util.VersionCheck;

import java.lang.reflect.Constructor;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.MulticastSocket;
import java.nio.channels.ServerSocketChannel;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

import static com.hazelcast.cluster.impl.MulticastService.createMulticastService;
import static com.hazelcast.instance.NodeShutdownHelper.shutdownNodeByFiringEvents;
import static com.hazelcast.util.UuidUtil.createMemberUuid;

public class Node {

    private final ILogger logger;

    private final AtomicBoolean joined = new AtomicBoolean(false);

    private volatile boolean active;

    private volatile boolean completelyShutdown;

    private final NodeShutdownHookThread shutdownHookThread = new NodeShutdownHookThread("hz.ShutdownThread");

    private final SerializationService serializationService;

    public final NodeEngineImpl nodeEngine;

    public final ClientEngineImpl clientEngine;

    public final InternalPartitionService partitionService;

    public final ClusterServiceImpl clusterService;

    public final MulticastService multicastService;

    public final ConnectionManager connectionManager;

    public final TextCommandServiceImpl textCommandService;

    public final Config config;

    public final GroupProperties groupProperties;

    public final Address address;

    public final MemberImpl localMember;

    private volatile Address masterAddress = null;

    public final HazelcastInstanceImpl hazelcastInstance;

    public final LoggingServiceImpl loggingService;

    private final Joiner joiner;

    private final NodeExtension nodeExtension;

    private ManagementCenterService managementCenterService;

    public final SecurityContext securityContext;

    private final ClassLoader configClassLoader;

    private final BuildInfo buildInfo;

    private final VersionCheck versionCheck = new VersionCheck();

    private final HazelcastThreadGroup hazelcastThreadGroup;

    public Node(HazelcastInstanceImpl hazelcastInstance, Config config, NodeContext nodeContext) {
        this.hazelcastInstance = hazelcastInstance;
        this.config = config;
        this.configClassLoader = config.getClassLoader();
        this.groupProperties = new GroupProperties(config);
        this.buildInfo = BuildInfoProvider.getBuildInfo();

        String loggingType = groupProperties.LOGGING_TYPE.getString();
        loggingService = new LoggingServiceImpl(config.getGroupConfig().getName(), loggingType, buildInfo);
        final AddressPicker addressPicker = nodeContext.createAddressPicker(this);
        try {
            addressPicker.pickAddress();
        } catch (Throwable e) {
            throw ExceptionUtil.rethrow(e);
        }

        final ServerSocketChannel serverSocketChannel = addressPicker.getServerSocketChannel();
        try {
            address = addressPicker.getPublicAddress();
            final Map<String, Object> memberAttributes = findMemberAttributes(config.getMemberAttributeConfig().asReadOnly());
            localMember = new MemberImpl(address, true, createMemberUuid(address), hazelcastInstance, memberAttributes);
            loggingService.setThisMember(localMember);
            logger = loggingService.getLogger(Node.class.getName());
            hazelcastThreadGroup = new HazelcastThreadGroup(
                    hazelcastInstance.getName(), logger, configClassLoader);
            nodeExtension = NodeExtensionFactory.create(configClassLoader);
            nodeExtension.beforeStart(this);

            serializationService = nodeExtension.createSerializationService();
            securityContext = config.getSecurityConfig().isEnabled() ? nodeExtension.getSecurityContext() : null;

            nodeEngine = new NodeEngineImpl(this);

            clientEngine = new ClientEngineImpl(this);
            connectionManager = nodeContext.createConnectionManager(this, serverSocketChannel);
            partitionService = new InternalPartitionServiceImpl(this);
            clusterService = new ClusterServiceImpl(this);
            textCommandService = new TextCommandServiceImpl(this);
            nodeExtension.printNodeInfo(this);
            this.multicastService = createMulticastService(addressPicker.getBindAddress(), this, config, logger);
            initializeListeners(config);
            joiner = nodeContext.createJoiner(this);
        } catch (Throwable e) {
            try {
                serverSocketChannel.close();
            } catch (Throwable ignored) {
            }
            throw ExceptionUtil.rethrow(e);
        }
    }

    public HazelcastThreadGroup getHazelcastThreadGroup() {
        return hazelcastThreadGroup;
    }

    private void initializeListeners(Config config) {
        for (final ListenerConfig listenerCfg : config.getListenerConfigs()) {
            Object listener = listenerCfg.getImplementation();
            if (listener == null) {
                try {
                    listener = ClassLoaderUtil.newInstance(configClassLoader, listenerCfg.getClassName());
                } catch (Exception e) {
                    logger.severe(e);
                }
            }
            if (listener instanceof HazelcastInstanceAware) {
                ((HazelcastInstanceAware) listener).setHazelcastInstance(hazelcastInstance);
            }
            boolean known = false;
            if (listener instanceof DistributedObjectListener) {
                final ProxyServiceImpl proxyService = (ProxyServiceImpl) nodeEngine.getProxyService();
                proxyService.addProxyListener((DistributedObjectListener) listener);
                known = true;
            }
            if (listener instanceof MembershipListener) {
                clusterService.addMembershipListener((MembershipListener) listener);
                known = true;
            }
            if (listener instanceof MigrationListener) {
                partitionService.addMigrationListener((MigrationListener) listener);
                known = true;
            }
            if (listener instanceof PartitionLostListener) {
                partitionService.addPartitionLostListener((PartitionLostListener) listener);
                known = true;
            }
            if (listener instanceof LifecycleListener) {
                hazelcastInstance.lifecycleService.addLifecycleListener((LifecycleListener) listener);
                known = true;
            }
            if (listener instanceof ClientListener) {
                String serviceName = ClientEngineImpl.SERVICE_NAME;
                nodeEngine.getEventService().registerLocalListener(serviceName, serviceName, listener);
                known = true;
            }
            if (listener != null && !known) {
                final String error = "Unknown listener type: " + listener.getClass();
                Throwable t = new IllegalArgumentException(error);
                logger.warning(error, t);
            }
        }
    }

    public ManagementCenterService getManagementCenterService() {
        return managementCenterService;
    }

    public SerializationService getSerializationService() {
        return serializationService;
    }

    public ClusterServiceImpl getClusterService() {
        return clusterService;
    }

    public InternalPartitionService getPartitionService() {
        return partitionService;
    }

    public Address getMasterAddress() {
        return masterAddress;
    }

    public Address getThisAddress() {
        return address;
    }

    public MemberImpl getLocalMember() {
        return localMember;
    }

    public boolean joined() {
        return joined.get();
    }

    public boolean isMaster() {
        return address != null && address.equals(masterAddress);
    }

    public void setMasterAddress(final Address master) {
        if (master != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("** setting master address to " + master);
            }
        }
        masterAddress = master;
    }

    public void start() {
        if (logger.isFinestEnabled()) {
            logger.finest("We are asked to start and completelyShutdown is " + String.valueOf(completelyShutdown));
        }
        if (completelyShutdown) return;
        nodeEngine.start();
        connectionManager.start();
        if (config.getNetworkConfig().getJoin().getMulticastConfig().isEnabled()) {
            final Thread multicastServiceThread = new Thread(
                    hazelcastThreadGroup.getInternalThreadGroup(), multicastService,
                    hazelcastThreadGroup.getThreadNamePrefix("MulticastThread"));
            multicastServiceThread.start();
        }
        setActive(true);
        if (!completelyShutdown && groupProperties.SHUTDOWNHOOK_ENABLED.getBoolean()) {
            logger.finest("Adding ShutdownHook");
            Runtime.getRuntime().addShutdownHook(shutdownHookThread);
        }
        logger.finest("finished starting threads, calling join");
        join();
        int clusterSize = clusterService.getSize();
        if (config.getNetworkConfig().isPortAutoIncrement()
                && address.getPort() >= config.getNetworkConfig().getPort() + clusterSize) {
            StringBuilder sb = new StringBuilder("Config seed port is ");
            sb.append(config.getNetworkConfig().getPort());
            sb.append(" and cluster size is ");
            sb.append(clusterSize);
            sb.append(". Some of the ports seem occupied!");
            logger.warning(sb.toString());
        }
        try {
            managementCenterService = new ManagementCenterService(hazelcastInstance);
        } catch (Exception e) {
            logger.warning("ManagementCenterService could not be constructed!", e);
        }
        nodeExtension.afterStart(this);
        versionCheck.check(this, getBuildInfo().getVersion(), buildInfo.isEnterprise());
    }

    public void shutdown(final boolean terminate) {
        long start = Clock.currentTimeMillis();
        if (logger.isFinestEnabled()) {
            logger.finest("** we are being asked to shutdown when active = " + String.valueOf(active));
        }
        if (!terminate && isActive() && joined()) {
            final int maxWaitSeconds = groupProperties.GRACEFUL_SHUTDOWN_MAX_WAIT.getInteger();
            if (!partitionService.prepareToSafeShutdown(maxWaitSeconds, TimeUnit.SECONDS)) {
                logger.warning("Graceful shutdown could not be completed in " + maxWaitSeconds + " seconds!");
            }
        }
        if (isActive()) {
            if (!terminate) {
                final int maxWaitSeconds = groupProperties.GRACEFUL_SHUTDOWN_MAX_WAIT.getInteger();
                if (!partitionService.prepareToSafeShutdown(maxWaitSeconds, TimeUnit.SECONDS)) {
                    logger.warning("Graceful shutdown could not be completed in " + maxWaitSeconds + " seconds!");
                }
                clusterService.sendShutdownMessage();
            } else {
                logger.warning("Terminating forcefully...");
            }
            
            
            
            joined.set(false);
            setActive(false);
            setMasterAddress(null);
            try {
                if (groupProperties.SHUTDOWNHOOK_ENABLED.getBoolean())
                    Runtime.getRuntime().removeShutdownHook(shutdownHookThread);
            } catch (Throwable ignored) {
            }
            versionCheck.shutdown();
            if (managementCenterService != null) {
                managementCenterService.shutdown();
            }

            textCommandService.stop();
            if (multicastService != null) {
                logger.info("Shutting down multicast service...");
                multicastService.stop();
            }
            logger.info("Shutting down connection manager...");
            connectionManager.shutdown();

            logger.info("Shutting down node engine...");
            nodeEngine.shutdown(terminate);

            if (securityContext != null) {
                securityContext.destroy();
            }
            nodeExtension.destroy();
            logger.finest("Destroying serialization service...");
            serializationService.destroy();

            hazelcastThreadGroup.destroy();
            logger.info("Hazelcast Shutdown is completed in " + (Clock.currentTimeMillis() - start) + " ms.");
        }
    }

    
    public void reset() {
        setMasterAddress(null);
        joined.set(false);
        joiner.reset();
        final String uuid = createMemberUuid(address);
        if (logger.isFinestEnabled()) {
            logger.finest("Generated new UUID for local member: " + uuid);
        }
        localMember.setUuid(uuid);
    }

    public ILogger getLogger(String name) {
        return loggingService.getLogger(name);
    }

    public ILogger getLogger(Class clazz) {
        return loggingService.getLogger(clazz);
    }

    public GroupProperties getGroupProperties() {
        return groupProperties;
    }

    public TextCommandService getTextCommandService() {
        return textCommandService;
    }

    public ConnectionManager getConnectionManager() {
        return connectionManager;
    }

    public void inactivate() {
        joined.set(false);
        setActive(false);
    }

    public ClassLoader getConfigClassLoader() {
        return configClassLoader;
    }

    public NodeEngineImpl getNodeEngine() {
        return nodeEngine;
    }

    public NodeExtension getNodeExtension() {
        return nodeExtension;
    }

    public class NodeShutdownHookThread extends Thread {

        NodeShutdownHookThread(String name) {
            super(name);
        }

        @Override
        public void run() {
            try {
                if (isActive() && !completelyShutdown) {
                    completelyShutdown = true;
                    hazelcastInstance.getLifecycleService().terminate();
                } else {
                    logger.finest(
                            "shutdown hook - we are not --> active and not completely down so we are not calling shutdown");
                }
            } catch (Exception e) {
                logger.warning(e);
            }
        }
    }

    public void setJoined() {
        joined.set(true);
    }

    public JoinRequest createJoinRequest() {
        return createJoinRequest(false);
    }

    public JoinRequest createJoinRequest(boolean withCredentials) {
        final Credentials credentials = (withCredentials && securityContext != null)
                ? securityContext.getCredentialsFactory().newCredentials() : null;

        return new JoinRequest(Packet.VERSION, buildInfo.getBuildNumber(), address,
                localMember.getUuid(), createConfigCheck(), credentials, clusterService.getSize(), 0,
                config.getMemberAttributeConfig().getAttributes());
    }

    public ConfigCheck createConfigCheck() {
        String joinerType = joiner == null ? "" : joiner.getType();
        return new ConfigCheck(config, joinerType);
    }

    public void rejoin() {
        prepareForJoin();
        join();
    }

    private void prepareForJoin() {
        masterAddress = null;
        joined.set(false);
        clusterService.reset();
    }

    public void join() {
        if (joiner == null) {
            logger.warning("No join method is enabled! Starting standalone.");
            setAsMaster();
            return;
        }

        try {
            prepareForJoin();
            joiner.join();
        } catch (Throwable e) {
            logger.severe("Error while joining the cluster!", e);
        }

        if (!joined()) {
            long maxJoinTime = groupProperties.MAX_JOIN_SECONDS.getInteger() * 1000L;
            logger.severe("Could not join cluster in " + maxJoinTime + " ms. Shutting down now!");
            shutdownNodeByFiringEvents(Node.this, true);
        }
    }

    public Joiner getJoiner() {
        return joiner;
    }

    Joiner createJoiner() {
        JoinConfig join = config.getNetworkConfig().getJoin();
        join.verify();

        if (join.getMulticastConfig().isEnabled() && multicastService != null) {
            logger.info("Creating MulticastJoiner");
            return new MulticastJoiner(this);
        } else if (join.getTcpIpConfig().isEnabled()) {
            logger.info("Creating TcpIpJoiner");
            return new TcpIpJoiner(this);
        } else if (join.getAwsConfig().isEnabled()) {
            Class clazz;
            try {
                logger.info("Creating AWSJoiner");
                clazz = Class.forName("com.hazelcast.cluster.impl.TcpIpJoinerOverAWS");
                Constructor constructor = clazz.getConstructor(Node.class);
                return (Joiner) constructor.newInstance(this);
            } catch (Exception e) {
                throw ExceptionUtil.rethrow(e);
            }
        }
        return null;
    }


    public void setAsMaster() {
        logger.finest("This node is being set as the master");
        masterAddress = address;
        setJoined();
        this.getClusterService().getClusterClock().
                setClusterStartTime(Clock.currentTimeMillis());
        this.getClusterService().setClusterId(
                UuidUtil.createClusterUuid()
        );
    }

    public Config getConfig() {
        return config;
    }

    
    public void setActive(boolean active) {
        this.active = active;
    }

    
    public boolean isActive() {
        return active;
    }

    @Override
    public String toString() {
        return "Node[" + hazelcastInstance.getName() + "]";
    }

    public BuildInfo getBuildInfo() {
        return buildInfo;
    }

    private Map<String, Object> findMemberAttributes(MemberAttributeConfig attributeConfig) {
        Map<String, Object> attributes = new HashMap<String, Object>(attributeConfig.getAttributes());
        Properties properties = System.getProperties();
        for (String key : properties.stringPropertyNames()) {
            if (key.startsWith("hazelcast.member.attribute.")) {
                String shortKey = key.substring("hazelcast.member.attribute.".length());
                String value = properties.getProperty(key);
                attributes.put(shortKey, value);
            }
        }
        return attributes;
    }
}

<code block>


package com.hazelcast.spi.impl.packettransceiver.impl;

import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.Packet;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.PacketHandler;
import com.hazelcast.spi.impl.packettransceiver.PacketTransceiver;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.util.concurrent.TimeUnit;

import static com.hazelcast.instance.OutOfMemoryErrorDispatcher.inspectOutputMemoryError;


public class PacketTransceiverImpl implements PacketTransceiver {

    private static final int RETRY_NUMBER = 5;
    private static final int DELAY_FACTOR = 100;

    private final Node node;
    private final ExecutionService executionService;
    private final ILogger logger;
    private final PacketHandler eventService;
    private final PacketHandler wanReplicationService;
    private final PacketHandler operationService;

    public PacketTransceiverImpl(Node node,
                                 ILogger logger,
                                 PacketHandler operationService,
                                 PacketHandler eventService,
                                 PacketHandler wanReplicationService,
                                 ExecutionService executionService) {
        this.node = node;
        this.executionService = executionService;
        this.operationService = operationService;
        this.eventService = eventService;
        this.wanReplicationService = wanReplicationService;
        this.logger = logger;
    }

    @Override
    public boolean transmit(Packet packet, Connection connection) {
        if (connection == null || !connection.isAlive()) {
            return false;
        }
        final MemberImpl memberImpl = node.getClusterService().getMember(connection.getEndPoint());
        if (memberImpl != null) {
            memberImpl.didWrite();
        }
        return connection.write(packet);
    }

    @Override
    public void receive(Packet packet) {
        try {
            if (packet.isHeaderSet(Packet.HEADER_OP)) {
                operationService.handle(packet);
            } else if (packet.isHeaderSet(Packet.HEADER_EVENT)) {
                eventService.handle(packet);
            } else if (packet.isHeaderSet(Packet.HEADER_WAN_REPLICATION)) {
                wanReplicationService.handle(packet);
            } else {
                logger.severe("Unknown packet type! Header: " + packet.getHeader());
            }
        } catch (Throwable t) {
            inspectOutputMemoryError(t);
            logger.severe("Failed to process packet:" + packet, t);
        }
    }

    
    @Override
    public boolean transmit(Packet packet, Address target) {
        return send(packet, target, null);
    }

    private boolean send(Packet packet, Address target, SendTask sendTask) {
        ConnectionManager connectionManager = node.getConnectionManager();
        Connection connection = connectionManager.getConnection(target);
        if (connection != null) {
            return transmit(packet, connection);
        }

        if (sendTask == null) {
            sendTask = new SendTask(packet, target);
        }

        final int retries = sendTask.retries;
        if (retries < RETRY_NUMBER && node.isActive()) {
            connectionManager.getOrConnect(target, true);
            
            executionService.schedule(sendTask, (retries + 1) * DELAY_FACTOR, TimeUnit.MILLISECONDS);
            return true;
        }
        return false;
    }

    private final class SendTask implements Runnable {
        private final Packet packet;
        private final Address target;
        private volatile int retries;

        private SendTask(Packet packet, Address target) {
            this.packet = packet;
            this.target = target;
        }

        @SuppressFBWarnings(value = "VO_VOLATILE_INCREMENT", justification = "single-writer, many-reader")
        @Override
        public void run() {
            retries++;
            if (logger.isFinestEnabled()) {
                logger.finest("Retrying[" + retries + "] packet send operation to: " + target);
            }
            send(packet, target, this);
        }
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.operations.MergeClustersOperation;
import com.hazelcast.cluster.impl.operations.PrepareMergeOperation;
import com.hazelcast.config.Config;
import com.hazelcast.core.Member;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.OperationResponseHandlerFactory;
import com.hazelcast.util.Clock;

import java.util.ArrayList;
import java.util.Collection;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.logging.Level;

import static com.hazelcast.spi.impl.OperationResponseHandlerFactory.*;
import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;

public abstract class AbstractJoiner implements Joiner {

    private final ExceptionHandler whileWaitMergeExceptionHandler;
    private final AtomicLong joinStartTime = new AtomicLong(Clock.currentTimeMillis());
    private final AtomicInteger tryCount = new AtomicInteger(0);
    
    protected final ConcurrentMap<Address, Boolean> blacklistedAddresses = new ConcurrentHashMap<Address, Boolean>();
    protected final Config config;
    protected final Node node;
    protected final ILogger logger;

    private volatile Address targetAddress;

    public AbstractJoiner(Node node) {
        this.node = node;
        this.logger = node.loggingService.getLogger(getClass());
        this.config = node.config;
        whileWaitMergeExceptionHandler =
                logAllExceptions(logger, "While waiting merge response...", Level.FINEST);
    }

    @Override
    public void blacklist(Address address, boolean permanent) {
        logger.info(address + " is added to the blacklist.");
        blacklistedAddresses.putIfAbsent(address, permanent);
    }

    @Override
    public boolean unblacklist(Address address) {
        if (blacklistedAddresses.remove(address, Boolean.FALSE)) {
            logger.info(address + " is removed from the blacklist.");
            return true;
        }
        return false;
    }

    @Override
    public boolean isBlacklisted(Address address) {
        return blacklistedAddresses.containsKey(address);
    }

    public abstract void doJoin();

    @Override
    public final void join() {
        blacklistedAddresses.clear();
        doJoin();
        postJoin();
    }

    private void postJoin() {
        blacklistedAddresses.clear();

        if (logger.isFinestEnabled()) {
            logger.finest("PostJoin master: " + node.getMasterAddress() + ", isMaster: " + node.isMaster());
        }
        if (!node.isActive()) {
            return;
        }
        if (tryCount.incrementAndGet() == 5) {
            logger.warning("Join try count exceed limit, setting this node as master!");
            node.setAsMaster();
        }

        if (node.joined()) {
            if (!node.isMaster()) {
                ensureConnectionToAllMembers();
            }

            if (node.getClusterService().getSize() == 1) {
                final StringBuilder sb = new StringBuilder("\n");
                sb.append(node.clusterService.membersString());
                logger.info(sb.toString());
            }
        }
    }

    private void ensureConnectionToAllMembers() {
        boolean allConnected = false;
        if (node.joined()) {
            logger.finest("Waiting for all connections");
            int connectAllWaitSeconds = node.groupProperties.CONNECT_ALL_WAIT_SECONDS.getInteger();
            int checkCount = 0;
            while (checkCount++ < connectAllWaitSeconds && !allConnected) {
                try {
                    
                    Thread.sleep(1000);
                } catch (InterruptedException ignored) {
                }

                allConnected = true;
                Collection<MemberImpl> members = node.getClusterService().getMemberList();
                for (MemberImpl member : members) {
                    if (!member.localMember() && node.connectionManager.getOrConnect(member.getAddress()) == null) {
                        allConnected = false;
                        if (logger.isFinestEnabled()) {
                            logger.finest("Not-connected to " + member.getAddress());
                        }
                    }
                }
            }
        }
    }

    protected final long getMaxJoinMillis() {return node.getGroupProperties().MAX_JOIN_SECONDS.getInteger() * 1000L;}

    protected final long getMaxJoinTimeToMasterNode() {
        
        
        
        return (node.getGroupProperties().MAX_WAIT_SECONDS_BEFORE_JOIN.getInteger() + 10) * 1000L;
    }

    boolean shouldMerge(JoinMessage joinRequest) {
        boolean shouldMerge = false;
        if (joinRequest != null) {
            boolean validJoinRequest;
            try {
                try {
                    validJoinRequest = node.getClusterService().validateJoinMessage(joinRequest);
                } catch (Exception e) {
                    logger.finest(e.getMessage());
                    validJoinRequest = false;
                }
                if (validJoinRequest) {
                    for (Member member : node.getClusterService().getMembers()) {
                        MemberImpl memberImpl = (MemberImpl) member;
                        if (memberImpl.getAddress().equals(joinRequest.getAddress())) {
                            if (logger.isFinestEnabled()) {
                                logger.finest("Should not merge to " + joinRequest.getAddress()
                                        + ", because it is already member of this cluster.");
                            }
                            return false;
                        }
                    }
                    int currentMemberCount = node.getClusterService().getMembers().size();
                    if (joinRequest.getMemberCount() > currentMemberCount) {
                        
                        logger.info(node.getThisAddress() + " is merging to " + joinRequest.getAddress()
                                + ", because : joinRequest.getMemberCount() > currentMemberCount ["
                                + (joinRequest.getMemberCount() + " > " + currentMemberCount) + "]");
                        if (logger.isFinestEnabled()) {
                            logger.finest(joinRequest.toString());
                        }
                        shouldMerge = true;
                    } else if (joinRequest.getMemberCount() == currentMemberCount) {
                        
                        if (node.getThisAddress().hashCode() > joinRequest.getAddress().hashCode()) {
                            logger.info(node.getThisAddress() + " is merging to " + joinRequest.getAddress()
                                    + ", because : node.getThisAddress().hashCode() > joinRequest.address.hashCode() "
                                    + ", this node member count: " + currentMemberCount);
                            if (logger.isFinestEnabled()) {
                                logger.finest(joinRequest.toString());
                            }
                            shouldMerge = true;
                        } else {
                            if (logger.isFinestEnabled()) {
                                logger.finest(joinRequest.getAddress() + " should merge to this node "
                                        + ", because : node.getThisAddress().hashCode() < joinRequest.address.hashCode() "
                                        + ", this node member count: " + currentMemberCount);
                            }
                        }
                    }
                }
            } catch (Throwable e) {
                logger.severe(e);
                return false;
            }
        }
        return shouldMerge;
    }

    @Override
    public void reset() {
        joinStartTime.set(Clock.currentTimeMillis());
        tryCount.set(0);
    }

    protected void startClusterMerge(final Address targetAddress) {
        final OperationService operationService = node.nodeEngine.getOperationService();
        final Collection<MemberImpl> memberList = node.getClusterService().getMemberList();
        final Collection<Future> calls = new ArrayList<Future>();
        for (MemberImpl member : memberList) {
            if (!member.localMember()) {
                Operation operation = new PrepareMergeOperation(targetAddress);
                Future f = operationService.createInvocationBuilder(ClusterServiceImpl.SERVICE_NAME,
                        operation, member.getAddress()).setTryCount(3).invoke();
                calls.add(f);
            }
        }

        waitWithDeadline(calls, 3, TimeUnit.SECONDS, whileWaitMergeExceptionHandler);

        final PrepareMergeOperation prepareMergeOperation = new PrepareMergeOperation(targetAddress);
        prepareMergeOperation.setNodeEngine(node.nodeEngine).setService(node.getClusterService())
                .setOperationResponseHandler(createEmptyResponseHandler());
        operationService.runOperationOnCallingThread(prepareMergeOperation);


        for (MemberImpl member : memberList) {
            if (!member.localMember()) {
                operationService.createInvocationBuilder(ClusterServiceImpl.SERVICE_NAME,
                        new MergeClustersOperation(targetAddress), member.getAddress())
                        .setTryCount(1).invoke();
            }
        }

        final MergeClustersOperation mergeClustersOperation = new MergeClustersOperation(targetAddress);
        mergeClustersOperation.setNodeEngine(node.nodeEngine).setService(node.getClusterService())
                .setOperationResponseHandler(createEmptyResponseHandler());
        operationService.runOperationOnCallingThread(mergeClustersOperation);
    }

    @Override
    public final long getStartTime() {
        return joinStartTime.get();
    }

    @Override
    public void setTargetAddress(Address targetAddress) {
        this.targetAddress = targetAddress;
    }

    public Address getTargetAddress() {
        final Address target = targetAddress;
        targetAddress = null;
        return target;
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;

import java.io.IOException;

public class JoinMessage implements DataSerializable {

    protected byte packetVersion;
    protected int buildNumber;
    protected Address address;
    protected String uuid;
    protected ConfigCheck configCheck;
    protected int memberCount;

    public JoinMessage() {
    }

    public JoinMessage(byte packetVersion, int buildNumber, Address address, String uuid, ConfigCheck configCheck,
                       int memberCount) {
        this.packetVersion = packetVersion;
        this.buildNumber = buildNumber;
        this.address = address;
        this.uuid = uuid;
        this.configCheck = configCheck;
        this.memberCount = memberCount;
    }

    public byte getPacketVersion() {
        return packetVersion;
    }

    public int getBuildNumber() {
        return buildNumber;
    }

    public Address getAddress() {
        return address;
    }

    public String getUuid() {
        return uuid;
    }

    public ConfigCheck getConfigCheck() {
        return configCheck;
    }

    public int getMemberCount() {
        return memberCount;
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        packetVersion = in.readByte();
        buildNumber = in.readInt();
        address = new Address();
        address.readData(in);
        uuid = in.readUTF();
        configCheck = new ConfigCheck();
        configCheck.readData(in);
        memberCount = in.readInt();
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeByte(packetVersion);
        out.writeInt(buildNumber);
        address.writeData(out);
        out.writeUTF(uuid);
        configCheck.writeData(out);
        out.writeInt(memberCount);
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("JoinMessage");
        sb.append("{packetVersion=").append(packetVersion);
        sb.append(", buildNumber=").append(buildNumber);
        sb.append(", address=").append(address);
        sb.append(", uuid='").append(uuid).append('\'');
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.config.NetworkConfig;
import com.hazelcast.instance.Node;
import com.hazelcast.nio.Address;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.RandomPicker;

import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

public class MulticastJoiner extends AbstractJoiner {

    private static final int PUBLISH_INTERVAL = 100;
    private static final long JOIN_RETRY_INTERVAL = 1000L;

    private final AtomicInteger currentTryCount = new AtomicInteger(0);
    private final AtomicInteger maxTryCount;

    public MulticastJoiner(Node node) {
        super(node);
        maxTryCount = new AtomicInteger(calculateTryCount());
    }

    @Override
    public void doJoin() {
        long joinStartTime = Clock.currentTimeMillis();
        long maxJoinMillis = getMaxJoinMillis();
        Address thisAddress = node.getThisAddress();

        while (node.isActive() && !node.joined() && (Clock.currentTimeMillis() - joinStartTime < maxJoinMillis)) {
            
            node.setMasterAddress(null);

            Address masterAddress = getTargetAddress();
            if (masterAddress == null) {
                masterAddress = findMasterWithMulticast();
            }
            node.setMasterAddress(masterAddress);

            if (masterAddress == null || thisAddress.equals(masterAddress)) {
                node.setAsMaster();
                return;
            }

            logger.info("Trying to join to discovered node: " + masterAddress);
            joinMaster();
        }
    }

    private void joinMaster() {
        long maxMasterJoinTime = getMaxJoinTimeToMasterNode();
        long start = Clock.currentTimeMillis();

        while (node.isActive() && !node.joined() && Clock.currentTimeMillis() - start < maxMasterJoinTime) {
            Address master = node.getMasterAddress();
            if (master != null) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Joining to master " + master);
                }
                node.clusterService.sendJoinRequest(master, true);
            } else {
                break;
            }

            try {
                Thread.sleep(JOIN_RETRY_INTERVAL);
            } catch (InterruptedException e) {
                EmptyStatement.ignore(e);
            }

            if (isBlacklisted(master)) {
                node.setMasterAddress(null);
                return;
            }
        }
    }

    @Override
    public void searchForOtherClusters() {
        final BlockingQueue<JoinMessage> q = new LinkedBlockingQueue<JoinMessage>();
        MulticastListener listener = new MulticastListener() {
            public void onMessage(Object msg) {
                if (msg != null && msg instanceof JoinMessage) {
                    JoinMessage joinRequest = (JoinMessage) msg;
                    if (node.getThisAddress() != null && !node.getThisAddress().equals(joinRequest.getAddress())) {
                        q.add(joinRequest);
                    }
                }
            }
        };
        node.multicastService.addMulticastListener(listener);
        node.multicastService.send(node.createJoinRequest());
        try {
            JoinMessage joinInfo = q.poll(3, TimeUnit.SECONDS);
            if (joinInfo != null) {
                if (joinInfo.getMemberCount() == 1) {
                    
                    
                    
                    Thread.sleep(node.groupProperties.WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L * 2);
                }
                if (shouldMerge(joinInfo)) {
                    logger.warning(node.getThisAddress() + " is merging [multicast] to " + joinInfo.getAddress());
                    startClusterMerge(joinInfo.getAddress());
                }
            }
        } catch (InterruptedException ignored) {
        } catch (Exception e) {
            if (logger != null) {
                logger.warning(e);
            }
        } finally {
            node.multicastService.removeMulticastListener(listener);
        }
    }

    @Override
    public String getType() {
        return "multicast";
    }

    private Address findMasterWithMulticast() {
        try {
            if (logger.isFinestEnabled()) {
                logger.finest("Searching for master node. Max tries: " + maxTryCount.get());
            }
            JoinRequest joinRequest = node.createJoinRequest();
            while (node.isActive() && currentTryCount.incrementAndGet() <= maxTryCount.get()) {
                joinRequest.setTryCount(currentTryCount.get());
                node.multicastService.send(joinRequest);
                if (node.getMasterAddress() == null) {
                    
                    Thread.sleep(PUBLISH_INTERVAL);
                } else {
                    return node.getMasterAddress();
                }
            }
        } catch (final Exception e) {
            if (logger != null) {
                logger.warning(e);
            }
        } finally {
            currentTryCount.set(0);
        }
        return null;
    }

    private int calculateTryCount() {
        final NetworkConfig networkConfig = config.getNetworkConfig();
        int timeoutSeconds = networkConfig.getJoin().getMulticastConfig().getMulticastTimeoutSeconds();
        int tryCountCoefficient = 1000 / PUBLISH_INTERVAL;
        int tryCount = timeoutSeconds * tryCountCoefficient;
        String host = node.getThisAddress().getHost();
        int lastDigits;
        try {
            lastDigits = Integer.parseInt(host.substring(host.lastIndexOf('.') + 1));
        } catch (NumberFormatException e) {
            lastDigits = RandomPicker.getInt(512);
        }
        lastDigits = lastDigits % 100;
        int portDiff = node.getThisAddress().getPort() - networkConfig.getPort();
        tryCount += lastDigits + portDiff * timeoutSeconds * 3;
        return tryCount;
    }

    public void onReceivedJoinRequest(JoinRequest joinRequest) {
        if (joinRequest.getUuid().compareTo(node.localMember.getUuid()) < 0) {
            maxTryCount.incrementAndGet();
        }
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.core.Member;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import java.util.Set;

import static com.hazelcast.util.AddressUtil.matchAnyInterface;
import static java.lang.String.format;

public class NodeMulticastListener implements MulticastListener {

    private final Node node;
    private final Set<String> trustedInterfaces;
    private final ILogger logger;
    private ConfigCheck ourConfig;

    public NodeMulticastListener(Node node) {
        this.node = node;
        this.trustedInterfaces = node.getConfig().getNetworkConfig()
                .getJoin().getMulticastConfig().getTrustedInterfaces();
        this.logger = node.getLogger(NodeMulticastListener.class.getName());
        this.ourConfig = node.createConfigCheck();
    }

    @Override
    public void onMessage(Object msg) {
        if (!isValidJoinMessage(msg)) {
            logDroppedMessage(msg);
            return;
        }

        JoinMessage joinMessage = (JoinMessage) msg;
        if (node.isActive() && node.joined()) {
            handleActiveAndJoined(joinMessage);
        } else {
            handleNotActiveOrNotJoined(joinMessage);
        }
    }

    private void logDroppedMessage(Object msg) {
        if (logger.isFinestEnabled()) {
            logger.finest("Dropped: " + msg);
        }
    }

    private void handleActiveAndJoined(JoinMessage joinMessage) {
        if (!(joinMessage instanceof JoinRequest)) {
            logDroppedMessage(joinMessage);
            return;
        }

        if (node.isMaster()) {
            JoinRequest request = (JoinRequest) joinMessage;
            JoinMessage response = new JoinMessage(request.getPacketVersion(), request.getBuildNumber(),
                    node.getThisAddress(), request.getUuid(), request.getConfigCheck(),
                    node.getClusterService().getSize());
            node.multicastService.send(response);
        } else if (isMasterNode(joinMessage.getAddress()) && !checkMasterUuid(joinMessage.getUuid())) {
            logger.warning("New join request has been received from current master. "
                    + "Removing " + node.getMasterAddress());
            node.getClusterService().removeAddress(node.getMasterAddress());
        }
    }

    private void handleNotActiveOrNotJoined(JoinMessage joinMessage) {
        if (isJoinRequest(joinMessage)) {
            Joiner joiner = node.getJoiner();
            if (joiner instanceof MulticastJoiner) {
                MulticastJoiner multicastJoiner = (MulticastJoiner) joiner;
                multicastJoiner.onReceivedJoinRequest((JoinRequest) joinMessage);
            } else {
                logDroppedMessage(joinMessage);
            }
        } else {
            Address address = joinMessage.getAddress();
            if (node.getJoiner().isBlacklisted(address)) {
                logDroppedMessage(joinMessage);
                return;
            }

            if (!node.joined() && node.getMasterAddress() == null) {
                String masterHost = joinMessage.getAddress().getHost();
                if (trustedInterfaces.isEmpty() || matchAnyInterface(masterHost, trustedInterfaces)) {
                    
                    Address masterAddress = new Address(joinMessage.getAddress());
                    node.setMasterAddress(masterAddress);
                } else {
                    logJoinMessageDropped(masterHost);
                }
            } else {
                logDroppedMessage(joinMessage);
            }
        }
    }

    private boolean isJoinRequest(JoinMessage joinMessage) {
        return joinMessage instanceof JoinRequest;
    }

    private void logJoinMessageDropped(String masterHost) {
        if (logger.isFinestEnabled()) {
            logger.finest(format(
                    "JoinMessage from %s is dropped because its sender is not a trusted interface", masterHost));
        }
    }

    private boolean isJoinMessage(Object msg) {
        return msg != null && msg instanceof JoinMessage;
    }

    private boolean isValidJoinMessage(Object msg) {
        if (!isJoinMessage(msg)) {
            return false;
        }

        JoinMessage joinMessage = (JoinMessage) msg;

        if (isMessageToSelf(joinMessage)) {
            return false;
        }

        ConfigCheck theirConfig = joinMessage.getConfigCheck();
        if (!ourConfig.isSameGroup(theirConfig)) {
            return false;
        }
        return true;
    }

    private boolean isMessageToSelf(JoinMessage joinMessage) {
        Address thisAddress = node.getThisAddress();
        return thisAddress == null || thisAddress.equals(joinMessage.getAddress());
    }

    private boolean isMasterNode(Address address) {
        return address.equals(node.getMasterAddress());
    }

    private boolean checkMasterUuid(String uuid) {
        Member masterMember = getMasterMember(node.getClusterService().getMembers());
        return masterMember == null || masterMember.getUuid().equals(uuid);
    }

    private Member getMasterMember(Set<Member> members) {
        if (members.isEmpty()) {
            return null;
        }

        return members.iterator().next();
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.impl.operations.MasterClaimOperation;
import com.hazelcast.config.Config;
import com.hazelcast.config.InterfacesConfig;
import com.hazelcast.config.NetworkConfig;
import com.hazelcast.config.TcpIpConfig;
import com.hazelcast.core.Member;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.util.AddressUtil;
import com.hazelcast.util.AddressUtil.AddressMatcher;
import com.hazelcast.util.AddressUtil.InvalidAddressException;
import com.hazelcast.util.Clock;

import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.Set;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.util.AddressUtil.AddressHolder;

public class TcpIpJoiner extends AbstractJoiner {

    private static final long JOIN_RETRY_WAIT_TIME = 1000L;

    private final int maxPortTryCount;
    private volatile boolean claimingMaster;

    public TcpIpJoiner(Node node) {
        super(node);
        int tryCount = node.groupProperties.TCP_JOIN_PORT_TRY_COUNT.getInteger();
        if (tryCount <= 0) {
            throw new IllegalArgumentException(GroupProperties.PROP_TCP_JOIN_PORT_TRY_COUNT
                    + " should be greater than zero! Current value: " + tryCount);
        }
        maxPortTryCount = tryCount;
    }

    public boolean isClaimingMaster() {
        return claimingMaster;
    }

    protected int getConnTimeoutSeconds() {
        return config.getNetworkConfig().getJoin().getTcpIpConfig().getConnectionTimeoutSeconds();
    }

    @Override
    public void doJoin() {
        final Address targetAddress = getTargetAddress();
        if (targetAddress != null) {
            long maxJoinMergeTargetMillis = node.getGroupProperties().MAX_JOIN_MERGE_TARGET_SECONDS.getInteger() * 1000L;
            joinViaTargetMember(targetAddress, maxJoinMergeTargetMillis);
            if (!node.joined()) {
                joinViaPossibleMembers();
            }
        } else if (config.getNetworkConfig().getJoin().getTcpIpConfig().getRequiredMember() != null) {
            Address requiredMember = getRequiredMemberAddress();
            long maxJoinMillis = getMaxJoinMillis();
            joinViaTargetMember(requiredMember, maxJoinMillis);
        } else {
            joinViaPossibleMembers();
        }
    }

    private void joinViaTargetMember(Address targetAddress, long maxJoinMillis) {
        try {
            if (targetAddress == null) {
                throw new IllegalArgumentException("Invalid target address -> NULL");
            }
            if (logger.isFinestEnabled()) {
                logger.finest("Joining over target member " + targetAddress);
            }
            if (targetAddress.equals(node.getThisAddress()) || isLocalAddress(targetAddress)) {
                node.setAsMaster();
                return;
            }
            long joinStartTime = Clock.currentTimeMillis();
            Connection connection;
            while (node.isActive() && !node.joined() && (Clock.currentTimeMillis() - joinStartTime < maxJoinMillis)) {
                connection = node.connectionManager.getOrConnect(targetAddress);
                if (connection == null) {
                    
                    Thread.sleep(JOIN_RETRY_WAIT_TIME);
                    continue;
                }
                if (logger.isFinestEnabled()) {
                    logger.finest("Sending joinRequest " + targetAddress);
                }
                node.clusterService.sendJoinRequest(targetAddress, true);
                
                Thread.sleep(JOIN_RETRY_WAIT_TIME);
            }
        } catch (final Exception e) {
            logger.warning(e);
        }
    }

    private void joinViaPossibleMembers() {
        try {
            blacklistedAddresses.clear();
            Collection<Address> possibleAddresses = getPossibleAddresses();

            boolean foundConnection = tryInitialConnection(possibleAddresses);
            if (!foundConnection) {
                logger.finest("This node will assume master role since no possible member where connected to.");
                node.setAsMaster();
                return;
            }

            long maxJoinMillis = getMaxJoinMillis();
            long startTime = Clock.currentTimeMillis();

            while (node.isActive() && !node.joined() && (Clock.currentTimeMillis() - startTime < maxJoinMillis)) {

                tryToJoinPossibleAddresses(possibleAddresses);
                if (node.joined()) {
                    return;
                }

                if (isAllBlacklisted(possibleAddresses)) {
                    logger.finest(
                            "This node will assume master role since none of the possible members accepted join request.");
                    node.setAsMaster();
                    return;
                }

                boolean masterCandidate = isThisNodeMasterCandidate(possibleAddresses);
                if (masterCandidate) {
                    boolean consensus = claimMastership(possibleAddresses);
                    if (consensus) {
                        if (logger.isFinestEnabled()) {
                            Set<Address> votingEndpoints = new HashSet<Address>(possibleAddresses);
                            votingEndpoints.removeAll(blacklistedAddresses.keySet());
                            logger.finest("Setting myself as master after consensus! " +
                                    "Voting endpoints: " + votingEndpoints);
                        }
                        node.setAsMaster();
                        claimingMaster = false;
                        return;
                    }
                } else {
                    if (logger.isFinestEnabled()) {
                        logger.finest("Cannot claim myself as master! Will try to connect a possible master...");
                    }
                }

                claimingMaster = false;
                lookForMaster(possibleAddresses);
            }
        } catch (Throwable t) {
            logger.severe(t);
        }
    }

    private boolean claimMastership(Collection<Address> possibleAddresses) {
        if (logger.isFinestEnabled()) {
            Set<Address> votingEndpoints = new HashSet<Address>(possibleAddresses);
            votingEndpoints.removeAll(blacklistedAddresses.keySet());
            logger.finest("Claiming myself as master node! Asking to endpoints: " + votingEndpoints);
        }
        claimingMaster = true;
        Collection<Future<Boolean>> responses = new LinkedList<Future<Boolean>>();
        for (Address address : possibleAddresses) {
            if (isBlacklisted(address)) {
                continue;
            }
            if (node.getConnectionManager().getConnection(address) != null) {
                Future future = node.nodeEngine.getOperationService()
                        .createInvocationBuilder(ClusterServiceImpl.SERVICE_NAME,
                                new MasterClaimOperation(), address).setTryCount(1).invoke();
                responses.add(future);
            }
        }

        final long maxWait = TimeUnit.SECONDS.toMillis(10);
        long waitTime = 0L;
        boolean consensus = true;
        for (Future<Boolean> response : responses) {
            long t = Clock.currentTimeMillis();
            try {
                consensus = response.get(1, TimeUnit.SECONDS);
            } catch (Exception e) {
                logger.finest(e);
                consensus = false;
            } finally {
                waitTime += (Clock.currentTimeMillis() - t);
            }

            if (!consensus) {
                break;
            }

            if (waitTime > maxWait) {
                consensus = false;
                break;
            }
        }
        return consensus;
    }

    private boolean isThisNodeMasterCandidate(Collection<Address> possibleAddresses) {
        int thisHashCode = node.getThisAddress().hashCode();
        for (Address address : possibleAddresses) {
            if (isBlacklisted(address)) {
                continue;
            }
            if (node.connectionManager.getConnection(address) != null) {
                if (thisHashCode > address.hashCode()) {
                    return false;
                }
            }
        }
        return true;
    }

    private void tryToJoinPossibleAddresses(Collection<Address> possibleAddresses) throws InterruptedException {
        long connectionTimeoutMillis = getConnTimeoutSeconds() * 1000L;
        long start = Clock.currentTimeMillis();

        while (!node.joined() && Clock.currentTimeMillis() - start < connectionTimeoutMillis) {
            Address masterAddress = node.getMasterAddress();
            if (isAllBlacklisted(possibleAddresses) && masterAddress == null) {
                return;
            }

            if (masterAddress != null) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Sending join request to " + masterAddress);
                }
                node.clusterService.sendJoinRequest(masterAddress, true);
            } else {
                sendMasterQuestion(possibleAddresses);
            }

            if (!node.joined()) {
                Thread.sleep(JOIN_RETRY_WAIT_TIME);
            }
        }
    }

    private boolean tryInitialConnection(Collection<Address> possibleAddresses) throws InterruptedException {
        long connectionTimeoutMillis = getConnTimeoutSeconds() * 1000L;
        long start = Clock.currentTimeMillis();
        while (Clock.currentTimeMillis() - start < connectionTimeoutMillis) {
            if (isAllBlacklisted(possibleAddresses)) {
                return false;
            }
            if (logger.isFinestEnabled()) {
                logger.finest("Will send master question to each address in: " + possibleAddresses);
            }
            if (sendMasterQuestion(possibleAddresses)) {
                return true;
            }
            Thread.sleep(JOIN_RETRY_WAIT_TIME);
        }
        return false;
    }

    private boolean isAllBlacklisted(Collection<Address> possibleAddresses) {
        return blacklistedAddresses.keySet().containsAll(possibleAddresses);
    }

    private void lookForMaster(Collection<Address> possibleAddresses) throws InterruptedException {
        int tryCount = 0;
        while (node.getMasterAddress() == null && tryCount++ < 20) {
            sendMasterQuestion(possibleAddresses);
            
            Thread.sleep(JOIN_RETRY_WAIT_TIME);
            if (isAllBlacklisted(possibleAddresses)) {
                break;
            }
        }

        if (node.joined()) {
            return;
        }

        if (isAllBlacklisted(possibleAddresses) && node.getMasterAddress() == null) {
            if (logger.isFinestEnabled()) {
                logger.finest("Setting myself as master! No possible addresses remaining to connect...");
            }
            node.setAsMaster();
            return;
        }

        long maxMasterJoinTime = getMaxJoinTimeToMasterNode();
        long start = Clock.currentTimeMillis();

        while (node.isActive() && !node.joined() && Clock.currentTimeMillis() - start < maxMasterJoinTime) {
            Address master = node.getMasterAddress();
            if (master != null) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Joining to master " + master);
                }
                node.clusterService.sendJoinRequest(master, true);
            } else {
                break;
            }

            
            Thread.sleep(JOIN_RETRY_WAIT_TIME);
        }

        if (!node.joined()) {
            Address master = node.getMasterAddress();
            if (master != null) {
                logger.warning("Couldn't join to the master : " + master);
            } else {
                if (logger.isFinestEnabled()) {
                    logger.finest("Couldn't find a master! But there was connections available: " + possibleAddresses);
                }
            }
        }
    }

    private boolean sendMasterQuestion(Collection<Address> possibleAddresses) {
        if (logger.isFinestEnabled()) {
            logger.finest("NOT sending master question to blacklisted endpoints: " + blacklistedAddresses);
        }
        boolean sent = false;
        for (Address address : possibleAddresses) {
            if (isBlacklisted(address)) {
                continue;
            }
            if (logger.isFinestEnabled()) {
                logger.finest("Sending master question to " + address);
            }
            if (node.clusterService.sendMasterQuestion(address)) {
                sent = true;
            }
        }
        return sent;
    }

    private Address getRequiredMemberAddress() {
        final TcpIpConfig tcpIpConfig = config.getNetworkConfig().getJoin().getTcpIpConfig();
        final String host = tcpIpConfig.getRequiredMember();
        try {
            final AddressHolder addressHolder = AddressUtil.getAddressHolder(host, config.getNetworkConfig().getPort());
            if (AddressUtil.isIpAddress(addressHolder.getAddress())) {
                return new Address(addressHolder.getAddress(), addressHolder.getPort());
            } else {
                final InterfacesConfig interfaces = config.getNetworkConfig().getInterfaces();
                if (interfaces.isEnabled()) {
                    final InetAddress[] inetAddresses = InetAddress.getAllByName(addressHolder.getAddress());
                    if (inetAddresses.length > 1) {
                        for (InetAddress inetAddress : inetAddresses) {
                            if (AddressUtil.matchAnyInterface(inetAddress.getHostAddress(),
                                    interfaces.getInterfaces())) {
                                return new Address(inetAddress, addressHolder.getPort());
                            }
                        }
                    } else {
                        final InetAddress inetAddress = inetAddresses[0];
                        if (AddressUtil.matchAnyInterface(inetAddress.getHostAddress(),
                                interfaces.getInterfaces())) {
                            return new Address(addressHolder.getAddress(), addressHolder.getPort());
                        }
                    }
                } else {
                    return new Address(addressHolder.getAddress(), addressHolder.getPort());
                }
            }
        } catch (final Exception e) {
            logger.warning(e);
        }
        return null;
    }

    private Collection<Address> getPossibleAddresses() {
        final Collection<String> possibleMembers = getMembers();
        final Set<Address> possibleAddresses = new HashSet<Address>();
        final NetworkConfig networkConfig = config.getNetworkConfig();
        for (String possibleMember : possibleMembers) {
            AddressHolder addressHolder = AddressUtil.getAddressHolder(possibleMember);
            try {
                boolean portIsDefined = addressHolder.getPort() != -1 || !networkConfig.isPortAutoIncrement();
                int count = portIsDefined ? 1 : maxPortTryCount;
                int port = addressHolder.getPort() != -1 ? addressHolder.getPort() : networkConfig.getPort();
                AddressMatcher addressMatcher = null;
                try {
                    addressMatcher = AddressUtil.getAddressMatcher(addressHolder.getAddress());
                } catch (InvalidAddressException ignore) {
                }
                if (addressMatcher != null) {
                    final Collection<String> matchedAddresses;
                    if (addressMatcher.isIPv4()) {
                        matchedAddresses = AddressUtil.getMatchingIpv4Addresses(addressMatcher);
                    } else {
                        
                        matchedAddresses = Collections.singleton(addressHolder.getAddress());
                    }
                    for (String matchedAddress : matchedAddresses) {
                        addPossibleAddresses(possibleAddresses, null, InetAddress.getByName(matchedAddress), port, count);
                    }
                } else {
                    final String host = addressHolder.getAddress();
                    final InterfacesConfig interfaces = networkConfig.getInterfaces();
                    if (interfaces.isEnabled()) {
                        final InetAddress[] inetAddresses = InetAddress.getAllByName(host);
                        if (inetAddresses.length > 1) {
                            for (InetAddress inetAddress : inetAddresses) {
                                if (AddressUtil.matchAnyInterface(inetAddress.getHostAddress(),
                                        interfaces.getInterfaces())) {
                                    addPossibleAddresses(possibleAddresses, null, inetAddress, port, count);
                                }
                            }
                        } else {
                            final InetAddress inetAddress = inetAddresses[0];
                            if (AddressUtil.matchAnyInterface(inetAddress.getHostAddress(),
                                    interfaces.getInterfaces())) {
                                addPossibleAddresses(possibleAddresses, host, null, port, count);
                            }
                        }
                    } else {
                        addPossibleAddresses(possibleAddresses, host, null, port, count);
                    }
                }
            } catch (UnknownHostException e) {
                logger.warning("Cannot resolve hostname '" + addressHolder.getAddress()
                        + "'. Please make sure host is valid and reachable.");
                if (logger.isFinestEnabled()) {
                    logger.finest("Error during resolving possible target!", e);
                }
            }
        }

        possibleAddresses.remove(node.getThisAddress());
        return possibleAddresses;
    }

    private void addPossibleAddresses(final Set<Address> possibleAddresses,
                                      final String host, final InetAddress inetAddress,
                                      final int port, final int count) throws UnknownHostException {
        for (int i = 0; i < count; i++) {
            int currentPort = port + i;
            Address address = host != null ? new Address(host, currentPort) : new Address(inetAddress, currentPort);
            if (!isLocalAddress(address)) {
                possibleAddresses.add(address);
            }
        }
    }

    private boolean isLocalAddress(final Address address) throws UnknownHostException {
        final Address thisAddress = node.getThisAddress();
        final boolean local = thisAddress.getInetSocketAddress().equals(address.getInetSocketAddress());
        if (logger.isFinestEnabled()) {
            logger.finest(address + " is local? " + local);
        }
        return local;
    }

    protected Collection<String> getMembers() {
        return getConfigurationMembers(config);
    }

    public static Collection<String> getConfigurationMembers(Config config) {
        final TcpIpConfig tcpIpConfig = config.getNetworkConfig().getJoin().getTcpIpConfig();
        final Collection<String> configMembers = tcpIpConfig.getMembers();
        final Set<String> possibleMembers = new HashSet<String>();
        for (String member : configMembers) {
            
            String[] members = member.split("[,; ]");
            Collections.addAll(possibleMembers, members);
        }
        return possibleMembers;
    }

    @Override
    public void searchForOtherClusters() {
        final Collection<Address> colPossibleAddresses;
        try {
            colPossibleAddresses = getPossibleAddresses();
        } catch (Throwable e) {
            logger.severe(e);
            return;
        }
        colPossibleAddresses.remove(node.getThisAddress());
        for (Member member : node.getClusterService().getMembers()) {
            colPossibleAddresses.remove(((MemberImpl) member).getAddress());
        }
        if (colPossibleAddresses.isEmpty()) {
            return;
        }
        for (Address possibleAddress : colPossibleAddresses) {
            if (logger.isFinestEnabled()) {
                logger.finest(node.getThisAddress() + " is connecting to " + possibleAddress);
            }
            node.connectionManager.getOrConnect(possibleAddress, true);
            try {
                
                Thread.sleep(1500);
            } catch (InterruptedException e) {
                return;
            }
            final Connection conn = node.connectionManager.getConnection(possibleAddress);
            if (conn != null) {
                final JoinRequest response = node.clusterService.checkJoinInfo(possibleAddress);
                if (response != null && shouldMerge(response)) {
                    logger.warning(node.getThisAddress() + " is merging [tcp/ip] to " + possibleAddress);
                    setTargetAddress(possibleAddress);
                    startClusterMerge(possibleAddress);
                    return;
                }
            }
        }
    }

    @Override
    public String getType() {
        return "tcp-ip";
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.cluster.MemberAttributeOperationType;
import com.hazelcast.cluster.MemberInfo;
import com.hazelcast.cluster.impl.operations.AuthenticationFailureOperation;
import com.hazelcast.cluster.impl.operations.BeforeJoinCheckFailureOperation;
import com.hazelcast.cluster.impl.operations.ConfigMismatchOperation;
import com.hazelcast.cluster.impl.operations.FinalizeJoinOperation;
import com.hazelcast.cluster.impl.operations.GroupMismatchOperation;
import com.hazelcast.cluster.impl.operations.HeartbeatOperation;
import com.hazelcast.cluster.impl.operations.JoinCheckOperation;
import com.hazelcast.cluster.impl.operations.JoinRequestOperation;
import com.hazelcast.cluster.impl.operations.MasterConfirmationOperation;
import com.hazelcast.cluster.impl.operations.MasterDiscoveryOperation;
import com.hazelcast.cluster.impl.operations.MemberInfoUpdateOperation;
import com.hazelcast.cluster.impl.operations.MemberRemoveOperation;
import com.hazelcast.cluster.impl.operations.PostJoinOperation;
import com.hazelcast.cluster.impl.operations.SetMasterOperation;
import com.hazelcast.cluster.impl.operations.TriggerMemberListPublishOperation;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.InitialMembershipEvent;
import com.hazelcast.core.InitialMembershipListener;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberAttributeEvent;
import com.hazelcast.core.MembershipEvent;
import com.hazelcast.core.MembershipListener;
import com.hazelcast.instance.BuildInfo;
import com.hazelcast.instance.HazelcastInstanceImpl;
import com.hazelcast.instance.LifecycleServiceImpl;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.Packet;
import com.hazelcast.security.Credentials;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.MemberAttributeServiceEvent;
import com.hazelcast.spi.MembershipAwareService;
import com.hazelcast.spi.MembershipServiceEvent;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.SplitBrainHandlerService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.executor.ExecutorType;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import javax.security.auth.login.LoginContext;
import javax.security.auth.login.LoginException;
import java.net.ConnectException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.Date;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.LinkedHashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;

import static com.hazelcast.cluster.impl.operations.FinalizeJoinOperation.FINALIZE_JOIN_MAX_TIMEOUT;
import static com.hazelcast.cluster.impl.operations.FinalizeJoinOperation.FINALIZE_JOIN_TIMEOUT_FACTOR;
import static com.hazelcast.core.LifecycleEvent.LifecycleState.MERGED;
import static com.hazelcast.core.LifecycleEvent.LifecycleState.MERGING;
import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;
import static com.hazelcast.util.Preconditions.checkNotNull;
import static com.hazelcast.util.Preconditions.isNotNull;
import static java.util.Collections.unmodifiableMap;
import static java.util.Collections.unmodifiableSet;

public final class ClusterServiceImpl implements ClusterService, ConnectionListener, ManagedService,
        EventPublishingService<MembershipEvent, MembershipListener> {

    public static final String SERVICE_NAME = "hz:core:clusterService";

    private static final String EXECUTOR_NAME = "hz:cluster";
    private static final int HEARTBEAT_INTERVAL = 500;
    private static final long HEARTBEAT_LOG_THRESHOLD = 10000L;
    private static final int PING_INTERVAL = 5000;

    private final Node node;

    private final NodeEngineImpl nodeEngine;

    private final ILogger logger;

    protected final Address thisAddress;

    protected final MemberImpl thisMember;

    private final long waitMillisBeforeJoin;

    private final long maxWaitMillisBeforeJoin;

    private final long heartbeatInterval;

    private final long maxNoHeartbeatMillis;

    private final long maxNoMasterConfirmationMillis;

    private final boolean icmpEnabled;

    private final int icmpTtl;

    private final int icmpTimeout;

    private final Lock lock = new ReentrantLock();

    private final Set<MemberInfo> setJoins = new LinkedHashSet<MemberInfo>(100);

    private final AtomicReference<Map<Address, MemberImpl>> membersMapRef
            = new AtomicReference<Map<Address, MemberImpl>>(Collections.<Address, MemberImpl>emptyMap());

    private final AtomicReference<Set<MemberImpl>> membersRef = new AtomicReference<Set<MemberImpl>>(Collections.<MemberImpl>emptySet());

    private final AtomicBoolean preparingToMerge = new AtomicBoolean(false);

    private volatile boolean joinInProgress = false;

    @Probe(name = "lastHeartBeat")
    private volatile long lastHeartBeat = 0L;

    private long timeToStartJoin = 0;

    private long firstJoinRequest = 0;

    private final ConcurrentMap<MemberImpl, Long> masterConfirmationTimes = new ConcurrentHashMap<MemberImpl, Long>();

    private final ExceptionHandler whileFinalizeJoinsExceptionHandler;

    private final ClusterClockImpl clusterClock;

    private String clusterId = null;

    public ClusterServiceImpl(final Node node) {
        this.node = node;
        nodeEngine = node.nodeEngine;
        logger = node.getLogger(ClusterService.class.getName());
        clusterClock = new ClusterClockImpl(logger);
        whileFinalizeJoinsExceptionHandler =
                logAllExceptions(logger, "While waiting finalize join calls...", Level.WARNING);
        thisAddress = node.getThisAddress();
        thisMember = node.getLocalMember();
        setMembers(thisMember);
        waitMillisBeforeJoin = node.groupProperties.WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L;
        maxWaitMillisBeforeJoin = node.groupProperties.MAX_WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L;
        long heartbeatIntervalSeconds = node.groupProperties.HEARTBEAT_INTERVAL_SECONDS.getInteger();
        heartbeatIntervalSeconds = heartbeatIntervalSeconds <= 0 ? 1 : heartbeatIntervalSeconds;
        heartbeatInterval = heartbeatIntervalSeconds;
        maxNoHeartbeatMillis = node.groupProperties.MAX_NO_HEARTBEAT_SECONDS.getInteger() * 1000L;
        maxNoMasterConfirmationMillis = node.groupProperties.MAX_NO_MASTER_CONFIRMATION_SECONDS.getInteger() * 1000L;
        icmpEnabled = node.groupProperties.ICMP_ENABLED.getBoolean();
        icmpTtl = node.groupProperties.ICMP_TTL.getInteger();
        icmpTimeout = node.groupProperties.ICMP_TIMEOUT.getInteger();
        node.connectionManager.addConnectionListener(this);

        registerMetrics();
    }

    void registerMetrics() {
        MetricsRegistry metricsRegistry = node.nodeEngine.getMetricsRegistry();
        metricsRegistry.scanAndRegister(clusterClock, "cluster.clock");
        metricsRegistry.scanAndRegister(this, "cluster");
    }

    @Override
    public ClusterClockImpl getClusterClock() {
        return clusterClock;
    }

    @Override
    public String getClusterId() {
        return clusterId;
    }

    public void setClusterId(String clusterId) {
        if (this.clusterId == null) {
            this.clusterId = clusterId;
        }
    }

    @Override
    public void init(final NodeEngine nodeEngine, Properties properties) {
        long mergeFirstRunDelay = node.getGroupProperties().MERGE_FIRST_RUN_DELAY_SECONDS.getLong() * 1000;
        mergeFirstRunDelay = mergeFirstRunDelay <= 0 ? 100 : mergeFirstRunDelay; 

        ExecutionService executionService = nodeEngine.getExecutionService();
        executionService.register(EXECUTOR_NAME, 2, 1000, ExecutorType.CACHED);

        long mergeNextRunDelay = node.getGroupProperties().MERGE_NEXT_RUN_DELAY_SECONDS.getLong() * 1000;
        mergeNextRunDelay = mergeNextRunDelay <= 0 ? 100 : mergeNextRunDelay; 
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new SplitBrainHandler(node),
                mergeFirstRunDelay, mergeNextRunDelay, TimeUnit.MILLISECONDS);

        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                heartBeater();
            }
        }, heartbeatInterval, heartbeatInterval, TimeUnit.SECONDS);

        long masterConfirmationInterval = node.groupProperties.MASTER_CONFIRMATION_INTERVAL_SECONDS.getInteger();
        masterConfirmationInterval = masterConfirmationInterval <= 0 ? 1 : masterConfirmationInterval;
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                sendMasterConfirmation();
            }
        }, masterConfirmationInterval, masterConfirmationInterval, TimeUnit.SECONDS);

        long memberListPublishInterval = node.groupProperties.MEMBER_LIST_PUBLISH_INTERVAL_SECONDS.getInteger();
        memberListPublishInterval = memberListPublishInterval <= 0 ? 1 : memberListPublishInterval;
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                sendMemberListToOthers();
            }
        }, memberListPublishInterval, memberListPublishInterval, TimeUnit.SECONDS);
    }

    public boolean isJoinInProgress() {
        if (joinInProgress) {
            return true;
        }

        lock.lock();
        try {
            return joinInProgress || !setJoins.isEmpty();
        } finally {
            lock.unlock();
        }
    }

    public JoinRequest checkJoinInfo(Address target) {
        Future f = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME,
                new JoinCheckOperation(node.createJoinRequest()), target)
                .setTryCount(1).invoke();
        try {
            return (JoinRequest) nodeEngine.toObject(f.get());
        } catch (Exception e) {
            logger.warning("Error during join check!", e);
        }
        return null;
    }

    public boolean validateJoinMessage(JoinMessage joinMessage) throws Exception {
        boolean valid = Packet.VERSION == joinMessage.getPacketVersion();
        if (valid) {
            try {
                ConfigCheck newMemberConfigCheck = joinMessage.getConfigCheck();
                ConfigCheck clusterConfigCheck = node.createConfigCheck();
                valid = clusterConfigCheck.isCompatible(newMemberConfigCheck);
            } catch (Exception e) {
                final String message = "Invalid join request from: " + joinMessage.getAddress() + ", reason:" + e.getMessage();
                logger.warning(message);
                throw e;
            }
        }
        return valid;
    }

    private boolean isValidJoinMessage(JoinMessage joinMessage) {
        boolean validJoinRequest;
        try {
            validJoinRequest = validateJoinMessage(joinMessage);
        } catch (ConfigMismatchException e) {
            throw e;
        } catch (Exception e) {
            validJoinRequest = false;
        }
        return validJoinRequest;
    }

    private void logIfConnectionToEndpointIsMissing(long now, MemberImpl member) {
        if ((now - member.getLastRead()) >= PING_INTERVAL && (now - member.getLastPing()) >= PING_INTERVAL) {
            Connection conn = node.connectionManager.getOrConnect(member.getAddress());
            if (conn == null || !conn.isAlive()) {
                logger.warning("This node does not have a connection to " + member);
            }
        }
    }

    private void heartBeater() {
        if (!node.joined() || !node.isActive()) {
            return;
        }

        long now = Clock.currentTimeMillis();

        
        long clockJump = 0L;
        if (lastHeartBeat != 0L) {
            clockJump = now - lastHeartBeat - TimeUnit.SECONDS.toMillis(heartbeatInterval);
            if (Math.abs(clockJump) > HEARTBEAT_LOG_THRESHOLD) {
                SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS");
                logger.info("System clock apparently jumped from " + sdf.format(new Date(lastHeartBeat)) + " to " +
                        sdf.format(new Date(now)) + " since last heartbeat (" + String.format("%+d", clockJump) + "ms).");
            }
            clockJump = Math.max(0L, clockJump);

            if (clockJump >= maxNoMasterConfirmationMillis / 2) {
                logger.warning(
                        "Resetting master confirmation timestamps because of huge system clock jump! " + "Clock-Jump: "
                                + clockJump + "ms, Master-Confirmation-Timeout: " + maxNoMasterConfirmationMillis
                                + "ms.");
                resetMemberMasterConfirmations();
            }
        }
        lastHeartBeat = now;

        if (node.isMaster()) {
            heartBeaterMaster(now, clockJump);
        } else {
            heartBeaterSlave(now, clockJump);
        }
    }

    private void heartBeaterMaster(long now, long clockJump) {
        Collection<MemberImpl> members = getMemberList();
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    logIfConnectionToEndpointIsMissing(now, member);
                    if (removeMemberIfNotHeartBeating(now - clockJump, member)) {
                        continue;
                    }

                    if (removeMemberIfMasterConfirmationExpired(now - clockJump, member)) {
                        continue;
                    }

                    pingMemberIfRequired(now, member);
                    sendHearBeatIfRequired(now, member);
                } catch (Throwable e) {
                    logger.severe(e);
                }
            }
        }
    }

    private boolean removeMemberIfNotHeartBeating(long now, MemberImpl member) {
        if ((now - member.getLastRead()) > maxNoHeartbeatMillis) {
            logger.warning("Removing " + member + " because it has not sent any heartbeats for " +
                    maxNoHeartbeatMillis + " ms.");
            removeAddress(member.getAddress());
            return true;
        }
        return false;
    }

    private boolean removeMemberIfMasterConfirmationExpired(long now, MemberImpl member) {
        Long lastConfirmation = masterConfirmationTimes.get(member);
        if (lastConfirmation == null ||
                (now - lastConfirmation > maxNoMasterConfirmationMillis)) {
            logger.warning("Removing " + member + " because it has not sent any master confirmation " +
                    " for " + maxNoMasterConfirmationMillis + " ms.");
            removeAddress(member.getAddress());
            return true;
        }
        return false;
    }

    private void heartBeaterSlave(long now, long clockJump) {
        Collection<MemberImpl> members = getMemberList();

        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    logIfConnectionToEndpointIsMissing(now, member);

                    if (isMaster(member)) {
                        if (removeMemberIfNotHeartBeating(now - clockJump, member)) {
                            continue;
                        }
                    }

                    pingMemberIfRequired(now, member);
                    sendHearBeatIfRequired(now, member);
                } catch (Throwable e) {
                    logger.severe(e);
                }
            }
        }
    }

    private boolean isMaster(MemberImpl member) {
        return member.getAddress().equals(getMasterAddress());
    }

    private void sendHearBeatIfRequired(long now, MemberImpl member) {
        if ((now - member.getLastWrite()) > HEARTBEAT_INTERVAL) {
            sendHeartbeat(member.getAddress());
        }
    }

    private void pingMemberIfRequired(long now, MemberImpl member) {
        if ((now - member.getLastRead()) >= PING_INTERVAL && (now - member.getLastPing()) >= PING_INTERVAL) {
            ping(member);
        }
    }

    private void ping(final MemberImpl memberImpl) {
        memberImpl.didPing();
        if (!icmpEnabled) {
            return;
        }
        nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
            public void run() {
                try {
                    final Address address = memberImpl.getAddress();
                    logger.warning(thisAddress + " will ping " + address);
                    for (int i = 0; i < 5; i++) {
                        try {
                            if (address.getInetAddress().isReachable(null, icmpTtl, icmpTimeout)) {
                                logger.info(thisAddress + " pings successfully. Target: " + address);
                                return;
                            }
                        } catch (ConnectException ignored) {
                            
                            
                        }
                    }
                    logger.warning(thisAddress + " couldn't ping " + address);
                    
                    removeAddress(address);
                } catch (Throwable ignored) {
                }
            }
        });
    }

    private void sendHeartbeat(Address target) {
        if (target == null) return;
        try {
            node.nodeEngine.getOperationService().send(new HeartbeatOperation(), target);
        } catch (Exception e) {
            if (logger.isFinestEnabled()) {
                logger.finest("Error while sending heartbeat -> "
                        + e.getClass().getName() + "[" + e.getMessage() + "]");
            }
        }
    }

    private void sendMasterConfirmation() {
        if (!node.joined() || !node.isActive() || isMaster()) {
            return;
        }
        final Address masterAddress = getMasterAddress();
        if (masterAddress == null) {
            logger.finest("Could not send MasterConfirmation, master is null!");
            return;
        }
        final MemberImpl masterMember = getMember(masterAddress);
        if (masterMember == null) {
            logger.finest("Could not send MasterConfirmation, master is null!");
            return;
        }
        if (logger.isFinestEnabled()) {
            logger.finest("Sending MasterConfirmation to " + masterMember);
        }
        nodeEngine.getOperationService().send(new MasterConfirmationOperation(), masterAddress);
    }

    
    private void resetMemberMasterConfirmations() {
        final Collection<MemberImpl> memberList = getMemberList();
        for (MemberImpl member : memberList) {
            masterConfirmationTimes.put(member, Clock.currentTimeMillis());
        }
    }


    public void sendMemberListToMember(Address target) {
        if (!isMaster()) {
            return;
        }
        if (thisAddress.equals(target)) {
            return;
        }
        final Collection<MemberImpl> members = getMemberList();
        MemberInfoUpdateOperation op = new MemberInfoUpdateOperation(
                createMemberInfoList(members), clusterClock.getClusterTime(), false);
        nodeEngine.getOperationService().send(op, target);
    }

    private void sendMemberListToOthers() {
        if (!isMaster()) {
            return;
        }
        final Collection<MemberImpl> members = getMemberList();
        MemberInfoUpdateOperation op = new MemberInfoUpdateOperation(
                createMemberInfoList(members), clusterClock.getClusterTime(), false);
        for (MemberImpl member : members) {
            if (member.equals(thisMember)) {
                continue;
            }
            nodeEngine.getOperationService().send(op, member.getAddress());
        }
    }

    public void removeAddress(Address deadAddress) {
        doRemoveAddress(deadAddress, true);
    }

    private void doRemoveAddress(Address deadAddress, boolean destroyConnection) {
        if (preparingToMerge.get()) {
            logger.warning("Cluster-merge process is ongoing, won't process member removal: " + deadAddress);
            return;
        }
        if (!node.joined()) {
            return;
        }
        if (deadAddress.equals(thisAddress)) {
            return;
        }
        lock.lock();
        try {
            if (deadAddress.equals(node.getMasterAddress())) {
                assignNewMaster();
            }
            if (node.isMaster()) {
                setJoins.remove(new MemberInfo(deadAddress));
                resetMemberMasterConfirmations();
            }
            final Connection conn = node.connectionManager.getConnection(deadAddress);
            if (destroyConnection && conn != null) {
                node.connectionManager.destroyConnection(conn);
            }
            MemberImpl deadMember = getMember(deadAddress);
            if (deadMember != null) {
                removeMember(deadMember);
                logger.info(membersString());
            }
        } finally {
            lock.unlock();
        }
    }

    private void assignNewMaster() {
        final Address oldMasterAddress = node.getMasterAddress();
        if (node.joined()) {
            final Collection<MemberImpl> members = getMemberList();
            MemberImpl newMaster = null;
            final int size = members.size();
            if (size > 1) {
                final Iterator<MemberImpl> iter = members.iterator();
                final MemberImpl member = iter.next();
                if (member.getAddress().equals(oldMasterAddress)) {
                    newMaster = iter.next();
                } else {
                    logger.severe("Old master " + oldMasterAddress
                            + " is dead but the first of member list is a different member " +
                            member + "!");
                    newMaster = member;
                }
            } else {
                logger.warning("Old master is dead and this node is not master " +
                        "but member list contains only " + size + " members! -> " + members);
            }
            logger.info("Master " + oldMasterAddress + " left the cluster. Assigning new master " + newMaster);
            if (newMaster != null) {
                node.setMasterAddress(newMaster.getAddress());
            } else {
                node.setMasterAddress(null);
            }
        } else {
            node.setMasterAddress(null);
        }
        if (logger.isFinestEnabled()) {
            logger.finest("Now Master " + node.getMasterAddress());
        }
    }

    public void answerMasterQuestion(JoinMessage joinMessage) {
        if (!ensureValidConfiguration(joinMessage)) {
            return;
        }

        if (node.getMasterAddress() != null) {
            sendMasterAnswer(joinMessage.getAddress());
        } else {
            if (logger.isFinestEnabled()) {
                logger.finest("Received a master question from " + joinMessage.getAddress()
                        + ", but this node is not master itself or doesn't have a master yet!");
            }
        }
    }

    public void handleJoinRequest(JoinRequest joinRequest, Connection connection) {
        if (!node.joined() || !node.isActive()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Node is not ready to process join request...");
            }
            return;
        }

        if (!ensureValidConfiguration(joinRequest)) {
            return;
        }

        Address target = joinRequest.getAddress();
        boolean isRequestFromCurrentMaster = target.equals(node.getMasterAddress());
        
        
        if (!node.isMaster() && !isRequestFromCurrentMaster) {
            sendMasterAnswer(target);
            return;
        }

        if (joinInProgress) {
            if (logger.isFinestEnabled()) {
                logger.finest("Join is in-progress. Cannot handle join request from "
                        + target + " at the moment.");
            }
            return;
        }

        lock.lock();
        try {
            if (isJoinRequestFromAnExistingMember(joinRequest, connection)) {
                return;
            }

            long now = Clock.currentTimeMillis();
            if (logger.isFinestEnabled()) {
                String msg = "Handling join from " + target + ", inProgress: " + joinInProgress
                        + (timeToStartJoin > 0 ? ", timeToStart: " + (timeToStartJoin - now) : "");
                logger.finest(msg);
            }

            MemberInfo memberInfo = new MemberInfo(target, joinRequest.getUuid(),
                    joinRequest.getAttributes());

            if (!setJoins.contains(memberInfo)) {
                try {
                    checkSecureLogin(joinRequest, memberInfo);
                } catch (Exception e) {
                    ILogger securityLogger = node.loggingService.getLogger("com.hazelcast.security");
                    sendAuthenticationFailure(target);
                    securityLogger.severe(e);
                    return;
                }
            }

            if (node.isMaster()) {
                try {
                    node.getNodeExtension().beforeJoin();
                } catch (Exception e) {
                    logger.warning(e.getMessage());
                    sendBeforeJoinCheckFailure(target, e.getMessage());
                    return;
                }
            }

            if (firstJoinRequest == 0) {
                firstJoinRequest = now;
            }

            if (setJoins.add(memberInfo)) {
                sendMasterAnswer(target);
                if (now - firstJoinRequest < maxWaitMillisBeforeJoin) {
                    timeToStartJoin = now + waitMillisBeforeJoin;
                }
            }
            if (now > timeToStartJoin) {
                startJoin();
            }
        } finally {
            lock.unlock();
        }
    }

    private boolean ensureValidConfiguration(JoinMessage joinMessage) {
        try {
            if (isValidJoinMessage(joinMessage)) {
                return true;
            }

            logger.warning("Received an invalid join request from " + joinMessage.getAddress()
                    + ", cause: clusters part of different cluster-groups");

            nodeEngine.getOperationService().send(new GroupMismatchOperation(), joinMessage.getAddress());
        } catch (ConfigMismatchException e) {
            logger.warning("Received an invalid join request from " + joinMessage.getAddress()
                    + ", cause:" + e.getMessage());
            sendConfigurationMismatchFailure(joinMessage.getAddress(), e.getMessage());
        }
        return false;
    }

    private void sendAuthenticationFailure(Address target) {
        nodeEngine.getOperationService().send(new AuthenticationFailureOperation(), target);
    }

    private void sendBeforeJoinCheckFailure(Address target, String message) {
        nodeEngine.getOperationService().send(new BeforeJoinCheckFailureOperation(message), target);
    }

    private void sendConfigurationMismatchFailure(Address target, String msg) {
        OperationService operationService = nodeEngine.getOperationService();
        operationService.send(new ConfigMismatchOperation(msg), target);
    }

    private void checkSecureLogin(JoinRequest joinRequest, MemberInfo newMemberInfo) {
        if (node.securityContext != null && !setJoins.contains(newMemberInfo)) {
            Credentials cr = joinRequest.getCredentials();
            if (cr == null) {
                throw new SecurityException("Expecting security credentials " +
                        "but credentials could not be found in JoinRequest!");
            }

            try {
                LoginContext lc = node.securityContext.createMemberLoginContext(cr);
                lc.login();
            } catch (LoginException e) {
                throw new SecurityException(
                        "Authentication has failed for " + cr.getPrincipal() + '@' + cr.getEndpoint()
                                + " => (" + e.getMessage() + ")");
            }
        }
    }

    private boolean isJoinRequestFromAnExistingMember(JoinRequest joinRequest, Connection connection) {
        MemberImpl member = getMember(joinRequest.getAddress());
        if (member == null) {
            return false;
        }

        Address target = member.getAddress();
        if (joinRequest.getUuid().equals(member.getUuid())) {
            if (node.isMaster()) {
                if (logger.isFinestEnabled()) {
                    String message = "Ignoring join request, member already exists.. => " + joinRequest;
                    logger.finest(message);
                }
                
                final Operation[] postJoinOps = nodeEngine.getPostJoinOperations();
                final PostJoinOperation postJoinOp = postJoinOps != null && postJoinOps.length > 0
                        ? new PostJoinOperation(postJoinOps) : null;

                Operation op = new FinalizeJoinOperation(createMemberInfoList(getMemberList()), postJoinOp,
                        clusterClock.getClusterTime(), false);
                nodeEngine.getOperationService().send(op, target);
            } else {
                sendMasterAnswer(target);
            }
            return true;
        }

        
        
        
        
        if (node.isMaster() || target.equals(node.getMasterAddress())) {
            logger.warning("New join request has been received from an existing endpoint! => " + member
                    + " Removing old member and processing join request...");

            doRemoveAddress(target, false);
            Connection existing = node.connectionManager.getConnection(target);
            if (existing != connection) {
                node.connectionManager.destroyConnection(existing);
                node.connectionManager.registerConnection(target, connection);
            }
            return false;
        }
        return true;
    }

    private void sendMasterAnswer(Address target) {
        Address masterAddress = node.getMasterAddress();
        if (masterAddress == null) {
            logger.info("Cannot send master answer to " + target + " since master node is not known yet");
            return;
        }
        SetMasterOperation op = new SetMasterOperation(masterAddress);
        nodeEngine.getOperationService().send(op, target);
    }

    public void handleMaster(Address masterAddress, Address callerAddress) {
        if (node.joined()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Ignoring master response: " + masterAddress + " from: " + callerAddress
                        + ". This node is already joined...");
            }
            return;
        }

        if (node.getThisAddress().equals(masterAddress)) {
            if (node.isMaster()) {
                logger.finest("Ignoring master response: " + masterAddress + " from: " + callerAddress
                        + ". This node is already master...");
            } else {
                node.setAsMaster();
            }
            return;
        }

        lock.lock();
        try {
            if (logger.isFinestEnabled()) {
                logger.finest("Handling master response: " + masterAddress + " from: " + callerAddress);
            }
            final Address currentMaster = node.getMasterAddress();
            if (currentMaster == null || currentMaster.equals(masterAddress)) {
                setMasterAndJoin(masterAddress);
            } else if (currentMaster.equals(callerAddress)) {
                logger.info("Setting master to: " + masterAddress + ", since "
                        + currentMaster + " says it's not master anymore.");
                setMasterAndJoin(masterAddress);
            } else {
                final Connection conn = node.connectionManager.getConnection(currentMaster);
                if (conn != null && conn.isAlive()) {
                    logger.info("Ignoring master response: " + masterAddress + " from: " + callerAddress
                            + ", since this node has an active master: " + currentMaster);
                    sendJoinRequest(currentMaster, true);
                } else {
                    logger.warning("Ambiguous master response, this node has a master: " + currentMaster
                            + ", but doesn't have a connection to. " + callerAddress + " sent master response as: "
                            + masterAddress + ". Master field will be unset now...");
                    node.setMasterAddress(null);
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void setMasterAndJoin(Address masterAddress) {
        node.setMasterAddress(masterAddress);
        node.connectionManager.getOrConnect(masterAddress);
        if (!sendJoinRequest(masterAddress, true)) {
            logger.warning("Could not create connection to possible master " + masterAddress);
        }
    }

    public void acceptMasterConfirmation(MemberImpl member) {
        if (member != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("MasterConfirmation has been received from " + member);
            }
            masterConfirmationTimes.put(member, Clock.currentTimeMillis());
        }
    }

    public void prepareToMerge(final Address newTargetAddress) {
        preparingToMerge.set(true);
        node.getJoiner().setTargetAddress(newTargetAddress);
        nodeEngine.getExecutionService().schedule(new Runnable() {
            public void run() {
                merge(newTargetAddress);
            }
        }, 10, TimeUnit.SECONDS);
    }

    public void merge(Address newTargetAddress) {
        if (preparingToMerge.compareAndSet(true, false)) {
            node.getJoiner().setTargetAddress(newTargetAddress);
            LifecycleServiceImpl lifecycleService = node.hazelcastInstance.getLifecycleService();
            lifecycleService.runUnderLifecycleLock(new MergeTask());
        }
    }

    private <V> V waitOnFutureInterruptible(Future<V> future, long timeout, TimeUnit timeUnit)
            throws ExecutionException, InterruptedException, TimeoutException {

        isNotNull(timeUnit, "timeUnit");
        long deadline = Clock.currentTimeMillis() + timeUnit.toMillis(timeout);
        while (true) {
            long localTimeout = Math.min(1000 * 10, deadline);
            try {
                return future.get(localTimeout, TimeUnit.MILLISECONDS);
            } catch (TimeoutException te) {
                deadline -= localTimeout;
                if (deadline <= 0) {
                    throw te;
                }
                if (!node.isActive()) {
                    future.cancel(true);
                    throw new HazelcastInstanceNotActiveException();
                }
            }
        }
    }

    private void joinReset() {
        lock.lock();
        try {
            joinInProgress = false;
            setJoins.clear();
            timeToStartJoin = Clock.currentTimeMillis() + waitMillisBeforeJoin;
            firstJoinRequest = 0;
        } finally {
            lock.unlock();
        }
    }

    @Override
    public void reset() {
        lock.lock();
        try {
            joinInProgress = false;
            setJoins.clear();
            timeToStartJoin = 0;
            setMembersRef(Collections.singletonMap(thisAddress, thisMember));
            masterConfirmationTimes.clear();
        } finally {
            lock.unlock();
        }
    }

    private void startJoin() {
        logger.finest("Starting Join.");
        lock.lock();
        try {
            try {
                joinInProgress = true;
                
                node.getPartitionService().pauseMigration();
                final Collection<MemberImpl> members = getMemberList();
                final Collection<MemberInfo> memberInfos = createMemberInfoList(members);
                for (MemberInfo memberJoining : setJoins) {
                    memberInfos.add(memberJoining);
                }
                final long time = clusterClock.getClusterTime();
                
                
                final Operation[] postJoinOps = nodeEngine.getPostJoinOperations();
                final PostJoinOperation postJoinOp = postJoinOps != null && postJoinOps.length > 0
                        ? new PostJoinOperation(postJoinOps) : null;
                final int count = members.size() - 1 + setJoins.size();
                final List<Future> calls = new ArrayList<Future>(count);
                for (MemberInfo member : setJoins) {
                    final long startTime = clusterClock.getClusterStartTime();
                    calls.add(invokeClusterOperation(new FinalizeJoinOperation(memberInfos, postJoinOp, time,
                            clusterId, startTime), member.getAddress()));
                }
                for (MemberImpl member : members) {
                    if (!member.getAddress().equals(thisAddress)) {
                        calls.add(invokeClusterOperation(new MemberInfoUpdateOperation(memberInfos, time, true), member.getAddress()));
                    }
                }
                updateMembers(memberInfos);
                int timeout = Math.min(calls.size() * FINALIZE_JOIN_TIMEOUT_FACTOR, FINALIZE_JOIN_MAX_TIMEOUT);
                waitWithDeadline(calls, timeout, TimeUnit.SECONDS, whileFinalizeJoinsExceptionHandler);
            } finally {
                node.getPartitionService().resumeMigration();
            }
        } finally {
            lock.unlock();
        }
    }

    private static List<MemberInfo> createMemberInfoList(Collection<MemberImpl> members) {
        final List<MemberInfo> memberInfos = new LinkedList<MemberInfo>();
        for (MemberImpl member : members) {
            memberInfos.add(new MemberInfo(member));
        }
        return memberInfos;
    }

    private static Set<MemberInfo> createMemberInfoSet(Collection<MemberImpl> members) {
        final Set<MemberInfo> memberInfos = new HashSet<MemberInfo>();
        for (MemberImpl member : members) {
            memberInfos.add(new MemberInfo(member));
        }
        return memberInfos;
    }

    public void updateMembers(Collection<MemberInfo> members) {
        lock.lock();
        try {
            Map<Address, MemberImpl> currentMemberMap = membersMapRef.get();

            if (!shouldProcessMemberUpdate(currentMemberMap, members)) {
                return;
            }

            MemberImpl[] newMembers = new MemberImpl[members.size()];
            int k = 0;
            for (MemberInfo memberInfo : members) {
                MemberImpl member = currentMemberMap.get(memberInfo.getAddress());
                if (member == null) {
                    member = createMember(memberInfo.getAddress(), memberInfo.getUuid(),
                            thisAddress.getScopeId(), memberInfo.getAttributes());
                }
                newMembers[k++] = member;
                member.didRead();
            }
            setMembers(newMembers);
            if (!getMemberList().contains(thisMember)) {
                throw new HazelcastException("Member list doesn't contain local member!");
            }
            joinReset();
            heartBeater();
            node.setJoined();
            logger.info(membersString());
        } finally {
            lock.unlock();
        }
    }

    private boolean shouldProcessMemberUpdate(Map<Address, MemberImpl> currentMembers,
                                              Collection<MemberInfo> newMemberInfos) {

        int currentMembersSize = currentMembers.size();
        int newMembersSize = newMemberInfos.size();

        if (currentMembersSize > newMembersSize) {
            logger.warning("Received an older member update, no need to process...");
            nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            return false;
        }

        
        if (currentMembersSize == newMembersSize) {
            Set<MemberInfo> currentMemberInfos = createMemberInfoSet(currentMembers.values());
            if (currentMemberInfos.containsAll(newMemberInfos)) {
                logger.finest("Received a periodic member update, no need to process...");
            } else {
                logger.warning("Received an inconsistent member update "
                        + "which contains new members and removes some of the current members! "
                        + "Ignoring and requesting a new member update...");
                nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            }
            return false;
        }

        Set<MemberInfo> currentMemberInfos = createMemberInfoSet(currentMembers.values());
        currentMemberInfos.removeAll(newMemberInfos);
        if (currentMemberInfos.isEmpty()) {
            return true;
        } else {
            logger.warning("Received an inconsistent member update, it has more members but "
                    + "but also removes some of the current members! "
                    + "Ignoring and requesting a new member update...");
            nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            return false;
        }
    }

    public void updateMemberAttribute(String uuid, MemberAttributeOperationType operationType, String key, Object value) {
        lock.lock();
        try {
            Map<Address, MemberImpl> memberMap = membersMapRef.get();
            for (MemberImpl member : memberMap.values()) {
                if (member.getUuid().equals(uuid)) {
                    if (!member.equals(getLocalMember())) {
                        member.updateAttribute(operationType, key, value);
                    }
                    sendMemberAttributeEvent(member, operationType, key, value);
                    break;
                }
            }
        } finally {
            lock.unlock();
        }
    }

    public boolean sendJoinRequest(Address toAddress, boolean withCredentials) {
        if (toAddress == null) {
            toAddress = node.getMasterAddress();
        }
        JoinRequestOperation joinRequest = new JoinRequestOperation(node.createJoinRequest(withCredentials));
        return nodeEngine.getOperationService().send(joinRequest, toAddress);
    }

    public boolean sendMasterQuestion(Address toAddress) {
        checkNotNull(toAddress, "No endpoint is specified!");

        BuildInfo buildInfo = node.getBuildInfo();
        JoinMessage joinMessage = new JoinMessage(Packet.VERSION, buildInfo.getBuildNumber(), thisAddress,
                thisMember.getUuid(), node.createConfigCheck(), getSize());
        return nodeEngine.getOperationService().send(new MasterDiscoveryOperation(joinMessage), toAddress);
    }

    @Override
    public void connectionAdded(final Connection connection) {
        MemberImpl member = getMember(connection.getEndPoint());
        if (member != null) {
            member.didRead();
        }
    }

    @Override
    public void connectionRemoved(Connection connection) {
        if (logger.isFinestEnabled()) {
            logger.finest("Connection is removed " + connection.getEndPoint());
        }
        if (!node.joined()) {
            final Address masterAddress = node.getMasterAddress();
            if (masterAddress != null && masterAddress.equals(connection.getEndPoint())) {
                node.setMasterAddress(null);
            }
        }
    }

    private Future invokeClusterOperation(Operation op, Address target) {
        return nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, op, target)
                .setTryCount(100).invoke();
    }

    public NodeEngineImpl getNodeEngine() {
        return nodeEngine;
    }

    private void setMembers(MemberImpl... members) {
        if (members == null || members.length == 0) return;
        if (logger.isFinestEnabled()) {
            logger.finest("Updating members -> " + Arrays.toString(members));
        }
        lock.lock();
        try {
            Map<Address, MemberImpl> oldMemberMap = membersMapRef.get();
            final Map<Address, MemberImpl> memberMap = new LinkedHashMap<Address, MemberImpl>();  
            final Collection<MemberImpl> newMembers = new LinkedList<MemberImpl>();
            for (MemberImpl member : members) {
                MemberImpl currentMember = oldMemberMap.get(member.getAddress());
                if (currentMember == null) {
                    newMembers.add(member);
                    masterConfirmationTimes.put(member, Clock.currentTimeMillis());
                }
                memberMap.put(member.getAddress(), member);
            }
            setMembersRef(memberMap);

            if (!newMembers.isEmpty()) {
                Set<Member> eventMembers = new LinkedHashSet<Member>(oldMemberMap.values());
                if (newMembers.size() == 1) {
                    MemberImpl newMember = newMembers.iterator().next();
                    node.getPartitionService().memberAdded(newMember); 
                    eventMembers.add(newMember);
                    sendMembershipEventNotifications(newMember, unmodifiableSet(eventMembers), true); 
                } else {
                    for (MemberImpl newMember : newMembers) {
                        node.getPartitionService().memberAdded(newMember); 
                        eventMembers.add(newMember);
                        sendMembershipEventNotifications(newMember, unmodifiableSet(new LinkedHashSet<Member>(eventMembers)), true); 
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void removeMember(MemberImpl deadMember) {
        logger.info("Removing " + deadMember);
        lock.lock();
        try {
            final Map<Address, MemberImpl> members = membersMapRef.get();
            if (members.containsKey(deadMember.getAddress())) {
                Map<Address, MemberImpl> newMembers = new LinkedHashMap<Address, MemberImpl>(members);  
                newMembers.remove(deadMember.getAddress());
                masterConfirmationTimes.remove(deadMember);
                setMembersRef(newMembers);
                node.getPartitionService().memberRemoved(deadMember); 
                nodeEngine.onMemberLeft(deadMember);                  
                if (node.isMaster()) {
                    if (logger.isFinestEnabled()) {
                        logger.finest(deadMember + " is dead. Sending remove to all other members.");
                    }
                    invokeMemberRemoveOperation(deadMember.getAddress());
                }
                
                sendMembershipEventNotifications(deadMember, unmodifiableSet(new LinkedHashSet<Member>(newMembers.values())), false);
            }
        } finally {
            lock.unlock();
        }
    }

    private void invokeMemberRemoveOperation(final Address deadAddress) {
        for (MemberImpl member : getMemberList()) {
            Address address = member.getAddress();
            if (!thisAddress.equals(address) && !address.equals(deadAddress)) {
                nodeEngine.getOperationService().send(new MemberRemoveOperation(deadAddress), address);
            }
        }
    }

    public void sendShutdownMessage() {
        invokeMemberRemoveOperation(thisAddress);
    }

    private void sendMembershipEventNotifications(final MemberImpl member, Set<Member> members, final boolean added) {
        final int eventType = added ? MembershipEvent.MEMBER_ADDED : MembershipEvent.MEMBER_REMOVED;
        final MembershipEvent membershipEvent = new MembershipEvent(getClusterProxy(), member, eventType, members);
        final Collection<MembershipAwareService> membershipAwareServices = nodeEngine.getServices(MembershipAwareService.class);
        if (membershipAwareServices != null && !membershipAwareServices.isEmpty()) {
            final MembershipServiceEvent event = new MembershipServiceEvent(membershipEvent);
            for (final MembershipAwareService service : membershipAwareServices) {
                
                nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                    public void run() {
                        if (added) {
                            service.memberAdded(event);
                        } else {
                            service.memberRemoved(event);
                        }
                    }
                });
            }
        }
        final EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        for (EventRegistration reg : registrations) {
            eventService.publishEvent(SERVICE_NAME, reg, membershipEvent, reg.getId().hashCode());
        }
    }

    private void sendMemberAttributeEvent(MemberImpl member, MemberAttributeOperationType operationType, String key, Object value) {
        final MemberAttributeEvent memberAttributeEvent = new MemberAttributeEvent(getClusterProxy(), member, operationType, key, value);
        final Collection<MembershipAwareService> membershipAwareServices = nodeEngine.getServices(MembershipAwareService.class);
        final MemberAttributeServiceEvent event = new MemberAttributeServiceEvent(getClusterProxy(), member, operationType, key, value);
        if (membershipAwareServices != null && !membershipAwareServices.isEmpty()) {
            for (final MembershipAwareService service : membershipAwareServices) {
                
                nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                    public void run() {
                        service.memberAttributeChanged(event);
                    }
                });
            }
        }
        final EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        for (EventRegistration reg : registrations) {
            eventService.publishEvent(SERVICE_NAME, reg, memberAttributeEvent, reg.getId().hashCode());
        }
    }

    protected MemberImpl createMember(Address address, String nodeUuid, String ipV6ScopeId, Map<String, Object> attributes) {
        address.setScopeId(ipV6ScopeId);
        return new MemberImpl(address, thisAddress.equals(address), nodeUuid,
                (HazelcastInstanceImpl) nodeEngine.getHazelcastInstance(), attributes);
    }

    @Override
    public MemberImpl getMember(Address address) {
        if (address == null) {
            return null;
        }
        Map<Address, MemberImpl> memberMap = membersMapRef.get();
        return memberMap.get(address);
    }

    @Override
    public MemberImpl getMember(String uuid) {
        if (uuid == null) {
            return null;
        }

        Map<Address, MemberImpl> memberMap = membersMapRef.get();
        for (MemberImpl member : memberMap.values()) {
            if (uuid.equals(member.getUuid())) {
                return member;
            }
        }
        return null;
    }

    private void setMembersRef(Map<Address, MemberImpl> memberMap) {
        memberMap = unmodifiableMap(memberMap);
        
        memberMap.values();
        memberMap.keySet();
        memberMap.entrySet();
        membersMapRef.set(memberMap);
        membersRef.set(unmodifiableSet(new LinkedHashSet<MemberImpl>(memberMap.values())));
    }

    @Override
    public Collection<MemberImpl> getMemberList() {
        return membersRef.get();
    }

    @Override
    public Set<Member> getMembers() {
        return (Set) membersRef.get();
    }

    @Override
    public void shutdown(boolean terminate) {
        reset();
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public boolean isMaster() {
        return node.isMaster();
    }

    @Override
    public Address getThisAddress() {
        return thisAddress;
    }

    public Member getLocalMember() {
        return node.getLocalMember();
    }

    @Probe(name = "size")
    @Override
    public int getSize() {
        final Collection<MemberImpl> members = getMemberList();
        return members != null ? members.size() : 0;
    }

    public String addMembershipListener(MembershipListener listener) {
        checkNotNull(listener, "listener can't be null");

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration;
        if (listener instanceof InitialMembershipListener) {
            lock.lock();
            try {
                ((InitialMembershipListener) listener).init(new InitialMembershipEvent(getClusterProxy(), getMembers()));
                registration = eventService.registerLocalListener(SERVICE_NAME, SERVICE_NAME, listener);
            } finally {
                lock.unlock();
            }
        } else {
            registration = eventService.registerLocalListener(SERVICE_NAME, SERVICE_NAME, listener);
        }

        return registration.getId();
    }

    public boolean removeMembershipListener(String registrationId) {
        checkNotNull(registrationId, "registrationId can't be null");

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, SERVICE_NAME, registrationId);
    }

    @SuppressFBWarnings("BC_UNCONFIRMED_CAST")
    @Override
    public void dispatchEvent(MembershipEvent event, MembershipListener listener) {
        switch (event.getEventType()) {
            case MembershipEvent.MEMBER_ADDED:
                listener.memberAdded(event);
                break;
            case MembershipEvent.MEMBER_REMOVED:
                listener.memberRemoved(event);
                break;
            case MembershipEvent.MEMBER_ATTRIBUTE_CHANGED:
                MemberAttributeEvent memberAttributeEvent = (MemberAttributeEvent) event;
                listener.memberAttributeChanged(memberAttributeEvent);
                break;
            default:
                throw new IllegalArgumentException("Unhandled event:" + event);
        }
    }

    public Cluster getClusterProxy() {
        return new ClusterProxy(this);
    }

    public String membersString() {
        StringBuilder sb = new StringBuilder("\n\nMembers [");
        final Collection<MemberImpl> members = getMemberList();
        sb.append(members != null ? members.size() : 0);
        sb.append("] {");
        if (members != null) {
            for (Member member : members) {
                sb.append("\n\t").append(member);
            }
        }
        sb.append("\n}\n");
        return sb.toString();
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("ClusterService");
        sb.append("{address=").append(thisAddress);
        sb.append('}');
        return sb.toString();
    }

    private class MergeTask implements Runnable {

        public void run() {
            LifecycleServiceImpl lifecycleService = node.hazelcastInstance.getLifecycleService();
            lifecycleService.fireLifecycleEvent(MERGING);

            resetState();

            Collection<Runnable> tasks = collectMergeTasks();

            resetServices();

            rejoin();

            executeMergeTasks(tasks);

            if (node.isActive() && node.joined()) {
                lifecycleService.fireLifecycleEvent(MERGED);
            }
        }

        private void resetState() {
            
            
            
            node.reset();
            ClusterServiceImpl.this.reset();
            
            
            
            
            node.connectionManager.stop();

            
            
            nodeEngine.reset();
        }

        private Collection<Runnable> collectMergeTasks() {
            
            Collection<SplitBrainHandlerService> services = nodeEngine.getServices(SplitBrainHandlerService.class);
            Collection<Runnable> tasks = new LinkedList<Runnable>();
            for (SplitBrainHandlerService service : services) {
                final Runnable runnable = service.prepareMergeRunnable();
                if (runnable != null) {
                    tasks.add(runnable);
                }
            }
            return tasks;
        }

        private void resetServices() {
            
            Collection<ManagedService> managedServices = nodeEngine.getServices(ManagedService.class);
            for (ManagedService service : managedServices) {
                service.reset();
            }
        }

        private void rejoin() {
            
            node.connectionManager.start();
            
            node.rejoin();
        }

        private void executeMergeTasks(Collection<Runnable> tasks) {
            
            Collection<Future> futures = new LinkedList<Future>();
            for (Runnable task : tasks) {
                Future f = nodeEngine.getExecutionService().submit("hz:system", task);
                futures.add(f);
            }
            long callTimeout = node.groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong();
            for (Future f : futures) {
                try {
                    waitOnFutureInterruptible(f, callTimeout, TimeUnit.MILLISECONDS);
                } catch (HazelcastInstanceNotActiveException e) {
                    EmptyStatement.ignore(e);
                } catch (Exception e) {
                    logger.severe("While merging...", e);
                }
            }
        }
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.security.Credentials;

import java.io.IOException;
import java.util.HashMap;
import java.util.Map;

public class JoinRequest extends JoinMessage implements DataSerializable {

    private Credentials credentials;
    private int tryCount;
    private Map<String, Object> attributes;

    public JoinRequest() {
    }

    public JoinRequest(byte packetVersion, int buildNumber, Address address, String uuid, ConfigCheck config,
                       Credentials credentials, int memberCount, int tryCount, Map<String, Object> attributes) {
        super(packetVersion, buildNumber, address, uuid, config, memberCount);
        this.credentials = credentials;
        this.tryCount = tryCount;
        this.attributes = attributes;
    }

    public Credentials getCredentials() {
        return credentials;
    }

    public int getTryCount() {
        return tryCount;
    }

    public void setTryCount(int tryCount) {
        this.tryCount = tryCount;
    }

    public Map<String, Object> getAttributes() {
        return attributes;
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        super.readData(in);
        credentials = in.readObject();
        if (credentials != null) {
            credentials.setEndpoint(getAddress().getHost());
        }
        tryCount = in.readInt();
        int size = in.readInt();
        attributes = new HashMap<String, Object>();
        for (int i = 0; i < size; i++) {
            String key = in.readUTF();
            Object value = in.readObject();
            attributes.put(key, value);
        }
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        super.writeData(out);
        out.writeObject(credentials);
        out.writeInt(tryCount);
        out.writeInt(attributes.size());
        for (Map.Entry<String, Object> entry : attributes.entrySet()) {
            out.writeUTF(entry.getKey());
            out.writeObject(entry.getValue());
        }
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("JoinRequest");
        sb.append("{packetVersion=").append(packetVersion);
        sb.append(", buildNumber=").append(buildNumber);
        sb.append(", address=").append(address);
        sb.append(", uuid='").append(uuid).append('\'');
        sb.append(", credentials=").append(credentials);
        sb.append(", memberCount=").append(memberCount);
        sb.append(", tryCount=").append(tryCount);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.JoinRequest;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.spi.AbstractOperation;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;

public class JoinCheckOperation extends AbstractOperation implements JoinOperation {

    private JoinRequest joinRequest;
    private JoinRequest response;

    public JoinCheckOperation() {
    }

    public JoinCheckOperation(final JoinRequest joinRequest) {
        this.joinRequest = joinRequest;
    }

    @Override
    public void run() {
        final ClusterServiceImpl service = getService();
        final NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        final Node node = nodeEngine.getNode();
        boolean ok = false;
        if (joinRequest != null && node.joined() && node.isActive()) {
            try {
                ok = service.validateJoinMessage(joinRequest);
            } catch (Exception ignored) {
            }
        }
        if (ok) {
            response = node.createJoinRequest();
        }
    }

    @Override
    public Object getResponse() {
        return response;
    }

    @Override
    protected void readInternal(final ObjectDataInput in) throws IOException {
        joinRequest = new JoinRequest();
        joinRequest.readData(in);
    }

    @Override
    protected void writeInternal(final ObjectDataOutput out) throws IOException {
        joinRequest.writeData(out);
    }
}


<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.ClusterDataSerializerHook;
import com.hazelcast.nio.serialization.IdentifiedDataSerializable;

public final class HeartbeatOperation extends AbstractClusterOperation
        implements JoinOperation, IdentifiedDataSerializable {

    @Override
    public void run() {
        
    }

    @Override
    public int getFactoryId() {
        return ClusterDataSerializerHook.F_ID;
    }

    @Override
    public int getId() {
        return ClusterDataSerializerHook.HEARTBEAT;
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.cluster.impl.JoinMessage;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;

import java.io.IOException;

public class MasterDiscoveryOperation extends AbstractClusterOperation implements JoinOperation {

    private JoinMessage joinMessage;

    public MasterDiscoveryOperation() {
    }

    public MasterDiscoveryOperation(JoinMessage joinMessage) {
        this.joinMessage = joinMessage;
    }

    @Override
    public void run() {
        ClusterServiceImpl cm = getService();
        cm.answerMasterQuestion(joinMessage);
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        joinMessage = new JoinMessage();
        joinMessage.readData(in);
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        joinMessage.writeData(out);
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("MasterDiscoveryOperation");
        sb.append("{message=").append(joinMessage);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.OperationService;

public class MasterConfirmationOperation extends AbstractClusterOperation {

    @Override
    public void run() {
        final Address endpoint = getCallerAddress();
        if (endpoint == null) {
            return;
        }

        final ClusterServiceImpl clusterService = getService();
        final ILogger logger = getNodeEngine().getLogger(MasterConfirmationOperation.class.getName());
        final MemberImpl member = clusterService.getMember(endpoint);
        if (member == null) {
            logger.warning("MasterConfirmation has been received from " + endpoint
                    + ", but it is not a member of this cluster!");
            OperationService operationService = getNodeEngine().getOperationService();
            operationService.send(new MemberRemoveOperation(clusterService.getThisAddress()), endpoint);
        } else {
            if (clusterService.isMaster()) {
                clusterService.acceptMasterConfirmation(member);
            } else {
                logger.warning(endpoint + " has sent MasterConfirmation, but this node is not master!");
            }
        }
    }

}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;

import java.io.IOException;

public class MemberRemoveOperation extends AbstractClusterOperation {

    private Address deadAddress;

    public MemberRemoveOperation() {
    }

    public MemberRemoveOperation(Address deadAddress) {
        this.deadAddress = deadAddress;
    }

    @Override
    public void run() {
        final ClusterServiceImpl clusterService = getService();
        final Address caller = getCallerAddress();
        if (caller != null
                && (caller.equals(deadAddress) || caller.equals(clusterService.getMasterAddress()))) {
            ILogger logger = getLogger();
            if (logger.isFinestEnabled()) {
                logger.finest("Removing " + deadAddress + ", called from " + caller);
            }
            clusterService.removeAddress(deadAddress);
        }
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        deadAddress = new Address();
        deadAddress.readData(in);
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        deadAddress.writeData(out);
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;

public class PrepareMergeOperation extends AbstractClusterOperation {

    private Address newTargetAddress;

    public PrepareMergeOperation() {
    }

    public PrepareMergeOperation(Address newTargetAddress) {
        this.newTargetAddress = newTargetAddress;
    }

    @Override
    public void run() {
        final Address caller = getCallerAddress();
        final NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        final Node node = nodeEngine.getNode();
        final Address masterAddress = node.getMasterAddress();
        final ILogger logger = node.loggingService.getLogger(this.getClass().getName());
        boolean local = caller == null;
        if (!local && !caller.equals(masterAddress)) {
            logger.warning("Prepare-merge instruction sent from non-master endpoint: " + caller);
            return;
        }
        logger.warning("Preparing to merge... Waiting for merge instruction...");
        node.getClusterService().prepareToMerge(newTargetAddress);
    }

    @Override
    public Object getResponse() {
        return Boolean.TRUE;
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        super.readInternal(in);
        newTargetAddress = new Address();
        newTargetAddress.readData(in);
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        super.writeInternal(out);
        newTargetAddress.writeData(out);
    }
}

<code block>


package com.hazelcast.cluster.impl.operations;

import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;

public class MergeClustersOperation extends AbstractClusterOperation {

    private Address newTargetAddress;

    public MergeClustersOperation() {
    }

    public MergeClustersOperation(Address newTargetAddress) {
        this.newTargetAddress = newTargetAddress;
    }

    @Override
    public void run() {
        final Address caller = getCallerAddress();
        final NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        final Node node = nodeEngine.getNode();
        final Address masterAddress = node.getMasterAddress();
        final ILogger logger = node.loggingService.getLogger(this.getClass().getName());
        boolean local = caller == null;
        if (!local && !caller.equals(masterAddress)) {
            logger.warning("Merge instruction sent from non-master endpoint: " + caller);
            return;
        }
        logger.warning(node.getThisAddress() + " is merging to " + newTargetAddress
                + ", because: instructed by master " + masterAddress);
        node.getClusterService().merge(newTargetAddress);
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        super.readInternal(in);
        newTargetAddress = new Address();
        newTargetAddress.readData(in);
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        super.writeInternal(out);
        newTargetAddress.writeData(out);
    }
}

<code block>


package com.hazelcast.nio;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.config.NetworkConfig;
import com.hazelcast.config.SSLConfig;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.config.SymmetricEncryptionConfig;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.ascii.TextCommandService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.PacketReader;
import com.hazelcast.nio.tcp.PacketWriter;
import com.hazelcast.nio.tcp.SocketChannelWrapperFactory;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.packettransceiver.PacketTransceiver;

import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.Set;

public class NodeIOService implements IOService {

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final PacketTransceiver packetTransceiver;

    public NodeIOService(Node node, NodeEngineImpl nodeEngine) {
        this.node = node;
        this.nodeEngine = nodeEngine;
        this.packetTransceiver = nodeEngine.getPacketTransceiver();
    }

    @Override
    public MetricsRegistry getMetricRegistry() {
        return nodeEngine.getMetricsRegistry();
    }

    @Override
    public boolean isActive() {
        return node.isActive();
    }

    @Override
    public ILogger getLogger(String name) {
        return node.getLogger(name);
    }

    @Override
    public void onOutOfMemory(OutOfMemoryError oom) {
        OutOfMemoryErrorDispatcher.onOutOfMemory(oom);
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public void onFatalError(Exception e) {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        new Thread(threadGroup.getInternalThreadGroup(), threadGroup.getThreadNamePrefix("io.error.shutdown")) {
            public void run() {
                node.shutdown(false);
            }
        } .start();
    }

    @Override
    public SocketInterceptorConfig getSocketInterceptorConfig() {
        return node.getConfig().getNetworkConfig().getSocketInterceptorConfig();
    }

    @Override
    public SymmetricEncryptionConfig getSymmetricEncryptionConfig() {
        return node.getConfig().getNetworkConfig().getSymmetricEncryptionConfig();
    }

    @Override
    public SSLConfig getSSLConfig() {
        return node.getConfig().getNetworkConfig().getSSLConfig();
    }

    @Override
    public void handleMemberPacket(final Packet packet) {
        final Address endPoint = packet.getConn().getEndPoint();
        if (endPoint != null) {
            final MemberImpl member = node.clusterService.getMember(endPoint);
            if (member != null) {
                member.didRead();
            }
        }
        packetTransceiver.receive(packet);
    }

    @Override
    public void handleClientPacket(Packet p) {
        node.clientEngine.handlePacket(p);
    }

    @Override
    public void handleClientMessage(ClientMessage cm, Connection connection) {
        node.clientEngine.handleClientMessage(cm, connection);
    }

    @Override
    public TextCommandService getTextCommandService() {
        return node.getTextCommandService();
    }

    @Override
    public boolean isMemcacheEnabled() {
        return node.groupProperties.MEMCACHE_ENABLED.getBoolean();
    }

    @Override
    public boolean isRestEnabled() {
        return node.groupProperties.REST_ENABLED.getBoolean();
    }

    @Override
    public void removeEndpoint(final Address endPoint) {
        nodeEngine.getExecutionService().execute(ExecutionService.IO_EXECUTOR, new Runnable() {
            @Override
            public void run() {
                node.clusterService.removeAddress(endPoint);
            }
        });
    }

    @Override
    public String getThreadPrefix() {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        return threadGroup.getThreadPoolNamePrefix("IO");
    }

    @Override
    public ThreadGroup getThreadGroup() {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        return threadGroup.getInternalThreadGroup();
    }

    @Override
    public void onSuccessfulConnection(Address address) {
        if (!node.joined()) {
            node.getJoiner().unblacklist(address);
        }
    }

    @Override
    public void onFailedConnection(Address address) {
        if (!node.joined()) {
            node.getJoiner().blacklist(address, false);
        }
    }

    @Override
    public void shouldConnectTo(Address address) {
        if (node.getThisAddress().equals(address)) {
            throw new RuntimeException("Connecting to self! " + address);
        }
    }

    @Override
    public boolean isSocketBind() {
        return node.groupProperties.SOCKET_CLIENT_BIND.getBoolean();
    }

    @Override
    public boolean isSocketBindAny() {
        return node.groupProperties.SOCKET_CLIENT_BIND_ANY.getBoolean();
    }

    @Override
    public int getSocketReceiveBufferSize() {
        return this.node.getGroupProperties().SOCKET_RECEIVE_BUFFER_SIZE.getInteger();
    }

    @Override
    public int getSocketSendBufferSize() {
        return this.node.getGroupProperties().SOCKET_SEND_BUFFER_SIZE.getInteger();
    }

    @Override
    public int getSocketClientReceiveBufferSize() {
        int clientSendBuffer = this.node.getGroupProperties().SOCKET_CLIENT_RECEIVE_BUFFER_SIZE.getInteger();
        return clientSendBuffer != -1 ? clientSendBuffer : getSocketReceiveBufferSize();
    }

    @Override
    public int getSocketClientSendBufferSize() {
        int clientReceiveBuffer = this.node.getGroupProperties().SOCKET_CLIENT_SEND_BUFFER_SIZE.getInteger();
        return clientReceiveBuffer != -1 ? clientReceiveBuffer : getSocketReceiveBufferSize();
    }

    @Override
    public int getSocketLingerSeconds() {
        return this.node.getGroupProperties().SOCKET_LINGER_SECONDS.getInteger();
    }

    @Override
    public int getSocketConnectTimeoutSeconds() {
        return this.node.getGroupProperties().SOCKET_CONNECT_TIMEOUT_SECONDS.getInteger();
    }

    @Override
    public boolean getSocketKeepAlive() {
        return this.node.getGroupProperties().SOCKET_KEEP_ALIVE.getBoolean();
    }

    @Override
    public boolean getSocketNoDelay() {
        return this.node.getGroupProperties().SOCKET_NO_DELAY.getBoolean();
    }

    @Override
    public int getSelectorThreadCount() {
        return node.groupProperties.IO_THREAD_COUNT.getInteger();
    }

    @Override
    public void onDisconnect(final Address endpoint) {
    }

    @Override
    public boolean isClient() {
        return false;
    }

    @Override
    public long getConnectionMonitorInterval() {
        return node.groupProperties.CONNECTION_MONITOR_INTERVAL.getLong();
    }

    @Override
    public int getConnectionMonitorMaxFaults() {
        return node.groupProperties.CONNECTION_MONITOR_MAX_FAULTS.getInteger();
    }

    @Override
    public int getBalancerIntervalSeconds() {
        return node.groupProperties.IO_BALANCER_INTERVAL_SECONDS.getInteger();
    }

    @Override
    public void executeAsync(final Runnable runnable) {
        nodeEngine.getExecutionService().execute(ExecutionService.IO_EXECUTOR, runnable);
    }

    @Override
    public EventService getEventService() {
        return nodeEngine.getEventService();
    }

    @Override
    public Data toData(Object obj) {
        return nodeEngine.toData(obj);
    }

    @Override
    public Object toObject(Data data) {
        return nodeEngine.toObject(data);
    }

    @Override
    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    @Override
    public SocketChannelWrapperFactory getSocketChannelWrapperFactory() {
        return node.getNodeExtension().getSocketChannelWrapperFactory();
    }

    @Override
    public MemberSocketInterceptor getMemberSocketInterceptor() {
        return node.getNodeExtension().getMemberSocketInterceptor();
    }

    @Override
    public PacketReader createPacketReader(TcpIpConnection connection) {
        return node.getNodeExtension().createPacketReader(connection, this);
    }

    @Override
    public PacketWriter createPacketWriter(TcpIpConnection connection) {
        return node.getNodeExtension().createPacketWriter(connection, this);
    }

    @Override
    public Collection<Integer> getOutboundPorts() {
        final NetworkConfig networkConfig = node.getConfig().getNetworkConfig();
        final Collection<String> portDefinitions = getPortDefinitions(networkConfig);
        final Set<Integer> ports = getPorts(networkConfig);
        if (portDefinitions.isEmpty() && ports.isEmpty()) {
            
            return Collections.emptySet();
        }
        if (portDefinitions.contains("*") || portDefinitions.contains("0")) {
            
            return Collections.emptySet();
        }
        transformPortDefinitionsToPorts(portDefinitions, ports);
        if (ports.contains(0)) {
            
            return Collections.emptySet();
        }
        return ports;
    }

    private void transformPortDefinitionsToPorts(Collection<String> portDefinitions, Set<Integer> ports) {
        
        for (String portDef : portDefinitions) {
            String[] portDefs = portDef.split("[,; ]");
            for (String def : portDefs) {
                def = def.trim();
                if (def.isEmpty()) {
                    continue;
                }
                final int dashPos = def.indexOf('-');
                if (dashPos > 0) {
                    final int start = Integer.parseInt(def.substring(0, dashPos));
                    final int end = Integer.parseInt(def.substring(dashPos + 1));
                    for (int port = start; port <= end; port++) {
                        ports.add(port);
                    }
                } else {
                    ports.add(Integer.parseInt(def));
                }
            }
        }
    }

    private Set<Integer> getPorts(NetworkConfig networkConfig) {
        return networkConfig.getOutboundPorts() == null
                ? new HashSet<Integer>() : new HashSet<Integer>(networkConfig.getOutboundPorts());
    }

    private Collection<String> getPortDefinitions(NetworkConfig networkConfig) {
        return networkConfig.getOutboundPortDefinitions() == null
                ? Collections.<String>emptySet() : networkConfig.getOutboundPortDefinitions();
    }
}


<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.config.Config;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.MemberLeftException;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.TestUtil;
import com.hazelcast.spi.AbstractOperation;
import com.hazelcast.spi.AbstractWaitNotifyKey;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.WaitNotifyKey;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.waitnotifyservice.impl.WaitNotifyServiceImpl;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.TestHazelcastInstanceFactory;
import com.hazelcast.test.annotation.QuickTest;
import com.hazelcast.util.EmptyStatement;
import java.util.concurrent.Callable;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import org.junit.Assert;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.fail;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class InvocationNetworkSplitTest extends HazelcastTestSupport {

    @Test
    public void testWaitingInvocations_whenNodeSplitFromCluster() throws Exception {
        SplitAction action = new FullSplitAction();
        testWaitingInvocations_whenNodeSplitFromCluster(action);
    }

    @Test
    public void testWaitingInvocations_whenNodePartiallySplitFromCluster_scenario1() throws Exception {
        SplitAction action = new PartialSplitAction();
        testWaitingInvocations_whenNodeSplitFromCluster(action);
    }

    @Test
    public void testWaitingInvocations_whenNodePartiallySplitFromCluster_scenario2() throws Exception {
        SplitAction action = new HalfPartialSplitAction();
        testWaitingInvocations_whenNodeSplitFromCluster(action);
    }

    private void testWaitingInvocations_whenNodeSplitFromCluster(SplitAction splitAction) throws Exception {
        Config config = new Config();
        config.getGroupConfig().setName(generateRandomString(10));
        TestHazelcastInstanceFactory factory = createHazelcastInstanceFactory(3);
        HazelcastInstance hz1 = factory.newHazelcastInstance(config);
        HazelcastInstance hz2 = factory.newHazelcastInstance(config);
        HazelcastInstance hz3 = factory.newHazelcastInstance(config);

        Node node1 = TestUtil.getNode(hz1);
        Node node2 = TestUtil.getNode(hz2);
        Node node3 = TestUtil.getNode(hz3);

        warmUpPartitions(hz1, hz2, hz3);
        int partitionId = getPartitionId(hz2);

        NodeEngineImpl nodeEngine3 = node3.getNodeEngine();
        OperationService operationService3 = nodeEngine3.getOperationService();
        Operation op = new AlwaysBlockingOperation();
        Future<Object> future = operationService3.invokeOnPartition("", op, partitionId);

        
        
        sleepSeconds(1);

        
        splitAction.run(node1, node2, node3);

        
        ClusterServiceImpl clusterService3 = node3.getClusterService();
        clusterService3.prepareToMerge(node1.address);
        clusterService3.merge(node1.address);

        assertEquals(3, node1.getClusterService().getSize());
        assertEquals(3, node2.getClusterService().getSize());
        assertEquals(3, node3.getClusterService().getSize());

        try {
            future.get(1, TimeUnit.MINUTES);
            fail("Future.get() should fail with a MemberLeftException!");
        } catch (MemberLeftException e) {
            
            EmptyStatement.ignore(e);
        } catch (Exception e) {
            fail(e.getClass().getName() + ": " + e.getMessage());
        }
    }

    @Test
    public void testWaitNotifyService_whenNodeSplitFromCluster() throws Exception {
        SplitAction action = new FullSplitAction();
        testWaitNotifyService_whenNodeSplitFromCluster(action);
    }

    @Test
    public void testWaitNotifyService_whenNodePartiallySplitFromCluster() throws Exception {
        SplitAction action = new PartialSplitAction();
        testWaitNotifyService_whenNodeSplitFromCluster(action);
    }

    private void testWaitNotifyService_whenNodeSplitFromCluster(SplitAction action) throws Exception {
        Config config = new Config();
        config.getGroupConfig().setName(generateRandomString(10));
        TestHazelcastInstanceFactory factory = createHazelcastInstanceFactory(5);
        HazelcastInstance hz1 = factory.newHazelcastInstance(config);
        HazelcastInstance hz2 = factory.newHazelcastInstance(config);
        HazelcastInstance hz3 = factory.newHazelcastInstance(config);

        final Node node1 = TestUtil.getNode(hz1);
        Node node2 = TestUtil.getNode(hz2);
        Node node3 = TestUtil.getNode(hz3);

        warmUpPartitions(hz1, hz2, hz3);
        int partitionId = getPartitionId(hz3);

        NodeEngineImpl nodeEngine1 = node1.getNodeEngine();
        OperationService operationService1 = nodeEngine1.getOperationService();
        operationService1.invokeOnPartition("", new AlwaysBlockingOperation(), partitionId);

        final WaitNotifyServiceImpl waitNotifyService3 = (WaitNotifyServiceImpl) node3.getNodeEngine().getWaitNotifyService();
        assertEqualsEventually(new Callable<Integer>() {
            @Override
            public Integer call() throws Exception {
                return waitNotifyService3.getTotalWaitingOperationCount();
            }
        }, 1);

        action.run(node1, node2, node3);

        
        
        factory.newHazelcastInstance(config);

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                Assert.assertEquals(0, node1.partitionService.getMigrationQueueSize());
            }
        });

        
        ClusterServiceImpl clusterService3 = node3.getClusterService();
        clusterService3.prepareToMerge(node1.address);
        clusterService3.merge(node1.address);

        assertEquals(4, node1.getClusterService().getSize());
        assertEquals(4, node2.getClusterService().getSize());
        assertEquals(4, node3.getClusterService().getSize());

        assertEquals(0, waitNotifyService3.getTotalWaitingOperationCount());
    }

    private static class AlwaysBlockingOperation extends AbstractOperation implements WaitSupport {

        @Override
        public void run() throws Exception {
        }

        @Override
        public WaitNotifyKey getWaitKey() {
            return new AbstractWaitNotifyKey(getServiceName(), "test") {
            };
        }

        @Override
        public boolean shouldWait() {
            return true;
        }

        @Override
        public void onWaitExpire() {
            sendResponse(new TimeoutException());
        }

        @Override
        public String getServiceName() {
            return "AlwaysBlockingOperationService";
        }

        @Override
        public ExceptionAction onException(Throwable throwable) {
            return ExceptionAction.THROW_EXCEPTION;
        }
    }

    private interface SplitAction {
        void run(Node node1, Node node2, Node node3);
    }

    private static class FullSplitAction implements SplitAction {
        @Override
        public void run(final Node node1, final Node node2, final Node node3) {
            
            node1.clusterService.removeAddress(node3.address);

            node3.clusterService.removeAddress(node1.address);
            node3.clusterService.removeAddress(node2.address);

            assertTrueEventually(new AssertTask() {
                @Override
                public void run() throws Exception {
                    assertEquals(2, node1.getClusterService().getSize());
                    assertEquals(2, node2.getClusterService().getSize());
                    assertEquals(1, node3.getClusterService().getSize());
                }
            }, 10);
        }
    }

    private static class PartialSplitAction implements SplitAction {
        @Override
        public void run(final Node node1, final Node node2, final Node node3) {
            
            
            
            node1.clusterService.removeAddress(node3.address);

            assertTrueEventually(new AssertTask() {
                @Override
                public void run() throws Exception {
                    assertEquals(2, node1.getClusterService().getSize());
                    assertEquals(2, node2.getClusterService().getSize());
                    assertEquals(3, node3.getClusterService().getSize());
                }
            }, 10);
        }
    }

    private static class HalfPartialSplitAction implements SplitAction {
        @Override
        public void run(final Node node1, final Node node2, final Node node3) {
            
            
            
            node1.clusterService.removeAddress(node3.address);
            node3.clusterService.removeAddress(node1.address);

            assertTrueEventually(new AssertTask() {
                @Override
                public void run() throws Exception {
                    assertEquals(2, node1.getClusterService().getSize());
                    assertEquals(2, node2.getClusterService().getSize());
                    assertEquals(2, node3.getClusterService().getSize());
                }
            }, 10);
        }
    }
}

<code block>


package com.hazelcast.cluster;

import com.hazelcast.config.Config;
import com.hazelcast.config.JoinConfig;
import com.hazelcast.config.ListenerConfig;
import com.hazelcast.config.NetworkConfig;
import com.hazelcast.core.Hazelcast;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.LifecycleEvent;
import com.hazelcast.core.LifecycleEvent.LifecycleState;
import com.hazelcast.core.LifecycleListener;
import com.hazelcast.core.MemberAttributeEvent;
import com.hazelcast.core.MembershipAdapter;
import com.hazelcast.core.MembershipEvent;
import com.hazelcast.core.MembershipListener;
import com.hazelcast.instance.DefaultNodeContext;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastInstanceFactory;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.TestUtil;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.NodeIOService;
import com.hazelcast.nio.tcp.FirewallingTcpIpConnectionManager;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.NightlyTest;
import com.hazelcast.util.Clock;
import java.io.IOException;
import java.nio.channels.ServerSocketChannel;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static com.hazelcast.instance.HazelcastInstanceFactory.newHazelcastInstance;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(NightlyTest.class)
public class SplitBrainHandlerTest extends HazelcastTestSupport {

    @Before
    @After
    public void killAllHazelcastInstances() throws IOException {
        HazelcastInstanceFactory.terminateAll();
    }

    @Test
    public void testMulticast_ClusterMerge() throws Exception {
        testClusterMerge(true);
    }

    @Test
    public void testTcpIp__ClusterMerge() throws Exception {
        testClusterMerge(false);
    }

    private void testClusterMerge(boolean multicast) throws Exception {
        Config config1 = new Config();
        config1.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config1.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String firstGroupName = generateRandomString(10);
        config1.getGroupConfig().setName(firstGroupName);

        NetworkConfig networkConfig1 = config1.getNetworkConfig();
        JoinConfig join1 = networkConfig1.getJoin();
        join1.getMulticastConfig().setEnabled(multicast);
        join1.getTcpIpConfig().setEnabled(!multicast);
        join1.getTcpIpConfig().addMember("127.0.0.1");

        Config config2 = new Config();
        config2.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config2.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String secondGroupName = generateRandomString(10);
        config2.getGroupConfig().setName(secondGroupName);

        NetworkConfig networkConfig2 = config2.getNetworkConfig();
        JoinConfig join2 = networkConfig2.getJoin();
        join2.getMulticastConfig().setEnabled(multicast);
        join2.getTcpIpConfig().setEnabled(!multicast);
        join2.getTcpIpConfig().addMember("127.0.0.1");

        HazelcastInstance h1 = Hazelcast.newHazelcastInstance(config1);
        HazelcastInstance h2 = Hazelcast.newHazelcastInstance(config2);
        LifecycleCountingListener l = new LifecycleCountingListener();
        h2.getLifecycleService().addLifecycleListener(l);

        assertEquals(1, h1.getCluster().getMembers().size());
        assertEquals(1, h2.getCluster().getMembers().size());

        
        config1.getGroupConfig().setName(secondGroupName);
        assertTrue(l.waitFor(LifecycleState.MERGED, 30));

        assertEquals(1, l.getCount(LifecycleState.MERGING));
        assertEquals(1, l.getCount(LifecycleState.MERGED));
        assertEquals(2, h1.getCluster().getMembers().size());
        assertEquals(2, h2.getCluster().getMembers().size());
    }

    @Test
    public void testClusterShouldNotMergeDifferentGroupName() throws Exception {
        Config config1 = new Config();
        config1.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config1.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String firstGroupName = generateRandomString(10);
        config1.getGroupConfig().setName(firstGroupName);

        NetworkConfig networkConfig1 = config1.getNetworkConfig();
        JoinConfig join1 = networkConfig1.getJoin();
        join1.getMulticastConfig().setEnabled(true);
        join1.getTcpIpConfig().addMember("127.0.0.1");

        Config config2 = new Config();
        config2.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config2.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String secondGroupName = generateRandomString(10);
        config2.getGroupConfig().setName(secondGroupName);

        NetworkConfig networkConfig2 = config2.getNetworkConfig();
        JoinConfig join2 = networkConfig2.getJoin();
        join2.getMulticastConfig().setEnabled(true);
        join2.getTcpIpConfig().addMember("127.0.0.1");

        HazelcastInstance h1 = Hazelcast.newHazelcastInstance(config1);
        HazelcastInstance h2 = Hazelcast.newHazelcastInstance(config2);
        LifecycleCountingListener l = new LifecycleCountingListener();
        h2.getLifecycleService().addLifecycleListener(l);

        assertEquals(1, h1.getCluster().getMembers().size());
        assertEquals(1, h2.getCluster().getMembers().size());

        HazelcastTestSupport.sleepSeconds(10);

        assertEquals(0, l.getCount(LifecycleState.MERGING));
        assertEquals(0, l.getCount(LifecycleState.MERGED));
        assertEquals(1, h1.getCluster().getMembers().size());
        assertEquals(1, h2.getCluster().getMembers().size());
    }

    private static class LifecycleCountingListener implements LifecycleListener {
        Map<LifecycleState, AtomicInteger> counter = new ConcurrentHashMap<LifecycleState, AtomicInteger>();
        BlockingQueue<LifecycleState> eventQueue = new LinkedBlockingQueue<LifecycleState>();

        LifecycleCountingListener() {
            for (LifecycleEvent.LifecycleState state : LifecycleEvent.LifecycleState.values()) {
                counter.put(state, new AtomicInteger(0));
            }
        }

        public void stateChanged(LifecycleEvent event) {
            counter.get(event.getState()).incrementAndGet();
            eventQueue.offer(event.getState());
        }

        int getCount(LifecycleEvent.LifecycleState state) {
            return counter.get(state).get();
        }

        boolean waitFor(LifecycleEvent.LifecycleState state, int seconds) {
            long remainingMillis = TimeUnit.SECONDS.toMillis(seconds);
            while (remainingMillis >= 0) {
                LifecycleEvent.LifecycleState received = null;
                try {
                    long now = Clock.currentTimeMillis();
                    received = eventQueue.poll(remainingMillis, TimeUnit.MILLISECONDS);
                    remainingMillis -= (Clock.currentTimeMillis() - now);
                } catch (InterruptedException e) {
                    return false;
                }
                if (received != null && received == state) {
                    return true;
                }
            }
            return false;
        }
    }

    @Test
    public void testMulticast_MergeAfterSplitBrain() throws InterruptedException {
        testMergeAfterSplitBrain(true);
    }

    @Test
    public void testTcpIp_MergeAfterSplitBrain() throws InterruptedException {
        testMergeAfterSplitBrain(false);
    }

    private void testMergeAfterSplitBrain(boolean multicast) throws InterruptedException {
        Config config = new Config();
        config.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        config.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");
        String groupName = generateRandomString(10);
        config.getGroupConfig().setName(groupName);

        NetworkConfig networkConfig = config.getNetworkConfig();
        JoinConfig join = networkConfig.getJoin();
        join.getMulticastConfig().setEnabled(multicast);
        join.getTcpIpConfig().setEnabled(!multicast);
        join.getTcpIpConfig().addMember("127.0.0.1");

        HazelcastInstance h1 = Hazelcast.newHazelcastInstance(config);
        HazelcastInstance h2 = Hazelcast.newHazelcastInstance(config);
        HazelcastInstance h3 = Hazelcast.newHazelcastInstance(config);

        final CountDownLatch splitLatch = new CountDownLatch(2);
        h3.getCluster().addMembershipListener(new MembershipListener() {
            @Override
            public void memberAdded(MembershipEvent membershipEvent) {
            }

            @Override
            public void memberRemoved(MembershipEvent membershipEvent) {
                splitLatch.countDown();
            }

            @Override
            public void memberAttributeChanged(MemberAttributeEvent memberAttributeEvent) {
            }
        });

        final CountDownLatch mergeLatch = new CountDownLatch(1);
        h3.getLifecycleService().addLifecycleListener(new LifecycleListener() {
            public void stateChanged(LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    mergeLatch.countDown();
                }
            }
        });

        closeConnectionBetween(h1, h3);
        closeConnectionBetween(h2, h3);

        assertTrue(splitLatch.await(10, TimeUnit.SECONDS));
        assertEquals(2, h1.getCluster().getMembers().size());
        assertEquals(2, h2.getCluster().getMembers().size());
        assertEquals(1, h3.getCluster().getMembers().size());

        assertTrue(mergeLatch.await(30, TimeUnit.SECONDS));
        assertEquals(3, h1.getCluster().getMembers().size());
        assertEquals(3, h2.getCluster().getMembers().size());
        assertEquals(3, h3.getCluster().getMembers().size());
    }

    @Test
    public void testTcpIpSplitBrainJoinsCorrectCluster() throws Exception {

        
        Config c1 = buildConfig(false, 15702);
        Config c2 = buildConfig(false, 15704);
        Config c3 = buildConfig(false, 15703);
        Config c4 = buildConfig(false, 15701);

        List<String> clusterOneMembers = Arrays.asList("127.0.0.1:15702", "127.0.0.1:15704");
        List<String> clusterTwoMembers = Arrays.asList("127.0.0.1:15703", "127.0.0.1:15701");

        c1.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterOneMembers);
        c2.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterOneMembers);
        c3.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterTwoMembers);
        c4.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterTwoMembers);


        final CountDownLatch latch = new CountDownLatch(2);
        c3.addListenerConfig(new ListenerConfig(new LifecycleListener() {
            public void stateChanged(final LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    latch.countDown();
                }
            }
        }));

        c4.addListenerConfig(new ListenerConfig(new LifecycleListener() {
            public void stateChanged(final LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    latch.countDown();
                }
            }
        }));

        HazelcastInstance h1 = Hazelcast.newHazelcastInstance(c1);
        HazelcastInstance h2 = Hazelcast.newHazelcastInstance(c2);
        HazelcastInstance h3 = Hazelcast.newHazelcastInstance(c3);
        HazelcastInstance h4 = Hazelcast.newHazelcastInstance(c4);

        
        assertEquals(2, h1.getCluster().getMembers().size());
        assertEquals(2, h2.getCluster().getMembers().size());
        assertEquals(2, h3.getCluster().getMembers().size());
        assertEquals(2, h4.getCluster().getMembers().size());

        List<String> allMembers = Arrays.asList("127.0.0.1:15701", "127.0.0.1:15704", "127.0.0.1:15703",
                "127.0.0.1:15702");

        
        h3.getConfig().getNetworkConfig().getJoin().getTcpIpConfig().setMembers(allMembers);
        h4.getConfig().getNetworkConfig().getJoin().getTcpIpConfig().clear().setMembers(Collections.<String>emptyList());

        assertTrue(latch.await(60, TimeUnit.SECONDS));

        
        assertEquals(4, h1.getCluster().getMembers().size());
        assertEquals(4, h2.getCluster().getMembers().size());
        assertEquals(4, h3.getCluster().getMembers().size());
        assertEquals(4, h4.getCluster().getMembers().size());
    }

    @Test
    public void testTcpIpSplitBrainStillWorks_WhenTargetDisappears() throws Exception {
        
        Config c1 = buildConfig(false, 25701);
        Config c2 = buildConfig(false, 25704);
        Config c3 = buildConfig(false, 25703);

        List<String> clusterOneMembers = Arrays.asList("127.0.0.1:25701");
        List<String> clusterTwoMembers = Arrays.asList("127.0.0.1:25704");
        List<String> clusterThreeMembers = Arrays.asList("127.0.0.1:25703");

        c1.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterOneMembers);
        c2.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterTwoMembers);
        c3.getNetworkConfig().getJoin().getTcpIpConfig().setMembers(clusterThreeMembers);

        final HazelcastInstance h1 = Hazelcast.newHazelcastInstance(c1);
        final HazelcastInstance h2 = Hazelcast.newHazelcastInstance(c2);

        final CountDownLatch latch = new CountDownLatch(1);
        c3.addListenerConfig(new ListenerConfig(new LifecycleListener() {
            public void stateChanged(final LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGING) {
                    h1.shutdown();
                } else if (event.getState() == LifecycleState.MERGED) {
                    latch.countDown();
                }
            }
        }));

        final HazelcastInstance h3 = Hazelcast.newHazelcastInstance(c3);

        
        assertEquals(1, h1.getCluster().getMembers().size());
        assertEquals(1, h2.getCluster().getMembers().size());
        assertEquals(1, h3.getCluster().getMembers().size());

        List<String> allMembers = Arrays.asList("127.0.0.1:25701", "127.0.0.1:25704", "127.0.0.1:25703");

        h3.getConfig().getNetworkConfig().getJoin().getTcpIpConfig().setMembers(allMembers);

        assertTrue(latch.await(60, TimeUnit.SECONDS));

        
        assertFalse(h1.getLifecycleService().isRunning());
        assertEquals(2, h2.getCluster().getMembers().size());
        assertEquals(2, h3.getCluster().getMembers().size());
    }

    private static Config buildConfig(boolean multicastEnabled, int port) {
        Config c = new Config();
        c.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "5");
        c.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "3");

        NetworkConfig networkConfig = c.getNetworkConfig();
        networkConfig.setPort(port).setPortAutoIncrement(false);
        networkConfig.getJoin().getMulticastConfig().setEnabled(multicastEnabled);
        networkConfig.getJoin().getTcpIpConfig().setEnabled(!multicastEnabled);
        return c;
    }

    @Test
    public void testMulticastJoin_DuringSplitBrainHandlerRunning() throws InterruptedException {
        Properties props = new Properties();
        props.setProperty(GroupProperties.PROP_WAIT_SECONDS_BEFORE_JOIN, "5");
        props.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "0");
        props.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "0");

        String groupName = generateRandomString(10);
        final CountDownLatch latch = new CountDownLatch(1);
        Config config1 = new Config();
        
        config1.getNetworkConfig().setPort(5901);
        config1.getGroupConfig().setName(groupName);
        config1.setProperties(props);
        config1.addListenerConfig(new ListenerConfig(new LifecycleListener() {
            public void stateChanged(final LifecycleEvent event) {
                switch (event.getState()) {
                    case MERGING:
                    case MERGED:
                        latch.countDown();
                    default:
                        break;
                }
            }
        }));
        Hazelcast.newHazelcastInstance(config1);
        Thread.sleep(5000);

        Config config2 = new Config();
        config2.getGroupConfig().setName(groupName);
        config2.getNetworkConfig().setPort(5701);
        config2.setProperties(props);
        Hazelcast.newHazelcastInstance(config2);

        assertFalse("Latch should not be countdown!", latch.await(3, TimeUnit.SECONDS));
    }

    @Test
    public void testMulticast_ClusterMerge_when_split_not_detected_by_master() throws InterruptedException {
        testClusterMerge_when_split_not_detected_by_master(true);
    }

    @Test
    public void testTcpIp_ClusterMerge_when_split_not_detected_by_master() throws InterruptedException {
        testClusterMerge_when_split_not_detected_by_master(false);
    }

    private void testClusterMerge_when_split_not_detected_by_master(boolean multicastEnabled)
            throws InterruptedException {
        Config config = new Config();
        String groupName = generateRandomString(10);
        config.getGroupConfig().setName(groupName);
        config.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "10");

        config.setProperty(GroupProperties.PROP_MAX_JOIN_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "10");

        NetworkConfig networkConfig = config.getNetworkConfig();
        networkConfig.getJoin().getMulticastConfig().setEnabled(multicastEnabled);
        networkConfig.getJoin().getTcpIpConfig()
                .setEnabled(!multicastEnabled).addMember("127.0.0.1");

        HazelcastInstance hz1 = newHazelcastInstance(config, "test-node1", new FirewallingNodeContext());
        HazelcastInstance hz2 = newHazelcastInstance(config, "test-node2", new FirewallingNodeContext());
        HazelcastInstance hz3 = newHazelcastInstance(config, "test-node3", new FirewallingNodeContext());

        final Node n1 = TestUtil.getNode(hz1);
        Node n2 = TestUtil.getNode(hz2);
        Node n3 = TestUtil.getNode(hz3);

        final CountDownLatch splitLatch = new CountDownLatch(2);
        MembershipAdapter membershipAdapter = new MembershipAdapter() {
            @Override
            public void memberRemoved(MembershipEvent event) {
                if (n1.getLocalMember().equals(event.getMember())) {
                    splitLatch.countDown();
                }
            }
        };

        hz2.getCluster().addMembershipListener(membershipAdapter);
        hz3.getCluster().addMembershipListener(membershipAdapter);

        final CountDownLatch mergeLatch = new CountDownLatch(2);
        LifecycleListener lifecycleListener = new LifecycleListener() {
            @Override
            public void stateChanged(LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    mergeLatch.countDown();
                }
            }
        };
        hz2.getLifecycleService().addLifecycleListener(lifecycleListener);
        hz3.getLifecycleService().addLifecycleListener(lifecycleListener);

        FirewallingTcpIpConnectionManager cm1 = getFireWalledConnectionManager(hz1);
        FirewallingTcpIpConnectionManager cm2 = getFireWalledConnectionManager(hz2);
        FirewallingTcpIpConnectionManager cm3 = getFireWalledConnectionManager(hz3);

        
        cm1.block(n2.address);
        cm1.block(n3.address);

        
        n2.clusterService.removeAddress(n1.address);
        n3.clusterService.removeAddress(n1.address);
        cm2.block(n1.address);
        cm3.block(n1.address);

        assertTrue(splitLatch.await(120, TimeUnit.SECONDS));
        assertEquals(3, hz1.getCluster().getMembers().size());
        assertEquals(2, hz2.getCluster().getMembers().size());
        assertEquals(2, hz3.getCluster().getMembers().size());

        
        
        cm1.unblock(n2.address);
        cm2.unblock(n1.address);
        cm3.unblock(n1.address);

        assertTrue(mergeLatch.await(120, TimeUnit.SECONDS));
        assertEquals(3, hz1.getCluster().getMembers().size());
        assertEquals(3, hz2.getCluster().getMembers().size());
        assertEquals(3, hz3.getCluster().getMembers().size());

        assertEquals(n1.getThisAddress(), n1.getMasterAddress());
        assertEquals(n1.getThisAddress(), n2.getMasterAddress());
        assertEquals(n1.getThisAddress(), n3.getMasterAddress());
    }

    @Test
    public void testClusterMerge_when_split_not_detected_by_slave() throws InterruptedException {
        Config config = new Config();
        String groupName = generateRandomString(10);
        config.getGroupConfig().setName(groupName);
        config.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "10");

        config.setProperty(GroupProperties.PROP_MAX_JOIN_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "10");

        NetworkConfig networkConfig = config.getNetworkConfig();
        networkConfig.getJoin().getMulticastConfig().setEnabled(false);
        networkConfig.getJoin().getTcpIpConfig()
                .setEnabled(true).addMember("127.0.0.1");

        HazelcastInstance hz1 = newHazelcastInstance(config, "test-node1", new FirewallingNodeContext());
        HazelcastInstance hz2 = newHazelcastInstance(config, "test-node2", new FirewallingNodeContext());
        HazelcastInstance hz3 = newHazelcastInstance(config, "test-node3", new FirewallingNodeContext());

        Node n1 = TestUtil.getNode(hz1);
        Node n2 = TestUtil.getNode(hz2);
        final Node n3 = TestUtil.getNode(hz3);

        final CountDownLatch splitLatch = new CountDownLatch(2);
        MembershipAdapter membershipAdapter = new MembershipAdapter() {
            @Override
            public void memberRemoved(MembershipEvent event) {
                if (n3.getLocalMember().equals(event.getMember())) {
                    splitLatch.countDown();
                }
            }
        };

        hz1.getCluster().addMembershipListener(membershipAdapter);
        hz2.getCluster().addMembershipListener(membershipAdapter);

        final CountDownLatch mergeLatch = new CountDownLatch(2);
        LifecycleListener lifecycleListener = new LifecycleListener() {
            @Override
            public void stateChanged(LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGED) {
                    mergeLatch.countDown();
                }
            }
        };
        hz1.getLifecycleService().addLifecycleListener(lifecycleListener);
        hz2.getLifecycleService().addLifecycleListener(lifecycleListener);

        FirewallingTcpIpConnectionManager cm1 = getFireWalledConnectionManager(hz1);
        FirewallingTcpIpConnectionManager cm2 = getFireWalledConnectionManager(hz2);
        FirewallingTcpIpConnectionManager cm3 = getFireWalledConnectionManager(hz3);

        cm3.block(n1.address);
        cm3.block(n2.address);

        n1.clusterService.removeAddress(n3.address);
        n2.clusterService.removeAddress(n3.address);
        cm1.block(n3.address);
        cm2.block(n3.address);

        assertTrue(splitLatch.await(20, TimeUnit.SECONDS));
        assertEquals(2, hz1.getCluster().getMembers().size());
        assertEquals(2, hz2.getCluster().getMembers().size());
        assertEquals(3, hz3.getCluster().getMembers().size());

        cm3.unblock(n1.address);
        cm1.unblock(n3.address);
        cm2.unblock(n3.address);

        assertTrue(mergeLatch.await(60, TimeUnit.SECONDS));
        assertEquals(3, hz1.getCluster().getMembers().size());
        assertEquals(3, hz2.getCluster().getMembers().size());
        assertEquals(3, hz3.getCluster().getMembers().size());

        assertEquals(n3.getThisAddress(), n1.getMasterAddress());
        assertEquals(n3.getThisAddress(), n2.getMasterAddress());
        assertEquals(n3.getThisAddress(), n3.getMasterAddress());
    }


    @Test
    public void testClusterMerge_when_split_not_detected_by_slave_and_restart_during_merge() throws InterruptedException {
        Config config = new Config();
        String groupName = generateRandomString(10);
        config.getGroupConfig().setName(groupName);
        config.setProperty(GroupProperties.PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "10");
        config.setProperty(GroupProperties.PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "10");

        config.setProperty(GroupProperties.PROP_MAX_JOIN_SECONDS, "40");
        config.setProperty(GroupProperties.PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "10");

        NetworkConfig networkConfig = config.getNetworkConfig();
        networkConfig.getJoin().getMulticastConfig().setEnabled(false);
        networkConfig.getJoin().getTcpIpConfig()
                .setEnabled(true).addMember("127.0.0.1:5701").addMember("127.0.0.1:5702").addMember("127.0.0.1:5703");

        networkConfig.setPort(5702);
        HazelcastInstance hz2 = newHazelcastInstance(config, "test-node2", new FirewallingNodeContext());
        networkConfig.setPort(5703);
        HazelcastInstance hz3 = newHazelcastInstance(config, "test-node3", new FirewallingNodeContext());
        networkConfig.setPort(5701);
        HazelcastInstance hz1 = newHazelcastInstance(config, "test-node1", new FirewallingNodeContext());

        final Node n1 = TestUtil.getNode(hz1);
        Node n2 = TestUtil.getNode(hz2);
        Node n3 = TestUtil.getNode(hz3);

        final CountDownLatch splitLatch = new CountDownLatch(2);
        MembershipAdapter membershipAdapter = new MembershipAdapter() {
            @Override
            public void memberRemoved(MembershipEvent event) {
                if (n1.getLocalMember().equals(event.getMember())) {
                    splitLatch.countDown();
                }
            }
        };

        hz2.getCluster().addMembershipListener(membershipAdapter);
        hz3.getCluster().addMembershipListener(membershipAdapter);

        final CountDownLatch mergingLatch = new CountDownLatch(1);
        final CountDownLatch mergeLatch = new CountDownLatch(2);
        LifecycleListener lifecycleListener = new LifecycleListener() {
            @Override
            public void stateChanged(LifecycleEvent event) {
                if (event.getState() == LifecycleState.MERGING) {
                    mergingLatch.countDown();
                }
                if (event.getState() == LifecycleState.MERGED) {
                    mergeLatch.countDown();
                }
            }
        };
        hz2.getLifecycleService().addLifecycleListener(lifecycleListener);
        hz3.getLifecycleService().addLifecycleListener(lifecycleListener);

        FirewallingTcpIpConnectionManager cm1 = getFireWalledConnectionManager(hz1);
        FirewallingTcpIpConnectionManager cm2 = getFireWalledConnectionManager(hz2);
        FirewallingTcpIpConnectionManager cm3 = getFireWalledConnectionManager(hz3);

        cm1.block(n2.address);
        cm1.block(n3.address);

        n2.clusterService.removeAddress(n1.address);
        n3.clusterService.removeAddress(n1.address);
        cm2.block(n1.address);
        cm3.block(n1.address);

        assertTrue(splitLatch.await(20, TimeUnit.SECONDS));
        assertEquals(2, hz2.getCluster().getMembers().size());
        assertEquals(2, hz3.getCluster().getMembers().size());
        assertEquals(3, hz1.getCluster().getMembers().size());

        cm1.unblock(n2.address);
        cm2.unblock(n1.address);
        cm3.unblock(n1.address);

        assertTrue(mergingLatch.await(60, TimeUnit.SECONDS));
        Thread.sleep(2700);
        hz1.getLifecycleService().terminate();
        hz1 = newHazelcastInstance(config, "test-node1", new FirewallingNodeContext());
        Node node1 = TestUtil.getNode(hz1);

        assertTrue(mergeLatch.await(60, TimeUnit.SECONDS));
        assertEquals(3, hz1.getCluster().getMembers().size());
        assertEquals(3, hz2.getCluster().getMembers().size());
        assertEquals(3, hz3.getCluster().getMembers().size());

        assertEquals(n3.getThisAddress(), node1.getMasterAddress());
        assertEquals(n3.getThisAddress(), n2.getMasterAddress());
        assertEquals(n3.getThisAddress(), n3.getMasterAddress());
    }

    private static class FirewallingNodeContext extends DefaultNodeContext {
        @Override
        public ConnectionManager createConnectionManager(Node node, ServerSocketChannel serverSocketChannel) {
            NodeIOService ioService = new NodeIOService(node, node.nodeEngine);
            return new FirewallingTcpIpConnectionManager(node.loggingService,
                    node.getHazelcastThreadGroup(), ioService, serverSocketChannel);
        }
    }

    private static FirewallingTcpIpConnectionManager getFireWalledConnectionManager(HazelcastInstance hz) {
        return (FirewallingTcpIpConnectionManager) getConnectionManager(hz);
    }
}

<code block>


package com.hazelcast.test;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.AbstractJoiner;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.AddressPicker;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.NodeContext;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.IOService;
import com.hazelcast.nio.NodeIOService;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.executor.StripedRunnable;

import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.nio.channels.ServerSocketChannel;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.CopyOnWriteArraySet;

public final class TestNodeRegistry {

    private final ConcurrentMap<Address, NodeEngineImpl> nodes = new ConcurrentHashMap<Address, NodeEngineImpl>(10);
    private final Object joinerLock = new Object();
    private final CopyOnWriteArrayList<Address> joinAddresses;

    TestNodeRegistry(CopyOnWriteArrayList<Address> addresses) {
        this.joinAddresses = addresses;
    }

    public NodeContext createNodeContext(Address address) {
        return new MockNodeContext(joinAddresses, nodes, address, joinerLock);
    }

    public HazelcastInstance getInstance(Address address) {
        NodeEngineImpl nodeEngine = nodes.get(address);
        return nodeEngine != null && nodeEngine.isActive() ? nodeEngine.getHazelcastInstance() : null;
    }

    Collection<HazelcastInstance> getAllHazelcastInstances() {
        Collection<HazelcastInstance> all = new LinkedList<HazelcastInstance>();
        for (NodeEngineImpl nodeEngine : nodes.values()) {
            if (nodeEngine.isActive()) {
                all.add(nodeEngine.getHazelcastInstance());
            }
        }
        return all;
    }

    void shutdown() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            value.getHazelcastInstance().shutdown();
        }
    }

    void terminate() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            HazelcastInstance hz = value.getHazelcastInstance();
            hz.getLifecycleService().terminate();
        }
    }

    private static class MockNodeContext implements NodeContext {

        final CopyOnWriteArrayList<Address> joinAddresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Address thisAddress;
        final Object joinerLock;

        public MockNodeContext(CopyOnWriteArrayList<Address> addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Address thisAddress, Object joinerLock) {
            this.joinAddresses = addresses;
            this.nodes = nodes;
            this.thisAddress = thisAddress;
            this.joinerLock = joinerLock;
        }

        public AddressPicker createAddressPicker(Node node) {
            return new StaticAddressPicker(thisAddress);
        }

        public Joiner createJoiner(Node node) {
            return new MockJoiner(node, joinAddresses, nodes, joinerLock);
        }

        public ConnectionManager createConnectionManager(Node node, ServerSocketChannel serverSocketChannel) {
            NodeIOService ioService = new NodeIOService(node, node.nodeEngine);
            return new MockConnectionManager(ioService, nodes, node, joinerLock);
        }
    }

    private static class StaticAddressPicker implements AddressPicker {
        final Address thisAddress;

        private StaticAddressPicker(Address thisAddress) {
            this.thisAddress = thisAddress;
        }

        public void pickAddress() throws Exception {
        }

        public Address getBindAddress() {
            return thisAddress;
        }

        public Address getPublicAddress() {
            return thisAddress;
        }

        public ServerSocketChannel getServerSocketChannel() {
            return null;
        }
    }

    private static class MockJoiner extends AbstractJoiner {

        final CopyOnWriteArrayList<Address> joinAddresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Object joinerLock;

        MockJoiner(Node node, CopyOnWriteArrayList<Address> addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Object joinerLock) {
            super(node);
            this.joinAddresses = addresses;
            this.nodes = nodes;
            this.joinerLock = joinerLock;
        }

        public void doJoin() {
            NodeEngineImpl nodeEngine = null;
            synchronized (joinerLock) {
                for (Address address : joinAddresses) {
                    NodeEngineImpl ne = nodes.get(address);
                    if (ne != null && ne.getNode().isActive() && ne.getNode().joined()) {
                        nodeEngine = ne;
                        break;
                    }
                }
                Address master = null;
                if (nodeEngine != null) {
                    if (nodeEngine.getNode().isMaster()) {
                        master = nodeEngine.getThisAddress();
                    } else {
                        master = nodeEngine.getMasterAddress();
                    }
                }
                if (master == null) {
                    master = node.getThisAddress();
                }
                node.setMasterAddress(master);
                if (node.getMasterAddress().equals(node.getThisAddress())) {
                    node.setJoined();
                    node.setAsMaster();
                } else {
                    for (int i = 0; !node.joined() && i < 2000; i++) {
                        try {
                            node.clusterService.sendJoinRequest(node.getMasterAddress(), true);
                            Thread.sleep(50);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    if (!node.joined()) {
                        throw new AssertionError("Node[" + node.getThisAddress()
                                + "] should have been joined to " + node.getMasterAddress());
                    }
                }
            }
        }

        public void searchForOtherClusters() {
        }

        @Override
        public String getType() {
            return "mock";
        }

        public String toString() {
            return "MockJoiner";
        }

        @Override
        public void blacklist(Address address, boolean permanent) {
        }

        @Override
        public boolean unblacklist(Address address) {
            return false;
        }

        @Override
        public boolean isBlacklisted(Address address) {
            return false;
        }
    }

    private static class MockConnectionManager implements ConnectionManager {
        private final Set<ConnectionListener> connectionListeners = new CopyOnWriteArraySet<ConnectionListener>();
        private final IOService ioService;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Map<Address, MockConnection> mapConnections = new ConcurrentHashMap<Address, MockConnection>(10);
        final Node node;
        final Object joinerLock;

        MockConnectionManager(IOService ioService, ConcurrentMap<Address, NodeEngineImpl> nodes,
                              Node node, Object joinerLock) {
            this.ioService = ioService;
            this.nodes = nodes;
            this.node = node;
            this.joinerLock = joinerLock;
            synchronized (this.joinerLock) {
                this.nodes.put(node.getThisAddress(), node.nodeEngine);
            }
        }

      @Override
      public Connection getConnection(Address address) {
            MockConnection conn = mapConnections.get(address);
            if (conn == null) {
                NodeEngineImpl nodeEngine = nodes.get(address);
                MockConnection thisConnection = new MockConnection(address, node.getThisAddress(), node.nodeEngine);
                conn = new MockConnection(node.getThisAddress(), address, nodeEngine);
                conn.localConnection = thisConnection;
                thisConnection.localConnection = conn;
                mapConnections.put(address, conn);
            }
            return conn;
        }

        @Override
        public Connection getOrConnect(Address address) {
            return getConnection(address);
        }

        @Override
        public Connection getOrConnect(Address address, boolean silent) {
            return getConnection(address);
        }

        @Override
        public void shutdown() {
            for (Address address : nodes.keySet()) {
                if (address.equals(node.getThisAddress())) continue;

                final NodeEngineImpl nodeEngine = nodes.get(address);
                if (nodeEngine != null && nodeEngine.isActive()) {
                    nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                        public void run() {
                            final ClusterServiceImpl clusterService = (ClusterServiceImpl) nodeEngine.getClusterService();
                            clusterService.removeAddress(node.getThisAddress());
                        }
                    });
                }
            }
        }

        @Override
        public boolean registerConnection(final Address remoteEndpoint, final Connection connection) {
            mapConnections.put(remoteEndpoint, (MockConnection) connection);
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionAdded(connection);
                    }
                }

                @Override
                public int getKey() {
                    return remoteEndpoint.hashCode();
                }
            });
            return true;
        }

        @Override
        public void start() {
        }

        @Override
        public void addConnectionListener(ConnectionListener connectionListener) {
            connectionListeners.add(connectionListener);
        }

        public void destroyConnection(final Connection connection) {
            final Address endPoint = connection.getEndPoint();
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionRemoved(connection);
                    }
                }

                @Override
                public int getKey() {
                    return endPoint.hashCode();
                }
            });
        }

        @Override
        public void stop() {
        }

        @Override
        public int getActiveConnectionCount() {
            return 0;
        }

        @Override
        public int getCurrentClientConnections() {
            return 0;
        }

        @Override
        public int getConnectionCount() {
            return 0;
        }

        @Override
        public int getAllTextConnections() {
            return 0;
        }
    }

    public static class MockConnection implements Connection {
        protected final Address localEndpoint;
        volatile Connection localConnection;
        final Address remoteEndpoint;
        protected final NodeEngineImpl nodeEngine;
        private volatile boolean live = true;

        public MockConnection(Address localEndpoint, Address remoteEndpoint, NodeEngineImpl nodeEngine) {
            this.localEndpoint = localEndpoint;
            this.remoteEndpoint = remoteEndpoint;
            this.nodeEngine = nodeEngine;
        }

        public Address getEndPoint() {
            return remoteEndpoint;
        }

        public boolean live() {
            return live;
        }

        public boolean write(SocketWritable socketWritable) {
            final Packet packet = (Packet) socketWritable;
            if (nodeEngine.getNode().isActive()) {
                Packet newPacket = readFromPacket(packet);
                MemberImpl member = nodeEngine.getClusterService().getMember(localEndpoint);
                if (member != null) {
                    member.didRead();
                }
                nodeEngine.getPacketTransceiver().receive(newPacket);
                return true;
            }
            return false;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }

            newPacket.setConn(localConnection);
            return newPacket;
        }

        public long lastReadTime() {
            return System.currentTimeMillis();
        }

        public long lastWriteTime() {
            return System.currentTimeMillis();
        }

        public void close() {
            if (!live) {
                return;
            }
            live = false;
            nodeEngine.getNode().connectionManager.destroyConnection(this);
        }

        public boolean isClient() {
            return false;
        }

        @Override
        public ConnectionType getType() {
            return ConnectionType.MEMBER;
        }

        public InetAddress getInetAddress() {
            try {
                return localEndpoint.getInetAddress();
            } catch (UnknownHostException e) {
                throw ExceptionUtil.rethrow(e);
            }
        }

        public InetSocketAddress getRemoteSocketAddress() {
            return new InetSocketAddress(getInetAddress(), getPort());
        }

        public int getPort() {
            return localEndpoint.getPort();
        }

        @Override
        public boolean isAlive() {
            return true;
        }

        @Override
        public String toString() {
            return "MockConnection{" +
                    "localEndpoint=" + localEndpoint +
                    ", remoteEndpoint=" + remoteEndpoint +
                    '}';
        }
    }
}

<code block>


package com.hazelcast.client.test;

import com.hazelcast.client.HazelcastClient;
import com.hazelcast.client.config.ClientAwsConfig;
import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.connection.AddressTranslator;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.connection.nio.ClientConnection;
import com.hazelcast.client.connection.nio.ClientConnectionManagerImpl;
import com.hazelcast.client.impl.ClientConnectionManagerFactory;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.spi.impl.AwsAddressTranslator;
import com.hazelcast.client.spi.impl.DefaultAddressTranslator;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.TestUtil;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.test.TestNodeRegistry;
import com.hazelcast.util.ExceptionUtil;

import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.util.logging.Level;

public class TestClientRegistry {

    private static final ILogger LOGGER = Logger.getLogger(HazelcastClient.class);
    private final TestNodeRegistry nodeRegistry;

    public TestClientRegistry(TestNodeRegistry nodeRegistry) {
        this.nodeRegistry = nodeRegistry;
    }


    ClientConnectionManagerFactory createClientServiceFactory(Address clientAddress) {
        return new MockClientConnectionManagerFactory(clientAddress);
    }

    private class MockClientConnectionManagerFactory implements ClientConnectionManagerFactory {

        private final Address clientAddress;

        public MockClientConnectionManagerFactory(Address clientAddress) {
            this.clientAddress = clientAddress;
        }

        @Override
        public ClientConnectionManager createConnectionManager(ClientConfig config, HazelcastClientInstanceImpl client) {
            final ClientAwsConfig awsConfig = config.getNetworkConfig().getAwsConfig();
            AddressTranslator addressTranslator;
            if (awsConfig != null && awsConfig.isEnabled()) {
                try {
                    addressTranslator = new AwsAddressTranslator(awsConfig);
                } catch (NoClassDefFoundError e) {
                    LOGGER.log(Level.WARNING, "hazelcast-cloud.jar might be missing!");
                    throw e;
                }
            } else {
                addressTranslator = new DefaultAddressTranslator();
            }
            return new MockClientConnectionManager(client, addressTranslator, clientAddress);
        }
    }


    private class MockClientConnectionManager extends ClientConnectionManagerImpl {

        private final Address clientAddress;
        private final HazelcastClientInstanceImpl client;

        public MockClientConnectionManager(HazelcastClientInstanceImpl client, AddressTranslator addressTranslator,
                                           Address clientAddress) {
            super(client, addressTranslator);
            this.client = client;
            this.clientAddress = clientAddress;
        }

        @Override
        protected void initializeSelectors(HazelcastClientInstanceImpl client) {

        }

        @Override
        protected void startSelectors() {

        }

        @Override
        protected void shutdownSelectors() {

        }

        @Override
        protected ClientConnection createSocketConnection(Address address) throws IOException {
            if (!alive) {
                throw new HazelcastException("ConnectionManager is not active!!!");
            }
            try {
                HazelcastInstance instance = nodeRegistry.getInstance(address);
                if (instance == null) {
                    throw new IOException("Can not connected to " + address + ": instance does not exist");
                }
                Node node = TestUtil.getNode(instance);
                return new MockedClientConnection(client, connectionIdGen.incrementAndGet(),
                        node.nodeEngine, address, clientAddress);
            } catch (Exception e) {
                throw ExceptionUtil.rethrow(e, IOException.class);
            }
        }


    }


    private class MockedClientConnection extends ClientConnection {
        private volatile long lastReadTime;
        private volatile long lastWriteTime;
        private final NodeEngineImpl serverNodeEngine;
        private final Address remoteAddress;
        private final Address localAddress;
        private final Connection serverSideConnection;

        public MockedClientConnection(HazelcastClientInstanceImpl client, int connectionId, NodeEngineImpl serverNodeEngine,
                                      Address address, Address localAddress) throws IOException {
            super(client, connectionId);
            this.serverNodeEngine = serverNodeEngine;
            this.remoteAddress = address;
            this.localAddress = localAddress;
            this.serverSideConnection = new MockedNodeConnection(connectionId, remoteAddress,
                    localAddress, serverNodeEngine, this);
        }

        void handlePacket(Packet packet) {
            lastReadTime = System.currentTimeMillis();
            getConnectionManager().handlePacket(packet);
        }

        @Override
        public boolean write(SocketWritable socketWritable) {
            Packet newPacket = readFromPacket((Packet) socketWritable);
            MemberImpl member = serverNodeEngine.getClusterService().getMember(remoteAddress);
            lastWriteTime = System.currentTimeMillis();
            if (member != null) {
                member.didRead();
            }
            serverNodeEngine.getNode().clientEngine.handlePacket(newPacket);
            return true;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }


            newPacket.setConn(serverSideConnection);
            return newPacket;
        }

        @Override
        public void init() throws IOException {

        }

        @Override
        public long lastReadTime() {
            return lastReadTime;
        }

        @Override
        public long lastWriteTime() {
            return lastWriteTime;
        }

        @Override
        public InetAddress getInetAddress() {
            try {
                return remoteAddress.getInetAddress();
            } catch (UnknownHostException e) {
                e.printStackTrace();
                return null;
            }
        }

        @Override
        public InetSocketAddress getRemoteSocketAddress() {
            try {
                return remoteAddress.getInetSocketAddress();
            } catch (UnknownHostException e) {
                e.printStackTrace();
                return null;
            }
        }

        @Override
        public int getPort() {
            return remoteAddress.getPort();
        }

        @Override
        public InetSocketAddress getLocalSocketAddress() {
            try {
                return localAddress.getInetSocketAddress();
            } catch (UnknownHostException e) {
                e.printStackTrace();
            }
            return null;
        }

        @Override
        protected void innerClose() throws IOException {
            serverSideConnection.close();
        }
    }

    private class MockedNodeConnection extends TestNodeRegistry.MockConnection {

        private final MockedClientConnection responseConnection;
        private final int connectionId;

        public MockedNodeConnection(int connectionId, Address localEndpoint, Address remoteEndpoint, NodeEngineImpl nodeEngine
                , MockedClientConnection responseConnection) {
            super(localEndpoint, remoteEndpoint, nodeEngine);
            this.responseConnection = responseConnection;
            this.connectionId = connectionId;
        }

        @Override
        public boolean write(SocketWritable socketWritable) {
            final Packet packet = (Packet) socketWritable;
            if (nodeEngine.getNode().isActive()) {
                Packet newPacket = readFromPacket(packet);
                MemberImpl member = nodeEngine.getClusterService().getMember(localEndpoint);
                if (member != null) {
                    member.didRead();
                }
                responseConnection.handlePacket(newPacket);
                return true;
            }
            return false;
        }

        @Override
        public boolean isClient() {
            return true;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }

            newPacket.setConn(responseConnection);
            return newPacket;
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (o == null || getClass() != o.getClass()) return false;

            MockedNodeConnection that = (MockedNodeConnection) o;

            if (connectionId != that.connectionId) return false;
            Address remoteEndpoint = getEndPoint();
            return !(remoteEndpoint != null ? !remoteEndpoint.equals(that.getEndPoint()) : that.getEndPoint() != null);

        }

        @Override
        public void close() {
            super.close();
            ClientConnectionManager connectionManager = responseConnection.getConnectionManager();
            connectionManager.destroyConnection(responseConnection);
        }

        @Override
        public int hashCode() {
            int result = connectionId;
            Address remoteEndpoint = getEndPoint();
            result = 31 * result + (remoteEndpoint != null ? remoteEndpoint.hashCode() : 0);
            return result;
        }

        @Override
        public ConnectionType getType() {
            return ConnectionType.JAVA_CLIENT;
        }

        @Override
        public String toString() {
            return "MockedNodeConnection{" +
                    " remoteEndpoint = " + getEndPoint() +
                    ", localEndpoint = " + localEndpoint +
                    ", connectionId = " + connectionId +
                    '}';
        }
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.annotation.Codec;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.map.impl.SimpleEntryView;
import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;

@Codec(SimpleEntryView.class)
public final class EntryViewCodec {

    private EntryViewCodec() {
    }

    public static SimpleEntryView<Data, Data> decode(ClientMessage clientMessage) {
        SimpleEntryView<Data, Data> dataEntryView = new SimpleEntryView<Data, Data>();
        dataEntryView.setKey(clientMessage.getData());
        dataEntryView.setValue(clientMessage.getData());
        dataEntryView.setCost(clientMessage.getLong());
        dataEntryView.setCreationTime(clientMessage.getLong());
        dataEntryView.setExpirationTime(clientMessage.getLong());
        dataEntryView.setHits(clientMessage.getLong());
        dataEntryView.setLastAccessTime(clientMessage.getLong());
        dataEntryView.setLastStoredTime(clientMessage.getLong());
        dataEntryView.setLastUpdateTime(clientMessage.getLong());
        dataEntryView.setVersion(clientMessage.getLong());
        dataEntryView.setEvictionCriteriaNumber(clientMessage.getLong());
        dataEntryView.setTtl(clientMessage.getLong());
        return dataEntryView;
    }

    public static void encode(SimpleEntryView<Data, Data> dataEntryView, ClientMessage clientMessage) {
        Data key = dataEntryView.getKey();
        Data value = dataEntryView.getValue();
        long cost = dataEntryView.getCost();
        long creationTime = dataEntryView.getCreationTime();
        long expirationTime = dataEntryView.getExpirationTime();
        long hits = dataEntryView.getHits();
        long lastAccessTime = dataEntryView.getLastAccessTime();
        long lastStoredTime = dataEntryView.getLastStoredTime();
        long lastUpdateTime = dataEntryView.getLastUpdateTime();
        long version = dataEntryView.getVersion();
        long ttl = dataEntryView.getTtl();
        long evictionCriteriaNumber = dataEntryView.getEvictionCriteriaNumber();

        clientMessage.set(key).set(value).set(cost).set(creationTime).set(expirationTime)
                .set(hits).set(lastAccessTime).set(lastStoredTime).set(lastUpdateTime)
                .set(version).set(evictionCriteriaNumber).set(ttl);
    }


    public static int calculateDataSize(SimpleEntryView<Data, Data> entryView) {
        int dataSize = ClientMessage.HEADER_SIZE;
        Data key = entryView.getKey();
        Data value = entryView.getValue();
        return dataSize
                + ParameterUtil.calculateDataSize(key)
                + ParameterUtil.calculateDataSize(value)
                + Bits.LONG_SIZE_IN_BYTES * 10;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.annotation.Codec;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.mapreduce.JobPartitionState;
import com.hazelcast.mapreduce.impl.task.JobPartitionStateImpl;
import com.hazelcast.nio.Address;

@Codec(JobPartitionState.class)
public class JobPartitionStateCodec {

    private JobPartitionStateCodec() {
    }

    public static JobPartitionState decode(ClientMessage clientMessage) {
        final Address address = AddressCodec.decode(clientMessage);
        String state = clientMessage.getStringUtf8();

        return new JobPartitionStateImpl(address, JobPartitionState.State.valueOf(state));
    }

    public static void encode(JobPartitionState jobPartitionState, ClientMessage clientMessage) {
        AddressCodec.encode(jobPartitionState.getOwner(), clientMessage);
        clientMessage.set(jobPartitionState.getState().name());
    }

    public static int calculateDataSize(JobPartitionState jobPartitionState) {
        int dataSize = AddressCodec.calculateDataSize(jobPartitionState.getOwner());
        dataSize += ParameterUtil.calculateDataSize(jobPartitionState.getState().name());
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.annotation.Codec;
import com.hazelcast.cache.impl.CacheEventData;
import com.hazelcast.cache.impl.CacheEventDataImpl;
import com.hazelcast.cache.impl.CacheEventType;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;

@Codec(CacheEventData.class)
public final class CacheEventDataCodec {

    private CacheEventDataCodec() {
    }

    public static CacheEventData decode(ClientMessage clientMessage) {
        int typeId = clientMessage.getInt();
        String name = clientMessage.getStringUtf8();
        Data key = clientMessage.getData();
        boolean value_isNull = clientMessage.getBoolean();
        Data value = null;
        if (!value_isNull) {
            value = clientMessage.getData();
        }

        boolean dataOldValue_isNull = clientMessage.getBoolean();
        Data oldValue = null;
        if (!dataOldValue_isNull) {
            oldValue = clientMessage.getData();
        }
        boolean isOldValueAvailable = clientMessage.getBoolean();
        return new CacheEventDataImpl(name, CacheEventType.getByType(typeId), key, value, oldValue, isOldValueAvailable);
    }

    public static void encode(CacheEventData cacheEventData, ClientMessage clientMessage) {
        clientMessage.set(cacheEventData.getCacheEventType().getType());
        clientMessage.set(cacheEventData.getName());
        clientMessage.set(cacheEventData.getDataKey());

        Data dataValue = cacheEventData.getDataValue();
        boolean dataValue_isNull = dataValue == null;
        clientMessage.set(dataValue_isNull);
        if (!dataValue_isNull) {
            clientMessage.set(dataValue);
        }
        Data dataOldValue = cacheEventData.getDataOldValue();
        boolean dataOldValue_isNull = dataOldValue == null;
        clientMessage.set(dataOldValue_isNull);
        if (!dataOldValue_isNull) {
            clientMessage.set(dataOldValue);
        }

        clientMessage.set(cacheEventData.isOldValueAvailable());
    }

    public static int calculateDataSize(CacheEventData cacheEventData) {
        int dataSize = Bits.INT_SIZE_IN_BYTES;
        dataSize += ParameterUtil.calculateDataSize(cacheEventData.getName());
        dataSize += ParameterUtil.calculateDataSize(cacheEventData.getDataKey());
        Data dataValue = cacheEventData.getDataValue();
        if (dataValue == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateDataSize(dataValue);
        }
        Data dataOldValue = cacheEventData.getDataOldValue();
        if (dataOldValue == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateDataSize(dataOldValue);
        }
        dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.annotation.Codec;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Bits;

import java.net.UnknownHostException;

@Codec(Address.class)
public final class AddressCodec {

    private AddressCodec() {
    }

    public static Address decode(ClientMessage clientMessage) {
        String host = clientMessage.getStringUtf8();
        int port = clientMessage.getInt();
        try {
            return new Address(host, port);
        } catch (UnknownHostException e) {
            return null;
        }
    }

    public static void encode(Address address, ClientMessage clientMessage) {
        clientMessage.set(address.getHost()).set(address.getPort());
    }

    public static int calculateDataSize(Address address) {
        int dataSize = ParameterUtil.calculateDataSize(address.getHost());
        dataSize += Bits.INT_SIZE_IN_BYTES;
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.annotation.Codec;
import com.hazelcast.client.impl.client.DistributedObjectInfo;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;

@Codec(DistributedObjectInfo.class)
public final class DistributedObjectInfoCodec {

    private DistributedObjectInfoCodec() {
    }

    public static DistributedObjectInfo decode(ClientMessage clientMessage) {
        String serviceName = clientMessage.getStringUtf8();
        String name = clientMessage.getStringUtf8();
        return new DistributedObjectInfo(serviceName, name);
    }

    public static void encode(DistributedObjectInfo info, ClientMessage clientMessage) {
        clientMessage.
                set(info.getServiceName()).
                set(info.getName());
    }

    public static int calculateDataSize(DistributedObjectInfo info) {
        return ParameterUtil.calculateDataSize(info.getServiceName())
                + ParameterUtil.calculateDataSize(info.getName());
    }
}


<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.annotation.Codec;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.nio.Bits;
import com.hazelcast.transaction.impl.xa.SerializableXID;

import javax.transaction.xa.Xid;

@Codec(Xid.class)
public final class XIDCodec {

    private XIDCodec() {
    }

    public static Xid decode(ClientMessage clientMessage) {
        int formatId = clientMessage.getInt();
        byte[] globalTransactionId = clientMessage.getByteArray();
        byte[] branchQualifier = clientMessage.getByteArray();
        return new SerializableXID(formatId, globalTransactionId, branchQualifier);

    }

    public static void encode(Xid xid, ClientMessage clientMessage) {
        clientMessage.set(xid.getFormatId());
        clientMessage.set(xid.getGlobalTransactionId());
        clientMessage.set(xid.getBranchQualifier());
    }

    public static int calculateDataSize(Xid xid) {
        int dataSize = 0;
        dataSize += Bits.INT_SIZE_IN_BYTES;
        dataSize += ParameterUtil.calculateDataSize(xid.getGlobalTransactionId());
        dataSize += ParameterUtil.calculateDataSize(xid.getBranchQualifier());
        return dataSize;
    }
}


<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.annotation.Codec;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.core.Member;
import com.hazelcast.instance.AbstractMember;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Bits;

import java.util.HashMap;
import java.util.Map;

@Codec(Member.class)
public final class MemberCodec {

    private MemberCodec() {
    }

    public static Member decode(ClientMessage clientMessage) {
        final Address address = AddressCodec.decode(clientMessage);
        String uuid = clientMessage.getStringUtf8();
        int attributeSize = clientMessage.getInt();
        Map<String, Object> attributes = new HashMap<String, Object>();
        for (int i = 0; i < attributeSize; i++) {
            String key = clientMessage.getStringUtf8();
            String value = clientMessage.getStringUtf8();
            attributes.put(key, value);
        }

        return new com.hazelcast.client.impl.MemberImpl(address, uuid, attributes);
    }

    public static void encode(Member member, ClientMessage clientMessage) {
        AddressCodec.encode(((AbstractMember) member).getAddress(), clientMessage);
        clientMessage.set(member.getUuid());
        Map<String, Object> attributes = new HashMap<String, Object>(member.getAttributes());
        clientMessage.set(attributes.size());
        for (Map.Entry<String, Object> entry : attributes.entrySet()) {
            clientMessage.set(entry.getKey());
            Object value = entry.getValue();
            clientMessage.set(value.toString());

        }
    }

    public static int calculateDataSize(Member member) {
        int dataSize = AddressCodec.calculateDataSize(((AbstractMember) member).getAddress());
        dataSize += ParameterUtil.calculateDataSize(member.getUuid());
        dataSize += Bits.INT_SIZE_IN_BYTES;
        Map<String, Object> attributes = member.getAttributes();
        for (Map.Entry<String, Object> entry : attributes.entrySet()) {
            dataSize += ParameterUtil.calculateDataSize(entry.getKey());
            Object value = entry.getValue();
            
            dataSize += ParameterUtil.calculateDataSize(value.toString());
        }
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.annotation.Codec;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.cluster.MemberAttributeOperationType;
import com.hazelcast.cluster.client.MemberAttributeChange;
import com.hazelcast.nio.Bits;

import static com.hazelcast.cluster.MemberAttributeOperationType.PUT;

@Codec(MemberAttributeChange.class)
public final class MemberAttributeChangeCodec {

    private MemberAttributeChangeCodec() {
    }

    public static MemberAttributeChange decode(ClientMessage clientMessage) {
        String uuid = clientMessage.getStringUtf8();
        String key = clientMessage.getStringUtf8();
        MemberAttributeOperationType operationType = MemberAttributeOperationType.getValue(clientMessage.getInt());
        Object value = null;
        if (operationType == PUT) {
            value = clientMessage.getStringUtf8();
        }
        return new MemberAttributeChange(uuid, operationType, key, value);
    }

    public static void encode(MemberAttributeChange memberAttributeChange, ClientMessage clientMessage) {
        clientMessage.set(memberAttributeChange.getUuid());
        clientMessage.set(memberAttributeChange.getKey());

        MemberAttributeOperationType operationType = memberAttributeChange.getOperationType();
        clientMessage.set(operationType.getId());
        if (operationType == PUT) {
            clientMessage.set(memberAttributeChange.getValue().toString());
        }
    }

    public static int calculateDataSize(MemberAttributeChange memberAttributeChange) {
        if (memberAttributeChange == null) {
            return Bits.BOOLEAN_SIZE_IN_BYTES;
        }
        int dataSize = ParameterUtil.calculateDataSize(memberAttributeChange.getUuid());
        dataSize += ParameterUtil.calculateDataSize(memberAttributeChange.getKey());
        
        dataSize += Bits.INT_SIZE_IN_BYTES;
        MemberAttributeOperationType operationType = memberAttributeChange.getOperationType();
        if (operationType == PUT) {
            dataSize += ParameterUtil.calculateDataSize(memberAttributeChange.getValue().toString());
        }
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.parameters;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.ResponseMessageConst;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.nio.Bits;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;


@SuppressFBWarnings(value = "URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD",
        justification = "fields may be needed for diagnostic")
public class ExceptionResultParameters {

    
    public static final int TYPE = ResponseMessageConst.EXCEPTION;
    public String className;
    public String causeClassName;
    public String message;
    public String stacktrace;

    private ExceptionResultParameters(ClientMessage flyweight) {
        className = flyweight.getStringUtf8();
        boolean causeClassName_isNull = flyweight.getBoolean();
        if (!causeClassName_isNull) {
            causeClassName = flyweight.getStringUtf8();
        }
        boolean message_isNull = flyweight.getBoolean();
        if (!message_isNull) {
            message = flyweight.getStringUtf8();
        }
        boolean stackTrace_isNull = flyweight.getBoolean();
        if (!stackTrace_isNull) {
            stacktrace = flyweight.getStringUtf8();
        }
    }

    public static ExceptionResultParameters decode(ClientMessage flyweight) {
        return new ExceptionResultParameters(flyweight);
    }

    public static ClientMessage encode(String className, String causeClassName, String message, String stacktrace) {
        final int requiredDataSize = calculateDataSize(className, causeClassName, message, stacktrace);
        ClientMessage clientMessage = ClientMessage.createForEncode(requiredDataSize);
        clientMessage.setMessageType(TYPE);
        clientMessage.set(className);
        boolean causeClassName_isNull = causeClassName == null;
        clientMessage.set(causeClassName_isNull);
        if (!causeClassName_isNull) {
            clientMessage.set(causeClassName);
        }
        boolean message_isNull = message == null;
        clientMessage.set(message_isNull);
        if (!message_isNull) {
            clientMessage.set(message);
        }
        boolean stackTrace_isNull = stacktrace == null;
        clientMessage.set(stackTrace_isNull);
        if (!stackTrace_isNull) {
            clientMessage.set(stacktrace);
        }

        clientMessage.updateFrameLength();
        return clientMessage;
    }

    
    public static int calculateDataSize(String className, String causeClassName, String message, String stacktrace) {
        int dataSize = ClientMessage.HEADER_SIZE + ParameterUtil.calculateDataSize(className);
        if (causeClassName == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateDataSize(causeClassName);
        }
        if (message == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateDataSize(message);
        }
        if (stacktrace == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateDataSize(stacktrace);
        }
        return dataSize;
    }

}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;

public final class ParameterUtil {

    private static final int UTF8_MAX_BYTES_PER_CHAR = 3;

    private ParameterUtil() { }

    public static int calculateDataSize(String string) {
        return Bits.INT_SIZE_IN_BYTES + string.length() * UTF8_MAX_BYTES_PER_CHAR;
    }

    public static int calculateDataSize(Data data) {
        return calculateDataSize(data.toByteArray());
    }

    public static int calculateDataSize(byte[] bytes) {
        return Bits.INT_SIZE_IN_BYTES + bytes.length;
    }

    public static int calculateDataSize(Integer data) {
        return Bits.INT_SIZE_IN_BYTES;
    }

    public static int calculateDataSize(Boolean data) {
        return Bits.BOOLEAN_SIZE_IN_BYTES;
    }
}

<code block>
package com.hazelcast.client.protocol;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ClientProtocolBuffer;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.client.impl.protocol.util.SafeBuffer;
import com.hazelcast.nio.Bits;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.io.IOException;
import java.io.UnsupportedEncodingException;
import java.nio.ByteBuffer;

import static org.hamcrest.core.Is.is;
import static org.junit.Assert.assertArrayEquals;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertThat;


@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class ClientMessageTest {

    private static final String DEFAULT_ENCODING = "UTF8";

    private static final String VAR_DATA_STR_1 = "abcdef";

    private static final byte[] BYTE_DATA = VAR_DATA_STR_1.getBytes();

    @Before
    public void setUp() {
    }

    @After
    public void tearDown() {
    }

    @Test
    public void shouldEncodeClientMessageCorrectly() {
        ByteBuffer byteBuffer = ByteBuffer.allocate(512);
        SafeBuffer safeBuffer = new SafeBuffer(byteBuffer.array());

        ClientMessage cmEncode = TestClientMessage.createForEncode(safeBuffer, 0);

        cmEncode.setMessageType(0x1122).setVersion((short) 0xEF).addFlag(ClientMessage.BEGIN_AND_END_FLAGS).setCorrelationId(0x12345678)
                .setPartitionId(0x11223344);

        
        
        assertThat(byteBuffer.get(0), is((byte) ClientMessage.HEADER_SIZE));
        assertThat(byteBuffer.get(1), is((byte) 0));
        assertThat(byteBuffer.get(2), is((byte) 0));
        assertThat(byteBuffer.get(3), is((byte) 0));

        
        assertThat(byteBuffer.get(4), is((byte) 0xEF));

        
        assertThat(byteBuffer.get(5), is((byte) 0xC0));

        
        assertThat(byteBuffer.get(6), is((byte) 0x22));
        assertThat(byteBuffer.get(7), is((byte) 0x11));

        
        assertThat(byteBuffer.get(8), is((byte) 0x78));
        assertThat(byteBuffer.get(9), is((byte) 0x56));
        assertThat(byteBuffer.get(10), is((byte) 0x34));
        assertThat(byteBuffer.get(11), is((byte) 0x12));

        
        assertThat(byteBuffer.get(12), is((byte) 0x44));
        assertThat(byteBuffer.get(13), is((byte) 0x33));
        assertThat(byteBuffer.get(14), is((byte) 0x22));
        assertThat(byteBuffer.get(15), is((byte) 0x11));

        
        assertThat(byteBuffer.get(16), is((byte) ClientMessage.HEADER_SIZE));
        assertThat(byteBuffer.get(17), is((byte) 0x00));

    }

    @Test
    public void shouldEncodeAndDecodeClientMessageCorrectly() {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[512]);

        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, 0);

        cmEncode.setMessageType(7)
                .setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        ClientMessage cmDecode = ClientMessage.createForDecode(byteBuffer, 0);

        assertEquals(7, cmDecode.getMessageType());
        assertEquals(3, cmDecode.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode.getFlags());
        assertEquals(66, cmDecode.getCorrelationId());
        assertEquals(77, cmDecode.getPartitionId());
        assertEquals(ClientMessage.HEADER_SIZE, cmDecode.getFrameLength());
    }

    @Test
    public void shouldEncodeAndDecodeClientMessageCorrectly_withPayLoadData()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[1024]);

        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, 0);

        cmEncode.setMessageType(7)
                .setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        final byte[] data1 = VAR_DATA_STR_1.getBytes(DEFAULT_ENCODING);
        final int calculatedFrameSize = ClientMessage.HEADER_SIZE + ParameterUtil.calculateDataSize(data1);
        cmEncode.set(data1);
        cmEncode.updateFrameLength();

        ClientMessage cmDecode = ClientMessage.createForDecode(byteBuffer, 0);

        byte[] cmDecodeVarData1 = cmDecode.getByteArray();

        assertEquals(calculatedFrameSize, cmDecode.getFrameLength());
        assertArrayEquals(cmDecodeVarData1, data1);
    }


    @Test
    public void shouldEncodeAndDecodeClientMessageCorrectly_withPayLoadData_fromOffset()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[150]);
        int offset = 100;

        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, offset);

        cmEncode.setMessageType(7)
                .setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        byte[] bytes = VAR_DATA_STR_1.getBytes();
        final int calculatedFrameSize = ClientMessage.HEADER_SIZE + Bits.INT_SIZE_IN_BYTES +
                ParameterUtil.calculateDataSize(bytes);
        cmEncode.set(1);
        cmEncode.set(bytes);
        cmEncode.updateFrameLength();

        ClientMessage cmDecode = ClientMessage.createForDecode(byteBuffer, offset);

        assertEquals(1, cmDecode.getInt());
        assertArrayEquals(bytes, cmDecode.getByteArray());

        assertEquals(calculatedFrameSize, cmDecode.getFrameLength());
    }

    @Test
    public void shouldEncodeWithNewVersionAndDecodeWithOldVersionCorrectly_withPayLoadData()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[1024]);

        FutureClientMessage cmEncode = new FutureClientMessage();
        cmEncode.wrapForEncode(byteBuffer, 0);

        cmEncode.theNewField(999)
                .setMessageType(7).setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        final int calculatedFrameSize = FutureClientMessage.THE_NEW_HEADER_SIZE
                + ParameterUtil.calculateDataSize(BYTE_DATA);
        cmEncode.set(BYTE_DATA);
        cmEncode.updateFrameLength();

        ClientMessage cmDecode = ClientMessage.createForDecode(byteBuffer, 0);

        final byte[] cmDecodeVarData1 = cmDecode.getByteArray();

        assertEquals(7, cmDecode.getMessageType());
        assertEquals(3, cmDecode.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode.getFlags());
        assertEquals(66, cmDecode.getCorrelationId());
        assertEquals(77, cmDecode.getPartitionId());
        assertEquals(calculatedFrameSize, cmDecode.getFrameLength());
        assertArrayEquals(cmDecodeVarData1, BYTE_DATA);
    }

    @Test
    public void shouldEncodeWithOldVersionAndDecodeWithNewVersionCorrectly_withPayLoadData()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[1024]);

        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, 0);

        cmEncode.setMessageType(7).setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        final int calculatedFrameSize = ClientMessage.HEADER_SIZE
                + ParameterUtil.calculateDataSize(BYTE_DATA);
        cmEncode.set(BYTE_DATA);
        cmEncode.updateFrameLength();
        ClientMessage cmDecode = FutureClientMessage.createForDecode(byteBuffer, 0);

        final byte[] cmDecodeVarData1 = cmDecode.getByteArray();

        assertEquals(7, cmDecode.getMessageType());
        assertEquals(3, cmDecode.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode.getFlags());
        assertEquals(66, cmDecode.getCorrelationId());
        assertEquals(77, cmDecode.getPartitionId());
        assertEquals(calculatedFrameSize, cmDecode.getFrameLength());
        assertArrayEquals(cmDecodeVarData1, BYTE_DATA);
    }

    @Test
    public void shouldEncodeAndDecodeClientMessageCorrectly_withPayLoadData_multipleMessages()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[1024]);
        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, 0);
        cmEncode.setMessageType(7).setVersion((short) 3).addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(1).setPartitionId(77);
        cmEncode.set(BYTE_DATA);
        cmEncode.updateFrameLength();
        final int calculatedFrame1Size = ClientMessage.HEADER_SIZE
                + ParameterUtil.calculateDataSize(BYTE_DATA);

        final int nexMessageOffset = cmEncode.getFrameLength();
        ClientMessage cmEncode2 =
                TestClientMessage.createForEncode(byteBuffer, nexMessageOffset);

        cmEncode2.setMessageType(7).setVersion((short) 3).addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(2).setPartitionId(77);
        cmEncode2.set(BYTE_DATA);
        cmEncode2.updateFrameLength();
        final int calculatedFrame2Size = ClientMessage.HEADER_SIZE
                + ParameterUtil.calculateDataSize(BYTE_DATA);

        ClientMessage cmDecode1 = ClientMessage.createForDecode(byteBuffer, 0);

        final byte[] cmDecodeVarData = cmDecode1.getByteArray();

        assertEquals(7, cmDecode1.getMessageType());
        assertEquals(3, cmDecode1.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode1.getFlags());
        assertEquals(1, cmDecode1.getCorrelationId());
        assertEquals(77, cmDecode1.getPartitionId());
        assertEquals(calculatedFrame1Size, cmDecode1.getFrameLength());
        assertArrayEquals(cmDecodeVarData, BYTE_DATA);

        ClientMessage cmDecode2 = ClientMessage.createForDecode(byteBuffer, cmDecode1.getFrameLength());
        byte[] cmDecodeVarData2 = cmDecode2.getByteArray();

        assertEquals(7, cmDecode2.getMessageType());
        assertEquals(3, cmDecode2.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode2.getFlags());
        assertEquals(2, cmDecode2.getCorrelationId());
        assertEquals(77, cmDecode2.getPartitionId());
        assertEquals(calculatedFrame2Size, cmDecode2.getFrameLength());
        assertArrayEquals(cmDecodeVarData2, BYTE_DATA);
    }

    private static class FutureClientMessage extends TestClientMessage {

        private static final int THE_NEW_FIELD_OFFSET = HEADER_SIZE + Bits.SHORT_SIZE_IN_BYTES;
        private static final int THE_NEW_HEADER_SIZE = HEADER_SIZE + Bits.INT_SIZE_IN_BYTES;

        @Override
        protected void wrapForEncode(ClientProtocolBuffer buffer, int offset) {
            super.wrap(buffer, offset);
            setDataOffset(THE_NEW_HEADER_SIZE);
            setFrameLength(THE_NEW_HEADER_SIZE);
            index(getDataOffset());
        }

        public int theNewField() {
            return (int) uint32Get(THE_NEW_FIELD_OFFSET);
        }

        public FutureClientMessage theNewField(int value) {
            uint32Put(THE_NEW_FIELD_OFFSET, value);
            return this;
        }
    }

    private static class TestClientMessage extends ClientMessage {

        @Override
        public ClientMessage setMessageType(int type) {
            return super.setMessageType(type);
        }
    }

    @Test
    public void test_empty_toString() {
        new ClientMessage().toString();
    }

    @Test(expected = IndexOutOfBoundsException.class)
    public void test_byteArray_constructor_withSmallBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[10]), 1);
    }

    @Test
    public void test_byteArray_constructor_withHeaderSizeBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[ClientMessage.HEADER_SIZE]), 0);
    }

    @Test
    public void test_byteArray_constructor_withLargeBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[100]), 10);
    }

    @Test(expected = IndexOutOfBoundsException.class)
    public void test_MutableDirectBuffer_constructor_withSmallBuffer() {
        SafeBuffer buffer = new SafeBuffer(new byte[10]);
        ClientMessage.createForEncode(buffer, 1);
    }

    @Test
    public void test_MutableDirectBuffer_constructor_withHeaderSizeBuffer() {
        SafeBuffer buffer = new SafeBuffer(new byte[ClientMessage.HEADER_SIZE]);
        ClientMessage.createForEncode(buffer, 0);
    }

    @Test
    public void test_MutableDirectBuffer_constructor_withLargeBuffer() {
        SafeBuffer buffer = new SafeBuffer(new byte[100]);
        ClientMessage.createForEncode(buffer, 10);
    }

    @Test(expected = IndexOutOfBoundsException.class)
    public void test_wrapForEncode_withSmallBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[10]), 1);
    }

    @Test
    public void test_wrapForEncode_withHeaderSizeBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[ClientMessage.HEADER_SIZE]), 0);
    }

    @Test
    public void test_wrapForEncode_withLargeBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[100]), 10);
    }

    @Test(expected = IndexOutOfBoundsException.class)
    public void test_wrapForDecode_withSmallBuffer() {
        ClientMessage.createForDecode(new SafeBuffer(new byte[10]), 1);
    }

    @Test
    public void test_wrapForDecode_withHeaderSizeBuffer() {
        ClientMessage.createForDecode(new SafeBuffer(new byte[ClientMessage.HEADER_SIZE]), 0);
    }

    @Test
    public void test_wrapForDecode_withLargeBuffer() {
        ClientMessage.createForDecode(new SafeBuffer(new byte[100]), 10);
    }

    @Test
    public void testUnsignedFields() throws IOException {
        ClientProtocolBuffer buffer = new SafeBuffer(new byte[18]);

        ClientMessage cmEncode = ClientMessage.createForEncode(buffer, 0);

        cmEncode.setVersion((short) (Byte.MAX_VALUE + 10));
        cmEncode.setMessageType(Short.MAX_VALUE + 10);
        cmEncode.setDataOffset((int) Short.MAX_VALUE + 10);
        cmEncode.setCorrelationId(Short.MAX_VALUE + 10);

        ClientMessage cmDecode = ClientMessage.createForDecode(buffer, 0);

        assertEquals(Byte.MAX_VALUE + 10, cmDecode.getVersion());
        assertEquals(Short.MAX_VALUE + 10, cmDecode.getMessageType());
        assertEquals((int) Short.MAX_VALUE + 10, cmDecode.getDataOffset());

    }

}

<code block>


package com.hazelcast.annotation;

import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;


@Retention(RetentionPolicy.SOURCE)
@Target(ElementType.TYPE)
public @interface Codec {

    
    Class value();

}


<code block>


package com.hazelcast.client.protocol.generator;


public enum Lang {

    
    JAVA,

    
    CSHARP,

    
    CPP,

    
    DOC
}

<code block>


package com.hazelcast.client.protocol.generator;

import com.hazelcast.annotation.EventResponse;
import com.hazelcast.annotation.GenerateCodec;
import com.hazelcast.annotation.Nullable;
import com.hazelcast.annotation.Request;

import javax.lang.model.element.ExecutableElement;
import javax.lang.model.element.TypeElement;
import javax.lang.model.element.VariableElement;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;

import static com.hazelcast.client.protocol.generator.CodeGenerationUtils.convertTypeToCSharp;

public class CodecModel {

    static final Map<String, TypeElement> CUSTOM_CODEC_MAP = new HashMap<String, TypeElement>();

    private final Lang lang;
    private String name;
    private String className;
    private String parentName;
    private String packageName;

    private int retryable;
    private int response;

    private final List<ParameterModel> requestParams = new LinkedList();
    private final List<ParameterModel> responseParams = new LinkedList();
    private final List<EventModel> events = new LinkedList();

    
    public CodecModel(boolean mockup) {
        this.retryable = 1;
        this.lang = Lang.JAVA;

        name = "put";
        parentName = "Map";
        className =
                CodeGenerationUtils.capitalizeFirstLetter(parentName) + CodeGenerationUtils.capitalizeFirstLetter(name) + "Codec";
        packageName = "com.hazelcast.client.impl.protocol.codec";

        response = 104;

        

        ParameterModel pm = new ParameterModel();
        pm.name = "name";
        pm.type = "java.lang.String";
        pm.lang = Lang.JAVA;
        pm.nullable = true;
        requestParams.add(pm);

        pm = new ParameterModel();
        pm.name = "val";
        pm.type = "int";
        pm.lang = Lang.JAVA;
        pm.nullable = false;
        requestParams.add(pm);

        pm = new ParameterModel();
        pm.name = "address";
        pm.type = "com.hazelcast.nio.Address";
        pm.lang = Lang.JAVA;
        pm.nullable = false;
        requestParams.add(pm);

        pm = new ParameterModel();
        pm.name = "arr";
        pm.type = "int[]";
        pm.lang = Lang.JAVA;
        pm.nullable = false;
        requestParams.add(pm);

        pm = new ParameterModel();
        pm.name = "setD";
        pm.type = "java.util.Set<" + CodeGenerationUtils.DATA_FULL_NAME + ">";
        pm.lang = Lang.JAVA;
        pm.nullable = false;
        requestParams.add(pm);

        pm = new ParameterModel();
        pm.name = "mapIS";
        pm.type = "java.util.Map<java.lang.Integer, java.lang.String>";
        pm.lang = Lang.JAVA;
        pm.nullable = false;
        requestParams.add(pm);

        pm = new ParameterModel();
        pm.name = "mapDD";
        pm.type = "java.util.Map<" + CodeGenerationUtils.DATA_FULL_NAME + ", " + CodeGenerationUtils.DATA_FULL_NAME + ">";
        pm.lang = Lang.JAVA;
        pm.nullable = false;
        requestParams.add(pm);

        pm = new ParameterModel();
        pm.name = "entryView";
        pm.type = "com.hazelcast.map.impl.SimpleEntryView<" + CodeGenerationUtils.DATA_FULL_NAME + ", "
                + CodeGenerationUtils.DATA_FULL_NAME + ">";
        pm.lang = Lang.JAVA;
        pm.nullable = true;
        requestParams.add(pm);

        
        pm = new ParameterModel();
        pm.name = "name";
        pm.type = "long";
        pm.lang = Lang.JAVA;
        pm.nullable = false;
        responseParams.add(pm);

        EventModel eventModel = new EventModel();
        eventModel.type = 104;
        eventModel.name = "";

        List<ParameterModel> eventParam = new ArrayList<ParameterModel>();
        pm = new ParameterModel();
        pm.name = "name";
        pm.type = "java.lang.String";
        pm.lang = Lang.JAVA;
        pm.nullable = true;
        eventParam.add(pm);
        eventModel.eventParams = eventParam;
        events.add(eventModel);
    }

    public CodecModel(TypeElement parent, ExecutableElement methodElement, ExecutableElement responseElement,
                      List<ExecutableElement> eventElementList, boolean retryable, Lang lang) {
        this.retryable = retryable ? 1 : 0;
        this.lang = lang;

        name = methodElement.getSimpleName().toString();
        parentName = parent.getAnnotation(GenerateCodec.class).name();
        className =
                CodeGenerationUtils.capitalizeFirstLetter(parentName) + CodeGenerationUtils.capitalizeFirstLetter(name) + "Codec";
        packageName = "com.hazelcast.client.impl.protocol.codec";

        
        
        

        response = methodElement.getAnnotation(Request.class).response();
        initParameters(methodElement, responseElement, eventElementList, lang);
    }

    private void initParameters(ExecutableElement methodElement, ExecutableElement responseElement,
                                List<ExecutableElement> eventElementList, Lang lang) {
        
        for (VariableElement param : methodElement.getParameters()) {
            final Nullable nullable = param.getAnnotation(Nullable.class);

            ParameterModel pm = new ParameterModel();
            pm.name = param.getSimpleName().toString();
            pm.type = param.asType().toString();
            pm.lang = lang;
            pm.nullable = nullable != null;
            requestParams.add(pm);
        }

        
        for (VariableElement param : responseElement.getParameters()) {
            final Nullable nullable = param.getAnnotation(Nullable.class);
            ParameterModel pm = new ParameterModel();
            pm.name = param.getSimpleName().toString();
            pm.type = param.asType().toString();
            pm.lang = lang;
            pm.nullable = nullable != null;
            responseParams.add(pm);
        }

        
        for (ExecutableElement element : eventElementList) {
            List<ParameterModel> eventParam = new ArrayList<ParameterModel>();
            for (VariableElement param : element.getParameters()) {
                final Nullable nullable = param.getAnnotation(Nullable.class);
                ParameterModel pm = new ParameterModel();
                pm.name = param.getSimpleName().toString();
                pm.type = param.asType().toString();
                pm.lang = lang;
                pm.nullable = nullable != null;
                eventParam.add(pm);
            }

            EventModel eventModel = new EventModel();
            eventModel.type = element.getAnnotation(EventResponse.class).value();
            eventModel.name = element.getSimpleName().toString();
            eventModel.eventParams = eventParam;

            events.add(eventModel);
        }
    }

    public String getName() {
        return name;
    }

    public String getClassName() {
        return className;
    }

    public String getParentName() {
        return parentName;
    }

    public String getPackageName() {
        return packageName;
    }

    public int getResponse() {
        return response;
    }

    public List<ParameterModel> getRequestParams() {
        return requestParams;
    }

    public List<ParameterModel> getResponseParams() {
        return responseParams;
    }

    public List<EventModel> getEvents() {
        return events;
    }

    public int getRetryable() {
        return retryable;
    }

    public static class EventModel {
        private String name;
        private List<ParameterModel> eventParams;
        private int type;

        public int getType() {
            return type;
        }

        public String getName() {
            return name;
        }

        public String getTypeString() {
            return "EVENT_" + name.toUpperCase();
        }

        public List<ParameterModel> getEventParams() {
            return eventParams;
        }
    }

    public static class ParameterModel {
        private String name;
        private String type;
        private Lang lang;
        private boolean nullable;

        public String getName() {
            return name;
        }

        public boolean isNullable() {
            return nullable;
        }

        public String getType() {
            if (lang == Lang.CSHARP) {
                return convertTypeToCSharp(type);
            }
            if (type.startsWith("java.util.List<") || type.startsWith("java.util.Set<") || type
                    .startsWith("java.util.Collection<")) {
                return type.replaceAll("java.util.*<(.*)>", "java.util.Collection<$1>");
            }
            return type;
        }

    }
}

<code block>


package com.hazelcast.client.protocol.generator;

import com.hazelcast.annotation.Codec;
import com.hazelcast.annotation.EventResponse;
import com.hazelcast.annotation.GenerateCodec;
import com.hazelcast.annotation.Request;
import com.hazelcast.annotation.Response;
import freemarker.cache.ClassTemplateLoader;
import freemarker.ext.beans.BeansWrapper;
import freemarker.log.Logger;
import freemarker.template.Configuration;
import freemarker.template.Template;
import freemarker.template.TemplateHashModel;
import freemarker.template.TemplateModelException;

import javax.annotation.processing.AbstractProcessor;
import javax.annotation.processing.Filer;
import javax.annotation.processing.Messager;
import javax.annotation.processing.ProcessingEnvironment;
import javax.annotation.processing.RoundEnvironment;
import javax.annotation.processing.SupportedAnnotationTypes;
import javax.annotation.processing.SupportedSourceVersion;
import javax.lang.model.SourceVersion;
import javax.lang.model.element.Element;
import javax.lang.model.element.ElementKind;
import javax.lang.model.element.ExecutableElement;
import javax.lang.model.element.TypeElement;
import javax.lang.model.type.MirroredTypeException;
import javax.lang.model.type.TypeMirror;
import javax.lang.model.util.Elements;
import javax.tools.Diagnostic;
import javax.tools.FileObject;
import javax.tools.JavaFileManager;
import javax.tools.JavaFileObject;
import javax.tools.StandardLocation;
import java.io.IOException;
import java.io.StringWriter;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Set;

@SupportedAnnotationTypes("com.hazelcast.annotation.GenerateCodec")
@SupportedSourceVersion(SourceVersion.RELEASE_6)
public class CodecCodeGenerator
        extends AbstractProcessor {

    private Filer filer;
    private Elements elementUtils;
    private Messager messager;
    private Template codecTemplate;
    
    private Template messageTypeTemplate;
    private Template messageTypeTemplateCSharp;
    private boolean csharpEnabled = Boolean.getBoolean("hazelcast.generator.csharp");
    private boolean cppEnabled = Boolean.getBoolean("hazelcast.generator.cpp");

    private Map<String, ExecutableElement> requestMap = new HashMap<String, ExecutableElement>();
    private Map<Integer, ExecutableElement> responseMap = new HashMap<Integer, ExecutableElement>();
    private Map<Integer, ExecutableElement> eventResponseMap = new HashMap<Integer, ExecutableElement>();

    @Override
    public void init(ProcessingEnvironment env) {

        filer = env.getFiler();
        messager = env.getMessager();
        elementUtils = env.getElementUtils();
        try {
            Logger.selectLoggerLibrary(Logger.LIBRARY_NONE);
        } catch (ClassNotFoundException e) {
            messager.printMessage(Diagnostic.Kind.ERROR, e.getMessage());
        }
        Configuration cfg = new Configuration(Configuration.VERSION_2_3_23);
        cfg.setTemplateLoader(new ClassTemplateLoader(getClass(), "/"));
        try {
            codecTemplate = cfg.getTemplate("codec-template-java.ftl");
            
            messageTypeTemplate = cfg.getTemplate("messagetype-template-java.ftl");
            messageTypeTemplateCSharp = cfg.getTemplate("messagetype-template-csharp.ftl");
        } catch (IOException e) {
            messager.printMessage(Diagnostic.Kind.ERROR, e.getMessage());
        }
    }

    @Override
    public boolean process(Set<? extends TypeElement> elements, RoundEnvironment env) {
        try {

            TypeElement te = elementUtils.getTypeElement("com.hazelcast.annotation.GenerateCodec");
            if(!elements.contains(te)) {
                return false;
            }
            for (Element element : env.getElementsAnnotatedWith(Codec.class)) {
                TypeElement classElement = (TypeElement) element;
                classElement.getAnnotationMirrors();
                Codec annotation = classElement.getAnnotation(Codec.class);
                if (annotation != null) {
                    try {
                        annotation.value();
                    } catch (MirroredTypeException mte) {
                        TypeMirror value = mte.getTypeMirror();
                        CodecModel.CUSTOM_CODEC_MAP.put(value.toString(), classElement);
                    }
                }
            }

            for (Element element : env.getElementsAnnotatedWith(GenerateCodec.class)) {
                register((TypeElement) element, Lang.JAVA);
            }

            for (Element element : env.getElementsAnnotatedWith(GenerateCodec.class)) {
                generateMessageTypeEnum((TypeElement) element, Lang.JAVA);
            }

            for (ExecutableElement element : requestMap.values()) {
                generateCodec(element, Lang.JAVA);
                if (csharpEnabled) {
                    
                }
                if (cppEnabled) {
                    
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
        return true;
    }

    public void register(TypeElement classElement, Lang lang) {
        for (Element enclosedElement : classElement.getEnclosedElements()) {
            if (!enclosedElement.getKind().equals(ElementKind.METHOD)) {
                continue;
            }
            ExecutableElement methodElement = (ExecutableElement) enclosedElement;

            short masterId = classElement.getAnnotation(GenerateCodec.class).id();

            final Request request = methodElement.getAnnotation(Request.class);
            if (request != null) {
                String id = CodeGenerationUtils.mergeIds(masterId, request.id());
                requestMap.put(id, methodElement);
                continue;
            }

            final Response response = methodElement.getAnnotation(Response.class);
            if (response != null) {
                responseMap.put(response.value(), methodElement);
                continue;
            }

            final EventResponse eventResponse = methodElement.getAnnotation(EventResponse.class);
            if (eventResponse != null) {
                eventResponseMap.put(eventResponse.value(), methodElement);
            }
        }
    }

    public void generateCodec(ExecutableElement methodElement, Lang lang) {
        CodecModel codecModel = createCodecModel(methodElement,lang);
        final String content;
        switch (lang) {
            case JAVA:
                content = generateFromTemplate(codecTemplate, codecModel);
                saveClass(codecModel.getPackageName(), codecModel.getClassName(), content);
                break;
            case CSHARP:
                
                
                
                
            case CPP:
                
                
                
                break;
            default:
                throw new UnsupportedOperationException("Unsupported language: " + lang);
        }
    }

    private CodecModel createCodecModel(ExecutableElement methodElement, Lang lang) {
        final TypeElement parent = (TypeElement) methodElement.getEnclosingElement();

        final Request methodElementAnnotation = methodElement.getAnnotation(Request.class);
        final int response = methodElementAnnotation.response();
        final int[] events = methodElementAnnotation.event();
        final boolean retryable = methodElementAnnotation.retryable();

        ExecutableElement responseElement = responseMap.get(response);

        List<ExecutableElement> eventElementList = new ArrayList<ExecutableElement>();
        if (events != null) {
            for (Integer eventType : events) {
                final ExecutableElement eventResponse = eventResponseMap.get(eventType);
                if (eventResponse != null) {
                    eventElementList.add(eventResponse);
                }
            }
        }

        return new CodecModel(parent, methodElement, responseElement, eventElementList, retryable, lang);
    }

    private void generateMessageTypeEnum(TypeElement classElement, Lang lang) {
        MessageTypeEnumModel clazz = new MessageTypeEnumModel(classElement, lang);
        if (clazz.isEmpty()) {
            return;
        }
        final String content;
        switch (lang) {
            case JAVA:
                content = generateFromTemplate(messageTypeTemplate, clazz);
                saveClass(clazz.getPackageName(), clazz.getClassName(), content);
                break;
            case CSHARP:
                content = generateFromTemplate(messageTypeTemplateCSharp, clazz);
                saveFile(clazz.getClassName() + ".cs", clazz.getPackageName(), content);
                break;
            case CPP:
                
                
                
                break;
            default:
                throw new UnsupportedOperationException("Unsupported language: " + lang);

        }
    }

    private void generateProtocolDoc() {






    }

    private void saveClass(String packageName, String className, String content) {
        JavaFileObject file;
        try {
            final String fullClassName = packageName + "." + className;
            file = filer.createSourceFile(fullClassName);
            file.openWriter().append(content).close();
        } catch (IOException e) {
            messager.printMessage(Diagnostic.Kind.WARNING, e.getMessage());
        }
    }

    private void saveFile(String fileName, String packageName, String content) {
        FileObject file;
        try {
            final JavaFileManager.Location location = StandardLocation.locationFor(StandardLocation.SOURCE_OUTPUT.name());
            file = filer.createResource(location, packageName, fileName);
            file.openWriter().append(content).close();
        } catch (IOException e) {
            messager.printMessage(Diagnostic.Kind.WARNING, e.getMessage());
        }
    }

    private String generateFromTemplate(Template template, Object model) {
        String content = null;
        try {
            Map<String, Object> data = new HashMap();
            setUtilModel(data);
            data.put("model", model);
            StringWriter writer = new StringWriter();
            template.process(data, writer);
            content = writer.toString();
        } catch (Exception e) {
            messager.printMessage(Diagnostic.Kind.ERROR, e.getMessage());
        }
        return content;
    }

    public static void setUtilModel(Map modelMap)
            throws TemplateModelException {
        BeansWrapper wrapper = BeansWrapper.getDefaultInstance();
        TemplateHashModel staticModels = wrapper.getStaticModels();
        TemplateHashModel statics = (TemplateHashModel) staticModels.get(CodeGenerationUtils.class.getName());
        modelMap.put("util", statics);
    }
}

<code block>


package com.hazelcast.client.protocol.generator;

import javax.lang.model.element.TypeElement;

public final class CodeGenerationUtils {

    public static final int BYTE_BIT_COUNT = 8;
    public static final String CODEC_PACKAGE = "com.hazelcast.client.impl.protocol.codec.";
    public static final String DATA_FULL_NAME = "com.hazelcast.nio.serialization.Data";

    private CodeGenerationUtils() {
    }

    public static String capitalizeFirstLetter(String input) {
        return input.substring(0, 1).toUpperCase() + input.substring(1);
    }


    public static String getPackageNameFromQualifiedName(String qualifiedClassName) {
        return qualifiedClassName.substring(0, qualifiedClassName.lastIndexOf("."));
    }

    public static String mergeIds(short classId, short methodId) {
        final String s = Integer.toHexString((classId << BYTE_BIT_COUNT) + methodId);
        return s.length() == 3 ? "0x0" + s : "0x" + s;
    }

    public static String getArrayType(String type) {
        int end = type.indexOf("[]");
        return type.substring(0, end).trim();
    }

    public static String getGenericType(String type) {
        int beg = type.indexOf("<");
        int end = type.lastIndexOf(">");
        return type.substring(beg + 1, end).trim();
    }

    public static String getFirstGenericParameterType(String type) {
        int beg = type.indexOf("<");
        int end = type.lastIndexOf(",");
        return type.substring(beg + 1, end).trim();
    }

    public static String getSecondGenericParameterType(String type) {
        int beg = type.indexOf(",");
        int end = type.lastIndexOf(">");
        return type.substring(beg + 1, end).trim();
    }

    public static boolean isPrimitive(String type) {
        return type.equals("int") || type.equals("long") || type.equals("short") || type.equals("byte") || type
                .equals("boolean");
    }

    public static String getTypeCategory(String type) {
        int endIndex = type.indexOf('<');
        String t = endIndex > 0 ? type.substring(0, endIndex) : type;
        if (CodecModel.CUSTOM_CODEC_MAP.containsKey(t)) {
            return "CUSTOM";
        } else if (t.equals("java.util.Map")) {
            return "MAP";
        } else if (t.equals("java.util.List") || t.equals("java.util.Set") || t.equals("java.util.Collection")) {
            return "COLLECTION";
        } else if (type.endsWith("[]")) {
            return "ARRAY";
        }
        return "OTHER";
    }

    public static String getTypeCodec(String type) {
        int endIndex = type.indexOf('<');
        String t = endIndex > 0 ? type.substring(0, endIndex) : type;
        TypeElement typeElement = CodecModel.CUSTOM_CODEC_MAP.get(t);
        return typeElement != null ? typeElement.toString() : "";
    }


    public static String convertTypeToCSharp(String type) {
        String getterString;
        if (type.equals(DATA_FULL_NAME + " ")) {
            getterString = "IData";
        } else if (type.equals("java.lang.String")) {
            getterString = "string";
        } else if (type.equals("boolean")) {
            getterString = "bool";
        } else if (type.equals("java.util.List<" + DATA_FULL_NAME + " >")) {
            getterString = "IList<IData>";
        } else if (type.equals("java.util.Set<" + DATA_FULL_NAME + " >")) {
            getterString = "ISet<IData>";
        } else if (type.equals("java.util.Collection<" + DATA_FULL_NAME + " >")) {
            getterString = "ICollection<IData>";
        } else {
            getterString = type;
        }
        return getterString;
    }


}

<code block>


package com.hazelcast.codegenerator;

import com.hazelcast.client.protocol.generator.CodecCodeGenerator;
import com.hazelcast.client.protocol.generator.CodecModel;
import freemarker.cache.ClassTemplateLoader;
import freemarker.template.Configuration;
import freemarker.template.Template;

import java.io.StringWriter;
import java.util.HashMap;
import java.util.Map;

public class GeneratorTest {
    private Template template;

    public static void main(String[] args) {
        new GeneratorTest().generate();

    }

    public GeneratorTest() {
        Configuration cfg = new Configuration(Configuration.VERSION_2_3_23);
        cfg.setTemplateLoader(new ClassTemplateLoader(getClass(), "/"));
        try {
            cfg.setSetting("object_wrapper","DefaultObjectWrapper(2.3.23)");
            template = cfg.getTemplate("codec-template-java.ftl");
        } catch (Exception e) {
            e.printStackTrace();
        }

    }

    public void generate() {
        try {
            CodecModel model = new CodecModel(true);
            Map<String, Object> data = new HashMap();
            CodecCodeGenerator.setUtilModel(data);
            data.put("model", model);
            StringWriter writer = new StringWriter();
            template.process(data, writer);
            String content = writer.toString();

            if( content == null || content.length() == 0) {
                content = ">>>>>>>>CONTENT EMPTY<<<<<<<<<<";

            }
            System.out.println(content);

        } catch (Exception e) {
            e.printStackTrace();
        }
    }

}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.map.impl.SimpleEntryView;
import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;

public final class EntryViewCodec {

    private EntryViewCodec() {
    }

    public static SimpleEntryView decode(ClientMessage clientMessage) {
        SimpleEntryView<Data, Data> dataEntryView = new SimpleEntryView<Data, Data>();
        dataEntryView.setKey(clientMessage.getData());
        dataEntryView.setValue(clientMessage.getData());
        dataEntryView.setCost(clientMessage.getLong());
        dataEntryView.setCreationTime(clientMessage.getLong());
        dataEntryView.setExpirationTime(clientMessage.getLong());
        dataEntryView.setHits(clientMessage.getLong());
        dataEntryView.setLastAccessTime(clientMessage.getLong());
        dataEntryView.setLastStoredTime(clientMessage.getLong());
        dataEntryView.setLastUpdateTime(clientMessage.getLong());
        dataEntryView.setVersion(clientMessage.getLong());
        dataEntryView.setEvictionCriteriaNumber(clientMessage.getLong());
        dataEntryView.setTtl(clientMessage.getLong());
        return dataEntryView;
    }

    public static void encode(SimpleEntryView<Data, Data> dataEntryView, ClientMessage clientMessage) {
        Data key = dataEntryView.getKey();
        Data value = dataEntryView.getValue();
        long cost = dataEntryView.getCost();
        long creationTime = dataEntryView.getCreationTime();
        long expirationTime = dataEntryView.getExpirationTime();
        long hits = dataEntryView.getHits();
        long lastAccessTime = dataEntryView.getLastAccessTime();
        long lastStoredTime = dataEntryView.getLastStoredTime();
        long lastUpdateTime = dataEntryView.getLastUpdateTime();
        long version = dataEntryView.getVersion();
        long ttl = dataEntryView.getTtl();
        long evictionCriteriaNumber = dataEntryView.getEvictionCriteriaNumber();


        clientMessage.set(key).set(value).set(cost).set(creationTime).set(expirationTime)
                .set(hits).set(lastAccessTime).set(lastStoredTime).set(lastUpdateTime)
                .set(version).set(evictionCriteriaNumber).set(ttl);
    }


    public static int calculateDataSize(SimpleEntryView<Data, Data> entryView) {
        int dataSize = ClientMessage.HEADER_SIZE;
        Data key = entryView.getKey();
        Data value = entryView.getValue();
        return dataSize
                + ParameterUtil.calculateDataSize(key)
                + ParameterUtil.calculateDataSize(value)
                + Bits.LONG_SIZE_IN_BYTES * 10;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.mapreduce.JobPartitionState;
import com.hazelcast.mapreduce.impl.task.JobPartitionStateImpl;
import com.hazelcast.nio.Address;

public class JobPartitionStateCodec {

    private JobPartitionStateCodec() {
    }

    public static JobPartitionState decode(ClientMessage clientMessage) {
        final Address address = AddressCodec.decode(clientMessage);
        String state = clientMessage.getStringUtf8();

        return new JobPartitionStateImpl(address, JobPartitionState.State.valueOf(state));
    }

    public static void encode(JobPartitionState jobPartitionState, ClientMessage clientMessage) {
        AddressCodec.encode(jobPartitionState.getOwner(), clientMessage);
        clientMessage.set(jobPartitionState.getState().name());
    }

    public static int calculateDataSize(JobPartitionState jobPartitionState) {
        int dataSize = AddressCodec.calculateDataSize(jobPartitionState.getOwner());
        dataSize += ParameterUtil.calculateStringDataSize(jobPartitionState.getState().name());
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.cache.impl.CacheEventData;
import com.hazelcast.cache.impl.CacheEventDataImpl;
import com.hazelcast.cache.impl.CacheEventType;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;

public final class CacheEventDataCodec {

    private CacheEventDataCodec() {
    }

    public static CacheEventData decode(ClientMessage clientMessage) {
        int typeId = clientMessage.getInt();
        String name = clientMessage.getStringUtf8();
        Data key = clientMessage.getData();
        boolean value_isNull = clientMessage.getBoolean();
        Data value = null;
        if (!value_isNull) {
            value = clientMessage.getData();
        }

        boolean dataOldValue_isNull = clientMessage.getBoolean();
        Data oldValue = null;
        if (!dataOldValue_isNull) {
            oldValue = clientMessage.getData();
        }
        boolean isOldValueAvailable = clientMessage.getBoolean();
        return new CacheEventDataImpl(name, CacheEventType.getByType(typeId), key, value, oldValue, isOldValueAvailable);
    }

    public static void encode(CacheEventData cacheEventData, ClientMessage clientMessage) {
        clientMessage.set(cacheEventData.getCacheEventType().getType());
        clientMessage.set(cacheEventData.getName());
        clientMessage.set(cacheEventData.getDataKey());

        Data dataValue = cacheEventData.getDataValue();
        boolean dataValue_isNull = dataValue == null;
        clientMessage.set(dataValue_isNull);
        if (!dataValue_isNull) {
            clientMessage.set(dataValue);
        }
        Data dataOldValue = cacheEventData.getDataOldValue();
        boolean dataOldValue_isNull = dataOldValue == null;
        clientMessage.set(dataOldValue_isNull);
        if (!dataOldValue_isNull) {
            clientMessage.set(dataOldValue);
        }

        clientMessage.set(cacheEventData.isOldValueAvailable());
    }

    public static int calculateDataSize(CacheEventData cacheEventData) {
        int dataSize = Bits.INT_SIZE_IN_BYTES;
        dataSize += ParameterUtil.calculateStringDataSize(cacheEventData.getName());
        dataSize += ParameterUtil.calculateDataSize(cacheEventData.getDataKey());
        Data dataValue = cacheEventData.getDataValue();
        if (dataValue == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateDataSize(dataValue);
        }
        Data dataOldValue = cacheEventData.getDataOldValue();
        if (dataOldValue == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateDataSize(dataOldValue);
        }
        dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Bits;

import java.net.UnknownHostException;

public final class AddressCodec {

    private AddressCodec() {
    }

    public static Address decode(ClientMessage clientMessage) {
        String host = clientMessage.getStringUtf8();
        int port = clientMessage.getInt();
        try {
            return new Address(host, port);
        } catch (UnknownHostException e) {
            return null;
        }
    }

    public static void encode(Address address, ClientMessage clientMessage) {
        clientMessage.set(address.getHost()).set(address.getPort());
    }

    public static int calculateDataSize(Address address) {
        int dataSize = ParameterUtil.calculateStringDataSize(address.getHost());
        dataSize += Bits.INT_SIZE_IN_BYTES;
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.client.impl.client.DistributedObjectInfo;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;

public final class DistributedObjectInfoCodec {

    private DistributedObjectInfoCodec() {
    }

    public static DistributedObjectInfo decode(ClientMessage clientMessage) {
        String serviceName = clientMessage.getStringUtf8();
        String name = clientMessage.getStringUtf8();
        return new DistributedObjectInfo(serviceName, name);
    }

    public static void encode(DistributedObjectInfo info, ClientMessage clientMessage) {
        clientMessage.
                set(info.getServiceName()).
                set(info.getName());
    }

    public static int calculateDataSize(DistributedObjectInfo info) {
        return ParameterUtil.calculateStringDataSize(info.getServiceName())
                + ParameterUtil.calculateStringDataSize(info.getName());
    }
}


<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.nio.Bits;
import com.hazelcast.transaction.impl.xa.SerializableXID;

import javax.transaction.xa.Xid;

public final class XIDCodec {

    private XIDCodec() {
    }

    public static Xid decode(ClientMessage clientMessage) {
        int formatId = clientMessage.getInt();
        byte[] globalTransactionId = clientMessage.getByteArray();
        byte[] branchQualifier = clientMessage.getByteArray();
        return new SerializableXID(formatId, globalTransactionId, branchQualifier);

    }

    public static void encode(Xid xid, ClientMessage clientMessage) {
        clientMessage.set(xid.getFormatId());
        clientMessage.set(xid.getGlobalTransactionId());
        clientMessage.set(xid.getBranchQualifier());
    }

    public static int calculateDataSize(Xid xid) {
        int dataSize = 0;
        dataSize += Bits.INT_SIZE_IN_BYTES;
        dataSize += ParameterUtil.calculateByteArrayDataSize(xid.getGlobalTransactionId());
        dataSize += ParameterUtil.calculateByteArrayDataSize(xid.getBranchQualifier());
        return dataSize;
    }
}


<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.core.Member;
import com.hazelcast.instance.AbstractMember;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Bits;

import java.util.HashMap;
import java.util.Map;

public final class MemberCodec {

    private MemberCodec() {
    }

    public static Member decode(ClientMessage clientMessage) {
        final Address address = AddressCodec.decode(clientMessage);
        String uuid = clientMessage.getStringUtf8();
        int attributeSize = clientMessage.getInt();
        Map<String, Object> attributes = new HashMap<String, Object>();
        for (int i = 0; i < attributeSize; i++) {
            String key = clientMessage.getStringUtf8();
            String value = clientMessage.getStringUtf8();
            attributes.put(key, value);
        }

        return new com.hazelcast.client.impl.MemberImpl(address, uuid, attributes);
    }

    public static void encode(Member member, ClientMessage clientMessage) {
        AddressCodec.encode(((AbstractMember) member).getAddress(), clientMessage);
        clientMessage.set(member.getUuid());
        Map<String, Object> attributes = new HashMap<String, Object>(member.getAttributes());
        clientMessage.set(attributes.size());
        for (Map.Entry<String, Object> entry : attributes.entrySet()) {
            clientMessage.set(entry.getKey());
            Object value = entry.getValue();
            clientMessage.set(value.toString());

        }
    }

    public static int calculateDataSize(Member member) {
        int dataSize = AddressCodec.calculateDataSize(((AbstractMember) member).getAddress());
        dataSize += ParameterUtil.calculateStringDataSize(member.getUuid());
        dataSize += Bits.INT_SIZE_IN_BYTES;
        Map<String, Object> attributes = member.getAttributes();
        for (Map.Entry<String, Object> entry : attributes.entrySet()) {
            dataSize += ParameterUtil.calculateStringDataSize(entry.getKey());
            Object value = entry.getValue();
            
            dataSize += ParameterUtil.calculateStringDataSize(value.toString());
        }
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.codec;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.cluster.MemberAttributeOperationType;
import com.hazelcast.cluster.client.MemberAttributeChange;
import com.hazelcast.nio.Bits;

import static com.hazelcast.cluster.MemberAttributeOperationType.PUT;

public final class MemberAttributeChangeCodec {

    private MemberAttributeChangeCodec() {
    }

    public static MemberAttributeChange decode(ClientMessage clientMessage) {
        String uuid = clientMessage.getStringUtf8();
        String key = clientMessage.getStringUtf8();
        MemberAttributeOperationType operationType = MemberAttributeOperationType.getValue(clientMessage.getInt());
        Object value = null;
        if (operationType == PUT) {
            value = clientMessage.getStringUtf8();
        }
        return new MemberAttributeChange(uuid, operationType, key, value);
    }

    public static void encode(MemberAttributeChange memberAttributeChange, ClientMessage clientMessage) {
        clientMessage.set(memberAttributeChange.getUuid());
        clientMessage.set(memberAttributeChange.getKey());

        MemberAttributeOperationType operationType = memberAttributeChange.getOperationType();
        clientMessage.set(operationType.getId());
        if (operationType == PUT) {
            clientMessage.set(memberAttributeChange.getValue().toString());
        }
    }

    public static int calculateDataSize(MemberAttributeChange memberAttributeChange) {
        if (memberAttributeChange == null) {
            return Bits.BOOLEAN_SIZE_IN_BYTES;
        }
        int dataSize = ParameterUtil.calculateStringDataSize(memberAttributeChange.getUuid());
        dataSize += ParameterUtil.calculateStringDataSize(memberAttributeChange.getKey());
        
        dataSize += Bits.INT_SIZE_IN_BYTES;
        MemberAttributeOperationType operationType = memberAttributeChange.getOperationType();
        if (operationType == PUT) {
            dataSize += ParameterUtil.calculateStringDataSize(memberAttributeChange.getValue().toString());
        }
        return dataSize;
    }
}

<code block>


package com.hazelcast.client.impl.protocol.parameters;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.ResponseMessageConst;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.nio.Bits;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;


@SuppressFBWarnings(value = "URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD",
        justification = "fields may be needed for diagnostic")
public class ExceptionResultParameters {

    
    public static final int TYPE = ResponseMessageConst.EXCEPTION;
    public String className;
    public String causeClassName;
    public String message;
    public String stacktrace;

    private ExceptionResultParameters(ClientMessage flyweight) {
        className = flyweight.getStringUtf8();
        boolean causeClassName_isNull = flyweight.getBoolean();
        if (!causeClassName_isNull) {
            causeClassName = flyweight.getStringUtf8();
        }
        boolean message_isNull = flyweight.getBoolean();
        if (!message_isNull) {
            message = flyweight.getStringUtf8();
        }
        boolean stackTrace_isNull = flyweight.getBoolean();
        if (!stackTrace_isNull) {
            stacktrace = flyweight.getStringUtf8();
        }
    }

    public static ExceptionResultParameters decode(ClientMessage flyweight) {
        return new ExceptionResultParameters(flyweight);
    }

    public static ClientMessage encode(String className, String causeClassName, String message, String stacktrace) {
        final int requiredDataSize = calculateDataSize(className, causeClassName, message, stacktrace);
        ClientMessage clientMessage = ClientMessage.createForEncode(requiredDataSize);
        clientMessage.setMessageType(TYPE);
        clientMessage.set(className);
        boolean causeClassName_isNull = causeClassName == null;
        clientMessage.set(causeClassName_isNull);
        if (!causeClassName_isNull) {
            clientMessage.set(causeClassName);
        }
        boolean message_isNull = message == null;
        clientMessage.set(message_isNull);
        if (!message_isNull) {
            clientMessage.set(message);
        }
        boolean stackTrace_isNull = stacktrace == null;
        clientMessage.set(stackTrace_isNull);
        if (!stackTrace_isNull) {
            clientMessage.set(stacktrace);
        }

        clientMessage.updateFrameLength();
        return clientMessage;
    }

    
    public static int calculateDataSize(String className, String causeClassName, String message, String stacktrace) {
        int dataSize = ClientMessage.HEADER_SIZE + ParameterUtil.calculateStringDataSize(className);
        if (causeClassName == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateStringDataSize(causeClassName);
        }
        if (message == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateStringDataSize(message);
        }
        if (stacktrace == null) {
            dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;
        } else {
            dataSize += ParameterUtil.calculateStringDataSize(stacktrace);
        }
        return dataSize;
    }

}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;

public final class ParameterUtil {

    private static final int UTF8_MAX_BYTES_PER_CHAR = 4;

    private ParameterUtil() { }

    public static int calculateStringDataSize(String string) {
        return Bits.INT_SIZE_IN_BYTES + string.length() * UTF8_MAX_BYTES_PER_CHAR;
    }

    public static int calculateByteArrayDataSize(byte[] bytes) {
        return Bits.INT_SIZE_IN_BYTES + bytes.length;
    }

    public static int calculateDataSize(Data key) {
        return calculateByteArrayDataSize(key.toByteArray());
    }
}

<code block>
package com.hazelcast.client.protocol;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.util.ClientProtocolBuffer;
import com.hazelcast.client.impl.protocol.util.ParameterUtil;
import com.hazelcast.client.impl.protocol.util.SafeBuffer;
import com.hazelcast.nio.Bits;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.io.IOException;
import java.io.UnsupportedEncodingException;
import java.nio.ByteBuffer;

import static org.hamcrest.core.Is.is;
import static org.junit.Assert.assertArrayEquals;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertThat;


@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class ClientMessageTest {

    private static final String DEFAULT_ENCODING = "UTF8";

    private static final String VAR_DATA_STR_1 = "abcdef";

    private static final byte[] BYTE_DATA = VAR_DATA_STR_1.getBytes();

    @Before
    public void setUp() {
    }

    @After
    public void tearDown() {
    }

    @Test
    public void shouldEncodeClientMessageCorrectly() {
        ByteBuffer byteBuffer = ByteBuffer.allocate(512);
        SafeBuffer safeBuffer = new SafeBuffer(byteBuffer.array());

        ClientMessage cmEncode = TestClientMessage.createForEncode(safeBuffer, 0);

        cmEncode.setMessageType(0x1122).setVersion((short) 0xEF).addFlag(ClientMessage.BEGIN_AND_END_FLAGS).setCorrelationId(0x12345678)
                .setPartitionId(0x11223344);

        
        
        assertThat(byteBuffer.get(0), is((byte) ClientMessage.HEADER_SIZE));
        assertThat(byteBuffer.get(1), is((byte) 0));
        assertThat(byteBuffer.get(2), is((byte) 0));
        assertThat(byteBuffer.get(3), is((byte) 0));

        
        assertThat(byteBuffer.get(4), is((byte) 0xEF));

        
        assertThat(byteBuffer.get(5), is((byte) 0xC0));

        
        assertThat(byteBuffer.get(6), is((byte) 0x22));
        assertThat(byteBuffer.get(7), is((byte) 0x11));

        
        assertThat(byteBuffer.get(8), is((byte) 0x78));
        assertThat(byteBuffer.get(9), is((byte) 0x56));
        assertThat(byteBuffer.get(10), is((byte) 0x34));
        assertThat(byteBuffer.get(11), is((byte) 0x12));

        
        assertThat(byteBuffer.get(12), is((byte) 0x44));
        assertThat(byteBuffer.get(13), is((byte) 0x33));
        assertThat(byteBuffer.get(14), is((byte) 0x22));
        assertThat(byteBuffer.get(15), is((byte) 0x11));

        
        assertThat(byteBuffer.get(16), is((byte) ClientMessage.HEADER_SIZE));
        assertThat(byteBuffer.get(17), is((byte) 0x00));

    }

    @Test
    public void shouldEncodeAndDecodeClientMessageCorrectly() {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[512]);

        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, 0);

        cmEncode.setMessageType(7)
                .setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        ClientMessage cmDecode = ClientMessage.createForDecode(byteBuffer, 0);

        assertEquals(7, cmDecode.getMessageType());
        assertEquals(3, cmDecode.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode.getFlags());
        assertEquals(66, cmDecode.getCorrelationId());
        assertEquals(77, cmDecode.getPartitionId());
        assertEquals(ClientMessage.HEADER_SIZE, cmDecode.getFrameLength());
    }

    @Test
    public void shouldEncodeAndDecodeClientMessageCorrectly_withPayLoadData()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[1024]);

        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, 0);

        cmEncode.setMessageType(7)
                .setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        final byte[] data1 = VAR_DATA_STR_1.getBytes(DEFAULT_ENCODING);
        final int calculatedFrameSize = ClientMessage.HEADER_SIZE + ParameterUtil.calculateByteArrayDataSize(data1);
        cmEncode.set(data1);
        cmEncode.updateFrameLength();

        ClientMessage cmDecode = ClientMessage.createForDecode(byteBuffer, 0);

        byte[] cmDecodeVarData1 = cmDecode.getByteArray();

        assertEquals(calculatedFrameSize, cmDecode.getFrameLength());
        assertArrayEquals(cmDecodeVarData1, data1);
    }


    @Test
    public void shouldEncodeAndDecodeClientMessageCorrectly_withPayLoadData_fromOffset()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[150]);
        int offset = 100;

        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, offset);

        cmEncode.setMessageType(7)
                .setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        byte[] bytes = VAR_DATA_STR_1.getBytes();
        final int calculatedFrameSize = ClientMessage.HEADER_SIZE + Bits.INT_SIZE_IN_BYTES +
                ParameterUtil.calculateByteArrayDataSize(bytes);
        cmEncode.set(1);
        cmEncode.set(bytes);
        cmEncode.updateFrameLength();

        ClientMessage cmDecode = ClientMessage.createForDecode(byteBuffer, offset);

        assertEquals(1, cmDecode.getInt());
        assertArrayEquals(bytes, cmDecode.getByteArray());

        assertEquals(calculatedFrameSize, cmDecode.getFrameLength());
    }

    @Test
    public void shouldEncodeWithNewVersionAndDecodeWithOldVersionCorrectly_withPayLoadData()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[1024]);

        FutureClientMessage cmEncode = new FutureClientMessage();
        cmEncode.wrapForEncode(byteBuffer, 0);

        cmEncode.theNewField(999)
                .setMessageType(7).setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        final int calculatedFrameSize = FutureClientMessage.THE_NEW_HEADER_SIZE
                + ParameterUtil.calculateByteArrayDataSize(BYTE_DATA);
        cmEncode.set(BYTE_DATA);
        cmEncode.updateFrameLength();

        ClientMessage cmDecode = ClientMessage.createForDecode(byteBuffer, 0);

        final byte[] cmDecodeVarData1 = cmDecode.getByteArray();

        assertEquals(7, cmDecode.getMessageType());
        assertEquals(3, cmDecode.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode.getFlags());
        assertEquals(66, cmDecode.getCorrelationId());
        assertEquals(77, cmDecode.getPartitionId());
        assertEquals(calculatedFrameSize, cmDecode.getFrameLength());
        assertArrayEquals(cmDecodeVarData1, BYTE_DATA);
    }

    @Test
    public void shouldEncodeWithOldVersionAndDecodeWithNewVersionCorrectly_withPayLoadData()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[1024]);

        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, 0);

        cmEncode.setMessageType(7).setVersion((short) 3)
                .addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(66).setPartitionId(77);

        final int calculatedFrameSize = ClientMessage.HEADER_SIZE
                + ParameterUtil.calculateByteArrayDataSize(BYTE_DATA);
        cmEncode.set(BYTE_DATA);
        cmEncode.updateFrameLength();
        ClientMessage cmDecode = FutureClientMessage.createForDecode(byteBuffer, 0);

        final byte[] cmDecodeVarData1 = cmDecode.getByteArray();

        assertEquals(7, cmDecode.getMessageType());
        assertEquals(3, cmDecode.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode.getFlags());
        assertEquals(66, cmDecode.getCorrelationId());
        assertEquals(77, cmDecode.getPartitionId());
        assertEquals(calculatedFrameSize, cmDecode.getFrameLength());
        assertArrayEquals(cmDecodeVarData1, BYTE_DATA);
    }

    @Test
    public void shouldEncodeAndDecodeClientMessageCorrectly_withPayLoadData_multipleMessages()
            throws UnsupportedEncodingException {
        SafeBuffer byteBuffer = new SafeBuffer(new byte[1024]);
        ClientMessage cmEncode = TestClientMessage.createForEncode(byteBuffer, 0);
        cmEncode.setMessageType(7).setVersion((short) 3).addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(1).setPartitionId(77);
        cmEncode.set(BYTE_DATA);
        cmEncode.updateFrameLength();
        final int calculatedFrame1Size = ClientMessage.HEADER_SIZE
                + ParameterUtil.calculateByteArrayDataSize(BYTE_DATA);

        final int nexMessageOffset = cmEncode.getFrameLength();
        ClientMessage cmEncode2 =
                TestClientMessage.createForEncode(byteBuffer, nexMessageOffset);

        cmEncode2.setMessageType(7).setVersion((short) 3).addFlag(ClientMessage.BEGIN_AND_END_FLAGS)
                .setCorrelationId(2).setPartitionId(77);
        cmEncode2.set(BYTE_DATA);
        cmEncode2.updateFrameLength();
        final int calculatedFrame2Size = ClientMessage.HEADER_SIZE
                + ParameterUtil.calculateByteArrayDataSize(BYTE_DATA);

        ClientMessage cmDecode1 = ClientMessage.createForDecode(byteBuffer, 0);

        final byte[] cmDecodeVarData = cmDecode1.getByteArray();

        assertEquals(7, cmDecode1.getMessageType());
        assertEquals(3, cmDecode1.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode1.getFlags());
        assertEquals(1, cmDecode1.getCorrelationId());
        assertEquals(77, cmDecode1.getPartitionId());
        assertEquals(calculatedFrame1Size, cmDecode1.getFrameLength());
        assertArrayEquals(cmDecodeVarData, BYTE_DATA);

        ClientMessage cmDecode2 = ClientMessage.createForDecode(byteBuffer, cmDecode1.getFrameLength());
        byte[] cmDecodeVarData2 = cmDecode2.getByteArray();

        assertEquals(7, cmDecode2.getMessageType());
        assertEquals(3, cmDecode2.getVersion());
        assertEquals(ClientMessage.BEGIN_AND_END_FLAGS, cmDecode2.getFlags());
        assertEquals(2, cmDecode2.getCorrelationId());
        assertEquals(77, cmDecode2.getPartitionId());
        assertEquals(calculatedFrame2Size, cmDecode2.getFrameLength());
        assertArrayEquals(cmDecodeVarData2, BYTE_DATA);
    }

    private static class FutureClientMessage extends TestClientMessage {

        private static final int THE_NEW_FIELD_OFFSET = HEADER_SIZE + Bits.SHORT_SIZE_IN_BYTES;
        private static final int THE_NEW_HEADER_SIZE = HEADER_SIZE + Bits.INT_SIZE_IN_BYTES;

        @Override
        protected void wrapForEncode(ClientProtocolBuffer buffer, int offset) {
            super.wrap(buffer, offset);
            setDataOffset(THE_NEW_HEADER_SIZE);
            setFrameLength(THE_NEW_HEADER_SIZE);
            index(getDataOffset());
        }

        public int theNewField() {
            return (int) uint32Get(THE_NEW_FIELD_OFFSET);
        }

        public FutureClientMessage theNewField(int value) {
            uint32Put(THE_NEW_FIELD_OFFSET, value);
            return this;
        }
    }

    private static class TestClientMessage extends ClientMessage {

        @Override
        public ClientMessage setMessageType(int type) {
            return super.setMessageType(type);
        }
    }

    @Test
    public void test_empty_toString() {
        new ClientMessage().toString();
    }

    @Test(expected = IndexOutOfBoundsException.class)
    public void test_byteArray_constructor_withSmallBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[10]), 1);
    }

    @Test
    public void test_byteArray_constructor_withHeaderSizeBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[ClientMessage.HEADER_SIZE]), 0);
    }

    @Test
    public void test_byteArray_constructor_withLargeBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[100]), 10);
    }

    @Test(expected = IndexOutOfBoundsException.class)
    public void test_MutableDirectBuffer_constructor_withSmallBuffer() {
        SafeBuffer buffer = new SafeBuffer(new byte[10]);
        ClientMessage.createForEncode(buffer, 1);
    }

    @Test
    public void test_MutableDirectBuffer_constructor_withHeaderSizeBuffer() {
        SafeBuffer buffer = new SafeBuffer(new byte[ClientMessage.HEADER_SIZE]);
        ClientMessage.createForEncode(buffer, 0);
    }

    @Test
    public void test_MutableDirectBuffer_constructor_withLargeBuffer() {
        SafeBuffer buffer = new SafeBuffer(new byte[100]);
        ClientMessage.createForEncode(buffer, 10);
    }

    @Test(expected = IndexOutOfBoundsException.class)
    public void test_wrapForEncode_withSmallBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[10]), 1);
    }

    @Test
    public void test_wrapForEncode_withHeaderSizeBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[ClientMessage.HEADER_SIZE]), 0);
    }

    @Test
    public void test_wrapForEncode_withLargeBuffer() {
        ClientMessage.createForEncode(new SafeBuffer(new byte[100]), 10);
    }

    @Test(expected = IndexOutOfBoundsException.class)
    public void test_wrapForDecode_withSmallBuffer() {
        ClientMessage.createForDecode(new SafeBuffer(new byte[10]), 1);
    }

    @Test
    public void test_wrapForDecode_withHeaderSizeBuffer() {
        ClientMessage.createForDecode(new SafeBuffer(new byte[ClientMessage.HEADER_SIZE]), 0);
    }

    @Test
    public void test_wrapForDecode_withLargeBuffer() {
        ClientMessage.createForDecode(new SafeBuffer(new byte[100]), 10);
    }

    @Test
    public void testUnsignedFields() throws IOException {
        ClientProtocolBuffer buffer = new SafeBuffer(new byte[18]);

        ClientMessage cmEncode = ClientMessage.createForEncode(buffer, 0);

        cmEncode.setVersion((short) (Byte.MAX_VALUE + 10));
        cmEncode.setMessageType(Short.MAX_VALUE + 10);
        cmEncode.setDataOffset((int) Short.MAX_VALUE + 10);
        cmEncode.setCorrelationId(Short.MAX_VALUE + 10);

        ClientMessage cmDecode = ClientMessage.createForDecode(buffer, 0);

        assertEquals(Byte.MAX_VALUE + 10, cmDecode.getVersion());
        assertEquals(Short.MAX_VALUE + 10, cmDecode.getMessageType());
        assertEquals((int) Short.MAX_VALUE + 10, cmDecode.getDataOffset());

    }

}

<code block>


package com.hazelcast.client.protocol.generator;


public enum Lang {

    
    JAVA,

    
    CSHARP,

    
    CPP
}

<code block>


package com.hazelcast.client.protocol.generator;

import com.hazelcast.annotation.EventResponse;
import com.hazelcast.annotation.GenerateCodec;
import com.hazelcast.annotation.Nullable;
import com.hazelcast.annotation.Request;

import javax.lang.model.element.ExecutableElement;
import javax.lang.model.element.TypeElement;
import javax.lang.model.element.VariableElement;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;

public class CodecModel {

    private static final String PARAMETERS_PACKAGE = "com.hazelcast.client.impl.protocol.codec.";
    private static final String DATA_FULL_NAME = "com.hazelcast.nio.serialization.Data";

    private final Lang lang;
    private String name;
    private String className;
    private String parentName;
    private String packageName;

    private int retryable;
    private int response;

    private final List<ParameterModel> requestParams = new LinkedList();
    private final List<ParameterModel> responseParams = new LinkedList();
    private final List<EventModel> events = new LinkedList();

    public CodecModel(TypeElement parent, ExecutableElement methodElement, ExecutableElement responseElement,
                      List<ExecutableElement> eventElementList, boolean retryable, Lang lang) {
        this.retryable = retryable ? 1 : 0;
        this.lang = lang;

        name = methodElement.getSimpleName().toString();
        parentName = parent.getAnnotation(GenerateCodec.class).name();
        className = CodeGenerationUtils.capitalizeFirstLetter(parentName)
                + CodeGenerationUtils.capitalizeFirstLetter(name) + "Codec";
        packageName = "com.hazelcast.client.impl.protocol.codec";

        
        
        

        response = methodElement.getAnnotation(Request.class).response();
        initParameters(methodElement, responseElement, eventElementList, lang);

    }

    private void initParameters(ExecutableElement methodElement, ExecutableElement responseElement,
                                List<ExecutableElement> eventElementList, Lang lang) {
        
        for (VariableElement param : methodElement.getParameters()) {
            final Nullable nullable = param.getAnnotation(Nullable.class);

            ParameterModel pm = new ParameterModel();
            pm.name = param.getSimpleName().toString();
            pm.type = param.asType().toString();
            pm.lang = lang;
            pm.isPrimitive = param.asType().getKind().isPrimitive();
            pm.isNullable = nullable != null;
            requestParams.add(pm);
        }

        
        for (VariableElement param : responseElement.getParameters()) {
            final Nullable nullable = param.getAnnotation(Nullable.class);
            ParameterModel pm = new ParameterModel();
            pm.name = param.getSimpleName().toString();
            pm.type = param.asType().toString();
            pm.lang = lang;
            pm.isPrimitive = param.asType().getKind().isPrimitive();
            pm.isNullable = nullable != null;
            responseParams.add(pm);
        }


        
        for (ExecutableElement element : eventElementList) {
            List<ParameterModel> eventParam = new ArrayList<ParameterModel>();
            for (VariableElement param : element.getParameters()) {
                final Nullable nullable = param.getAnnotation(Nullable.class);
                ParameterModel pm = new ParameterModel();
                pm.name = param.getSimpleName().toString();
                pm.type = param.asType().toString();
                pm.lang = lang;
                pm.isPrimitive = param.asType().getKind().isPrimitive();
                pm.isNullable = nullable != null;
                eventParam.add(pm);
            }

            EventModel eventModel = new EventModel();
            eventModel.type = element.getAnnotation(EventResponse.class).value();
            eventModel.name = element.getSimpleName().toString();
            eventModel.eventParams = eventParam;

            events.add(eventModel);
        }
    }

    public String getName() {
        return name;
    }

    public String getClassName() {
        return className;
    }

    public String getParentName() {
        return parentName;
    }

    public String getPackageName() {
        return packageName;
    }

    public int getResponse() {
        return response;
    }

    public List<ParameterModel> getRequestParams() {
        return requestParams;
    }

    public List<ParameterModel> getResponseParams() {
        return responseParams;
    }

    public List<EventModel> getEvents() {
        return events;
    }

    public int getRetryable() {
        return retryable;
    }

    public static class EventModel {
        private String name;
        private List<ParameterModel> eventParams;
        private int type;

        public int getType() {
            return type;
        }

        public String getName() {
            return name;
        }

        public String getTypeString() {
            return "EVENT_" + name.toUpperCase();
        }

        public List<ParameterModel> getEventParams() {
            return eventParams;
        }
    }

    public static class ParameterModel {
        private String name;
        private String type;
        private Lang lang;
        private boolean isNullable;
        private boolean isPrimitive;

        public String getName() {
            return name;
        }

        public String getType() {
            if (lang == Lang.CSHARP) {
                return convertTypeToCSharp(type);
            }
            if (type.startsWith("java.util.List<") || type.startsWith("java.util.Set<")
                    || type.startsWith("java.util.Collection<")) {
                return type.replaceAll("java.util.*<(.*)>", "java.util.Collection<$1>");
            }
            return type;
        }

        public String getSizeString() {
            if (lang == Lang.CSHARP) {
                return getSizeStringCSharp();
            }
            return getSizeStringJava();
        }

        public String getSizeStringJava() {
            String stringJava = resolveSizeStringJava(type, name);
            return getNullableCheckedSizeStringJava(stringJava);
        }

        private String getNullableCheckedSizeStringJava(String innerString) {
            StringBuilder sizeString = new StringBuilder();
            if (isNullable) {
                sizeString.append("dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;\n");
                sizeString.append("        if (" + name + " != null) {\n");
                sizeString.append(innerString);
                sizeString.append("        }\n");
                return sizeString.toString();
            } else {
                return innerString;
            }
        }

        private String resolveSizeStringJava(String type, String name) {
            StringBuilder sizeString = new StringBuilder();
            if (type.equals(DATA_FULL_NAME)) {
                sizeString.append("dataSize += ParameterUtil.calculateDataSize(" + name + ");");
            } else if (type.equals("java.lang.Integer")) {
                sizeString.append("dataSize += Bits.INT_SIZE_IN_BYTES;");
            } else if (type.equals("java.lang.Boolean")) {
                sizeString.append("dataSize += Bits.BOOLEAN_SIZE_IN_BYTES;");
            } else if (type.equals("java.lang.String")) {
                sizeString.append("dataSize += ParameterUtil.calculateStringDataSize(" + name + ");");
            } else if (type.equals("int") || type.equals("long") || type.equals("short")
                    || type.equals("byte") || type.equals("boolean")) {
                sizeString.append("dataSize += Bits." + type.toUpperCase() + "_SIZE_IN_BYTES;");
            } else if (type.equals("com.hazelcast.nio.Address")) {
                sizeString.append("dataSize += " + PARAMETERS_PACKAGE + "AddressCodec.calculateDataSize(" + name + ");");
            } else if (type.equals("com.hazelcast.core.Member")) {
                sizeString.append("dataSize += " + PARAMETERS_PACKAGE + "MemberCodec.calculateDataSize(" + name + ");");
            } else if (type.equals("com.hazelcast.cluster.client.MemberAttributeChange")) {
                sizeString.append("dataSize += " + PARAMETERS_PACKAGE
                        + "MemberAttributeChangeCodec.calculateDataSize(" + name + ");");
            } else if (type.equals("com.hazelcast.map.impl.SimpleEntryView<" + DATA_FULL_NAME
                    + "," + DATA_FULL_NAME + ">")) {
                sizeString.append("dataSize += " + PARAMETERS_PACKAGE + "EntryViewCodec.calculateDataSize(" + name + ");");
            } else if (type.equals("com.hazelcast.client.impl.client.DistributedObjectInfo")) {
                sizeString.append("dataSize += "
                        + PARAMETERS_PACKAGE + "DistributedObjectInfoCodec.calculateDataSize(" + name + ");");
            } else if (type.equals("com.hazelcast.mapreduce.JobPartitionState")) {
                sizeString.append("dataSize += "
                        + PARAMETERS_PACKAGE + "JobPartitionStateCodec.calculateDataSize(" + name + ");");
            } else if (type.equals("javax.transaction.xa.Xid")) {
                sizeString.append("dataSize += " + PARAMETERS_PACKAGE + "XIDCodec.calculateDataSize(" + name + ");");
            } else if (type.equals("com.hazelcast.map.impl.querycache.event.SingleEventData")) {
                sizeString.append("dataSize += " + PARAMETERS_PACKAGE + "SingleEventDataCodec.calculateDataSize(" + name + ");");
            } else if (type.equals("com.hazelcast.cache.impl.CacheEventData")) {
                sizeString.append("dataSize += " + PARAMETERS_PACKAGE + "CacheEventDataCodec.calculateDataSize(" + name + ");");
            } else if (type.startsWith("java.util.Map<")) {
                sizeString.append(getMapSizeStringJava(type, name));
            } else if (type.startsWith("java.util.List<") || type.startsWith("java.util.Set<")
                    || type.startsWith("java.util.Collection<")) {

                sizeString.append(getCollectionSizeString(name, type));

            } else if (type.endsWith("[]")) {
                sizeString.append(getArraySizeString(type, name));
            } else {
                sizeString.append(CodeGenerationUtils.capitalizeFirstLetter(type) + "Codec.calculateDataSize(" + name + ");");
            }
            return sizeString.toString();
        }

        private String getArraySizeString(String type, String name) {
            String itemType = CodeGenerationUtils.getTypeInsideData(type);
            StringBuilder builder = new StringBuilder();
            builder.append("dataSize += Bits.INT_SIZE_IN_BYTES;\n        ");
            builder.append("for (" + itemType + " " + name + "_item : " + name + " ) {\n        ");
            builder.append("    " + resolveSizeStringJava(itemType, name + "_item") + "\n        ");
            builder.append("}\n        ");
            return builder.toString();
        }

        private String getCollectionSizeString(String name, String type) {
            String subType = CodeGenerationUtils.getTypeInsideCollection(type);
            StringBuilder builder = new StringBuilder();
            builder.append("dataSize += Bits.INT_SIZE_IN_BYTES;\n        ");
            builder.append("for (" + subType + " " + name + "_item : " + name + " ) {\n        ");
            builder.append("    " + resolveSizeStringJava(subType, name + "_item") + "\n        ");
            builder.append("}\n        ");
            return builder.toString();
        }

        private String getMapSizeStringJava(String type, String name) {
            StringBuilder builder = new StringBuilder();
            String keyType = CodeGenerationUtils.getKeyTypeInsideMap(type);
            builder.append("java.util.Collection<" + keyType + "> " + name
                    + "_keySet = (java.util.Collection<" + keyType + ">) " + name + ".keySet();\n     ");
            builder.append(resolveSizeStringJava("java.util.Collection<" + keyType + "> ", name + "_keySet"));

            String valueType = CodeGenerationUtils.getValueTypeInsideMap(type);
            builder.append("java.util.Collection<" + valueType + "> " + name
                    + "_values = (java.util.Collection<" + valueType + "> )" + name + ".values();\n       ");
            builder.append(resolveSizeStringJava("java.util.Collection<" + valueType + ">", name + "_values"));
            return builder.toString();
        }


        public String getSizeStringCSharp() {
            if (type.equals(DATA_FULL_NAME)) {
                return "ParameterUtil.CalculateDataSize(" + name + ")";
            } else if (type.equals("java.lang.String")) {
                return "ParameterUtil.CalculateStringDataSize(" + name + ")";
            } else if (type.equals("byte[]")) {
                return "ParameterUtil.CalculateByteArrayDataSize(" + name + ")";
            } else if (type.equals("java.util.List<" + DATA_FULL_NAME + " >")
                    || type.equals("java.util.Set<" + DATA_FULL_NAME + " >")
                    || type.equals("java.util.Collection<" + DATA_FULL_NAME + " >")) {
                return "ParameterUtil.CalculateCollectionDataSize(" + name + ")";
            }
            return "BitUtil.SizeOf" + CodeGenerationUtils.capitalizeFirstLetter(type);
        }

        public String getDataGetterString() {
            if (lang == Lang.CSHARP) {
                return getDataGetterStringCSharp();
            }
            return getDataGetterStringJava();
        }

        public String getEventGetterString() {
            String getterString = resolveDataGetterStringJava(type, name) + "\n        ";
            return getNullableCheckedGetterStringJava(getterString);
        }

        public String getDataGetterStringJava() {
            String getterString = resolveDataGetterStringJava(type, name) + "\n        ";
            getterString += "    parameters." + name + " = " + name + "; \n        ";
            return getNullableCheckedGetterStringJava(getterString);
        }

        private String getNullableCheckedGetterStringJava(String innerGetterString) {
            String getterString = type + " " + name + ";\n        ";
            if (!isPrimitive) {
                getterString += name + " = null ;\n        ";
            }

            if (isNullable) {
                getterString += " boolean " + name + "_isNull = clientMessage.getBoolean();\n        ";
                getterString += " if(!" + name + "_isNull) { \n        ";
            }

            getterString += innerGetterString;

            if (isNullable) {
                getterString += "\n             }\n        ";
            }
            return getterString;
        }

        private String resolveDataGetterStringJava(String type, String name) {
            String getterString;

            if (type.equals(DATA_FULL_NAME)) {
                getterString = name + " = clientMessage.getData();";
            } else if (type.equals("java.lang.Integer")) {
                getterString = name + " = clientMessage.getInt();";
            } else if (type.equals("java.lang.Boolean")) {
                getterString = name + " = clientMessage.getBoolean();";
            } else if (type.equals("java.lang.String")) {
                getterString = name + " = clientMessage.getStringUtf8();";
            } else if (type.equals("com.hazelcast.nio.Address")) {
                getterString = name + " = " + PARAMETERS_PACKAGE + "AddressCodec.decode(clientMessage);";
            } else if (type.equals("com.hazelcast.core.Member")) {
                getterString = name + " = " + PARAMETERS_PACKAGE + "MemberCodec.decode(clientMessage);";
            } else if (type.equals("com.hazelcast.cluster.client.MemberAttributeChange")) {
                getterString = name + " = " + PARAMETERS_PACKAGE + "MemberAttributeChangeCodec.decode(clientMessage);";
            } else if (type.equals("com.hazelcast.map.impl.SimpleEntryView<" + DATA_FULL_NAME
                    + "," + DATA_FULL_NAME + ">")) {
                getterString = name + " = " + PARAMETERS_PACKAGE + "EntryViewCodec.decode(clientMessage);";
            } else if (type.equals("com.hazelcast.client.impl.client.DistributedObjectInfo")) {
                getterString = name + " = " + PARAMETERS_PACKAGE + "DistributedObjectInfoCodec.decode(clientMessage);";
            } else if (type.equals("com.hazelcast.mapreduce.JobPartitionState")) {
                getterString = name + " = " + PARAMETERS_PACKAGE + "JobPartitionStateCodec.decode(clientMessage);";
            } else if (type.equals("javax.transaction.xa.Xid")) {
                getterString = name + " = " + PARAMETERS_PACKAGE + "XIDCodec.decode(clientMessage);";
            } else if (type.equals("com.hazelcast.cache.impl.CacheEventData")) {
                getterString = name + " = " + PARAMETERS_PACKAGE + "CacheEventDataCodec.decode(clientMessage);";
            } else if (type.equals("com.hazelcast.map.impl.querycache.event.SingleEventData")) {
                getterString = name + " = " + PARAMETERS_PACKAGE + "SingleEventDataCodec.decode(clientMessage);";
            } else if (type.startsWith("java.util.Map<")) {
                getterString = getMapGetterString(type, name);
            } else if (type.startsWith("java.util.List<") || type.startsWith("java.util.Set<")
                    || type.startsWith("java.util.Collection<")) {
                getterString = getCollectionGetterString(type, name);
            } else if (type.endsWith("[]")) {
                getterString = getArrayGetterString(type, name);
            } else {
                getterString = name + " = clientMessage.get" + CodeGenerationUtils.capitalizeFirstLetter(type) + "();";
            }


            return getterString;
        }

        private String getArrayGetterString(String type, String name) {
            String itemVariableType = CodeGenerationUtils.getTypeInsideData(type);
            String itemVariableName = name + "_item";

            String sizeVariableName = name + "_size";
            String indexVariableName = name + "_index";

            StringBuilder builder = new StringBuilder();
            builder.append("int " + sizeVariableName + " = clientMessage.getInt();\n        ");
            builder.append(name + " = new " + itemVariableType + "[" + sizeVariableName + "];\n        ");
            builder.append("for (int " + indexVariableName + " = 0; " + indexVariableName + " < "
                    + sizeVariableName + "; " + indexVariableName + "++) {\n        ");
            builder.append("    " + itemVariableType + " "
                    + resolveDataGetterStringJava(itemVariableType, itemVariableName) + "\n        ");
            builder.append("    " + name + "[" + indexVariableName + "] = " + itemVariableName + ";");
            builder.append("}\n        ");
            return builder.toString();
        }

        private String getCollectionGetterString(String type, String name) {
            String itemVariableType = CodeGenerationUtils.getTypeInsideCollection(type);
            String itemVariableName = name + "_item";

            StringBuilder builder = new StringBuilder();
            String sizeVariableName = name + "_size";
            String indexVariableName = name + "_index";

            builder.append("int " + sizeVariableName + " = clientMessage.getInt();\n        ");
            String collectionType = getCollectionType(type);
            builder.append(name + " = new " + collectionType + "<" + itemVariableType + ">("
                    + sizeVariableName + ");\n        ");
            builder.append("for (int " + indexVariableName + " = 0; " + indexVariableName + " < "
                    + sizeVariableName + "; " + indexVariableName + "++) {\n        ");
            builder.append("    " + itemVariableType + " " + itemVariableName + ";\n        ");
            builder.append("    " + resolveDataGetterStringJava(itemVariableType, itemVariableName) + "\n        ");
            builder.append("    " + name + ".add( " + itemVariableName + ");\n      ");
            builder.append("}\n        ");
            return builder.toString();
        }

        private String getMapGetterString(String type, String name) {
            String keyType = CodeGenerationUtils.getKeyTypeInsideMap(type);

            StringBuilder builder = new StringBuilder();
            builder.append("java.util.List<" + keyType + "> " + name + "_keySet;\n     ");
            builder.append(resolveDataGetterStringJava("java.util.List<" + keyType + "> ", name + "_keySet"));

            String valueType = CodeGenerationUtils.getValueTypeInsideMap(type);
            builder.append("java.util.List<" + valueType + "> " + name + "_values;\n       ");
            builder.append(resolveDataGetterStringJava("java.util.List<" + valueType + ">", name + "_values"));


            String mapIndexVariableName = name + "_index";
            builder.append(name + " = new java.util.HashMap<" + keyType + "," + valueType + ">();\n       ");

            builder.append("for (int " + mapIndexVariableName + " = 0; " + mapIndexVariableName + " < "
                    + name + "_keySet_size; " + mapIndexVariableName + "++) {\n        ");
            builder.append("    " + name + ".put( " + name + "_keySet.get(" + mapIndexVariableName + ") , "
                    + name + "_values.get(" + mapIndexVariableName + ") );\n        ");
            builder.append("}\n        ");

            return builder.toString();
        }

        private String getCollectionType(String name) {
            if (name.startsWith("java.util.Set")) {
                return "java.util.HashSet";
            } else {
                return "java.util.ArrayList";
            }
        }

        public String getDataGetterStringCSharp() {
            String getterString;
            if (type.equals(DATA_FULL_NAME + " ")) {
                getterString = "GetData";
            } else if (type.equals("java.lang.String")) {
                getterString = "GetStringUtf8";
            } else if (type.equals("byte[]")) {
                getterString = "GetByteArray";
            } else if (type.equals("java.util.List<" + DATA_FULL_NAME + " >")) {
                getterString = "GetDataList";
            } else if (type.equals("java.util.Set<" + DATA_FULL_NAME + " >")) {
                getterString = "GetDataSet";
            } else if (type.equals("java.util.Collection<" + DATA_FULL_NAME + " >")) {
                getterString = "GetDataSet";
            } else {
                getterString = "Get" + CodeGenerationUtils.capitalizeFirstLetter(type);
            }
            return getterString;
        }


        public String getDataSetterString() {



            return getDataSetterStringJava();
        }

        public String getDataSetterStringJava() {
            String setterString = resolveDataSetterStringJava(type, name);
            return getNullableCheckedSetterStringJava(setterString);
        }

        private String getNullableCheckedSetterStringJava(String innerGetterString) {
            StringBuilder setterString = new StringBuilder();


            String isNullVariableName = name + "_isNull";
            if (isNullable) {
                setterString.append("boolean " + isNullVariableName + ";\n            ");
                setterString.append("if (" + name + " == null) {\n            ");
                setterString.append("    " + isNullVariableName + " = true;\n            ");
                setterString.append("    clientMessage.set(" + isNullVariableName + ");\n            ");
                setterString.append("} else {\n            ");
                setterString.append("" + isNullVariableName + " = false;\n            ");
                setterString.append("clientMessage.set(" + isNullVariableName + ");\n            ");
                setterString.append(innerGetterString);
                setterString.append("} \n            ");

                return setterString.toString();
            } else {
                return innerGetterString;
            }

        }

        private String resolveDataSetterStringJava(String type, String name) {
            StringBuilder setterString = new StringBuilder();
            if (type.equals("com.hazelcast.nio.Address")) {
                setterString.append(PARAMETERS_PACKAGE + "AddressCodec.encode(" + name + ",clientMessage);");
            } else if (type.equals("com.hazelcast.core.Member")) {
                setterString.append(PARAMETERS_PACKAGE + "MemberCodec.encode(" + name + ", clientMessage);");
            } else if (type.equals("com.hazelcast.cluster.client.MemberAttributeChange")) {
                setterString.append(PARAMETERS_PACKAGE
                        + "MemberAttributeChangeCodec.encode(" + name + ", clientMessage);");
            } else if (type.equals("com.hazelcast.map.impl.SimpleEntryView<" + DATA_FULL_NAME
                    + "," + DATA_FULL_NAME + ">")) {
                setterString.append(PARAMETERS_PACKAGE + "EntryViewCodec.encode(" + name + ", clientMessage);");
            } else if (type.equals("com.hazelcast.client.impl.client.DistributedObjectInfo")) {
                setterString.append(PARAMETERS_PACKAGE + "DistributedObjectInfoCodec.encode(" + name + ", clientMessage);");
            } else if (type.equals("com.hazelcast.mapreduce.JobPartitionState")) {
                setterString.append(PARAMETERS_PACKAGE + "JobPartitionStateCodec.encode(" + name + ", clientMessage);");
            } else if (type.equals("javax.transaction.xa.Xid")) {
                setterString.append(PARAMETERS_PACKAGE + "XIDCodec.encode(" + name + ", clientMessage);");
            } else if (type.equals("com.hazelcast.cache.impl.CacheEventData")) {
                setterString.append(PARAMETERS_PACKAGE + "CacheEventDataCodec.encode(" + name + ", clientMessage);");
            } else if (type.equals("com.hazelcast.map.impl.querycache.event.SingleEventData")) {
                setterString.append(PARAMETERS_PACKAGE + "SingleEventDataCodec.encode(" + name + ", clientMessage);");
            } else if (type.startsWith("java.util.Map<")) {
                setterString.append(getMapSetterString(type, name));
            } else if (type.startsWith("java.util.List<") || type.startsWith("java.util.Set<")
                    || type.startsWith("java.util.Collection<")) {
                setterString.append(getCollectionSetterString(type, name));
            } else if (type.endsWith("[]")) {
                setterString.append(getArraySetterString(type, name));
            } else {
                setterString.append("clientMessage.set(" + name + ");");
            }
            return setterString.toString();
        }

        private String getArraySetterString(String type, String name) {
            String itemVariableName = name + "_item";

            String itemVariableType = CodeGenerationUtils.getTypeInsideData(type);

            StringBuilder builder = new StringBuilder();
            builder.append("clientMessage.set(" + name + ".length);\n        ");
            builder.append("for (" + itemVariableType + " " + itemVariableName + " : " + name + " ) {\n        ");
            builder.append("    " + resolveDataSetterStringJava(itemVariableType, itemVariableName) + "\n        ");
            builder.append("}\n        ");
            return builder.toString();
        }

        private String getCollectionSetterString(String type, String name) {
            String itemType = CodeGenerationUtils.getTypeInsideCollection(type);
            String itemVariableName = name + "_item";

            StringBuilder builder = new StringBuilder();
            builder.append("clientMessage.set(" + name + ".size());\n        ");
            builder.append("for (" + itemType + " " + itemVariableName + ": " + name + " ) {\n        ");
            builder.append("    " + resolveDataSetterStringJava(itemType, itemVariableName) + "\n        ");
            builder.append("}\n        ");
            return builder.toString();
        }

        private String getMapSetterString(String type, String name) {
            StringBuilder builder = new StringBuilder();

            String keyType = CodeGenerationUtils.getKeyTypeInsideMap(type);
            builder.append("java.util.Collection<" + keyType + "> " + name
                    + "_keySet = (java.util.Collection<" + keyType + ">) " + name + ".keySet();\n     ");
            builder.append(resolveDataSetterStringJava("java.util.Collection<" + keyType + "> ", name + "_keySet"));

            String valueType = CodeGenerationUtils.getValueTypeInsideMap(type);
            builder.append("java.util.Collection<" + valueType + "> " + name
                    + "_values = (java.util.Collection<" + valueType + "> )" + name + ".values();\n       ");
            builder.append(resolveDataSetterStringJava("java.util.Collection<" + valueType + ">", name + "_values"));

            return builder.toString();
        }





















        public String convertTypeToCSharp(String type) {
            String getterString;
            if (type.equals(DATA_FULL_NAME + " ")) {
                getterString = "IData";
            } else if (type.equals("java.lang.String")) {
                getterString = "string";
            } else if (type.equals("boolean")) {
                getterString = "bool";
            } else if (type.equals("java.util.List<" + DATA_FULL_NAME + " >")) {
                getterString = "IList<IData>";
            } else if (type.equals("java.util.Set<" + DATA_FULL_NAME + " >")) {
                getterString = "ISet<IData>";
            } else if (type.equals("java.util.Collection<" + DATA_FULL_NAME + " >")) {
                getterString = "ICollection<IData>";
            } else {
                getterString = type;
            }
            return getterString;
        }

        @Override
        public String toString() {
            return "ParameterModel{"
                    + "name='" + name + '\''
                    + ", type='" + type + '\''
                    + ", lang=" + lang
                    + '}';
        }
    }
}

<code block>


package com.hazelcast.client.protocol.generator;

import com.hazelcast.annotation.EventResponse;
import com.hazelcast.annotation.GenerateCodec;
import com.hazelcast.annotation.Request;
import com.hazelcast.annotation.Response;
import freemarker.cache.ClassTemplateLoader;
import freemarker.log.Logger;
import freemarker.template.Configuration;
import freemarker.template.Template;

import javax.annotation.processing.AbstractProcessor;
import javax.annotation.processing.Filer;
import javax.annotation.processing.Messager;
import javax.annotation.processing.ProcessingEnvironment;
import javax.annotation.processing.RoundEnvironment;
import javax.annotation.processing.SupportedAnnotationTypes;
import javax.annotation.processing.SupportedSourceVersion;
import javax.lang.model.SourceVersion;
import javax.lang.model.element.Element;
import javax.lang.model.element.ElementKind;
import javax.lang.model.element.ExecutableElement;
import javax.lang.model.element.TypeElement;
import javax.tools.Diagnostic;
import javax.tools.FileObject;
import javax.tools.JavaFileManager;
import javax.tools.JavaFileObject;
import javax.tools.StandardLocation;
import java.io.IOException;
import java.io.StringWriter;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Set;

@SupportedAnnotationTypes("com.hazelcast.annotation.GenerateCodec")
@SupportedSourceVersion(SourceVersion.RELEASE_6)
public class CodecCodeGenerator
        extends AbstractProcessor {

    private Filer filer;
    private Messager messager;
    private Template codecTemplate;

    private Template messageTypeTemplate;
    private Template messageTypeTemplateCSharp;


    private Map<String, ExecutableElement> requestMap = new HashMap<String, ExecutableElement>();
    private Map<Integer, ExecutableElement> responseMap = new HashMap<Integer, ExecutableElement>();
    private Map<Integer, ExecutableElement> eventResponseMap = new HashMap<Integer, ExecutableElement>();

    @Override
    public void init(ProcessingEnvironment env) {

        filer = env.getFiler();
        messager = env.getMessager();

        try {
            Logger.selectLoggerLibrary(Logger.LIBRARY_NONE);
        } catch (ClassNotFoundException e) {
            messager.printMessage(Diagnostic.Kind.ERROR, e.getMessage());
        }
        Configuration cfg = new Configuration(Configuration.VERSION_2_3_22);
        cfg.setTemplateLoader(new ClassTemplateLoader(getClass(), "/"));
        try {
            codecTemplate = cfg.getTemplate("codec-template-java.ftl");

            messageTypeTemplate = cfg.getTemplate("messagetype-template-java.ftl");
            messageTypeTemplateCSharp = cfg.getTemplate("messagetype-template-csharp.ftl");
        } catch (IOException e) {
            messager.printMessage(Diagnostic.Kind.ERROR, e.getMessage());
            
        }
    }

    @Override
    public boolean process(Set<? extends TypeElement> elements, RoundEnvironment env) {
        try {
            for (Element element : env.getElementsAnnotatedWith(GenerateCodec.class)) {
                register((TypeElement) element, Lang.JAVA);
            }

            for (Element element : env.getElementsAnnotatedWith(GenerateCodec.class)) {
                generateMessageTypeEnum((TypeElement) element, Lang.JAVA);
            }

            for (ExecutableElement element : requestMap.values()) {
                generateCodec(element, Lang.JAVA);
                
                
                
                
                
                
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
        return true;
    }

    public void register(TypeElement classElement, Lang lang) {
        for (Element enclosedElement : classElement.getEnclosedElements()) {
            if (!enclosedElement.getKind().equals(ElementKind.METHOD)) {
                continue;
            }
            ExecutableElement methodElement = (ExecutableElement) enclosedElement;

            short masterId = classElement.getAnnotation(GenerateCodec.class).id();

            final Request request = methodElement.getAnnotation(Request.class);
            if (request != null) {
                String id = CodeGenerationUtils.mergeIds(masterId, request.id());
                requestMap.put(id, methodElement);
                continue;
            }

            final Response response = methodElement.getAnnotation(Response.class);
            if (response != null) {
                responseMap.put(response.value(), methodElement);
                continue;
            }

            final EventResponse eventResponse = methodElement.getAnnotation(EventResponse.class);
            if (eventResponse != null) {
                eventResponseMap.put(eventResponse.value(), methodElement);
            }

        }
    }

    public void generateCodec(ExecutableElement methodElement, Lang lang) {
        final TypeElement parent = (TypeElement) methodElement.getEnclosingElement();

        final Request methodElementAnnotation = methodElement.getAnnotation(Request.class);
        final int response = methodElementAnnotation.response();
        final int[] events = methodElementAnnotation.event();
        final boolean retryable = methodElementAnnotation.retryable();

        ExecutableElement responseElement = responseMap.get(response);

        List<ExecutableElement> eventElementList = new ArrayList<ExecutableElement>();
        if (events != null) {
            for (Integer eventType : events) {
                final ExecutableElement eventResponse = eventResponseMap.get(eventType);
                if (eventResponse != null) {
                    eventElementList.add(eventResponse);
                }
            }
        }

        CodecModel codecModel = new CodecModel(parent, methodElement,
                responseElement, eventElementList, retryable, lang);

        final String content;
        switch (lang) {
            case JAVA:
                content = generateFromTemplate(codecTemplate, codecModel);
                saveClass(codecModel.getPackageName(), codecModel.getClassName(), content);
                break;
            case CSHARP:



            case CPP:
                
                
                
                break;
            default:
                throw new UnsupportedOperationException("Unsupported language: " + lang);
        }
    }

    private void generateMessageTypeEnum(TypeElement classElement, Lang lang) {
        MessageTypeEnumModel clazz = new MessageTypeEnumModel(classElement, lang);
        if (clazz.isEmpty()) {
            return;
        }
        final String content;
        switch (lang) {
            case JAVA:
                content = generateFromTemplate(messageTypeTemplate, clazz);
                saveClass(clazz.getPackageName(), clazz.getClassName(), content);
                break;
            case CSHARP:
                content = generateFromTemplate(messageTypeTemplateCSharp, clazz);
                saveFile(clazz.getClassName() + ".cs", clazz.getPackageName(), content);
                break;
            case CPP:
                
                
                
                break;
            default:
                throw new UnsupportedOperationException("Unsupported language: " + lang);

        }
    }

    private void saveClass(String packageName, String className, String content) {
        JavaFileObject file;
        try {
            final String fullClassName = packageName + "." + className;
            file = filer.createSourceFile(fullClassName);
            file.openWriter().append(content).close();
        } catch (IOException e) {
            messager.printMessage(Diagnostic.Kind.WARNING, e.getMessage());
        }
    }

    private void saveFile(String fileName, String packageName, String content) {
        FileObject file;
        try {
            final JavaFileManager.Location location = StandardLocation.locationFor(StandardLocation.SOURCE_OUTPUT.name());
            file = filer.createResource(location, packageName, fileName);
            file.openWriter().append(content).close();
        } catch (IOException e) {
            messager.printMessage(Diagnostic.Kind.ERROR, e.getMessage());
        }
    }

    private String generateFromTemplate(Template template, Object model) {
        String content = null;
        try {
            Map<String, Object> data = new HashMap();
            data.put("model", model);
            StringWriter writer = new StringWriter();
            template.process(data, writer);
            content = writer.toString();
        } catch (Exception e) {
            messager.printMessage(Diagnostic.Kind.ERROR, e.getMessage());
        }
        return content;
    }
}

<code block>


package com.hazelcast.client.protocol.generator;

public final class CodeGenerationUtils {

    private static final int BYTE_BIT_COUNT = 8;

    private CodeGenerationUtils() {
    }

    public static String capitalizeFirstLetter(String input) {
        return input.substring(0, 1).toUpperCase() + input.substring(1);
    }


    public static String getPackageNameFromQualifiedName(String qualifiedClassName) {
        return qualifiedClassName.substring(0, qualifiedClassName.lastIndexOf("."));
    }

    public static String mergeIds(short classId, short methodId) {
        final String s = Integer.toHexString((classId << BYTE_BIT_COUNT) + methodId);
        return s.length() == 3 ? "0x0" + s : "0x" + s;
    }

    public static String getTypeInsideData(String type) {
        int end = type.indexOf("[]");
        return type.substring(0, end);
    }

    public static String getTypeInsideCollection(String type) {
        int beg = type.indexOf("<");
        int end = type.lastIndexOf(">");
        return type.substring(beg + 1, end);
    }

    public static String getKeyTypeInsideMap(String type) {
        int beg = type.indexOf("<");
        int end = type.lastIndexOf(",");
        return type.substring(beg + 1, end);
    }

    public static String getValueTypeInsideMap(String type) {
        int beg = type.indexOf(",");
        int end = type.lastIndexOf(">");
        return type.substring(beg + 1, end);
    }


}

<code block>


package com.hazelcast.query;

import com.hazelcast.query.impl.predicates.AndPredicate;
import com.hazelcast.query.impl.predicates.BetweenPredicate;
import com.hazelcast.query.impl.predicates.EqualPredicate;
import com.hazelcast.query.impl.predicates.GreaterLessPredicate;
import com.hazelcast.query.impl.predicates.ILikePredicate;
import com.hazelcast.query.impl.predicates.InPredicate;
import com.hazelcast.query.impl.predicates.InstanceOfPredicate;
import com.hazelcast.query.impl.predicates.LikePredicate;
import com.hazelcast.query.impl.predicates.NotEqualPredicate;
import com.hazelcast.query.impl.predicates.NotPredicate;
import com.hazelcast.query.impl.predicates.OrPredicate;
import com.hazelcast.query.impl.predicates.RegexPredicate;


public final class Predicates {

    
    private Predicates() {
    }

    public static Predicate instanceOf(final Class klass) {
        return new InstanceOfPredicate(klass);
    }

    public static Predicate and(Predicate... predicates) {
        return new AndPredicate(predicates);
    }

    public static Predicate not(Predicate predicate) {
        return new NotPredicate(predicate);
    }

    
    public static Predicate or(Predicate... predicates) {
        return new OrPredicate(predicates);
    }

    public static Predicate notEqual(String attribute, Comparable y) {
        return new NotEqualPredicate(attribute, y);
    }

    public static Predicate equal(String attribute, Comparable y) {
        return new EqualPredicate(attribute, y);
    }

    public static Predicate like(String attribute, String pattern) {
        return new LikePredicate(attribute, pattern);
    }

    public static Predicate ilike(String attribute, String pattern) {
        return new ILikePredicate(attribute, pattern);
    }

    public static Predicate regex(String attribute, String pattern) {
        return new RegexPredicate(attribute, pattern);
    }

    public static Predicate greaterThan(String x, Comparable y) {
        return new GreaterLessPredicate(x, y, false, false);
    }

    public static Predicate greaterEqual(String x, Comparable y) {
        return new GreaterLessPredicate(x, y, true, false);
    }

    public static Predicate lessThan(String x, Comparable y) {
        return new GreaterLessPredicate(x, y, false, true);
    }

    public static Predicate lessEqual(String x, Comparable y) {
        return new GreaterLessPredicate(x, y, true, true);
    }

    public static Predicate between(String attribute, Comparable from, Comparable to) {
        return new BetweenPredicate(attribute, from, to);
    }

    public static Predicate in(String attribute, Comparable... values) {
        return new InPredicate(attribute, values);
    }

}

<code block>


package com.hazelcast.query;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.query.impl.IndexImpl;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Set;

import com.hazelcast.query.impl.predicates.AbstractPredicate;
import static com.hazelcast.query.Predicates.and;
import static com.hazelcast.query.Predicates.between;
import static com.hazelcast.query.Predicates.equal;
import static com.hazelcast.query.Predicates.greaterEqual;
import static com.hazelcast.query.Predicates.greaterThan;
import static com.hazelcast.query.Predicates.ilike;
import static com.hazelcast.query.Predicates.lessEqual;
import static com.hazelcast.query.Predicates.lessThan;
import static com.hazelcast.query.Predicates.like;
import static com.hazelcast.query.Predicates.notEqual;
import static com.hazelcast.query.Predicates.or;
import static com.hazelcast.query.Predicates.regex;



public class SqlPredicate extends AbstractPredicate implements IndexAwarePredicate {

    private static final long serialVersionUID = 1;

    private transient Predicate predicate;
    private String sql;

    public SqlPredicate(String sql) {
        this.sql = sql;
        predicate = createPredicate(sql);
    }

    public SqlPredicate() {
    }

    @Override
    public boolean apply(Map.Entry mapEntry) {
        return predicate.apply(mapEntry);
    }

    @Override
    public boolean isIndexed(QueryContext queryContext) {
        if (predicate instanceof IndexAwarePredicate) {
            return ((IndexAwarePredicate) predicate).isIndexed(queryContext);
        }
        return false;
    }

    @Override
    public Set<QueryableEntry> filter(QueryContext queryContext) {
        return ((IndexAwarePredicate) predicate).filter(queryContext);
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeUTF(sql);
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        sql = in.readUTF();
        predicate = createPredicate(sql);
    }

    private int getApostropheIndex(String str, int start) {
        return str.indexOf('\'', start);
    }

    private int getApostropheIndexIgnoringDoubles(String str, int start) {
        int i = str.indexOf('\'', start);
        int j = str.indexOf('\'', i + 1);
        
        while (i == j - 1) {
            i = str.indexOf('\'', j + 1);
            j = str.indexOf('\'', i + 1);
        }
        return i;
    }

    private String removeEscapes(String phrase) {
        return (phrase.length() > 2) ? phrase.replace("''", "'") : phrase;
    }

    private Predicate createPredicate(String sql) {
        String paramSql = sql;
        Map<String, String> mapPhrases = new HashMap<String, String>(1);
        int apoIndex = getApostropheIndex(paramSql, 0);
        if (apoIndex != -1) {
            int phraseId = 0;
            StringBuilder newSql = new StringBuilder();
            while (apoIndex != -1) {
                phraseId++;
                int start = apoIndex + 1;
                int end = getApostropheIndexIgnoringDoubles(paramSql, apoIndex + 1);
                if (end == -1) {
                    throw new RuntimeException("Missing ' in sql");
                }
                String phrase = removeEscapes(paramSql.substring(start, end));

                String key = "$" + phraseId;
                mapPhrases.put(key, phrase);
                String before = paramSql.substring(0, apoIndex);
                paramSql = paramSql.substring(end + 1);
                newSql.append(before);
                newSql.append(key);
                apoIndex = getApostropheIndex(paramSql, 0);
            }
            newSql.append(paramSql);
            paramSql = newSql.toString();
        }
        Parser parser = new Parser();
        List<String> sqlTokens = parser.toPrefix(paramSql);
        List<Object> tokens = new ArrayList<Object>(sqlTokens);
        if (tokens.size() == 0) {
            throw new RuntimeException("Invalid SQL: [" + paramSql + "]");
        }
        if (tokens.size() == 1) {
            return eval(tokens.get(0));
        }
        root:
        while (tokens.size() > 1) {
            boolean foundOperand = false;
            for (int i = 0; i < tokens.size(); i++) {
                Object tokenObj = tokens.get(i);
                if (tokenObj instanceof String && parser.isOperand((String) tokenObj)) {
                    String token = (String) tokenObj;
                    if ("=".equals(token) || "==".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, equal((String) first, (Comparable) second));
                    } else if ("!=".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, notEqual((String) first, (Comparable) second));
                    } else if (">".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, greaterThan((String) first, (Comparable) second));
                    } else if (">=".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, greaterEqual((String) first, (Comparable) second));
                    } else if ("<=".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, lessEqual((String) first, (Comparable) second));
                    } else if ("<".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, lessThan((String) first, (Comparable) second));
                    } else if ("LIKE".equalsIgnoreCase(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, like((String) first, (String) second));
                    } else if ("ILIKE".equalsIgnoreCase(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, ilike((String) first, (String) second));
                    } else if ("REGEX".equalsIgnoreCase(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, regex((String) first, (String) second));
                    } else if ("IN".equalsIgnoreCase(token)) {
                        int position = i - 2;
                        validateOperandPosition(position);
                        Object exp = toValue(tokens.remove(position), mapPhrases);
                        String[] values = toValue(((String) tokens.remove(position)).split(","), mapPhrases);
                        setOrAdd(tokens, position, Predicates.in((String) exp, values));
                    } else if ("NOT".equalsIgnoreCase(token)) {
                        int position = i - 1;
                        validateOperandPosition(position);
                        Object exp = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, Predicates.not(eval(exp)));
                    } else if ("BETWEEN".equalsIgnoreCase(token)) {
                        int position = i - 3;
                        validateOperandPosition(position);
                        Object expression = tokens.remove(position);
                        Object from = toValue(tokens.remove(position), mapPhrases);
                        Object to = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, between((String) expression, (Comparable) from, (Comparable) to));
                    } else if ("AND".equalsIgnoreCase(token)) {
                        int position = i - 2;
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, and(eval(first), eval(second)));
                    } else if ("OR".equalsIgnoreCase(token)) {
                        int position = i - 2;
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, or(eval(first), eval(second)));
                    } else {
                        throw new RuntimeException("Unknown token " + token);
                    }
                    continue root;
                }
            }
            if (!foundOperand) {
                throw new RuntimeException("Invalid SQL: [" + paramSql + "]");
            }
        }
        return (Predicate) tokens.get(0);
    }

    private void validateOperandPosition(int pos) {
        if (pos < 0) {
            throw new RuntimeException("Invalid SQL: [" + sql + "]");
        }
    }

    private Object toValue(final Object key, final Map<String, String> phrases) {
        final String value = phrases.get(key);
        if (value != null) {
            return value;
        } else if (key instanceof String && ("null".equalsIgnoreCase((String) key))) {
            return IndexImpl.NULL;
        } else {
            return key;
        }
    }

    private String[] toValue(final String[] keys, final Map<String, String> phrases) {
        for (int i = 0; i < keys.length; i++) {
            final String value = phrases.get(keys[i]);
            if (value != null) {
                keys[i] = value;
            }
        }
        return keys;
    }

    private void setOrAdd(List tokens, int position, Predicate predicate) {
        if (tokens.size() == 0) {
            tokens.add(predicate);
        } else {
            tokens.set(position, predicate);
        }
    }

    private Predicate eval(Object statement) {
        if (statement instanceof String) {
            return equal((String) statement, "true");
        } else {
            return (Predicate) statement;
        }
    }

    private void readObject(java.io.ObjectInputStream in)
            throws IOException, ClassNotFoundException {
        predicate = createPredicate(sql);
    }

    @Override
    public String toString() {
        return predicate.toString();
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (!(o instanceof SqlPredicate)) {
            return false;
        }

        SqlPredicate that = (SqlPredicate) o;

        return sql.equals(that.sql);
    }

    @Override
    public int hashCode() {
        return sql.hashCode();
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.query.impl.ComparisonType;
import com.hazelcast.query.impl.Index;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.Map;
import java.util.Set;


public class GreaterLessPredicate extends EqualPredicate {
    boolean equal;
    boolean less;

    public GreaterLessPredicate() {
    }

    public GreaterLessPredicate(String attribute, Comparable value, boolean equal, boolean less) {
        super(attribute);

        if (value == null) {
            throw new NullPointerException("Arguments can't be null");
        }

        this.value = value;
        this.equal = equal;
        this.less = less;
    }

    @Override
    public boolean apply(Map.Entry mapEntry) {
        final Comparable entryValue = readAttribute(mapEntry);
        if (entryValue == null) {
            return false;
        }
        final Comparable attributeValue = convert(mapEntry, entryValue, value);
        final int result = entryValue.compareTo(attributeValue);
        return equal && result == 0 || (less ? (result < 0) : (result > 0));
    }

    @Override
    public Set<QueryableEntry> filter(QueryContext queryContext) {
        Index index = getIndex(queryContext);
        final ComparisonType comparisonType;
        if (less) {
            comparisonType = equal ? ComparisonType.LESSER_EQUAL : ComparisonType.LESSER;
        } else {
            comparisonType = equal ? ComparisonType.GREATER_EQUAL : ComparisonType.GREATER;
        }
        return index.getSubRecords(comparisonType, value);
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        super.readData(in);
        equal = in.readBoolean();
        less = in.readBoolean();
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        super.writeData(out);
        out.writeBoolean(equal);
        out.writeBoolean(less);
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append(attribute);
        sb.append(less ? "<" : ">");
        if (equal) {
            sb.append("=");
        }
        sb.append(value);
        return sb.toString();
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.query.impl.IndexImpl;
import com.hazelcast.query.impl.QueryableEntry;

import java.util.Map;


public final class AttributeUtils {

    private AttributeUtils() {
    }

    static Comparable readAttribute(Map.Entry entry, String attribute) {
        QueryableEntry queryableEntry = (QueryableEntry) entry;
        Comparable value = queryableEntry.getAttribute(attribute);
        if (value == null) {
            return IndexImpl.NULL;
        }
        return value;
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.nio.serialization.HazelcastSerializationException;
import com.hazelcast.query.Predicate;

import java.io.IOException;
import java.util.Map;


public class InstanceOfPredicate implements Predicate, DataSerializable {
    private Class klass;

    public InstanceOfPredicate(Class klass) {
        this.klass = klass;
    }

    @Override
    public boolean apply(Map.Entry mapEntry) {
        Object value = mapEntry.getValue();
        if (value == null) {
            return false;
        }
        return klass.isAssignableFrom(value.getClass());
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeUTF(klass.getName());
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        String klassName = in.readUTF();
        try {
            klass = in.getClassLoader().loadClass(klassName);
        } catch (ClassNotFoundException e) {
            throw new HazelcastSerializationException("Failed to load class: " + klass, e);
        }
    }

    @Override
    public String toString() {
        return " instanceOf (" + klass.getName() + ")";
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.query.IndexAwarePredicate;
import com.hazelcast.query.Predicate;
import com.hazelcast.query.impl.AndResultSet;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Set;


public class AndPredicate implements IndexAwarePredicate, DataSerializable {

    protected Predicate[] predicates;

    public AndPredicate() {
    }

    public AndPredicate(Predicate... predicates) {
        this.predicates = predicates;
    }

    @Override
    public Set<QueryableEntry> filter(QueryContext queryContext) {
        Set<QueryableEntry> smallestIndexedResult = null;
        List<Set<QueryableEntry>> otherIndexedResults = new LinkedList<Set<QueryableEntry>>();
        List<Predicate> lsNoIndexPredicates = null;
        for (Predicate predicate : predicates) {
            boolean indexed = false;
            if (predicate instanceof IndexAwarePredicate) {
                IndexAwarePredicate iap = (IndexAwarePredicate) predicate;
                if (iap.isIndexed(queryContext)) {
                    indexed = true;
                    Set<QueryableEntry> s = iap.filter(queryContext);
                    if (smallestIndexedResult == null) {
                        smallestIndexedResult = s;
                    } else if (s.size() < smallestIndexedResult.size()) {
                        otherIndexedResults.add(smallestIndexedResult);
                        smallestIndexedResult = s;
                    } else {
                        otherIndexedResults.add(s);
                    }
                }
            }
            if (!indexed) {
                if (lsNoIndexPredicates == null) {
                    lsNoIndexPredicates = new LinkedList<Predicate>();
                }
                lsNoIndexPredicates.add(predicate);
            }
        }
        if (smallestIndexedResult == null) {
            return null;
        }
        return new AndResultSet(smallestIndexedResult, otherIndexedResults, lsNoIndexPredicates);
    }

    @Override
    public boolean isIndexed(QueryContext queryContext) {
        for (Predicate predicate : predicates) {
            if (predicate instanceof IndexAwarePredicate) {
                IndexAwarePredicate iap = (IndexAwarePredicate) predicate;
                if (iap.isIndexed(queryContext)) {
                    return true;
                }
            }
        }
        return false;
    }

    @Override
    public boolean apply(Map.Entry mapEntry) {
        for (Predicate predicate : predicates) {
            if (!predicate.apply(mapEntry)) {
                return false;
            }
        }
        return true;
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("(");
        int size = predicates.length;
        for (int i = 0; i < size; i++) {
            if (i > 0) {
                sb.append(" AND ");
            }
            sb.append(predicates[i]);
        }
        sb.append(")");
        return sb.toString();
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeInt(predicates.length);
        for (Predicate predicate : predicates) {
            out.writeObject(predicate);
        }
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        int size = in.readInt();
        predicates = new Predicate[size];
        for (int i = 0; i < size; i++) {
            predicates[i] = in.readObject();
        }
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.query.Predicate;

import java.io.IOException;
import java.util.Map;


public class NotPredicate implements Predicate, DataSerializable {
    private Predicate predicate;

    public NotPredicate(Predicate predicate) {
        this.predicate = predicate;
    }

    public NotPredicate() {
    }

    @Override
    public boolean apply(Map.Entry mapEntry) {
        return !predicate.apply(mapEntry);
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeObject(predicate);
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        predicate = in.readObject();
    }

    @Override
    public String toString() {
        return "NOT(" + predicate + ")";
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.query.IndexAwarePredicate;
import com.hazelcast.query.QueryException;
import com.hazelcast.query.impl.AttributeType;
import com.hazelcast.query.impl.Index;
import com.hazelcast.query.impl.IndexImpl;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.Map;


public abstract class AbstractPredicate implements IndexAwarePredicate, DataSerializable {

    protected String attribute;
    private transient volatile AttributeType attributeType;

    protected AbstractPredicate() {
    }

    protected AbstractPredicate(String attribute) {
        this.attribute = attribute;
    }

    protected Comparable convert(Map.Entry mapEntry, Comparable entryValue, Comparable attributeValue) {
        if (attributeValue == null) {
            return null;
        }
        if (attributeValue instanceof IndexImpl.NullObject) {
            return IndexImpl.NULL;
        }
        AttributeType type = attributeType;
        if (type == null) {
            QueryableEntry queryableEntry = (QueryableEntry) mapEntry;
            type = queryableEntry.getAttributeType(attribute);
            attributeType = type;
        }
        if (type == AttributeType.ENUM) {
            
            return type.getConverter().convert(attributeValue);
        } else {
            
            if (entryValue != null && entryValue.getClass().isAssignableFrom(attributeValue.getClass())) {
                return attributeValue;
            } else if (type != null) {
                return type.getConverter().convert(attributeValue);
            } else {
                throw new QueryException("Unknown attribute type: " + attributeValue.getClass().getName()
                        + " for attribute: " + attribute);
            }
        }
    }

    @Override
    public boolean isIndexed(QueryContext queryContext) {
        return getIndex(queryContext) != null;
    }

    protected Index getIndex(QueryContext queryContext) {
        return queryContext.getIndex(attribute);
    }

    protected Comparable readAttribute(Map.Entry entry) {
        QueryableEntry queryableEntry = (QueryableEntry) entry;
        Comparable val = queryableEntry.getAttribute(attribute);
        if (val != null && val.getClass().isEnum()) {
            val = val.toString();
        }
        return val;
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeUTF(attribute);
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        attribute = in.readUTF();
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.query.impl.Index;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.Map;
import java.util.Set;


public class BetweenPredicate extends AbstractPredicate {
    private Comparable to;
    private Comparable from;

    public BetweenPredicate() {
    }

    public BetweenPredicate(String first, Comparable from, Comparable to) {
        super(first);
        if (from == null || to == null) {
            throw new NullPointerException("Arguments can't be null");
        }
        this.from = from;
        this.to = to;
    }

    @Override
    public boolean apply(Map.Entry entry) {
        Comparable entryValue = readAttribute(entry);
        if (entryValue == null) {
            return false;
        }
        Comparable fromConvertedValue = convert(entry, entryValue, from);
        Comparable toConvertedValue = convert(entry, entryValue, to);
        if (fromConvertedValue == null || toConvertedValue == null) {
            return false;
        }
        return entryValue.compareTo(fromConvertedValue) >= 0 && entryValue.compareTo(toConvertedValue) <= 0;
    }

    @Override
    public Set<QueryableEntry> filter(QueryContext queryContext) {
        Index index = getIndex(queryContext);
        return index.getSubRecordsBetween(from, to);
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        super.writeData(out);
        out.writeObject(to);
        out.writeObject(from);
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        super.readData(in);
        to = in.readObject();
        from = in.readObject();
    }

    @Override
    public String toString() {
        return attribute + " BETWEEN " + from + " AND " + to;
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.query.impl.ComparisonType;
import com.hazelcast.query.impl.Index;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.util.Map;
import java.util.Set;


public class NotEqualPredicate extends EqualPredicate {
    public NotEqualPredicate() {
    }

    public NotEqualPredicate(String attribute, Comparable value) {
        super(attribute, value);
    }

    @Override
    public boolean apply(Map.Entry entry) {
        Comparable entryValue = readAttribute(entry);
        if (entryValue == null) {
            return false;
        }

        return !super.apply(entry);
    }

    @Override
    public Set<QueryableEntry> filter(QueryContext queryContext) {
        Index index = getIndex(queryContext);
        if (index != null) {
            return index.getSubRecords(ComparisonType.NOT_EQUAL, value);
        } else {
            return null;
        }
    }

    @Override
    public String toString() {
        return attribute + " != " + value;
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.query.IndexAwarePredicate;
import com.hazelcast.query.Predicate;
import com.hazelcast.query.impl.OrResultSet;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Set;


public class OrPredicate implements IndexAwarePredicate, DataSerializable {

    private Predicate[] predicates;

    public OrPredicate() {
    }

    public OrPredicate(Predicate... predicates) {
        this.predicates = predicates;
    }

    @Override
    public Set<QueryableEntry> filter(QueryContext queryContext) {
        List<Set<QueryableEntry>> indexedResults = new LinkedList<Set<QueryableEntry>>();
        for (Predicate predicate : predicates) {
            if (predicate instanceof IndexAwarePredicate) {
                IndexAwarePredicate iap = (IndexAwarePredicate) predicate;
                if (iap.isIndexed(queryContext)) {
                    Set<QueryableEntry> s = iap.filter(queryContext);
                    if (s != null) {
                        indexedResults.add(s);
                    }
                } else {
                    return null;
                }
            }
        }
        return indexedResults.isEmpty() ? null : new OrResultSet(indexedResults);
    }

    @Override
    public boolean isIndexed(QueryContext queryContext) {
        for (Predicate predicate : predicates) {
            if (predicate instanceof IndexAwarePredicate) {
                IndexAwarePredicate iap = (IndexAwarePredicate) predicate;
                if (!iap.isIndexed(queryContext)) {
                    return false;
                }
            } else {
                return false;
            }
        }
        return true;
    }

    @Override
    public boolean apply(Map.Entry mapEntry) {
        for (Predicate predicate : predicates) {
            if (predicate.apply(mapEntry)) {
                return true;
            }
        }
        return false;
    }


    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeInt(predicates.length);
        for (Predicate predicate : predicates) {
            out.writeObject(predicate);
        }
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        int size = in.readInt();
        predicates = new Predicate[size];
        for (int i = 0; i < size; i++) {
            predicates[i] = in.readObject();
        }
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("(");
        int size = predicates.length;
        for (int i = 0; i < size; i++) {
            if (i > 0) {
                sb.append(" OR ");
            }
            sb.append(predicates[i]);
        }
        sb.append(")");
        return sb.toString();
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.query.impl.Index;
import com.hazelcast.query.impl.IndexImpl;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.Map;
import java.util.Set;


public class EqualPredicate extends AbstractPredicate {
    protected Comparable value;

    public EqualPredicate() {
    }

    public EqualPredicate(String attribute) {
        super(attribute);
    }

    public EqualPredicate(String attribute, Comparable value) {
        super(attribute);
        this.value = value;
    }

    @Override
    public Set<QueryableEntry> filter(QueryContext queryContext) {
        Index index = getIndex(queryContext);
        return index.getRecords(value);
    }

    @Override
    public boolean apply(Map.Entry mapEntry) {
        Comparable entryValue = readAttribute(mapEntry);
        if (entryValue == null) {
            return value == null || value == IndexImpl.NULL;
        }
        value = convert(mapEntry, entryValue, value);
        return entryValue.equals(value);
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        super.writeData(out);
        out.writeObject(value);
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        super.readData(in);
        value = in.readObject();
    }

    @Override
    public String toString() {
        return attribute + "=" + value;
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.query.impl.Index;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;


public class InPredicate extends AbstractPredicate {
    private Comparable[] values;
    private volatile Set<Comparable> convertedInValues;

    public InPredicate() {
    }

    public InPredicate(String attribute, Comparable... values) {
        super(attribute);

        if (values == null) {
            throw new NullPointerException("Array can't be null");
        }
        this.values = values;
    }

    @Override
    public boolean apply(Map.Entry entry) {
        Comparable entryValue = readAttribute(entry);
        if (entryValue == null) {
            return false;
        }
        Set<Comparable> set = convertedInValues;
        if (set == null) {
            set = new HashSet<Comparable>(values.length);
            for (Comparable value : values) {
                set.add(convert(entry, entryValue, value));
            }
            convertedInValues = set;
        }
        return set.contains(entryValue);
    }

    @Override
    public Set<QueryableEntry> filter(QueryContext queryContext) {
        Index index = getIndex(queryContext);
        if (index != null) {
            return index.getRecords(values);
        } else {
            return null;
        }
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        super.writeData(out);
        out.writeInt(values.length);
        for (Object value : values) {
            out.writeObject(value);
        }
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        super.readData(in);
        int len = in.readInt();
        values = new Comparable[len];
        for (int i = 0; i < len; i++) {
            values[i] = in.readObject();
        }
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append(attribute);
        sb.append(" IN (");
        for (int i = 0; i < values.length; i++) {
            if (i > 0) {
                sb.append(",");
            }
            sb.append(values[i]);
        }
        sb.append(")");
        return sb.toString();
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import java.util.regex.Pattern;


public class ILikePredicate extends LikePredicate {

    public ILikePredicate() {
    }

    public ILikePredicate(String attribute, String second) {
        super(attribute, second);
    }

    @Override
    public String toString() {
        StringBuilder builder = new StringBuilder(attribute)
                .append(" ILIKE '")
                .append(second)
                .append("'");
        return builder.toString();
    }


    @Override
    protected int getFlags() {
        return Pattern.CASE_INSENSITIVE;
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.query.Predicate;
import com.hazelcast.query.impl.IndexImpl;

import java.io.IOException;
import java.util.Map;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import static com.hazelcast.query.impl.predicates.AttributeUtils.readAttribute;


public class RegexPredicate implements Predicate, DataSerializable {
    private String attribute;
    private String regex;
    private volatile Pattern pattern;

    public RegexPredicate() {
    }

    public RegexPredicate(String attribute, String regex) {
        this.attribute = attribute;
        this.regex = regex;
    }

    @Override
    public boolean apply(Map.Entry entry) {
        Comparable attribute = readAttribute(entry, this.attribute);
        String firstVal = attribute == IndexImpl.NULL ? null : (String) attribute;
        if (firstVal == null) {
            return (regex == null);
        } else if (regex == null) {
            return false;
        } else {
            if (pattern == null) {
                pattern = Pattern.compile(regex);
            }
            Matcher m = pattern.matcher(firstVal);
            return m.matches();
        }
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeUTF(attribute);
        out.writeUTF(regex);
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        attribute = in.readUTF();
        regex = in.readUTF();
    }

    @Override
    public String toString() {
        return attribute + " REGEX '" + regex + "'";
    }
}

<code block>


package com.hazelcast.query.impl.predicates;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.query.Predicate;
import com.hazelcast.query.impl.IndexImpl;

import java.io.IOException;
import java.util.Map;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import static com.hazelcast.query.impl.predicates.AttributeUtils.readAttribute;


public class LikePredicate implements Predicate, DataSerializable {
    protected String attribute;
    protected String second;
    private volatile Pattern pattern;

    public LikePredicate() {
    }

    public LikePredicate(String attribute, String second) {
        this.attribute = attribute;
        this.second = second;
    }

    @Override
    public boolean apply(Map.Entry entry) {
        Comparable attribute = readAttribute(entry, this.attribute);
        String firstVal = attribute == IndexImpl.NULL ? null : (String) attribute;
        if (firstVal == null) {
            return (second == null);
        } else if (second == null) {
            return false;
        } else {
            if (pattern == null) {
                
                
                final String quoted = Pattern.quote(second);
                String regex = quoted
                        
                        .replaceAll("(?<!\\\\)[%]", "\\\\E.*\\\\Q")
                                
                        .replaceAll("(?<!\\\\)[_]", "\\\\E.\\\\Q")
                                
                        .replaceAll("\\\\%", "%")
                                
                        .replaceAll("\\\\_", "_");
                int flags = getFlags();
                pattern = Pattern.compile(regex, flags);
            }
            Matcher m = pattern.matcher(firstVal);
            return m.matches();
        }
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeUTF(attribute);
        out.writeUTF(second);
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        attribute = in.readUTF();
        second = in.readUTF();
    }


    protected int getFlags() {
        
        return 0;
    }

    @Override
    public String toString() {
        StringBuilder builder = new StringBuilder(attribute)
                .append(" LIKE '")
                .append(second)
                .append("'");
        return builder.toString();
    }
}

<code block>


package com.hazelcast.query;

import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.IMap;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.query.impl.AttributeType;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryEntry;
import com.hazelcast.query.impl.QueryableEntry;
import com.hazelcast.query.impl.getters.ReflectionHelper;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.math.BigDecimal;
import java.util.Map;
import java.util.Set;

import static com.hazelcast.instance.TestUtil.toData;

import com.hazelcast.query.impl.predicates.AndPredicate;

import com.hazelcast.query.impl.predicates.EqualPredicate;
import static com.hazelcast.query.Predicates.and;
import static com.hazelcast.query.Predicates.between;
import static com.hazelcast.query.Predicates.equal;
import static com.hazelcast.query.Predicates.greaterEqual;
import static com.hazelcast.query.Predicates.greaterThan;
import static com.hazelcast.query.Predicates.ilike;
import static com.hazelcast.query.Predicates.in;
import static com.hazelcast.query.Predicates.instanceOf;
import static com.hazelcast.query.Predicates.lessEqual;
import static com.hazelcast.query.Predicates.lessThan;
import static com.hazelcast.query.Predicates.like;
import static com.hazelcast.query.Predicates.notEqual;
import static com.hazelcast.query.Predicates.or;
import static com.hazelcast.query.Predicates.regex;
import static com.hazelcast.query.SampleObjects.Employee;
import static com.hazelcast.query.SampleObjects.Value;
import static java.lang.Boolean.FALSE;
import static java.lang.Boolean.TRUE;
import static java.util.Map.Entry;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class PredicatesTest extends HazelcastTestSupport {

    @Test
    public void testAndPredicate_whenFirstIndexAwarePredicateIsNotIndexed() throws Exception {
        final HazelcastInstance instance = createHazelcastInstance();
        final IMap<Object, Object> map = instance.getMap("map");
        map.addIndex("name", false);
        String name = randomString();
        map.put("key", new Value(name));

        final ShouldExecuteOncePredicate indexAwareNotIndexedPredicate = new ShouldExecuteOncePredicate();
        final EqualPredicate equalPredicate = new EqualPredicate("name", name);
        final AndPredicate andPredicate = new AndPredicate(indexAwareNotIndexedPredicate, equalPredicate);
        map.values(andPredicate);
    }

    static class ShouldExecuteOncePredicate implements IndexAwarePredicate {

        boolean executed = false;

        @Override
        public boolean apply(Map.Entry mapEntry) {
            if (!executed) {
                executed = true;
                return true;
            }
            throw new RuntimeException();
        }

        @Override
        public Set<QueryableEntry> filter(final QueryContext queryContext) {
            return null;
        }

        @Override
        public boolean isIndexed(final QueryContext queryContext) {
            return false;
        }
    }

    @Test
    public void testEqual() {
        assertPredicateTrue(equal(null, "value"), "value");
        assertPredicateFalse(equal(null, "value1"), "value");
        assertPredicateTrue(equal(null, TRUE), true);
        assertPredicateTrue(equal(null, true), TRUE);
        assertPredicateFalse(equal(null, true), FALSE);
        assertPredicateFalse(equal(null, new BigDecimal("1.23E3")), new BigDecimal("1.23E2"));
        assertPredicateTrue(equal(null, new BigDecimal("1.23E3")), new BigDecimal("1.23E3"));
        assertPredicateFalse(equal(null, 15.22), 15.23);
        assertPredicateTrue(equal(null, 15.22), 15.22);
        assertPredicateFalse(equal(null, 16), 15);
    }


    @Test
    public void testAnd() {
        final Predicate and1 = and(greaterThan(null, 4), lessThan(null, 6));
        assertPredicateTrue(and1, 5);
        final Predicate and2 = and(greaterThan(null, 5), lessThan(null, 6));
        assertPredicateFalse(and2, 4);
        final Predicate and3 = and(greaterThan(null, 4), lessThan(null, 6), equal(null, 5));
        assertPredicateTrue(and3, 5);
        final Predicate and4 = Predicates.and(greaterThan(null, 3), lessThan(null, 6), equal(null, 4));
        assertPredicateFalse(and4, 5);
    }

    @Test
    public void testOr() {
        final Predicate or1 = or(equal(null, 3), equal(null, 4), equal(null, 5));
        assertPredicateTrue(or1, 4);
        assertPredicateFalse(or1, 6);
    }

    @Test
    public void testGreaterEqual() {
        assertPredicateTrue(greaterEqual(null, 5), 5);
    }

    @Test
    public void testLessThan() {
        assertPredicateTrue(lessThan(null, 7), 6);
        assertPredicateFalse(lessThan(null, 3), 4);
        assertPredicateFalse(lessThan(null, 4), 4);
        assertPredicateTrue(lessThan(null, "tc"), "bz");
        assertPredicateFalse(lessThan(null, "gx"), "h0");
    }

    @Test
    public void testGreaterThan() {
        assertPredicateTrue(greaterThan(null, 5), 6);
        assertPredicateFalse(greaterThan(null, 5), 4);
        assertPredicateFalse(greaterThan(null, 5), 5);
        assertPredicateTrue(greaterThan(null, "aa"), "xa");
        assertPredicateFalse(greaterThan(null, "da"), "cz");
        assertPredicateTrue(greaterThan(null, new BigDecimal("1.23E2")), new BigDecimal("1.23E3"));
    }

    @Test
    public void testLessEqual() {
        assertPredicateTrue(lessEqual(null, 4), 4);
    }

    @Test
    public void testPredicatesAgainstANullField() {
        assertFalse_withNullEntry(lessEqual("nullField", 1));

        assertFalse_withNullEntry(in("nullField", 1));
        assertFalse_withNullEntry(lessThan("nullField", 1));
        assertFalse_withNullEntry(greaterEqual("nullField", 1));
        assertFalse_withNullEntry(greaterThan("nullField", 1));
        assertFalse_withNullEntry(equal("nullField", 1));
        assertFalse_withNullEntry(notEqual("nullField", null));
        assertFalse_withNullEntry(notEqual("nullField", 1));
        assertFalse_withNullEntry(between("nullField", 1, 1));
        assertTrue_withNullEntry(like("nullField", null));
        assertTrue_withNullEntry(ilike("nullField", null));
        assertTrue_withNullEntry(regex("nullField", null));
    }

    @Test
    public void testBetween() {
        assertPredicateTrue(between(null, 4, 6), 5);
        assertPredicateTrue(between(null, 5, 6), 5);
        assertPredicateTrue(between(null, "abc", "xyz"), "prs");
        assertPredicateFalse(between(null, "klmn", "xyz"), "efgh");
        assertPredicateFalse(between(null, 6, 7), 5);
    }

    @Test
    public void testIn() {
        assertPredicateTrue(in(null, 4, 7, 8, 5), 5);
        assertPredicateTrue(in(null, 5, 7, 8), 5);
        assertPredicateFalse(in(null, 6, 7, 8), 5);
        assertPredicateFalse(in(null, 6, 7, 8), 9);
    }

    @Test
    public void testLike() {
        assertPredicateTrue(like(null, "J%"), "Java");
        assertPredicateTrue(like(null, "Ja%"), "Java");
        assertPredicateTrue(like(null, "J_v_"), "Java");
        assertPredicateTrue(like(null, "_av_"), "Java");
        assertPredicateTrue(like(null, "_a__"), "Java");
        assertPredicateTrue(like(null, "J%v_"), "Java");
        assertPredicateTrue(like(null, "J%_"), "Java");
        assertPredicateFalse(like(null, "java"), "Java");
        assertPredicateFalse(like(null, "j%"), "Java");
        assertPredicateFalse(like(null, "J_a"), "Java");
        assertPredicateFalse(like(null, "J_ava"), "Java");
        assertPredicateFalse(like(null, "J_a_a"), "Java");
        assertPredicateFalse(like(null, "J_av__"), "Java");
        assertPredicateFalse(like(null, "J_Va"), "Java");
        assertPredicateTrue(like(null, "Java World"), "Java World");
        assertPredicateTrue(like(null, "Java%ld"), "Java World");
        assertPredicateTrue(like(null, "%World"), "Java World");
        assertPredicateTrue(like(null, "Java_World"), "Java World");

        assertPredicateTrue(like(null, "J.-*.*\\%"), "J.-*.*%");
        assertPredicateTrue(like(null, "J\\_"), "J_");
        assertPredicateTrue(like(null, "J%"), "Java");

    }

    @Test
    public void testILike() {
        assertPredicateFalse(like(null, "JavaWorld"), "Java World");
        assertPredicateTrue(ilike(null, "Java_World"), "java World");
        assertPredicateTrue(ilike(null, "java%ld"), "Java World");
        assertPredicateTrue(ilike(null, "%world"), "Java World");
        assertPredicateFalse(ilike(null, "Java_World"), "gava World");
    }

    @Test
    public void testIsInstanceOf() {
        assertTrue(instanceOf(Long.class).apply(new DummyEntry(1L)));
        assertFalse(instanceOf(Long.class).apply(new DummyEntry("Java")));
        assertTrue(instanceOf(Number.class).apply(new DummyEntry(4)));
    }

    @Test
    public void testCriteriaAPI() {
        Object value = new Employee(12, "abc-123-xvz", 34, true, 10D);
        EntryObject e = new PredicateBuilder().getEntryObject();
        EntryObject e2 = e.get("age");
        Predicate predicate = e2.greaterEqual(29).and(e2.lessEqual(36));
        assertTrue(predicate.apply(createEntry("1", value)));
        e = new PredicateBuilder().getEntryObject();
        assertTrue(e.get("id").equal(12).apply(createEntry("1", value)));
    }

    @Test(expected = NullPointerException.class)
    public void testBetweenNull() {
        Predicates.between("", null, null);
    }

    @Test(expected = NullPointerException.class)
    public void testLessThanNull() {
        Predicates.lessThan("", null);
    }

    @Test(expected = NullPointerException.class)
    public void testLessEqualNull() {
        Predicates.lessEqual("", null);
    }

    @Test(expected = NullPointerException.class)
    public void testGreaterThanNull() {
        Predicates.greaterThan("", null);
    }

    @Test(expected = NullPointerException.class)
    public void testGreaterEqualNull() {
        Predicates.greaterEqual("", null);
    }

    @Test(expected = NullPointerException.class)
    public void testInNullWithNullArray() {
        Predicates.in("", null);
    }

    private class DummyEntry extends QueryEntry {

        DummyEntry(Comparable attribute) {
            super(null, toData("1"), "1", attribute);
        }

        @Override
        public Comparable getAttribute(String attributeName) throws QueryException {
            return (Comparable) getValue();
        }

        @Override
        public AttributeType getAttributeType(String attributeName) {
            return ReflectionHelper.getAttributeType(getValue().getClass());
        }
    }

    private class NullDummyEntry implements QueryableEntry {

        private Integer nullField;

        private NullDummyEntry() {
        }

        public Integer getNullField() {
            return nullField;
        }

        public void setNullField(Integer nullField) {
            this.nullField = nullField;
        }

        @Override
        public Object getValue() {
            return null;
        }

        @Override
        public Object setValue(Object value) {
            return null;
        }

        @Override
        public Object getKey() {
            return 1;
        }

        @Override
        public Comparable getAttribute(String attributeName) throws QueryException {
            return null;
        }

        @Override
        public AttributeType getAttributeType(String attributeName) {
            return AttributeType.INTEGER;
        }

        @Override
        public Data getKeyData() {
            return null;
        }

        @Override
        public Data getValueData() {
            return null;
        }

        @Override
        public Data getIndexKey() {
            return null;
        }

    }

    private static Entry createEntry(final Object key, final Object value) {
        return new QueryEntry(null, toData(key), key, value);
    }

    private void assertPredicateTrue(Predicate p, Comparable comparable) {
        assertTrue(p.apply(new DummyEntry(comparable)));
    }

    private void assertPredicateFalse(Predicate p, Comparable comparable) {
        assertFalse(p.apply(new DummyEntry(comparable)));
    }

    private void assertTrue_withNullEntry(Predicate p) {
        assertTrue(p.apply(new NullDummyEntry()));
    }

    private void assertFalse_withNullEntry(Predicate p) {
        assertFalse(p.apply(new NullDummyEntry()));
    }
}

<code block>


package com.hazelcast.query.impl;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.nio.serialization.impl.DefaultSerializationServiceBuilder;
import com.hazelcast.nio.serialization.Portable;
import com.hazelcast.nio.serialization.PortableFactory;
import com.hazelcast.nio.serialization.PortableReader;
import com.hazelcast.nio.serialization.PortableWriter;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.query.impl.predicates.AndPredicate;
import com.hazelcast.query.impl.predicates.EqualPredicate;
import com.hazelcast.query.QueryException;
import com.hazelcast.query.impl.getters.ReflectionHelper;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.io.IOException;
import java.util.concurrent.ConcurrentMap;

import static com.hazelcast.instance.TestUtil.toData;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class IndexTest {

    static final short FACTORY_ID = 1;

    final SerializationService ss = new DefaultSerializationServiceBuilder()
            .addPortableFactory(FACTORY_ID, new TestPortableFactory()).build();

    @Test
    public void testBasics() {
        testIt(true);
        testIt(false);
    }

    private QueryRecord newRecord(Object key, final Comparable attributeValue) {
        return new QueryRecord(toData(key), attributeValue);
    }

    @Test
    public void testRemoveEnumIndex() {
        IndexService is = new IndexService();
        is.addOrGetIndex("favoriteCity", false);
        Data key = ss.toData(1);
        Data value = ss.toData(new SerializableWithEnum(SerializableWithEnum.City.Istanbul));
        is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        assertNotNull(is.getIndex("favoriteCity"));
        is.removeEntryIndex(key);
        assertEquals(0,is.getIndex("favoriteCity").getRecords(SerializableWithEnum.City.Istanbul).size());
    }

    @Test
    public void testIndex() throws QueryException {
        IndexService is = new IndexService();
        Index dIndex = is.addOrGetIndex("d", false);
        Index boolIndex = is.addOrGetIndex("bool", false);
        Index strIndex = is.addOrGetIndex("str", false);
        for (int i = 0; i < 1000; i++) {
            Data key = ss.toData(i);
            Data value = ss.toData(new MainPortable(i % 2 == 0, -10.34d, "joe" + i));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }
        assertEquals(1000, dIndex.getRecords(-10.34d).size());
        assertEquals(1, strIndex.getRecords("joe23").size());
        assertEquals(500, boolIndex.getRecords(true).size());
        for (int i = 0; i < 1000; i++) {
            Data key = ss.toData(i);
            Data value = ss.toData(new MainPortable(false, 11.34d, "joe"));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }
        assertEquals(0, dIndex.getRecords(-10.34d).size());
        assertEquals(0, strIndex.getRecords("joe23").size());
        assertEquals(1000, strIndex.getRecords("joe").size());
        assertEquals(1000, boolIndex.getRecords(false).size());
        assertEquals(0, boolIndex.getRecords(true).size());
        for (int i = 0; i < 1000; i++) {
            Data key = ss.toData(i);
            Data value = ss.toData(new MainPortable(false, -1 * (i + 1), "joe" + i));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }
        assertEquals(0, dIndex.getSubRecordsBetween(1d, 1001d).size());
        assertEquals(1000, dIndex.getSubRecordsBetween(-1d, -1001d).size());
        for (int i = 0; i < 1000; i++) {
            Data key = ss.toData(i);
            Data value = ss.toData(new MainPortable(false, 1 * (i + 1), "joe" + i));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }
        assertEquals(1000, dIndex.getSubRecordsBetween(1d, 1001d).size());
        assertEquals(0, dIndex.getSubRecordsBetween(-1d, -1001d).size());
        assertEquals(400, dIndex.getSubRecords(ComparisonType.GREATER, 600d).size());
        assertEquals(401, dIndex.getSubRecords(ComparisonType.GREATER_EQUAL, 600d).size());
        assertEquals(9, dIndex.getSubRecords(ComparisonType.LESSER, 10d).size());
        assertEquals(10, dIndex.getSubRecords(ComparisonType.LESSER_EQUAL, 10d).size());
        assertEquals(1, is.query(new AndPredicate(new EqualPredicate("d", 1d), new EqualPredicate("bool", "false"))).size());
        assertEquals(1, is.query(new AndPredicate(new EqualPredicate("d", 1), new EqualPredicate("bool", Boolean.FALSE))).size());
        assertEquals(1, is.query(new AndPredicate(new EqualPredicate("d", "1"), new EqualPredicate("bool", false))).size());
    }

    @Test
    public void testIndexWithNull() throws QueryException {
        IndexService is = new IndexService();
        Index strIndex = is.addOrGetIndex("str", true);

        Data value = ss.toData(new MainPortable(false, 1, null));
        Data key1 = ss.toData(0);
        is.saveEntryIndex(new QueryEntry(ss, key1, key1, value));

        value = ss.toData(new MainPortable(false, 2, null));
        Data key2 = ss.toData(1);
        is.saveEntryIndex(new QueryEntry(ss, key2, key2, value));


        for (int i = 2; i < 1000; i++) {
            Data key = ss.toData(i);
            value = ss.toData(new MainPortable(false, 1 * (i + 1), "joe" + i));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }

        Comparable c = null;
        assertEquals(2, strIndex.getRecords(c).size());
        assertEquals(998, strIndex.getSubRecords(ComparisonType.NOT_EQUAL, null).size());
    }

    private class TestPortableFactory implements PortableFactory {

        public Portable create(int classId) {
            switch (classId) {
                case 1:
                    return new MainPortable();
            }
            return null;
        }

        public int getFactoryId() {
            return FACTORY_ID;
        }
    }

    private static class SerializableWithEnum implements DataSerializable {

        enum City {
            Istanbul,
            Rize,
            Krakow,
            Trabzon;
        }

        private City favoriteCity;

        private SerializableWithEnum() {
        }

        private SerializableWithEnum(City favoriteCity) {
            this.favoriteCity = favoriteCity;
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            out.writeObject(favoriteCity);
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            favoriteCity = in.readObject();
        }
    }

    private static class MainPortable implements Portable {

        byte b;
        boolean bool;
        char c;
        short s;
        int i;
        long l;
        float f;
        double d;
        String str;

        private MainPortable() {
        }

        private MainPortable(boolean bool, double d, String str) {
            this.bool = bool;
            this.d = d;
            this.str = str;
        }

        private MainPortable(byte b, boolean bool, char c, short s, int i, long l, float f,
                             double d, String str) {
            this.b = b;
            this.bool = bool;
            this.c = c;
            this.s = s;
            this.i = i;
            this.l = l;
            this.f = f;
            this.d = d;
            this.str = str;
        }

        public int getClassId() {
            return 1;
        }

        public void writePortable(PortableWriter writer) throws IOException {
            writer.writeByte("b", b);
            writer.writeBoolean("bool", bool);
            writer.writeChar("c", c);
            writer.writeShort("s", s);
            writer.writeInt("i", i);
            writer.writeLong("l", l);
            writer.writeFloat("f", f);
            writer.writeDouble("d", d);
            writer.writeUTF("str", str);
        }

        public void readPortable(PortableReader reader) throws IOException {
            b = reader.readByte("b");
            bool = reader.readBoolean("bool");
            c = reader.readChar("c");
            s = reader.readShort("s");
            i = reader.readInt("i");
            l = reader.readLong("l");
            f = reader.readFloat("f");
            d = reader.readDouble("d");
            str = reader.readUTF("str");
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (o == null || getClass() != o.getClass()) return false;
            MainPortable that = (MainPortable) o;
            if (b != that.b) return false;
            if (bool != that.bool) return false;
            if (c != that.c) return false;
            if (Double.compare(that.d, d) != 0) return false;
            if (Float.compare(that.f, f) != 0) return false;
            if (i != that.i) return false;
            if (l != that.l) return false;
            if (s != that.s) return false;
            if (str != null ? !str.equals(that.str) : that.str != null) return false;
            return true;
        }

        @Override
        public int hashCode() {
            int result;
            long temp;
            result = (int) b;
            result = 31 * result + (bool ? 1 : 0);
            result = 31 * result + (int) c;
            result = 31 * result + (int) s;
            result = 31 * result + i;
            result = 31 * result + (int) (l ^ (l >>> 32));
            result = 31 * result + (f != +0.0f ? Float.floatToIntBits(f) : 0);
            temp = d != +0.0d ? Double.doubleToLongBits(d) : 0L;
            result = 31 * result + (int) (temp ^ (temp >>> 32));
            result = 31 * result + (str != null ? str.hashCode() : 0);
            return result;
        }

        @Override
        public String toString() {
            return "MainPortable{" +
                    "b=" + b +
                    ", bool=" + bool +
                    ", c=" + c +
                    ", s=" + s +
                    ", i=" + i +
                    ", l=" + l +
                    ", f=" + f +
                    ", d=" + d +
                    ", str='" + str + '\'' +
                    '}';
        }

        public int getFactoryId() {
            return FACTORY_ID;
        }
    }

    class QueryRecord implements QueryableEntry {
        Data key;
        Comparable attributeValue;

        QueryRecord(Data key, Comparable attributeValue) {
            this.key = key;
            this.attributeValue = attributeValue;
        }

        public Comparable getAttribute(String attributeName) throws QueryException {
            return attributeValue;
        }

        public AttributeType getAttributeType(String attributeName) {
            return ReflectionHelper.getAttributeType(attributeValue.getClass());
        }

        public Data getKeyData() {
            return key;
        }

        public Data getValueData() {
            return null;
        }

        public Data getIndexKey() {
            return key;
        }

        public long getCreationTime() {
            return 0;
        }

        public long getLastAccessTime() {
            return 0;
        }

        public Object getKey() {
            return key;
        }

        public Object getValue() {
            return null;
        }

        public Object setValue(Object value) {
            return null;
        }

        public void changeAttribute(Comparable newAttributeValue) {
            this.attributeValue = newAttributeValue;
        }

        public void writeData(ObjectDataOutput out) throws IOException {
        }

        public void readData(ObjectDataInput in) throws IOException {
        }
    }

    private void testIt(boolean ordered) {
        IndexImpl index = new IndexImpl(null, ordered);
        assertEquals(0, index.getRecords(0L).size());
        assertEquals(0, index.getSubRecordsBetween(0L, 1000L).size());
        QueryRecord record5 = newRecord(5L, 55L);
        index.saveEntryIndex(record5);
        assertEquals(1, index.getRecordValues().size());
        assertEquals(55L, index.getRecordValues().get(record5.getIndexKey()));
        QueryRecord record6 = newRecord(6L, 66L);
        index.saveEntryIndex(record6);
        assertEquals(2, index.getRecordValues().size());
        assertEquals(new Long(66L), index.getRecordValues().get(record6.getIndexKey()));
        record5.changeAttribute(555L);
        index.saveEntryIndex(record5);
        assertEquals(2, index.getRecordValues().size());
        assertEquals(new Long(555L), index.getRecordValues().get(record5.getIndexKey()));
        assertEquals(1, index.getRecords(555L).size());
        assertEquals(2, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(2, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(1, index.getSubRecordsBetween(555L, 555L).size());
        QueryRecord record50 = newRecord(50L, 555L);
        index.saveEntryIndex(record50);
        assertEquals(3, index.getRecordValues().size());
        assertEquals(new Long(555L), index.getRecordValues().get(record5.getIndexKey()));
        assertEquals(new Long(555L), index.getRecordValues().get(record50.getIndexKey()));
        ConcurrentMap<Data, QueryableEntry> records = index.getRecordMap(555L);
        assertNotNull(records);
        assertEquals(2, records.size());
        assertEquals(record5, records.get(record5.getIndexKey()));
        assertEquals(record50, records.get(record50.getIndexKey()));
        assertEquals(2, index.getRecords(555L).size());
        assertEquals(3, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(3, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(2, index.getSubRecordsBetween(555L, 555L).size());
        assertEquals(0, index.getSubRecords(ComparisonType.LESSER, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.LESSER_EQUAL, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.LESSER_EQUAL, 67L).size());
        assertEquals(2, index.getSubRecords(ComparisonType.GREATER, 66L).size());
        assertEquals(3, index.getSubRecords(ComparisonType.GREATER_EQUAL, 66L).size());
        assertEquals(3, index.getSubRecords(ComparisonType.GREATER_EQUAL, 61L).size());
        assertEquals(3, index.getSubRecords(ComparisonType.NOT_EQUAL, 61L).size());
        assertEquals(2, index.getSubRecords(ComparisonType.NOT_EQUAL, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.NOT_EQUAL, 555L).size());
        assertEquals(3, index.getRecords(new Comparable[]{66L, 555L, 34234L}).size());
        assertEquals(2, index.getRecords(new Comparable[]{555L, 34234L}).size());
        index.removeEntryIndex(record5.getIndexKey());
        assertEquals(2, index.getRecordValues().size());
        assertEquals(new Long(555L), index.getRecordValues().get(record50.getIndexKey()));
        assertEquals(null, index.getRecordValues().get(record5.getIndexKey()));
        records = index.getRecordMap(555L);
        assertNotNull(records);
        assertEquals(null, records.get(5L));
        assertEquals(record50, records.get(toData(50L)));
        assertEquals(1, index.getRecords(555L).size());
        assertEquals(2, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(2, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(1, index.getSubRecordsBetween(555L, 555L).size());
        assertEquals(0, index.getSubRecords(ComparisonType.LESSER, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.LESSER_EQUAL, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.LESSER_EQUAL, 67L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.GREATER, 66L).size());
        assertEquals(2, index.getSubRecords(ComparisonType.GREATER_EQUAL, 66L).size());
        assertEquals(2, index.getSubRecords(ComparisonType.GREATER_EQUAL, 61L).size());
        index.removeEntryIndex(record50.getIndexKey());
        assertEquals(1, index.getRecordValues().size());
        assertEquals(null, index.getRecordValues().get(50L));
        records = index.getRecordMap(555L);
        assertNull(records);
        assertEquals(0, index.getRecords(555L).size());
        assertEquals(1, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(1, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(0, index.getSubRecordsBetween(555L, 555L).size());
        index.removeEntryIndex(record6.getIndexKey());
        assertEquals(0, index.getRecordValues().size());
        assertEquals(null, index.getRecordValues().get(6L));
        assertNull(index.getRecordMap(66L));
        assertEquals(0, index.getRecords(555L).size());
        assertEquals(0, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(0, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(0, index.getSubRecordsBetween(555L, 555L).size());
    }
}

<code block>


package com.hazelcast.query;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.nio.serialization.HazelcastSerializationException;
import com.hazelcast.query.impl.AndResultSet;
import com.hazelcast.query.impl.AttributeType;
import com.hazelcast.query.impl.ComparisonType;
import com.hazelcast.query.impl.Index;
import com.hazelcast.query.impl.IndexImpl;
import com.hazelcast.query.impl.OrResultSet;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.regex.Matcher;
import java.util.regex.Pattern;


public final class Predicates {

    
    private Predicates() {
    }

    public static Predicate instanceOf(final Class klass) {
        return new InstanceOfPredicate(klass);
    }

    private static Comparable readAttribute(Map.Entry entry, String attribute) {
        QueryableEntry queryableEntry = (QueryableEntry) entry;
        Comparable value = queryableEntry.getAttribute(attribute);
        if (value == null) {
            return IndexImpl.NULL;
        }
        return value;
    }

    public static Predicate and(Predicate... predicates) {
        return new AndPredicate(predicates);
    }

    public static Predicate not(Predicate predicate) {
        return new NotPredicate(predicate);
    }

    
    public static Predicate or(Predicate... predicates) {
        return new OrPredicate(predicates);
    }

    public static Predicate notEqual(String attribute, Comparable y) {
        return new NotEqualPredicate(attribute, y);
    }

    public static Predicate equal(String attribute, Comparable y) {
        return new EqualPredicate(attribute, y);
    }

    public static Predicate like(String attribute, String pattern) {
        return new LikePredicate(attribute, pattern);
    }

    public static Predicate ilike(String attribute, String pattern) {
        return new ILikePredicate(attribute, pattern);
    }

    public static Predicate regex(String attribute, String pattern) {
        return new RegexPredicate(attribute, pattern);
    }

    public static Predicate greaterThan(String x, Comparable y) {
        return new GreaterLessPredicate(x, y, false, false);
    }

    public static Predicate greaterEqual(String x, Comparable y) {
        return new GreaterLessPredicate(x, y, true, false);
    }

    public static Predicate lessThan(String x, Comparable y) {
        return new GreaterLessPredicate(x, y, false, true);
    }

    public static Predicate lessEqual(String x, Comparable y) {
        return new GreaterLessPredicate(x, y, true, true);
    }

    public static Predicate between(String attribute, Comparable from, Comparable to) {
        return new BetweenPredicate(attribute, from, to);
    }

    public static Predicate in(String attribute, Comparable... values) {
        return new InPredicate(attribute, values);
    }

    
    public static class BetweenPredicate extends AbstractPredicate {
        private Comparable to;
        private Comparable from;

        public BetweenPredicate() {
        }

        public BetweenPredicate(String first, Comparable from, Comparable to) {
            super(first);
            if (from == null || to == null) {
                throw new NullPointerException("Arguments can't be null");
            }
            this.from = from;
            this.to = to;
        }

        @Override
        public boolean apply(Map.Entry entry) {
            Comparable entryValue = readAttribute(entry);
            if (entryValue == null) {
                return false;
            }
            Comparable fromConvertedValue = convert(entry, entryValue, from);
            Comparable toConvertedValue = convert(entry, entryValue, to);
            if (fromConvertedValue == null || toConvertedValue == null) {
                return false;
            }
            return entryValue.compareTo(fromConvertedValue) >= 0 && entryValue.compareTo(toConvertedValue) <= 0;
        }

        @Override
        public Set<QueryableEntry> filter(QueryContext queryContext) {
            Index index = getIndex(queryContext);
            return index.getSubRecordsBetween(from, to);
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            super.writeData(out);
            out.writeObject(to);
            out.writeObject(from);
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            super.readData(in);
            to = in.readObject();
            from = in.readObject();
        }

        @Override
        public String toString() {
            return attribute + " BETWEEN " + from + " AND " + to;
        }
    }

    
    public static class NotPredicate implements Predicate, DataSerializable {
        private Predicate predicate;

        public NotPredicate(Predicate predicate) {
            this.predicate = predicate;
        }

        public NotPredicate() {
        }

        @Override
        public boolean apply(Map.Entry mapEntry) {
            return !predicate.apply(mapEntry);
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            out.writeObject(predicate);
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            predicate = in.readObject();
        }

        @Override
        public String toString() {
            return "NOT(" + predicate + ")";
        }
    }

    
    public static class InPredicate extends AbstractPredicate {
        private Comparable[] values;
        private volatile Set<Comparable> convertedInValues;

        public InPredicate() {
        }

        public InPredicate(String attribute, Comparable... values) {
            super(attribute);

            if (values == null) {
                throw new NullPointerException("Array can't be null");
            }
            this.values = values;
        }

        @Override
        public boolean apply(Map.Entry entry) {
            Comparable entryValue = readAttribute(entry);
            if (entryValue == null) {
                return false;
            }
            Set<Comparable> set = convertedInValues;
            if (set == null) {
                set = new HashSet<Comparable>(values.length);
                for (Comparable value : values) {
                    set.add(convert(entry, entryValue, value));
                }
                convertedInValues = set;
            }
            return set.contains(entryValue);
        }

        @Override
        public Set<QueryableEntry> filter(QueryContext queryContext) {
            Index index = getIndex(queryContext);
            if (index != null) {
                return index.getRecords(values);
            } else {
                return null;
            }
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            super.writeData(out);
            out.writeInt(values.length);
            for (Object value : values) {
                out.writeObject(value);
            }
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            super.readData(in);
            int len = in.readInt();
            values = new Comparable[len];
            for (int i = 0; i < len; i++) {
                values[i] = in.readObject();
            }
        }

        @Override
        public String toString() {
            final StringBuilder sb = new StringBuilder();
            sb.append(attribute);
            sb.append(" IN (");
            for (int i = 0; i < values.length; i++) {
                if (i > 0) {
                    sb.append(",");
                }
                sb.append(values[i]);
            }
            sb.append(")");
            return sb.toString();
        }
    }

    
    public static class RegexPredicate implements Predicate, DataSerializable {
        private String attribute;
        private String regex;
        private volatile Pattern pattern;

        public RegexPredicate() {
        }

        public RegexPredicate(String attribute, String regex) {
            this.attribute = attribute;
            this.regex = regex;
        }

        @Override
        public boolean apply(Map.Entry entry) {
            Comparable attribute = readAttribute(entry, this.attribute);
            String firstVal = attribute == IndexImpl.NULL ? null : (String) attribute;
            if (firstVal == null) {
                return (regex == null);
            } else if (regex == null) {
                return false;
            } else {
                if (pattern == null) {
                    pattern = Pattern.compile(regex);
                }
                Matcher m = pattern.matcher(firstVal);
                return m.matches();
            }
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            out.writeUTF(attribute);
            out.writeUTF(regex);
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            attribute = in.readUTF();
            regex = in.readUTF();
        }

        @Override
        public String toString() {
            return attribute + " REGEX '" + regex + "'";
        }
    }

    
    public static class LikePredicate implements Predicate, DataSerializable {
        protected String attribute;
        protected String second;
        private volatile Pattern pattern;

        public LikePredicate() {
        }

        public LikePredicate(String attribute, String second) {
            this.attribute = attribute;
            this.second = second;
        }

        @Override
        public boolean apply(Map.Entry entry) {
            Comparable attribute = readAttribute(entry, this.attribute);
            String firstVal = attribute == IndexImpl.NULL ? null : (String) attribute;
            if (firstVal == null) {
                return (second == null);
            } else if (second == null) {
                return false;
            } else {
                if (pattern == null) {
                    
                    
                    final String quoted = Pattern.quote(second);
                    String regex = quoted
                            
                            .replaceAll("(?<!\\\\)[%]", "\\\\E.*\\\\Q")
                                    
                            .replaceAll("(?<!\\\\)[_]", "\\\\E.\\\\Q")
                                    
                            .replaceAll("\\\\%", "%")
                                    
                            .replaceAll("\\\\_", "_");
                    int flags = getFlags();
                    pattern = Pattern.compile(regex, flags);
                }
                Matcher m = pattern.matcher(firstVal);
                return m.matches();
            }
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            out.writeUTF(attribute);
            out.writeUTF(second);
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            attribute = in.readUTF();
            second = in.readUTF();
        }


        protected int getFlags() {
            
            return 0;
        }

        @Override
        public String toString() {
            StringBuilder builder = new StringBuilder(attribute)
                    .append(" LIKE '")
                    .append(second)
                    .append("'");
            return builder.toString();
        }
    }

    
    public static class ILikePredicate extends LikePredicate {

        public ILikePredicate() {
        }

        public ILikePredicate(String attribute, String second) {
            super(attribute, second);
        }

        @Override
        public String toString() {
            StringBuilder builder = new StringBuilder(attribute)
                    .append(" ILIKE '")
                    .append(second)
                    .append("'");
            return builder.toString();
        }


        @Override
        protected int getFlags() {
            return Pattern.CASE_INSENSITIVE;
        }
    }

    
    public static class AndPredicate implements IndexAwarePredicate, DataSerializable {

        protected Predicate[] predicates;

        public AndPredicate() {
        }

        public AndPredicate(Predicate... predicates) {
            this.predicates = predicates;
        }

        @Override
        public Set<QueryableEntry> filter(QueryContext queryContext) {
            Set<QueryableEntry> smallestIndexedResult = null;
            List<Set<QueryableEntry>> otherIndexedResults = new LinkedList<Set<QueryableEntry>>();
            List<Predicate> lsNoIndexPredicates = null;
            for (Predicate predicate : predicates) {
                boolean indexed = false;
                if (predicate instanceof IndexAwarePredicate) {
                    IndexAwarePredicate iap = (IndexAwarePredicate) predicate;
                    if (iap.isIndexed(queryContext)) {
                        indexed = true;
                        Set<QueryableEntry> s = iap.filter(queryContext);
                        if (smallestIndexedResult == null) {
                            smallestIndexedResult = s;
                        } else if (s.size() < smallestIndexedResult.size()) {
                            otherIndexedResults.add(smallestIndexedResult);
                            smallestIndexedResult = s;
                        } else {
                            otherIndexedResults.add(s);
                        }
                    }
                }
                if (!indexed) {
                    if (lsNoIndexPredicates == null) {
                        lsNoIndexPredicates = new LinkedList<Predicate>();
                    }
                    lsNoIndexPredicates.add(predicate);
                }
            }
            if (smallestIndexedResult == null) {
                return null;
            }
            return new AndResultSet(smallestIndexedResult, otherIndexedResults, lsNoIndexPredicates);
        }

        @Override
        public boolean isIndexed(QueryContext queryContext) {
            for (Predicate predicate : predicates) {
                if (predicate instanceof IndexAwarePredicate) {
                    IndexAwarePredicate iap = (IndexAwarePredicate) predicate;
                    if (iap.isIndexed(queryContext)) {
                        return true;
                    }
                }
            }
            return false;
        }

        @Override
        public boolean apply(Map.Entry mapEntry) {
            for (Predicate predicate : predicates) {
                if (!predicate.apply(mapEntry)) {
                    return false;
                }
            }
            return true;
        }

        @Override
        public String toString() {
            final StringBuilder sb = new StringBuilder();
            sb.append("(");
            int size = predicates.length;
            for (int i = 0; i < size; i++) {
                if (i > 0) {
                    sb.append(" AND ");
                }
                sb.append(predicates[i]);
            }
            sb.append(")");
            return sb.toString();
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            out.writeInt(predicates.length);
            for (Predicate predicate : predicates) {
                out.writeObject(predicate);
            }
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            int size = in.readInt();
            predicates = new Predicate[size];
            for (int i = 0; i < size; i++) {
                predicates[i] = in.readObject();
            }
        }
    }

    
    public static class OrPredicate implements IndexAwarePredicate, DataSerializable {

        private Predicate[] predicates;

        public OrPredicate() {
        }

        public OrPredicate(Predicate... predicates) {
            this.predicates = predicates;
        }

        @Override
        public Set<QueryableEntry> filter(QueryContext queryContext) {
            List<Set<QueryableEntry>> indexedResults = new LinkedList<Set<QueryableEntry>>();
            for (Predicate predicate : predicates) {
                if (predicate instanceof IndexAwarePredicate) {
                    IndexAwarePredicate iap = (IndexAwarePredicate) predicate;
                    if (iap.isIndexed(queryContext)) {
                        Set<QueryableEntry> s = iap.filter(queryContext);
                        if (s != null) {
                            indexedResults.add(s);
                        }
                    } else {
                        return null;
                    }
                }
            }
            return indexedResults.isEmpty() ? null : new OrResultSet(indexedResults);
        }

        @Override
        public boolean isIndexed(QueryContext queryContext) {
            for (Predicate predicate : predicates) {
                if (predicate instanceof IndexAwarePredicate) {
                    IndexAwarePredicate iap = (IndexAwarePredicate) predicate;
                    if (!iap.isIndexed(queryContext)) {
                        return false;
                    }
                } else {
                    return false;
                }
            }
            return true;
        }

        @Override
        public boolean apply(Map.Entry mapEntry) {
            for (Predicate predicate : predicates) {
                if (predicate.apply(mapEntry)) {
                    return true;
                }
            }
            return false;
        }


        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            out.writeInt(predicates.length);
            for (Predicate predicate : predicates) {
                out.writeObject(predicate);
            }
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            int size = in.readInt();
            predicates = new Predicate[size];
            for (int i = 0; i < size; i++) {
                predicates[i] = in.readObject();
            }
        }

        @Override
        public String toString() {
            final StringBuilder sb = new StringBuilder();
            sb.append("(");
            int size = predicates.length;
            for (int i = 0; i < size; i++) {
                if (i > 0) {
                    sb.append(" OR ");
                }
                sb.append(predicates[i]);
            }
            sb.append(")");
            return sb.toString();
        }
    }

    
    public static class GreaterLessPredicate extends EqualPredicate {
        boolean equal;
        boolean less;

        public GreaterLessPredicate() {
        }

        public GreaterLessPredicate(String attribute, Comparable value, boolean equal, boolean less) {
            super(attribute);

            if (value == null) {
                throw new NullPointerException("Arguments can't be null");
            }

            this.value = value;
            this.equal = equal;
            this.less = less;
        }

        @Override
        public boolean apply(Map.Entry mapEntry) {
            final Comparable entryValue = readAttribute(mapEntry);
            if (entryValue == null) {
                return false;
            }
            final Comparable attributeValue = convert(mapEntry, entryValue, value);
            final int result = entryValue.compareTo(attributeValue);
            return equal && result == 0 || (less ? (result < 0) : (result > 0));
        }

        @Override
        public Set<QueryableEntry> filter(QueryContext queryContext) {
            Index index = getIndex(queryContext);
            final ComparisonType comparisonType;
            if (less) {
                comparisonType = equal ? ComparisonType.LESSER_EQUAL : ComparisonType.LESSER;
            } else {
                comparisonType = equal ? ComparisonType.GREATER_EQUAL : ComparisonType.GREATER;
            }
            return index.getSubRecords(comparisonType, value);
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            super.readData(in);
            equal = in.readBoolean();
            less = in.readBoolean();
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            super.writeData(out);
            out.writeBoolean(equal);
            out.writeBoolean(less);
        }

        @Override
        public String toString() {
            final StringBuilder sb = new StringBuilder();
            sb.append(attribute);
            sb.append(less ? "<" : ">");
            if (equal) {
                sb.append("=");
            }
            sb.append(value);
            return sb.toString();
        }
    }

    
    public static class NotEqualPredicate extends EqualPredicate {
        public NotEqualPredicate() {
        }

        public NotEqualPredicate(String attribute, Comparable value) {
            super(attribute, value);
        }

        @Override
        public boolean apply(Map.Entry entry) {
            Comparable entryValue = readAttribute(entry);
            if (entryValue == null) {
                return false;
            }

            return !super.apply(entry);
        }

        @Override
        public Set<QueryableEntry> filter(QueryContext queryContext) {
            Index index = getIndex(queryContext);
            if (index != null) {
                return index.getSubRecords(ComparisonType.NOT_EQUAL, value);
            } else {
                return null;
            }
        }

        @Override
        public String toString() {
            return attribute + " != " + value;
        }
    }

    
    public static class EqualPredicate extends AbstractPredicate {
        protected Comparable value;

        public EqualPredicate() {
        }

        public EqualPredicate(String attribute) {
            super(attribute);
        }

        public EqualPredicate(String attribute, Comparable value) {
            super(attribute);
            this.value = value;
        }

        @Override
        public Set<QueryableEntry> filter(QueryContext queryContext) {
            Index index = getIndex(queryContext);
            return index.getRecords(value);
        }

        @Override
        public boolean apply(Map.Entry mapEntry) {
            Comparable entryValue = readAttribute(mapEntry);
            if (entryValue == null) {
                return value == null || value == IndexImpl.NULL;
            }
            value = convert(mapEntry, entryValue, value);
            return entryValue.equals(value);
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            super.writeData(out);
            out.writeObject(value);
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            super.readData(in);
            value = in.readObject();
        }

        @Override
        public String toString() {
            return attribute + "=" + value;
        }
    }

    
    public abstract static class AbstractPredicate implements IndexAwarePredicate, DataSerializable {

        protected String attribute;
        private transient volatile AttributeType attributeType;

        protected AbstractPredicate() {
        }

        protected AbstractPredicate(String attribute) {
            this.attribute = attribute;
        }

        protected Comparable convert(Map.Entry mapEntry, Comparable entryValue, Comparable attributeValue) {
            if (attributeValue == null) {
                return null;
            }
            if (attributeValue instanceof IndexImpl.NullObject) {
                return IndexImpl.NULL;
            }
            AttributeType type = attributeType;
            if (type == null) {
                QueryableEntry queryableEntry = (QueryableEntry) mapEntry;
                type = queryableEntry.getAttributeType(attribute);
                attributeType = type;
            }
            if (type == AttributeType.ENUM) {
                
                return type.getConverter().convert(attributeValue);
            } else {
                
                if (entryValue != null && entryValue.getClass().isAssignableFrom(attributeValue.getClass())) {
                    return attributeValue;
                } else if (type != null) {
                    return type.getConverter().convert(attributeValue);
                } else {
                    throw new QueryException("Unknown attribute type: " + attributeValue.getClass().getName()
                            + " for attribute: " + attribute);
                }
            }
        }

        @Override
        public boolean isIndexed(QueryContext queryContext) {
            return getIndex(queryContext) != null;
        }

        protected Index getIndex(QueryContext queryContext) {
            return queryContext.getIndex(attribute);
        }

        protected Comparable readAttribute(Map.Entry entry) {
            QueryableEntry queryableEntry = (QueryableEntry) entry;
            Comparable val = queryableEntry.getAttribute(attribute);
            if (val != null && val.getClass().isEnum()) {
                val = val.toString();
            }
            return val;
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            out.writeUTF(attribute);
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            attribute = in.readUTF();
        }
    }

    private static class InstanceOfPredicate implements Predicate, DataSerializable {
        private Class klass;

        public InstanceOfPredicate(Class klass) {
            this.klass = klass;
        }

        @Override
        public boolean apply(Map.Entry mapEntry) {
            Object value = mapEntry.getValue();
            if (value == null) {
                return false;
            }
            return klass.isAssignableFrom(value.getClass());
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            out.writeUTF(klass.getName());
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            String klassName = in.readUTF();
            try {
                klass = in.getClassLoader().loadClass(klassName);
            } catch (ClassNotFoundException e) {
                throw new HazelcastSerializationException("Failed to load class: " + klass, e);
            }
        }

        @Override
        public String toString() {
            return " instanceOf (" + klass.getName() + ")";
        }
    }
}

<code block>


package com.hazelcast.query;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.query.impl.IndexImpl;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryableEntry;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Set;

import static com.hazelcast.query.Predicates.AbstractPredicate;
import static com.hazelcast.query.Predicates.and;
import static com.hazelcast.query.Predicates.between;
import static com.hazelcast.query.Predicates.equal;
import static com.hazelcast.query.Predicates.greaterEqual;
import static com.hazelcast.query.Predicates.greaterThan;
import static com.hazelcast.query.Predicates.ilike;
import static com.hazelcast.query.Predicates.lessEqual;
import static com.hazelcast.query.Predicates.lessThan;
import static com.hazelcast.query.Predicates.like;
import static com.hazelcast.query.Predicates.notEqual;
import static com.hazelcast.query.Predicates.or;
import static com.hazelcast.query.Predicates.regex;



public class SqlPredicate extends AbstractPredicate implements IndexAwarePredicate {

    private static final long serialVersionUID = 1;

    private transient Predicate predicate;
    private String sql;

    public SqlPredicate(String sql) {
        this.sql = sql;
        predicate = createPredicate(sql);
    }

    public SqlPredicate() {
    }

    @Override
    public boolean apply(Map.Entry mapEntry) {
        return predicate.apply(mapEntry);
    }

    @Override
    public boolean isIndexed(QueryContext queryContext) {
        if (predicate instanceof IndexAwarePredicate) {
            return ((IndexAwarePredicate) predicate).isIndexed(queryContext);
        }
        return false;
    }

    @Override
    public Set<QueryableEntry> filter(QueryContext queryContext) {
        return ((IndexAwarePredicate) predicate).filter(queryContext);
    }

    @Override
    public void writeData(ObjectDataOutput out) throws IOException {
        out.writeUTF(sql);
    }

    @Override
    public void readData(ObjectDataInput in) throws IOException {
        sql = in.readUTF();
        predicate = createPredicate(sql);
    }

    private int getApostropheIndex(String str, int start) {
        return str.indexOf('\'', start);
    }

    private int getApostropheIndexIgnoringDoubles(String str, int start) {
        int i = str.indexOf('\'', start);
        int j = str.indexOf('\'', i + 1);
        
        while (i == j - 1) {
            i = str.indexOf('\'', j + 1);
            j = str.indexOf('\'', i + 1);
        }
        return i;
    }

    private String removeEscapes(String phrase) {
        return (phrase.length() > 2) ? phrase.replace("''", "'") : phrase;
    }

    private Predicate createPredicate(String sql) {
        String paramSql = sql;
        Map<String, String> mapPhrases = new HashMap<String, String>(1);
        int apoIndex = getApostropheIndex(paramSql, 0);
        if (apoIndex != -1) {
            int phraseId = 0;
            StringBuilder newSql = new StringBuilder();
            while (apoIndex != -1) {
                phraseId++;
                int start = apoIndex + 1;
                int end = getApostropheIndexIgnoringDoubles(paramSql, apoIndex + 1);
                if (end == -1) {
                    throw new RuntimeException("Missing ' in sql");
                }
                String phrase = removeEscapes(paramSql.substring(start, end));

                String key = "$" + phraseId;
                mapPhrases.put(key, phrase);
                String before = paramSql.substring(0, apoIndex);
                paramSql = paramSql.substring(end + 1);
                newSql.append(before);
                newSql.append(key);
                apoIndex = getApostropheIndex(paramSql, 0);
            }
            newSql.append(paramSql);
            paramSql = newSql.toString();
        }
        Parser parser = new Parser();
        List<String> sqlTokens = parser.toPrefix(paramSql);
        List<Object> tokens = new ArrayList<Object>(sqlTokens);
        if (tokens.size() == 0) {
            throw new RuntimeException("Invalid SQL: [" + paramSql + "]");
        }
        if (tokens.size() == 1) {
            return eval(tokens.get(0));
        }
        root:
        while (tokens.size() > 1) {
            boolean foundOperand = false;
            for (int i = 0; i < tokens.size(); i++) {
                Object tokenObj = tokens.get(i);
                if (tokenObj instanceof String && parser.isOperand((String) tokenObj)) {
                    String token = (String) tokenObj;
                    if ("=".equals(token) || "==".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, equal((String) first, (Comparable) second));
                    } else if ("!=".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, notEqual((String) first, (Comparable) second));
                    } else if (">".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, greaterThan((String) first, (Comparable) second));
                    } else if (">=".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, greaterEqual((String) first, (Comparable) second));
                    } else if ("<=".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, lessEqual((String) first, (Comparable) second));
                    } else if ("<".equals(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, lessThan((String) first, (Comparable) second));
                    } else if ("LIKE".equalsIgnoreCase(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, like((String) first, (String) second));
                    } else if ("ILIKE".equalsIgnoreCase(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, ilike((String) first, (String) second));
                    } else if ("REGEX".equalsIgnoreCase(token)) {
                        int position = (i - 2);
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, regex((String) first, (String) second));
                    } else if ("IN".equalsIgnoreCase(token)) {
                        int position = i - 2;
                        validateOperandPosition(position);
                        Object exp = toValue(tokens.remove(position), mapPhrases);
                        String[] values = toValue(((String) tokens.remove(position)).split(","), mapPhrases);
                        setOrAdd(tokens, position, Predicates.in((String) exp, values));
                    } else if ("NOT".equalsIgnoreCase(token)) {
                        int position = i - 1;
                        validateOperandPosition(position);
                        Object exp = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, Predicates.not(eval(exp)));
                    } else if ("BETWEEN".equalsIgnoreCase(token)) {
                        int position = i - 3;
                        validateOperandPosition(position);
                        Object expression = tokens.remove(position);
                        Object from = toValue(tokens.remove(position), mapPhrases);
                        Object to = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, between((String) expression, (Comparable) from, (Comparable) to));
                    } else if ("AND".equalsIgnoreCase(token)) {
                        int position = i - 2;
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, and(eval(first), eval(second)));
                    } else if ("OR".equalsIgnoreCase(token)) {
                        int position = i - 2;
                        validateOperandPosition(position);
                        Object first = toValue(tokens.remove(position), mapPhrases);
                        Object second = toValue(tokens.remove(position), mapPhrases);
                        setOrAdd(tokens, position, or(eval(first), eval(second)));
                    } else {
                        throw new RuntimeException("Unknown token " + token);
                    }
                    continue root;
                }
            }
            if (!foundOperand) {
                throw new RuntimeException("Invalid SQL: [" + paramSql + "]");
            }
        }
        return (Predicate) tokens.get(0);
    }

    private void validateOperandPosition(int pos) {
        if (pos < 0) {
            throw new RuntimeException("Invalid SQL: [" + sql + "]");
        }
    }

    private Object toValue(final Object key, final Map<String, String> phrases) {
        final String value = phrases.get(key);
        if (value != null) {
            return value;
        } else if (key instanceof String && ("null".equalsIgnoreCase((String) key))) {
            return IndexImpl.NULL;
        } else {
            return key;
        }
    }

    private String[] toValue(final String[] keys, final Map<String, String> phrases) {
        for (int i = 0; i < keys.length; i++) {
            final String value = phrases.get(keys[i]);
            if (value != null) {
                keys[i] = value;
            }
        }
        return keys;
    }

    private void setOrAdd(List tokens, int position, Predicate predicate) {
        if (tokens.size() == 0) {
            tokens.add(predicate);
        } else {
            tokens.set(position, predicate);
        }
    }

    private Predicate eval(Object statement) {
        if (statement instanceof String) {
            return equal((String) statement, "true");
        } else {
            return (Predicate) statement;
        }
    }

    private void readObject(java.io.ObjectInputStream in)
            throws IOException, ClassNotFoundException {
        predicate = createPredicate(sql);
    }

    @Override
    public String toString() {
        return predicate.toString();
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (!(o instanceof SqlPredicate)) {
            return false;
        }

        SqlPredicate that = (SqlPredicate) o;

        return sql.equals(that.sql);
    }

    @Override
    public int hashCode() {
        return sql.hashCode();
    }
}

<code block>


package com.hazelcast.query;

import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.IMap;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.query.impl.AttributeType;
import com.hazelcast.query.impl.QueryContext;
import com.hazelcast.query.impl.QueryEntry;
import com.hazelcast.query.impl.QueryableEntry;
import com.hazelcast.query.impl.getters.ReflectionHelper;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.math.BigDecimal;
import java.util.Map;
import java.util.Set;

import static com.hazelcast.instance.TestUtil.toData;
import static com.hazelcast.query.Predicates.AndPredicate;
import static com.hazelcast.query.Predicates.EqualPredicate;
import static com.hazelcast.query.Predicates.and;
import static com.hazelcast.query.Predicates.between;
import static com.hazelcast.query.Predicates.equal;
import static com.hazelcast.query.Predicates.greaterEqual;
import static com.hazelcast.query.Predicates.greaterThan;
import static com.hazelcast.query.Predicates.ilike;
import static com.hazelcast.query.Predicates.in;
import static com.hazelcast.query.Predicates.instanceOf;
import static com.hazelcast.query.Predicates.lessEqual;
import static com.hazelcast.query.Predicates.lessThan;
import static com.hazelcast.query.Predicates.like;
import static com.hazelcast.query.Predicates.notEqual;
import static com.hazelcast.query.Predicates.or;
import static com.hazelcast.query.Predicates.regex;
import static com.hazelcast.query.SampleObjects.Employee;
import static com.hazelcast.query.SampleObjects.Value;
import static java.lang.Boolean.FALSE;
import static java.lang.Boolean.TRUE;
import static java.util.Map.Entry;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class PredicatesTest extends HazelcastTestSupport {

    @Test
    public void testAndPredicate_whenFirstIndexAwarePredicateIsNotIndexed() throws Exception {
        final HazelcastInstance instance = createHazelcastInstance();
        final IMap<Object, Object> map = instance.getMap("map");
        map.addIndex("name", false);
        String name = randomString();
        map.put("key", new Value(name));

        final ShouldExecuteOncePredicate indexAwareNotIndexedPredicate = new ShouldExecuteOncePredicate();
        final EqualPredicate equalPredicate = new EqualPredicate("name", name);
        final AndPredicate andPredicate = new AndPredicate(indexAwareNotIndexedPredicate, equalPredicate);
        map.values(andPredicate);
    }

    static class ShouldExecuteOncePredicate implements IndexAwarePredicate {

        boolean executed = false;

        @Override
        public boolean apply(Map.Entry mapEntry) {
            if (!executed) {
                executed = true;
                return true;
            }
            throw new RuntimeException();
        }

        @Override
        public Set<QueryableEntry> filter(final QueryContext queryContext) {
            return null;
        }

        @Override
        public boolean isIndexed(final QueryContext queryContext) {
            return false;
        }
    }

    @Test
    public void testEqual() {
        assertPredicateTrue(equal(null, "value"), "value");
        assertPredicateFalse(equal(null, "value1"), "value");
        assertPredicateTrue(equal(null, TRUE), true);
        assertPredicateTrue(equal(null, true), TRUE);
        assertPredicateFalse(equal(null, true), FALSE);
        assertPredicateFalse(equal(null, new BigDecimal("1.23E3")), new BigDecimal("1.23E2"));
        assertPredicateTrue(equal(null, new BigDecimal("1.23E3")), new BigDecimal("1.23E3"));
        assertPredicateFalse(equal(null, 15.22), 15.23);
        assertPredicateTrue(equal(null, 15.22), 15.22);
        assertPredicateFalse(equal(null, 16), 15);
    }


    @Test
    public void testAnd() {
        final Predicate and1 = and(greaterThan(null, 4), lessThan(null, 6));
        assertPredicateTrue(and1, 5);
        final Predicate and2 = and(greaterThan(null, 5), lessThan(null, 6));
        assertPredicateFalse(and2, 4);
        final Predicate and3 = and(greaterThan(null, 4), lessThan(null, 6), equal(null, 5));
        assertPredicateTrue(and3, 5);
        final Predicate and4 = Predicates.and(greaterThan(null, 3), lessThan(null, 6), equal(null, 4));
        assertPredicateFalse(and4, 5);
    }

    @Test
    public void testOr() {
        final Predicate or1 = or(equal(null, 3), equal(null, 4), equal(null, 5));
        assertPredicateTrue(or1, 4);
        assertPredicateFalse(or1, 6);
    }

    @Test
    public void testGreaterEqual() {
        assertPredicateTrue(greaterEqual(null, 5), 5);
    }

    @Test
    public void testLessThan() {
        assertPredicateTrue(lessThan(null, 7), 6);
        assertPredicateFalse(lessThan(null, 3), 4);
        assertPredicateFalse(lessThan(null, 4), 4);
        assertPredicateTrue(lessThan(null, "tc"), "bz");
        assertPredicateFalse(lessThan(null, "gx"), "h0");
    }

    @Test
    public void testGreaterThan() {
        assertPredicateTrue(greaterThan(null, 5), 6);
        assertPredicateFalse(greaterThan(null, 5), 4);
        assertPredicateFalse(greaterThan(null, 5), 5);
        assertPredicateTrue(greaterThan(null, "aa"), "xa");
        assertPredicateFalse(greaterThan(null, "da"), "cz");
        assertPredicateTrue(greaterThan(null, new BigDecimal("1.23E2")), new BigDecimal("1.23E3"));
    }

    @Test
    public void testLessEqual() {
        assertPredicateTrue(lessEqual(null, 4), 4);
    }

    @Test
    public void testPredicatesAgainstANullField() {
        assertFalse_withNullEntry(lessEqual("nullField", 1));

        assertFalse_withNullEntry(in("nullField", 1));
        assertFalse_withNullEntry(lessThan("nullField", 1));
        assertFalse_withNullEntry(greaterEqual("nullField", 1));
        assertFalse_withNullEntry(greaterThan("nullField", 1));
        assertFalse_withNullEntry(equal("nullField", 1));
        assertFalse_withNullEntry(notEqual("nullField", null));
        assertFalse_withNullEntry(notEqual("nullField", 1));
        assertFalse_withNullEntry(between("nullField", 1, 1));
        assertTrue_withNullEntry(like("nullField", null));
        assertTrue_withNullEntry(ilike("nullField", null));
        assertTrue_withNullEntry(regex("nullField", null));
    }

    @Test
    public void testBetween() {
        assertPredicateTrue(between(null, 4, 6), 5);
        assertPredicateTrue(between(null, 5, 6), 5);
        assertPredicateTrue(between(null, "abc", "xyz"), "prs");
        assertPredicateFalse(between(null, "klmn", "xyz"), "efgh");
        assertPredicateFalse(between(null, 6, 7), 5);
    }

    @Test
    public void testIn() {
        assertPredicateTrue(in(null, 4, 7, 8, 5), 5);
        assertPredicateTrue(in(null, 5, 7, 8), 5);
        assertPredicateFalse(in(null, 6, 7, 8), 5);
        assertPredicateFalse(in(null, 6, 7, 8), 9);
    }

    @Test
    public void testLike() {
        assertPredicateTrue(like(null, "J%"), "Java");
        assertPredicateTrue(like(null, "Ja%"), "Java");
        assertPredicateTrue(like(null, "J_v_"), "Java");
        assertPredicateTrue(like(null, "_av_"), "Java");
        assertPredicateTrue(like(null, "_a__"), "Java");
        assertPredicateTrue(like(null, "J%v_"), "Java");
        assertPredicateTrue(like(null, "J%_"), "Java");
        assertPredicateFalse(like(null, "java"), "Java");
        assertPredicateFalse(like(null, "j%"), "Java");
        assertPredicateFalse(like(null, "J_a"), "Java");
        assertPredicateFalse(like(null, "J_ava"), "Java");
        assertPredicateFalse(like(null, "J_a_a"), "Java");
        assertPredicateFalse(like(null, "J_av__"), "Java");
        assertPredicateFalse(like(null, "J_Va"), "Java");
        assertPredicateTrue(like(null, "Java World"), "Java World");
        assertPredicateTrue(like(null, "Java%ld"), "Java World");
        assertPredicateTrue(like(null, "%World"), "Java World");
        assertPredicateTrue(like(null, "Java_World"), "Java World");

        assertPredicateTrue(like(null, "J.-*.*\\%"), "J.-*.*%");
        assertPredicateTrue(like(null, "J\\_"), "J_");
        assertPredicateTrue(like(null, "J%"), "Java");

    }

    @Test
    public void testILike() {
        assertPredicateFalse(like(null, "JavaWorld"), "Java World");
        assertPredicateTrue(ilike(null, "Java_World"), "java World");
        assertPredicateTrue(ilike(null, "java%ld"), "Java World");
        assertPredicateTrue(ilike(null, "%world"), "Java World");
        assertPredicateFalse(ilike(null, "Java_World"), "gava World");
    }

    @Test
    public void testIsInstanceOf() {
        assertTrue(instanceOf(Long.class).apply(new DummyEntry(1L)));
        assertFalse(instanceOf(Long.class).apply(new DummyEntry("Java")));
        assertTrue(instanceOf(Number.class).apply(new DummyEntry(4)));
    }

    @Test
    public void testCriteriaAPI() {
        Object value = new Employee(12, "abc-123-xvz", 34, true, 10D);
        EntryObject e = new PredicateBuilder().getEntryObject();
        EntryObject e2 = e.get("age");
        Predicate predicate = e2.greaterEqual(29).and(e2.lessEqual(36));
        assertTrue(predicate.apply(createEntry("1", value)));
        e = new PredicateBuilder().getEntryObject();
        assertTrue(e.get("id").equal(12).apply(createEntry("1", value)));
    }

    @Test(expected = NullPointerException.class)
    public void testBetweenNull() {
        Predicates.between("", null, null);
    }

    @Test(expected = NullPointerException.class)
    public void testLessThanNull() {
        Predicates.lessThan("", null);
    }

    @Test(expected = NullPointerException.class)
    public void testLessEqualNull() {
        Predicates.lessEqual("", null);
    }

    @Test(expected = NullPointerException.class)
    public void testGreaterThanNull() {
        Predicates.greaterThan("", null);
    }

    @Test(expected = NullPointerException.class)
    public void testGreaterEqualNull() {
        Predicates.greaterEqual("", null);
    }

    @Test(expected = NullPointerException.class)
    public void testInNullWithNullArray() {
        Predicates.in("", null);
    }

    private class DummyEntry extends QueryEntry {

        DummyEntry(Comparable attribute) {
            super(null, toData("1"), "1", attribute);
        }

        @Override
        public Comparable getAttribute(String attributeName) throws QueryException {
            return (Comparable) getValue();
        }

        @Override
        public AttributeType getAttributeType(String attributeName) {
            return ReflectionHelper.getAttributeType(getValue().getClass());
        }
    }

    private class NullDummyEntry implements QueryableEntry {

        private Integer nullField;

        private NullDummyEntry() {
        }

        public Integer getNullField() {
            return nullField;
        }

        public void setNullField(Integer nullField) {
            this.nullField = nullField;
        }

        @Override
        public Object getValue() {
            return null;
        }

        @Override
        public Object setValue(Object value) {
            return null;
        }

        @Override
        public Object getKey() {
            return 1;
        }

        @Override
        public Comparable getAttribute(String attributeName) throws QueryException {
            return null;
        }

        @Override
        public AttributeType getAttributeType(String attributeName) {
            return AttributeType.INTEGER;
        }

        @Override
        public Data getKeyData() {
            return null;
        }

        @Override
        public Data getValueData() {
            return null;
        }

        @Override
        public Data getIndexKey() {
            return null;
        }

    }

    private static Entry createEntry(final Object key, final Object value) {
        return new QueryEntry(null, toData(key), key, value);
    }

    private void assertPredicateTrue(Predicate p, Comparable comparable) {
        assertTrue(p.apply(new DummyEntry(comparable)));
    }

    private void assertPredicateFalse(Predicate p, Comparable comparable) {
        assertFalse(p.apply(new DummyEntry(comparable)));
    }

    private void assertTrue_withNullEntry(Predicate p) {
        assertTrue(p.apply(new NullDummyEntry()));
    }

    private void assertFalse_withNullEntry(Predicate p) {
        assertFalse(p.apply(new NullDummyEntry()));
    }
}

<code block>


package com.hazelcast.query.impl;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.nio.serialization.impl.DefaultSerializationServiceBuilder;
import com.hazelcast.nio.serialization.Portable;
import com.hazelcast.nio.serialization.PortableFactory;
import com.hazelcast.nio.serialization.PortableReader;
import com.hazelcast.nio.serialization.PortableWriter;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.query.Predicates.AndPredicate;
import com.hazelcast.query.Predicates.EqualPredicate;
import com.hazelcast.query.QueryException;
import com.hazelcast.query.impl.getters.ReflectionHelper;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.io.IOException;
import java.util.concurrent.ConcurrentMap;

import static com.hazelcast.instance.TestUtil.toData;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class IndexTest {

    static final short FACTORY_ID = 1;

    final SerializationService ss = new DefaultSerializationServiceBuilder()
            .addPortableFactory(FACTORY_ID, new TestPortableFactory()).build();

    @Test
    public void testBasics() {
        testIt(true);
        testIt(false);
    }

    private QueryRecord newRecord(Object key, final Comparable attributeValue) {
        return new QueryRecord(toData(key), attributeValue);
    }

    @Test
    public void testRemoveEnumIndex() {
        IndexService is = new IndexService();
        is.addOrGetIndex("favoriteCity", false);
        Data key = ss.toData(1);
        Data value = ss.toData(new SerializableWithEnum(SerializableWithEnum.City.Istanbul));
        is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        assertNotNull(is.getIndex("favoriteCity"));
        is.removeEntryIndex(key);
        assertEquals(0,is.getIndex("favoriteCity").getRecords(SerializableWithEnum.City.Istanbul).size());
    }

    @Test
    public void testIndex() throws QueryException {
        IndexService is = new IndexService();
        Index dIndex = is.addOrGetIndex("d", false);
        Index boolIndex = is.addOrGetIndex("bool", false);
        Index strIndex = is.addOrGetIndex("str", false);
        for (int i = 0; i < 1000; i++) {
            Data key = ss.toData(i);
            Data value = ss.toData(new MainPortable(i % 2 == 0, -10.34d, "joe" + i));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }
        assertEquals(1000, dIndex.getRecords(-10.34d).size());
        assertEquals(1, strIndex.getRecords("joe23").size());
        assertEquals(500, boolIndex.getRecords(true).size());
        for (int i = 0; i < 1000; i++) {
            Data key = ss.toData(i);
            Data value = ss.toData(new MainPortable(false, 11.34d, "joe"));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }
        assertEquals(0, dIndex.getRecords(-10.34d).size());
        assertEquals(0, strIndex.getRecords("joe23").size());
        assertEquals(1000, strIndex.getRecords("joe").size());
        assertEquals(1000, boolIndex.getRecords(false).size());
        assertEquals(0, boolIndex.getRecords(true).size());
        for (int i = 0; i < 1000; i++) {
            Data key = ss.toData(i);
            Data value = ss.toData(new MainPortable(false, -1 * (i + 1), "joe" + i));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }
        assertEquals(0, dIndex.getSubRecordsBetween(1d, 1001d).size());
        assertEquals(1000, dIndex.getSubRecordsBetween(-1d, -1001d).size());
        for (int i = 0; i < 1000; i++) {
            Data key = ss.toData(i);
            Data value = ss.toData(new MainPortable(false, 1 * (i + 1), "joe" + i));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }
        assertEquals(1000, dIndex.getSubRecordsBetween(1d, 1001d).size());
        assertEquals(0, dIndex.getSubRecordsBetween(-1d, -1001d).size());
        assertEquals(400, dIndex.getSubRecords(ComparisonType.GREATER, 600d).size());
        assertEquals(401, dIndex.getSubRecords(ComparisonType.GREATER_EQUAL, 600d).size());
        assertEquals(9, dIndex.getSubRecords(ComparisonType.LESSER, 10d).size());
        assertEquals(10, dIndex.getSubRecords(ComparisonType.LESSER_EQUAL, 10d).size());
        assertEquals(1, is.query(new AndPredicate(new EqualPredicate("d", 1d), new EqualPredicate("bool", "false"))).size());
        assertEquals(1, is.query(new AndPredicate(new EqualPredicate("d", 1), new EqualPredicate("bool", Boolean.FALSE))).size());
        assertEquals(1, is.query(new AndPredicate(new EqualPredicate("d", "1"), new EqualPredicate("bool", false))).size());
    }

    @Test
    public void testIndexWithNull() throws QueryException {
        IndexService is = new IndexService();
        Index strIndex = is.addOrGetIndex("str", true);

        Data value = ss.toData(new MainPortable(false, 1, null));
        Data key1 = ss.toData(0);
        is.saveEntryIndex(new QueryEntry(ss, key1, key1, value));

        value = ss.toData(new MainPortable(false, 2, null));
        Data key2 = ss.toData(1);
        is.saveEntryIndex(new QueryEntry(ss, key2, key2, value));


        for (int i = 2; i < 1000; i++) {
            Data key = ss.toData(i);
            value = ss.toData(new MainPortable(false, 1 * (i + 1), "joe" + i));
            is.saveEntryIndex(new QueryEntry(ss, key, key, value));
        }

        Comparable c = null;
        assertEquals(2, strIndex.getRecords(c).size());
        assertEquals(998, strIndex.getSubRecords(ComparisonType.NOT_EQUAL, null).size());
    }

    private class TestPortableFactory implements PortableFactory {

        public Portable create(int classId) {
            switch (classId) {
                case 1:
                    return new MainPortable();
            }
            return null;
        }

        public int getFactoryId() {
            return FACTORY_ID;
        }
    }

    private static class SerializableWithEnum implements DataSerializable {

        enum City {
            Istanbul,
            Rize,
            Krakow,
            Trabzon;
        }

        private City favoriteCity;

        private SerializableWithEnum() {
        }

        private SerializableWithEnum(City favoriteCity) {
            this.favoriteCity = favoriteCity;
        }

        @Override
        public void writeData(ObjectDataOutput out) throws IOException {
            out.writeObject(favoriteCity);
        }

        @Override
        public void readData(ObjectDataInput in) throws IOException {
            favoriteCity = in.readObject();
        }
    }

    private static class MainPortable implements Portable {

        byte b;
        boolean bool;
        char c;
        short s;
        int i;
        long l;
        float f;
        double d;
        String str;

        private MainPortable() {
        }

        private MainPortable(boolean bool, double d, String str) {
            this.bool = bool;
            this.d = d;
            this.str = str;
        }

        private MainPortable(byte b, boolean bool, char c, short s, int i, long l, float f,
                             double d, String str) {
            this.b = b;
            this.bool = bool;
            this.c = c;
            this.s = s;
            this.i = i;
            this.l = l;
            this.f = f;
            this.d = d;
            this.str = str;
        }

        public int getClassId() {
            return 1;
        }

        public void writePortable(PortableWriter writer) throws IOException {
            writer.writeByte("b", b);
            writer.writeBoolean("bool", bool);
            writer.writeChar("c", c);
            writer.writeShort("s", s);
            writer.writeInt("i", i);
            writer.writeLong("l", l);
            writer.writeFloat("f", f);
            writer.writeDouble("d", d);
            writer.writeUTF("str", str);
        }

        public void readPortable(PortableReader reader) throws IOException {
            b = reader.readByte("b");
            bool = reader.readBoolean("bool");
            c = reader.readChar("c");
            s = reader.readShort("s");
            i = reader.readInt("i");
            l = reader.readLong("l");
            f = reader.readFloat("f");
            d = reader.readDouble("d");
            str = reader.readUTF("str");
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (o == null || getClass() != o.getClass()) return false;
            MainPortable that = (MainPortable) o;
            if (b != that.b) return false;
            if (bool != that.bool) return false;
            if (c != that.c) return false;
            if (Double.compare(that.d, d) != 0) return false;
            if (Float.compare(that.f, f) != 0) return false;
            if (i != that.i) return false;
            if (l != that.l) return false;
            if (s != that.s) return false;
            if (str != null ? !str.equals(that.str) : that.str != null) return false;
            return true;
        }

        @Override
        public int hashCode() {
            int result;
            long temp;
            result = (int) b;
            result = 31 * result + (bool ? 1 : 0);
            result = 31 * result + (int) c;
            result = 31 * result + (int) s;
            result = 31 * result + i;
            result = 31 * result + (int) (l ^ (l >>> 32));
            result = 31 * result + (f != +0.0f ? Float.floatToIntBits(f) : 0);
            temp = d != +0.0d ? Double.doubleToLongBits(d) : 0L;
            result = 31 * result + (int) (temp ^ (temp >>> 32));
            result = 31 * result + (str != null ? str.hashCode() : 0);
            return result;
        }

        @Override
        public String toString() {
            return "MainPortable{" +
                    "b=" + b +
                    ", bool=" + bool +
                    ", c=" + c +
                    ", s=" + s +
                    ", i=" + i +
                    ", l=" + l +
                    ", f=" + f +
                    ", d=" + d +
                    ", str='" + str + '\'' +
                    '}';
        }

        public int getFactoryId() {
            return FACTORY_ID;
        }
    }

    class QueryRecord implements QueryableEntry {
        Data key;
        Comparable attributeValue;

        QueryRecord(Data key, Comparable attributeValue) {
            this.key = key;
            this.attributeValue = attributeValue;
        }

        public Comparable getAttribute(String attributeName) throws QueryException {
            return attributeValue;
        }

        public AttributeType getAttributeType(String attributeName) {
            return ReflectionHelper.getAttributeType(attributeValue.getClass());
        }

        public Data getKeyData() {
            return key;
        }

        public Data getValueData() {
            return null;
        }

        public Data getIndexKey() {
            return key;
        }

        public long getCreationTime() {
            return 0;
        }

        public long getLastAccessTime() {
            return 0;
        }

        public Object getKey() {
            return key;
        }

        public Object getValue() {
            return null;
        }

        public Object setValue(Object value) {
            return null;
        }

        public void changeAttribute(Comparable newAttributeValue) {
            this.attributeValue = newAttributeValue;
        }

        public void writeData(ObjectDataOutput out) throws IOException {
        }

        public void readData(ObjectDataInput in) throws IOException {
        }
    }

    private void testIt(boolean ordered) {
        IndexImpl index = new IndexImpl(null, ordered);
        assertEquals(0, index.getRecords(0L).size());
        assertEquals(0, index.getSubRecordsBetween(0L, 1000L).size());
        QueryRecord record5 = newRecord(5L, 55L);
        index.saveEntryIndex(record5);
        assertEquals(1, index.getRecordValues().size());
        assertEquals(55L, index.getRecordValues().get(record5.getIndexKey()));
        QueryRecord record6 = newRecord(6L, 66L);
        index.saveEntryIndex(record6);
        assertEquals(2, index.getRecordValues().size());
        assertEquals(new Long(66L), index.getRecordValues().get(record6.getIndexKey()));
        record5.changeAttribute(555L);
        index.saveEntryIndex(record5);
        assertEquals(2, index.getRecordValues().size());
        assertEquals(new Long(555L), index.getRecordValues().get(record5.getIndexKey()));
        assertEquals(1, index.getRecords(555L).size());
        assertEquals(2, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(2, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(1, index.getSubRecordsBetween(555L, 555L).size());
        QueryRecord record50 = newRecord(50L, 555L);
        index.saveEntryIndex(record50);
        assertEquals(3, index.getRecordValues().size());
        assertEquals(new Long(555L), index.getRecordValues().get(record5.getIndexKey()));
        assertEquals(new Long(555L), index.getRecordValues().get(record50.getIndexKey()));
        ConcurrentMap<Data, QueryableEntry> records = index.getRecordMap(555L);
        assertNotNull(records);
        assertEquals(2, records.size());
        assertEquals(record5, records.get(record5.getIndexKey()));
        assertEquals(record50, records.get(record50.getIndexKey()));
        assertEquals(2, index.getRecords(555L).size());
        assertEquals(3, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(3, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(2, index.getSubRecordsBetween(555L, 555L).size());
        assertEquals(0, index.getSubRecords(ComparisonType.LESSER, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.LESSER_EQUAL, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.LESSER_EQUAL, 67L).size());
        assertEquals(2, index.getSubRecords(ComparisonType.GREATER, 66L).size());
        assertEquals(3, index.getSubRecords(ComparisonType.GREATER_EQUAL, 66L).size());
        assertEquals(3, index.getSubRecords(ComparisonType.GREATER_EQUAL, 61L).size());
        assertEquals(3, index.getSubRecords(ComparisonType.NOT_EQUAL, 61L).size());
        assertEquals(2, index.getSubRecords(ComparisonType.NOT_EQUAL, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.NOT_EQUAL, 555L).size());
        assertEquals(3, index.getRecords(new Comparable[]{66L, 555L, 34234L}).size());
        assertEquals(2, index.getRecords(new Comparable[]{555L, 34234L}).size());
        index.removeEntryIndex(record5.getIndexKey());
        assertEquals(2, index.getRecordValues().size());
        assertEquals(new Long(555L), index.getRecordValues().get(record50.getIndexKey()));
        assertEquals(null, index.getRecordValues().get(record5.getIndexKey()));
        records = index.getRecordMap(555L);
        assertNotNull(records);
        assertEquals(null, records.get(5L));
        assertEquals(record50, records.get(toData(50L)));
        assertEquals(1, index.getRecords(555L).size());
        assertEquals(2, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(2, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(1, index.getSubRecordsBetween(555L, 555L).size());
        assertEquals(0, index.getSubRecords(ComparisonType.LESSER, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.LESSER_EQUAL, 66L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.LESSER_EQUAL, 67L).size());
        assertEquals(1, index.getSubRecords(ComparisonType.GREATER, 66L).size());
        assertEquals(2, index.getSubRecords(ComparisonType.GREATER_EQUAL, 66L).size());
        assertEquals(2, index.getSubRecords(ComparisonType.GREATER_EQUAL, 61L).size());
        index.removeEntryIndex(record50.getIndexKey());
        assertEquals(1, index.getRecordValues().size());
        assertEquals(null, index.getRecordValues().get(50L));
        records = index.getRecordMap(555L);
        assertNull(records);
        assertEquals(0, index.getRecords(555L).size());
        assertEquals(1, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(1, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(0, index.getSubRecordsBetween(555L, 555L).size());
        index.removeEntryIndex(record6.getIndexKey());
        assertEquals(0, index.getRecordValues().size());
        assertEquals(null, index.getRecordValues().get(6L));
        assertNull(index.getRecordMap(66L));
        assertEquals(0, index.getRecords(555L).size());
        assertEquals(0, index.getSubRecordsBetween(55L, 555L).size());
        assertEquals(0, index.getSubRecordsBetween(66L, 555L).size());
        assertEquals(0, index.getSubRecordsBetween(555L, 555L).size());
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.cluster.MemberInfo;
import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.Member;
import com.hazelcast.core.MigrationEvent;
import com.hazelcast.core.MigrationEvent.MigrationStatus;
import com.hazelcast.core.MigrationListener;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionLostEvent;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationEndpoint;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.partition.PartitionEvent;
import com.hazelcast.partition.PartitionEventListener;
import com.hazelcast.partition.PartitionInfo;
import com.hazelcast.partition.PartitionLostEvent;
import com.hazelcast.partition.PartitionLostListener;
import com.hazelcast.partition.PartitionRuntimeState;
import com.hazelcast.partition.PartitionServiceProxy;
import com.hazelcast.partition.membergroup.MemberGroup;
import com.hazelcast.partition.membergroup.MemberGroupFactory;
import com.hazelcast.partition.membergroup.MemberGroupFactoryFactory;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationResponseHandler;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PartitionAwareService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.FutureUtil.ExceptionHandler;
import com.hazelcast.util.scheduler.CoalescingDelayedTrigger;
import com.hazelcast.util.scheduler.EntryTaskScheduler;
import com.hazelcast.util.scheduler.EntryTaskSchedulerFactory;
import com.hazelcast.util.scheduler.ScheduleType;
import com.hazelcast.util.scheduler.ScheduledEntry;
import com.hazelcast.util.scheduler.ScheduledEntryProcessor;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReferenceArray;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;

import static com.hazelcast.partition.impl.InternalPartitionServiceState.MIGRATION_LOCAL;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.MIGRATION_ON_MASTER;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.REPLICA_NOT_SYNC;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.SAFE;
import static com.hazelcast.spi.impl.OperationResponseHandlerFactory.createErrorLoggingResponseHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;



public class InternalPartitionServiceImpl implements InternalPartitionService, ManagedService,
        EventPublishingService<PartitionEvent, PartitionEventListener<PartitionEvent>>, PartitionAwareService {

    private static final String EXCEPTION_MSG_PARTITION_STATE_SYNC_TIMEOUT = "Partition state sync invocation timed out";

    private static final int DEFAULT_PAUSE_MILLIS = 1000;
    private static final int PARTITION_OWNERSHIP_WAIT_MILLIS = 10;
    private static final int REPLICA_SYNC_CHECK_TIMEOUT_SECONDS = 10;

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final ILogger logger;
    private final int partitionCount;
    private final InternalPartitionImpl[] partitions;
    private final PartitionReplicaVersions[] replicaVersions;
    private final AtomicReferenceArray<ReplicaSyncInfo> replicaSyncRequests;
    private final EntryTaskScheduler<Integer, ReplicaSyncInfo> replicaSyncScheduler;
    @Probe
    private final Semaphore replicaSyncProcessLock;
    private final MigrationThread migrationThread;
    private final long partitionMigrationInterval;
    private final long partitionMigrationTimeout;
    private final long backupSyncCheckInterval;
    private final int maxParallelReplications;
    private final PartitionStateGenerator partitionStateGenerator;
    private final MemberGroupFactory memberGroupFactory;
    private final PartitionServiceProxy proxy;
    private final Lock lock = new ReentrantLock();

    @Probe
    private final AtomicInteger stateVersion = new AtomicInteger();
    @Probe(name = "migrationQueueSize")
    private final BlockingQueue<Runnable> migrationQueue = new LinkedBlockingQueue<Runnable>();
    private final AtomicBoolean migrationActive = new AtomicBoolean(true);
    @Probe(name = "lastRepartitionTime")
    private final AtomicLong lastRepartitionTime = new AtomicLong();
    private final CoalescingDelayedTrigger delayedResumeMigrationTrigger;

    private final ExceptionHandler partitionStateSyncTimeoutHandler;

    @Probe
    
    private volatile int memberGroupsSize;

    
    private volatile boolean initialized;

    @Probe(name = "activeMigrationCount")
    
    private final ConcurrentMap<Integer, MigrationInfo> activeMigrations
            = new ConcurrentHashMap<Integer, MigrationInfo>(3, 0.75f, 1);

    
    private final LinkedList<MigrationInfo> completedMigrations = new LinkedList<MigrationInfo>();

    @Probe
    private final AtomicLong completedMigrationCounter = new AtomicLong();

    public InternalPartitionServiceImpl(Node node) {
        this.partitionCount = node.groupProperties.PARTITION_COUNT.getInteger();
        this.node = node;
        this.nodeEngine = node.nodeEngine;
        this.logger = node.getLogger(InternalPartitionService.class);
        partitionStateSyncTimeoutHandler =
                logAllExceptions(logger, EXCEPTION_MSG_PARTITION_STATE_SYNC_TIMEOUT, Level.FINEST);
        this.partitions = new InternalPartitionImpl[partitionCount];
        PartitionListener partitionListener = new LocalPartitionListener(this, node.getThisAddress());
        for (int i = 0; i < partitionCount; i++) {
            this.partitions[i] = new InternalPartitionImpl(i, partitionListener, node.getThisAddress());
        }
        replicaVersions = new PartitionReplicaVersions[partitionCount];
        for (int i = 0; i < replicaVersions.length; i++) {
            replicaVersions[i] = new PartitionReplicaVersions(i);
        }

        memberGroupFactory = MemberGroupFactoryFactory.newMemberGroupFactory(node.getConfig().getPartitionGroupConfig());
        partitionStateGenerator = new PartitionStateGeneratorImpl();

        long interval = node.groupProperties.PARTITION_MIGRATION_INTERVAL.getLong();
        partitionMigrationInterval = interval > 0 ? TimeUnit.SECONDS.toMillis(interval) : 0;

        partitionMigrationTimeout = TimeUnit.SECONDS.toMillis(
                node.groupProperties.PARTITION_MIGRATION_TIMEOUT.getLong());

        migrationThread = new MigrationThread(node);
        proxy = new PartitionServiceProxy(this);

        ExecutionService executionService = nodeEngine.getExecutionService();
        ScheduledExecutorService scheduledExecutor = executionService.getDefaultScheduledExecutor();

        
        
        
        
        
        
        
        replicaSyncScheduler = EntryTaskSchedulerFactory.newScheduler(scheduledExecutor,
                new ReplicaSyncEntryProcessor(this), ScheduleType.POSTPONE);

        replicaSyncRequests = new AtomicReferenceArray<ReplicaSyncInfo>(partitionCount);

        long maxMigrationDelayMs = calculateMaxMigrationDelayOnMemberRemoved();
        long minMigrationDelayMs = calculateMigrationDelayOnMemberRemoved(maxMigrationDelayMs);
        this.delayedResumeMigrationTrigger = new CoalescingDelayedTrigger(
                executionService, minMigrationDelayMs, maxMigrationDelayMs, new Runnable() {
            @Override
            public void run() {
                resumeMigration();
            }
        });

        long definedBackupSyncCheckInterval = node.groupProperties.PARTITION_BACKUP_SYNC_INTERVAL.getInteger();
        backupSyncCheckInterval = definedBackupSyncCheckInterval > 0 ? definedBackupSyncCheckInterval : 1;
        maxParallelReplications = node.groupProperties.PARTITION_MAX_PARALLEL_REPLICATIONS.getInteger();
        replicaSyncProcessLock = new Semaphore(maxParallelReplications);
        nodeEngine.getMetricsRegistry().scanAndRegister(this, "partitions");
    }

    private long calculateMaxMigrationDelayOnMemberRemoved() {
        
        return node.groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong() / 2;
    }

    private long calculateMigrationDelayOnMemberRemoved(long maxDelayMs) {
        long migrationDelayMs = node.groupProperties.MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS.getLong() * 1000;

        long connectionErrorDetectionIntervalMs = node.groupProperties.CONNECTION_MONITOR_INTERVAL.getLong()
                * node.groupProperties.CONNECTION_MONITOR_MAX_FAULTS.getInteger() * 5;
        migrationDelayMs = Math.max(migrationDelayMs, connectionErrorDetectionIntervalMs);

        long heartbeatIntervalMs = node.groupProperties.HEARTBEAT_INTERVAL_SECONDS.getLong() * 1000;
        migrationDelayMs = Math.max(migrationDelayMs, heartbeatIntervalMs * 3);

        migrationDelayMs = Math.min(migrationDelayMs, maxDelayMs);
        return migrationDelayMs;
    }

    @Probe(name = "migrationActive")
    private int migrationActiveProbe() {
        return migrationActive.get() ? 1 : 0;
    }

    @Probe
    private int localPartitionCount() {
        int count = 0;
        for (InternalPartition partition : partitions) {
            if (partition.isLocal()) {
                count++;
            }
        }
        return count;
    }

    @Override
    public void init(NodeEngine nodeEngine, Properties properties) {
        migrationThread.start();

        int partitionTableSendInterval = node.groupProperties.PARTITION_TABLE_SEND_INTERVAL.getInteger();
        if (partitionTableSendInterval <= 0) {
            partitionTableSendInterval = 1;
        }
        ExecutionService executionService = nodeEngine.getExecutionService();
        executionService.scheduleAtFixedRate(new SendClusterStateTask(),
                partitionTableSendInterval, partitionTableSendInterval, TimeUnit.SECONDS);

        executionService.scheduleWithFixedDelay(new SyncReplicaVersionTask(),
                backupSyncCheckInterval, backupSyncCheckInterval, TimeUnit.SECONDS);
    }

    @Override
    public Address getPartitionOwner(int partitionId) {
        if (!initialized) {
            firstArrangement();
        }
        if (partitions[partitionId].getOwnerOrNull() == null && !node.isMaster() && node.joined()) {
            notifyMasterToAssignPartitions();
        }
        return partitions[partitionId].getOwnerOrNull();
    }

    @Override
    public Address getPartitionOwnerOrWait(int partition) {
        Address owner = getPartitionOwner(partition);
        while (owner == null) {
            try {
                Thread.sleep(PARTITION_OWNERSHIP_WAIT_MILLIS);
            } catch (InterruptedException e) {
                ExceptionUtil.rethrow(e);
            }
            owner = getPartitionOwner(partition);
        }
        return owner;
    }

    private void notifyMasterToAssignPartitions() {
        if (initialized) {
            return;
        }
        if (lock.tryLock()) {
            try {
                if (!initialized && !node.isMaster() && node.getMasterAddress() != null && node.joined()) {
                    Future f = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, new AssignPartitions(),
                            node.getMasterAddress()).setTryCount(1).invoke();
                    f.get(1, TimeUnit.SECONDS);
                }
            } catch (Exception e) {
                logger.finest(e);
            } finally {
                lock.unlock();
            }
        }
    }

    @Override
    public void firstArrangement() {
        if (!node.isMaster() || !node.isActive()) {
            notifyMasterToAssignPartitions();
            return;
        }
        if (!initialized) {
            lock.lock();
            try {
                if (initialized) {
                    return;
                }
                PartitionStateGenerator psg = partitionStateGenerator;
                final Set<Member> members = node.getClusterService().getMembers();
                Collection<MemberGroup> memberGroups = memberGroupFactory.createMemberGroups(members);
                if (memberGroups.isEmpty()) {
                    logger.warning("No member group is available to assign partition ownership...");
                    return;
                }

                logger.info("Initializing cluster partition table first arrangement...");
                Address[][] newState = psg.initialize(memberGroups, partitionCount);
                if (newState.length != partitionCount) {
                    throw new HazelcastException("Invalid partition count! "
                            + "Expected: " + partitionCount + ", Actual: " + newState.length);
                }

                for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
                    InternalPartitionImpl partition = partitions[partitionId];
                    Address[] replicas = newState[partitionId];
                    partition.setReplicaAddresses(replicas);
                }
                initialized = true;
                publishPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
        }
    }

    private void updateMemberGroupsSize() {
        Set<Member> members = node.getClusterService().getMembers();
        final Collection<MemberGroup> groups = memberGroupFactory.createMemberGroups(members);
        int size = 0;
        for (MemberGroup group : groups) {
            if (group.size() > 0) {
                size++;
            }
        }
        memberGroupsSize = size;
    }

    @Override
    public int getMemberGroupsSize() {
        int size = memberGroupsSize;
        
        
        return size > 0 ? size : 1;
    }

    @Probe(name = "maxBackupCount")
    @Override
    public int getMaxBackupCount() {
        return Math.min(getMemberGroupsSize() - 1, InternalPartition.MAX_BACKUP_COUNT);
    }

    @Override
    public void memberAdded(MemberImpl member) {
        if (!member.localMember()) {
            updateMemberGroupsSize();
        }
        if (node.isMaster() && node.isActive()) {
            lock.lock();
            try {
                migrationQueue.clear();
                if (initialized) {
                    migrationQueue.add(new RepartitioningTask());

                    
                    Collection<MemberImpl> members = node.clusterService.getMemberList();
                    PartitionStateOperation op = new PartitionStateOperation(createPartitionState(members));
                    nodeEngine.getOperationService().send(op, member.getAddress());
                }
            } finally {
                lock.unlock();
            }
        }
    }

    @Override
    public void memberRemoved(final MemberImpl member) {
        updateMemberGroupsSize();
        final Address deadAddress = member.getAddress();
        final Address thisAddress = node.getThisAddress();
        if (deadAddress == null || deadAddress.equals(thisAddress)) {
            return;
        }
        lock.lock();
        try {
            migrationQueue.clear();
            if (!activeMigrations.isEmpty()) {
                if (node.isMaster()) {
                    rollbackActiveMigrationsFromPreviousMaster(node.getLocalMember().getUuid());
                }
                for (MigrationInfo migrationInfo : activeMigrations.values()) {
                    if (deadAddress.equals(migrationInfo.getSource()) || deadAddress.equals(migrationInfo.getDestination())) {
                        migrationInfo.invalidate();
                    }
                }
            }
            
            
            
            
            pauseMigration();
            cancelReplicaSyncRequestsTo(deadAddress);
            removeDeadAddress(deadAddress, thisAddress);

            if (node.isMaster() && initialized) {
                migrationQueue.add(new RepartitioningTask());
            }

            resumeMigrationEventually();
        } finally {
            lock.unlock();
        }
    }

    private void cancelReplicaSyncRequestsTo(Address deadAddress) {
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            ReplicaSyncInfo syncInfo = replicaSyncRequests.get(partitionId);
            if (syncInfo != null && deadAddress.equals(syncInfo.target)) {
                cancelReplicaSync(partitionId);
            }
        }
    }

    void cancelReplicaSync(int partitionId) {
        ReplicaSyncInfo syncInfo = replicaSyncRequests.get(partitionId);
        if (syncInfo != null && replicaSyncRequests.compareAndSet(partitionId, syncInfo, null)) {
            replicaSyncScheduler.cancel(partitionId);
            releaseReplicaSyncPermit();
        }
    }

    private void resumeMigrationEventually() {
        delayedResumeMigrationTrigger.executeWithDelay();
    }

    private void removeDeadAddress(Address deadAddress, Address thisAddress) {
        for (InternalPartitionImpl partition : partitions) {
            if (deadAddress.equals(partition.getOwnerOrNull()) && thisAddress.equals(partition.getReplicaAddress(1))) {
                partition.setMigrating(true);
            }
            
            partition.onDeadAddress(deadAddress);
            
            if (partition.onDeadAddress(deadAddress)) {
                throw new IllegalStateException("Duplicate address found in partition replicas!");
            }

        }
    }

    private void rollbackActiveMigrationsFromPreviousMaster(final String currentMasterUuid) {
        lock.lock();
        try {
            if (!activeMigrations.isEmpty()) {
                for (MigrationInfo migrationInfo : activeMigrations.values()) {
                    if (!currentMasterUuid.equals(migrationInfo.getMasterUuid())) {
                        
                        
                        logger.info("Rolling-back migration initiated by the old master -> " + migrationInfo);
                        finalizeActiveMigration(migrationInfo);
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private PartitionRuntimeState createPartitionState(Collection<MemberImpl> members) {
        lock.lock();
        try {
            List<MemberInfo> memberInfos = new ArrayList<MemberInfo>(members.size());
            for (MemberImpl member : members) {
                MemberInfo memberInfo = new MemberInfo(member.getAddress(), member.getUuid(), member.getAttributes());
                memberInfos.add(memberInfo);
            }
            ArrayList<MigrationInfo> migrationInfos = new ArrayList<MigrationInfo>(completedMigrations);
            ILogger logger = node.getLogger(PartitionRuntimeState.class);
            return new PartitionRuntimeState(logger, memberInfos, partitions, migrationInfos, stateVersion.get());
        } finally {
            lock.unlock();
        }
    }

    private void publishPartitionRuntimeState() {
        if (!initialized) {
            
            return;
        }

        if (!node.isMaster() || !node.isActive() || !node.joined()) {
            return;
        }

        if (!isMigrationActive()) {
            
            return;
        }

        lock.lock();
        try {
            Collection<MemberImpl> members = node.clusterService.getMemberList();
            PartitionRuntimeState partitionState = createPartitionState(members);
            PartitionStateOperation op = new PartitionStateOperation(partitionState);

            OperationService operationService = nodeEngine.getOperationService();
            for (MemberImpl member : members) {
                if (!member.localMember()) {
                    try {
                        operationService.send(op, member.getAddress());
                    } catch (Exception e) {
                        logger.finest(e);
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void syncPartitionRuntimeState() {
        syncPartitionRuntimeState(node.clusterService.getMemberList());
    }

    private void syncPartitionRuntimeState(Collection<MemberImpl> members) {
        if (!initialized) {
            
            return;
        }

        if (!node.isMaster() || !node.isActive() || !node.joined()) {
            return;
        }

        lock.lock();
        try {
            PartitionRuntimeState partitionState = createPartitionState(members);
            OperationService operationService = nodeEngine.getOperationService();

            List<Future> calls = firePartitionStateOperation(members, partitionState, operationService);
            waitWithDeadline(calls, 3, TimeUnit.SECONDS, partitionStateSyncTimeoutHandler);
        } finally {
            lock.unlock();
        }
    }

    private List<Future> firePartitionStateOperation(Collection<MemberImpl> members,
                                                     PartitionRuntimeState partitionState,
                                                     OperationService operationService) {
        List<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    Address address = member.getAddress();
                    PartitionStateOperation operation = new PartitionStateOperation(partitionState, true);
                    Future<Object> f = operationService.invokeOnTarget(SERVICE_NAME, operation, address);
                    calls.add(f);
                } catch (Exception e) {
                    logger.finest(e);
                }
            }
        }
        return calls;
    }

    void processPartitionRuntimeState(PartitionRuntimeState partitionState) {
        lock.lock();
        try {
            if (!node.isActive() || !node.joined()) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Node should be active(" + node.isActive() + ") and joined(" + node.joined()
                            + ") to be able to process partition table!");
                }
                return;
            }
            final Address sender = partitionState.getEndpoint();
            final Address master = node.getMasterAddress();
            if (node.isMaster()) {
                logger.warning("This is the master node and received a PartitionRuntimeState from "
                        + sender + ". Ignoring incoming state! ");
                return;
            } else {
                if (sender == null || !sender.equals(master)) {
                    if (node.clusterService.getMember(sender) == null) {
                        logger.severe("Received a ClusterRuntimeState from an unknown member!"
                                + " => Sender: " + sender + ", Master: " + master + "! ");
                        return;
                    } else {
                        logger.warning("Received a ClusterRuntimeState, but its sender doesn't seem to be master!"
                                + " => Sender: " + sender + ", Master: " + master + "! "
                                + "(Ignore if master node has changed recently.)");
                        return;
                    }
                }
            }

            stateVersion.set(partitionState.getVersion());
            initialized = true;

            PartitionInfo[] state = partitionState.getPartitions();
            filterAndLogUnknownAddressesInPartitionTable(sender, state);
            finalizeOrRollbackMigration(partitionState, state);
        } finally {
            lock.unlock();
        }
    }

    private void finalizeOrRollbackMigration(PartitionRuntimeState partitionState, PartitionInfo[] state) {
        Collection<MigrationInfo> completedMigrations = partitionState.getCompletedMigrations();
        for (MigrationInfo completedMigration : completedMigrations) {
            addCompletedMigration(completedMigration);
            int partitionId = completedMigration.getPartitionId();
            PartitionInfo partitionInfo = state[partitionId];
            
            
            
            
            
            
            updatePartition(partitionInfo);
            finalizeActiveMigration(completedMigration);
        }
        if (!activeMigrations.isEmpty()) {
            final MemberImpl masterMember = getMasterMember();
            rollbackActiveMigrationsFromPreviousMaster(masterMember.getUuid());
        }

        updateAllPartitions(state);
    }

    private void updatePartition(PartitionInfo partitionInfo) {
        InternalPartitionImpl partition = partitions[partitionInfo.getPartitionId()];
        Address[] replicas = partitionInfo.getReplicaAddresses();
        partition.setReplicaAddresses(replicas);
    }

    private void updateAllPartitions(PartitionInfo[] state) {
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            updatePartition(state[partitionId]);
        }
    }

    private void filterAndLogUnknownAddressesInPartitionTable(Address sender, PartitionInfo[] state) {
        final Set<Address> unknownAddresses = new HashSet<Address>();
        for (int partitionId = 0; partitionId < state.length; partitionId++) {
            PartitionInfo partitionInfo = state[partitionId];
            searchUnknownAddressesInPartitionTable(sender, unknownAddresses, partitionId, partitionInfo);
        }
        logUnknownAddressesInPartitionTable(sender, unknownAddresses);
    }

    private void logUnknownAddressesInPartitionTable(Address sender, Set<Address> unknownAddresses) {
        if (!unknownAddresses.isEmpty() && logger.isLoggable(Level.WARNING)) {
            StringBuilder s = new StringBuilder("Following unknown addresses are found in partition table")
                    .append(" sent from master[").append(sender).append("].")
                    .append(" (Probably they have recently joined or left the cluster.)")
                    .append(" {");
            for (Address address : unknownAddresses) {
                s.append("\n\t").append(address);
            }
            s.append("\n}");
            logger.warning(s.toString());
        }
    }

    private void searchUnknownAddressesInPartitionTable(Address sender, Set<Address> unknownAddresses, int partitionId,
                                                        PartitionInfo partitionInfo) {
        for (int index = 0; index < InternalPartition.MAX_REPLICA_COUNT; index++) {
            Address address = partitionInfo.getReplicaAddress(index);
            if (address != null && getMember(address) == null) {
                if (logger.isFinestEnabled()) {
                    logger.finest(
                            "Unknown " + address + " found in partition table sent from master "
                                    + sender + ". It has probably already left the cluster. partitionId="
                                    + partitionId);
                }
                unknownAddresses.add(address);
            }
        }
    }

    private void finalizeActiveMigration(final MigrationInfo migrationInfo) {
        if (activeMigrations.containsKey(migrationInfo.getPartitionId())) {
            lock.lock();
            try {
                if (activeMigrations.containsValue(migrationInfo)) {
                    if (migrationInfo.startProcessing()) {
                        processMigrationInfo(migrationInfo);
                    } else {
                        logger.info("Scheduling finalization of " + migrationInfo
                                + ", because migration process is currently running.");
                        nodeEngine.getExecutionService().schedule(new Runnable() {
                            @Override
                            public void run() {
                                finalizeActiveMigration(migrationInfo);
                            }
                        }, 3, TimeUnit.SECONDS);
                    }
                }
            } finally {
                lock.unlock();
            }
        }
    }

    private void processMigrationInfo(MigrationInfo migrationInfo) {
        try {
            Address thisAddress = node.getThisAddress();
            boolean source = thisAddress.equals(migrationInfo.getSource());
            boolean destination = thisAddress.equals(migrationInfo.getDestination());
            if (source || destination) {
                int partitionId = migrationInfo.getPartitionId();
                InternalPartitionImpl migratingPartition = getPartitionImpl(partitionId);
                Address ownerAddress = migratingPartition.getOwnerOrNull();
                boolean success = migrationInfo.getDestination().equals(ownerAddress);
                MigrationEndpoint endpoint = source ? MigrationEndpoint.SOURCE : MigrationEndpoint.DESTINATION;
                FinalizeMigrationOperation op = new FinalizeMigrationOperation(endpoint, success);
                op.setPartitionId(partitionId)
                        .setNodeEngine(nodeEngine)
                        .setValidateTarget(false)
                        .setService(this);
                nodeEngine.getOperationService().executeOperation(op);
            }
        } catch (Exception e) {
            logger.warning(e);
        } finally {
            migrationInfo.doneProcessing();
        }
    }

    void addActiveMigration(MigrationInfo migrationInfo) {
        lock.lock();
        try {
            int partitionId = migrationInfo.getPartitionId();
            partitions[partitionId].setMigrating(true);
            MigrationInfo currentMigrationInfo = activeMigrations.putIfAbsent(partitionId, migrationInfo);
            if (currentMigrationInfo != null) {
                boolean oldMaster = false;
                MigrationInfo oldMigration;
                MigrationInfo newMigration;
                MemberImpl masterMember = getMasterMember();
                String master = masterMember.getUuid();
                if (!master.equals(currentMigrationInfo.getMasterUuid())) {
                    
                    oldMigration = currentMigrationInfo;
                    newMigration = migrationInfo;
                    oldMaster = true;
                } else if (!master.equals(migrationInfo.getMasterUuid())) {
                    
                    oldMigration = migrationInfo;
                    newMigration = currentMigrationInfo;
                    oldMaster = true;
                } else if (!currentMigrationInfo.isProcessing() && migrationInfo.isProcessing()) {
                    
                    oldMigration = currentMigrationInfo;
                    newMigration = migrationInfo;
                } else {
                    String message = "Something is seriously wrong! There are two migration requests for the "
                            + "same partition! First -> " + currentMigrationInfo + ", Second -> " + migrationInfo;
                    IllegalStateException error = new IllegalStateException(message);
                    logger.severe(message, error);
                    throw error;
                }

                if (oldMaster) {
                    logger.info("Finalizing migration instantiated by the old master -> " + oldMigration);
                } else {
                    if (logger.isFinestEnabled()) {
                        logger.finest("Finalizing previous migration -> " + oldMigration);
                    }
                }
                finalizeActiveMigration(oldMigration);
                activeMigrations.put(partitionId, newMigration);
            }
        } finally {
            lock.unlock();
        }
    }

    private MemberImpl getMasterMember() {
        return node.clusterService.getMember(node.getMasterAddress());
    }

    MigrationInfo getActiveMigration(int partitionId) {
        return activeMigrations.get(partitionId);
    }

    MigrationInfo removeActiveMigration(int partitionId) {
        partitions[partitionId].setMigrating(false);
        return activeMigrations.remove(partitionId);
    }

    @Override
    public Collection<MigrationInfo> getActiveMigrations() {
        return Collections.unmodifiableCollection(activeMigrations.values());
    }

    private void addCompletedMigration(MigrationInfo migrationInfo) {
        completedMigrationCounter.incrementAndGet();

        lock.lock();
        try {
            if (completedMigrations.size() > 25) {
                completedMigrations.removeFirst();
            }
            completedMigrations.add(migrationInfo);
        } finally {
            lock.unlock();
        }
    }

    private void evictCompletedMigrations() {
        lock.lock();
        try {
            if (!completedMigrations.isEmpty()) {
                completedMigrations.removeFirst();
            }
        } finally {
            lock.unlock();
        }
    }

    
    
    
    void triggerPartitionReplicaSync(int partitionId, int replicaIndex, long delayMillis) {
        if (replicaIndex < 0 || replicaIndex > InternalPartition.MAX_REPLICA_COUNT) {
            throw new IllegalArgumentException("Invalid replica index! replicaIndex=" + replicaIndex
                    + " for partitionId=" + partitionId);
        }

        if (!checkSyncPartitionTarget(partitionId, replicaIndex)) {
            return;
        }

        InternalPartitionImpl partition = getPartitionImpl(partitionId);
        Address target = partition.getOwnerOrNull();
        ReplicaSyncInfo syncInfo = new ReplicaSyncInfo(partitionId, replicaIndex, target);

        if (delayMillis > 0) {
            schedulePartitionReplicaSync(syncInfo, target, delayMillis);
            return;
        }

        
        
        
        if (!isMigrationActive() || partition.isMigrating()) {
            schedulePartitionReplicaSync(syncInfo, target, REPLICA_SYNC_RETRY_DELAY);
            return;
        }

        if (replicaSyncRequests.compareAndSet(partitionId, null, syncInfo)) {
            if (fireSyncReplicaRequest(syncInfo, target)) {
                return;
            }

            replicaSyncRequests.compareAndSet(partitionId, syncInfo, null);
            schedulePartitionReplicaSync(syncInfo, target, REPLICA_SYNC_RETRY_DELAY);
            return;
        }

        long scheduleDelay = getReplicaSyncScheduleDelay(partitionId);
        schedulePartitionReplicaSync(syncInfo, target, scheduleDelay);
    }

    private long getReplicaSyncScheduleDelay(int partitionId) {
        long scheduleDelay = DEFAULT_REPLICA_SYNC_DELAY;
        Address thisAddress = node.getThisAddress();
        InternalPartitionImpl partition = getPartitionImpl(partitionId);
        ReplicaSyncInfo currentSyncInfo = replicaSyncRequests.get(partitionId);
        if (currentSyncInfo != null
                && !thisAddress.equals(partition.getReplicaAddress(currentSyncInfo.replicaIndex))) {
            clearReplicaSyncRequest(partitionId, currentSyncInfo.replicaIndex);
            scheduleDelay = REPLICA_SYNC_RETRY_DELAY;
        }
        return scheduleDelay;
    }

    private boolean fireSyncReplicaRequest(ReplicaSyncInfo syncInfo, Address target) {
        if (tryToAcquireReplicaSyncPermit()) {
            int partitionId = syncInfo.partitionId;
            int replicaIndex = syncInfo.replicaIndex;
            replicaSyncScheduler.cancel(partitionId);

            if (logger.isFinestEnabled()) {
                logger.finest("Sending sync replica request to -> " + target + "; for partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex);
            }
            replicaSyncScheduler.schedule(partitionMigrationTimeout, partitionId, syncInfo);
            ReplicaSyncRequest syncRequest = new ReplicaSyncRequest(partitionId, replicaIndex);
            nodeEngine.getOperationService().send(syncRequest, target);
            return true;
        }
        return false;
    }

    private void schedulePartitionReplicaSync(ReplicaSyncInfo syncInfo, Address target, long delayMillis) {
        int partitionId = syncInfo.partitionId;
        int replicaIndex = syncInfo.replicaIndex;

        if (logger.isFinestEnabled()) {
            logger.finest("Scheduling [" + delayMillis + "ms] sync replica request to -> " + target
                    + "; for partitionId=" + partitionId + ", replicaIndex=" + replicaIndex);
        }
        replicaSyncScheduler.schedule(delayMillis, partitionId, syncInfo);
    }

    private boolean checkSyncPartitionTarget(int partitionId, int replicaIndex) {
        final InternalPartitionImpl partition = getPartitionImpl(partitionId);
        final Address target = partition.getOwnerOrNull();
        if (target == null) {
            logger.info("Sync replica target is null, no need to sync -> partitionId=" + partitionId + ", replicaIndex="
                    + replicaIndex);
            return false;
        }

        Address thisAddress = nodeEngine.getThisAddress();
        if (target.equals(thisAddress)) {
            if (logger.isFinestEnabled()) {
                logger.finest("This node is now owner of partition, cannot sync replica -> partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex + ", partition-info="
                        + getPartitionImpl(partitionId));
            }
            return false;
        }

        if (!partition.isOwnerOrBackup(thisAddress)) {
            if (logger.isFinestEnabled()) {
                logger.finest("This node is not backup replica of partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex + " anymore.");
            }
            return false;
        }
        return true;
    }

    @Override
    public InternalPartition[] getPartitions() {
        
        InternalPartition[] result = new InternalPartition[partitions.length];
        System.arraycopy(partitions, 0, result, 0, partitions.length);
        return result;
    }

    @Override
    public MemberImpl getMember(Address address) {
        return node.clusterService.getMember(address);
    }

    InternalPartitionImpl getPartitionImpl(int partitionId) {
        return partitions[partitionId];
    }

    @Override
    public InternalPartitionImpl getPartition(int partitionId) {
        return getPartition(partitionId, true);
    }

    @Override
    public InternalPartitionImpl getPartition(int partitionId, boolean triggerOwnerAssignment) {
        InternalPartitionImpl p = getPartitionImpl(partitionId);
        if (triggerOwnerAssignment && p.getOwnerOrNull() == null) {
            
            
            getPartitionOwner(partitionId);
        }
        return p;
    }

    @Override
    public boolean prepareToSafeShutdown(long timeout, TimeUnit unit) {
        long timeoutInMillis = unit.toMillis(timeout);
        long sleep = DEFAULT_PAUSE_MILLIS;
        while (timeoutInMillis > 0) {
            while (timeoutInMillis > 0 && shouldWaitMigrationOrBackups(Level.INFO)) {
                timeoutInMillis = sleepWithBusyWait(timeoutInMillis, sleep);
            }
            if (timeoutInMillis <= 0) {
                break;
            }

            if (node.isMaster()) {
                syncPartitionRuntimeState();
            } else {
                timeoutInMillis = waitForOngoingMigrations(timeoutInMillis, sleep);
                if (timeoutInMillis <= 0) {
                    break;
                }
            }

            long start = Clock.currentTimeMillis();
            boolean ok = checkReplicaSyncState();
            timeoutInMillis -= (Clock.currentTimeMillis() - start);
            if (ok) {
                logger.finest("Replica sync state before shutdown is OK");
                return true;
            } else {
                if (timeoutInMillis <= 0) {
                    break;
                }
                logger.info("Some backup replicas are inconsistent with primary, waiting for synchronization. Timeout: "
                        + timeoutInMillis + "ms");
                timeoutInMillis = sleepWithBusyWait(timeoutInMillis, sleep);
            }
        }
        return false;
    }

    private long waitForOngoingMigrations(long timeoutInMillis, long sleep) {
        long timeout = timeoutInMillis;
        while (timeout > 0 && hasOnGoingMigrationMaster(Level.WARNING)) {
            
            logger.info("Waiting for the master node to complete remaining migrations!");
            timeout = sleepWithBusyWait(timeout, sleep);
        }
        return timeout;
    }

    private long sleepWithBusyWait(long timeoutInMillis, long sleep) {
        try {
            
            Thread.sleep(sleep);
        } catch (InterruptedException ie) {
            logger.finest("Busy wait interrupted", ie);
        }
        return timeoutInMillis - sleep;
    }

    @Override
    public boolean isMemberStateSafe() {
        return getMemberState() == SAFE;
    }

    public InternalPartitionServiceState getMemberState() {
        if (hasOnGoingMigrationLocal()) {
            return MIGRATION_LOCAL;
        }

        if (!node.isMaster()) {
            if (hasOnGoingMigrationMaster(Level.OFF)) {
                return MIGRATION_ON_MASTER;
            }
        }

        return isReplicaInSyncState() ? SAFE : REPLICA_NOT_SYNC;
    }

    @Override
    public boolean hasOnGoingMigration() {
        return hasOnGoingMigrationLocal() || (!node.isMaster() && hasOnGoingMigrationMaster(Level.FINEST));
    }

    private boolean hasOnGoingMigrationMaster(Level level) {
        Address masterAddress = node.getMasterAddress();
        if (masterAddress == null) {
            return true;
        }
        Operation operation = new HasOngoingMigration();
        OperationService operationService = nodeEngine.getOperationService();
        InvocationBuilder invocationBuilder = operationService.createInvocationBuilder(SERVICE_NAME, operation,
                masterAddress);
        Future future = invocationBuilder.setTryCount(100).setTryPauseMillis(100).invoke();
        try {
            return (Boolean) future.get(1, TimeUnit.MINUTES);
        } catch (InterruptedException ie) {
            Logger.getLogger(InternalPartitionServiceImpl.class).finest("Future wait interrupted", ie);
        } catch (Exception e) {
            logger.log(level, "Could not get a response from master about migrations! -> " + e.toString());
        }
        return false;
    }

    @Override
    public boolean hasOnGoingMigrationLocal() {
        return !activeMigrations.isEmpty() || !migrationQueue.isEmpty()
                || !isMigrationActive()
                || migrationThread.isMigrating()
                || shouldWaitMigrationOrBackups(Level.OFF);
    }

    private boolean isReplicaInSyncState() {
        if (!initialized || getMemberGroupsSize() < 2) {
            return true;
        }
        final int replicaIndex = 1;
        final List<Future> futures = new ArrayList<Future>();
        final Address thisAddress = node.getThisAddress();
        for (InternalPartitionImpl partition : partitions) {
            final Address owner = partition.getOwnerOrNull();
            if (thisAddress.equals(owner)) {
                if (partition.getReplicaAddress(replicaIndex) != null) {
                    final int partitionId = partition.getPartitionId();
                    final long replicaVersion = getCurrentReplicaVersion(replicaIndex, partitionId);
                    final Operation operation = createReplicaSyncStateOperation(replicaVersion, partitionId);
                    final Future future = invoke(operation, replicaIndex, partitionId);
                    futures.add(future);
                }
            }
        }
        if (futures.isEmpty()) {
            return true;
        }
        for (Future future : futures) {
            boolean isSync = getFutureResult(future, REPLICA_SYNC_CHECK_TIMEOUT_SECONDS, TimeUnit.SECONDS);
            if (!isSync) {
                return false;
            }
        }
        return true;
    }

    private long getCurrentReplicaVersion(int replicaIndex, int partitionId) {
        final long[] versions = getPartitionReplicaVersions(partitionId);
        return versions[replicaIndex - 1];
    }

    private boolean getFutureResult(Future future, long seconds, TimeUnit unit) {
        boolean sync;
        try {
            sync = (Boolean) future.get(seconds, unit);
        } catch (Throwable t) {
            sync = false;
            logger.warning("Exception while getting future", t);
        }
        return sync;
    }

    private Future invoke(Operation operation, int replicaIndex, int partitionId) {
        final OperationService operationService = nodeEngine.getOperationService();
        return operationService.createInvocationBuilder(InternalPartitionService.SERVICE_NAME, operation, partitionId)
                .setTryCount(3)
                .setTryPauseMillis(250)
                .setReplicaIndex(replicaIndex)
                .invoke();
    }

    private Operation createReplicaSyncStateOperation(long replicaVersion, int partitionId) {
        final Operation op = new IsReplicaVersionSync(replicaVersion);
        op.setService(this);
        op.setNodeEngine(nodeEngine);
        op.setOperationResponseHandler(createErrorLoggingResponseHandler(node.getLogger(IsReplicaVersionSync.class)));
        op.setPartitionId(partitionId);

        return op;
    }

    private boolean checkReplicaSyncState() {
        if (!initialized) {
            return true;
        }

        if (getMemberGroupsSize() < 2) {
            return true;
        }

        final Address thisAddress = node.getThisAddress();
        final Semaphore s = new Semaphore(0);
        final AtomicBoolean ok = new AtomicBoolean(true);
        final ExecutionCallback<Object> callback = new ExecutionCallback<Object>() {
            @Override
            public void onResponse(Object response) {
                if (Boolean.FALSE.equals(response)) {
                    ok.compareAndSet(true, false);
                }
                s.release();
            }

            @Override
            public void onFailure(Throwable t) {
                ok.compareAndSet(true, false);
            }
        };
        int ownedCount = submitSyncReplicaOperations(thisAddress, s, ok, callback);
        try {
            if (ok.get()) {
                int permits = ownedCount * getMaxBackupCount();
                return s.tryAcquire(permits, REPLICA_SYNC_CHECK_TIMEOUT_SECONDS, TimeUnit.SECONDS) && ok.get();
            } else {
                return false;
            }
        } catch (InterruptedException ignored) {
            return false;
        }
    }

    private int submitSyncReplicaOperations(Address thisAddress, Semaphore s, AtomicBoolean ok,
                                            ExecutionCallback callback) {

        int ownedCount = 0;
        ILogger responseLogger = node.getLogger(SyncReplicaVersion.class);
        OperationResponseHandler responseHandler =
                createErrorLoggingResponseHandler(responseLogger);

        for (InternalPartitionImpl partition : partitions) {
            Address owner = partition.getOwnerOrNull();
            if (thisAddress.equals(owner)) {
                for (int i = 1; i <= getMaxBackupCount(); i++) {
                    if (partition.getReplicaAddress(i) != null) {
                        SyncReplicaVersion op = new SyncReplicaVersion(i, callback);
                        op.setService(this);
                        op.setNodeEngine(nodeEngine);
                        op.setOperationResponseHandler(responseHandler);
                        op.setPartitionId(partition.getPartitionId());
                        nodeEngine.getOperationService().executeOperation(op);
                    } else {
                        ok.set(false);
                        s.release();
                    }
                }
                ownedCount++;
            } else if (owner == null) {
                ok.set(false);
            }
        }
        return ownedCount;
    }

    private boolean shouldWaitMigrationOrBackups(Level level) {
        if (!preCheckShouldWaitMigrationOrBackups()) {
            return false;
        }

        if (checkForActiveMigrations(level)) {
            return true;
        }

        for (InternalPartitionImpl partition : partitions) {
            if (partition.getReplicaAddress(1) == null) {
                if (logger.isLoggable(level)) {
                    logger.log(level, "Should take backup of partitionId=" + partition.getPartitionId());
                }
                return true;
            }
        }
        int replicaSyncProcesses = maxParallelReplications - replicaSyncProcessLock.availablePermits();
        if (replicaSyncProcesses > 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Processing replica sync requests: " + replicaSyncProcesses);
            }
            return true;
        }
        return false;
    }

    private boolean preCheckShouldWaitMigrationOrBackups() {
        if (!initialized) {
            return false;
        }

        if (getMemberGroupsSize() < 2) {
            return false;
        }

        return true;
    }

    private boolean checkForActiveMigrations(Level level) {
        final int activeSize = activeMigrations.size();
        if (activeSize != 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Waiting for active migration tasks: " + activeSize);
            }
            return true;
        }

        int queueSize = migrationQueue.size();
        if (queueSize != 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Waiting for cluster migration tasks: " + queueSize);
            }
            return true;
        }
        return false;
    }

    @Override
    public final int getPartitionId(Data key) {
        int hash = key.getPartitionHash();
        if (hash == Integer.MIN_VALUE) {
            return 0;
        } else {
            return Math.abs(hash) % partitionCount;
        }
    }

    @Override
    public final int getPartitionId(Object key) {
        return getPartitionId(nodeEngine.toData(key));
    }

    @Override
    public final int getPartitionCount() {
        return partitionCount;
    }

    public long getPartitionMigrationTimeout() {
        return partitionMigrationTimeout;
    }

    
    
    @Override
    public long[] incrementPartitionReplicaVersions(int partitionId, int backupCount) {
        PartitionReplicaVersions replicaVersion = replicaVersions[partitionId];
        return replicaVersion.incrementAndGet(backupCount);
    }

    
    @Override
    public void updatePartitionReplicaVersions(int partitionId, long[] versions, int replicaIndex) {
        PartitionReplicaVersions partitionVersion = replicaVersions[partitionId];
        if (!partitionVersion.update(versions, replicaIndex)) {
            
            triggerPartitionReplicaSync(partitionId, replicaIndex, 0L);
        }
    }

    
    
    @Override
    public long[] getPartitionReplicaVersions(int partitionId) {
        return replicaVersions[partitionId].get();
    }

    
    @Override
    public void setPartitionReplicaVersions(int partitionId, long[] versions, int replicaOffset) {
        replicaVersions[partitionId].set(versions, replicaOffset);
    }

    @Override
    public void clearPartitionReplicaVersions(int partitionId) {
        replicaVersions[partitionId].clear();
    }

    
    void finalizeReplicaSync(int partitionId, int replicaIndex, long[] versions) {
        PartitionReplicaVersions replicaVersion = replicaVersions[partitionId];
        replicaVersion.clear();
        replicaVersion.set(versions, replicaIndex);
        clearReplicaSyncRequest(partitionId, replicaIndex);
    }

    
    void clearReplicaSyncRequest(int partitionId, int replicaIndex) {
        ReplicaSyncInfo syncInfo = new ReplicaSyncInfo(partitionId, replicaIndex, null);
        ReplicaSyncInfo currentSyncInfo = replicaSyncRequests.get(partitionId);

        replicaSyncScheduler.cancelIfExists(partitionId, syncInfo);

        if (syncInfo.equals(currentSyncInfo)
                && replicaSyncRequests.compareAndSet(partitionId, currentSyncInfo, null)) {

            releaseReplicaSyncPermit();
        } else if (currentSyncInfo != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("Not able to cancel sync! " + syncInfo + " VS Current " + currentSyncInfo);
            }
        }
    }

    boolean tryToAcquireReplicaSyncPermit() {
        return replicaSyncProcessLock.tryAcquire();
    }

    void releaseReplicaSyncPermit() {
        replicaSyncProcessLock.release();
    }

    @Override
    public Map<Address, List<Integer>> getMemberPartitionsMap() {
        final int members = node.getClusterService().getSize();
        Map<Address, List<Integer>> memberPartitions = new HashMap<Address, List<Integer>>(members);
        for (int i = 0; i < partitionCount; i++) {
            Address owner;
            while ((owner = getPartitionOwner(i)) == null) {
                try {
                    Thread.sleep(PARTITION_OWNERSHIP_WAIT_MILLIS);
                } catch (InterruptedException e) {
                    throw new HazelcastException(e);
                }
            }
            List<Integer> ownedPartitions = memberPartitions.get(owner);
            if (ownedPartitions == null) {
                ownedPartitions = new ArrayList<Integer>();
                memberPartitions.put(owner, ownedPartitions);
            }
            ownedPartitions.add(i);
        }
        return memberPartitions;
    }

    @Override
    public List<Integer> getMemberPartitions(Address target) {
        List<Integer> ownedPartitions = new LinkedList<Integer>();
        for (int i = 0; i < partitionCount; i++) {
            final Address owner = getPartitionOwner(i);
            if (target.equals(owner)) {
                ownedPartitions.add(i);
            }
        }
        return ownedPartitions;
    }

    @Override
    public void reset() {
        migrationQueue.clear();
        for (int k = 0; k < replicaSyncRequests.length(); k++) {
            replicaSyncRequests.set(k, null);
        }
        replicaSyncScheduler.cancelAll();
        
        
        replicaSyncProcessLock.drainPermits();
        replicaSyncProcessLock.release(maxParallelReplications);

        lock.lock();
        try {
            initialized = false;
            for (InternalPartitionImpl partition : partitions) {
                partition.reset();
            }
            activeMigrations.clear();
            completedMigrations.clear();
            stateVersion.set(0);
        } finally {
            lock.unlock();
        }
    }

    public void pauseMigration() {
        migrationActive.set(false);
    }

    public void resumeMigration() {
        migrationActive.set(true);
    }

    public boolean isMigrationActive() {
        return migrationActive.get();
    }

    @Override
    public void shutdown(boolean terminate) {
        logger.finest("Shutting down the partition service");
        migrationThread.stopNow();
        reset();
    }

    public long getMigrationQueueSize() {
        return migrationQueue.size();
    }

    public PartitionServiceProxy getPartitionServiceProxy() {
        return proxy;
    }

    private void sendMigrationEvent(final MigrationInfo migrationInfo, final MigrationStatus status) {
        MemberImpl current = getMember(migrationInfo.getSource());
        MemberImpl newOwner = getMember(migrationInfo.getDestination());
        MigrationEvent event = new MigrationEvent(migrationInfo.getPartitionId(), current, newOwner, status);
        EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, MIGRATION_EVENT_TOPIC);
        eventService.publishEvent(SERVICE_NAME, registrations, event, event.getPartitionId());
    }

    @Override
    public String addMigrationListener(MigrationListener listener) {
        if (listener == null) {
            throw new NullPointerException("listener can't be null");
        }

        final MigrationListenerAdapter adapter = new MigrationListenerAdapter(listener);

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration = eventService.registerListener(SERVICE_NAME, MIGRATION_EVENT_TOPIC, adapter);
        return registration.getId();
    }

    @Override
    public boolean removeMigrationListener(String registrationId) {
        if (registrationId == null) {
            throw new NullPointerException("registrationId can't be null");
        }

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, MIGRATION_EVENT_TOPIC, registrationId);
    }

    @Override
    public String addPartitionLostListener(PartitionLostListener listener) {
        if (listener == null) {
            throw new NullPointerException("listener can't be null");
        }

        final PartitionLostListenerAdapter adapter = new PartitionLostListenerAdapter(listener);

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration = eventService.registerListener(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC, adapter);
        return registration.getId();
    }

    @Override
    public boolean removePartitionLostListener(String registrationId) {
        if (registrationId == null) {
            throw new NullPointerException("registrationId can't be null");
        }

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC, registrationId);
    }

    @Override
    public void dispatchEvent(PartitionEvent partitionEvent, PartitionEventListener partitionEventListener) {
        partitionEventListener.onEvent(partitionEvent);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder("PartitionManager[" + stateVersion + "] {\n");
        sb.append("\n");
        sb.append("migrationQ: ").append(migrationQueue.size());
        sb.append("\n}");
        return sb.toString();
    }

    public Node getNode() {
        return node;
    }

    @Override
    public boolean isPartitionOwner(int partitionId) {
        InternalPartitionImpl partition = getPartition(partitionId);
        return node.getThisAddress().equals(partition.getOwnerOrNull());
    }

    @Override
    public int getPartitionStateVersion() {
        return stateVersion.get();
    }

    @Override
    public void onPartitionLost(InternalPartitionLostEvent event) {
        final PartitionLostEvent partitionLostEvent = new PartitionLostEvent(event.getPartitionId(), event.getLostReplicaIndex(),
                event.getEventSource());
        final EventService eventService = nodeEngine.getEventService();
        final Collection<EventRegistration> registrations = eventService
                .getRegistrations(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC);
        eventService.publishEvent(SERVICE_NAME, registrations, partitionLostEvent, event.getPartitionId());
    }

    
    public List<ReplicaSyncInfo> getOngoingReplicaSyncRequests() {
        final int length = replicaSyncRequests.length();
        final List<ReplicaSyncInfo> replicaSyncRequestsList = new ArrayList<ReplicaSyncInfo>(length);
        for (int i = 0; i < length; i++) {
            final ReplicaSyncInfo replicaSyncInfo = replicaSyncRequests.get(i);
            if (replicaSyncInfo != null) {
                replicaSyncRequestsList.add(replicaSyncInfo);
            }
        }

        return replicaSyncRequestsList;
    }

    
    public List<ScheduledEntry<Integer, ReplicaSyncInfo>> getScheduledReplicaSyncRequests() {
        final List<ScheduledEntry<Integer, ReplicaSyncInfo>> entries = new ArrayList<ScheduledEntry<Integer, ReplicaSyncInfo>>();
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            final ScheduledEntry<Integer, ReplicaSyncInfo> entry = replicaSyncScheduler.get(partitionId);
            if (entry != null) {
                entries.add(entry);
            }
        }

        return entries;
    }

    private class SendClusterStateTask implements Runnable {
        @Override
        public void run() {
            if (node.isMaster() && node.isActive()) {
                if (!migrationQueue.isEmpty() && isMigrationActive()) {
                    logger.info("Remaining migration tasks in queue => " + migrationQueue.size());
                }
                publishPartitionRuntimeState();
            }
        }
    }

    private class SyncReplicaVersionTask implements Runnable {
        @Override
        public void run() {
            if (node.isActive() && migrationActive.get()) {
                for (InternalPartitionImpl partition : partitions) {
                    if (partition.isLocal()) {
                        for (int index = 1; index < InternalPartition.MAX_REPLICA_COUNT; index++) {
                            if (partition.getReplicaAddress(index) != null) {
                                SyncReplicaVersion op = new SyncReplicaVersion(index, null);
                                op.setService(InternalPartitionServiceImpl.this);
                                op.setNodeEngine(nodeEngine);
                                op.setOperationResponseHandler(
                                        createErrorLoggingResponseHandler(node.getLogger(SyncReplicaVersion.class)));
                                op.setPartitionId(partition.getPartitionId());
                                nodeEngine.getOperationService().executeOperation(op);
                            }
                        }
                    }
                }
            }
        }
    }

    private class RepartitioningTask implements Runnable {
        @Override
        public void run() {
            if (node.isMaster() && node.isActive()) {
                lock.lock();
                try {
                    if (!initialized) {
                        return;
                    }
                    if (!isMigrationAllowed()) {
                        return;
                    }

                    migrationQueue.clear();
                    PartitionStateGenerator psg = partitionStateGenerator;
                    Collection<MemberImpl> members = node.getClusterService().getMemberList();
                    Collection<MemberGroup> memberGroups = memberGroupFactory.createMemberGroups(members);
                    Address[][] newState = psg.reArrange(memberGroups, partitions);

                    if (!isMigrationAllowed()) {
                        return;
                    }

                    int migrationCount = 0;
                    int lostCount = 0;
                    lastRepartitionTime.set(Clock.currentTimeMillis());
                    for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
                        Address[] replicas = newState[partitionId];
                        InternalPartitionImpl currentPartition = partitions[partitionId];
                        Address currentOwner = currentPartition.getOwnerOrNull();
                        Address newOwner = replicas[0];

                        if (currentOwner == null) {
                            
                            lostCount++;
                            assignNewPartitionOwner(partitionId, replicas, currentPartition, newOwner);
                        } else if (newOwner != null && !currentOwner.equals(newOwner)) {
                            if (logger.isFinestEnabled()) {
                                logger.finest("PartitionToMigrate partitionId=" + partitionId
                                        + " replicas=" + Arrays.toString(replicas) + " currentOwner="
                                        + currentOwner + " newOwner=" + newOwner);
                            }

                            migrationCount++;
                            migratePartitionToNewOwner(partitionId, replicas, currentOwner, newOwner);
                        } else {
                            currentPartition.setReplicaAddresses(replicas);
                        }
                    }
                    syncPartitionRuntimeState(members);
                    logMigrationStatistics(migrationCount, lostCount);
                } finally {
                    lock.unlock();
                }
            }
        }

        private void logMigrationStatistics(int migrationCount, int lostCount) {
            if (lostCount > 0) {
                logger.warning("Assigning new owners for " + lostCount + " LOST partitions!");
            }

            if (migrationCount > 0) {
                logger.info("Re-partitioning cluster data... Migration queue size: " + migrationCount);
            } else {
                logger.info("Partition balance is ok, no need to re-partition cluster data... ");
            }
        }

        private void migratePartitionToNewOwner(int partitionId, Address[] replicas, Address currentOwner, Address newOwner) {
            MigrationInfo info = new MigrationInfo(partitionId, currentOwner, newOwner);
            MigrateTask migrateTask = new MigrateTask(info, replicas);
            boolean offered = migrationQueue.offer(migrateTask);
            if (!offered) {
                logger.severe("Failed to offer: " + migrateTask);
            }
        }

        private void assignNewPartitionOwner(int partitionId, Address[] replicas, InternalPartitionImpl currentPartition,
                                             Address newOwner) {
            currentPartition.setReplicaAddresses(replicas);
            MigrationInfo migrationInfo = new MigrationInfo(partitionId, null, newOwner);
            sendMigrationEvent(migrationInfo, MigrationStatus.STARTED);
            sendMigrationEvent(migrationInfo, MigrationStatus.COMPLETED);
        }

        private boolean isMigrationAllowed() {
            if (isMigrationActive()) {
                return true;
            }
            migrationQueue.add(this);
            return false;
        }
    }

    private class MigrateTask implements Runnable {
        final MigrationInfo migrationInfo;
        final Address[] addresses;

        public MigrateTask(MigrationInfo migrationInfo, Address[] addresses) {
            this.migrationInfo = migrationInfo;
            this.addresses = addresses;
            final MemberImpl masterMember = getMasterMember();
            if (masterMember != null) {
                migrationInfo.setMasterUuid(masterMember.getUuid());
                migrationInfo.setMaster(masterMember.getAddress());
            }
        }

        @Override
        public void run() {
            if (!node.isActive() || !node.isMaster()) {
                return;
            }
            final MigrationRequestOperation migrationRequestOp = new MigrationRequestOperation(migrationInfo);
            try {
                MigrationInfo info = migrationInfo;
                InternalPartitionImpl partition = partitions[info.getPartitionId()];
                Address owner = partition.getOwnerOrNull();
                if (owner == null) {
                    logger.severe("ERROR: partition owner is not set! -> partitionId=" + info.getPartitionId()
                            + " , " + partition + " -VS- " + info);
                    return;
                }
                if (!owner.equals(info.getSource())) {
                    logger.severe("ERROR: partition owner is not the source of migration! -> partitionId="
                            + info.getPartitionId() + " , " + partition + " -VS- " + info + " found owner=" + owner);
                    return;
                }
                sendMigrationEvent(migrationInfo, MigrationStatus.STARTED);
                Boolean result;
                MemberImpl fromMember = getMember(migrationInfo.getSource());
                if (logger.isFinestEnabled()) {
                    logger.finest("Starting Migration: " + migrationInfo);
                }
                if (fromMember == null) {
                    
                    logger.warning("Partition is lost! Assign new owner and exit... partitionId=" + info.getPartitionId());
                    result = Boolean.TRUE;
                } else {
                    result = executeMigrateOperation(migrationRequestOp, fromMember);
                }
                processMigrationResult(result);
            } catch (Throwable t) {
                final Level level = migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Error [" + t.getClass() + ": " + t.getMessage() + "] while executing " + migrationRequestOp);
                logger.finest(t);
                migrationOperationFailed();
            }
        }

        private void processMigrationResult(Boolean result) {
            if (Boolean.TRUE.equals(result)) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Finished Migration: " + migrationInfo);
                }
                migrationOperationSucceeded();
            } else {
                final Level level = migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Migration failed: " + migrationInfo);
                migrationOperationFailed();
            }
        }

        private Boolean executeMigrateOperation(MigrationRequestOperation migrationRequestOp, MemberImpl fromMember) {
            Future future = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, migrationRequestOp,
                    migrationInfo.getSource())
                    .setCallTimeout(partitionMigrationTimeout)
                    .setTryPauseMillis(DEFAULT_PAUSE_MILLIS).invoke();

            try {
                Object response = future.get();
                return (Boolean) nodeEngine.toObject(response);
            } catch (Throwable e) {
                final Level level = node.isActive() && migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Failed migration from " + fromMember + " for " + migrationRequestOp.getMigrationInfo(), e);
            }
            return Boolean.FALSE;
        }

        private void migrationOperationFailed() {
            lock.lock();
            try {
                addCompletedMigration(migrationInfo);
                finalizeActiveMigration(migrationInfo);
                publishPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
            sendMigrationEvent(migrationInfo, MigrationStatus.FAILED);

            
            migrationQueue.add(new RepartitioningTask());
        }

        private void migrationOperationSucceeded() {
            lock.lock();
            try {
                final int partitionId = migrationInfo.getPartitionId();
                InternalPartitionImpl partition = partitions[partitionId];
                partition.setReplicaAddresses(addresses);
                addCompletedMigration(migrationInfo);
                finalizeActiveMigration(migrationInfo);
                syncPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
            sendMigrationEvent(migrationInfo, MigrationStatus.COMPLETED);
        }

        @Override
        public String toString() {
            return getClass().getSimpleName() + "{" + "migrationInfo=" + migrationInfo + '}';
        }
    }

    private class MigrationThread extends Thread implements Runnable {
        private final long sleepTime = Math.max(250L, partitionMigrationInterval);
        private volatile boolean migrating;

        MigrationThread(Node node) {
            super(node.getHazelcastThreadGroup().getInternalThreadGroup(),
                    node.getHazelcastThreadGroup().getThreadNamePrefix("migration"));
        }

        @Override
        public void run() {
            try {
                while (!isInterrupted()) {
                    doRun();
                }
            } catch (InterruptedException e) {
                if (logger.isFinestEnabled()) {
                    logger.finest("MigrationThread is interrupted: " + e.getMessage());
                }
            } catch (OutOfMemoryError e) {
                OutOfMemoryErrorDispatcher.onOutOfMemory(e);
            } finally {
                migrationQueue.clear();
            }
        }

        private void doRun() throws InterruptedException {
            for (; ; ) {
                if (!isMigrationActive()) {
                    break;
                }
                Runnable r = migrationQueue.poll(1, TimeUnit.SECONDS);
                if (r == null) {
                    break;
                }

                processTask(r);
                if (partitionMigrationInterval > 0) {
                    Thread.sleep(partitionMigrationInterval);
                }
            }
            boolean hasNoTasks = migrationQueue.isEmpty();
            if (hasNoTasks) {
                if (migrating) {
                    migrating = false;
                    logger.info("All migration tasks have been completed, queues are empty.");
                }
                evictCompletedMigrations();
                Thread.sleep(sleepTime);
            } else if (!isMigrationActive()) {
                Thread.sleep(sleepTime);
            }
        }

        boolean processTask(Runnable r) {
            if (r == null || isInterrupted()) {
                return false;
            }
            migrating = (r instanceof MigrateTask);
            try {
                r.run();
            } catch (Throwable t) {
                logger.warning(t);
            }
            return true;
        }

        void stopNow() {
            migrationQueue.clear();
            interrupt();
        }

        boolean isMigrating() {
            return migrating;
        }
    }

    private static final class LocalPartitionListener implements PartitionListener {
        final Address thisAddress;
        final InternalPartitionServiceImpl partitionService;

        private LocalPartitionListener(InternalPartitionServiceImpl partitionService, Address thisAddress) {
            this.thisAddress = thisAddress;
            this.partitionService = partitionService;
        }

        @Override
        public void replicaChanged(PartitionReplicaChangeEvent event) {
            final int partitionId = event.getPartitionId();
            final int replicaIndex = event.getReplicaIndex();
            final Address newAddress = event.getNewAddress();
            final Address oldAddress = event.getOldAddress();
            final PartitionReplicaChangeReason reason = event.getReason();

            final boolean initialAssignment = event.getOldAddress() == null;

            if (replicaIndex > 0) {
                
                if (thisAddress.equals(oldAddress)) {
                    clearPartition(partitionId, replicaIndex);
                } else if (thisAddress.equals(newAddress)) {
                    synchronizePartition(partitionId, replicaIndex, reason, initialAssignment);
                }
            } else {
                if (!initialAssignment && thisAddress.equals(newAddress)) {
                    
                    
                    
                    promoteFromBackups(partitionId, reason, oldAddress);
                }
                partitionService.cancelReplicaSync(partitionId);
            }

            Node node = partitionService.node;
            if (replicaIndex == 0 && newAddress == null && node.isActive() && node.joined()) {
                logOwnerOfPartitionIsRemoved(event);
            }
            if (node.isMaster()) {
                partitionService.stateVersion.incrementAndGet();
            }
        }

        private void clearPartition(final int partitionId, final int oldReplicaIndex) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            ClearReplicaOperation op = new ClearReplicaOperation(oldReplicaIndex);
            op.setPartitionId(partitionId).setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void synchronizePartition(int partitionId, int replicaIndex,
                                          PartitionReplicaChangeReason reason, boolean initialAssignment) {
            
            if (partitionService.initialized) {
                long delayMillis = 0L;
                if (replicaIndex > 1) {
                    
                    
                    
                    delayMillis = (long) (REPLICA_SYNC_RETRY_DELAY + (Math.random() * DEFAULT_REPLICA_SYNC_DELAY));
                }

                resetReplicaVersion(partitionId, replicaIndex, reason, initialAssignment);
                partitionService.triggerPartitionReplicaSync(partitionId, replicaIndex, delayMillis);
            }
        }

        private void resetReplicaVersion(int partitionId, int replicaIndex,
                                         PartitionReplicaChangeReason reason, boolean initialAssignment) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            ResetReplicaVersionOperation op = new ResetReplicaVersionOperation(reason, initialAssignment);
            op.setPartitionId(partitionId).setReplicaIndex(replicaIndex)
                    .setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void promoteFromBackups(int partitionId, PartitionReplicaChangeReason reason, Address oldAddress) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            PromoteFromBackupOperation op = new PromoteFromBackupOperation(reason, oldAddress);
            op.setPartitionId(partitionId).setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void logOwnerOfPartitionIsRemoved(PartitionReplicaChangeEvent event) {
            String warning = "Owner of partition is being removed! "
                    + "Possible data loss for partitionId=" + event.getPartitionId() + " , " + event;
            partitionService.logger.warning(warning);
        }
    }

    private static class ReplicaSyncEntryProcessor implements ScheduledEntryProcessor<Integer, ReplicaSyncInfo> {

        final InternalPartitionServiceImpl partitionService;

        ReplicaSyncEntryProcessor(InternalPartitionServiceImpl partitionService) {
            this.partitionService = partitionService;
        }

        @Override
        public void process(EntryTaskScheduler<Integer, ReplicaSyncInfo> scheduler,
                            Collection<ScheduledEntry<Integer, ReplicaSyncInfo>> entries) {

            for (ScheduledEntry<Integer, ReplicaSyncInfo> entry : entries) {
                ReplicaSyncInfo syncInfo = entry.getValue();
                int partitionId = syncInfo.partitionId;
                if (partitionService.replicaSyncRequests.compareAndSet(partitionId, syncInfo, null)) {
                    partitionService.releaseReplicaSyncPermit();
                }

                InternalPartitionImpl partition = partitionService.getPartitionImpl(partitionId);
                int currentReplicaIndex = partition.getReplicaIndex(partitionService.node.getThisAddress());
                if (currentReplicaIndex > 0) {
                    partitionService.triggerPartitionReplicaSync(partitionId, currentReplicaIndex, 0L);
                }
            }
        }
    }
}

<code block>


package com.hazelcast.instance;

import com.hazelcast.config.Config;
import com.hazelcast.core.IMap;
import com.hazelcast.internal.monitors.HealthMonitorLevel;
import com.hazelcast.map.QueryResultSizeExceededException;
import com.hazelcast.map.impl.QueryResultSizeLimiter;
import com.hazelcast.query.TruePredicate;


public class GroupProperties {

    
    public static final String PROP_APPLICATION_VALIDATION_TOKEN = "hazelcast.application.validation.token";

    public static final String PROP_HEALTH_MONITORING_LEVEL = "hazelcast.health.monitoring.level";
    public static final String PROP_HEALTH_MONITORING_DELAY_SECONDS = "hazelcast.health.monitoring.delay.seconds";

    
    public static final String PROP_PERFORMANCE_MONITOR_ENABLED = "hazelcast.performance.monitoring.enabled";

    
    public static final String PROP_PERFORMANCE_MONITOR_DELAY_SECONDS
            = "hazelcast.performance.monitor.delay.seconds";

    
    public static final String PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE_MB
            = "hazelcast.performance.monitor.max.rolled.file.size.mb";

    
    public static final String PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT
            = "hazelcast.performance.monitor.max.rolled.file.count";

    
    public static final String PROP_PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT
            = "hazelcast.performance.monitor.human.friendly.format";

    public static final String PROP_VERSION_CHECK_ENABLED = "hazelcast.version.check.enabled";
    public static final String PROP_PREFER_IPv4_STACK = "hazelcast.prefer.ipv4.stack";
    public static final String PROP_IO_THREAD_COUNT = "hazelcast.io.thread.count";

    
    public static final String PROP_IO_BALANCER_INTERVAL_SECONDS = "hazelcast.io.balancer.interval.seconds";
    
    public static final String PROP_PARTITION_OPERATION_THREAD_COUNT = "hazelcast.operation.thread.count";
    public static final String PROP_GENERIC_OPERATION_THREAD_COUNT = "hazelcast.operation.generic.thread.count";
    public static final String PROP_EVENT_THREAD_COUNT = "hazelcast.event.thread.count";
    public static final String PROP_EVENT_QUEUE_CAPACITY = "hazelcast.event.queue.capacity";
    public static final String PROP_EVENT_QUEUE_TIMEOUT_MILLIS = "hazelcast.event.queue.timeout.millis";
    public static final String PROP_CONNECT_ALL_WAIT_SECONDS = "hazelcast.connect.all.wait.seconds";
    public static final String PROP_MEMCACHE_ENABLED = "hazelcast.memcache.enabled";
    public static final String PROP_REST_ENABLED = "hazelcast.rest.enabled";
    public static final String PROP_MAP_LOAD_CHUNK_SIZE = "hazelcast.map.load.chunk.size";
    public static final String PROP_MERGE_FIRST_RUN_DELAY_SECONDS = "hazelcast.merge.first.run.delay.seconds";
    public static final String PROP_MERGE_NEXT_RUN_DELAY_SECONDS = "hazelcast.merge.next.run.delay.seconds";
    public static final String PROP_OPERATION_CALL_TIMEOUT_MILLIS = "hazelcast.operation.call.timeout.millis";

    
    public static final String PROP_OPERATION_BACKUP_TIMEOUT_MILLIS = "hazelcast.operation.backup.timeout.millis";

    public static final String PROP_SOCKET_BIND_ANY = "hazelcast.socket.bind.any";
    public static final String PROP_SOCKET_SERVER_BIND_ANY = "hazelcast.socket.server.bind.any";
    public static final String PROP_SOCKET_CLIENT_BIND_ANY = "hazelcast.socket.client.bind.any";
    public static final String PROP_SOCKET_CLIENT_BIND = "hazelcast.socket.client.bind";
    
    public static final String PROP_CLIENT_ENGINE_THREAD_COUNT = "hazelcast.clientengine.thread.count";
    public static final String PROP_SOCKET_RECEIVE_BUFFER_SIZE = "hazelcast.socket.receive.buffer.size";
    public static final String PROP_SOCKET_SEND_BUFFER_SIZE = "hazelcast.socket.send.buffer.size";
    public static final String PROP_SOCKET_LINGER_SECONDS = "hazelcast.socket.linger.seconds";
    public static final String PROP_SOCKET_CONNECT_TIMEOUT_SECONDS = "hazelcast.socket.connect.timeout.seconds";
    public static final String PROP_SOCKET_KEEP_ALIVE = "hazelcast.socket.keep.alive";
    public static final String PROP_SOCKET_NO_DELAY = "hazelcast.socket.no.delay";
    public static final String PROP_SHUTDOWNHOOK_ENABLED = "hazelcast.shutdownhook.enabled";
    public static final String PROP_WAIT_SECONDS_BEFORE_JOIN = "hazelcast.wait.seconds.before.join";
    public static final String PROP_MAX_WAIT_SECONDS_BEFORE_JOIN = "hazelcast.max.wait.seconds.before.join";
    public static final String PROP_MAX_JOIN_SECONDS = "hazelcast.max.join.seconds";
    public static final String PROP_MAX_JOIN_MERGE_TARGET_SECONDS = "hazelcast.max.join.merge.target.seconds";
    public static final String PROP_HEARTBEAT_INTERVAL_SECONDS = "hazelcast.heartbeat.interval.seconds";
    public static final String PROP_MAX_NO_HEARTBEAT_SECONDS = "hazelcast.max.no.heartbeat.seconds";
    public static final String PROP_MAX_NO_MASTER_CONFIRMATION_SECONDS = "hazelcast.max.no.master.confirmation.seconds";
    public static final String PROP_MASTER_CONFIRMATION_INTERVAL_SECONDS
            = "hazelcast.master.confirmation.interval.seconds";
    public static final String PROP_MEMBER_LIST_PUBLISH_INTERVAL_SECONDS
            = "hazelcast.member.list.publish.interval.seconds";
    public static final String PROP_ICMP_ENABLED = "hazelcast.icmp.enabled";
    public static final String PROP_ICMP_TIMEOUT = "hazelcast.icmp.timeout";
    public static final String PROP_ICMP_TTL = "hazelcast.icmp.ttl";
    public static final String PROP_INITIAL_MIN_CLUSTER_SIZE = "hazelcast.initial.min.cluster.size";
    public static final String PROP_INITIAL_WAIT_SECONDS = "hazelcast.initial.wait.seconds";

    
    public static final String PROP_TCP_JOIN_PORT_TRY_COUNT = "hazelcast.tcp.join.port.try.count";
    public static final String PROP_MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS
            = "hazelcast.map.replica.scheduled.task.delay.seconds";
    
    public static final String PROP_MAP_EXPIRY_DELAY_SECONDS = "hazelcast.map.expiry.delay.seconds";
    public static final String PROP_PARTITION_COUNT = "hazelcast.partition.count";
    public static final String PROP_LOGGING_TYPE = "hazelcast.logging.type";
    public static final String PROP_ENABLE_JMX = "hazelcast.jmx";
    public static final String PROP_ENABLE_JMX_DETAILED = "hazelcast.jmx.detailed";
    public static final String PROP_MC_MAX_VISIBLE_INSTANCE_COUNT = "hazelcast.mc.max.visible.instance.count";
    public static final String PROP_MC_MAX_VISIBLE_SLOW_OPERATION_COUNT = "hazelcast.mc.max.visible.slow.operations.count";
    public static final String PROP_MC_URL_CHANGE_ENABLED = "hazelcast.mc.url.change.enabled";
    public static final String PROP_CONNECTION_MONITOR_INTERVAL = "hazelcast.connection.monitor.interval";
    public static final String PROP_CONNECTION_MONITOR_MAX_FAULTS = "hazelcast.connection.monitor.max.faults";
    public static final String PROP_PARTITION_MIGRATION_INTERVAL = "hazelcast.partition.migration.interval";
    public static final String PROP_PARTITION_MIGRATION_TIMEOUT = "hazelcast.partition.migration.timeout";
    public static final String PROP_PARTITION_MIGRATION_ZIP_ENABLED = "hazelcast.partition.migration.zip.enabled";
    public static final String PROP_PARTITION_TABLE_SEND_INTERVAL = "hazelcast.partition.table.send.interval";
    public static final String PROP_PARTITION_BACKUP_SYNC_INTERVAL = "hazelcast.partition.backup.sync.interval";
    public static final String PROP_PARTITION_MAX_PARALLEL_REPLICATIONS
            = "hazelcast.partition.max.parallel.replications";
    public static final String PROP_PARTITIONING_STRATEGY_CLASS = "hazelcast.partitioning.strategy.class";
    public static final String PROP_GRACEFUL_SHUTDOWN_MAX_WAIT = "hazelcast.graceful.shutdown.max.wait";
    public static final String PROP_SYSTEM_LOG_ENABLED = "hazelcast.system.log.enabled";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_ENABLED = "hazelcast.slow.operation.detector.enabled";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS
            = "hazelcast.slow.operation.detector.threshold.millis";


    
    public static final String PROP_SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS
            = "hazelcast.slow.invocation.detector.threshold.millis";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS
            = "hazelcast.slow.operation.detector.log.retention.seconds";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS
            = "hazelcast.slow.operation.detector.log.purge.interval.seconds";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED
            = "hazelcast.slow.operation.detector.stacktrace.logging.enabled";

    
    public static final String PROP_ELASTIC_MEMORY_ENABLED = "hazelcast.elastic.memory.enabled";
    public static final String PROP_ELASTIC_MEMORY_TOTAL_SIZE = "hazelcast.elastic.memory.total.size";
    public static final String PROP_ELASTIC_MEMORY_CHUNK_SIZE = "hazelcast.elastic.memory.chunk.size";
    public static final String PROP_ELASTIC_MEMORY_SHARED_STORAGE = "hazelcast.elastic.memory.shared.storage";
    public static final String PROP_ELASTIC_MEMORY_UNSAFE_ENABLED = "hazelcast.elastic.memory.unsafe.enabled";
    public static final String PROP_ENTERPRISE_LICENSE_KEY = "hazelcast.enterprise.license.key";
    public static final String PROP_MAP_WRITE_BEHIND_QUEUE_CAPACITY = "hazelcast.map.write.behind.queue.capacity";

    
    public static final String PROP_ENTERPRISE_WAN_REP_QUEUE_CAPACITY = "hazelcast.enterprise.wanrep.queue.capacity";

    
    public static final String PROP_ENTERPRISE_WAN_REP_BATCH_SIZE = "hazelcast.enterprise.wanrep.batch.size";

    
    public static final String PROP_ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS
            = "hazelcast.enterprise.wanrep.batchfrequency.seconds";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED
            = "hazelcast.cache.invalidation.batch.enabled";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_SIZE
            = "hazelcast.cache.invalidation.batch.size";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS
            = "hazelcast.cache.invalidation.batchfrequency.seconds";

    
    public static final String PROP_ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS
            = "hazelcast.enterprise.wanrep.optimeout.millis";

    public static final String PROP_CLIENT_MAX_NO_HEARTBEAT_SECONDS = "hazelcast.client.max.no.heartbeat.seconds";
    public static final String PROP_MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS
            = "hazelcast.migration.min.delay.on.member.removed.seconds";

    
    public static final String PROP_BACKPRESSURE_ENABLED = "hazelcast.backpressure.enabled";

    
    public static final String PROP_BACKPRESSURE_SYNCWINDOW = "hazelcast.backpressure.syncwindow";

    
    public static final String PROP_BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS
            = "hazelcast.backpressure.backoff.timeout.millis";

    
    public static final String PROP_BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION
            = "hazelcast.backpressure.max.concurrent.invocations.per.partition";


    
    public static final String PROP_QUERY_PREDICATE_PARALLEL_EVALUATION = "hazelcast.query.predicate.parallel.evaluation";


    
    public static final String PROP_JCACHE_PROVIDER_TYPE = "hazelcast.jcache.provider.type";

    
    public static final String PROP_QUERY_RESULT_SIZE_LIMIT = "hazelcast.query.result.size.limit";

    
    public static final String PROP_QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK
            = "hazelcast.query.max.local.partition.limit.for.precheck";

    public final GroupProperty CLIENT_ENGINE_THREAD_COUNT;

    public final GroupProperty PARTITION_OPERATION_THREAD_COUNT;

    public final GroupProperty GENERIC_OPERATION_THREAD_COUNT;

    public final GroupProperty EVENT_THREAD_COUNT;

    public final GroupProperty HEALTH_MONITORING_LEVEL;

    public final GroupProperty HEALTH_MONITORING_DELAY_SECONDS;

    public final GroupProperty PERFORMANCE_MONITOR_ENABLED;

    public final GroupProperty PERFORMANCE_MONITOR_DELAY_SECONDS;

    public final GroupProperty PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE;

    public final GroupProperty PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT;

    public final GroupProperty PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT;

    public final GroupProperty IO_THREAD_COUNT;

    public final GroupProperty IO_BALANCER_INTERVAL_SECONDS;

    public final GroupProperty EVENT_QUEUE_CAPACITY;

    public final GroupProperty EVENT_QUEUE_TIMEOUT_MILLIS;

    public final GroupProperty PREFER_IPv4_STACK;

    public final GroupProperty CONNECT_ALL_WAIT_SECONDS;

    public final GroupProperty VERSION_CHECK_ENABLED;

    public final GroupProperty MEMCACHE_ENABLED;

    public final GroupProperty REST_ENABLED;

    public final GroupProperty MAP_LOAD_CHUNK_SIZE;

    public final GroupProperty MERGE_FIRST_RUN_DELAY_SECONDS;

    public final GroupProperty MERGE_NEXT_RUN_DELAY_SECONDS;

    public final GroupProperty OPERATION_CALL_TIMEOUT_MILLIS;

    public final GroupProperty OPERATION_BACKUP_TIMEOUT_MILLIS;

    public final GroupProperty SOCKET_SERVER_BIND_ANY;

    public final GroupProperty SOCKET_CLIENT_BIND_ANY;

    public final GroupProperty SOCKET_CLIENT_BIND;

    
    public final GroupProperty SOCKET_RECEIVE_BUFFER_SIZE;

    
    public final GroupProperty SOCKET_SEND_BUFFER_SIZE;

    public final GroupProperty SOCKET_LINGER_SECONDS;

    public final GroupProperty SOCKET_CONNECT_TIMEOUT_SECONDS;

    public final GroupProperty SOCKET_KEEP_ALIVE;

    public final GroupProperty SOCKET_NO_DELAY;

    public final GroupProperty SHUTDOWNHOOK_ENABLED;

    public final GroupProperty WAIT_SECONDS_BEFORE_JOIN;

    public final GroupProperty MAX_WAIT_SECONDS_BEFORE_JOIN;

    public final GroupProperty MAX_JOIN_SECONDS;

    public final GroupProperty MAX_JOIN_MERGE_TARGET_SECONDS;

    public final GroupProperty MAX_NO_HEARTBEAT_SECONDS;

    public final GroupProperty HEARTBEAT_INTERVAL_SECONDS;

    public final GroupProperty MASTER_CONFIRMATION_INTERVAL_SECONDS;

    public final GroupProperty MAX_NO_MASTER_CONFIRMATION_SECONDS;

    public final GroupProperty MEMBER_LIST_PUBLISH_INTERVAL_SECONDS;

    public final GroupProperty ICMP_ENABLED;

    public final GroupProperty ICMP_TIMEOUT;

    public final GroupProperty ICMP_TTL;

    public final GroupProperty INITIAL_WAIT_SECONDS;

    public final GroupProperty INITIAL_MIN_CLUSTER_SIZE;

    public final GroupProperty TCP_JOIN_PORT_TRY_COUNT;

    public final GroupProperty MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS;

    public final GroupProperty MAP_EXPIRY_DELAY_SECONDS;

    public final GroupProperty PARTITION_COUNT;

    public final GroupProperty LOGGING_TYPE;

    public final GroupProperty ENABLE_JMX;

    public final GroupProperty ENABLE_JMX_DETAILED;

    public final GroupProperty MC_MAX_INSTANCE_COUNT;

    public final GroupProperty MC_MAX_SLOW_OPERATION_COUNT;

    public final GroupProperty MC_URL_CHANGE_ENABLED;

    public final GroupProperty CONNECTION_MONITOR_INTERVAL;

    public final GroupProperty CONNECTION_MONITOR_MAX_FAULTS;

    public final GroupProperty PARTITION_MIGRATION_INTERVAL;

    public final GroupProperty PARTITION_MIGRATION_TIMEOUT;

    public final GroupProperty PARTITION_MIGRATION_ZIP_ENABLED;

    public final GroupProperty PARTITION_TABLE_SEND_INTERVAL;

    public final GroupProperty PARTITION_BACKUP_SYNC_INTERVAL;

    public final GroupProperty PARTITION_MAX_PARALLEL_REPLICATIONS;

    public final GroupProperty PARTITIONING_STRATEGY_CLASS;

    public final GroupProperty GRACEFUL_SHUTDOWN_MAX_WAIT;

    public final GroupProperty SYSTEM_LOG_ENABLED;

    public final GroupProperty SLOW_OPERATION_DETECTOR_ENABLED;
    public final GroupProperty SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED;

    public final GroupProperty SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS;

    public final GroupProperty ELASTIC_MEMORY_ENABLED;

    public final GroupProperty ELASTIC_MEMORY_TOTAL_SIZE;

    public final GroupProperty ELASTIC_MEMORY_CHUNK_SIZE;

    public final GroupProperty ELASTIC_MEMORY_SHARED_STORAGE;

    public final GroupProperty ELASTIC_MEMORY_UNSAFE_ENABLED;

    public final GroupProperty ENTERPRISE_LICENSE_KEY;

    
    public final GroupProperty MAP_WRITE_BEHIND_QUEUE_CAPACITY;

    public final GroupProperty ENTERPRISE_WAN_REP_QUEUE_CAPACITY;
    public final GroupProperty ENTERPRISE_WAN_REP_BATCH_SIZE;
    public final GroupProperty ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS;
    public final GroupProperty ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS;

    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED;
    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_SIZE;
    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS;

    public final GroupProperty CLIENT_HEARTBEAT_TIMEOUT_SECONDS;

    public final GroupProperty MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS;

    public final GroupProperty BACKPRESSURE_ENABLED;
    public final GroupProperty BACKPRESSURE_SYNCWINDOW;
    public final GroupProperty BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS;
    public final GroupProperty BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION;

    public final GroupProperty QUERY_RESULT_SIZE_LIMIT;
    public final GroupProperty QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK;

    public final GroupProperty QUERY_PREDICATE_PARALLEL_EVALUATION;

    public GroupProperties(Config config) {
        HEALTH_MONITORING_LEVEL
                = new GroupProperty(config, PROP_HEALTH_MONITORING_LEVEL, HealthMonitorLevel.SILENT.toString());
        HEALTH_MONITORING_DELAY_SECONDS
                = new GroupProperty(config, PROP_HEALTH_MONITORING_DELAY_SECONDS, "30");

        PERFORMANCE_MONITOR_ENABLED
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_ENABLED, "false");
        PERFORMANCE_MONITOR_DELAY_SECONDS
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_DELAY_SECONDS, "30");
        PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE_MB, "10");
        PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT, "10");
        PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT
                = new GroupProperty(config, PROP_PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT, "true");

        VERSION_CHECK_ENABLED = new GroupProperty(config, PROP_VERSION_CHECK_ENABLED, "true");
        PREFER_IPv4_STACK = new GroupProperty(config, PROP_PREFER_IPv4_STACK, "true");
        IO_THREAD_COUNT = new GroupProperty(config, PROP_IO_THREAD_COUNT, "3");
        IO_BALANCER_INTERVAL_SECONDS = new GroupProperty(config, PROP_IO_BALANCER_INTERVAL_SECONDS, "20");

        
        PARTITION_OPERATION_THREAD_COUNT = new GroupProperty(config, PROP_PARTITION_OPERATION_THREAD_COUNT, "-1");
        GENERIC_OPERATION_THREAD_COUNT = new GroupProperty(config, PROP_GENERIC_OPERATION_THREAD_COUNT, "-1");
        EVENT_THREAD_COUNT = new GroupProperty(config, PROP_EVENT_THREAD_COUNT, "5");
        EVENT_QUEUE_CAPACITY = new GroupProperty(config, PROP_EVENT_QUEUE_CAPACITY, "1000000");
        EVENT_QUEUE_TIMEOUT_MILLIS = new GroupProperty(config, PROP_EVENT_QUEUE_TIMEOUT_MILLIS, "250");
        CLIENT_ENGINE_THREAD_COUNT = new GroupProperty(config, PROP_CLIENT_ENGINE_THREAD_COUNT, "-1");

        CONNECT_ALL_WAIT_SECONDS = new GroupProperty(config, PROP_CONNECT_ALL_WAIT_SECONDS, "120");
        MEMCACHE_ENABLED = new GroupProperty(config, PROP_MEMCACHE_ENABLED, "true");
        REST_ENABLED = new GroupProperty(config, PROP_REST_ENABLED, "true");
        MAP_LOAD_CHUNK_SIZE = new GroupProperty(config, PROP_MAP_LOAD_CHUNK_SIZE, "1000");
        MERGE_FIRST_RUN_DELAY_SECONDS = new GroupProperty(config, PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "300");
        MERGE_NEXT_RUN_DELAY_SECONDS = new GroupProperty(config, PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "120");
        OPERATION_CALL_TIMEOUT_MILLIS = new GroupProperty(config, PROP_OPERATION_CALL_TIMEOUT_MILLIS, "60000");
        OPERATION_BACKUP_TIMEOUT_MILLIS = new GroupProperty(config, PROP_OPERATION_BACKUP_TIMEOUT_MILLIS, "5000");

        final GroupProperty SOCKET_BIND_ANY = new GroupProperty(config, PROP_SOCKET_BIND_ANY, "true");
        SOCKET_SERVER_BIND_ANY = new GroupProperty(config, PROP_SOCKET_SERVER_BIND_ANY, SOCKET_BIND_ANY);
        SOCKET_CLIENT_BIND_ANY = new GroupProperty(config, PROP_SOCKET_CLIENT_BIND_ANY, SOCKET_BIND_ANY);
        SOCKET_CLIENT_BIND = new GroupProperty(config, PROP_SOCKET_CLIENT_BIND, "true");
        SOCKET_RECEIVE_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_RECEIVE_BUFFER_SIZE, "32");
        SOCKET_SEND_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_SEND_BUFFER_SIZE, "32");
        SOCKET_LINGER_SECONDS = new GroupProperty(config, PROP_SOCKET_LINGER_SECONDS, "0");
        SOCKET_CONNECT_TIMEOUT_SECONDS = new GroupProperty(config, PROP_SOCKET_CONNECT_TIMEOUT_SECONDS, "0");
        SOCKET_KEEP_ALIVE = new GroupProperty(config, PROP_SOCKET_KEEP_ALIVE, "true");
        SOCKET_NO_DELAY = new GroupProperty(config, PROP_SOCKET_NO_DELAY, "true");
        SHUTDOWNHOOK_ENABLED = new GroupProperty(config, PROP_SHUTDOWNHOOK_ENABLED, "true");
        WAIT_SECONDS_BEFORE_JOIN = new GroupProperty(config, PROP_WAIT_SECONDS_BEFORE_JOIN, "5");
        MAX_WAIT_SECONDS_BEFORE_JOIN = new GroupProperty(config, PROP_MAX_WAIT_SECONDS_BEFORE_JOIN, "20");
        MAX_JOIN_SECONDS = new GroupProperty(config, PROP_MAX_JOIN_SECONDS, "300");
        MAX_JOIN_MERGE_TARGET_SECONDS = new GroupProperty(config, PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "20");
        HEARTBEAT_INTERVAL_SECONDS = new GroupProperty(config, PROP_HEARTBEAT_INTERVAL_SECONDS, "1");
        MAX_NO_HEARTBEAT_SECONDS = new GroupProperty(config, PROP_MAX_NO_HEARTBEAT_SECONDS, "300");
        MASTER_CONFIRMATION_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_MASTER_CONFIRMATION_INTERVAL_SECONDS, "30");
        MAX_NO_MASTER_CONFIRMATION_SECONDS = new GroupProperty(config, PROP_MAX_NO_MASTER_CONFIRMATION_SECONDS, "500");
        MEMBER_LIST_PUBLISH_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_MEMBER_LIST_PUBLISH_INTERVAL_SECONDS, "300");
        ICMP_ENABLED = new GroupProperty(config, PROP_ICMP_ENABLED, "false");
        ICMP_TIMEOUT = new GroupProperty(config, PROP_ICMP_TIMEOUT, "1000");
        ICMP_TTL = new GroupProperty(config, PROP_ICMP_TTL, "0");
        INITIAL_MIN_CLUSTER_SIZE = new GroupProperty(config, PROP_INITIAL_MIN_CLUSTER_SIZE, "0");
        INITIAL_WAIT_SECONDS = new GroupProperty(config, PROP_INITIAL_WAIT_SECONDS, "0");
        TCP_JOIN_PORT_TRY_COUNT = new GroupProperty(config, PROP_TCP_JOIN_PORT_TRY_COUNT, "3");
        MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS
                = new GroupProperty(config, PROP_MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS, "10");
        MAP_EXPIRY_DELAY_SECONDS = new GroupProperty(config, PROP_MAP_EXPIRY_DELAY_SECONDS, "10");
        PARTITION_COUNT = new GroupProperty(config, PROP_PARTITION_COUNT, "271");
        LOGGING_TYPE = new GroupProperty(config, PROP_LOGGING_TYPE, "jdk");
        ENABLE_JMX = new GroupProperty(config, PROP_ENABLE_JMX, "false");
        ENABLE_JMX_DETAILED = new GroupProperty(config, PROP_ENABLE_JMX_DETAILED, "false");
        MC_MAX_INSTANCE_COUNT = new GroupProperty(config, PROP_MC_MAX_VISIBLE_INSTANCE_COUNT, "100");
        MC_MAX_SLOW_OPERATION_COUNT = new GroupProperty(config, PROP_MC_MAX_VISIBLE_SLOW_OPERATION_COUNT, "10");
        MC_URL_CHANGE_ENABLED = new GroupProperty(config, PROP_MC_URL_CHANGE_ENABLED, "true");
        CONNECTION_MONITOR_INTERVAL = new GroupProperty(config, PROP_CONNECTION_MONITOR_INTERVAL, "100");
        CONNECTION_MONITOR_MAX_FAULTS = new GroupProperty(config, PROP_CONNECTION_MONITOR_MAX_FAULTS, "3");
        PARTITION_MIGRATION_INTERVAL = new GroupProperty(config, PROP_PARTITION_MIGRATION_INTERVAL, "0");
        PARTITION_MIGRATION_TIMEOUT = new GroupProperty(config, PROP_PARTITION_MIGRATION_TIMEOUT, "300");
        PARTITION_MIGRATION_ZIP_ENABLED = new GroupProperty(config, PROP_PARTITION_MIGRATION_ZIP_ENABLED, "true");
        PARTITION_TABLE_SEND_INTERVAL = new GroupProperty(config, PROP_PARTITION_TABLE_SEND_INTERVAL, "15");
        PARTITION_BACKUP_SYNC_INTERVAL = new GroupProperty(config, PROP_PARTITION_BACKUP_SYNC_INTERVAL, "30");
        PARTITION_MAX_PARALLEL_REPLICATIONS = new GroupProperty(config, PROP_PARTITION_MAX_PARALLEL_REPLICATIONS, "5");
        PARTITIONING_STRATEGY_CLASS = new GroupProperty(config, PROP_PARTITIONING_STRATEGY_CLASS, "");
        GRACEFUL_SHUTDOWN_MAX_WAIT = new GroupProperty(config, PROP_GRACEFUL_SHUTDOWN_MAX_WAIT, "600");
        SYSTEM_LOG_ENABLED = new GroupProperty(config, PROP_SYSTEM_LOG_ENABLED, "true");

        SLOW_OPERATION_DETECTOR_ENABLED
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_ENABLED, "true");
        SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS, "10000");
        SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS, "3600");
        SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS, "300");
        SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED, "false");
        SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS
                = new GroupProperty(config, PROP_SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS, "-1");

        ELASTIC_MEMORY_ENABLED = new GroupProperty(config, PROP_ELASTIC_MEMORY_ENABLED, "false");
        ELASTIC_MEMORY_TOTAL_SIZE = new GroupProperty(config, PROP_ELASTIC_MEMORY_TOTAL_SIZE, "128M");
        ELASTIC_MEMORY_CHUNK_SIZE = new GroupProperty(config, PROP_ELASTIC_MEMORY_CHUNK_SIZE, "1K");
        ELASTIC_MEMORY_SHARED_STORAGE = new GroupProperty(config, PROP_ELASTIC_MEMORY_SHARED_STORAGE, "false");
        ELASTIC_MEMORY_UNSAFE_ENABLED = new GroupProperty(config, PROP_ELASTIC_MEMORY_UNSAFE_ENABLED, "false");
        ENTERPRISE_LICENSE_KEY = new GroupProperty(config, PROP_ENTERPRISE_LICENSE_KEY);
        MAP_WRITE_BEHIND_QUEUE_CAPACITY
                = new GroupProperty(config, PROP_MAP_WRITE_BEHIND_QUEUE_CAPACITY, "50000");

        ENTERPRISE_WAN_REP_QUEUE_CAPACITY = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_QUEUE_CAPACITY, "100000");
        ENTERPRISE_WAN_REP_BATCH_SIZE = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_BATCH_SIZE, "50");
        ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS
                = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS, "5");
        ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS, "60000");

        CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED, "true");
        CACHE_INVALIDATION_MESSAGE_BATCH_SIZE
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_SIZE, "100");
        CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS, "10");

        CLIENT_HEARTBEAT_TIMEOUT_SECONDS = new GroupProperty(config, PROP_CLIENT_MAX_NO_HEARTBEAT_SECONDS, "300");
        MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS
                = new GroupProperty(config, PROP_MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS, "5");
        BACKPRESSURE_ENABLED
                = new GroupProperty(config, PROP_BACKPRESSURE_ENABLED, "false");
        BACKPRESSURE_SYNCWINDOW
                = new GroupProperty(config, PROP_BACKPRESSURE_SYNCWINDOW, "100");
        BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION
                = new GroupProperty(config, PROP_BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION, "100");
        BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS
                = new GroupProperty(config, PROP_BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS, "60000");

        QUERY_RESULT_SIZE_LIMIT = new GroupProperty(config, PROP_QUERY_RESULT_SIZE_LIMIT, "-1");
        QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK
                = new GroupProperty(config, PROP_QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK, "3");

        QUERY_PREDICATE_PARALLEL_EVALUATION
                = new GroupProperty(config, PROP_QUERY_PREDICATE_PARALLEL_EVALUATION, "false");
    }

    public static class GroupProperty {

        private final String name;
        private final String value;

        GroupProperty(Config config, String name) {
            this(config, name, (String) null);
        }

        GroupProperty(Config config, String name, GroupProperty defaultValue) {
            this(config, name, defaultValue != null ? defaultValue.getString() : null);
        }

        GroupProperty(Config config, String name, String defaultValue) {
            this.name = name;
            String configValue = (config != null) ? config.getProperty(name) : null;
            if (configValue != null) {
                value = configValue;
            } else if (System.getProperty(name) != null) {
                value = System.getProperty(name);
            } else {
                value = defaultValue;
            }
        }

        public String getName() {
            return this.name;
        }

        public String getValue() {
            return value;
        }

        public int getInteger() {
            return Integer.parseInt(this.value);
        }

        public byte getByte() {
            return Byte.parseByte(this.value);
        }

        public boolean getBoolean() {
            return Boolean.valueOf(this.value);
        }

        public float getFloat() {
            return Float.valueOf(this.value);
        }

        public String getString() {
            return value;
        }

        public long getLong() {
            return Long.parseLong(this.value);
        }

        @Override
        public String toString() {
            return "GroupProperty [name=" + this.name + ", value=" + this.value + "]";
        }
    }
}

<code block>


package com.hazelcast.instance;

import com.hazelcast.client.impl.ClientServiceProxy;
import com.hazelcast.collection.impl.list.ListService;
import com.hazelcast.collection.impl.queue.QueueService;
import com.hazelcast.collection.impl.set.SetService;
import com.hazelcast.concurrent.atomiclong.AtomicLongService;
import com.hazelcast.concurrent.atomicreference.AtomicReferenceService;
import com.hazelcast.concurrent.countdownlatch.CountDownLatchService;
import com.hazelcast.concurrent.idgen.IdGeneratorService;
import com.hazelcast.concurrent.lock.LockProxy;
import com.hazelcast.concurrent.lock.LockService;
import com.hazelcast.concurrent.semaphore.SemaphoreService;
import com.hazelcast.config.Config;
import com.hazelcast.core.ClientService;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.DistributedObjectListener;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.HazelcastInstanceAware;
import com.hazelcast.core.IAtomicLong;
import com.hazelcast.core.IAtomicReference;
import com.hazelcast.core.ICountDownLatch;
import com.hazelcast.core.IExecutorService;
import com.hazelcast.core.IList;
import com.hazelcast.core.ILock;
import com.hazelcast.core.IMap;
import com.hazelcast.core.IQueue;
import com.hazelcast.core.ISemaphore;
import com.hazelcast.core.ISet;
import com.hazelcast.core.ITopic;
import com.hazelcast.core.IdGenerator;
import com.hazelcast.core.ManagedContext;
import com.hazelcast.core.Member;
import com.hazelcast.core.MultiMap;
import com.hazelcast.core.PartitionService;
import com.hazelcast.core.ReplicatedMap;
import com.hazelcast.executor.impl.DistributedExecutorService;
import com.hazelcast.internal.monitors.HealthMonitor;
import com.hazelcast.internal.monitors.PerformanceMonitor;
import com.hazelcast.jmx.ManagementService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.mapreduce.JobTracker;
import com.hazelcast.mapreduce.impl.MapReduceService;
import com.hazelcast.memory.MemoryStats;
import com.hazelcast.multimap.impl.MultiMapService;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.quorum.QuorumService;
import com.hazelcast.replicatedmap.impl.ReplicatedMapService;
import com.hazelcast.ringbuffer.Ringbuffer;
import com.hazelcast.ringbuffer.impl.RingbufferService;
import com.hazelcast.spi.ProxyService;
import com.hazelcast.spi.annotation.PrivateApi;
import com.hazelcast.topic.impl.TopicService;
import com.hazelcast.topic.impl.reliable.ReliableTopicService;
import com.hazelcast.transaction.HazelcastXAResource;
import com.hazelcast.transaction.TransactionContext;
import com.hazelcast.transaction.TransactionException;
import com.hazelcast.transaction.TransactionManagerService;
import com.hazelcast.transaction.TransactionOptions;
import com.hazelcast.transaction.TransactionalTask;
import com.hazelcast.transaction.impl.xa.XAService;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.ExceptionUtil;

import java.util.Collection;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import static com.hazelcast.core.LifecycleEvent.LifecycleState.STARTING;
import static com.hazelcast.util.Preconditions.checkNotNull;

@SuppressWarnings("unchecked")
@PrivateApi
public class HazelcastInstanceImpl implements HazelcastInstance {

    public final Node node;

    final ILogger logger;

    final String name;

    final ManagementService managementService;

    final LifecycleServiceImpl lifecycleService;

    final ManagedContext managedContext;

    final ConcurrentMap<String, Object> userContext = new ConcurrentHashMap<String, Object>();

    final PerformanceMonitor performanceMonitor;

    final HealthMonitor healthMonitor;

    HazelcastInstanceImpl(String name, Config config, NodeContext nodeContext)
            throws Exception {
        this.name = name;


        lifecycleService = new LifecycleServiceImpl(this);
        ManagedContext configuredManagedContext = config.getManagedContext();
        managedContext = new HazelcastManagedContext(this, configuredManagedContext);

        
        
        
        userContext.putAll(config.getUserContext());
        node = new Node(this, config, nodeContext);

        try {
            logger = node.getLogger(getClass().getName());
            lifecycleService.fireLifecycleEvent(STARTING);

            node.start();
            if (!node.isActive()) {
                throw new IllegalStateException("Node failed to start!");
            }

            managementService = new ManagementService(this);
            initManagedContext(configuredManagedContext);

            this.performanceMonitor = new PerformanceMonitor(this).start();
            this.healthMonitor = new HealthMonitor(node).start();
        } catch (Throwable e) {
            try {
                
                
                node.shutdown(true);
            } catch (Throwable ignored) {
                EmptyStatement.ignore(ignored);
            }
            throw ExceptionUtil.rethrow(e);
        }
    }

    private void initManagedContext(ManagedContext configuredManagedContext) {
        if (configuredManagedContext != null) {
            if (configuredManagedContext instanceof HazelcastInstanceAware) {
                ((HazelcastInstanceAware) configuredManagedContext).setHazelcastInstance(this);
            }
        }
    }

    public ManagementService getManagementService() {
        return managementService;
    }

    @Override
    public String getName() {
        return name;
    }

    @Override
    public <K, V> IMap<K, V> getMap(String name) {
        checkNotNull(name, "Retrieving a map instance with a null name is not allowed!");
        return getDistributedObject(MapService.SERVICE_NAME, name);
    }

    @Override
    public <E> IQueue<E> getQueue(String name) {
        checkNotNull(name, "Retrieving a queue instance with a null name is not allowed!");
        return getDistributedObject(QueueService.SERVICE_NAME, name);
    }

    @Override
    public <E> ITopic<E> getTopic(String name) {
        checkNotNull(name, "Retrieving a topic instance with a null name is not allowed!");
        return getDistributedObject(TopicService.SERVICE_NAME, name);
    }

    @Override
    public <E> ITopic<E> getReliableTopic(String name) {
        checkNotNull(name, "Retrieving a topic instance with a null name is not allowed!");
        return getDistributedObject(ReliableTopicService.SERVICE_NAME, name);
    }

    @Override
    public <E> ISet<E> getSet(String name) {
        checkNotNull(name, "Retrieving a set instance with a null name is not allowed!");
        return getDistributedObject(SetService.SERVICE_NAME, name);
    }

    @Override
    public <E> IList<E> getList(String name) {
        checkNotNull(name, "Retrieving a list instance with a null name is not allowed!");
        return getDistributedObject(ListService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> MultiMap<K, V> getMultiMap(String name) {
        checkNotNull(name, "Retrieving a multi-map instance with a null name is not allowed!");
        return getDistributedObject(MultiMapService.SERVICE_NAME, name);
    }

    @Override
    public JobTracker getJobTracker(String name) {
        checkNotNull(name, "Retrieving a job tracker instance with a null name is not allowed!");
        return getDistributedObject(MapReduceService.SERVICE_NAME, name);
    }

    @Override
    public <E> Ringbuffer<E> getRingbuffer(String name) {
        checkNotNull(name, "Retrieving a ringbuffer instance with a null name is not allowed!");
        return getDistributedObject(RingbufferService.SERVICE_NAME, name);
    }

    @Deprecated
    public ILock getLock(Object key) {
        checkNotNull(key, "Retrieving a lock instance with a null key is not allowed!");
        String name = LockProxy.convertToStringKey(key, node.getSerializationService());
        return getLock(name);
    }

    @Override
    public ILock getLock(String key) {
        checkNotNull(key, "Retrieving a lock instance with a null key is not allowed!");
        return getDistributedObject(LockService.SERVICE_NAME, key);
    }

    @Override
    public <T> T executeTransaction(TransactionalTask<T> task)
            throws TransactionException {
        return executeTransaction(TransactionOptions.getDefault(), task);
    }

    @Override
    public <T> T executeTransaction(TransactionOptions options, TransactionalTask<T> task)
            throws TransactionException {
        TransactionManagerService transactionManagerService = node.nodeEngine.getTransactionManagerService();
        return transactionManagerService.executeTransaction(options, task);
    }

    @Override
    public TransactionContext newTransactionContext() {
        return newTransactionContext(TransactionOptions.getDefault());
    }

    @Override
    public TransactionContext newTransactionContext(TransactionOptions options) {
        TransactionManagerService transactionManagerService = node.nodeEngine.getTransactionManagerService();
        return transactionManagerService.newTransactionContext(options);
    }

    @Override
    public IExecutorService getExecutorService(String name) {
        checkNotNull(name, "Retrieving an executor instance with a null name is not allowed!");
        return getDistributedObject(DistributedExecutorService.SERVICE_NAME, name);
    }

    @Override
    public IdGenerator getIdGenerator(String name) {
        checkNotNull(name, "Retrieving an id-generator instance with a null name is not allowed!");
        return getDistributedObject(IdGeneratorService.SERVICE_NAME, name);
    }

    @Override
    public IAtomicLong getAtomicLong(String name) {
        checkNotNull(name, "Retrieving an atomic-long instance with a null name is not allowed!");
        return getDistributedObject(AtomicLongService.SERVICE_NAME, name);
    }

    @Override
    public <E> IAtomicReference<E> getAtomicReference(String name) {
        checkNotNull(name, "Retrieving an atomic-reference instance with a null name is not allowed!");
        return getDistributedObject(AtomicReferenceService.SERVICE_NAME, name);
    }

    @Override
    public ICountDownLatch getCountDownLatch(String name) {
        checkNotNull(name, "Retrieving a countdown-latch instance with a null name is not allowed!");
        return getDistributedObject(CountDownLatchService.SERVICE_NAME, name);
    }

    @Override
    public ISemaphore getSemaphore(String name) {
        checkNotNull(name, "Retrieving a semaphore instance with a null name is not allowed!");
        return getDistributedObject(SemaphoreService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> ReplicatedMap<K, V> getReplicatedMap(String name) {
        checkNotNull(name, "Retrieving a replicated map instance with a null name is not allowed!");
        return getDistributedObject(ReplicatedMapService.SERVICE_NAME, name);
    }

    @Override
    public Cluster getCluster() {
        return node.clusterService.getClusterProxy();
    }

    @Override
    public Member getLocalEndpoint() {
        return node.clusterService.getLocalMember();
    }

    @Override
    public Collection<DistributedObject> getDistributedObjects() {
        ProxyService proxyService = node.nodeEngine.getProxyService();
        return proxyService.getAllDistributedObjects();
    }

    @Override
    public Config getConfig() {
        return node.getConfig();
    }

    @Override
    public ConcurrentMap<String, Object> getUserContext() {
        return userContext;
    }

    @Override
    public PartitionService getPartitionService() {
        return node.partitionService.getPartitionServiceProxy();
    }

    @Override
    public QuorumService getQuorumService() {
        return node.nodeEngine.getQuorumService();
    }

    @Override
    public ClientService getClientService() {
        return new ClientServiceProxy(node);
    }

    @Override
    public LoggingService getLoggingService() {
        return node.loggingService;
    }

    @Override
    public LifecycleServiceImpl getLifecycleService() {
        return lifecycleService;
    }

    @Override
    public void shutdown() {
        getLifecycleService().shutdown();
    }

    @Override
    public <T extends DistributedObject> T getDistributedObject(String serviceName, String name) {
        ProxyService proxyService = node.nodeEngine.getProxyService();
        return (T) proxyService.getDistributedObject(serviceName, name);
    }

    @Override
    public String addDistributedObjectListener(DistributedObjectListener distributedObjectListener) {
        final ProxyService proxyService = node.nodeEngine.getProxyService();
        return proxyService.addProxyListener(distributedObjectListener);
    }

    @Override
    public boolean removeDistributedObjectListener(String registrationId) {
        final ProxyService proxyService = node.nodeEngine.getProxyService();
        return proxyService.removeProxyListener(registrationId);
    }

    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    public MemoryStats getMemoryStats() {
        return node.getNodeExtension().getMemoryStats();
    }

    @Override
    public HazelcastXAResource getXAResource() {
        return getDistributedObject(XAService.SERVICE_NAME, XAService.SERVICE_NAME);
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (o == null || !(o instanceof HazelcastInstance)) {
            return false;
        }

        HazelcastInstance that = (HazelcastInstance) o;
        return !(name != null ? !name.equals(that.getName()) : that.getName() != null);
    }

    @Override
    public int hashCode() {
        return name != null ? name.hashCode() : 0;
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("HazelcastInstance");
        sb.append("{name='").append(name).append('\'');
        sb.append(", node=").append(node.getThisAddress());
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.spi.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.config.Config;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.management.ManagementCenterService;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.internal.storage.DataRef;
import com.hazelcast.internal.storage.Storage;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.quorum.impl.QuorumServiceImpl;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.PostJoinAwareService;
import com.hazelcast.spi.impl.servicemanager.ServiceInfo;
import com.hazelcast.spi.SharedService;
import com.hazelcast.spi.impl.eventservice.InternalEventService;
import com.hazelcast.spi.impl.eventservice.impl.EventServiceImpl;
import com.hazelcast.spi.impl.executionservice.InternalExecutionService;
import com.hazelcast.spi.impl.executionservice.impl.ExecutionServiceImpl;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import com.hazelcast.spi.impl.operationservice.impl.OperationServiceImpl;
import com.hazelcast.spi.impl.proxyservice.InternalProxyService;
import com.hazelcast.spi.impl.proxyservice.impl.ProxyServiceImpl;
import com.hazelcast.spi.impl.servicemanager.impl.ServiceManagerImpl;
import com.hazelcast.spi.impl.waitnotifyservice.InternalWaitNotifyService;
import com.hazelcast.spi.impl.waitnotifyservice.impl.WaitNotifyServiceImpl;
import com.hazelcast.spi.impl.transceiver.PacketTransceiver;
import com.hazelcast.spi.impl.transceiver.impl.PacketTransceiverImpl;
import com.hazelcast.transaction.TransactionManagerService;
import com.hazelcast.transaction.impl.TransactionManagerServiceImpl;
import com.hazelcast.wan.WanReplicationService;

import java.util.Collection;
import java.util.LinkedList;


public class NodeEngineImpl implements NodeEngine {

    private final Node node;
    private final ILogger logger;
    private final EventServiceImpl eventService;
    private final OperationServiceImpl operationService;
    private final ExecutionServiceImpl executionService;
    private final WaitNotifyServiceImpl waitNotifyService;
    private final ServiceManagerImpl serviceManager;
    private final TransactionManagerServiceImpl transactionManagerService;
    private final ProxyServiceImpl proxyService;
    private final WanReplicationService wanReplicationService;
    private final PacketTransceiver packetTransceiver;
    private final QuorumServiceImpl quorumService;
    private final MetricsRegistryImpl metricsRegistry;

    public NodeEngineImpl(Node node) {
        this.node = node;
        this.logger = node.getLogger(NodeEngine.class.getName());
        this.metricsRegistry = new MetricsRegistryImpl(node.getLogger(MetricsRegistryImpl.class));
        this.proxyService = new ProxyServiceImpl(this);
        this.serviceManager = new ServiceManagerImpl(this);
        this.executionService = new ExecutionServiceImpl(this);
        this.operationService = new OperationServiceImpl(this);
        this.eventService = new EventServiceImpl(this);
        this.waitNotifyService = new WaitNotifyServiceImpl(this);
        this.transactionManagerService = new TransactionManagerServiceImpl(this);
        this.wanReplicationService = node.getNodeExtension().createService(WanReplicationService.class);
        this.packetTransceiver = new PacketTransceiverImpl(
                node, logger, operationService, eventService, wanReplicationService, executionService);
        quorumService = new QuorumServiceImpl(this);
    }

    public MetricsRegistry getMetricsRegistry() {
        return metricsRegistry;
    }

    public PacketTransceiver getPacketTransceiver() {
        return packetTransceiver;
    }

    public void start() {
        serviceManager.start();
        proxyService.init();
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public MemberImpl getLocalMember() {
        return node.getLocalMember();
    }

    @Override
    public Config getConfig() {
        return node.getConfig();
    }

    @Override
    public ClassLoader getConfigClassLoader() {
        return node.getConfigClassLoader();
    }

    @Override
    public InternalEventService getEventService() {
        return eventService;
    }

    @Override
    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    @Override
    public InternalOperationService getOperationService() {
        return operationService;
    }

    @Override
    public InternalExecutionService getExecutionService() {
        return executionService;
    }

    @Override
    public InternalPartitionService getPartitionService() {
        return node.getPartitionService();
    }

    @Override
    public ClusterService getClusterService() {
        return node.getClusterService();
    }

    public ManagementCenterService getManagementCenterService() {
        return node.getManagementCenterService();
    }

    @Override
    public InternalProxyService getProxyService() {
        return proxyService;
    }

    @Override
    public InternalWaitNotifyService getWaitNotifyService() {
        return waitNotifyService;
    }

    @Override
    public WanReplicationService getWanReplicationService() {
        return wanReplicationService;
    }

    @Override
    public QuorumServiceImpl getQuorumService() {
        return quorumService;
    }

    @Override
    public TransactionManagerService getTransactionManagerService() {
        return transactionManagerService;
    }

    @Override
    public Data toData(final Object object) {
        return node.getSerializationService().toData(object);
    }

    @Override
    public Object toObject(final Object object) {
        if (object instanceof Data) {
            return node.getSerializationService().toObject(object);
        }
        return object;
    }

    @Override
    public boolean isActive() {
        return node.isActive();
    }

    @Override
    public HazelcastInstance getHazelcastInstance() {
        return node.hazelcastInstance;
    }

    @Override
    public ILogger getLogger(String name) {
        return node.getLogger(name);
    }

    @Override
    public ILogger getLogger(Class clazz) {
        return node.getLogger(clazz);
    }

    @Override
    public GroupProperties getGroupProperties() {
        return node.getGroupProperties();
    }

    public <T> T getService(String serviceName) {
        return serviceManager.getService(serviceName);
    }

    @Override
    public <T extends SharedService> T getSharedService(String serviceName) {
        return serviceManager.getSharedService(serviceName);
    }

    
    public <S> Collection<S> getServices(Class<S> serviceClass) {
        return serviceManager.getServices(serviceClass);
    }

    public Collection<ServiceInfo> getServiceInfos(Class serviceClass) {
        return serviceManager.getServiceInfos(serviceClass);
    }

    public Node getNode() {
        return node;
    }

    public void onMemberLeft(MemberImpl member) {
        waitNotifyService.onMemberLeft(member);
        operationService.onMemberLeft(member);
        eventService.onMemberLeft(member);
    }

    public void onClientDisconnected(String clientUuid) {
        waitNotifyService.onClientDisconnected(clientUuid);
    }

    public void onPartitionMigrate(MigrationInfo migrationInfo) {
        waitNotifyService.onPartitionMigrate(getThisAddress(), migrationInfo);
    }

    
    public Operation[] getPostJoinOperations() {
        final Collection<Operation> postJoinOps = new LinkedList<Operation>();
        Operation eventPostJoinOp = eventService.getPostJoinOperation();
        if (eventPostJoinOp != null) {
            postJoinOps.add(eventPostJoinOp);
        }
        Collection<PostJoinAwareService> services = getServices(PostJoinAwareService.class);
        for (PostJoinAwareService service : services) {
            final Operation postJoinOperation = service.getPostJoinOperation();
            if (postJoinOperation != null) {
                if (postJoinOperation.getPartitionId() >= 0) {
                    logger.severe(
                            "Post-join operations cannot implement PartitionAwareOperation! Service: "
                                    + service + ", Operation: "
                                    + postJoinOperation);
                    continue;
                }
                postJoinOps.add(postJoinOperation);
            }
        }
        return postJoinOps.isEmpty() ? null : postJoinOps.toArray(new Operation[postJoinOps.size()]);
    }

    @Override
    public Storage<DataRef> getOffHeapStorage() {
        return node.getNodeExtension().getNativeDataStorage();
    }

    public void reset() {
        waitNotifyService.reset();
        operationService.reset();
    }

    public void shutdown(final boolean terminate) {
        logger.finest("Shutting down services...");
        waitNotifyService.shutdown();
        proxyService.shutdown();
        serviceManager.shutdown(terminate);
        eventService.shutdown();
        operationService.shutdown();
        wanReplicationService.shutdown();
        executionService.shutdown();
        metricsRegistry.shutdown();
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.internal.management.dto.SlowOperationDTO;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;

import java.util.List;


public interface InternalOperationService extends OperationService {

    
    boolean isCallTimedOut(Operation op);

    
    void execute(PartitionSpecificRunnable task);

    
    OperationExecutor getOperationExecutor();

    
    List<SlowOperationDTO> getSlowOperationDTOs();

    <V> void asyncInvokeOnPartition(String serviceName, Operation op, int partitionId, ExecutionCallback<V> callback);

    <V> void asyncInvokeOnTarget(String serviceName, Operation op, Address target, ExecutionCallback<V> callback);
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.MemberLeftException;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.ReplicaErrorLogger;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.executionservice.InternalExecutionService;
import com.hazelcast.spi.impl.operationexecutor.OperationHostileThread;
import com.hazelcast.spi.impl.operationservice.impl.responses.BackupResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.ErrorResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.NormalResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.Response;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.counters.MwCounter;
import com.hazelcast.util.counters.SwCounter;

import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.instance.OutOfMemoryErrorDispatcher.inspectOutputMemoryError;
import static com.hazelcast.spi.Operation.CALL_ID_LOCAL_SKIPPED;
import static com.hazelcast.spi.OperationAccessor.setCallId;
import static com.hazelcast.util.counters.MwCounter.newMwCounter;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;


public class InvocationRegistry {

    private static final long SCHEDULE_DELAY = 1111;
    private static final int INITIAL_CAPACITY = 1000;
    private static final float LOAD_FACTOR = 0.75f;
    private static final int DELAY_MILLIS = 1000;
    private static final double HUNDRED_PERCENT = 100d;

    private final long backupTimeoutMillis;

    @Probe(name = "invocations.pending")
    private final ConcurrentMap<Long, Invocation> invocations;
    private final NodeEngineImpl nodeEngine;
    private final ILogger logger;
    private final InspectionThread inspectionThread;
    private final CallIdSequence callIdSequence;
    private final long slowInvocationThresholdMs;

    @Probe(name = "response.normal.count")
    private final SwCounter responseNormalCounter = newSwCounter();
    @Probe(name = "response.timeout.count")
    private final SwCounter responseTimeoutCounter = newSwCounter();
    @Probe(name = "response.backup.count")
    private final MwCounter responseBackupCounter = newMwCounter();
    @Probe(name = "response.error.count")
    private final SwCounter responseErrorCounter = newSwCounter();
    @Probe(name = "invocations.backupTimeouts")
    private final SwCounter backupTimeoutsCount = newSwCounter();
    @Probe(name = "invocations.normalTimeouts")
    private final SwCounter normalTimeoutsCount = newSwCounter();

    public InvocationRegistry(NodeEngineImpl nodeEngine, ILogger logger, BackpressureRegulator backpressureRegulator,
                              int concurrencyLevel) {
        this.nodeEngine = nodeEngine;
        this.logger = logger;
        this.callIdSequence = backpressureRegulator.newCallIdSequence();
        GroupProperties props = nodeEngine.getGroupProperties();
        this.slowInvocationThresholdMs = initSlowInvocationThresholdMs(props);
        this.backupTimeoutMillis = props.OPERATION_BACKUP_TIMEOUT_MILLIS.getLong();
        this.invocations = new ConcurrentHashMap<Long, Invocation>(INITIAL_CAPACITY, LOAD_FACTOR, concurrencyLevel);
        this.inspectionThread = new InspectionThread();

        inspectionThread.start();
        nodeEngine.getMetricsRegistry().scanAndRegister(this, "operation");
    }

    @Probe(name = "invocations.usedPercentage")
    private double invocationsUsedPercentage() {
        int maxConcurrentInvocations = callIdSequence.getMaxConcurrentInvocations();
        if (maxConcurrentInvocations == Integer.MAX_VALUE) {
            return 0;
        }

        return (HUNDRED_PERCENT * invocations.size()) / maxConcurrentInvocations;
    }

    private long initSlowInvocationThresholdMs(GroupProperties props) {
        long thresholdMs = props.SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS.getLong();
        if (thresholdMs > -1) {
            logger.info("Slow invocation detector enabled, using threshold: " + thresholdMs + " ms");
        }
        return thresholdMs;
    }

    @Probe(name = "invocations.lastCallId")
    public long getLastCallId() {
        return callIdSequence.getLastCallId();
    }

    
    public void register(Invocation invocation) {
        assert invocation.op.getCallId() == 0 : "can't register twice:" + invocation;

        long callId = callIdSequence.next(invocation);
        setCallId(invocation.op, callId);

        if (callId == CALL_ID_LOCAL_SKIPPED) {
            return;
        }

        invocations.put(callId, invocation);
    }

    
    public void deregister(Invocation invocation) {
        long callId = invocation.op.getCallId();

        callIdSequence.complete(invocation);

        setCallId(invocation.op, 0);

        if (callId == 0 || callId == CALL_ID_LOCAL_SKIPPED) {
            return;
        }

        boolean deleted = invocations.remove(callId) != null;
        assert deleted : "failed to deregister callId:" + callId + " " + invocation;
    }

    
    public int size() {
        return invocations.size();
    }

    
    public Invocation get(long callId) {
        return invocations.get(callId);
    }

    
    public void notify(Response response) {
        if (response instanceof NormalResponse) {
            notifyNormalResponse((NormalResponse) response);
        } else if (response instanceof BackupResponse) {
            notifyBackupComplete(response.getCallId());
        } else if (response instanceof CallTimeoutResponse) {
            notifyCallTimeout((CallTimeoutResponse) response);
        } else if (response instanceof ErrorResponse) {
            notifyErrorResponse((ErrorResponse) response);
        } else {
            logger.severe("Unrecognized response: " + response);
        }
    }

    public void notifyBackupComplete(long callId) {
        responseBackupCounter.inc();

        try {
            Invocation invocation = invocations.get(callId);

            
            
            
            if (invocation == null) {
                if (logger.isFinestEnabled()) {
                    logger.finest("No Invocation found for BackupResponse with callId " + callId);
                }
                return;
            }

            invocation.notifySingleBackupComplete();
        } catch (Exception e) {
            ReplicaErrorLogger.log(e, logger);
        }
    }

    private void notifyErrorResponse(ErrorResponse response) {
        responseErrorCounter.inc();

        Invocation invocation = invocations.get(response.getCallId());

        if (invocation == null) {
            if (nodeEngine.isActive()) {
                logger.warning("No Invocation found for response: " + response);
            }
            return;
        }

        invocation.notifyError(response.getCause());
    }

    private void notifyNormalResponse(NormalResponse response) {
        responseNormalCounter.inc();

        Invocation invocation = invocations.get(response.getCallId());

        if (invocation == null) {
            if (nodeEngine.isActive()) {
                logger.warning("No Invocation found for response: " + response);
            }
            return;
        }
        invocation.notifyNormalResponse(response.getValue(), response.getBackupCount());
    }

    private void notifyCallTimeout(CallTimeoutResponse response) {
        responseTimeoutCounter.inc();

        Invocation invocation = invocations.get(response.getCallId());

        if (invocation == null) {
            if (nodeEngine.isActive()) {
                logger.warning("No Invocation found for response: " + response);
            }
            return;
        }
        invocation.notifyCallTimeout();
    }

    public void onMemberLeft(MemberImpl member) {
        
        InternalExecutionService executionService = nodeEngine.getExecutionService();
        Runnable task = new OnMemberLeftTask(member);
        executionService.schedule(task, SCHEDULE_DELAY, TimeUnit.MILLISECONDS);
    }

    public void reset() {
        for (Invocation invocation : invocations.values()) {
            try {
                invocation.notifyError(new MemberLeftException());
            } catch (Throwable e) {
                logger.warning(invocation + " could not be notified with reset message -> " + e.getMessage());
            }
        }
    }

    public void shutdown() {
        inspectionThread.shutdown();

        for (Invocation invocation : invocations.values()) {
            try {
                invocation.notifyError(new HazelcastInstanceNotActiveException());
            } catch (Throwable e) {
                logger.warning(invocation + " could not be notified with shutdown message -> " + e.getMessage(), e);
            }
        }
    }

    public void awaitTermination(long timeoutMillis) throws InterruptedException {
        inspectionThread.join(timeoutMillis);
    }

    
    class InspectionThread extends Thread implements OperationHostileThread {

        private volatile boolean shutdown;

        InspectionThread() {
            super(nodeEngine.getNode().getHazelcastThreadGroup().getThreadNamePrefix("InspectInvocationsThread"));
        }

        public void shutdown() {
            shutdown = true;
            interrupt();
        }

        @Override
        public void run() {
            try {
                while (!shutdown) {
                    scanHandleOperationTimeout();
                    if (!shutdown) {
                        sleep();
                    }
                }
            } catch (Throwable t) {
                inspectOutputMemoryError(t);
                logger.severe("Failed to run", t);
            }
        }

        private void sleep() {
            try {
                Thread.sleep(DELAY_MILLIS);
            } catch (InterruptedException ignore) {
                
                EmptyStatement.ignore(ignore);
            }
        }

        private void scanHandleOperationTimeout() {
            if (invocations.isEmpty()) {
                return;
            }

            long now = Clock.currentTimeMillis();
            int backupTimeouts = 0;
            int invocationTimeouts = 0;
            for (Invocation invocation : invocations.values()) {
                if (shutdown) {
                    return;
                }

                detectSlowInvocation(now, invocation);

                if (checkInvocationTimeout(invocation)) {
                    invocationTimeouts++;
                }

                if (checkBackupTimeout(invocation)) {
                    backupTimeouts++;
                }
            }

            backupTimeoutsCount.inc(backupTimeouts);
            normalTimeoutsCount.inc(invocationTimeouts);
            log(backupTimeouts, invocationTimeouts);
        }

        private void detectSlowInvocation(long now, Invocation invocation) {
            if (slowInvocationThresholdMs > 0) {
                long durationMs = now - invocation.op.getInvocationTime();
                if (durationMs > slowInvocationThresholdMs) {
                    logger.info("Slow invocation: duration=" + durationMs + " ms, operation="
                            + invocation.op.getClass().getName() + " inv:" + invocation);
                }
            }
        }

        private boolean checkInvocationTimeout(Invocation invocation) {
            try {
                return invocation.checkInvocationTimeout();
            } catch (Throwable t) {
                inspectOutputMemoryError(t);
                logger.severe("Failed to handle operation timeout of invocation:" + invocation, t);
                return false;
            }
        }

        private boolean checkBackupTimeout(Invocation invocation) {
            try {
                return invocation.checkBackupTimeout(backupTimeoutMillis);
            } catch (Throwable t) {
                inspectOutputMemoryError(t);
                logger.severe("Failed to handle backup timeout of invocation:" + invocation, t);
                return false;
            }
        }

        private void log(int backupTimeouts, int invocationTimeouts) {
            if (backupTimeouts > 0 || invocationTimeouts > 0) {
                logger.info("Handled " + invocationTimeouts + " invocation timeouts and " + backupTimeouts + " backupTimeouts");
            }
        }
    }

    private class OnMemberLeftTask implements Runnable {
        private final MemberImpl leftMember;

        public OnMemberLeftTask(MemberImpl leftMember) {
            this.leftMember = leftMember;
        }

        @Override
        public void run() {
            for (Invocation invocation : invocations.values()) {
                if (hasMemberLeft(invocation)) {
                    invocation.notifyError(new MemberLeftException(leftMember));
                }
            }
        }

        private boolean hasMemberLeft(Invocation invocation) {
            MemberImpl targetMember = invocation.targetMember;
            if (targetMember == null) {
                Address invTarget = invocation.invTarget;
                return leftMember.getAddress().equals(invTarget);
            } else {
                return leftMember.getUuid().equals(targetMember.getUuid());
            }
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.IOUtil;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.quorum.impl.QuorumServiceImpl;
import com.hazelcast.spi.BackupAwareOperation;
import com.hazelcast.spi.Notifier;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationResponseHandler;
import com.hazelcast.spi.ReadonlyOperation;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.exception.CallerNotMemberException;
import com.hazelcast.spi.exception.PartitionMigratingException;
import com.hazelcast.spi.exception.RetryableException;
import com.hazelcast.spi.exception.WrongTargetException;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.operationexecutor.OperationRunner;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.ErrorResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.NormalResponse;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.counters.Counter;

import java.util.concurrent.atomic.AtomicLong;
import java.util.logging.Level;

import static com.hazelcast.spi.Operation.CALL_ID_LOCAL_SKIPPED;
import static com.hazelcast.spi.OperationAccessor.setCallerAddress;
import static com.hazelcast.spi.OperationAccessor.setConnection;
import static com.hazelcast.spi.impl.OperationResponseHandlerFactory.createEmptyResponseHandler;
import static com.hazelcast.spi.impl.operationutil.Operations.isJoinOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isMigrationOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isWanReplicationOperation;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;
import static java.util.logging.Level.FINEST;
import static java.util.logging.Level.SEVERE;
import static java.util.logging.Level.WARNING;


class OperationRunnerImpl extends OperationRunner {

    static final int AD_HOC_PARTITION_ID = -2;

    private final ILogger logger;
    private final OperationServiceImpl operationService;
    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final AtomicLong executedOperationsCount;

    @Probe
    private final Counter count;

    
    
    private InternalPartition internalPartition;

    private final OperationResponseHandler remoteResponseHandler;

    
    
    
    
    
    public OperationRunnerImpl(OperationServiceImpl operationService, int partitionId) {
        super(partitionId);
        this.operationService = operationService;
        this.logger = operationService.logger;
        this.node = operationService.node;
        this.nodeEngine = operationService.nodeEngine;
        this.remoteResponseHandler = new RemoteInvocationResponseHandler(operationService);
        this.executedOperationsCount = operationService.completedOperationsCount;

        if (partitionId >= 0) {
            this.count = newSwCounter();
            nodeEngine.getMetricsRegistry().scanAndRegister(this, "operation.partition[" + partitionId + "]");
        } else {
            this.count = null;
        }
    }

    @Override
    public void run(Runnable task) {
        boolean publishCurrentTask = publishCurrentTask();

        if (publishCurrentTask) {
            currentTask = task;
        }

        try {
            task.run();
        } finally {
            if (publishCurrentTask) {
                currentTask = null;
            }
        }
    }

    private boolean publishCurrentTask() {
        return (getPartitionId() != AD_HOC_PARTITION_ID && currentTask == null);
    }

    @Override
    public void run(Operation op) {
        if (count != null) {
            count.inc();
        }

        executedOperationsCount.incrementAndGet();

        boolean publishCurrentTask = publishCurrentTask();

        if (publishCurrentTask) {
            currentTask = op;
        }

        try {
            if (timeout(op)) {
                return;
            }

            ensureNoPartitionProblems(op);

            ensureQuorumPresent(op);

            op.beforeRun();

            if (waitingNeeded(op)) {
                return;
            }

            op.run();
            handleResponse(op);
            afterRun(op);
        } catch (Throwable e) {
            handleOperationError(op, e);
        } finally {
            if (publishCurrentTask) {
                currentTask = null;
            }
        }
    }

    private void ensureQuorumPresent(Operation op) {
        QuorumServiceImpl quorumService = operationService.nodeEngine.getQuorumService();
        quorumService.ensureQuorumPresent(op);
    }

    private boolean waitingNeeded(Operation op) {
        if (!(op instanceof WaitSupport)) {
            return false;
        }

        WaitSupport waitSupport = (WaitSupport) op;
        if (waitSupport.shouldWait()) {
            nodeEngine.getWaitNotifyService().await(waitSupport);
            return true;
        }
        return false;
    }

    private boolean timeout(Operation op) {
        if (!operationService.isCallTimedOut(op)) {
            return false;
        }

        CallTimeoutResponse callTimeoutResponse = new CallTimeoutResponse(op.getCallId(), op.isUrgent());
        OperationResponseHandler responseHandler = op.getOperationResponseHandler();
        responseHandler.sendResponse(op, callTimeoutResponse);
        return true;
    }

    private void handleResponse(Operation op) throws Exception {
        boolean returnsResponse = op.returnsResponse();
        Object response = null;
        if (op instanceof BackupAwareOperation) {
            BackupAwareOperation backupAwareOp = (BackupAwareOperation) op;
            int syncBackupCount = 0;
            if (backupAwareOp.shouldBackup()) {
                syncBackupCount = operationService.operationBackupHandler.backup(backupAwareOp);
            }
            if (returnsResponse) {
                response = new NormalResponse(op.getResponse(), op.getCallId(), syncBackupCount, op.isUrgent());
            }
        }

        if (!returnsResponse) {
            return;
        }

        if (response == null) {
            response = op.getResponse();
        }

        OperationResponseHandler responseHandler = op.getOperationResponseHandler();
        if (responseHandler == null) {
            throw new IllegalStateException("ResponseHandler should not be null! " + op);
        }
        responseHandler.sendResponse(op, response);
    }

    private void afterRun(Operation op) {
        try {
            op.afterRun();
            if (op instanceof Notifier) {
                final Notifier notifier = (Notifier) op;
                if (notifier.shouldNotify()) {
                    operationService.nodeEngine.getWaitNotifyService().notify(notifier);
                }
            }
        } catch (Throwable e) {
            
            
            
            logOperationError(op, e);
        }
    }

    protected void ensureNoPartitionProblems(Operation op) {
        int partitionId = op.getPartitionId();

        if (partitionId < 0) {
            return;
        }

        if (partitionId != getPartitionId()) {
            throw new IllegalStateException("wrong partition, expected: " + getPartitionId() + " but found:" + partitionId);
        }

        if (internalPartition == null) {
            internalPartition = nodeEngine.getPartitionService().getPartition(partitionId);
        }

        if (retryDuringMigration(op) && internalPartition.isMigrating()) {
            throw new PartitionMigratingException(node.getThisAddress(), partitionId,
                    op.getClass().getName(), op.getServiceName());
        }

        Address owner = internalPartition.getReplicaAddress(op.getReplicaIndex());
        if (op.validatesTarget() && !node.getThisAddress().equals(owner)) {
            throw new WrongTargetException(node.getThisAddress(), owner, partitionId, op.getReplicaIndex(),
                    op.getClass().getName(), op.getServiceName());
        }
    }

    private boolean retryDuringMigration(Operation op) {
        return !(op instanceof ReadonlyOperation || isMigrationOperation(op));
    }

    private void handleOperationError(Operation operation, Throwable e) {
        if (e instanceof OutOfMemoryError) {
            OutOfMemoryErrorDispatcher.onOutOfMemory((OutOfMemoryError) e);
        }
        operation.logError(e);

        OperationResponseHandler responseHandler = operation.getOperationResponseHandler();
        if (operation.returnsResponse() && responseHandler != null) {
            try {
                if (node.isActive()) {
                    responseHandler.sendResponse(operation, e);
                } else if (responseHandler.isLocal()) {
                    responseHandler.sendResponse(operation, new HazelcastInstanceNotActiveException());
                }
            } catch (Throwable t) {
                logger.warning("While sending op error... op: " + operation + ", error: " + e, t);
            }
        }
    }

    private void logOperationError(Operation op, Throwable e) {
        if (e instanceof OutOfMemoryError) {
            OutOfMemoryErrorDispatcher.onOutOfMemory((OutOfMemoryError) e);
        }
        op.logError(e);
    }

    @Override
    public void run(Packet packet) throws Exception {
        boolean publishCurrentTask = publishCurrentTask();

        if (publishCurrentTask) {
            currentTask = packet;
        }

        Connection connection = packet.getConn();
        Address caller = connection.getEndPoint();
        Data data = packet.getData();
        try {
            Object object = nodeEngine.toObject(data);
            Operation op = (Operation) object;
            op.setNodeEngine(nodeEngine);
            setCallerAddress(op, caller);
            setConnection(op, connection);
            setCallerUuidIfNotSet(caller, op);
            setOperationResponseHandler(op);

            if (!ensureValidMember(op)) {
                return;
            }

            if (publishCurrentTask) {
                currentTask = null;
            }
            run(op);
        } catch (Throwable throwable) {
            
            long callId = IOUtil.extractOperationCallId(data, node.getSerializationService());
            operationService.send(new ErrorResponse(throwable, callId, packet.isUrgent()), caller);
            logOperationDeserializationException(throwable, callId);
            throw ExceptionUtil.rethrow(throwable);
        } finally {
            if (publishCurrentTask) {
                currentTask = null;
            }
        }
    }

    private void setOperationResponseHandler(Operation op) {
        OperationResponseHandler handler = remoteResponseHandler;
        if (op.getCallId() == 0 || op.getCallId() == CALL_ID_LOCAL_SKIPPED) {
            if (op.returnsResponse()) {
                throw new HazelcastException(
                        "Op: " + op + " can not return response without call-id!");
            }
            handler = createEmptyResponseHandler();
        }
        op.setOperationResponseHandler(handler);
    }

    private boolean ensureValidMember(Operation op) {
        if (node.clusterService.getMember(op.getCallerAddress()) != null
                || isJoinOperation(op)
                || isWanReplicationOperation(op)) {
            return true;
        }

        Exception error = new CallerNotMemberException(
                op.getCallerAddress(), op.getPartitionId(),
                op.getClass().getName(), op.getServiceName());
        handleOperationError(op, error);
        return false;
    }

    private void setCallerUuidIfNotSet(Address caller, Operation op) {
        if (op.getCallerUuid() != null) {
            return;

        }
        MemberImpl callerMember = node.clusterService.getMember(caller);
        if (callerMember != null) {
            op.setCallerUuid(callerMember.getUuid());
        }
    }

    public void logOperationDeserializationException(Throwable t, long callId) {
        boolean returnsResponse = callId != 0;

        if (t instanceof RetryableException) {
            final Level level = returnsResponse ? FINEST : WARNING;
            if (logger.isLoggable(level)) {
                logger.log(level, t.getClass().getName() + ": " + t.getMessage());
            }
        } else if (t instanceof OutOfMemoryError) {
            try {
                logger.log(SEVERE, t.getMessage(), t);
            } catch (Throwable ignored) {
                logger.log(SEVERE, ignored.getMessage(), t);
            }
        } else {
            final Level level = operationService.nodeEngine.isActive() ? SEVERE : FINEST;
            if (logger.isLoggable(level)) {
                logger.log(level, t.getMessage(), t);
            }
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.management.dto.SlowOperationDTO;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationFactory;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.UrgentSystemOperation;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;
import com.hazelcast.spi.impl.operationexecutor.classic.ClassicOperationExecutor;
import com.hazelcast.spi.impl.operationexecutor.slowoperationdetector.SlowOperationDetector;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import com.hazelcast.spi.impl.operationservice.impl.responses.Response;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.counters.MwCounter;
import com.hazelcast.util.executor.ExecutorType;
import com.hazelcast.util.executor.ManagedExecutorService;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.spi.InvocationBuilder.DEFAULT_CALL_TIMEOUT;
import static com.hazelcast.spi.InvocationBuilder.DEFAULT_DESERIALIZE_RESULT;
import static com.hazelcast.spi.InvocationBuilder.DEFAULT_REPLICA_INDEX;
import static com.hazelcast.spi.InvocationBuilder.DEFAULT_TRY_COUNT;
import static com.hazelcast.spi.InvocationBuilder.DEFAULT_TRY_PAUSE_MILLIS;


public final class OperationServiceImpl implements InternalOperationService {

    private static final int CORE_SIZE_CHECK = 8;
    private static final int CORE_SIZE_FACTOR = 4;
    private static final int CONCURRENCY_LEVEL = 16;
    private static final int ASYNC_QUEUE_CAPACITY = 100000;
    private static final long TERMINATION_TIMEOUT_MILLIS = TimeUnit.SECONDS.toMillis(10);

    final InvocationRegistry invocationsRegistry;
    final OperationExecutor operationExecutor;
    final ILogger invocationLogger;
    final ManagedExecutorService asyncExecutor;

    @Probe(name = "completed.count")
    final AtomicLong completedOperationsCount = new AtomicLong();

    @Probe(name = "operationTimeoutCount")
    final MwCounter operationTimeoutCount = MwCounter.newMwCounter();

    @Probe(name = "callTimeoutCount")
    final MwCounter callTimeoutCount = MwCounter.newMwCounter();

    @Probe(name = "retryCount")
    final MwCounter retryCount = MwCounter.newMwCounter();

    final NodeEngineImpl nodeEngine;
    final MetricsRegistry metricsRegistry;
    final Node node;
    final ILogger logger;
    final OperationBackupHandler operationBackupHandler;
    final BackpressureRegulator backpressureRegulator;
    final long defaultCallTimeoutMillis;

    private final SlowOperationDetector slowOperationDetector;
    private final IsStillRunningService isStillRunningService;

    public OperationServiceImpl(NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.node = nodeEngine.getNode();
        this.logger = node.getLogger(OperationService.class);
        this.metricsRegistry = nodeEngine.getMetricsRegistry();

        this.invocationLogger = nodeEngine.getLogger(Invocation.class);
        GroupProperties groupProperties = node.getGroupProperties();
        this.defaultCallTimeoutMillis = groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong();

        this.backpressureRegulator = new BackpressureRegulator(groupProperties, logger);

        int coreSize = Runtime.getRuntime().availableProcessors();
        boolean reallyMultiCore = coreSize >= CORE_SIZE_CHECK;
        int concurrencyLevel = reallyMultiCore ? coreSize * CORE_SIZE_FACTOR : CONCURRENCY_LEVEL;

        this.invocationsRegistry = new InvocationRegistry(nodeEngine, logger, backpressureRegulator, concurrencyLevel);
        this.operationBackupHandler = new OperationBackupHandler(this);

        this.operationExecutor = new ClassicOperationExecutor(
                groupProperties,
                node.loggingService,
                node.getThisAddress(),
                new OperationRunnerFactoryImpl(this),
                new ResponsePacketHandlerImpl(this),
                node.getHazelcastThreadGroup(),
                node.getNodeExtension(),
                metricsRegistry
        );

        this.isStillRunningService = new IsStillRunningService(operationExecutor, nodeEngine, logger);

        ExecutionService executionService = nodeEngine.getExecutionService();
        this.asyncExecutor = executionService.register(ExecutionService.ASYNC_EXECUTOR, coreSize,
                ASYNC_QUEUE_CAPACITY, ExecutorType.CONCRETE);

        this.slowOperationDetector = initSlowOperationDetector();

        nodeEngine.getMetricsRegistry().scanAndRegister(this, "operation");
    }

    private SlowOperationDetector initSlowOperationDetector() {
        return new SlowOperationDetector(node.loggingService,
                operationExecutor.getGenericOperationRunners(),
                operationExecutor.getPartitionOperationRunners(),
                node.groupProperties,
                node.getHazelcastThreadGroup());
    }

    public IsStillRunningService getIsStillRunningService() {
        return isStillRunningService;
    }

    @Override
    public void dumpPerformanceMetrics(StringBuffer sb) {
    }

    @Override
    public List<SlowOperationDTO> getSlowOperationDTOs() {
        return slowOperationDetector.getSlowOperationDTOs();
    }

    public InvocationRegistry getInvocationsRegistry() {
        return invocationsRegistry;
    }

    @Override
    public int getPartitionOperationThreadCount() {
        return operationExecutor.getPartitionOperationThreadCount();
    }

    @Override
    public int getGenericOperationThreadCount() {
        return operationExecutor.getGenericOperationThreadCount();
    }

    @Probe(name = "running.count")
    @Override
    public int getRunningOperationsCount() {
        return operationExecutor.getRunningOperationCount();
    }

    @Override
    public long getExecutedOperationCount() {
        return completedOperationsCount.get();
    }

    @Override
    public int getRemoteOperationsCount() {
        return invocationsRegistry.size();
    }

    @Probe(name = "response-queue.size")
    @Override
    public int getResponseQueueSize() {
        return operationExecutor.getResponseQueueSize();
    }

    @Probe(name = "queue.size")
    @Override
    public int getOperationExecutorQueueSize() {
        return operationExecutor.getOperationExecutorQueueSize();
    }

    @Probe(name = "priority-queue.size")
    @Override
    public int getPriorityOperationExecutorQueueSize() {
        return operationExecutor.getPriorityOperationExecutorQueueSize();
    }

    @Override
    public OperationExecutor getOperationExecutor() {
        return operationExecutor;
    }

    @Override
    public void execute(PartitionSpecificRunnable task) {
        operationExecutor.execute(task);
    }

    @Override
    public InvocationBuilder createInvocationBuilder(String serviceName, Operation op, int partitionId) {
        if (partitionId < 0) {
            throw new IllegalArgumentException("Partition id cannot be negative!");
        }
        return new InvocationBuilderImpl(nodeEngine, serviceName, op, partitionId);
    }

    @Override
    public InvocationBuilder createInvocationBuilder(String serviceName, Operation op, Address target) {
        if (target == null) {
            throw new IllegalArgumentException("Target cannot be null!");
        }
        return new InvocationBuilderImpl(nodeEngine, serviceName, op, target);
    }

    @Override
    public void runOperationOnCallingThread(Operation op) {
        operationExecutor.runOnCallingThread(op);
    }

    @Override
    public void executeOperation(Operation op) {
        operationExecutor.execute(op);
    }

    @Override
    public boolean isAllowedToRunOnCallingThread(Operation op) {
        return operationExecutor.isAllowedToRunInCurrentThread(op);
    }

    @Override
    @SuppressWarnings("unchecked")
    public <E> InternalCompletableFuture<E> invokeOnPartition(String serviceName, Operation op, int partitionId) {
        return new PartitionInvocation(
                nodeEngine, serviceName, op, partitionId, DEFAULT_REPLICA_INDEX,
                DEFAULT_TRY_COUNT, DEFAULT_TRY_PAUSE_MILLIS,
                DEFAULT_CALL_TIMEOUT, null, DEFAULT_DESERIALIZE_RESULT).invoke();
    }

    @Override
    @SuppressWarnings("unchecked")
    public <E> InternalCompletableFuture<E> invokeOnTarget(String serviceName, Operation op, Address target) {
        return new TargetInvocation(nodeEngine, serviceName, op, target, DEFAULT_TRY_COUNT,
                DEFAULT_TRY_PAUSE_MILLIS,
                DEFAULT_CALL_TIMEOUT, null, DEFAULT_DESERIALIZE_RESULT).invoke();
    }

    @Override
    @SuppressWarnings("unchecked")
    public <V> void asyncInvokeOnPartition(String serviceName, Operation op, int partitionId, ExecutionCallback<V> callback) {
        new PartitionInvocation(nodeEngine, serviceName, op, partitionId, DEFAULT_REPLICA_INDEX,
                DEFAULT_TRY_COUNT, DEFAULT_TRY_PAUSE_MILLIS,
                DEFAULT_CALL_TIMEOUT, callback, DEFAULT_DESERIALIZE_RESULT).invokeAsync();
    }

    @Override
    @SuppressWarnings("unchecked")
    public <V> void asyncInvokeOnTarget(String serviceName, Operation op, Address target, ExecutionCallback<V> callback) {
        new TargetInvocation(nodeEngine, serviceName, op, target, DEFAULT_TRY_COUNT,
                DEFAULT_TRY_PAUSE_MILLIS,
                DEFAULT_CALL_TIMEOUT, callback, DEFAULT_DESERIALIZE_RESULT).invokeAsync();
    }

    

    @Override
    public boolean isCallTimedOut(Operation op) {
        if (!op.returnsResponse() || op.getCallId() == 0) {
            return false;
        }

        long callTimeout = op.getCallTimeout();
        long invocationTime = op.getInvocationTime();
        long expireTime = invocationTime + callTimeout;

        if (expireTime <= 0 || expireTime >= Long.MAX_VALUE) {
            return false;
        }

        long now = nodeEngine.getClusterService().getClusterClock().getClusterTime();
        if (expireTime < now) {
            return true;
        }

        return false;
    }

    @Override
    public Map<Integer, Object> invokeOnAllPartitions(String serviceName, OperationFactory operationFactory) throws Exception {
        Map<Address, List<Integer>> memberPartitions = nodeEngine.getPartitionService().getMemberPartitionsMap();
        InvokeOnPartitions invokeOnPartitions = new InvokeOnPartitions(this, serviceName, operationFactory, memberPartitions);
        return invokeOnPartitions.invoke();
    }

    @Override
    public Map<Integer, Object> invokeOnPartitions(String serviceName, OperationFactory operationFactory,
                                                   Collection<Integer> partitions) throws Exception {
        Map<Address, List<Integer>> memberPartitions = new HashMap<Address, List<Integer>>(3);
        InternalPartitionService partitionService = nodeEngine.getPartitionService();
        for (int partition : partitions) {
            Address owner = partitionService.getPartitionOwnerOrWait(partition);

            if (!memberPartitions.containsKey(owner)) {
                memberPartitions.put(owner, new ArrayList<Integer>());
            }

            memberPartitions.get(owner).add(partition);
        }
        InvokeOnPartitions invokeOnPartitions = new InvokeOnPartitions(this, serviceName, operationFactory, memberPartitions);
        return invokeOnPartitions.invoke();
    }

    @Override
    public boolean send(Operation op, Address target) {
        if (target == null) {
            throw new IllegalArgumentException("Target is required!");
        }

        if (nodeEngine.getThisAddress().equals(target)) {
            throw new IllegalArgumentException("Target is this node! -> " + target + ", op: " + op);
        }

        Data data = nodeEngine.toData(op);
        int partitionId = op.getPartitionId();
        Packet packet = new Packet(data, partitionId);
        packet.setHeader(Packet.HEADER_OP);

        if (op instanceof UrgentSystemOperation) {
            packet.setHeader(Packet.HEADER_URGENT);
        }

        Connection connection = node.getConnectionManager().getOrConnect(target);
        return nodeEngine.getPacketTransceiver().transmit(packet, connection);
    }

    @Override
    public boolean send(Response response, Address target) {
        if (target == null) {
            throw new IllegalArgumentException("Target is required!");
        }

        if (nodeEngine.getThisAddress().equals(target)) {
            throw new IllegalArgumentException("Target is this node! -> " + target + ", response: " + response);
        }

        Data data = nodeEngine.toData(response);
        Packet packet = new Packet(data);
        packet.setHeader(Packet.HEADER_OP);
        packet.setHeader(Packet.HEADER_RESPONSE);

        if (response.isUrgent()) {
            packet.setHeader(Packet.HEADER_URGENT);
        }

        Connection connection = node.getConnectionManager().getOrConnect(target);
        return nodeEngine.getPacketTransceiver().transmit(packet, connection);
    }

    public void onMemberLeft(MemberImpl member) {
        invocationsRegistry.onMemberLeft(member);
    }

    public void reset() {
        invocationsRegistry.reset();
    }

    public void shutdown() {
        logger.finest("Shutting down OperationService");
        invocationsRegistry.shutdown();
        operationExecutor.shutdown();
        slowOperationDetector.shutdown();

        try {
            invocationsRegistry.awaitTermination(TERMINATION_TIMEOUT_MILLIS);
        } catch (InterruptedException e) {
            
            
            Thread.currentThread().interrupt();
            EmptyStatement.ignore(e);
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.OperationTimeoutException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationResponseHandler;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.exception.ResponseAlreadySentException;
import com.hazelcast.spi.exception.RetryableException;
import com.hazelcast.spi.exception.RetryableIOException;
import com.hazelcast.spi.exception.TargetNotMemberException;
import com.hazelcast.spi.exception.WrongTargetException;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.ErrorResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.NormalResponse;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;

import static com.hazelcast.spi.ExecutionService.ASYNC_EXECUTOR;
import static com.hazelcast.spi.OperationAccessor.setCallTimeout;
import static com.hazelcast.spi.OperationAccessor.setCallerAddress;
import static com.hazelcast.spi.OperationAccessor.setInvocationTime;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.INTERRUPTED_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.NULL_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.WAIT_RESPONSE;
import static com.hazelcast.spi.impl.operationutil.Operations.isJoinOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isMigrationOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isWanReplicationOperation;
import static java.lang.Boolean.FALSE;
import static java.lang.Boolean.TRUE;
import static java.util.logging.Level.WARNING;


abstract class Invocation implements OperationResponseHandler, Runnable {

    private static final AtomicReferenceFieldUpdater<Invocation, Boolean> RESPONSE_RECEIVED =
            AtomicReferenceFieldUpdater.newUpdater(Invocation.class, Boolean.class, "responseReceived");

    private static final AtomicIntegerFieldUpdater<Invocation> BACKUPS_COMPLETED =
            AtomicIntegerFieldUpdater.newUpdater(Invocation.class, "backupsCompleted");

    private static final long MIN_TIMEOUT = 10000;
    private static final int MAX_FAST_INVOCATION_COUNT = 5;
    
    private static final int LOG_MAX_INVOCATION_COUNT = 99;
    private static final int LOG_INVOCATION_COUNT_MOD = 10;

    
    volatile long pendingResponseReceivedMillis = -1;
    
    volatile Object pendingResponse;
    
    volatile int backupsExpected;
    
    volatile int backupsCompleted;
    
    volatile Boolean responseReceived = FALSE;

    final long callTimeout;
    final NodeEngineImpl nodeEngine;
    final String serviceName;
    final Operation op;
    final int partitionId;
    final int replicaIndex;
    final int tryCount;
    final long tryPauseMillis;
    final ILogger logger;
    final boolean resultDeserialized;
    boolean remote;
    Address invTarget;
    MemberImpl targetMember;
    final InvocationFuture invocationFuture;
    final OperationServiceImpl operationService;

    
    volatile int invokeCount;

    Invocation(NodeEngineImpl nodeEngine, String serviceName, Operation op, int partitionId,
               int replicaIndex, int tryCount, long tryPauseMillis, long callTimeout, ExecutionCallback callback,
               boolean resultDeserialized) {
        this.operationService = (OperationServiceImpl) nodeEngine.getOperationService();
        this.logger = operationService.invocationLogger;
        this.nodeEngine = nodeEngine;
        this.serviceName = serviceName;
        this.op = op;
        this.partitionId = partitionId;
        this.replicaIndex = replicaIndex;
        this.tryCount = tryCount;
        this.tryPauseMillis = tryPauseMillis;
        this.callTimeout = getCallTimeout(callTimeout);
        this.invocationFuture = new InvocationFuture(operationService, this, callback);
        this.resultDeserialized = resultDeserialized;
    }

    abstract ExceptionAction onException(Throwable t);

    protected abstract Address getTarget();

    InternalPartition getPartition() {
        return nodeEngine.getPartitionService().getPartition(partitionId);
    }

    @Override
    public boolean isLocal() {
        return true;
    }

    private long getCallTimeout(long callTimeout) {
        if (callTimeout > 0) {
            return callTimeout;
        }

        long defaultCallTimeout = operationService.defaultCallTimeoutMillis;
        if (!(op instanceof WaitSupport)) {
            return defaultCallTimeout;
        }

        long waitTimeoutMillis = op.getWaitTimeout();
        if (waitTimeoutMillis > 0 && waitTimeoutMillis < Long.MAX_VALUE) {
            
            long max = Math.max(waitTimeoutMillis, MIN_TIMEOUT);
            return Math.min(max, defaultCallTimeout);
        }
        return defaultCallTimeout;
    }

    public final InvocationFuture invoke() {
        invokeInternal(false);
        return invocationFuture;
    }

    public final void invokeAsync() {
        invokeInternal(true);
    }

    private void invokeInternal(boolean isAsync) {
        if (invokeCount > 0) {
            
            throw new IllegalStateException("An invocation can not be invoked more than once!");
        }

        if (op.getCallId() != 0) {
            throw new IllegalStateException("An operation[" + op + "] can not be used for multiple invocations!");
        }

        try {
            setCallTimeout(op, callTimeout);
            setCallerAddress(op, nodeEngine.getThisAddress());
            op.setNodeEngine(nodeEngine)
                    .setServiceName(serviceName)
                    .setPartitionId(partitionId)
                    .setReplicaIndex(replicaIndex);

            boolean isAllowed = operationService.operationExecutor.isInvocationAllowedFromCurrentThread(op, isAsync);
            if (!isAllowed && !isMigrationOperation(op)) {
                throw new IllegalThreadStateException(Thread.currentThread() + " cannot make remote call: " + op);
            }
            doInvoke(isAsync);
        } catch (Exception e) {
            handleInvocationException(e);
        }
    }

    private void handleInvocationException(Exception e) {
        if (e instanceof RetryableException) {
            notify(e);
        } else {
            throw ExceptionUtil.rethrow(e);
        }
    }

    @SuppressFBWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "We have the guarantee that only a single thread at any given time can change the volatile field")
    private void doInvoke(boolean isAsync) {
        if (!engineActive()) {
            return;
        }

        invokeCount++;

        
        if (!initInvocationTarget()) {
            return;
        }

        setInvocationTime(op, nodeEngine.getClusterService().getClusterClock().getClusterTime());
        operationService.invocationsRegistry.register(this);
        if (remote) {
            doInvokeRemote();
        } else {
            doInvokeLocal(isAsync);
        }
    }

    private void doInvokeLocal(boolean isAsync) {
        if (op.getCallerUuid() == null) {
            op.setCallerUuid(nodeEngine.getLocalMember().getUuid());
        }

        responseReceived = FALSE;
        op.setOperationResponseHandler(this);

        OperationExecutor executor = operationService.operationExecutor;
        if (isAsync) {
            executor.execute(op);
        } else {
            executor.runOnCallingThreadIfPossible(op);
        }

    }

    private void doInvokeRemote() {
        boolean sent = operationService.send(op, invTarget);
        if (!sent) {
            operationService.invocationsRegistry.deregister(this);
            notify(new RetryableIOException("Packet not send to -> " + invTarget));
        }
    }

    @Override
    public void run() {
        doInvoke(false);
    }

    private boolean engineActive() {
        if (nodeEngine.isActive()) {
            return true;
        }

        remote = false;
        notify(new HazelcastInstanceNotActiveException());
        return false;
    }

    
    boolean initInvocationTarget() {
        Address thisAddress = nodeEngine.getThisAddress();

        invTarget = getTarget();

        if (invTarget == null) {
            remote = false;
            if (nodeEngine.isActive()) {
                notify(new WrongTargetException(thisAddress, null, partitionId
                        , replicaIndex, op.getClass().getName(), serviceName));
            } else {
                notify(new HazelcastInstanceNotActiveException());
            }
            return false;
        }

        targetMember = nodeEngine.getClusterService().getMember(invTarget);
        if (targetMember == null && !(isJoinOperation(op) || isWanReplicationOperation(op))) {
            notify(new TargetNotMemberException(invTarget, partitionId, op.getClass().getName(), serviceName));
            return false;
        }

        if (op.getPartitionId() != partitionId) {
            notify(new IllegalStateException("Partition id of operation: " + op.getPartitionId()
                    + " is not equal to the partition id of invocation: " + partitionId));
            return false;
        }

        if (op.getReplicaIndex() != replicaIndex) {
            notify(new IllegalStateException("Replica index of operation: " + op.getReplicaIndex()
                    + " is not equal to the replica index of invocation: " + replicaIndex));
            return false;
        }

        remote = !thisAddress.equals(invTarget);
        return true;
    }

    @Override
    public void sendResponse(Operation op, Object obj) {
        if (!RESPONSE_RECEIVED.compareAndSet(this, FALSE, TRUE)) {
            throw new ResponseAlreadySentException("NormalResponse already responseReceived for callback: " + this
                    + ", current-response: : " + obj);
        }
        notify(obj);
    }

    
    
    void notify(Object response) {
        if (response == null) {
            response = NULL_RESPONSE;
        }

        if (response instanceof CallTimeoutResponse) {
            notifyCallTimeout();
            return;
        }

        if (response instanceof ErrorResponse || response instanceof Throwable) {
            notifyError(response);
            return;
        }

        if (response instanceof NormalResponse) {
            NormalResponse normalResponse = (NormalResponse) response;
            notifyNormalResponse(normalResponse.getValue(), normalResponse.getBackupCount());
            return;
        }

        
        invocationFuture.set(response);
    }

    void notifyError(Object error) {
        assert error != null;

        Throwable cause;
        if (error instanceof Throwable) {
            cause = (Throwable) error;
        } else {
            cause = ((ErrorResponse) error).getCause();
        }

        switch (onException(cause)) {
            case CONTINUE_WAIT:
                handleContinueWait();
                break;
            case THROW_EXCEPTION:
                notifyNormalResponse(cause, 0);
                break;
            case RETRY_INVOCATION:
                if (invokeCount < tryCount) {
                    
                    handleRetry(cause);
                } else {
                    
                    notifyNormalResponse(cause, 0);
                }
                break;
            default:
                throw new IllegalStateException("Unhandled ExceptionAction");
        }
    }

    void notifyNormalResponse(Object value, int expectedBackups) {
        if (value == null) {
            value = NULL_RESPONSE;
        }

        
        

        if (expectedBackups > backupsCompleted) {
            
            

            this.pendingResponseReceivedMillis = Clock.currentTimeMillis();

            this.backupsExpected = expectedBackups;

            
            
            this.pendingResponse = value;

            if (backupsCompleted != expectedBackups) {
                
                return;
            }
        }

        
        
        
        invocationFuture.set(value);
    }

    @SuppressFBWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "We have the guarantee that only a single thread at any given time can change the volatile field")
    void notifyCallTimeout() {
        operationService.callTimeoutCount.inc();

        if (logger.isFinestEnabled()) {
            logger.finest("Call timed-out during wait-notify phase, retrying call: " + toString());
        }

        if (op instanceof WaitSupport) {
            
            long waitTimeout = op.getWaitTimeout();
            waitTimeout -= callTimeout;
            op.setWaitTimeout(waitTimeout);
        }

        invokeCount--;
        handleRetry("invocation timeout");
    }

    void notifySingleBackupComplete() {
        int newBackupsCompleted = BACKUPS_COMPLETED.incrementAndGet(this);

        Object pendingResponse = this.pendingResponse;
        if (pendingResponse == null) {
            
            return;
        }

        
        int backupsExpected = this.backupsExpected;
        if (backupsExpected < newBackupsCompleted) {
            
            return;
        }

        if (backupsExpected != newBackupsCompleted) {
            
            return;
        }

        
        
        invocationFuture.set(pendingResponse);
    }

    boolean checkInvocationTimeout() {
        long maxCallTimeout = invocationFuture.getMaxCallTimeout();
        long expirationTime = op.getInvocationTime() + maxCallTimeout;

        boolean hasResponse = pendingResponse != null;
        boolean hasWaitingThreads = invocationFuture.getWaitingThreadsCount() > 0;
        boolean notExpired = maxCallTimeout == Long.MAX_VALUE
                || expirationTime < 0
                || expirationTime >= Clock.currentTimeMillis();

        if (hasResponse || hasWaitingThreads || notExpired) {
            return false;
        }

        operationService.getIsStillRunningService().timeoutInvocationIfNotExecuting(this);
        return true;
    }

    Object newOperationTimeoutException(long totalTimeoutMs) {
        operationService.operationTimeoutCount.inc();

        boolean hasResponse = this.pendingResponse != null;
        int backupsExpected = this.backupsExpected;
        int backupsCompleted = this.backupsCompleted;

        if (hasResponse) {
            return new OperationTimeoutException("No response for " + totalTimeoutMs + " ms."
                    + " Aborting invocation! " + toString()
                    + " Not all backups have completed! "
                    + " backups-expected:" + backupsExpected
                    + " backups-completed: " + backupsCompleted);
        } else {
            return new OperationTimeoutException("No response for " + totalTimeoutMs + " ms."
                    + " Aborting invocation! " + toString()
                    + " No response has been received! "
                    + " backups-expected:" + backupsExpected
                    + " backups-completed: " + backupsCompleted);
        }
    }

    private void handleContinueWait() {
        invocationFuture.set(WAIT_RESPONSE);
    }

    private void handleRetry(Object cause) {
        operationService.retryCount.inc();

        if (invokeCount > LOG_MAX_INVOCATION_COUNT && invokeCount % LOG_INVOCATION_COUNT_MOD == 0) {
            if (logger.isLoggable(WARNING)) {
                logger.warning("Retrying invocation: " + toString() + ", Reason: " + cause);
            }
        }

        operationService.invocationsRegistry.deregister(this);

        if (invocationFuture.interrupted) {
            invocationFuture.set(INTERRUPTED_RESPONSE);
            return;
        }

        invocationFuture.set(WAIT_RESPONSE);
        ExecutionService ex = nodeEngine.getExecutionService();
        
        if (invokeCount < MAX_FAST_INVOCATION_COUNT) {
            operationService.asyncExecutor.execute(this);
        } else {
            ex.schedule(ASYNC_EXECUTOR, this, tryPauseMillis, TimeUnit.MILLISECONDS);
        }
    }

    boolean checkBackupTimeout(long timeoutMillis) {
        
        
        
        boolean allBackupsComplete = backupsExpected == backupsCompleted;
        long responseReceivedMillis = pendingResponseReceivedMillis;

        
        long expirationTime = responseReceivedMillis + timeoutMillis;
        boolean timeout = expirationTime > 0 && expirationTime < Clock.currentTimeMillis();

        
        
        boolean responseReceived = pendingResponse != null;

        if (allBackupsComplete || !responseReceived || !timeout) {
            return false;
        }

        boolean targetDead = nodeEngine.getClusterService().getMember(invTarget) == null;
        if (targetDead) {
            
            
            
            
            
            
            resetAndReInvoke();
            return false;
        }

         
        invocationFuture.set(pendingResponse);
        return true;
    }

    private void resetAndReInvoke() {
        operationService.invocationsRegistry.deregister(this);
        invokeCount = 0;
        pendingResponse = null;
        pendingResponseReceivedMillis = -1;
        backupsExpected = 0;
        backupsCompleted = 0;
        doInvoke(false);
    }

    @Override
    public String toString() {
        String connectionStr = null;
        Address invTarget = this.invTarget;
        if (invTarget != null) {
            ConnectionManager connectionManager = operationService.nodeEngine.getNode().getConnectionManager();
            Connection connection = connectionManager.getConnection(invTarget);
            connectionStr = connection == null ? null : connection.toString();
        }

        StringBuilder sb = new StringBuilder();
        sb.append("Invocation");
        sb.append("{ serviceName='").append(serviceName).append('\'');
        sb.append(", op=").append(op);
        sb.append(", partitionId=").append(partitionId);
        sb.append(", replicaIndex=").append(replicaIndex);
        sb.append(", tryCount=").append(tryCount);
        sb.append(", tryPauseMillis=").append(tryPauseMillis);
        sb.append(", invokeCount=").append(invokeCount);
        sb.append(", callTimeout=").append(callTimeout);
        sb.append(", target=").append(invTarget);
        sb.append(", backupsExpected=").append(backupsExpected);
        sb.append(", backupsCompleted=").append(backupsCompleted);
        sb.append(", connection=").append(connectionStr);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.spi.impl.eventservice.impl;

import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.spi.EventFilter;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.eventservice.InternalEventService;
import com.hazelcast.spi.impl.eventservice.impl.operations.DeregistrationOperation;
import com.hazelcast.spi.impl.eventservice.impl.operations.PostJoinRegistrationOperation;
import com.hazelcast.spi.impl.eventservice.impl.operations.RegistrationOperation;
import com.hazelcast.spi.impl.eventservice.impl.operations.SendEventOperation;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.counters.MwCounter;
import com.hazelcast.util.executor.StripedExecutor;

import java.io.Closeable;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.LinkedList;
import java.util.UUID;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.logging.Level;

import static com.hazelcast.util.EmptyStatement.ignore;
import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;
import static com.hazelcast.util.counters.MwCounter.newMwCounter;

public class EventServiceImpl implements InternalEventService {

    private static final EventRegistration[] EMPTY_REGISTRATIONS = new EventRegistration[0];

    private static final int EVENT_SYNC_FREQUENCY = 100000;
    private static final int SEND_RETRY_COUNT = 50;
    private static final int SEND_EVENT_TIMEOUT_SECONDS = 5;
    private static final int REGISTRATION_TIMEOUT_SECONDS = 5;
    private static final int DEREGISTER_TIMEOUT_SECONDS = 5;
    private static final int WARNING_LOG_FREQUENCY = 1000;

    final ILogger logger;
    final NodeEngineImpl nodeEngine;

    private final ExceptionHandler registrationExceptionHandler;
    private final ExceptionHandler deregistrationExceptionHandler;
    private final ConcurrentMap<String, EventServiceSegment> segments;
    private final StripedExecutor eventExecutor;
    private final int eventQueueTimeoutMs;

    @Probe(name = "threadCount")
    private final int eventThreadCount;
    @Probe(name = "queueCapacity")
    private final int eventQueueCapacity;
    @Probe(name = "totalFailureCount")
    private final MwCounter totalFailures = newMwCounter();
    @Probe(name = "rejectedCount")
    private final MwCounter rejectedCount = newMwCounter();

    public EventServiceImpl(NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.logger = nodeEngine.getLogger(EventService.class.getName());
        final Node node = nodeEngine.getNode();
        GroupProperties groupProperties = node.getGroupProperties();
        this.eventThreadCount = groupProperties.EVENT_THREAD_COUNT.getInteger();
        this.eventQueueCapacity = groupProperties.EVENT_QUEUE_CAPACITY.getInteger();
        this.eventQueueTimeoutMs = groupProperties.EVENT_QUEUE_TIMEOUT_MILLIS.getInteger();
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        this.eventExecutor = new StripedExecutor(
                node.getLogger(EventServiceImpl.class),
                threadGroup.getThreadNamePrefix("event"),
                threadGroup.getInternalThreadGroup(),
                eventThreadCount,
                eventQueueCapacity);
        this.registrationExceptionHandler
                = new FutureUtilExceptionHandler(logger, "Member left while registering listener...");
        this.deregistrationExceptionHandler
                = new FutureUtilExceptionHandler(logger, "Member left while de-registering listener...");
        this.segments = new ConcurrentHashMap<String, EventServiceSegment>();

        nodeEngine.getMetricsRegistry().scanAndRegister(this, "event");
    }

    @Override
    public void close(EventRegistration eventRegistration) {
        Registration registration = (Registration) eventRegistration;

        Object listener = registration.getListener();
        if (!(listener instanceof Closeable)) {
            return;
        }

        try {
            ((Closeable) listener).close();
        } catch (IOException e) {
            EmptyStatement.ignore(e);
        }
    }

    @Override
    public int getEventThreadCount() {
        return eventThreadCount;
    }

    @Override
    public int getEventQueueCapacity() {
        return eventQueueCapacity;
    }

    @Probe(name = "eventQueueSize")
    @Override
    public int getEventQueueSize() {
        return eventExecutor.getWorkQueueSize();
    }

    @Override
    public EventRegistration registerLocalListener(String serviceName, String topic, Object listener) {
        return registerListenerInternal(serviceName, topic, new EmptyFilter(), listener, true);
    }

    @Override
    public EventRegistration registerLocalListener(String serviceName, String topic, EventFilter filter, Object listener) {
        return registerListenerInternal(serviceName, topic, filter, listener, true);
    }

    @Override
    public EventRegistration registerListener(String serviceName, String topic, Object listener) {
        return registerListenerInternal(serviceName, topic, new EmptyFilter(), listener, false);
    }

    @Override
    public EventRegistration registerListener(String serviceName, String topic, EventFilter filter, Object listener) {
        return registerListenerInternal(serviceName, topic, filter, listener, false);
    }

    private EventRegistration registerListenerInternal(String serviceName, String topic, EventFilter filter,
                                                       Object listener, boolean localOnly) {
        if (listener == null) {
            throw new IllegalArgumentException("Listener required!");
        }
        if (filter == null) {
            throw new IllegalArgumentException("EventFilter required!");
        }
        EventServiceSegment segment = getSegment(serviceName, true);
        Registration reg = new Registration(UUID.randomUUID().toString(), serviceName, topic, filter,
                nodeEngine.getThisAddress(), listener, localOnly);
        if (!segment.addRegistration(topic, reg)) {
            return null;
        }

        if (!localOnly) {
            invokeRegistrationOnOtherNodes(serviceName, reg);
        }
        return reg;
    }

    public boolean handleRegistration(Registration reg) {
        if (nodeEngine.getThisAddress().equals(reg.getSubscriber())) {
            return false;
        }
        EventServiceSegment segment = getSegment(reg.getServiceName(), true);
        return segment.addRegistration(reg.getTopic(), reg);
    }

    @Override
    public boolean deregisterListener(String serviceName, String topic, Object id) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            final Registration reg = segment.removeRegistration(topic, String.valueOf(id));
            if (reg != null && !reg.isLocalOnly()) {
                invokeDeregistrationOnOtherNodes(serviceName, topic, String.valueOf(id));
            }
            return reg != null;
        }
        return false;
    }

    @Override
    public void deregisterAllListeners(String serviceName, String topic) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            segment.removeRegistrations(topic);
        }
    }

    private void invokeRegistrationOnOtherNodes(String serviceName, Registration reg) {
        OperationService operationService = nodeEngine.getOperationService();
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        Collection<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                RegistrationOperation operation = new RegistrationOperation(reg);
                Future f = operationService.invokeOnTarget(serviceName, operation, member.getAddress());
                calls.add(f);
            }
        }

        waitWithDeadline(calls, REGISTRATION_TIMEOUT_SECONDS, TimeUnit.SECONDS, registrationExceptionHandler);
    }

    private void invokeDeregistrationOnOtherNodes(String serviceName, String topic, String id) {
        OperationService operationService = nodeEngine.getOperationService();
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        Collection<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                DeregistrationOperation operation = new DeregistrationOperation(topic, id);
                Future f = operationService.invokeOnTarget(serviceName, operation, member.getAddress());
                calls.add(f);
            }
        }

        waitWithDeadline(calls, DEREGISTER_TIMEOUT_SECONDS, TimeUnit.SECONDS, deregistrationExceptionHandler);
    }

    @Override
    public EventRegistration[] getRegistrationsAsArray(String serviceName, String topic) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            final Collection<Registration> registrations = segment.getRegistrations(topic, false);
            if (registrations == null || registrations.isEmpty()) {
                return EMPTY_REGISTRATIONS;
            } else {
                return registrations.toArray(new Registration[registrations.size()]);
            }
        }
        return EMPTY_REGISTRATIONS;
    }

    @Override
    public Collection<EventRegistration> getRegistrations(String serviceName, String topic) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            final Collection<Registration> registrations = segment.getRegistrations(topic, false);
            if (registrations == null || registrations.isEmpty()) {
                return Collections.<EventRegistration>emptySet();
            } else {
                return Collections.<EventRegistration>unmodifiableCollection(registrations);
            }
        }
        return Collections.emptySet();
    }

    @Override
    public boolean hasEventRegistration(String serviceName, String topic) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            return segment.hasRegistration(topic);
        }
        return false;
    }

    @Override
    public void publishEvent(String serviceName, String topic, Object event, int orderKey) {
        Collection<EventRegistration> registrations = getRegistrations(serviceName, topic);
        publishEvent(serviceName, registrations, event, orderKey);
    }

    @Override
    public void publishEvent(String serviceName, EventRegistration registration, Object event, int orderKey) {
        if (!(registration instanceof Registration)) {
            throw new IllegalArgumentException();
        }
        if (isLocal(registration)) {
            executeLocal(serviceName, event, registration, orderKey);
        } else {
            final Address subscriber = registration.getSubscriber();
            sendEventPacket(subscriber, new EventPacket(registration.getId(), serviceName, event), orderKey);
        }
    }

    @Override
    public void publishEvent(String serviceName, Collection<EventRegistration> registrations, Object event, int orderKey) {
        Data eventData = null;
        for (EventRegistration registration : registrations) {
            if (!(registration instanceof Registration)) {
                throw new IllegalArgumentException();
            }
            if (isLocal(registration)) {
                executeLocal(serviceName, event, registration, orderKey);
                continue;
            }

            if (eventData == null) {
                eventData = nodeEngine.toData(event);
            }
            EventPacket eventPacket = new EventPacket(registration.getId(), serviceName, eventData);
            sendEventPacket(registration.getSubscriber(), eventPacket, orderKey);
        }
    }

    @Override
    public void publishRemoteEvent(String serviceName, Collection<EventRegistration> registrations, Object event, int orderKey) {
        if (registrations.isEmpty()) {
            return;
        }
        Data eventData = nodeEngine.toData(event);
        for (EventRegistration registration : registrations) {
            if (!(registration instanceof Registration)) {
                throw new IllegalArgumentException();
            }
            if (isLocal(registration)) {
                continue;
            }
            EventPacket eventPacket = new EventPacket(registration.getId(), serviceName, eventData);
            sendEventPacket(registration.getSubscriber(), eventPacket, orderKey);
        }
    }

    private void executeLocal(String serviceName, Object event, EventRegistration registration, int orderKey) {
        if (nodeEngine.isActive()) {
            Registration reg = (Registration) registration;
            try {
                if (reg.getListener() != null) {
                    eventExecutor.execute(new LocalEventDispatcher(this, serviceName, event, reg.getListener()
                            , orderKey, eventQueueTimeoutMs));
                } else {
                    logger.warning("Something seems wrong! Listener instance is null! -> " + reg);
                }
            } catch (RejectedExecutionException e) {
                rejectedCount.inc();

                if (eventExecutor.isLive()) {
                    logFailure("EventQueue overloaded! %s failed to publish to %s:%s",
                            event, reg.getServiceName(), reg.getTopic());
                }
            }
        }
    }

    private void sendEventPacket(Address subscriber, EventPacket eventPacket, int orderKey) {
        final String serviceName = eventPacket.getServiceName();
        final EventServiceSegment segment = getSegment(serviceName, true);
        boolean sync = segment.incrementPublish() % EVENT_SYNC_FREQUENCY == 0;

        if (sync) {
            SendEventOperation op = new SendEventOperation(eventPacket, orderKey);
            Future f = nodeEngine.getOperationService()
                    .createInvocationBuilder(serviceName, op, subscriber)
                    .setTryCount(SEND_RETRY_COUNT).invoke();
            try {
                f.get(SEND_EVENT_TIMEOUT_SECONDS, TimeUnit.SECONDS);
            } catch (Exception ignored) {
                ignore(ignored);
            }
        } else {
            final Packet packet = new Packet(nodeEngine.toData(eventPacket), orderKey);
            packet.setHeader(Packet.HEADER_EVENT);

            if (!nodeEngine.getPacketTransceiver().transmit(packet, subscriber)) {
                if (nodeEngine.isActive()) {
                    logFailure("IO Queue overloaded! Failed to send event packet to: %s", subscriber);
                }
            }
        }
    }

    public EventServiceSegment getSegment(String service, boolean forceCreate) {
        EventServiceSegment segment = segments.get(service);
        if (segment == null && forceCreate) {
            
            EventServiceSegment newSegment = new EventServiceSegment(service, nodeEngine.getService(service));
            EventServiceSegment existingSegment = segments.putIfAbsent(service, newSegment);
            if (existingSegment == null) {
                segment = newSegment;
                nodeEngine.getMetricsRegistry().scanAndRegister(newSegment, "event." + service);
            } else {
                segment = existingSegment;
            }
        }
        return segment;
    }

    boolean isLocal(EventRegistration reg) {
        return nodeEngine.getThisAddress().equals(reg.getSubscriber());
    }

    @Override
    public void executeEventCallback(Runnable callback) {
        if (nodeEngine.isActive()) {
            try {
                eventExecutor.execute(callback);
            } catch (RejectedExecutionException e) {
                rejectedCount.inc();

                if (eventExecutor.isLive()) {
                    logFailure("EventQueue overloaded! Failed to execute event callback: %s", callback);
                }
            }
        }
    }

    @Override
    public void handleEvent(Packet packet) {
        try {
            eventExecutor.execute(new RemoteEventPacketProcessor(this, packet));
        } catch (RejectedExecutionException e) {
            rejectedCount.inc();

            if (eventExecutor.isLive()) {
                Connection conn = packet.getConn();
                String endpoint = conn.getEndPoint() != null ? conn.getEndPoint().toString() : conn.toString();
                logFailure("EventQueue overloaded! Failed to process event packet sent from: %s", endpoint);
            }
        }
    }

    public PostJoinRegistrationOperation getPostJoinOperation() {
        final Collection<Registration> registrations = new LinkedList<Registration>();
        for (EventServiceSegment segment : segments.values()) {
            
            for (Registration reg : (Iterable<Registration>) segment.getRegistrationIdMap().values()) {
                if (!reg.isLocalOnly()) {
                    registrations.add(reg);
                }
            }
        }
        return registrations.isEmpty() ? null : new PostJoinRegistrationOperation(registrations);
    }

    public void shutdown() {
        logger.finest("Stopping event executor...");
        eventExecutor.shutdown();
        for (EventServiceSegment segment : segments.values()) {
            segment.clear();
        }
        segments.clear();
    }

    public void onMemberLeft(MemberImpl member) {
        final Address address = member.getAddress();
        for (EventServiceSegment segment : segments.values()) {
            segment.onMemberLeft(address);
        }
    }

    private void logFailure(String message, Object... args) {
        totalFailures.inc();

        long total = totalFailures.get();

        
        
        
        Level level = total % WARNING_LOG_FREQUENCY == 0
                ? Level.WARNING : Level.FINEST;

        if (logger.isLoggable(level)) {
            logger.log(level, String.format(message, args));
        }
    }

}

<code block>


package com.hazelcast.spi.impl.eventservice.impl;

import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.EventFilter;
import com.hazelcast.spi.ListenerWrapperEventFilter;
import com.hazelcast.spi.NotifiableEventListener;
import com.hazelcast.util.ConcurrencyUtil;
import com.hazelcast.util.ConstructorFunction;

import java.util.Collection;
import java.util.Collections;
import java.util.Iterator;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.atomic.AtomicLong;

public class EventServiceSegment<S> {

    private final String serviceName;
    private final S service;

    private final ConcurrentMap<String, Collection<Registration>> registrations
            = new ConcurrentHashMap<String, Collection<Registration>>();

    @Probe(name = "listenerCount")
    private final ConcurrentMap<String, Registration> registrationIdMap = new ConcurrentHashMap<String, Registration>();

    @Probe(name = "publicationCount")
    private final AtomicLong totalPublishes = new AtomicLong();

    public EventServiceSegment(String serviceName, S service) {
        this.serviceName = serviceName;
        this.service = service;
    }

    private void pingNotifiableEventListenerIfAvailable(String topic, Registration registration, boolean register) {
        Object listener = registration.getListener();
        if (!(listener instanceof NotifiableEventListener)) {
            EventFilter filter = registration.getFilter();
            if (filter instanceof ListenerWrapperEventFilter) {
                listener = ((ListenerWrapperEventFilter) filter).getListener();
            }
        }
        if (listener instanceof NotifiableEventListener) {
            NotifiableEventListener notifiableEventListener = (NotifiableEventListener) listener;
            if (register) {
                notifiableEventListener.onRegister(service, serviceName, topic, registration);
            } else {
                notifiableEventListener.onDeregister(service, serviceName, topic, registration);
            }
        }
    }

    public Collection<Registration> getRegistrations(String topic, boolean forceCreate) {
        Collection<Registration> listenerList = registrations.get(topic);
        if (listenerList == null && forceCreate) {
            ConstructorFunction<String, Collection<Registration>> func
                    = new ConstructorFunction<String, Collection<Registration>>() {
                public Collection<Registration> createNew(String key) {
                    return Collections.newSetFromMap(new ConcurrentHashMap<Registration, Boolean>());
                }
            };
            return ConcurrencyUtil.getOrPutIfAbsent(registrations, topic, func);
        }
        return listenerList;
    }

    public ConcurrentMap<String, Registration> getRegistrationIdMap() {
        return registrationIdMap;
    }

    public boolean addRegistration(String topic, Registration registration) {
        final Collection<Registration> registrations = getRegistrations(topic, true);
        if (registrations.add(registration)) {
            registrationIdMap.put(registration.getId(), registration);
            pingNotifiableEventListenerIfAvailable(topic, registration, true);
            return true;
        }
        return false;
    }

    public Registration removeRegistration(String topic, String id) {
        final Registration registration = registrationIdMap.remove(id);
        if (registration != null) {
            final Collection<Registration> all = registrations.get(topic);
            if (all != null) {
                all.remove(registration);
            }
            pingNotifiableEventListenerIfAvailable(topic, registration, false);
        }
        return registration;
    }

    void removeRegistrations(String topic) {
        final Collection<Registration> all = registrations.remove(topic);
        if (all != null) {
            for (Registration reg : all) {
                registrationIdMap.remove(reg.getId());
                pingNotifiableEventListenerIfAvailable(topic, reg, false);
            }
        }
    }

    void clear() {
        for (Collection<Registration> all : registrations.values()) {
            Iterator<Registration> iter = all.iterator();
            while (iter.hasNext()) {
                Registration reg = iter.next();
                iter.remove();
                registrationIdMap.remove(reg.getId());
                pingNotifiableEventListenerIfAvailable(reg.getTopic(), reg, false);
            }
        }
    }

    void onMemberLeft(Address address) {
        for (Collection<Registration> all : registrations.values()) {
            Iterator<Registration> iter = all.iterator();
            while (iter.hasNext()) {
                Registration reg = iter.next();
                if (address.equals(reg.getSubscriber())) {
                    iter.remove();
                    registrationIdMap.remove(reg.getId());
                    pingNotifiableEventListenerIfAvailable(reg.getTopic(), reg, false);
                }
            }
        }
    }

    long incrementPublish() {
        return totalPublishes.incrementAndGet();
    }

    boolean hasRegistration(String topic) {
        Collection<Registration> topicRegistrations = registrations.get(topic);
        return !(topicRegistrations == null || topicRegistrations.isEmpty());
    }
}

<code block>


package com.hazelcast.spi.impl.executionservice.impl;

import com.hazelcast.config.ExecutorConfig;
import com.hazelcast.core.ICompletableFuture;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.logging.ILogger;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.executionservice.InternalExecutionService;
import com.hazelcast.util.ConcurrencyUtil;
import com.hazelcast.util.ConstructorFunction;
import com.hazelcast.util.executor.CachedExecutorServiceDelegate;
import com.hazelcast.util.executor.ExecutorType;
import com.hazelcast.util.executor.ManagedExecutorService;
import com.hazelcast.util.executor.NamedThreadPoolExecutor;
import com.hazelcast.util.executor.PoolExecutorThreadFactory;
import com.hazelcast.util.executor.SingleExecutorThreadFactory;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.util.concurrent.Callable;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.RejectedExecutionHandler;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.SynchronousQueue;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.util.EmptyStatement.ignore;

public final class ExecutionServiceImpl implements InternalExecutionService {

    private static final int CORE_POOL_SIZE = 3;
    private static final long KEEP_ALIVE_TIME = 60L;
    private static final long INITIAL_DELAY = 1000;
    private static final long PERIOD = 100;
    private static final int BEGIN_INDEX = 3;
    private static final long AWAIT_TIME = 3;
    private static final int POOL_MULTIPLIER = 2;
    private static final int QUEUE_MULTIPLIER = 100000;

    private final NodeEngineImpl nodeEngine;
    private final ExecutorService cachedExecutorService;
    private final ScheduledExecutorService scheduledExecutorService;
    private final ScheduledExecutorService defaultScheduledExecutorServiceDelegate;
    private final ILogger logger;
    private final CompletableFutureTask completableFutureTask;

    private final ConcurrentMap<String, ManagedExecutorService> executors
            = new ConcurrentHashMap<String, ManagedExecutorService>();

    private final ConstructorFunction<String, ManagedExecutorService> constructor =
            new ConstructorFunction<String, ManagedExecutorService>() {
                @Override
                public ManagedExecutorService createNew(String name) {
                    final ExecutorConfig cfg = nodeEngine.getConfig().findExecutorConfig(name);
                    final int queueCapacity = cfg.getQueueCapacity() <= 0 ? Integer.MAX_VALUE : cfg.getQueueCapacity();
                    return createExecutor(name, cfg.getPoolSize(), queueCapacity, ExecutorType.CACHED);
                }
            };

    private final MetricsRegistry metricsRegistry;

    public ExecutionServiceImpl(NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.metricsRegistry = nodeEngine.getMetricsRegistry();
        final Node node = nodeEngine.getNode();
        logger = node.getLogger(ExecutionService.class.getName());
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        final ThreadFactory threadFactory = new PoolExecutorThreadFactory(threadGroup, "cached");

        cachedExecutorService = new ThreadPoolExecutor(
                CORE_POOL_SIZE, Integer.MAX_VALUE, KEEP_ALIVE_TIME, TimeUnit.SECONDS,
                new SynchronousQueue<Runnable>(), threadFactory, new RejectedExecutionHandler() {
            public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Node is shutting down; discarding the task: " + r);
                }
            }
        }
        );

        scheduledExecutorService = new ScheduledThreadPoolExecutor(1, new SingleExecutorThreadFactory(threadGroup, "scheduled"));
        enableRemoveOnCancelIfAvailable();

        final int coreSize = Runtime.getRuntime().availableProcessors();
        
        register(SYSTEM_EXECUTOR, coreSize, Integer.MAX_VALUE, ExecutorType.CACHED);
        register(SCHEDULED_EXECUTOR, coreSize * POOL_MULTIPLIER, coreSize * QUEUE_MULTIPLIER, ExecutorType.CACHED);
        defaultScheduledExecutorServiceDelegate = getScheduledExecutor(SCHEDULED_EXECUTOR);

        
        completableFutureTask = new CompletableFutureTask();
        scheduleWithFixedDelay(completableFutureTask, INITIAL_DELAY, PERIOD, TimeUnit.MILLISECONDS);
    }

    private void enableRemoveOnCancelIfAvailable() {
        try {
            final Method m = scheduledExecutorService.getClass().getMethod("setRemoveOnCancelPolicy", boolean.class);
            m.invoke(scheduledExecutorService, true);
        } catch (NoSuchMethodException ignored) {
            ignore(ignored);
        } catch (InvocationTargetException ignored) {
            ignore(ignored);
        } catch (IllegalAccessException ignored) {
            ignore(ignored);
        }
    }

    @Override
    public ManagedExecutorService register(String name, int defaultPoolSize, int defaultQueueCapacity,
                                           ExecutorType type) {
        ExecutorConfig cfg = nodeEngine.getConfig().getExecutorConfigs().get(name);

        int poolSize = defaultPoolSize;
        int queueCapacity = defaultQueueCapacity;
        if (cfg != null) {
            poolSize = cfg.getPoolSize();
            if (cfg.getQueueCapacity() <= 0) {
                queueCapacity = Integer.MAX_VALUE;
            } else {
                queueCapacity = cfg.getQueueCapacity();
            }
        }

        final ManagedExecutorService executor = createExecutor(name, poolSize, queueCapacity, type);
        if (executors.putIfAbsent(name, executor) != null) {
            throw new IllegalArgumentException("ExecutorService['" + name + "'] already exists!");
        }

        metricsRegistry.scanAndRegister(executor, "executor." + name);

        return executor;
    }

    private ManagedExecutorService createExecutor(String name, int poolSize, int queueCapacity, ExecutorType type) {
        ManagedExecutorService executor;
        if (type == ExecutorType.CACHED) {
            executor = new CachedExecutorServiceDelegate(nodeEngine, name, cachedExecutorService, poolSize, queueCapacity);
        } else if (type == ExecutorType.CONCRETE) {
            Node node = nodeEngine.getNode();
            String internalName = name.startsWith("hz:") ? name.substring(BEGIN_INDEX) : name;
            HazelcastThreadGroup hazelcastThreadGroup = node.getHazelcastThreadGroup();
            PoolExecutorThreadFactory threadFactory = new PoolExecutorThreadFactory(hazelcastThreadGroup,
                    hazelcastThreadGroup.getThreadPoolNamePrefix(internalName));
            NamedThreadPoolExecutor pool = new NamedThreadPoolExecutor(name, poolSize, poolSize,
                    KEEP_ALIVE_TIME, TimeUnit.SECONDS,
                    new LinkedBlockingQueue<Runnable>(queueCapacity),
                    threadFactory
            );
            pool.allowCoreThreadTimeOut(true);
            executor = pool;
        } else {
            throw new IllegalArgumentException("Unknown executor type: " + type);
        }
        return executor;
    }

    @Override
    public ManagedExecutorService getExecutor(String name) {
        return ConcurrencyUtil.getOrPutIfAbsent(executors, name, constructor);
    }

    @Override
    public <V> ICompletableFuture<V> asCompletableFuture(Future<V> future) {
        if (future == null) {
            throw new IllegalArgumentException("future must not be null");
        }
        if (future instanceof ICompletableFuture) {
            return (ICompletableFuture<V>) future;
        }
        return registerCompletableFuture(future);
    }

    @Override
    public void execute(String name, Runnable command) {
        getExecutor(name).execute(command);
    }

    @Override
    public Future<?> submit(String name, Runnable task) {
        return getExecutor(name).submit(task);
    }

    @Override
    public <T> Future<T> submit(String name, Callable<T> task) {
        return getExecutor(name).submit(task);
    }

    @Override
    public ScheduledFuture<?> schedule(Runnable command, long delay, TimeUnit unit) {
        return defaultScheduledExecutorServiceDelegate.schedule(command, delay, unit);
    }

    @Override
    public ScheduledFuture<?> schedule(String name, Runnable command, long delay, TimeUnit unit) {
        return getScheduledExecutor(name).schedule(command, delay, unit);
    }

    @Override
    public ScheduledFuture<?> scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) {
        return defaultScheduledExecutorServiceDelegate.scheduleAtFixedRate(command, initialDelay, period, unit);
    }

    @Override
    public ScheduledFuture<?> scheduleAtFixedRate(String name, Runnable command, long initialDelay,
                                                  long period, TimeUnit unit) {
        return getScheduledExecutor(name).scheduleAtFixedRate(command, initialDelay, period, unit);
    }

    @Override
    public ScheduledFuture<?> scheduleWithFixedDelay(Runnable command, long initialDelay, long period, TimeUnit unit) {
        return defaultScheduledExecutorServiceDelegate.scheduleWithFixedDelay(command, initialDelay, period, unit);
    }

    @Override
    public ScheduledFuture<?> scheduleWithFixedDelay(String name, Runnable command, long initialDelay,
                                                     long period, TimeUnit unit) {
        return getScheduledExecutor(name).scheduleWithFixedDelay(command, initialDelay, period, unit);
    }

    @Override
    public ScheduledExecutorService getDefaultScheduledExecutor() {
        return defaultScheduledExecutorServiceDelegate;
    }

    @Override
    public ScheduledExecutorService getScheduledExecutor(String name) {
        return new ScheduledExecutorServiceDelegate(scheduledExecutorService, getExecutor(name));
    }

    public void shutdown() {
        logger.finest("Stopping executors...");
        for (ExecutorService executorService : executors.values()) {
            executorService.shutdown();
        }
        scheduledExecutorService.shutdownNow();
        cachedExecutorService.shutdown();
        try {
            scheduledExecutorService.awaitTermination(AWAIT_TIME, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            logger.finest(e);
        }
        try {
            cachedExecutorService.awaitTermination(AWAIT_TIME, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            logger.finest(e);
        }
        executors.clear();
    }

    @Override
    public void shutdownExecutor(String name) {
        final ExecutorService ex = executors.remove(name);
        if (ex != null) {
            ex.shutdown();
        }
    }

    private <V> ICompletableFuture<V> registerCompletableFuture(Future<V> future) {
        CompletableFutureEntry<V> entry = new CompletableFutureEntry<V>(future, nodeEngine);
        completableFutureTask.registerCompletableFutureEntry(entry);
        return entry.completableFuture;
    }
}

<code block>


package com.hazelcast.spi.impl.operationexecutor;

import com.hazelcast.nio.Packet;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;


public interface OperationExecutor {

    
    @Deprecated
    int getRunningOperationCount();

    
    @Deprecated
    int getOperationExecutorQueueSize();

    
    @Deprecated
    int getPriorityOperationExecutorQueueSize();

    
    @Deprecated
    int getResponseQueueSize();

    
    @Deprecated
    int getPartitionOperationThreadCount();

    
    @Deprecated
    int getGenericOperationThreadCount();

    
    OperationRunner[] getPartitionOperationRunners();

    
    OperationRunner[] getGenericOperationRunners();

    
    void execute(Operation op);

    
    void execute(PartitionSpecificRunnable task);

    
    void execute(Packet packet);

    
    void runOnCallingThread(Operation op);

    
    void runOnCallingThreadIfPossible(Operation op);

    
    @Deprecated
    boolean isAllowedToRunInCurrentThread(Operation op);

    
    boolean isOperationThread();

    
    boolean isInvocationAllowedFromCurrentThread(Operation op, boolean isAsync);

    
    void shutdown();

}

<code block>


package com.hazelcast.spi.impl.operationexecutor.classic;

import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.NodeExtension;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Packet;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.spi.impl.operationexecutor.OperationRunner;
import com.hazelcast.util.counters.SwCounter;
import com.hazelcast.util.executor.HazelcastManagedThread;

import java.util.concurrent.TimeUnit;

import static com.hazelcast.instance.OutOfMemoryErrorDispatcher.inspectOutputMemoryError;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;


public abstract class OperationThread extends HazelcastManagedThread {

    final int threadId;
    final ScheduleQueue scheduleQueue;

    
    @Probe
    private final SwCounter processedTotalCount = newSwCounter();
    @Probe
    private final SwCounter processedPacketCount = newSwCounter();
    @Probe
    private final SwCounter processedOperationsCount = newSwCounter();
    @Probe
    private final SwCounter processedPartitionSpecificRunnableCount = newSwCounter();

    private final NodeExtension nodeExtension;
    private final ILogger logger;
    private volatile boolean shutdown;

    
    
    private OperationRunner currentOperationRunner;

    public OperationThread(String name, int threadId, ScheduleQueue scheduleQueue,
                           ILogger logger, HazelcastThreadGroup threadGroup, NodeExtension nodeExtension) {
        super(threadGroup.getInternalThreadGroup(), name);
        setContextClassLoader(threadGroup.getClassLoader());
        this.scheduleQueue = scheduleQueue;
        this.threadId = threadId;
        this.logger = logger;
        this.nodeExtension = nodeExtension;
    }

    @Probe
    int priorityPendingCount() {
        return scheduleQueue.normalSize();
    }

    @Probe
    int normalPendingCount() {
        return scheduleQueue.normalSize();
    }

    public OperationRunner getCurrentOperationRunner() {
        return currentOperationRunner;
    }

    public abstract OperationRunner getOperationRunner(int partitionId);

    @Override
    public final void run() {
        nodeExtension.onThreadStart(this);
        try {
            doRun();
        } catch (Throwable t) {
            inspectOutputMemoryError(t);
            logger.severe(t);
        } finally {
            nodeExtension.onThreadStop(this);
        }
    }

    private void doRun() {
        for (; ; ) {
            Object task;
            try {
                task = scheduleQueue.take();
            } catch (InterruptedException e) {
                if (shutdown) {
                    return;
                }
                continue;
            }

            if (shutdown) {
                return;
            }

            process(task);
        }
    }

    private void process(Object task) {
        processedTotalCount.inc();

        if (task instanceof Operation) {
            processOperation((Operation) task);
            return;
        }

        if (task instanceof Packet) {
            processPacket((Packet) task);
            return;
        }

        if (task instanceof PartitionSpecificRunnable) {
            processPartitionSpecificRunnable((PartitionSpecificRunnable) task);
            return;
        }

        throw new IllegalStateException("Unhandled task type for task:" + task);
    }

    private void processPartitionSpecificRunnable(PartitionSpecificRunnable runnable) {
        processedPartitionSpecificRunnableCount.inc();

        currentOperationRunner = getOperationRunner(runnable.getPartitionId());
        try {
            currentOperationRunner.run(runnable);
        } catch (Throwable e) {
            inspectOutputMemoryError(e);
            logger.severe("Failed to process task: " + runnable + " on " + getName(), e);
        } finally {
            currentOperationRunner = null;
        }
    }

    private void processPacket(Packet packet) {
        processedPacketCount.inc();

        currentOperationRunner = getOperationRunner(packet.getPartitionId());
        try {
            currentOperationRunner.run(packet);
        } catch (Throwable e) {
            inspectOutputMemoryError(e);
            logger.severe("Failed to process packet: " + packet + " on " + getName(), e);
        } finally {
            currentOperationRunner = null;
        }
    }

    private void processOperation(Operation operation) {
        processedOperationsCount.inc();

        currentOperationRunner = getOperationRunner(operation.getPartitionId());
        try {
            currentOperationRunner.run(operation);
        } catch (Throwable e) {
            inspectOutputMemoryError(e);
            logger.severe("Failed to process operation: " + operation + " on " + getName(), e);
        } finally {
            currentOperationRunner = null;
        }
    }

    public final void shutdown() {
        shutdown = true;
        interrupt();
    }

    public final void awaitTermination(int timeout, TimeUnit unit) throws InterruptedException {
        long timeoutMs = unit.toMillis(timeout);
        join(timeoutMs);
    }
}

<code block>


package com.hazelcast.spi.impl.operationexecutor.classic;

import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.NodeExtension;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Packet;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;
import com.hazelcast.spi.impl.operationexecutor.OperationHostileThread;
import com.hazelcast.spi.impl.operationexecutor.OperationRunner;
import com.hazelcast.spi.impl.operationexecutor.OperationRunnerFactory;
import com.hazelcast.spi.impl.operationexecutor.ResponsePacketHandler;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.util.concurrent.TimeUnit;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class ClassicOperationExecutor implements OperationExecutor {

    public static final int TERMINATION_TIMEOUT_SECONDS = 3;

    private final ILogger logger;

    
    private final PartitionOperationThread[] partitionOperationThreads;
    private final OperationRunner[] partitionOperationRunners;

    private final ScheduleQueue genericScheduleQueue;

    
    private final GenericOperationThread[] genericOperationThreads;
    private final OperationRunner[] genericOperationRunners;

    private final ResponseThread responseThread;
    private final ResponsePacketHandler responsePacketHandler;
    private final Address thisAddress;
    private final NodeExtension nodeExtension;
    private final HazelcastThreadGroup threadGroup;
    private final OperationRunner adHocOperationRunner;
    private final MetricsRegistry metricsRegistry;

    public ClassicOperationExecutor(GroupProperties properties,
                                    LoggingService loggerService,
                                    Address thisAddress,
                                    OperationRunnerFactory operationRunnerFactory,
                                    ResponsePacketHandler responsePacketHandler,
                                    HazelcastThreadGroup hazelcastThreadGroup,
                                    NodeExtension nodeExtension,
                                    MetricsRegistry metricsRegistry) {
        this.thisAddress = thisAddress;
        this.nodeExtension = nodeExtension;
        this.threadGroup = hazelcastThreadGroup;
        this.metricsRegistry = metricsRegistry;
        this.logger = loggerService.getLogger(ClassicOperationExecutor.class);
        this.responsePacketHandler = responsePacketHandler;
        this.genericScheduleQueue = new DefaultScheduleQueue();

        this.adHocOperationRunner = operationRunnerFactory.createAdHocRunner();

        this.partitionOperationRunners = initPartitionOperationRunners(properties, operationRunnerFactory);
        this.partitionOperationThreads = initPartitionThreads(properties);

        this.genericOperationRunners = initGenericOperationRunners(properties, operationRunnerFactory);
        this.genericOperationThreads = initGenericThreads();

        this.responseThread = initResponseThread();

        logger.info("Starting with " + genericOperationThreads.length + " generic operation threads and "
                + partitionOperationThreads.length + " partition operation threads.");
    }

    private OperationRunner[] initPartitionOperationRunners(GroupProperties properties, OperationRunnerFactory handlerFactory) {
        OperationRunner[] operationRunners = new OperationRunner[properties.PARTITION_COUNT.getInteger()];
        for (int partitionId = 0; partitionId < operationRunners.length; partitionId++) {
            operationRunners[partitionId] = handlerFactory.createPartitionRunner(partitionId);
        }
        return operationRunners;
    }

    private OperationRunner[] initGenericOperationRunners(GroupProperties properties, OperationRunnerFactory runnerFactory) {
        int genericThreadCount = properties.GENERIC_OPERATION_THREAD_COUNT.getInteger();
        if (genericThreadCount <= 0) {
            
            int coreSize = Runtime.getRuntime().availableProcessors();
            genericThreadCount = Math.max(2, coreSize / 2);
        }

        OperationRunner[] operationRunners = new OperationRunner[genericThreadCount];
        for (int partitionId = 0; partitionId < operationRunners.length; partitionId++) {
            operationRunners[partitionId] = runnerFactory.createGenericRunner();
        }
        return operationRunners;
    }

    private PartitionOperationThread[] initPartitionThreads(GroupProperties properties) {
        int threadCount = properties.PARTITION_OPERATION_THREAD_COUNT.getInteger();
        if (threadCount <= 0) {
            
            int coreSize = Runtime.getRuntime().availableProcessors();
            threadCount = Math.max(2, coreSize);
        }

        PartitionOperationThread[] threads = new PartitionOperationThread[threadCount];
        for (int threadId = 0; threadId < threads.length; threadId++) {
            String threadName = threadGroup.getThreadPoolNamePrefix("partition-operation") + threadId;
            ScheduleQueue scheduleQueue = new DefaultScheduleQueue();

            PartitionOperationThread operationThread = new PartitionOperationThread(threadName, threadId, scheduleQueue, logger,
                    threadGroup, nodeExtension, partitionOperationRunners);

            threads[threadId] = operationThread;
            operationThread.start();

            metricsRegistry.scanAndRegister(operationThread, "operation." + operationThread.getName());
        }

        
        for (int partitionId = 0; partitionId < partitionOperationRunners.length; partitionId++) {
            int threadId = partitionId % threadCount;
            Thread thread = threads[threadId];
            OperationRunner runner = partitionOperationRunners[partitionId];
            runner.setCurrentThread(thread);
        }

        return threads;
    }

    private GenericOperationThread[] initGenericThreads() {
        
        int threadCount = genericOperationRunners.length;
        GenericOperationThread[] threads = new GenericOperationThread[threadCount];

        for (int threadId = 0; threadId < threads.length; threadId++) {
            String threadName = threadGroup.getThreadPoolNamePrefix("generic-operation") + threadId;
            OperationRunner operationRunner = genericOperationRunners[threadId];

            GenericOperationThread operationThread = new GenericOperationThread(
                    threadName, threadId, genericScheduleQueue,
                    logger, threadGroup, nodeExtension, operationRunner);

            threads[threadId] = operationThread;
            operationThread.start();

            operationRunner.setCurrentThread(operationThread);

            metricsRegistry.scanAndRegister(operationThread, "operation." + operationThread.getName());
        }

        return threads;
    }

    private ResponseThread initResponseThread() {
        ResponseThread thread = new ResponseThread(threadGroup, logger, responsePacketHandler);
        thread.start();
        return thread;
    }

    @SuppressFBWarnings({"EI_EXPOSE_REP" })
    @Override
    public OperationRunner[] getPartitionOperationRunners() {
        return partitionOperationRunners;
    }

    @SuppressFBWarnings({"EI_EXPOSE_REP" })
    @Override
    public OperationRunner[] getGenericOperationRunners() {
        return genericOperationRunners;
    }

    @Override
    public boolean isAllowedToRunInCurrentThread(Operation op) {
        checkNotNull(op, "op can't be null");

        Thread currentThread = Thread.currentThread();

        
        if (currentThread instanceof OperationHostileThread) {
            return false;
        }

        int partitionId = op.getPartitionId();
        
        if (partitionId < 0) {
            return true;
        }

        
        if (!(currentThread instanceof PartitionOperationThread)) {
            return false;
        }

        PartitionOperationThread partitionThread = (PartitionOperationThread) currentThread;

        
        
        return toPartitionThreadIndex(partitionId) == partitionThread.threadId;
    }

    @Override
    public boolean isOperationThread() {
        return Thread.currentThread() instanceof OperationThread;
    }

    @Override
    public boolean isInvocationAllowedFromCurrentThread(Operation op, boolean isAsync) {
        checkNotNull(op, "op can't be null");

        Thread currentThread = Thread.currentThread();

        
        if (currentThread instanceof OperationHostileThread) {
            return false;
        }

        
        if (isAsync) {
            return true;
        }

        if (op.getPartitionId() < 0) {
            return true;
        }

        
        if (!(currentThread instanceof PartitionOperationThread)) {
            return true;
        }

        
        
        PartitionOperationThread partitionThread = (PartitionOperationThread) currentThread;
        return toPartitionThreadIndex(op.getPartitionId()) == partitionThread.threadId;
    }

    @Override
    public int getRunningOperationCount() {
        int result = 0;
        for (OperationRunner handler : partitionOperationRunners) {
            if (handler.currentTask() != null) {
                result++;
            }
        }
        for (OperationRunner handler : genericOperationRunners) {
            if (handler.currentTask() != null) {
                result++;
            }
        }
        return result;
    }

    @Override
    public int getOperationExecutorQueueSize() {
        int size = 0;

        for (PartitionOperationThread t : partitionOperationThreads) {
            size += t.scheduleQueue.normalSize();
        }

        size += genericScheduleQueue.normalSize();

        return size;
    }

    @Override
    public int getPriorityOperationExecutorQueueSize() {
        int size = 0;

        for (PartitionOperationThread t : partitionOperationThreads) {
            size += t.scheduleQueue.prioritySize();
        }

        size += genericScheduleQueue.prioritySize();
        return size;
    }

    @Override
    public int getResponseQueueSize() {
        return responseThread.workQueue.size();
    }

    @Override
    public int getPartitionOperationThreadCount() {
        return partitionOperationThreads.length;
    }

    @Override
    public int getGenericOperationThreadCount() {
        return genericOperationThreads.length;
    }

    @Override
    public void execute(Operation op) {
        checkNotNull(op, "op can't be null");

        execute(op, op.getPartitionId(), op.isUrgent());
    }

    @Override
    public void execute(PartitionSpecificRunnable task) {
        checkNotNull(task, "task can't be null");

        execute(task, task.getPartitionId(), false);
    }

    @Override
    public void runOnCallingThreadIfPossible(Operation op) {
        if (isAllowedToRunInCurrentThread(op)) {
            runOnCallingThread(op);
        } else {
            execute(op);
        }
    }

    @Override
    public void execute(Packet packet) {
        checkNotNull(packet, "packet can't be null");
        checkOpPacket(packet);

        if (packet.isHeaderSet(Packet.HEADER_RESPONSE)) {
            
            responseThread.workQueue.add(packet);
        } else {
            
            int partitionId = packet.getPartitionId();
            boolean hasPriority = packet.isUrgent();
            execute(packet, partitionId, hasPriority);
        }
    }

    private void checkOpPacket(Packet packet) {
        if (!packet.isHeaderSet(Packet.HEADER_OP)) {
            throw new IllegalStateException("Packet " + packet + " doesn't have Packet.HEADER_OP set");
        }
    }

    @Override
    public void runOnCallingThread(Operation operation) {
        checkNotNull(operation, "operation can't be null");

        if (!isAllowedToRunInCurrentThread(operation)) {
            throw new IllegalThreadStateException("Operation '" + operation + "' cannot be run in current thread: "
                    + Thread.currentThread());
        }

        OperationRunner operationRunner = getOperationRunner(operation);
        operationRunner.run(operation);
    }

    OperationRunner getOperationRunner(Operation operation) {
        checkNotNull(operation, "operation can't be null");

        if (operation.getPartitionId() >= 0) {
            
            return partitionOperationRunners[operation.getPartitionId()];
        }

        Thread thread = Thread.currentThread();
        if (!(thread instanceof OperationThread)) {
            
            return adHocOperationRunner;
        }

        
        
        
        OperationThread operationThread = (OperationThread) thread;
        return operationThread.getCurrentOperationRunner();
    }

    private void execute(Object task, int partitionId, boolean priority) {
        ScheduleQueue scheduleQueue;

        if (partitionId < 0) {
            scheduleQueue = genericScheduleQueue;
        } else {
            OperationThread partitionOperationThread = partitionOperationThreads[toPartitionThreadIndex(partitionId)];
            scheduleQueue = partitionOperationThread.scheduleQueue;
        }

        if (priority) {
            scheduleQueue.addUrgent(task);
        } else {
            scheduleQueue.add(task);
        }
    }

    public int toPartitionThreadIndex(int partitionId) {
        return partitionId % partitionOperationThreads.length;
    }

    @Override
    public void shutdown() {
        responseThread.shutdown();
        shutdownAll(partitionOperationThreads);
        shutdownAll(genericOperationThreads);
        awaitTermination(partitionOperationThreads);
        awaitTermination(genericOperationThreads);
    }

    private static void shutdownAll(OperationThread[] operationThreads) {
        for (OperationThread thread : operationThreads) {
            thread.shutdown();
        }
    }

    private static void awaitTermination(OperationThread[] operationThreads) {
        for (OperationThread thread : operationThreads) {
            try {
                thread.awaitTermination(TERMINATION_TIMEOUT_SECONDS, TimeUnit.SECONDS);
            } catch (InterruptedException ignored) {
                Thread.currentThread().interrupt();
            }
        }
    }

    @Override
    public String toString() {
        return "ClassicOperationExecutor{"
                + "node=" + thisAddress
                + '}';
    }
}

<code block>


package com.hazelcast.spi.impl.proxyservice.impl;

import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.DistributedObjectListener;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PostJoinAwareService;
import com.hazelcast.spi.ProxyService;
import com.hazelcast.spi.RemoteService;
import com.hazelcast.spi.exception.DistributedObjectDestroyedException;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.proxyservice.InternalProxyService;
import com.hazelcast.spi.impl.proxyservice.impl.operations.DistributedObjectDestroyOperation;
import com.hazelcast.spi.impl.proxyservice.impl.operations.PostJoinProxyOperation;
import com.hazelcast.util.ConstructorFunction;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.FutureUtil.ExceptionHandler;
import com.hazelcast.util.UuidUtil;
import com.hazelcast.util.counters.MwCounter;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.LinkedList;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.logging.Level;

import static com.hazelcast.core.DistributedObjectEvent.EventType.CREATED;
import static com.hazelcast.util.ConcurrencyUtil.getOrPutIfAbsent;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;
import static com.hazelcast.util.Preconditions.checkNotNull;
import static com.hazelcast.util.counters.MwCounter.newMwCounter;

public class ProxyServiceImpl
        implements InternalProxyService, PostJoinAwareService, EventPublishingService<DistributedObjectEventPacket, Object> {

    public static final String SERVICE_NAME = "hz:core:proxyService";

    private static final ExceptionHandler DESTROY_PROXY_EXCEPTION_HANDLER = logAllExceptions(Level.WARNING);

    private static final int TRY_COUNT = 10;
    private static final long DESTROY_TIMEOUT_SECONDS = 30;

    final NodeEngineImpl nodeEngine;
    final ILogger logger;
    final ConcurrentMap<String, DistributedObjectListener> listeners =
            new ConcurrentHashMap<String, DistributedObjectListener>();

    private final ConstructorFunction<String, ProxyRegistry> registryConstructor =
            new ConstructorFunction<String, ProxyRegistry>() {
                public ProxyRegistry createNew(String serviceName) {
                    return new ProxyRegistry(ProxyServiceImpl.this, serviceName);
                }
            };

    private final ConcurrentMap<String, ProxyRegistry> registries =
            new ConcurrentHashMap<String, ProxyRegistry>();

    @Probe(name = "createdCount")
    private final MwCounter createdCounter = newMwCounter();
    @Probe(name = "destroyedCount")
    private final MwCounter destroyedCounter = newMwCounter();

    public ProxyServiceImpl(NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.logger = nodeEngine.getLogger(ProxyService.class.getName());
        nodeEngine.getMetricsRegistry().scanAndRegister(this, "proxy");
    }

    public void init() {
        nodeEngine.getEventService().registerListener(SERVICE_NAME, SERVICE_NAME, new Object());
    }

    @Probe(name = "proxyCount")
    @Override
    public int getProxyCount() {
        int count = 0;
        for (ProxyRegistry registry : registries.values()) {
            count += registry.getProxyCount();
        }

        return count;
    }

    @Override
    public void initializeDistributedObject(String serviceName, String name) {
        checkServiceNameNotNull(serviceName);
        checkObjectNameNotNull(name);

        ProxyRegistry registry = getOrCreateRegistry(serviceName);
        registry.createProxy(name, true, true);
        createdCounter.inc();
    }

    public ProxyRegistry getOrCreateRegistry(String serviceName) {
        return getOrPutIfAbsent(registries, serviceName, registryConstructor);
    }

    @Override
    public DistributedObject getDistributedObject(String serviceName, String name) {
        checkServiceNameNotNull(serviceName);
        checkObjectNameNotNull(name);

        ProxyRegistry registry = getOrCreateRegistry(serviceName);
        return registry.getOrCreateProxy(name, true, true);
    }

    @Override
    public void destroyDistributedObject(String serviceName, String name) {
        checkServiceNameNotNull(serviceName);
        checkObjectNameNotNull(name);

        OperationService operationService = nodeEngine.getOperationService();
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        Collection<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (member.localMember()) {
                continue;
            }

            DistributedObjectDestroyOperation operation = new DistributedObjectDestroyOperation(serviceName, name);
            Future f = operationService.createInvocationBuilder(SERVICE_NAME, operation, member.getAddress())
                    .setTryCount(TRY_COUNT).invoke();
            calls.add(f);
        }

        destroyLocalDistributedObject(serviceName, name, true);

        waitWithDeadline(calls, DESTROY_TIMEOUT_SECONDS, TimeUnit.SECONDS, DESTROY_PROXY_EXCEPTION_HANDLER);
    }

    public void destroyLocalDistributedObject(String serviceName, String name, boolean fireEvent) {
        ProxyRegistry registry = registries.get(serviceName);
        if (registry != null) {
            registry.destroyProxy(name, fireEvent);
            destroyedCounter.inc();
        }
        RemoteService service = nodeEngine.getService(serviceName);
        if (service != null) {
            service.destroyDistributedObject(name);
        }
        String message = "DistributedObject[" + service + " -> " + name + "] has been destroyed!";
        Throwable cause = new DistributedObjectDestroyedException(message);
        nodeEngine.getWaitNotifyService().cancelWaitingOps(serviceName, name, cause);
    }

    @Override
    public Collection<DistributedObject> getDistributedObjects(String serviceName) {
        checkServiceNameNotNull(serviceName);

        Collection<DistributedObject> result = new LinkedList<DistributedObject>();
        ProxyRegistry registry = registries.get(serviceName);
        if (registry != null) {
            registry.getDistributedObjects(result);
        }

        return result;
    }

    @Override
    public Collection<String> getDistributedObjectNames(String serviceName) {
        checkServiceNameNotNull(serviceName);

        ProxyRegistry registry = registries.get(serviceName);
        if (registry == null) {
            return Collections.EMPTY_SET;
        } else {
            return registry.getDistributedObjectNames();
        }
    }

    @Override
    public Collection<DistributedObject> getAllDistributedObjects() {
        Collection<DistributedObject> result = new LinkedList<DistributedObject>();
        for (ProxyRegistry registry : registries.values()) {
            registry.getDistributedObjects(result);
        }
        return result;
    }

    @Override
    public String addProxyListener(DistributedObjectListener distributedObjectListener) {
        String id = UuidUtil.buildRandomUuidString();
        listeners.put(id, distributedObjectListener);
        return id;
    }

    @Override
    public boolean removeProxyListener(String registrationId) {
        return listeners.remove(registrationId) != null;
    }

    @Override
    public void dispatchEvent(final DistributedObjectEventPacket eventPacket, Object ignore) {
        String serviceName = eventPacket.getServiceName();
        if (eventPacket.getEventType() == CREATED) {
            try {
                final ProxyRegistry registry = getOrCreateRegistry(serviceName);
                if (!registry.contains(eventPacket.getName())) {
                    registry.createProxy(eventPacket.getName(), false,
                            true);
                    
                }
            } catch (HazelcastInstanceNotActiveException ignored) {
                EmptyStatement.ignore(ignored);
            }
        } else {
            final ProxyRegistry registry = registries.get(serviceName);
            if (registry != null) {
                registry.destroyProxy(eventPacket.getName(), false);
            }
        }
    }

    @Override
    public Operation getPostJoinOperation() {
        Collection<ProxyInfo> proxies = new LinkedList<ProxyInfo>();
        for (ProxyRegistry registry : registries.values()) {
            registry.getProxyInfos(proxies);
        }
        return proxies.isEmpty() ? null : new PostJoinProxyOperation(proxies);
    }

    public void shutdown() {
        for (ProxyRegistry registry : registries.values()) {
            registry.destroy();
        }
        registries.clear();
        listeners.clear();
    }

    private static String checkServiceNameNotNull(String serviceName) {
        return checkNotNull(serviceName, "Service name is required!");
    }

    private static String checkObjectNameNotNull(String name) {
        return checkNotNull(name, "Object name is required!");
    }
}

<code block>


package com.hazelcast.internal.monitors;

import com.hazelcast.core.Member;
import com.hazelcast.instance.BuildInfo;
import com.hazelcast.instance.BuildInfoProvider;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastInstanceImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.management.dto.SlowOperationDTO;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.renderers.CommaSeparatedKeyValueProbeRenderer;
import com.hazelcast.internal.metrics.renderers.HumanFriendlyProbeRenderer;
import com.hazelcast.internal.metrics.renderers.ProbeRenderer;
import com.hazelcast.logging.ILogger;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.lang.management.ManagementFactory;
import java.lang.management.RuntimeMXBean;
import java.net.InetSocketAddress;
import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.LinkedList;
import java.util.List;
import java.util.Properties;

import static com.hazelcast.nio.IOUtil.closeResource;
import static java.lang.Math.round;
import static java.lang.String.format;
import static java.lang.System.currentTimeMillis;
import static java.lang.System.getProperties;
import static java.lang.System.getProperty;
import static java.util.Collections.sort;

final class PerformanceLogFile {

    private static final int ONE_MB = 1024 * 1024;

    volatile File logFile;

    private final MetricsRegistry metricRegistry;
    private final HazelcastInstanceImpl hazelcastInstance;
    private final InternalOperationService operationService;
    private final ILogger logger;

    private final HeadRenderer headRenderer = new HeadRenderer();
    private final BodyRenderer bodyRenderer;
    private final String pathname;
    private long lastModified;
    private int index;
    private BufferedWriter writer;
    private boolean renderHead;
    private int maxRollingFileCount;
    private int maxRollingFileSizeBytes;

    PerformanceLogFile(PerformanceMonitor performanceMonitor) {
        this.bodyRenderer = new BodyRenderer(performanceMonitor.humanFriendlyFormat);
        this.logger = performanceMonitor.logger;
        this.hazelcastInstance = performanceMonitor.hazelcastInstance;
        Node node = hazelcastInstance.node;
        this.metricRegistry = node.nodeEngine.getMetricsRegistry();
        this.operationService = node.nodeEngine.getOperationService();
        this.pathname = getPathName();
        GroupProperties props = node.getGroupProperties();
        this.maxRollingFileCount = props.PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT.getInteger();

        
        this.maxRollingFileSizeBytes = round(ONE_MB * props.PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE.getFloat());

        if (logger.isFinestEnabled()) {
            logger.finest("max rolling file size: " + maxRollingFileSizeBytes);
            logger.finest("max rolling file count: " + maxRollingFileCount);
        }
    }

    private String getPathName() {
        Member localMember = hazelcastInstance.getCluster().getLocalMember();
        InetSocketAddress address = localMember.getSocketAddress();
        String addressString = address.getHostString().replace(":", "_") + "#" + address.getPort();
        return "performance-" + addressString + "-" + currentTimeMillis() + "-%03d.log";
    }

    void render() {
        try {
            if (logFile == null) {
                logFile = new File(format(pathname, index));
                renderHead = true;
            }

            if (writer == null) {
                writer = new BufferedWriter(new FileWriter(logFile, true));
            }

            if (renderHead) {
                headRenderer.render(writer);
                renderHead = false;
            }

            bodyRenderer.render(writer);
            writer.flush();
            lastModified = logFile.lastModified();

            if (logFile.length() > maxRollingFileSizeBytes) {
                closeResource(writer);
                writer = null;
                logFile = null;
                index++;
                deleteOld();
            }
        } catch (IOException e) {
            logIOError(e);
            logFile = null;
            closeResource(writer);
            writer = null;
        }
    }

    private void logIOError(IOException e) {
        if (logger.isFinestEnabled()) {
            logger.finest("PerformanceMonitor failed to output to file:"
                    + logFile.getAbsolutePath() + " cause:" + e.getMessage(), e);
        } else {
            logger.warning("PerformanceMonitor failed to output to file:"
                    + logFile.getAbsolutePath() + " cause:" + e.getMessage());
        }
    }

    private void deleteOld() {
        File file = new File(format(pathname, index - maxRollingFileCount));
        file.delete();
    }

    
    boolean isRenderingForced() {
        if (logFile == null) {
            return false;
        }

        return logFile.lastModified() != lastModified;
    }

    private final class BodyRenderer {

        private final SimpleDateFormat sdf = new SimpleDateFormat("EEE, d MMM yyyy HH:mm:ss Z");
        private final ProbeRenderer probeRenderer;

        public BodyRenderer(boolean humanFriendlyFormat) {
            probeRenderer = humanFriendlyFormat ? new HumanFriendlyProbeRenderer() : new CommaSeparatedKeyValueProbeRenderer();
        }

        private void render(BufferedWriter writer) throws IOException {
            renderHeader(writer);
            renderMetricsRegistry(writer);
            writer.append("\n\n");
            if (renderSlowOperation(writer)) {
                writer.append("\n\n");
            }
        }

        private void renderHeader(BufferedWriter writer) throws IOException {
            writer.append("================[ Metrics ]============================================\n");
            Calendar calendar = Calendar.getInstance();
            writer.append(sdf.format(calendar.getTime())).append('\n');
            writer.append("------------------------------------------------------------------------\n");
        }

        private void renderMetricsRegistry(BufferedWriter writer) throws IOException {
            metricRegistry.render(probeRenderer);
            writer.append(probeRenderer.getResult());
        }

        private boolean renderSlowOperation(BufferedWriter writer) throws IOException {
            List<SlowOperationDTO> slowOperations = operationService.getSlowOperationDTOs();
            if (slowOperations.isEmpty()) {
                return false;
            }

            writer.append("================[ Slow Operations ]=====================================\n");
            int k = 1;
            for (SlowOperationDTO slowOperation : slowOperations) {
                writer.append("#" + k)
                        .append("\n    " + slowOperation.operation)
                        .append("\n    Invocations: " + slowOperation.totalInvocations)
                        .append("\n    Stacktrace:\n");
                writer.append(slowOperation.stackTrace).append("\n\n");
                k++;
            }
            return true;
        }
    }

    
    private final class HeadRenderer {

        private void render(BufferedWriter writer) throws IOException {
            renderBuildInfo(writer);
            writer.append("\n\n");
            renderSystemProperties(writer);
            writer.append("\n\n");
            renderConfigProperties(writer);
            writer.append("\n\n");
            writer.flush();
        }

        private void renderSystemProperties(BufferedWriter writer) throws IOException {
            writer.append("================[ System Properties ]===================================\n");
            writer.append(format("%-30s  %4s\n", "property", "value"));
            writer.append("------------------------------------------------------------------------\n");
            List keys = new LinkedList();
            keys.addAll(getProperties().keySet());
            sort(keys);

            for (Object key : keys) {
                String keyString = (String) key;
                if (ignore(keyString)) {
                    continue;
                }

                Object value = getProperty(keyString);

                String s = formatKeyValue(keyString, value);
                writer.append(s);
            }

            writer.append(formatKeyValue("jvm.args", getInputArgs()));
        }

        private String getInputArgs() {
            RuntimeMXBean runtimeMxBean = ManagementFactory.getRuntimeMXBean();
            List<String> arguments = runtimeMxBean.getInputArguments();

            StringBuffer sb = new StringBuffer();
            sb.append("jvm.args=");
            for (String argument : arguments) {
                sb.append(argument);
                sb.append(" ");
            }
            return sb.toString();
        }

        private void renderConfigProperties(BufferedWriter writer) throws IOException {
            writer.append("=================[ Hazelcast Config ]===================================\n");
            writer.append(format("%-60s  %4s\n", "property", "value"));
            writer.append("------------------------------------------------------------------------\n");
            List keys = new LinkedList();
            Properties properties = hazelcastInstance.getConfig().getProperties();
            keys.addAll(properties.keySet());
            sort(keys);

            for (Object key : keys) {
                String keyString = (String) key;
                String value = properties.getProperty(keyString);
                writer.append(format("%-60s  %4s\n", keyString, value));
            }
        }

        private void renderBuildInfo(BufferedWriter writer) throws IOException {
            writer.append("====================[ Build Info ]======================================\n");
            writer.append(format("%-30s  %4s\n", "property", "value"));
            writer.append("------------------------------------------------------------------------\n");

            BuildInfo buildInfo = BuildInfoProvider.getBuildInfo();
            writer.append(formatKeyValue("Version", buildInfo.getVersion()));
            writer.append(formatKeyValue("Build", buildInfo.getBuild()));
            writer.append(formatKeyValue("BuildNumber", buildInfo.getBuildNumber()));
            writer.append(formatKeyValue("Revision", buildInfo.getVersion()));
            writer.append(formatKeyValue("Enterprise", buildInfo.isEnterprise()));
        }

        private String formatKeyValue(String keyString, Object value) {
            return format("%-30s  %4s\n", keyString, value);
        }

        private boolean ignore(String systemProperty) {
            if (systemProperty.startsWith("java.awt")) {
                return true;
            }

            if (systemProperty.startsWith("java")
                    || systemProperty.startsWith("hazelcast")
                    || systemProperty.startsWith("sun")
                    || systemProperty.startsWith("os")) {
                return false;
            }

            return true;
        }
    }
}

<code block>


package com.hazelcast.internal.monitors;

import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.internal.metrics.DoubleGauge;
import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.logging.ILogger;
import com.hazelcast.memory.MemoryStats;

import java.util.logging.Level;

import static com.hazelcast.internal.monitors.HealthMonitorLevel.OFF;
import static com.hazelcast.internal.monitors.HealthMonitorLevel.valueOf;
import static com.hazelcast.util.StringUtil.getLineSeperator;
import static java.lang.String.format;
import static java.util.concurrent.TimeUnit.SECONDS;


public class HealthMonitor {

    private static final String[] UNITS = new String[]{"", "K", "M", "G", "T", "P", "E"};
    private static final double PERCENTAGE_MULTIPLIER = 100d;
    private static final double THRESHOLD_PERCENTAGE = 70;

    final HealthMetrics healthMetrics;

    private final ILogger logger;
    private final Node node;
    private final HealthMonitorLevel monitorLevel;
    private final MetricsRegistry metricRegistry;
    private final HealthMonitorThread monitorThread;

    public HealthMonitor(Node node) {
        this.node = node;
        this.logger = node.getLogger(HealthMonitor.class);
        this.metricRegistry = node.nodeEngine.getMetricsRegistry();
        this.monitorLevel = getHealthMonitorLevel();
        this.monitorThread = initMonitorThread();
        this.healthMetrics = new HealthMetrics();
    }

    private HealthMonitorThread initMonitorThread() {
        if (monitorLevel == OFF) {
            return null;
        }

        int delaySeconds = node.getGroupProperties().HEALTH_MONITORING_DELAY_SECONDS.getInteger();
        return new HealthMonitorThread(delaySeconds);
    }

    public HealthMonitor start() {
        if (monitorLevel == OFF) {
            logger.finest("HealthMonitor is disabled");
            return this;
        }

        monitorThread.start();
        logger.finest("HealthMonitor started");
        return this;
    }

    private HealthMonitorLevel getHealthMonitorLevel() {
        GroupProperties properties = node.getGroupProperties();
        String healthMonitorLevelString = properties.HEALTH_MONITORING_LEVEL.getString();
        return valueOf(healthMonitorLevelString);
    }

    private final class HealthMonitorThread extends Thread {
        private final int delaySeconds;
        private boolean performanceLogHint;

        private HealthMonitorThread(int delaySeconds) {
            super(node.getHazelcastThreadGroup().getInternalThreadGroup(),
                    node.getHazelcastThreadGroup().getThreadNamePrefix("HealthMonitor"));
            setDaemon(true);
            this.delaySeconds = delaySeconds;
            this.performanceLogHint = node.getGroupProperties().PERFORMANCE_MONITOR_ENABLED.getBoolean();
        }

        @Override
        public void run() {
            try {
                while (node.isActive()) {
                    switch (monitorLevel) {
                        case NOISY:
                            if (healthMetrics.exceedsThreshold()) {
                                logPerformanceMonitorHint();
                            }
                            logger.log(Level.INFO, healthMetrics.render());
                            break;
                        case SILENT:
                            if (healthMetrics.exceedsThreshold()) {
                                logPerformanceMonitorHint();
                                logger.log(Level.INFO, healthMetrics.render());
                            }
                            break;
                        default:
                            throw new IllegalStateException("unrecognized HealthMonitorLevel:" + monitorLevel);
                    }

                    try {
                        SECONDS.sleep(delaySeconds);
                    } catch (InterruptedException e) {
                        return;
                    }
                }
            } catch (OutOfMemoryError e) {
                OutOfMemoryErrorDispatcher.onOutOfMemory(e);
            } catch (Throwable t) {
                logger.warning("Health Monitor failed", t);
            }
        }

        private void logPerformanceMonitorHint() {
            if (!performanceLogHint) {
                return;
            }

            
            performanceLogHint = false;

            logger.info(
                    "The HealthMonitor has detected a high load on the system. For more detailed information, "
                            + getLineSeperator()
                            + "enable the PerformanceMonitor by adding -D" + GroupProperties.PROP_PERFORMANCE_MONITOR_ENABLED
                            + "=true");
        }
    }

    class HealthMetrics {
        final LongGauge clientEndpointCount
                = metricRegistry.newLongGauge("client.endpoint.count");
        final LongGauge clusterTimeDiff
                = metricRegistry.newLongGauge("cluster.clock.clusterTimeDiff");

        final LongGauge executorAsyncQueueSize
                = metricRegistry.newLongGauge("executor.hz:async.queueSize");
        final LongGauge executorClientQueueSize
                = metricRegistry.newLongGauge("executor.hz:client.queueSize");
        final LongGauge executorClusterQueueSize
                = metricRegistry.newLongGauge("executor.hz:cluster.queueSize");
        final LongGauge executorScheduledQueueSize
                = metricRegistry.newLongGauge("executor.hz:scheduled.queueSize");
        final LongGauge executorSystemQueueSize
                = metricRegistry.newLongGauge("executor.hz:system.queueSize");
        final LongGauge executorIoQueueSize
                = metricRegistry.newLongGauge("executor.hz:io.queueSize");
        final LongGauge executorQueryQueueSize
                = metricRegistry.newLongGauge("executor.hz:query.queueSize");
        final LongGauge executorMapLoadQueueSize
                = metricRegistry.newLongGauge("executor.hz:map-load.queueSize");
        final LongGauge executorMapLoadAllKeysQueueSize
                = metricRegistry.newLongGauge("executor.hz:map-loadAllKeys.queueSize");

        final LongGauge eventQueueSize
                = metricRegistry.newLongGauge("event.eventQueueSize");

        final LongGauge gcMinorCount
                = metricRegistry.newLongGauge("gc.minorCount");
        final LongGauge gcMinorTime
                = metricRegistry.newLongGauge("gc.minorTime");
        final LongGauge gcMajorCount
                = metricRegistry.newLongGauge("gc.majorCount");
        final LongGauge gcMajorTime
                = metricRegistry.newLongGauge("gc.majorTime");
        final LongGauge gcUnknownCount
                = metricRegistry.newLongGauge("gc.unknownCount");
        final LongGauge gcUnknownTime
                = metricRegistry.newLongGauge("gc.unknownTime");

        final LongGauge runtimeAvailableProcessors
                = metricRegistry.newLongGauge("runtime.availableProcessors");
        final LongGauge runtimeMaxMemory
                = metricRegistry.newLongGauge("runtime.maxMemory");
        final LongGauge runtimeFreeMemory
                = metricRegistry.newLongGauge("runtime.freeMemory");
        final LongGauge runtimeAvailableMemory
                = metricRegistry.newLongGauge("runtime.availableMemory");
        final LongGauge runtimeTotalMemory
                = metricRegistry.newLongGauge("runtime.totalMemory");
        final LongGauge runtimeUsedMemory
                = metricRegistry.newLongGauge("runtime.usedMemory");

        final LongGauge threadPeakThreadCount
                = metricRegistry.newLongGauge("thread.peakThreadCount");
        final LongGauge threadThreadCount
                = metricRegistry.newLongGauge("thread.threadCount");

        final DoubleGauge osProcessCpuLoad
                = metricRegistry.newDoubleGauge("os.processCpuLoad");
        final DoubleGauge osSystemLoadAverage
                = metricRegistry.newDoubleGauge("os.systemLoadAverage");
        final DoubleGauge osSystemCpuLoad
                = metricRegistry.newDoubleGauge("os.systemCpuLoad");
        final LongGauge osTotalPhysicalMemorySize
                = metricRegistry.newLongGauge("os.totalPhysicalMemorySize");
        final LongGauge osFreePhysicalMemorySize
                = metricRegistry.newLongGauge("os.freePhysicalMemorySize");
        final LongGauge osTotalSwapSpaceSize
                = metricRegistry.newLongGauge("os.totalSwapSpaceSize");
        final LongGauge osFreeSwapSpaceSize
                = metricRegistry.newLongGauge("os.freeSwapSpaceSize");

        final LongGauge operationServiceExecutorQueueSize
                = metricRegistry.newLongGauge("operation.queue.size");
        final LongGauge operationServiceExecutorPriorityQueueSize
                = metricRegistry.newLongGauge("operation.priority-queue.size");
        final LongGauge operationServiceResponseQueueSize
                = metricRegistry.newLongGauge("operation.response-queue.size");
        final LongGauge operationServiceRunningOperationsCount
                = metricRegistry.newLongGauge("operation.running.count");
        final LongGauge operationServiceCompletedOperationsCount
                = metricRegistry.newLongGauge("operation.completed.count");
        final LongGauge operationServicePendingInvocationsCount
                = metricRegistry.newLongGauge("operation.invocations.pending");
        final DoubleGauge operationServicePendingInvocationsPercentage
                = metricRegistry.newDoubleGauge("operation.invocations.used");

        final LongGauge proxyCount
                = metricRegistry.newLongGauge("proxy.proxyCount");

        final LongGauge tcpConnectionActiveCount
                = metricRegistry.newLongGauge("tcp.connection.activeCount");
        final LongGauge tcpConnectionCount
                = metricRegistry.newLongGauge("tcp.connection.count");
        final LongGauge tcpConnectionClientCount
                = metricRegistry.newLongGauge("tcp.connection.clientCount");

        private final StringBuilder sb = new StringBuilder();
        private double memoryUsedOfTotalPercentage;
        private double memoryUsedOfMaxPercentage;

        public void update() {
            memoryUsedOfTotalPercentage = PERCENTAGE_MULTIPLIER * runtimeUsedMemory.read() / runtimeTotalMemory.read();
            memoryUsedOfMaxPercentage = PERCENTAGE_MULTIPLIER * runtimeUsedMemory.read() / runtimeMaxMemory.read();
        }

        public boolean exceedsThreshold() {
            if (memoryUsedOfMaxPercentage > THRESHOLD_PERCENTAGE) {
                return true;
            }

            if (osProcessCpuLoad.read() > THRESHOLD_PERCENTAGE) {
                return true;
            }

            if (osSystemCpuLoad.read() > THRESHOLD_PERCENTAGE) {
                return true;
            }

            if (operationServicePendingInvocationsPercentage.read() > THRESHOLD_PERCENTAGE) {
                return true;
            }

            return false;
        }

        public String render() {
            sb.setLength(0);
            renderProcessors();
            renderPhysicalMemory();
            renderSwap();
            renderHeap();
            renderNativeMemory();
            renderGc();
            renderLoad();
            renderThread();
            renderCluster();
            renderEvents();
            renderExecutors();
            renderOperationService();
            renderProxy();
            renderClient();
            renderConnection();
            return sb.toString();
        }

        private void renderConnection() {
            sb.append("connection.active.count=")
                    .append(tcpConnectionActiveCount.read()).append(", ");
            sb.append("client.connection.count=")
                    .append(tcpConnectionClientCount.read()).append(", ");
            sb.append("connection.count=")
                    .append(tcpConnectionCount.read());
        }

        private void renderClient() {
            sb.append("clientEndpoint.count=")
                    .append(clientEndpointCount.read()).append(", ");
        }

        private void renderProxy() {
            sb.append("proxy.count=")
                    .append(proxyCount.read()).append(", ");
        }

        private void renderLoad() {
            sb.append("load.process").append('=')
                    .append(format("%.2f", osProcessCpuLoad.read())).append("%, ");
            sb.append("load.system").append('=')
                    .append(format("%.2f", osSystemCpuLoad.read())).append("%, ");

            double value = osSystemLoadAverage.read();
            if (value < 0) {
                sb.append("load.systemAverage").append("=n/a ");
            } else {
                sb.append("load.systemAverage").append('=')
                        .append(format("%.2f", osSystemLoadAverage.read())).append("%, ");
            }
        }

        private void renderProcessors() {
            sb.append("processors=")
                    .append(runtimeAvailableProcessors.read()).append(", ");
        }

        private void renderPhysicalMemory() {
            sb.append("physical.memory.total=")
                    .append(numberToUnit(osTotalPhysicalMemorySize.read())).append(", ");
            sb.append("physical.memory.free=")
                    .append(numberToUnit(osFreePhysicalMemorySize.read())).append(", ");
        }

        private void renderSwap() {
            sb.append("swap.space.total=")
                    .append(numberToUnit(osTotalSwapSpaceSize.read())).append(", ");
            sb.append("swap.space.free=")
                    .append(numberToUnit(osFreeSwapSpaceSize.read())).append(", ");
        }

        private void renderHeap() {
            sb.append("heap.memory.used=")
                    .append(numberToUnit(runtimeUsedMemory.read())).append(", ");
            sb.append("heap.memory.free=")
                    .append(numberToUnit(runtimeFreeMemory.read())).append(", ");
            sb.append("heap.memory.total=")
                    .append(numberToUnit(runtimeTotalMemory.read())).append(", ");
            sb.append("heap.memory.max=")
                    .append(numberToUnit(runtimeMaxMemory.read())).append(", ");
            sb.append("heap.memory.used/total=")
                    .append(percentageString(memoryUsedOfTotalPercentage)).append(", ");
            sb.append("heap.memory.used/max=")
                    .append(percentageString(memoryUsedOfMaxPercentage)).append((", "));
        }

        private void renderEvents() {
            sb.append("event.q.size=")
                    .append(eventQueueSize.read()).append(", ");
        }

        private void renderCluster() {
            sb.append("cluster.timeDiff=")
                    .append(clusterTimeDiff.read()).append(", ");
        }

        private void renderThread() {
            sb.append("thread.count=")
                    .append(threadThreadCount.read()).append(", ");
            sb.append("thread.peakCount=")
                    .append(threadPeakThreadCount.read()).append(", ");
        }

        private void renderGc() {
            sb.append("minor.gc.count=")
                    .append(gcMinorCount.read()).append(", ");
            sb.append("minor.gc.time=")
                    .append(gcMinorTime.read()).append("ms, ");
            sb.append("major.gc.count=")
                    .append(gcMajorCount.read()).append(", ");
            sb.append("major.gc.time=")
                    .append(gcMajorTime.read()).append("ms, ");

            if (gcUnknownCount.read() > 0) {
                sb.append("unknown.gc.count=")
                        .append(gcUnknownCount.read()).append(", ");
                sb.append("unknown.gc.time=")
                        .append(gcUnknownTime.read()).append("ms, ");
            }
        }

        private void renderNativeMemory() {
            MemoryStats memoryStats = node.getNodeExtension().getMemoryStats();
            if (memoryStats.getMaxNativeMemory() <= 0L) {
                return;
            }

            sb.append("native.memory.used=")
                    .append(numberToUnit(memoryStats.getUsedNativeMemory())).append(", ");
            sb.append("native.memory.free=")
                    .append(numberToUnit(memoryStats.getFreeNativeMemory())).append(", ");
            sb.append("native.memory.total=")
                    .append(numberToUnit(memoryStats.getCommittedNativeMemory())).append(", ");
            sb.append("native.memory.max=")
                    .append(numberToUnit(memoryStats.getMaxNativeMemory())).append(", ");
        }

        private void renderExecutors() {
            sb.append("executor.q.async.size=")
                    .append(executorAsyncQueueSize.read()).append(", ");
            sb.append("executor.q.client.size=")
                    .append(executorClientQueueSize.read()).append(", ");
            sb.append("executor.q.query.size=")
                    .append(executorQueryQueueSize.read()).append(", ");
            sb.append("executor.q.scheduled.size=")
                    .append(executorScheduledQueueSize.read()).append(", ");
            sb.append("executor.q.io.size=")
                    .append(executorIoQueueSize.read()).append(", ");
            sb.append("executor.q.system.size=")
                    .append(executorSystemQueueSize.read()).append(", ");
            sb.append("executor.q.operations.size=")
                    .append(operationServiceExecutorQueueSize.read()).append(", ");
            sb.append("executor.q.priorityOperation.size=").
                    append(operationServiceExecutorPriorityQueueSize.read()).append(", ");
            sb.append("operations.completed.count=")
                    .append(operationServiceCompletedOperationsCount.read()).append(", ");
            sb.append("executor.q.mapLoad.size=")
                    .append(executorMapLoadQueueSize.read()).append(", ");
            sb.append("executor.q.mapLoadAllKeys.size=")
                    .append(executorMapLoadAllKeysQueueSize.read()).append(", ");
            sb.append("executor.q.cluster.size=")
                    .append(executorClusterQueueSize.read()).append(", ");
        }


        

        private void renderOperationService() {
            sb.append("executor.q.response.size=")
                    .append(operationServiceResponseQueueSize.read()).append(", ");
            sb.append("operations.running.count=")
                    .append(operationServiceRunningOperationsCount.read()).append(", ");
            sb.append("operations.pending.invocations.percentage=")
                    .append(format("%.2f", operationServicePendingInvocationsPercentage.read())).append("%, ");
            sb.append("operations.pending.invocations.count=")
                    .append(operationServicePendingInvocationsCount.read()).append(", ");
        }
    }

    
    public static String percentageString(double p) {
        return format("%.2f", p) + "%";
    }

    public static String numberToUnit(long number) {
        
        for (int i = 6; i > 0; i--) {
            double step = Math.pow(1024, i); 
            if (number > step) {
                return format("%3.1f%s", number / step, UNITS[i]);
            }
        }
        
        return Long.toString(number);
    }
}

<code block>


package com.hazelcast.internal.monitors;

import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.GroupProperties.GroupProperty;
import com.hazelcast.instance.HazelcastInstanceImpl;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.logging.ILogger;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;


public class PerformanceMonitor {

    final MetricsRegistry metricRegistry;
    final HazelcastInstanceImpl hazelcastInstance;
    final ILogger logger;
    final InternalOperationService operationService;
    final PerformanceLogFile performanceLogFile;
    final boolean humanFriendlyFormat;
    private final Node node;
    private final MonitorThread monitorThread;
    private final boolean enabled;

    public PerformanceMonitor(HazelcastInstanceImpl hazelcastInstance) {
        this.hazelcastInstance = hazelcastInstance;
        this.node = hazelcastInstance.node;
        this.operationService = node.nodeEngine.getOperationService();
        this.logger = node.getLogger(PerformanceMonitor.class);
        this.metricRegistry = hazelcastInstance.node.nodeEngine.getMetricsRegistry();
        this.enabled = node.getGroupProperties().PERFORMANCE_MONITOR_ENABLED.getBoolean();
        this.humanFriendlyFormat = node.getGroupProperties().PERFORMANCE_MONITOR_HUMAN_FRIENDLY_FORMAT.getBoolean();
        this.performanceLogFile = new PerformanceLogFile(this);
        this.monitorThread = initMonitorThread();
    }

    private MonitorThread initMonitorThread() {
        if (!enabled) {
            return null;
        }

        GroupProperties props = node.getGroupProperties();
        int delaySeconds = props.PERFORMANCE_MONITOR_DELAY_SECONDS.getInteger();

        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        return new MonitorThread(threadGroup, delaySeconds);
    }

    public PerformanceMonitor start() {
        if (!enabled) {
            logger.finest("PerformanceMonitor disabled");
            return this;
        }

        logger.info("PerformanceMonitor started");

        GroupProperty slowOperationDetectorEnabled = node.getGroupProperties().SLOW_OPERATION_DETECTOR_ENABLED;
        if (!slowOperationDetectorEnabled.getBoolean()) {
            logger.info("To enable the SlowOperationDetector in the Performance log, set the following property: "
                    + "-D" + slowOperationDetectorEnabled.getName() + "=true");
        }

        monitorThread.start();
        return this;
    }

    private final class MonitorThread extends Thread {
        private static final int DELAY_MILLIS = 1000;
        private final int delaySeconds;

        private MonitorThread(HazelcastThreadGroup threadGroup, int delaySeconds) {
            super(threadGroup.getInternalThreadGroup(), threadGroup.getThreadNamePrefix("PerformanceMonitor"));
            this.delaySeconds = delaySeconds;
        }

        @Override
        public void run() {
            try {
                while (node.isActive()) {
                    performanceLogFile.render();
                    sleep();
                }

                
                performanceLogFile.render();
            } catch (Throwable t) {
                logger.warning(t.getMessage(), t);
            }
        }

        private void sleep() {
            for (int k = 0; k < delaySeconds; k++) {
                try {
                    Thread.sleep(DELAY_MILLIS);
                } catch (InterruptedException e) {
                    
                    return;
                }

                if (performanceLogFile.isRenderingForced()) {
                    logger.info("Detected a request to update the Performance Log");
                    return;
                }
            }
        }
    }
}

<code block>


package com.hazelcast.internal.metrics;


public interface LongProbeFunction<S> extends ProbeFunction {

    
    long get(S source) throws Exception;
}

<code block>


package com.hazelcast.internal.metrics;


public interface ProbeFunction {
}

<code block>


package com.hazelcast.internal.metrics;

import java.lang.annotation.Retention;
import java.lang.annotation.Target;

import static java.lang.annotation.ElementType.FIELD;
import static java.lang.annotation.ElementType.METHOD;
import static java.lang.annotation.RetentionPolicy.RUNTIME;


@Retention(value = RUNTIME)
@Target({FIELD, METHOD })
public @interface Probe {

    
    String name() default "";
}

<code block>


package com.hazelcast.internal.metrics;

import com.hazelcast.internal.metrics.renderers.ProbeRenderer;

import java.util.Set;
import java.util.concurrent.TimeUnit;


public interface MetricsRegistry {

    
    LongGauge newLongGauge(String name);

    
    DoubleGauge newDoubleGauge(String name);

    
    Set<String> getNames();

    
    <S> void scanAndRegister(S source, String namePrefix);

    
    <S> void register(S source, String name, LongProbeFunction<S> probe);

    
    <S> void register(S source, String name, DoubleProbeFunction<S> probe);

    
    <S> void deregister(S source);

    
    void scheduleAtFixedRate(Runnable publisher, long period, TimeUnit timeUnit);

    
    void render(ProbeRenderer renderer);
}

<code block>


package com.hazelcast.internal.metrics;


public interface Metric {

    
    String getName();
}

<code block>


package com.hazelcast.internal.metrics;


public interface DoubleProbeFunction<S> extends ProbeFunction {

    
    double get(S source) throws Exception;
}

<code block>


package com.hazelcast.internal.metrics;


public interface DoubleGauge extends Metric {

    
    double read();
}

<code block>


package com.hazelcast.internal.metrics;


public interface LongGauge extends Metric {

    
    long read();
}

<code block>


package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.LongProbeFunction;

import java.lang.management.ClassLoadingMXBean;
import java.lang.management.ManagementFactory;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class ClassLoadingMetricSet {

    private ClassLoadingMetricSet() {
    }

    
    public static void register(MetricsRegistry metricsRegistry) {
        checkNotNull(metricsRegistry, "metricsRegistry");

        ClassLoadingMXBean mxBean = ManagementFactory.getClassLoadingMXBean();

        metricsRegistry.register(mxBean, "classloading.loadedClassesCount",
                new LongProbeFunction<ClassLoadingMXBean>() {
                    @Override
                    public long get(ClassLoadingMXBean classLoadingMXBean) {
                        return classLoadingMXBean.getLoadedClassCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "classloading.totalLoadedClassesCount",
                new LongProbeFunction<ClassLoadingMXBean>() {
                    @Override
                    public long get(ClassLoadingMXBean classLoadingMXBean) {
                        return classLoadingMXBean.getTotalLoadedClassCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "classloading.unloadedClassCount",
                new LongProbeFunction<ClassLoadingMXBean>() {
                    @Override
                    public long get(ClassLoadingMXBean classLoadingMXBean) {
                        return classLoadingMXBean.getUnloadedClassCount();
                    }
                }
        );
    }
}

<code block>


package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.LongProbeFunction;

import java.lang.management.ManagementFactory;
import java.lang.management.OperatingSystemMXBean;
import java.lang.reflect.Method;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class OperatingSystemMetricsSet {

    private static final double PERCENTAGE_MULTIPLIER = 100d;

    private OperatingSystemMetricsSet() {
    }

    
    public static void register(MetricsRegistry metricsRegistry) {
        checkNotNull(metricsRegistry, "metricsRegistry");

        OperatingSystemMXBean mxBean = ManagementFactory.getOperatingSystemMXBean();

        registerMethod(metricsRegistry, mxBean, "getCommittedVirtualMemorySize", "os.committedVirtualMemorySize");
        registerMethod(metricsRegistry, mxBean, "getFreePhysicalMemorySize", "os.freePhysicalMemorySize");
        registerMethod(metricsRegistry, mxBean, "getFreeSwapSpaceSize", "os.freeSwapSpaceSize");
        registerMethod(metricsRegistry, mxBean, "getProcessCpuTime", "os.processCpuTime");
        registerMethod(metricsRegistry, mxBean, "getTotalPhysicalMemorySize", "os.totalPhysicalMemorySize");
        registerMethod(metricsRegistry, mxBean, "getTotalSwapSpaceSize", "os.totalSwapSpaceSize");
        registerMethod(metricsRegistry, mxBean, "getMaxFileDescriptorCount", "os.maxFileDescriptorCount");
        registerMethod(metricsRegistry, mxBean, "getOpenFileDescriptorCount", "os.openFileDescriptorCount");
        registerMethod(metricsRegistry, mxBean, "getProcessCpuLoad", "os.processCpuLoad");
        registerMethod(metricsRegistry, mxBean, "getSystemCpuLoad", "os.systemCpuLoad");

        metricsRegistry.register(mxBean, "os.systemLoadAverage",
                new DoubleProbeFunction<OperatingSystemMXBean>() {
                    @Override
                    public double get(OperatingSystemMXBean bean) {
                        return PERCENTAGE_MULTIPLIER * bean.getSystemLoadAverage();
                    }
                }
        );
    }


    
    
    static void registerMethod(MetricsRegistry metricsRegistry, Object osBean, String methodName, String name) {
        final Method method = getMethod(osBean, methodName);

        if (method == null) {
            return;
        }

        if (long.class.equals(method.getReturnType())) {
            metricsRegistry.register(osBean, name,
                    new LongProbeFunction() {
                        @Override
                        public long get(Object bean) throws Exception {
                            return (Long) method.invoke(bean);
                        }
                    });
        } else {
            metricsRegistry.register(osBean, name,
                    new DoubleProbeFunction() {
                        @Override
                        public double get(Object bean) throws Exception {
                            return (Double) method.invoke(bean);
                        }
                    });
        }
    }

    
    private static Method getMethod(Object source, String methodName) {
        try {
            Method method = source.getClass().getDeclaredMethod(methodName);
            method.setAccessible(true);
            return method;
        } catch (Exception e) {
            return null;
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.LongProbeFunction;

import java.lang.management.ManagementFactory;
import java.lang.management.ThreadMXBean;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class ThreadMetricSet {

    private ThreadMetricSet() {
    }

    
    public static void register(MetricsRegistry metricsRegistry) {
        checkNotNull(metricsRegistry, "metricsRegistry");

        ThreadMXBean mxBean = ManagementFactory.getThreadMXBean();

        metricsRegistry.register(mxBean, "thread.threadCount", new LongProbeFunction<ThreadMXBean>() {
                    @Override
                    public long get(ThreadMXBean threadMXBean) {
                        return threadMXBean.getThreadCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "thread.peakThreadCount", new LongProbeFunction<ThreadMXBean>() {
                    @Override
                    public long get(ThreadMXBean threadMXBean) {
                        return threadMXBean.getPeakThreadCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "thread.daemonThreadCount", new LongProbeFunction<ThreadMXBean>() {
                    @Override
                    public long get(ThreadMXBean threadMXBean) {
                        return threadMXBean.getDaemonThreadCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "thread.totalStartedThreadCount", new LongProbeFunction<ThreadMXBean>() {
                    @Override
                    public long get(ThreadMXBean threadMXBean) {
                        return threadMXBean.getTotalStartedThreadCount();
                    }
                }
        );
    }
}

<code block>


package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.LongProbeFunction;

import java.lang.management.ManagementFactory;
import java.lang.management.RuntimeMXBean;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class RuntimeMetricSet {

    private RuntimeMetricSet() {
    }

    
    public static void register(MetricsRegistry metricsRegistry) {
        checkNotNull(metricsRegistry, "metricsRegistry");

        Runtime runtime = Runtime.getRuntime();
        RuntimeMXBean mxBean = ManagementFactory.getRuntimeMXBean();

        metricsRegistry.register(runtime, "runtime.freeMemory", new LongProbeFunction<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.freeMemory();
                    }
                }
        );

        metricsRegistry.register(runtime, "runtime.totalMemory", new LongProbeFunction<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.totalMemory();
                    }
                }
        );

        metricsRegistry.register(runtime, "runtime.maxMemory", new LongProbeFunction<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.maxMemory();
                    }
                }
        );

        metricsRegistry.register(runtime, "runtime.usedMemory", new LongProbeFunction<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.totalMemory() - runtime.freeMemory();
                    }
                }
        );

        metricsRegistry.register(runtime, "runtime.availableProcessors", new LongProbeFunction<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.availableProcessors();
                    }
                }
        );

        metricsRegistry.register(mxBean, "runtime.uptime", new LongProbeFunction<RuntimeMXBean>() {
                    @Override
                    public long get(RuntimeMXBean runtimeMXBean) {
                        return runtimeMXBean.getUptime();
                    }
                }
        );
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.LongProbeFunction;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.internal.metrics.ProbeFunction;
import com.hazelcast.util.counters.Counter;

import java.lang.reflect.Field;
import java.util.Collection;
import java.util.Map;
import java.util.concurrent.Semaphore;

import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_COLLECTION;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_COUNTER;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_DOUBLE_NUMBER;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_DOUBLE_PRIMITIVE;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_LONG_NUMBER;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_MAP;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_PRIMITIVE_LONG;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_SEMAPHORE;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.getType;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.isDouble;
import static java.lang.String.format;


abstract class FieldProbe implements ProbeFunction {

    final Probe probe;
    final Field field;
    final int type;

    FieldProbe(Field field, Probe probe, int type) {
        this.field = field;
        this.probe = probe;
        this.type = type;
        field.setAccessible(true);
    }

    void register(MetricsRegistryImpl metricsRegistry, Object source, String namePrefix) {
        String name = getName(namePrefix);
        metricsRegistry.registerInternal(source, name, this);
    }

    private String getName(String namePrefix) {
        String name = field.getName();
        if (!probe.name().equals("")) {
            name = probe.name();
        }

        return namePrefix + "." + name;
    }

    static <S> FieldProbe createFieldProbe(Field field, Probe probe) {
        int type = getType(field.getType());
        if (type == -1) {
            throw new IllegalArgumentException(format("@Probe field '%s' is of an unhandled type", field));
        }

        if (isDouble(type)) {
            return new DoubleFieldProbe<S>(field, probe, type);
        } else {
            return new LongFieldProbe<S>(field, probe, type);
        }
    }

    static class LongFieldProbe<S> extends FieldProbe implements LongProbeFunction<S> {

        public LongFieldProbe(Field field, Probe probe, int type) {
            super(field, probe, type);
        }

        @Override
        public long get(S source) throws Exception {
            switch (type) {
                case TYPE_PRIMITIVE_LONG:
                    return field.getLong(source);
                case TYPE_LONG_NUMBER:
                    Number longNumber = (Number) field.get(source);
                    return longNumber == null ? 0 : longNumber.longValue();
                case TYPE_MAP:
                    Map<?, ?> map = (Map<?, ?>) field.get(source);
                    return map == null ? 0 : map.size();
                case TYPE_COLLECTION:
                    Collection<?> collection = (Collection<?>) field.get(source);
                    return collection == null ? 0 : collection.size();
                case TYPE_COUNTER:
                    Counter counter = (Counter) field.get(source);
                    return counter == null ? 0 : counter.get();
                case TYPE_SEMAPHORE:
                    Semaphore semaphore = (Semaphore) field.get(source);
                    return semaphore == null ? 0 : semaphore.availablePermits();
                default:
                    throw new IllegalStateException("Unhandled type:" + type);
            }
        }
    }

    static class DoubleFieldProbe<S> extends FieldProbe implements DoubleProbeFunction<S> {

        public DoubleFieldProbe(Field field, Probe probe, int type) {
            super(field, probe, type);
        }

        @Override
        public double get(S source) throws Exception {
            switch (type) {
                case TYPE_DOUBLE_PRIMITIVE:
                    return field.getDouble(source);
                case TYPE_DOUBLE_NUMBER:
                    Number doubleNumber = (Number) field.get(source);
                    return doubleNumber == null ? 0 : doubleNumber.doubleValue();
                default:
                    throw new IllegalStateException("Unhandled type:" + type);
            }
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.LongProbeFunction;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.internal.metrics.ProbeFunction;
import com.hazelcast.util.counters.Counter;

import java.lang.reflect.Method;
import java.util.Collection;
import java.util.Map;
import java.util.concurrent.Semaphore;

import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_COLLECTION;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_COUNTER;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_DOUBLE_NUMBER;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_DOUBLE_PRIMITIVE;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_LONG_NUMBER;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_MAP;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_PRIMITIVE_LONG;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.TYPE_SEMAPHORE;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.getType;
import static com.hazelcast.internal.metrics.impl.ProbeUtils.isDouble;
import static java.lang.String.format;


abstract class MethodProbe implements ProbeFunction {

    final Method method;
    final Probe probe;
    final int type;

    MethodProbe(Method method, Probe probe, int type) {
        this.method = method;
        this.probe = probe;
        this.type = type;
        method.setAccessible(true);
    }

    void register(MetricsRegistryImpl metricsRegistry, Object source, String namePrefix) {
        String name = getName(namePrefix);
        metricsRegistry.registerInternal(source, name, this);
    }

    private String getName(String namePrefix) {
        String name = method.getName();
        if (!probe.name().equals("")) {
            name = probe.name();
        }

        return namePrefix + "." + name;
    }

    static <S> MethodProbe createMethodProbe(Method method, Probe probe) {
        int type = getType(method.getReturnType());
        if (type == -1) {
            throw new IllegalArgumentException(format("@Probe method '%s.%s() has an unsupported return type'",
                    method.getDeclaringClass().getName(), method.getName()));
        }

        if (method.getParameterTypes().length != 0) {
            throw new IllegalArgumentException(format("@Probe method '%s.%s' can't have arguments",
                    method.getDeclaringClass().getName(), method.getName()));
        }

        if (isDouble(type)) {
            return new DoubleMethodProbe<S>(method, probe, type);
        } else {
            return new LongMethodProbe<S>(method, probe, type);
        }
    }

    static class LongMethodProbe<S> extends MethodProbe implements LongProbeFunction<S> {

        public LongMethodProbe(Method method, Probe probe, int type) {
            super(method, probe, type);
        }

        @Override
        public long get(S source) throws Exception {
            switch (type) {
                case TYPE_PRIMITIVE_LONG:
                    return ((Number) method.invoke(source)).longValue();
                case TYPE_LONG_NUMBER:
                    Number longNumber = (Number) method.invoke(source);
                    return longNumber == null ? 0 : longNumber.longValue();
                case TYPE_MAP:
                    Map<?, ?> map = (Map<?, ?>) method.invoke(source);
                    return map == null ? 0 : map.size();
                case TYPE_COLLECTION:
                    Collection<?> collection = (Collection<?>) method.invoke(source);
                    return collection == null ? 0 : collection.size();
                case TYPE_COUNTER:
                    Counter counter = (Counter) method.invoke(source);
                    return counter == null ? 0 : counter.get();
                case TYPE_SEMAPHORE:
                    Semaphore semaphore = (Semaphore) method.invoke(source);
                    return semaphore == null ? 0 : semaphore.availablePermits();
                default:
                    throw new IllegalStateException("Unrecognized type:" + type);
            }
        }
    }

    static class DoubleMethodProbe<S> extends MethodProbe implements DoubleProbeFunction<S> {

        public DoubleMethodProbe(Method method, Probe probe, int type) {
            super(method, probe, type);
        }

        @Override
        public double get(S source) throws Exception {
            switch (type) {
                case TYPE_DOUBLE_PRIMITIVE:
                case TYPE_DOUBLE_NUMBER:
                    Number result = (Number) method.invoke(source);
                    return result == null ? 0 : result.doubleValue();
                default:
                    throw new IllegalStateException("Unrecognized type:" + type);
            }
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.internal.metrics.LongProbeFunction;
import com.hazelcast.internal.metrics.ProbeFunction;

class LongGaugeImpl extends AbstractGauge implements LongGauge {

    private static final long DEFAULT_VALUE = 0;

    LongGaugeImpl(MetricsRegistryImpl metricsRegistry, String name) {
        super(metricsRegistry, name);
    }

    @Override
    public long read() {
        ProbeInstance probeInstance = getProbeInstance();

        ProbeFunction function = null;
        Object source = null;

        if (probeInstance != null) {
            function = probeInstance.function;
            source = probeInstance.source;
        }

        if (function == null || source == null) {
            clearProbeInstance();
            return DEFAULT_VALUE;
        }

        try {
            if (function instanceof LongProbeFunction) {
                LongProbeFunction longFunction = (LongProbeFunction) function;
                return longFunction.get(source);
            } else {
                DoubleProbeFunction doubleFunction = (DoubleProbeFunction) function;
                double doubleResult = doubleFunction.get(source);
                return Math.round(doubleResult);
            }
        } catch (Exception e) {
            metricsRegistry.logger.warning("Failed to access probe:" + name, e);
            return DEFAULT_VALUE;
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Metric;

abstract class AbstractGauge implements Metric {

    protected final MetricsRegistryImpl metricsRegistry;
    protected final String name;
    private volatile ProbeInstance probeInstance;

    AbstractGauge(MetricsRegistryImpl metricsRegistry, String name) {
        this.metricsRegistry = metricsRegistry;
        this.name = name;
    }

    @Override
    public String getName() {
        return name;
    }

    void clearProbeInstance() {
        probeInstance = null;
    }

    ProbeInstance getProbeInstance() {
        ProbeInstance probeInstance = this.probeInstance;
        if (probeInstance == null) {
            probeInstance = metricsRegistry.getProbeInstance(name);
            this.probeInstance = probeInstance;
        }
        return probeInstance;
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import static java.lang.Math.abs;
import static java.lang.Math.max;
import static java.lang.System.identityHashCode;


class LockStripe {

    private static final int STRIPE_LENGTH = 20;

    private final Object[] stripe = new Object[STRIPE_LENGTH];

    LockStripe() {
        for (int k = 0; k < stripe.length; k++) {
            stripe[k] = new Object();
        }
    }

    Object getLock(Object source) {
        int hash = identityHashCode(source);

        
        
        hash = max(0, abs(hash));
        return stripe[hash % stripe.length];
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.ProbeFunction;


class ProbeInstance<S> {

    final String name;
    volatile ProbeFunction function;
    volatile S source;

    ProbeInstance(String name, S source, ProbeFunction function) {
        this.name = name;
        this.function = function;
        this.source = source;
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.Comparator;


class SortedProbesInstances extends ArrayList<ProbeInstance> {

    static final Comparator<ProbeInstance> COMPARATOR = new Comparator<ProbeInstance>() {
        @Override
        public int compare(ProbeInstance o1, ProbeInstance o2) {
            return o1.name.compareTo(o2.name);
        }
    };

    final int modCount;

    SortedProbesInstances() {
        this.modCount = 0;
    }

    SortedProbesInstances(Collection<ProbeInstance> values, int modCount) {
        super(values);
        this.modCount = modCount;

        Collections.sort(this, COMPARATOR);
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleGauge;
import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.LongProbeFunction;
import com.hazelcast.internal.metrics.ProbeFunction;

class DoubleGaugeImpl extends AbstractGauge implements DoubleGauge {

    private static final double DEFAULT_VALUE = 0d;

    DoubleGaugeImpl(MetricsRegistryImpl metricsRegistry, String name) {
        super(metricsRegistry, name);
    }

    @Override
    public double read() {
        ProbeInstance probeInstance = getProbeInstance();

        ProbeFunction function = null;
        Object source = null;

        if (probeInstance != null) {
            function = probeInstance.function;
            source = probeInstance.source;
        }

        if (function == null || source == null) {
            clearProbeInstance();
            return DEFAULT_VALUE;
        }

        try {
            if (function instanceof LongProbeFunction) {
                LongProbeFunction longFunction = (LongProbeFunction) function;
                return longFunction.get(source);
            } else {
                DoubleProbeFunction doubleFunction = (DoubleProbeFunction) function;
                return doubleFunction.get(source);
            }
        } catch (Exception e) {
            metricsRegistry.logger.warning("Failed to access probe:" + name, e);
            return DEFAULT_VALUE;
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Probe;

import java.lang.reflect.Field;
import java.lang.reflect.Method;
import java.util.ArrayList;
import java.util.List;

import static com.hazelcast.internal.metrics.impl.ProbeUtils.flatten;
import static com.hazelcast.internal.metrics.impl.FieldProbe.createFieldProbe;
import static com.hazelcast.internal.metrics.impl.MethodProbe.createMethodProbe;


final class SourceMetadata {
    private final List<FieldProbe> fields = new ArrayList<FieldProbe>();
    private final List<MethodProbe> methods = new ArrayList<MethodProbe>();

    SourceMetadata(Class clazz) {
        
        List<Class<?>> classList = new ArrayList<Class<?>>();
        flatten(clazz, classList);

        for (Class flattenedClass : classList) {
            scanFields(flattenedClass);
            scanMethods(flattenedClass);
        }
    }

    void register(MetricsRegistryImpl metricsRegistry, Object source, String namePrefix) {
        for (FieldProbe field : fields) {
            field.register(metricsRegistry, source, namePrefix);
        }

        for (MethodProbe method : methods) {
            method.register(metricsRegistry, source, namePrefix);
        }
    }

    void scanFields(Class<?> clazz) {
        for (Field field : clazz.getDeclaredFields()) {
            Probe probe = field.getAnnotation(Probe.class);

            if (probe == null) {
                continue;
            }

            FieldProbe fieldProbe = createFieldProbe(field, probe);
            fields.add(fieldProbe);
        }
    }

    void scanMethods(Class<?> clazz) {
        for (Method method : clazz.getDeclaredMethods()) {
            Probe probe = method.getAnnotation(Probe.class);

            if (probe == null) {
                continue;
            }

            MethodProbe methodProbe = createMethodProbe(method, probe);
            methods.add(methodProbe);
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.util.counters.Counter;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.Semaphore;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;


final class ProbeUtils {

    static final int TYPE_PRIMITIVE_LONG = 1;
    static final int TYPE_LONG_NUMBER = 2;

    static final int TYPE_DOUBLE_PRIMITIVE = 3;
    static final int TYPE_DOUBLE_NUMBER = 4;

    static final int TYPE_COLLECTION = 5;
    static final int TYPE_MAP = 6;
    static final int TYPE_COUNTER = 7;
    static final int TYPE_SEMAPHORE = 8;

    private static final Map<Class<?>, Integer> TYPES = new HashMap<Class<?>, Integer>();

    static {
        TYPES.put(byte.class, TYPE_PRIMITIVE_LONG);
        TYPES.put(short.class, TYPE_PRIMITIVE_LONG);
        TYPES.put(int.class, TYPE_PRIMITIVE_LONG);
        TYPES.put(long.class, TYPE_PRIMITIVE_LONG);

        TYPES.put(Byte.class, TYPE_LONG_NUMBER);
        TYPES.put(Short.class, TYPE_LONG_NUMBER);
        TYPES.put(Integer.class, TYPE_LONG_NUMBER);
        TYPES.put(Long.class, TYPE_LONG_NUMBER);
        TYPES.put(AtomicInteger.class, TYPE_LONG_NUMBER);
        TYPES.put(AtomicLong.class, TYPE_LONG_NUMBER);

        TYPES.put(double.class, TYPE_DOUBLE_PRIMITIVE);
        TYPES.put(float.class, TYPE_DOUBLE_PRIMITIVE);

        TYPES.put(Double.class, TYPE_DOUBLE_NUMBER);
        TYPES.put(Float.class, TYPE_DOUBLE_NUMBER);

        TYPES.put(Collection.class, TYPE_COLLECTION);
        TYPES.put(Map.class, TYPE_MAP);
        TYPES.put(Counter.class, TYPE_COUNTER);

        TYPES.put(Semaphore.class, TYPE_SEMAPHORE);
    }

    private ProbeUtils() {
    }

    static boolean isDouble(int type) {
        return type == TYPE_DOUBLE_PRIMITIVE || type == TYPE_DOUBLE_NUMBER;
    }

    
    static int getType(Class classType) {
        Integer type = TYPES.get(classType);
        if (type != null) {
            return type;
        }

        List<Class<?>> flattenedClasses = new ArrayList<Class<?>>();

        flatten(classType, flattenedClasses);

        for (Class<?> clazz : flattenedClasses) {
            type = TYPES.get(clazz);
            if (type != null) {
                return type;
            }
        }

        return -1;
    }

    static void flatten(Class clazz, List<Class<?>> result) {
        if (!result.contains(clazz)) {
            result.add(clazz);
        }

        if (clazz.getSuperclass() != null) {
            flatten(clazz.getSuperclass(), result);
        }

        for (Class interfaze : clazz.getInterfaces()) {
            if (!result.contains(interfaze)) {
                result.add(interfaze);
            }

            flatten(interfaze, result);
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleGauge;
import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.LongProbeFunction;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.ProbeFunction;
import com.hazelcast.internal.metrics.metricsets.ClassLoadingMetricSet;
import com.hazelcast.internal.metrics.metricsets.GarbageCollectionMetricSet;
import com.hazelcast.internal.metrics.metricsets.OperatingSystemMetricsSet;
import com.hazelcast.internal.metrics.metricsets.RuntimeMetricSet;
import com.hazelcast.internal.metrics.metricsets.ThreadMetricSet;
import com.hazelcast.internal.metrics.renderers.ProbeRenderer;
import com.hazelcast.logging.ILogger;

import java.util.Collections;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;

import static com.hazelcast.util.Preconditions.checkNotNull;
import static java.lang.String.format;


public class MetricsRegistryImpl implements MetricsRegistry {

    final ILogger logger;

    private final ScheduledExecutorService scheduledExecutorService = new ScheduledThreadPoolExecutor(2);
    private final AtomicInteger modCount = new AtomicInteger();
    private final ConcurrentMap<String, ProbeInstance> probeInstances = new ConcurrentHashMap<String, ProbeInstance>();
    private final ConcurrentMap<Class<?>, SourceMetadata> metadataMap
            = new ConcurrentHashMap<Class<?>, SourceMetadata>();
    private final LockStripe lockStripe = new LockStripe();

    private AtomicReference<SortedProbesInstances> sortedProbeInstance = new AtomicReference<SortedProbesInstances>(
            new SortedProbesInstances()
    );

    
    public MetricsRegistryImpl(ILogger logger) {
        this.logger = checkNotNull(logger, "logger can't be null");

        RuntimeMetricSet.register(this);
        GarbageCollectionMetricSet.register(this);
        OperatingSystemMetricsSet.register(this);
        ThreadMetricSet.register(this);
        ClassLoadingMetricSet.register(this);
    }

    int modCount() {
        return modCount.get();
    }

    @Override
    public Set<String> getNames() {
        Set<String> names = new HashSet<String>(probeInstances.keySet());
        return Collections.unmodifiableSet(names);
    }

    
    SourceMetadata loadSourceMetadata(Class<?> clazz) {
        SourceMetadata metadata = metadataMap.get(clazz);
        if (metadata == null) {
            metadata = new SourceMetadata(clazz);
            SourceMetadata found = metadataMap.putIfAbsent(clazz, metadata);
            metadata = found == null ? metadata : found;
        }

        return metadata;
    }

    @Override
    public <S> void scanAndRegister(S source, String namePrefix) {
        checkNotNull(source, "source can't be null");
        checkNotNull(namePrefix, "namePrefix can't be null");

        SourceMetadata metadata = loadSourceMetadata(source.getClass());
        metadata.register(this, source, namePrefix);
    }

    @Override
    public <S> void register(S source, String name, LongProbeFunction<S> function) {
        checkNotNull(source, "source can't be null");
        checkNotNull(name, "name can't be null");
        checkNotNull(function, "function can't be null");

        registerInternal(source, name, function);
    }

    @Override
    public <S> void register(S source, String name, DoubleProbeFunction<S> function) {
        checkNotNull(source, "source can't be null");
        checkNotNull(name, "name can't be null");
        checkNotNull(function, "function can't be null");

        registerInternal(source, name, function);
    }

    public ProbeInstance getProbeInstance(String name) {
        checkNotNull(name, "name can't be null");

        return probeInstances.get(name);
    }

    <S> void registerInternal(S source, String name, ProbeFunction function) {
        synchronized (lockStripe.getLock(source)) {
            ProbeInstance probeInstance = probeInstances.get(name);
            if (probeInstance == null) {
                probeInstance = new ProbeInstance<S>(name, source, function);
                probeInstances.put(name, probeInstance);
            } else {
                logOverwrite(probeInstance);
            }

            if (logger.isFinestEnabled()) {
                logger.finest("Registered probeInstance " + name);
            }

            probeInstance.source = source;
            probeInstance.function = function;
        }
        modCount.incrementAndGet();
    }

    private void logOverwrite(ProbeInstance probeInstance) {
        if (probeInstance.function != null || probeInstance.source != null) {
            logger.warning(format("Overwriting existing probe '%s'", probeInstance.name));
        }
    }

    @Override
    public LongGaugeImpl newLongGauge(String name) {
        checkNotNull(name, "name can't be null");

        return new LongGaugeImpl(this, name);
    }

    @Override
    public DoubleGauge newDoubleGauge(String name) {
        checkNotNull(name, "name can't be null");

        return new DoubleGaugeImpl(this, name);
    }

    @Override
    public <S> void deregister(S source) {
        checkNotNull(source, "source can't be null");

        boolean changed = false;
        for (Map.Entry<String, ProbeInstance> entry : probeInstances.entrySet()) {
            ProbeInstance probeInstance = entry.getValue();

            if (probeInstance.source != source) {
                continue;
            }

            String name = entry.getKey();

            boolean destroyed = false;
            synchronized (lockStripe.getLock(source)) {
                if (probeInstance.source == source) {
                    changed = true;
                    probeInstances.remove(name);
                    probeInstance.source = null;
                    probeInstance.function = null;
                    destroyed = true;
                }
            }

            if (destroyed && logger.isFinestEnabled()) {
                logger.finest("Destroying probeInstance " + name);
            }
        }

        if (changed) {
            modCount.incrementAndGet();
        }
    }

    @Override
    public void render(ProbeRenderer renderer) {
        checkNotNull(renderer, "renderer can't be null");

        renderer.start();
        for (ProbeInstance probeInstance : getSortedProbeInstances()) {
            render(renderer, probeInstance);
        }
        renderer.finish();
    }

    
    SortedProbesInstances getSortedProbeInstances() {
        SortedProbesInstances sortedProbeInstances = this.sortedProbeInstance.get();
        int lastModCount = modCount.get();
        if (lastModCount == sortedProbeInstances.modCount) {
            return sortedProbeInstances;
        }

        SortedProbesInstances newSortedProbeInstances = new SortedProbesInstances(probeInstances.values(), lastModCount);
        this.sortedProbeInstance.compareAndSet(sortedProbeInstances, newSortedProbeInstances);
        return sortedProbeInstance.get();
    }

    private void render(ProbeRenderer renderer, ProbeInstance probeInstance) {
        ProbeFunction function = probeInstance.function;
        Object source = probeInstance.source;
        String name = probeInstance.name;

        if (function == null || source == null) {
            renderer.renderNoValue(name);
            return;
        }

        try {
            if (function instanceof LongProbeFunction) {
                LongProbeFunction longFunction = (LongProbeFunction) function;
                renderer.renderLong(name, longFunction.get(source));
            } else {
                DoubleProbeFunction doubleFunction = (DoubleProbeFunction) function;
                renderer.renderDouble(name, doubleFunction.get(source));
            }
        } catch (Exception e) {
            renderer.renderException(name, e);
        }
    }

    @Override
    public void scheduleAtFixedRate(final Runnable publisher, long period, TimeUnit timeUnit) {
        scheduledExecutorService.scheduleAtFixedRate(publisher, 0, period, timeUnit);
    }

    public void shutdown() {
        scheduledExecutorService.shutdown();
    }
}

<code block>



package com.hazelcast.internal.metrics.renderers;

<code block>


package com.hazelcast.internal.metrics.renderers;


public class HumanFriendlyProbeRenderer implements ProbeRenderer {

    private final StringBuilder sb = new StringBuilder();

    @Override
    public void start() {
        sb.setLength(0);
    }

    @Override
    public void renderLong(String name, long value) {
        sb.append(name).append('=').append(value).append('\n');
    }

    @Override
    public void renderDouble(String name, double value) {
        sb.append(name).append('=').append(value).append('\n');
    }

    @Override
    public void renderException(String name, Exception e) {
        sb.append(name).append('=').append(e.getMessage()).append('\n');
    }

    @Override
    public void renderNoValue(String name) {
        sb.append(name).append('=').append("NA").append('\n');
    }

    @Override
    public void finish() {
        
    }

    @Override
    public String getResult() {
        return sb.toString();
    }
}

<code block>


package com.hazelcast.internal.metrics.renderers;


public interface ProbeRenderer {

    void start();

    void renderLong(String name, long value);

    void renderDouble(String name, double value);

    void renderException(String name, Exception e);

    void renderNoValue(String name);

    void finish();

    String getResult();
}

<code block>


package com.hazelcast.internal.metrics.renderers;

public class CommaSeparatedKeyValueProbeRenderer implements ProbeRenderer {

    private final StringBuilder sb = new StringBuilder();

    @Override
    public void start() {
        sb.setLength(0);
        sb.append("{").append("time").append("=").append(System.currentTimeMillis());
    }

    @Override
    public void renderLong(String name, long value) {
        sb.append(',').append(name).append('=').append(value);
    }

    @Override
    public void renderDouble(String name, double value) {
        sb.append(',').append(name).append('=').append(value);
    }

    @Override
    public void renderException(String name, Exception e) {
        sb.append(',').append(name).append('=').append("NA");
    }

    @Override
    public void renderNoValue(String name) {
        sb.append(',').append(name).append('=').append("NA");
    }

    @Override
    public void finish() {
        sb.append("}\n");
    }

    @Override
    public String getResult() {
        return sb.toString();
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.ClusterClock;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.util.Clock;


public class ClusterClockImpl implements ClusterClock {

    private final ILogger logger;

    private volatile long clusterTimeDiff = Long.MAX_VALUE;
    private volatile long clusterStartTime = Long.MIN_VALUE;

    public ClusterClockImpl(ILogger logger) {
        this.logger = logger;
    }

    @Probe(name = "clusterTime")
    @Override
    public long getClusterTime() {
        return Clock.currentTimeMillis() + ((clusterTimeDiff == Long.MAX_VALUE) ? 0 : clusterTimeDiff);
    }

    public void setMasterTime(long masterTime) {
        long diff = masterTime - Clock.currentTimeMillis();
        if (logger.isFinestEnabled()) {
            logger.finest("Setting cluster time diff to " + diff + "ms.");
        }
        this.clusterTimeDiff = diff;
    }

    @Probe(name = "clusterTimeDiff")
    @Override
    public long getClusterTimeDiff() {
        return (clusterTimeDiff == Long.MAX_VALUE) ? 0 : clusterTimeDiff;
    }

    @Probe(name = "clusterUpTime")
    @Override
    public long getClusterUpTime() {
        return Clock.currentTimeMillis() - clusterStartTime;
    }

    public void setClusterStartTime(long startTime) {
        if (this.clusterStartTime == Long.MIN_VALUE) {
            this.clusterStartTime = startTime;
        }
    }

    @Probe(name = "localClockTime")
    private long getLocalClockTime() {
        return Clock.currentTimeMillis();
    }

    @Probe(name = "clusterStartTime")
    public long getClusterStartTime() {
        return clusterStartTime;
    }

}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.cluster.MemberAttributeOperationType;
import com.hazelcast.cluster.MemberInfo;
import com.hazelcast.cluster.impl.operations.AuthenticationFailureOperation;
import com.hazelcast.cluster.impl.operations.BeforeJoinCheckFailureOperation;
import com.hazelcast.cluster.impl.operations.ConfigMismatchOperation;
import com.hazelcast.cluster.impl.operations.FinalizeJoinOperation;
import com.hazelcast.cluster.impl.operations.GroupMismatchOperation;
import com.hazelcast.cluster.impl.operations.HeartbeatOperation;
import com.hazelcast.cluster.impl.operations.JoinCheckOperation;
import com.hazelcast.cluster.impl.operations.JoinRequestOperation;
import com.hazelcast.cluster.impl.operations.MasterConfirmationOperation;
import com.hazelcast.cluster.impl.operations.MasterDiscoveryOperation;
import com.hazelcast.cluster.impl.operations.MemberInfoUpdateOperation;
import com.hazelcast.cluster.impl.operations.MemberRemoveOperation;
import com.hazelcast.cluster.impl.operations.PostJoinOperation;
import com.hazelcast.cluster.impl.operations.SetMasterOperation;
import com.hazelcast.cluster.impl.operations.TriggerMemberListPublishOperation;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.InitialMembershipEvent;
import com.hazelcast.core.InitialMembershipListener;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberAttributeEvent;
import com.hazelcast.core.MembershipEvent;
import com.hazelcast.core.MembershipListener;
import com.hazelcast.instance.BuildInfo;
import com.hazelcast.instance.HazelcastInstanceImpl;
import com.hazelcast.instance.LifecycleServiceImpl;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.Packet;
import com.hazelcast.security.Credentials;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.MemberAttributeServiceEvent;
import com.hazelcast.spi.MembershipAwareService;
import com.hazelcast.spi.MembershipServiceEvent;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.SplitBrainHandlerService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.executor.ExecutorType;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import javax.security.auth.login.LoginContext;
import javax.security.auth.login.LoginException;
import java.net.ConnectException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.Date;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.LinkedHashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;

import static com.hazelcast.cluster.impl.operations.FinalizeJoinOperation.FINALIZE_JOIN_MAX_TIMEOUT;
import static com.hazelcast.cluster.impl.operations.FinalizeJoinOperation.FINALIZE_JOIN_TIMEOUT_FACTOR;
import static com.hazelcast.core.LifecycleEvent.LifecycleState.MERGED;
import static com.hazelcast.core.LifecycleEvent.LifecycleState.MERGING;
import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;
import static com.hazelcast.util.Preconditions.checkNotNull;
import static com.hazelcast.util.Preconditions.isNotNull;
import static java.util.Collections.unmodifiableMap;
import static java.util.Collections.unmodifiableSet;

public final class ClusterServiceImpl implements ClusterService, ConnectionListener, ManagedService,
        EventPublishingService<MembershipEvent, MembershipListener> {

    public static final String SERVICE_NAME = "hz:core:clusterService";

    private static final String EXECUTOR_NAME = "hz:cluster";
    private static final int HEARTBEAT_INTERVAL = 500;
    private static final long HEARTBEAT_LOG_THRESHOLD = 10000L;
    private static final int PING_INTERVAL = 5000;

    private final Node node;

    private final NodeEngineImpl nodeEngine;

    private final ILogger logger;

    protected final Address thisAddress;

    protected final MemberImpl thisMember;

    private final long waitMillisBeforeJoin;

    private final long maxWaitMillisBeforeJoin;

    private final long heartbeatInterval;

    private final long maxNoHeartbeatMillis;

    private final long maxNoMasterConfirmationMillis;

    private final boolean icmpEnabled;

    private final int icmpTtl;

    private final int icmpTimeout;

    private final Lock lock = new ReentrantLock();

    private final Set<MemberInfo> setJoins = new LinkedHashSet<MemberInfo>(100);

    private final AtomicReference<Map<Address, MemberImpl>> membersMapRef
            = new AtomicReference<Map<Address, MemberImpl>>(Collections.<Address, MemberImpl>emptyMap());

    private final AtomicReference<Set<MemberImpl>> membersRef = new AtomicReference<Set<MemberImpl>>(Collections.<MemberImpl>emptySet());

    private final AtomicBoolean preparingToMerge = new AtomicBoolean(false);

    private volatile boolean joinInProgress = false;

    @Probe(name = "lastHeartBeat")
    private volatile long lastHeartBeat = 0L;

    private long timeToStartJoin = 0;

    private long firstJoinRequest = 0;

    private final ConcurrentMap<MemberImpl, Long> masterConfirmationTimes = new ConcurrentHashMap<MemberImpl, Long>();

    private final ExceptionHandler whileFinalizeJoinsExceptionHandler;

    private final ClusterClockImpl clusterClock;

    private String clusterId = null;

    public ClusterServiceImpl(final Node node) {
        this.node = node;
        nodeEngine = node.nodeEngine;
        logger = node.getLogger(ClusterService.class.getName());
        clusterClock = new ClusterClockImpl(logger);
        whileFinalizeJoinsExceptionHandler =
                logAllExceptions(logger, "While waiting finalize join calls...", Level.WARNING);
        thisAddress = node.getThisAddress();
        thisMember = node.getLocalMember();
        setMembers(thisMember);
        waitMillisBeforeJoin = node.groupProperties.WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L;
        maxWaitMillisBeforeJoin = node.groupProperties.MAX_WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L;
        long heartbeatIntervalSeconds = node.groupProperties.HEARTBEAT_INTERVAL_SECONDS.getInteger();
        heartbeatIntervalSeconds = heartbeatIntervalSeconds <= 0 ? 1 : heartbeatIntervalSeconds;
        heartbeatInterval = heartbeatIntervalSeconds;
        maxNoHeartbeatMillis = node.groupProperties.MAX_NO_HEARTBEAT_SECONDS.getInteger() * 1000L;
        maxNoMasterConfirmationMillis = node.groupProperties.MAX_NO_MASTER_CONFIRMATION_SECONDS.getInteger() * 1000L;
        icmpEnabled = node.groupProperties.ICMP_ENABLED.getBoolean();
        icmpTtl = node.groupProperties.ICMP_TTL.getInteger();
        icmpTimeout = node.groupProperties.ICMP_TIMEOUT.getInteger();
        node.connectionManager.addConnectionListener(this);

        registerMetrics();
    }

    void registerMetrics() {
        MetricsRegistry metricsRegistry = node.nodeEngine.getMetricsRegistry();
        metricsRegistry.scanAndRegister(clusterClock, "cluster.clock");
        metricsRegistry.scanAndRegister(this, "cluster");
    }

    @Override
    public ClusterClockImpl getClusterClock() {
        return clusterClock;
    }

    @Override
    public String getClusterId() {
        return clusterId;
    }

    public void setClusterId(String clusterId) {
        if (this.clusterId == null) {
            this.clusterId = clusterId;
        }
    }

    @Override
    public void init(final NodeEngine nodeEngine, Properties properties) {
        long mergeFirstRunDelay = node.getGroupProperties().MERGE_FIRST_RUN_DELAY_SECONDS.getLong() * 1000;
        mergeFirstRunDelay = mergeFirstRunDelay <= 0 ? 100 : mergeFirstRunDelay; 

        ExecutionService executionService = nodeEngine.getExecutionService();
        executionService.register(EXECUTOR_NAME, 2, 1000, ExecutorType.CACHED);

        long mergeNextRunDelay = node.getGroupProperties().MERGE_NEXT_RUN_DELAY_SECONDS.getLong() * 1000;
        mergeNextRunDelay = mergeNextRunDelay <= 0 ? 100 : mergeNextRunDelay; 
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new SplitBrainHandler(node),
                mergeFirstRunDelay, mergeNextRunDelay, TimeUnit.MILLISECONDS);

        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                heartBeater();
            }
        }, heartbeatInterval, heartbeatInterval, TimeUnit.SECONDS);

        long masterConfirmationInterval = node.groupProperties.MASTER_CONFIRMATION_INTERVAL_SECONDS.getInteger();
        masterConfirmationInterval = masterConfirmationInterval <= 0 ? 1 : masterConfirmationInterval;
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                sendMasterConfirmation();
            }
        }, masterConfirmationInterval, masterConfirmationInterval, TimeUnit.SECONDS);

        long memberListPublishInterval = node.groupProperties.MEMBER_LIST_PUBLISH_INTERVAL_SECONDS.getInteger();
        memberListPublishInterval = memberListPublishInterval <= 0 ? 1 : memberListPublishInterval;
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                sendMemberListToOthers();
            }
        }, memberListPublishInterval, memberListPublishInterval, TimeUnit.SECONDS);
    }

    public boolean isJoinInProgress() {
        if (joinInProgress) {
            return true;
        }

        lock.lock();
        try {
            return joinInProgress || !setJoins.isEmpty();
        } finally {
            lock.unlock();
        }
    }

    public JoinRequest checkJoinInfo(Address target) {
        Future f = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME,
                new JoinCheckOperation(node.createJoinRequest()), target)
                .setTryCount(1).invoke();
        try {
            return (JoinRequest) nodeEngine.toObject(f.get());
        } catch (Exception e) {
            logger.warning("Error during join check!", e);
        }
        return null;
    }

    public boolean validateJoinMessage(JoinMessage joinMessage) throws Exception {
        boolean valid = Packet.VERSION == joinMessage.getPacketVersion();
        if (valid) {
            try {
                ConfigCheck newMemberConfigCheck = joinMessage.getConfigCheck();
                ConfigCheck clusterConfigCheck = node.createConfigCheck();
                valid = clusterConfigCheck.isCompatible(newMemberConfigCheck);
            } catch (Exception e) {
                final String message = "Invalid join request from: " + joinMessage.getAddress() + ", reason:" + e.getMessage();
                logger.warning(message);
                throw e;
            }
        }
        return valid;
    }

    private boolean isValidJoinMessage(JoinMessage joinMessage) {
        boolean validJoinRequest;
        try {
            validJoinRequest = validateJoinMessage(joinMessage);
        } catch (ConfigMismatchException e) {
            throw e;
        } catch (Exception e) {
            validJoinRequest = false;
        }
        return validJoinRequest;
    }

    private void logIfConnectionToEndpointIsMissing(long now, MemberImpl member) {
        if ((now - member.getLastRead()) >= PING_INTERVAL && (now - member.getLastPing()) >= PING_INTERVAL) {
            Connection conn = node.connectionManager.getOrConnect(member.getAddress());
            if (conn == null || !conn.isAlive()) {
                logger.warning("This node does not have a connection to " + member);
            }
        }
    }

    private void heartBeater() {
        if (!node.joined() || !node.isActive()) {
            return;
        }

        long now = Clock.currentTimeMillis();

        
        long clockJump = 0L;
        if (lastHeartBeat != 0L) {
            clockJump = now - lastHeartBeat - TimeUnit.SECONDS.toMillis(heartbeatInterval);
            if (Math.abs(clockJump) > HEARTBEAT_LOG_THRESHOLD) {
                SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS");
                logger.info("System clock apparently jumped from " + sdf.format(new Date(lastHeartBeat)) + " to " +
                        sdf.format(new Date(now)) + " since last heartbeat (" + String.format("%+d", clockJump) + "ms).");
            }
            clockJump = Math.max(0L, clockJump);

            if (clockJump >= maxNoMasterConfirmationMillis / 2) {
                logger.warning(
                        "Resetting master confirmation timestamps because of huge system clock jump! " + "Clock-Jump: "
                                + clockJump + "ms, Master-Confirmation-Timeout: " + maxNoMasterConfirmationMillis
                                + "ms.");
                resetMemberMasterConfirmations();
            }
        }
        lastHeartBeat = now;

        if (node.isMaster()) {
            heartBeaterMaster(now, clockJump);
        } else {
            heartBeaterSlave(now, clockJump);
        }
    }

    private void heartBeaterMaster(long now, long clockJump) {
        Collection<MemberImpl> members = getMemberList();
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    logIfConnectionToEndpointIsMissing(now, member);
                    if (removeMemberIfNotHeartBeating(now - clockJump, member)) {
                        continue;
                    }

                    if (removeMemberIfMasterConfirmationExpired(now - clockJump, member)) {
                        continue;
                    }

                    pingMemberIfRequired(now, member);
                    sendHearBeatIfRequired(now, member);
                } catch (Throwable e) {
                    logger.severe(e);
                }
            }
        }
    }

    private boolean removeMemberIfNotHeartBeating(long now, MemberImpl member) {
        if ((now - member.getLastRead()) > maxNoHeartbeatMillis) {
            logger.warning("Removing " + member + " because it has not sent any heartbeats for " +
                    maxNoHeartbeatMillis + " ms.");
            removeAddress(member.getAddress());
            return true;
        }
        return false;
    }

    private boolean removeMemberIfMasterConfirmationExpired(long now, MemberImpl member) {
        Long lastConfirmation = masterConfirmationTimes.get(member);
        if (lastConfirmation == null ||
                (now - lastConfirmation > maxNoMasterConfirmationMillis)) {
            logger.warning("Removing " + member + " because it has not sent any master confirmation " +
                    " for " + maxNoMasterConfirmationMillis + " ms.");
            removeAddress(member.getAddress());
            return true;
        }
        return false;
    }

    private void heartBeaterSlave(long now, long clockJump) {
        Collection<MemberImpl> members = getMemberList();

        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    logIfConnectionToEndpointIsMissing(now, member);

                    if (isMaster(member)) {
                        if (removeMemberIfNotHeartBeating(now - clockJump, member)) {
                            continue;
                        }
                    }

                    pingMemberIfRequired(now, member);
                    sendHearBeatIfRequired(now, member);
                } catch (Throwable e) {
                    logger.severe(e);
                }
            }
        }
    }

    private boolean isMaster(MemberImpl member) {
        return member.getAddress().equals(getMasterAddress());
    }

    private void sendHearBeatIfRequired(long now, MemberImpl member) {
        if ((now - member.getLastWrite()) > HEARTBEAT_INTERVAL) {
            sendHeartbeat(member.getAddress());
        }
    }

    private void pingMemberIfRequired(long now, MemberImpl member) {
        if ((now - member.getLastRead()) >= PING_INTERVAL && (now - member.getLastPing()) >= PING_INTERVAL) {
            ping(member);
        }
    }

    private void ping(final MemberImpl memberImpl) {
        memberImpl.didPing();
        if (!icmpEnabled) {
            return;
        }
        nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
            public void run() {
                try {
                    final Address address = memberImpl.getAddress();
                    logger.warning(thisAddress + " will ping " + address);
                    for (int i = 0; i < 5; i++) {
                        try {
                            if (address.getInetAddress().isReachable(null, icmpTtl, icmpTimeout)) {
                                logger.info(thisAddress + " pings successfully. Target: " + address);
                                return;
                            }
                        } catch (ConnectException ignored) {
                            
                            
                        }
                    }
                    logger.warning(thisAddress + " couldn't ping " + address);
                    
                    removeAddress(address);
                } catch (Throwable ignored) {
                }
            }
        });
    }

    private void sendHeartbeat(Address target) {
        if (target == null) return;
        try {
            node.nodeEngine.getOperationService().send(new HeartbeatOperation(), target);
        } catch (Exception e) {
            if (logger.isFinestEnabled()) {
                logger.finest("Error while sending heartbeat -> "
                        + e.getClass().getName() + "[" + e.getMessage() + "]");
            }
        }
    }

    private void sendMasterConfirmation() {
        if (!node.joined() || !node.isActive() || isMaster()) {
            return;
        }
        final Address masterAddress = getMasterAddress();
        if (masterAddress == null) {
            logger.finest("Could not send MasterConfirmation, master is null!");
            return;
        }
        final MemberImpl masterMember = getMember(masterAddress);
        if (masterMember == null) {
            logger.finest("Could not send MasterConfirmation, master is null!");
            return;
        }
        if (logger.isFinestEnabled()) {
            logger.finest("Sending MasterConfirmation to " + masterMember);
        }
        nodeEngine.getOperationService().send(new MasterConfirmationOperation(), masterAddress);
    }

    
    private void resetMemberMasterConfirmations() {
        final Collection<MemberImpl> memberList = getMemberList();
        for (MemberImpl member : memberList) {
            masterConfirmationTimes.put(member, Clock.currentTimeMillis());
        }
    }


    public void sendMemberListToMember(Address target) {
        if (!isMaster()) {
            return;
        }
        if (thisAddress.equals(target)) {
            return;
        }
        final Collection<MemberImpl> members = getMemberList();
        MemberInfoUpdateOperation op = new MemberInfoUpdateOperation(
                createMemberInfoList(members), clusterClock.getClusterTime(), false);
        nodeEngine.getOperationService().send(op, target);
    }

    private void sendMemberListToOthers() {
        if (!isMaster()) {
            return;
        }
        final Collection<MemberImpl> members = getMemberList();
        MemberInfoUpdateOperation op = new MemberInfoUpdateOperation(
                createMemberInfoList(members), clusterClock.getClusterTime(), false);
        for (MemberImpl member : members) {
            if (member.equals(thisMember)) {
                continue;
            }
            nodeEngine.getOperationService().send(op, member.getAddress());
        }
    }

    public void removeAddress(Address deadAddress) {
        doRemoveAddress(deadAddress, true);
    }

    private void doRemoveAddress(Address deadAddress, boolean destroyConnection) {
        if (preparingToMerge.get()) {
            logger.warning("Cluster-merge process is ongoing, won't process member removal: " + deadAddress);
            return;
        }
        if (!node.joined()) {
            return;
        }
        if (deadAddress.equals(thisAddress)) {
            return;
        }
        lock.lock();
        try {
            if (deadAddress.equals(node.getMasterAddress())) {
                assignNewMaster();
            }
            if (node.isMaster()) {
                setJoins.remove(new MemberInfo(deadAddress));
                resetMemberMasterConfirmations();
            }
            final Connection conn = node.connectionManager.getConnection(deadAddress);
            if (destroyConnection && conn != null) {
                node.connectionManager.destroyConnection(conn);
            }
            MemberImpl deadMember = getMember(deadAddress);
            if (deadMember != null) {
                removeMember(deadMember);
                logger.info(membersString());
            }
        } finally {
            lock.unlock();
        }
    }

    private void assignNewMaster() {
        final Address oldMasterAddress = node.getMasterAddress();
        if (node.joined()) {
            final Collection<MemberImpl> members = getMemberList();
            MemberImpl newMaster = null;
            final int size = members.size();
            if (size > 1) {
                final Iterator<MemberImpl> iter = members.iterator();
                final MemberImpl member = iter.next();
                if (member.getAddress().equals(oldMasterAddress)) {
                    newMaster = iter.next();
                } else {
                    logger.severe("Old master " + oldMasterAddress
                            + " is dead but the first of member list is a different member " +
                            member + "!");
                    newMaster = member;
                }
            } else {
                logger.warning("Old master is dead and this node is not master " +
                        "but member list contains only " + size + " members! -> " + members);
            }
            logger.info("Master " + oldMasterAddress + " left the cluster. Assigning new master " + newMaster);
            if (newMaster != null) {
                node.setMasterAddress(newMaster.getAddress());
            } else {
                node.setMasterAddress(null);
            }
        } else {
            node.setMasterAddress(null);
        }
        if (logger.isFinestEnabled()) {
            logger.finest("Now Master " + node.getMasterAddress());
        }
    }

    public void answerMasterQuestion(JoinMessage joinMessage) {
        if (!ensureValidConfiguration(joinMessage)) {
            return;
        }

        if (node.getMasterAddress() != null) {
            sendMasterAnswer(joinMessage.getAddress());
        } else {
            if (logger.isFinestEnabled()) {
                logger.finest("Received a master question from " + joinMessage.getAddress()
                        + ", but this node is not master itself or doesn't have a master yet!");
            }
        }
    }

    public void handleJoinRequest(JoinRequest joinRequest, Connection connection) {
        if (!node.joined() || !node.isActive()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Node is not ready to process join request...");
            }
            return;
        }

        if (!ensureValidConfiguration(joinRequest)) {
            return;
        }

        Address target = joinRequest.getAddress();
        boolean isRequestFromCurrentMaster = target.equals(node.getMasterAddress());
        
        
        if (!node.isMaster() && !isRequestFromCurrentMaster) {
            sendMasterAnswer(target);
            return;
        }

        if (joinInProgress) {
            if (logger.isFinestEnabled()) {
                logger.finest("Join is in-progress. Cannot handle join request from "
                        + target + " at the moment.");
            }
            return;
        }

        lock.lock();
        try {
            if (isJoinRequestFromAnExistingMember(joinRequest, connection)) {
                return;
            }

            long now = Clock.currentTimeMillis();
            if (logger.isFinestEnabled()) {
                String msg = "Handling join from " + target + ", inProgress: " + joinInProgress
                        + (timeToStartJoin > 0 ? ", timeToStart: " + (timeToStartJoin - now) : "");
                logger.finest(msg);
            }

            MemberInfo memberInfo = new MemberInfo(target, joinRequest.getUuid(),
                    joinRequest.getAttributes());

            if (!setJoins.contains(memberInfo)) {
                try {
                    checkSecureLogin(joinRequest, memberInfo);
                } catch (Exception e) {
                    ILogger securityLogger = node.loggingService.getLogger("com.hazelcast.security");
                    sendAuthenticationFailure(target);
                    securityLogger.severe(e);
                    return;
                }
            }

            if (node.isMaster()) {
                try {
                    node.getNodeExtension().beforeJoin();
                } catch (Exception e) {
                    logger.warning(e.getMessage());
                    sendBeforeJoinCheckFailure(target, e.getMessage());
                    return;
                }
            }

            if (firstJoinRequest == 0) {
                firstJoinRequest = now;
            }

            if (setJoins.add(memberInfo)) {
                sendMasterAnswer(target);
                if (now - firstJoinRequest < maxWaitMillisBeforeJoin) {
                    timeToStartJoin = now + waitMillisBeforeJoin;
                }
            }
            if (now > timeToStartJoin) {
                startJoin();
            }
        } finally {
            lock.unlock();
        }
    }

    private boolean ensureValidConfiguration(JoinMessage joinMessage) {
        try {
            if (isValidJoinMessage(joinMessage)) {
                return true;
            }

            logger.warning("Received an invalid join request from " + joinMessage.getAddress()
                    + ", cause: clusters part of different cluster-groups");

            nodeEngine.getOperationService().send(new GroupMismatchOperation(), joinMessage.getAddress());
        } catch (ConfigMismatchException e) {
            logger.warning("Received an invalid join request from " + joinMessage.getAddress()
                    + ", cause:" + e.getMessage());
            sendConfigurationMismatchFailure(joinMessage.getAddress(), e.getMessage());
        }
        return false;
    }

    private void sendAuthenticationFailure(Address target) {
        nodeEngine.getOperationService().send(new AuthenticationFailureOperation(), target);
    }

    private void sendBeforeJoinCheckFailure(Address target, String message) {
        nodeEngine.getOperationService().send(new BeforeJoinCheckFailureOperation(message), target);
    }

    private void sendConfigurationMismatchFailure(Address target, String msg) {
        OperationService operationService = nodeEngine.getOperationService();
        operationService.send(new ConfigMismatchOperation(msg), target);
    }

    private void checkSecureLogin(JoinRequest joinRequest, MemberInfo newMemberInfo) {
        if (node.securityContext != null && !setJoins.contains(newMemberInfo)) {
            Credentials cr = joinRequest.getCredentials();
            if (cr == null) {
                throw new SecurityException("Expecting security credentials " +
                        "but credentials could not be found in JoinRequest!");
            }

            try {
                LoginContext lc = node.securityContext.createMemberLoginContext(cr);
                lc.login();
            } catch (LoginException e) {
                throw new SecurityException(
                        "Authentication has failed for " + cr.getPrincipal() + '@' + cr.getEndpoint()
                                + " => (" + e.getMessage() + ")");
            }
        }
    }

    private boolean isJoinRequestFromAnExistingMember(JoinRequest joinRequest, Connection connection) {
        MemberImpl member = getMember(joinRequest.getAddress());
        if (member == null) {
            return false;
        }

        Address target = member.getAddress();
        if (joinRequest.getUuid().equals(member.getUuid())) {
            if (node.isMaster()) {
                if (logger.isFinestEnabled()) {
                    String message = "Ignoring join request, member already exists.. => " + joinRequest;
                    logger.finest(message);
                }
                
                final Operation[] postJoinOps = nodeEngine.getPostJoinOperations();
                final PostJoinOperation postJoinOp = postJoinOps != null && postJoinOps.length > 0
                        ? new PostJoinOperation(postJoinOps) : null;

                Operation op = new FinalizeJoinOperation(createMemberInfoList(getMemberList()), postJoinOp,
                        clusterClock.getClusterTime(), false);
                nodeEngine.getOperationService().send(op, target);
            } else {
                sendMasterAnswer(target);
            }
            return true;
        }

        
        
        
        
        if (node.isMaster() || target.equals(node.getMasterAddress())) {
            logger.warning("New join request has been received from an existing endpoint! => " + member
                    + " Removing old member and processing join request...");

            doRemoveAddress(target, false);
            Connection existing = node.connectionManager.getConnection(target);
            if (existing != connection) {
                node.connectionManager.destroyConnection(existing);
                node.connectionManager.registerConnection(target, connection);
            }
            return false;
        }
        return true;
    }

    private void sendMasterAnswer(Address target) {
        Address masterAddress = node.getMasterAddress();
        if (masterAddress == null) {
            logger.info("Cannot send master answer to " + target + " since master node is not known yet");
            return;
        }
        SetMasterOperation op = new SetMasterOperation(masterAddress);
        nodeEngine.getOperationService().send(op, target);
    }

    public void handleMaster(Address masterAddress, Address callerAddress) {
        if (node.joined()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Ignoring master response: " + masterAddress + " from: " + callerAddress
                        + ". This node is already joined...");
            }
            return;
        }

        if (node.getThisAddress().equals(masterAddress)) {
            if (node.isMaster()) {
                logger.finest("Ignoring master response: " + masterAddress + " from: " + callerAddress
                        + ". This node is already master...");
            } else {
                node.setAsMaster();
            }
            return;
        }

        lock.lock();
        try {
            if (logger.isFinestEnabled()) {
                logger.finest("Handling master response: " + masterAddress + " from: " + callerAddress);
            }
            final Address currentMaster = node.getMasterAddress();
            if (currentMaster == null || currentMaster.equals(masterAddress)) {
                setMasterAndJoin(masterAddress);
            } else if (currentMaster.equals(callerAddress)) {
                logger.info("Setting master to: " + masterAddress + ", since "
                        + currentMaster + " says it's not master anymore.");
                setMasterAndJoin(masterAddress);
            } else {
                final Connection conn = node.connectionManager.getConnection(currentMaster);
                if (conn != null && conn.isAlive()) {
                    logger.info("Ignoring master response: " + masterAddress + " from: " + callerAddress
                            + ", since this node has an active master: " + currentMaster);
                    sendJoinRequest(currentMaster, true);
                } else {
                    logger.warning("Ambiguous master response, this node has a master: " + currentMaster
                            + ", but doesn't have a connection to. " + callerAddress + " sent master response as: "
                            + masterAddress + ". Master field will be unset now...");
                    node.setMasterAddress(null);
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void setMasterAndJoin(Address masterAddress) {
        node.setMasterAddress(masterAddress);
        node.connectionManager.getOrConnect(masterAddress);
        if (!sendJoinRequest(masterAddress, true)) {
            logger.warning("Could not create connection to possible master " + masterAddress);
        }
    }

    public void acceptMasterConfirmation(MemberImpl member) {
        if (member != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("MasterConfirmation has been received from " + member);
            }
            masterConfirmationTimes.put(member, Clock.currentTimeMillis());
        }
    }

    public void prepareToMerge(final Address newTargetAddress) {
        preparingToMerge.set(true);
        node.getJoiner().setTargetAddress(newTargetAddress);
        nodeEngine.getExecutionService().schedule(new Runnable() {
            public void run() {
                merge(newTargetAddress);
            }
        }, 10, TimeUnit.SECONDS);
    }

    public void merge(Address newTargetAddress) {
        if (preparingToMerge.compareAndSet(true, false)) {
            node.getJoiner().setTargetAddress(newTargetAddress);
            final LifecycleServiceImpl lifecycleService = node.hazelcastInstance.getLifecycleService();
            lifecycleService.runUnderLifecycleLock(new Runnable() {
                public void run() {
                    lifecycleService.fireLifecycleEvent(MERGING);
                    final NodeEngineImpl nodeEngine = node.nodeEngine;
                    final Collection<SplitBrainHandlerService> services = nodeEngine
                            .getServices(SplitBrainHandlerService.class);
                    final Collection<Runnable> tasks = new LinkedList<Runnable>();
                    for (SplitBrainHandlerService service : services) {
                        final Runnable runnable = service.prepareMergeRunnable();
                        if (runnable != null) {
                            tasks.add(runnable);
                        }
                    }
                    final Collection<ManagedService> managedServices = nodeEngine.getServices(ManagedService.class);
                    for (ManagedService service : managedServices) {
                        service.reset();
                    }
                    node.onRestart();
                    node.nodeEngine.reset();
                    node.connectionManager.restart();
                    node.rejoin();
                    final Collection<Future> futures = new LinkedList<Future>();
                    for (Runnable task : tasks) {
                        Future f = nodeEngine.getExecutionService().submit("hz:system", task);
                        futures.add(f);
                    }
                    long callTimeout = node.groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong();
                    for (Future f : futures) {
                        try {
                            waitOnFutureInterruptible(f, callTimeout, TimeUnit.MILLISECONDS);
                        } catch (HazelcastInstanceNotActiveException e) {
                            EmptyStatement.ignore(e);
                        } catch (Exception e) {
                            logger.severe("While merging...", e);
                        }
                    }
                    if (node.isActive() && node.joined()) {
                        lifecycleService.fireLifecycleEvent(MERGED);
                    }
                }
            });
        }
    }

    private <V> V waitOnFutureInterruptible(Future<V> future, long timeout, TimeUnit timeUnit)
            throws ExecutionException, InterruptedException, TimeoutException {

        isNotNull(timeUnit, "timeUnit");
        long deadline = Clock.currentTimeMillis() + timeUnit.toMillis(timeout);
        while (true) {
            long localTimeout = Math.min(1000 * 10, deadline);
            try {
                return future.get(localTimeout, TimeUnit.MILLISECONDS);
            } catch (TimeoutException te) {
                deadline -= localTimeout;
                if (deadline <= 0) {
                    throw te;
                }
                if (!node.isActive()) {
                    future.cancel(true);
                    throw new HazelcastInstanceNotActiveException();
                }
            }
        }
    }

    private void joinReset() {
        lock.lock();
        try {
            joinInProgress = false;
            setJoins.clear();
            timeToStartJoin = Clock.currentTimeMillis() + waitMillisBeforeJoin;
            firstJoinRequest = 0;
        } finally {
            lock.unlock();
        }
    }

    @Override
    public void reset() {
        lock.lock();
        try {
            joinInProgress = false;
            setJoins.clear();
            timeToStartJoin = 0;
            setMembersRef(Collections.singletonMap(thisAddress, thisMember));
            masterConfirmationTimes.clear();
        } finally {
            lock.unlock();
        }
    }

    private void startJoin() {
        logger.finest("Starting Join.");
        lock.lock();
        try {
            try {
                joinInProgress = true;
                
                node.getPartitionService().pauseMigration();
                final Collection<MemberImpl> members = getMemberList();
                final Collection<MemberInfo> memberInfos = createMemberInfoList(members);
                for (MemberInfo memberJoining : setJoins) {
                    memberInfos.add(memberJoining);
                }
                final long time = clusterClock.getClusterTime();
                
                
                final Operation[] postJoinOps = nodeEngine.getPostJoinOperations();
                final PostJoinOperation postJoinOp = postJoinOps != null && postJoinOps.length > 0
                        ? new PostJoinOperation(postJoinOps) : null;
                final int count = members.size() - 1 + setJoins.size();
                final List<Future> calls = new ArrayList<Future>(count);
                for (MemberInfo member : setJoins) {
                    final long startTime = clusterClock.getClusterStartTime();
                    calls.add(invokeClusterOperation(new FinalizeJoinOperation(memberInfos, postJoinOp, time,
                            clusterId, startTime), member.getAddress()));
                }
                for (MemberImpl member : members) {
                    if (!member.getAddress().equals(thisAddress)) {
                        calls.add(invokeClusterOperation(new MemberInfoUpdateOperation(memberInfos, time, true), member.getAddress()));
                    }
                }
                updateMembers(memberInfos);
                int timeout = Math.min(calls.size() * FINALIZE_JOIN_TIMEOUT_FACTOR, FINALIZE_JOIN_MAX_TIMEOUT);
                waitWithDeadline(calls, timeout, TimeUnit.SECONDS, whileFinalizeJoinsExceptionHandler);
            } finally {
                node.getPartitionService().resumeMigration();
            }
        } finally {
            lock.unlock();
        }
    }

    private static List<MemberInfo> createMemberInfoList(Collection<MemberImpl> members) {
        final List<MemberInfo> memberInfos = new LinkedList<MemberInfo>();
        for (MemberImpl member : members) {
            memberInfos.add(new MemberInfo(member));
        }
        return memberInfos;
    }

    private static Set<MemberInfo> createMemberInfoSet(Collection<MemberImpl> members) {
        final Set<MemberInfo> memberInfos = new HashSet<MemberInfo>();
        for (MemberImpl member : members) {
            memberInfos.add(new MemberInfo(member));
        }
        return memberInfos;
    }

    public void updateMembers(Collection<MemberInfo> members) {
        lock.lock();
        try {
            Map<Address, MemberImpl> currentMemberMap = membersMapRef.get();

            if (!shouldProcessMemberUpdate(currentMemberMap, members)) {
                return;
            }

            MemberImpl[] newMembers = new MemberImpl[members.size()];
            int k = 0;
            for (MemberInfo memberInfo : members) {
                MemberImpl member = currentMemberMap.get(memberInfo.getAddress());
                if (member == null) {
                    member = createMember(memberInfo.getAddress(), memberInfo.getUuid(),
                            thisAddress.getScopeId(), memberInfo.getAttributes());
                }
                newMembers[k++] = member;
                member.didRead();
            }
            setMembers(newMembers);
            if (!getMemberList().contains(thisMember)) {
                throw new HazelcastException("Member list doesn't contain local member!");
            }
            joinReset();
            heartBeater();
            node.setJoined();
            logger.info(membersString());
        } finally {
            lock.unlock();
        }
    }

    private boolean shouldProcessMemberUpdate(Map<Address, MemberImpl> currentMembers,
                                              Collection<MemberInfo> newMemberInfos) {

        int currentMembersSize = currentMembers.size();
        int newMembersSize = newMemberInfos.size();

        if (currentMembersSize > newMembersSize) {
            logger.warning("Received an older member update, no need to process...");
            nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            return false;
        }

        
        if (currentMembersSize == newMembersSize) {
            Set<MemberInfo> currentMemberInfos = createMemberInfoSet(currentMembers.values());
            if (currentMemberInfos.containsAll(newMemberInfos)) {
                logger.finest("Received a periodic member update, no need to process...");
            } else {
                logger.warning("Received an inconsistent member update "
                        + "which contains new members and removes some of the current members! "
                        + "Ignoring and requesting a new member update...");
                nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            }
            return false;
        }

        Set<MemberInfo> currentMemberInfos = createMemberInfoSet(currentMembers.values());
        currentMemberInfos.removeAll(newMemberInfos);
        if (currentMemberInfos.isEmpty()) {
            return true;
        } else {
            logger.warning("Received an inconsistent member update, it has more members but "
                    + "but also removes some of the current members! "
                    + "Ignoring and requesting a new member update...");
            nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            return false;
        }
    }

    public void updateMemberAttribute(String uuid, MemberAttributeOperationType operationType, String key, Object value) {
        lock.lock();
        try {
            Map<Address, MemberImpl> memberMap = membersMapRef.get();
            for (MemberImpl member : memberMap.values()) {
                if (member.getUuid().equals(uuid)) {
                    if (!member.equals(getLocalMember())) {
                        member.updateAttribute(operationType, key, value);
                    }
                    sendMemberAttributeEvent(member, operationType, key, value);
                    break;
                }
            }
        } finally {
            lock.unlock();
        }
    }

    public boolean sendJoinRequest(Address toAddress, boolean withCredentials) {
        if (toAddress == null) {
            toAddress = node.getMasterAddress();
        }
        JoinRequestOperation joinRequest = new JoinRequestOperation(node.createJoinRequest(withCredentials));
        return nodeEngine.getOperationService().send(joinRequest, toAddress);
    }

    public boolean sendMasterQuestion(Address toAddress) {
        checkNotNull(toAddress, "No endpoint is specified!");

        BuildInfo buildInfo = node.getBuildInfo();
        JoinMessage joinMessage = new JoinMessage(Packet.VERSION, buildInfo.getBuildNumber(), thisAddress,
                thisMember.getUuid(), node.createConfigCheck(), getSize());
        return nodeEngine.getOperationService().send(new MasterDiscoveryOperation(joinMessage), toAddress);
    }

    @Override
    public void connectionAdded(final Connection connection) {
        MemberImpl member = getMember(connection.getEndPoint());
        if (member != null) {
            member.didRead();
        }
    }

    @Override
    public void connectionRemoved(Connection connection) {
        if (logger.isFinestEnabled()) {
            logger.finest("Connection is removed " + connection.getEndPoint());
        }
        if (!node.joined()) {
            final Address masterAddress = node.getMasterAddress();
            if (masterAddress != null && masterAddress.equals(connection.getEndPoint())) {
                node.setMasterAddress(null);
            }
        }
    }

    private Future invokeClusterOperation(Operation op, Address target) {
        return nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, op, target)
                .setTryCount(100).invoke();
    }

    public NodeEngineImpl getNodeEngine() {
        return nodeEngine;
    }

    private void setMembers(MemberImpl... members) {
        if (members == null || members.length == 0) return;
        if (logger.isFinestEnabled()) {
            logger.finest("Updating members -> " + Arrays.toString(members));
        }
        lock.lock();
        try {
            Map<Address, MemberImpl> oldMemberMap = membersMapRef.get();
            final Map<Address, MemberImpl> memberMap = new LinkedHashMap<Address, MemberImpl>();  
            final Collection<MemberImpl> newMembers = new LinkedList<MemberImpl>();
            for (MemberImpl member : members) {
                MemberImpl currentMember = oldMemberMap.get(member.getAddress());
                if (currentMember == null) {
                    newMembers.add(member);
                    masterConfirmationTimes.put(member, Clock.currentTimeMillis());
                }
                memberMap.put(member.getAddress(), member);
            }
            setMembersRef(memberMap);

            if (!newMembers.isEmpty()) {
                Set<Member> eventMembers = new LinkedHashSet<Member>(oldMemberMap.values());
                if (newMembers.size() == 1) {
                    MemberImpl newMember = newMembers.iterator().next();
                    node.getPartitionService().memberAdded(newMember); 
                    eventMembers.add(newMember);
                    sendMembershipEventNotifications(newMember, unmodifiableSet(eventMembers), true); 
                } else {
                    for (MemberImpl newMember : newMembers) {
                        node.getPartitionService().memberAdded(newMember); 
                        eventMembers.add(newMember);
                        sendMembershipEventNotifications(newMember, unmodifiableSet(new LinkedHashSet<Member>(eventMembers)), true); 
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void removeMember(MemberImpl deadMember) {
        logger.info("Removing " + deadMember);
        lock.lock();
        try {
            final Map<Address, MemberImpl> members = membersMapRef.get();
            if (members.containsKey(deadMember.getAddress())) {
                Map<Address, MemberImpl> newMembers = new LinkedHashMap<Address, MemberImpl>(members);  
                newMembers.remove(deadMember.getAddress());
                masterConfirmationTimes.remove(deadMember);
                setMembersRef(newMembers);
                node.getPartitionService().memberRemoved(deadMember); 
                nodeEngine.onMemberLeft(deadMember);                  
                if (node.isMaster()) {
                    if (logger.isFinestEnabled()) {
                        logger.finest(deadMember + " is dead. Sending remove to all other members.");
                    }
                    invokeMemberRemoveOperation(deadMember.getAddress());
                }
                
                sendMembershipEventNotifications(deadMember, unmodifiableSet(new LinkedHashSet<Member>(newMembers.values())), false);
            }
        } finally {
            lock.unlock();
        }
    }

    private void invokeMemberRemoveOperation(final Address deadAddress) {
        for (MemberImpl member : getMemberList()) {
            Address address = member.getAddress();
            if (!thisAddress.equals(address) && !address.equals(deadAddress)) {
                nodeEngine.getOperationService().send(new MemberRemoveOperation(deadAddress), address);
            }
        }
    }

    public void sendShutdownMessage() {
        invokeMemberRemoveOperation(thisAddress);
    }

    private void sendMembershipEventNotifications(final MemberImpl member, Set<Member> members, final boolean added) {
        final int eventType = added ? MembershipEvent.MEMBER_ADDED : MembershipEvent.MEMBER_REMOVED;
        final MembershipEvent membershipEvent = new MembershipEvent(getClusterProxy(), member, eventType, members);
        final Collection<MembershipAwareService> membershipAwareServices = nodeEngine.getServices(MembershipAwareService.class);
        if (membershipAwareServices != null && !membershipAwareServices.isEmpty()) {
            final MembershipServiceEvent event = new MembershipServiceEvent(membershipEvent);
            for (final MembershipAwareService service : membershipAwareServices) {
                
                nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                    public void run() {
                        if (added) {
                            service.memberAdded(event);
                        } else {
                            service.memberRemoved(event);
                        }
                    }
                });
            }
        }
        final EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        for (EventRegistration reg : registrations) {
            eventService.publishEvent(SERVICE_NAME, reg, membershipEvent, reg.getId().hashCode());
        }
    }

    private void sendMemberAttributeEvent(MemberImpl member, MemberAttributeOperationType operationType, String key, Object value) {
        final MemberAttributeEvent memberAttributeEvent = new MemberAttributeEvent(getClusterProxy(), member, operationType, key, value);
        final Collection<MembershipAwareService> membershipAwareServices = nodeEngine.getServices(MembershipAwareService.class);
        final MemberAttributeServiceEvent event = new MemberAttributeServiceEvent(getClusterProxy(), member, operationType, key, value);
        if (membershipAwareServices != null && !membershipAwareServices.isEmpty()) {
            for (final MembershipAwareService service : membershipAwareServices) {
                
                nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                    public void run() {
                        service.memberAttributeChanged(event);
                    }
                });
            }
        }
        final EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        for (EventRegistration reg : registrations) {
            eventService.publishEvent(SERVICE_NAME, reg, memberAttributeEvent, reg.getId().hashCode());
        }
    }

    protected MemberImpl createMember(Address address, String nodeUuid, String ipV6ScopeId, Map<String, Object> attributes) {
        address.setScopeId(ipV6ScopeId);
        return new MemberImpl(address, thisAddress.equals(address), nodeUuid,
                (HazelcastInstanceImpl) nodeEngine.getHazelcastInstance(), attributes);
    }

    @Override
    public MemberImpl getMember(Address address) {
        if (address == null) {
            return null;
        }
        Map<Address, MemberImpl> memberMap = membersMapRef.get();
        return memberMap.get(address);
    }

    @Override
    public MemberImpl getMember(String uuid) {
        if (uuid == null) {
            return null;
        }

        Map<Address, MemberImpl> memberMap = membersMapRef.get();
        for (MemberImpl member : memberMap.values()) {
            if (uuid.equals(member.getUuid())) {
                return member;
            }
        }
        return null;
    }

    private void setMembersRef(Map<Address, MemberImpl> memberMap) {
        memberMap = unmodifiableMap(memberMap);
        
        memberMap.values();
        memberMap.keySet();
        memberMap.entrySet();
        membersMapRef.set(memberMap);
        membersRef.set(unmodifiableSet(new LinkedHashSet<MemberImpl>(memberMap.values())));
    }

    @Override
    public Collection<MemberImpl> getMemberList() {
        return membersRef.get();
    }

    @Override
    public Set<Member> getMembers() {
        return (Set) membersRef.get();
    }

    @Override
    public void shutdown(boolean terminate) {
        reset();
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public boolean isMaster() {
        return node.isMaster();
    }

    @Override
    public Address getThisAddress() {
        return thisAddress;
    }

    public Member getLocalMember() {
        return node.getLocalMember();
    }

    @Probe(name = "size")
    @Override
    public int getSize() {
        final Collection<MemberImpl> members = getMemberList();
        return members != null ? members.size() : 0;
    }

    public String addMembershipListener(MembershipListener listener) {
        checkNotNull(listener, "listener can't be null");

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration;
        if (listener instanceof InitialMembershipListener) {
            lock.lock();
            try {
                ((InitialMembershipListener) listener).init(new InitialMembershipEvent(getClusterProxy(), getMembers()));
                registration = eventService.registerLocalListener(SERVICE_NAME, SERVICE_NAME, listener);
            } finally {
                lock.unlock();
            }
        } else {
            registration = eventService.registerLocalListener(SERVICE_NAME, SERVICE_NAME, listener);
        }

        return registration.getId();
    }

    public boolean removeMembershipListener(String registrationId) {
        checkNotNull(registrationId, "registrationId can't be null");

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, SERVICE_NAME, registrationId);
    }

    @SuppressFBWarnings("BC_UNCONFIRMED_CAST")
    @Override
    public void dispatchEvent(MembershipEvent event, MembershipListener listener) {
        switch (event.getEventType()) {
            case MembershipEvent.MEMBER_ADDED:
                listener.memberAdded(event);
                break;
            case MembershipEvent.MEMBER_REMOVED:
                listener.memberRemoved(event);
                break;
            case MembershipEvent.MEMBER_ATTRIBUTE_CHANGED:
                MemberAttributeEvent memberAttributeEvent = (MemberAttributeEvent) event;
                listener.memberAttributeChanged(memberAttributeEvent);
                break;
            default:
                throw new IllegalArgumentException("Unhandled event:" + event);
        }
    }

    public Cluster getClusterProxy() {
        return new ClusterProxy(this);
    }

    public String membersString() {
        StringBuilder sb = new StringBuilder("\n\nMembers [");
        final Collection<MemberImpl> members = getMemberList();
        sb.append(members != null ? members.size() : 0);
        sb.append("] {");
        if (members != null) {
            for (Member member : members) {
                sb.append("\n\t").append(member);
            }
        }
        sb.append("\n}\n");
        return sb.toString();
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("ClusterService");
        sb.append("{address=").append(thisAddress);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.client.impl;

import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.ClientEndpointManager;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Connection;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.counters.MwCounter;

import javax.security.auth.login.LoginException;
import java.util.Collection;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.util.Preconditions.checkNotNull;
import static com.hazelcast.util.counters.MwCounter.newMwCounter;


public class ClientEndpointManagerImpl implements ClientEndpointManager {

    private static final int DESTROY_ENDPOINT_DELAY_MS = 1111;

    private final ILogger logger;
    private final ClientEngineImpl clientEngine;
    private final NodeEngine nodeEngine;

    @Probe(name = "count")
    private final ConcurrentMap<Connection, ClientEndpoint> endpoints =
            new ConcurrentHashMap<Connection, ClientEndpoint>();

    @Probe(name = "totalRegistrations")
    private MwCounter totalRegistrations = newMwCounter();

    public ClientEndpointManagerImpl(ClientEngineImpl clientEngine, NodeEngine nodeEngine) {
        this.clientEngine = clientEngine;
        this.nodeEngine = nodeEngine;
        this.logger = nodeEngine.getLogger(ClientEndpointManager.class);

        MetricsRegistry metricsRegistry = ((NodeEngineImpl) nodeEngine).getMetricsRegistry();
        metricsRegistry.scanAndRegister(this, "client.endpoint");
    }

    @Override
    public Set<ClientEndpoint> getEndpoints(String clientUuid) {
        checkNotNull(clientUuid, "clientUuid can't be null");

        Set<ClientEndpoint> endpointSet = new HashSet<ClientEndpoint>();
        for (ClientEndpoint endpoint : endpoints.values()) {
            if (clientUuid.equals(endpoint.getUuid())) {
                endpointSet.add(endpoint);
            }
        }
        return endpointSet;
    }

    @Override
    public ClientEndpoint getEndpoint(Connection connection) {
        checkNotNull(connection, "connection can't be null");

        return endpoints.get(connection);
    }

    @Override
    public void registerEndpoint(ClientEndpoint endpoint) {
        checkNotNull(endpoint, "endpoint can't be null");

        final Connection conn = endpoint.getConnection();
        if (endpoints.putIfAbsent(conn, endpoint) != null) {
            logger.severe("An endpoint already exists for connection:" + conn);
        } else {
            totalRegistrations.inc();
        }
    }

    @Override
    public void removeEndpoint(ClientEndpoint endpoint) {
        removeEndpoint(endpoint, false);
    }

    @Override
    public void removeEndpoint(final ClientEndpoint ce, boolean closeImmediately) {
        checkNotNull(ce, "endpoint can't be null");

        ClientEndpointImpl endpoint = (ClientEndpointImpl) ce;

        endpoints.remove(endpoint.getConnection());
        logger.info("Destroying " + endpoint);
        try {
            endpoint.destroy();
        } catch (LoginException e) {
            logger.warning(e);
        }

        final Connection connection = endpoint.getConnection();
        if (closeImmediately) {
            try {
                connection.close();
            } catch (Throwable e) {
                logger.warning("While closing client connection: " + connection, e);
            }
        } else {
            nodeEngine.getExecutionService().schedule(new Runnable() {
                public void run() {
                    if (connection.isAlive()) {
                        try {
                            connection.close();
                        } catch (Throwable e) {
                            logger.warning("While closing client connection: " + e.toString());
                        }
                    }
                }
            }, DESTROY_ENDPOINT_DELAY_MS, TimeUnit.MILLISECONDS);
        }
        clientEngine.sendClientEvent(endpoint);
    }

    public void removeEndpoints(String memberUuid) {
        Iterator<ClientEndpoint> iterator = endpoints.values().iterator();
        while (iterator.hasNext()) {
            ClientEndpoint endpoint = iterator.next();
            String ownerUuid = endpoint.getPrincipal().getOwnerUuid();
            if (memberUuid.equals(ownerUuid)) {
                iterator.remove();
                removeEndpoint(endpoint, true);
            }
        }
    }

    @Override
    public void clear() {
        endpoints.clear();
    }

    @Override
    public Collection<ClientEndpoint> getEndpoints() {
        return endpoints.values();
    }

    @Override
    public int size() {
        return endpoints.size();
    }
}

<code block>


package com.hazelcast.util.executor;

import com.hazelcast.internal.metrics.Probe;

import java.util.concurrent.ExecutorService;

public interface ManagedExecutorService extends ExecutorService {

    String getName();

    @Probe(name = "completedTaskCount")
    long getCompletedTaskCount();

    @Probe(name = "maximumPoolSize")
    int getMaximumPoolSize();

    @Probe(name = "poolSize")
    int getPoolSize();

    @Probe(name = "queueSize")
    int getQueueSize();

    @Probe(name = "remainingQueueCapacity")
    int getRemainingQueueCapacity();
}

<code block>


package com.hazelcast.nio;


public interface ConnectionManager {

    int getCurrentClientConnections();

    int getConnectionCount();

    int getAllTextConnections();

    int getActiveConnectionCount();

    Connection getConnection(Address address);

    Connection getOrConnect(Address address);

    Connection getOrConnect(Address address, boolean silent);

    boolean registerConnection(Address address, Connection connection);

    void destroyConnection(Connection conn);

    void shutdown();

    void start();

    void restart();

    void addConnectionListener(ConnectionListener connectionListener);
}

<code block>


package com.hazelcast.nio;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.internal.ascii.TextCommandService;
import com.hazelcast.config.NetworkConfig;
import com.hazelcast.config.SSLConfig;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.config.SymmetricEncryptionConfig;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.PacketReader;
import com.hazelcast.nio.tcp.PacketWriter;
import com.hazelcast.nio.tcp.SocketChannelWrapperFactory;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.transceiver.PacketTransceiver;

import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.Set;

public class NodeIOService implements IOService {

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final PacketTransceiver packetTransceiver;

    public NodeIOService(Node node, NodeEngineImpl nodeEngine) {
        this.node = node;
        this.nodeEngine = nodeEngine;
        this.packetTransceiver = nodeEngine.getPacketTransceiver();
    }

    @Override
    public MetricsRegistry getMetricRegistry() {
        return nodeEngine.getMetricsRegistry();
    }

    @Override
    public boolean isActive() {
        return node.isActive();
    }

    @Override
    public ILogger getLogger(String name) {
        return node.getLogger(name);
    }

    @Override
    public void onOutOfMemory(OutOfMemoryError oom) {
        OutOfMemoryErrorDispatcher.onOutOfMemory(oom);
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public void onFatalError(Exception e) {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        new Thread(threadGroup.getInternalThreadGroup(), threadGroup.getThreadNamePrefix("io.error.shutdown")) {
            public void run() {
                node.shutdown(false);
            }
        } .start();
    }

    @Override
    public SocketInterceptorConfig getSocketInterceptorConfig() {
        return node.getConfig().getNetworkConfig().getSocketInterceptorConfig();
    }

    @Override
    public SymmetricEncryptionConfig getSymmetricEncryptionConfig() {
        return node.getConfig().getNetworkConfig().getSymmetricEncryptionConfig();
    }

    @Override
    public SSLConfig getSSLConfig() {
        return node.getConfig().getNetworkConfig().getSSLConfig();
    }

    @Override
    public void handleMemberPacket(final Packet packet) {
        final Address endPoint = packet.getConn().getEndPoint();
        if (endPoint != null) {
            final MemberImpl member = node.clusterService.getMember(endPoint);
            if (member != null) {
                member.didRead();
            }
        }
        packetTransceiver.receive(packet);
    }

    @Override
    public void handleClientPacket(Packet p) {
        node.clientEngine.handlePacket(p);
    }

    @Override
    public void handleClientMessage(ClientMessage cm, Connection connection) {
        node.clientEngine.handleClientMessage(cm, connection);
    }

    @Override
    public TextCommandService getTextCommandService() {
        return node.getTextCommandService();
    }

    @Override
    public boolean isMemcacheEnabled() {
        return node.groupProperties.MEMCACHE_ENABLED.getBoolean();
    }

    @Override
    public boolean isRestEnabled() {
        return node.groupProperties.REST_ENABLED.getBoolean();
    }

    @Override
    public void removeEndpoint(final Address endPoint) {
        nodeEngine.getExecutionService().execute(ExecutionService.IO_EXECUTOR, new Runnable() {
            @Override
            public void run() {
                node.clusterService.removeAddress(endPoint);
            }
        });
    }

    @Override
    public String getThreadPrefix() {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        return threadGroup.getThreadPoolNamePrefix("IO");
    }

    @Override
    public ThreadGroup getThreadGroup() {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        return threadGroup.getInternalThreadGroup();
    }

    @Override
    public void onSuccessfulConnection(Address address) {
        if (!node.joined()) {
            node.getJoiner().unblacklist(address);
        }
    }

    @Override
    public void onFailedConnection(Address address) {
        if (!node.joined()) {
            node.getJoiner().blacklist(address, false);
        }
    }

    @Override
    public void shouldConnectTo(Address address) {
        if (node.getThisAddress().equals(address)) {
            throw new RuntimeException("Connecting to self! " + address);
        }
    }

    @Override
    public boolean isSocketBind() {
        return node.groupProperties.SOCKET_CLIENT_BIND.getBoolean();
    }

    @Override
    public boolean isSocketBindAny() {
        return node.groupProperties.SOCKET_CLIENT_BIND_ANY.getBoolean();
    }

    @Override
    public int getSocketReceiveBufferSize() {
        return this.node.getGroupProperties().SOCKET_RECEIVE_BUFFER_SIZE.getInteger();
    }

    @Override
    public int getSocketSendBufferSize() {
        return this.node.getGroupProperties().SOCKET_SEND_BUFFER_SIZE.getInteger();
    }

    @Override
    public int getSocketLingerSeconds() {
        return this.node.getGroupProperties().SOCKET_LINGER_SECONDS.getInteger();
    }

    @Override
    public int getSocketConnectTimeoutSeconds() {
        return this.node.getGroupProperties().SOCKET_CONNECT_TIMEOUT_SECONDS.getInteger();
    }

    @Override
    public boolean getSocketKeepAlive() {
        return this.node.getGroupProperties().SOCKET_KEEP_ALIVE.getBoolean();
    }

    @Override
    public boolean getSocketNoDelay() {
        return this.node.getGroupProperties().SOCKET_NO_DELAY.getBoolean();
    }

    @Override
    public int getSelectorThreadCount() {
        return node.groupProperties.IO_THREAD_COUNT.getInteger();
    }

    @Override
    public void onDisconnect(final Address endpoint) {
    }

    @Override
    public boolean isClient() {
        return false;
    }

    @Override
    public long getConnectionMonitorInterval() {
        return node.groupProperties.CONNECTION_MONITOR_INTERVAL.getLong();
    }

    @Override
    public int getConnectionMonitorMaxFaults() {
        return node.groupProperties.CONNECTION_MONITOR_MAX_FAULTS.getInteger();
    }

    @Override
    public int getBalancerIntervalSeconds() {
        return node.groupProperties.IO_BALANCER_INTERVAL_SECONDS.getInteger();
    }

    @Override
    public void executeAsync(final Runnable runnable) {
        nodeEngine.getExecutionService().execute(ExecutionService.IO_EXECUTOR, runnable);
    }

    @Override
    public EventService getEventService() {
        return nodeEngine.getEventService();
    }

    @Override
    public Data toData(Object obj) {
        return nodeEngine.toData(obj);
    }

    @Override
    public Object toObject(Data data) {
        return nodeEngine.toObject(data);
    }

    @Override
    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    @Override
    public SocketChannelWrapperFactory getSocketChannelWrapperFactory() {
        return node.getNodeExtension().getSocketChannelWrapperFactory();
    }

    @Override
    public MemberSocketInterceptor getMemberSocketInterceptor() {
        return node.getNodeExtension().getMemberSocketInterceptor();
    }

    @Override
    public PacketReader createPacketReader(TcpIpConnection connection) {
        return node.getNodeExtension().createPacketReader(connection, this);
    }

    @Override
    public PacketWriter createPacketWriter(TcpIpConnection connection) {
        return node.getNodeExtension().createPacketWriter(connection, this);
    }

    @Override
    public Collection<Integer> getOutboundPorts() {
        final NetworkConfig networkConfig = node.getConfig().getNetworkConfig();
        final Collection<String> portDefinitions = getPortDefinitions(networkConfig);
        final Set<Integer> ports = getPorts(networkConfig);
        if (portDefinitions.isEmpty() && ports.isEmpty()) {
            
            return Collections.emptySet();
        }
        if (portDefinitions.contains("*") || portDefinitions.contains("0")) {
            
            return Collections.emptySet();
        }
        transformPortDefinitionsToPorts(portDefinitions, ports);
        if (ports.contains(0)) {
            
            return Collections.emptySet();
        }
        return ports;
    }

    private void transformPortDefinitionsToPorts(Collection<String> portDefinitions, Set<Integer> ports) {
        
        for (String portDef : portDefinitions) {
            String[] portDefs = portDef.split("[,; ]");
            for (String def : portDefs) {
                def = def.trim();
                if (def.isEmpty()) {
                    continue;
                }
                final int dashPos = def.indexOf('-');
                if (dashPos > 0) {
                    final int start = Integer.parseInt(def.substring(0, dashPos));
                    final int end = Integer.parseInt(def.substring(dashPos + 1));
                    for (int port = start; port <= end; port++) {
                        ports.add(port);
                    }
                } else {
                    ports.add(Integer.parseInt(def));
                }
            }
        }
    }

    private Set<Integer> getPorts(NetworkConfig networkConfig) {
        return networkConfig.getOutboundPorts() == null
                ? new HashSet<Integer>() : new HashSet<Integer>(networkConfig.getOutboundPorts());
    }

    private Collection<String> getPortDefinitions(NetworkConfig networkConfig) {
        return networkConfig.getOutboundPortDefinitions() == null
                ? Collections.<String>emptySet() : networkConfig.getOutboundPortDefinitions();
    }
}


<code block>


package com.hazelcast.nio;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.internal.ascii.TextCommandService;
import com.hazelcast.config.SSLConfig;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.config.SymmetricEncryptionConfig;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.PacketReader;
import com.hazelcast.nio.tcp.PacketWriter;
import com.hazelcast.nio.tcp.SocketChannelWrapperFactory;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.spi.EventService;

import java.util.Collection;

public interface IOService {

    int KILO_BYTE = 1024;

    MetricsRegistry getMetricRegistry();

    boolean isActive();

    ILogger getLogger(String name);

    void onOutOfMemory(OutOfMemoryError oom);

    Address getThisAddress();

    void onFatalError(Exception e);

    SocketInterceptorConfig getSocketInterceptorConfig();

    SymmetricEncryptionConfig getSymmetricEncryptionConfig();

    SSLConfig getSSLConfig();

    void handleMemberPacket(Packet p);

    void handleClientPacket(Packet p);

    void handleClientMessage(ClientMessage cm, Connection connection);

    TextCommandService getTextCommandService();

    boolean isMemcacheEnabled();

    boolean isRestEnabled();

    void removeEndpoint(Address endpoint);

    String getThreadPrefix();

    ThreadGroup getThreadGroup();

    void onSuccessfulConnection(Address address);

    void onFailedConnection(Address address);

    void shouldConnectTo(Address address);

    boolean isSocketBind();

    boolean isSocketBindAny();

    int getSocketReceiveBufferSize();

    int getSocketSendBufferSize();

    int getSocketLingerSeconds();

    int getSocketConnectTimeoutSeconds();

    boolean getSocketKeepAlive();

    boolean getSocketNoDelay();

    int getSelectorThreadCount();

    long getConnectionMonitorInterval();

    int getConnectionMonitorMaxFaults();

    
    int getBalancerIntervalSeconds();

    void onDisconnect(Address endpoint);

    boolean isClient();

    void executeAsync(Runnable runnable);

    EventService getEventService();

    Collection<Integer> getOutboundPorts();

    Data toData(Object obj);

    Object toObject(Data data);

    SerializationService getSerializationService();

    SocketChannelWrapperFactory getSocketChannelWrapperFactory();

    MemberSocketInterceptor getMemberSocketInterceptor();

    PacketReader createPacketReader(TcpIpConnection connection);

    PacketWriter createPacketWriter(TcpIpConnection connection);
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.ConnectionType;

import java.io.IOException;
import java.nio.channels.ClosedChannelException;
import java.nio.channels.SelectionKey;
import java.nio.channels.Selector;
import java.util.logging.Level;

public abstract class AbstractSelectionHandler implements MigratableHandler {

    protected final ILogger logger;
    protected final SocketChannelWrapper socketChannel;
    protected final TcpIpConnection connection;
    protected final TcpIpConnectionManager connectionManager;
    protected Selector selector;
    protected IOSelector ioSelector;

    protected SelectionKey selectionKey;
    private final int initialOps;

    public AbstractSelectionHandler(TcpIpConnection connection, IOSelector ioSelector, int initialOps) {
        this.connection = connection;
        this.ioSelector = ioSelector;
        this.selector = ioSelector.getSelector();
        this.socketChannel = connection.getSocketChannelWrapper();
        this.connectionManager = connection.getConnectionManager();
        this.logger = connectionManager.ioService.getLogger(this.getClass().getName());
        this.initialOps = initialOps;
    }

    protected SelectionKey getSelectionKey() {
        if (selectionKey == null) {
            try {
                selectionKey = socketChannel.register(selector, initialOps, this);
            } catch (ClosedChannelException e) {
                handleSocketException(e);
            }
        }
        return selectionKey;
    }

    void handleSocketException(Throwable e) {
        if (e instanceof OutOfMemoryError) {
            connectionManager.ioService.onOutOfMemory((OutOfMemoryError) e);
        }
        if (selectionKey != null) {
            selectionKey.cancel();
        }
        connection.close(e);
        ConnectionType connectionType = connection.getType();
        if (connectionType.isClient() && !connectionType.isBinary()) {
            return;
        }
        StringBuilder sb = new StringBuilder();
        sb.append(Thread.currentThread().getName());
        sb.append(" Closing socket to endpoint ");
        sb.append(connection.getEndPoint());
        sb.append(", Cause:").append(e);
        Level level = connectionManager.ioService.isActive() ? Level.WARNING : Level.FINEST;
        if (e instanceof IOException) {
            logger.log(level, sb.toString());
        } else {
            logger.log(level, sb.toString(), e);
        }
    }

    final void registerOp(int operation) {
        SelectionKey selectionKey = getSelectionKey();

        try {
            selectionKey.interestOps(selectionKey.interestOps() | operation);
        } catch (Throwable e) {
            handleSocketException(e);
        }
    }

    final void unregisterOp(int operation) {
        SelectionKey selectionKey = getSelectionKey();
        try {
            selectionKey.interestOps(selectionKey.interestOps() & ~operation);
        } catch (Throwable e) {
            handleSocketException(e);
        }
    }

    @Override
    public IOSelector getOwner() {
        return ioSelector;
    }

    
    void startMigration(final IOSelector newOwner) {
        assert ioSelector == Thread.currentThread() : "startMigration can only run on the owning IOSelector thread";
        assert ioSelector != newOwner : "newOwner can't be the same as the existing owner";

        if (!socketChannel.isOpen()) {
            
            return;
        }

        unregisterOp(initialOps);
        ioSelector = newOwner;
        selectionKey.cancel();
        selectionKey = null;
        selector = null;

        newOwner.addTaskAndWakeup(new Runnable() {
            @Override
            public void run() {
                completeMigration(newOwner);
            }
        });
    }

    private void completeMigration(IOSelector newOwner) {
        assert ioSelector == newOwner;

        connectionManager.getIOBalancer().signalMigrationComplete();

        if (!socketChannel.isOpen()) {
            return;
        }

        selector = newOwner.getSelector();
        selectionKey = getSelectionKey();
        registerOp(initialOps);
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.util.counters.SwCounter;

import java.nio.channels.SelectionKey;

import static com.hazelcast.util.counters.SwCounter.newSwCounter;

public final class OutSelectorImpl extends AbstractIOSelector {

    
    @Probe
    private final SwCounter writeEvents = newSwCounter();

    public OutSelectorImpl(ThreadGroup threadGroup, String tname, ILogger logger, IOSelectorOutOfMemoryHandler oomeHandler) {
        super(threadGroup, tname, logger, oomeHandler);
    }

    
    public long getWriteEvents() {
        return writeEvents.get();
    }

    @Override
    protected void handleSelectionKey(SelectionKey sk) {
        if (sk.isValid() && sk.isWritable()) {
            writeEvents.inc();
            SelectionHandler handler = (SelectionHandler) sk.attachment();
            handler.handle();
        }
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.cluster.impl.BindMessage;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.IOService;
import com.hazelcast.nio.IOUtil;
import com.hazelcast.nio.MemberSocketInterceptor;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.tcp.iobalancer.IOBalancer;
import com.hazelcast.util.ConcurrencyUtil;
import com.hazelcast.util.ConstructorFunction;
import com.hazelcast.util.counters.MwCounter;
import com.hazelcast.util.executor.StripedRunnable;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.io.IOException;
import java.net.Socket;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;
import java.util.Collection;
import java.util.Collections;
import java.util.LinkedList;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CopyOnWriteArraySet;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.logging.Level;

import static com.hazelcast.util.counters.MwCounter.newMwCounter;

public class TcpIpConnectionManager implements ConnectionManager {

    private static final int DEFAULT_KILL_THREAD_MILLIS = 1000 * 10;

    final int socketReceiveBufferSize;

    final IOService ioService;

    final int socketSendBufferSize;

    private final ConstructorFunction<Address, TcpIpConnectionMonitor> monitorConstructor
            = new ConstructorFunction<Address, TcpIpConnectionMonitor>() {
        public TcpIpConnectionMonitor createNew(Address endpoint) {
            return new TcpIpConnectionMonitor(TcpIpConnectionManager.this, endpoint);
        }
    };

    private final ILogger logger;

    private final int socketLingerSeconds;

    private final int socketConnectTimeoutSeconds;

    private final boolean socketKeepAlive;

    private final boolean socketNoDelay;

    @Probe(name = "count")
    private final ConcurrentHashMap<Address, Connection> connectionsMap = new ConcurrentHashMap<Address, Connection>(100);

    @Probe(name = "monitorCount")
    private final ConcurrentHashMap<Address, TcpIpConnectionMonitor> monitors =
            new ConcurrentHashMap<Address, TcpIpConnectionMonitor>(100);

    @Probe(name = "inProgressCount")
    private final Set<Address> connectionsInProgress =
            Collections.newSetFromMap(new ConcurrentHashMap<Address, Boolean>());

    @Probe(name = "connectionListenerCount")
    private final Set<ConnectionListener> connectionListeners = new CopyOnWriteArraySet<ConnectionListener>();

    @Probe(name = "acceptedSocketCount")
    private final Set<SocketChannelWrapper> acceptedSockets =
            Collections.newSetFromMap(new ConcurrentHashMap<SocketChannelWrapper, Boolean>());

    @Probe(name = "activeCount")
    private final Set<TcpIpConnection> activeConnections =
            Collections.newSetFromMap(new ConcurrentHashMap<TcpIpConnection, Boolean>());

    @Probe(name = "textCount")
    private final AtomicInteger allTextConnections = new AtomicInteger();

    private final AtomicInteger connectionIdGen = new AtomicInteger();
    private final MetricsRegistry metricRegistry;

    private volatile boolean live;

    private final ServerSocketChannel serverSocketChannel;

    private final int selectorThreadCount;

    private final InSelectorImpl[] inSelectors;

    private final OutSelectorImpl[] outSelectors;

    private final AtomicInteger nextSelectorIndex = new AtomicInteger();

    private final SocketChannelWrapperFactory socketChannelWrapperFactory;

    private final int outboundPortCount;

    private final HazelcastThreadGroup hazelcastThreadGroup;

    
    private final LinkedList<Integer> outboundPorts = new LinkedList<Integer>();

    
    private volatile Thread socketAcceptorThread;

    private IOBalancer ioBalancer;
    private final LoggingService loggingService;

    @Probe
    private final MwCounter openedCount = newMwCounter();
    @Probe
    private final MwCounter closedCount = newMwCounter();

    public TcpIpConnectionManager(IOService ioService, ServerSocketChannel serverSocketChannel,
                                  HazelcastThreadGroup hazelcastThreadGroup, LoggingService loggingService) {
        this.ioService = ioService;
        this.metricRegistry = ioService.getMetricRegistry();
        this.hazelcastThreadGroup = hazelcastThreadGroup;
        this.serverSocketChannel = serverSocketChannel;
        this.logger = loggingService.getLogger(TcpIpConnectionManager.class.getName());
        this.socketReceiveBufferSize = ioService.getSocketReceiveBufferSize() * IOService.KILO_BYTE;
        this.socketSendBufferSize = ioService.getSocketSendBufferSize() * IOService.KILO_BYTE;
        this.socketLingerSeconds = ioService.getSocketLingerSeconds();
        this.socketConnectTimeoutSeconds = ioService.getSocketConnectTimeoutSeconds();
        this.socketKeepAlive = ioService.getSocketKeepAlive();
        this.socketNoDelay = ioService.getSocketNoDelay();
        this.selectorThreadCount = ioService.getSelectorThreadCount();
        this.inSelectors = new InSelectorImpl[selectorThreadCount];
        this.outSelectors = new OutSelectorImpl[selectorThreadCount];
        final Collection<Integer> ports = ioService.getOutboundPorts();
        this.outboundPortCount = ports.size();
        this.outboundPorts.addAll(ports);
        this.socketChannelWrapperFactory = ioService.getSocketChannelWrapperFactory();
        this.loggingService = loggingService;

        metricRegistry.scanAndRegister(this, "tcp.connection");
    }

    public MetricsRegistry getMetricRegistry() {
        return metricRegistry;
    }


    public void interceptSocket(Socket socket, boolean onAccept) throws IOException {
        if (!isSocketInterceptorEnabled()) {
            return;
        }
        final MemberSocketInterceptor memberSocketInterceptor = ioService.getMemberSocketInterceptor();
        if (memberSocketInterceptor == null) {
            return;
        }
        if (onAccept) {
            memberSocketInterceptor.onAccept(socket);
        } else {
            memberSocketInterceptor.onConnect(socket);
        }
    }

    public boolean isSocketInterceptorEnabled() {
        final SocketInterceptorConfig socketInterceptorConfig = ioService.getSocketInterceptorConfig();
        if (socketInterceptorConfig != null && socketInterceptorConfig.isEnabled()) {
            return true;
        }
        return false;
    }

    public PacketReader createPacketReader(TcpIpConnection connection) {
        return ioService.createPacketReader(connection);
    }

    public PacketWriter createPacketWriter(TcpIpConnection connection) {
        return ioService.createPacketWriter(connection);
    }

    
    public Set<TcpIpConnection> getActiveConnections() {
        return activeConnections;
    }

    @SuppressFBWarnings(value = "EI_EXPOSE_REP", justification = "used only for testing")
    public InSelectorImpl[] getInSelectors() {
        return inSelectors;
    }

    @SuppressFBWarnings(value = "EI_EXPOSE_REP", justification = "used only for testing")
    public OutSelectorImpl[] getOutSelectors() {
        return outSelectors;
    }

    @Override
    public int getActiveConnectionCount() {
        return activeConnections.size();
    }

    public int getAllTextConnections() {
        return allTextConnections.get();
    }

    @Override
    public int getConnectionCount() {
        return connectionsMap.size();
    }

    public IOBalancer getIOBalancer() {
        return ioBalancer;
    }

    public boolean isSSLEnabled() {
        return socketChannelWrapperFactory.isSSlEnabled();
    }

    public void incrementTextConnections() {
        allTextConnections.incrementAndGet();
    }

    public IOService getIOHandler() {
        return ioService;
    }

    public int getSocketConnectTimeoutSeconds() {
        return socketConnectTimeoutSeconds;
    }

    @Override
    public void addConnectionListener(ConnectionListener listener) {
        connectionListeners.add(listener);
    }

    public boolean bind(TcpIpConnection connection, Address remoteEndPoint, Address localEndpoint, boolean reply) {
        if (logger.isFinestEnabled()) {
            log(Level.FINEST, "Binding " + connection + " to " + remoteEndPoint + ", reply is " + reply);
        }
        final Address thisAddress = ioService.getThisAddress();
        if (ioService.isSocketBindAny() && !connection.isClient() && !thisAddress.equals(localEndpoint)) {
            log(Level.WARNING, "Wrong bind request from " + remoteEndPoint
                    + "! This node is not requested endpoint: " + localEndpoint);
            connection.close();
            return false;
        }
        connection.setEndPoint(remoteEndPoint);
        ioService.onSuccessfulConnection(remoteEndPoint);
        if (reply) {
            sendBindRequest(connection, remoteEndPoint, false);
        }
        if (checkAlreadyConnected(connection, remoteEndPoint)) {
            return false;
        }
        if (!registerConnection(remoteEndPoint, connection)) {
            return false;
        }
        return true;
    }

    public boolean registerConnection(final Address remoteEndPoint, final Connection connection) {
        if (remoteEndPoint.equals(ioService.getThisAddress())) {
            return false;
        }

        if (connection instanceof TcpIpConnection) {
            TcpIpConnection tcpConnection = (TcpIpConnection) connection;
            Address currentEndPoint = tcpConnection.getEndPoint();
            if (currentEndPoint != null && !currentEndPoint.equals(remoteEndPoint)) {
                throw new IllegalArgumentException(connection + " has already a different endpoint than: "
                        + remoteEndPoint);
            }
            tcpConnection.setEndPoint(remoteEndPoint);

            if (!connection.isClient()) {
                TcpIpConnectionMonitor connectionMonitor = getConnectionMonitor(remoteEndPoint, true);
                tcpConnection.setMonitor(connectionMonitor);
            }
        }
        connectionsMap.put(remoteEndPoint, connection);
        connectionsInProgress.remove(remoteEndPoint);
        ioService.getEventService().executeEventCallback(new StripedRunnable() {
            @Override
            public void run() {
                for (ConnectionListener listener : connectionListeners) {
                    listener.connectionAdded(connection);
                }
            }

            @Override
            public int getKey() {
                return remoteEndPoint.hashCode();
            }
        });
        return true;
    }

    private boolean checkAlreadyConnected(TcpIpConnection connection, Address remoteEndPoint) {
        final Connection existingConnection = connectionsMap.get(remoteEndPoint);
        if (existingConnection != null && existingConnection.isAlive()) {
            if (existingConnection != connection) {
                if (logger.isFinestEnabled()) {
                    log(Level.FINEST, existingConnection + " is already bound to " + remoteEndPoint
                            + ", new one is " + connection);
                }
                activeConnections.add(connection);
            }
            return true;
        }
        return false;
    }

    void sendBindRequest(TcpIpConnection connection, Address remoteEndPoint, boolean replyBack) {
        connection.setEndPoint(remoteEndPoint);
        ioService.onSuccessfulConnection(remoteEndPoint);
        
        if (logger.isFinestEnabled()) {
            log(Level.FINEST, "Sending bind packet to " + remoteEndPoint);
        }
        BindMessage bind = new BindMessage(ioService.getThisAddress(), remoteEndPoint, replyBack);
        Data bindData = ioService.toData(bind);
        Packet packet = new Packet(bindData);
        packet.setHeader(Packet.HEADER_BIND);
        connection.write(packet);
        
    }

    private int nextSelectorIndex() {
        return Math.abs(nextSelectorIndex.getAndIncrement()) % selectorThreadCount;
    }

    SocketChannelWrapper wrapSocketChannel(SocketChannel socketChannel, boolean client) throws Exception {
        SocketChannelWrapper wrapper = socketChannelWrapperFactory.wrapSocketChannel(socketChannel, client);
        acceptedSockets.add(wrapper);
        return wrapper;
    }

    TcpIpConnection assignSocketChannel(SocketChannelWrapper channel, Address endpoint) {
        int index = nextSelectorIndex();

        final TcpIpConnection connection = new TcpIpConnection(this, inSelectors[index],
                outSelectors[index], connectionIdGen.incrementAndGet(), channel);

        connection.setEndPoint(endpoint);
        activeConnections.add(connection);
        acceptedSockets.remove(channel);

        connection.start();
        ioBalancer.connectionAdded(connection);

        log(Level.INFO, "Established socket connection between " + channel.socket().getLocalSocketAddress());
        openedCount.inc();

        return connection;
    }

    void failedConnection(Address address, Throwable t, boolean silent) {
        connectionsInProgress.remove(address);
        ioService.onFailedConnection(address);
        if (!silent) {
            getConnectionMonitor(address, false).onError(t);
        }
    }

    @Override
    public Connection getConnection(Address address) {
        return connectionsMap.get(address);
    }

    @Override
    public Connection getOrConnect(Address address) {
        return getOrConnect(address, false);
    }

    @Override
    public Connection getOrConnect(final Address address, final boolean silent) {
        Connection connection = connectionsMap.get(address);
        if (connection == null && live) {
            if (connectionsInProgress.add(address)) {
                ioService.shouldConnectTo(address);
                ioService.executeAsync(new SocketConnector(this, address, silent));
            }
        }
        return connection;
    }

    private TcpIpConnectionMonitor getConnectionMonitor(Address endpoint, boolean reset) {
        TcpIpConnectionMonitor monitor = ConcurrencyUtil.getOrPutIfAbsent(monitors, endpoint, monitorConstructor);
        if (reset) {
            monitor.reset();
        }
        return monitor;
    }

    @Override
    public void destroyConnection(final Connection connection) {
        if (connection == null) {
            return;
        }
        if (logger.isFinestEnabled()) {
            log(Level.FINEST, "Destroying " + connection);
        }

        activeConnections.remove(connection);
        final Address endPoint = connection.getEndPoint();
        if (endPoint != null) {
            connectionsInProgress.remove(endPoint);
            connectionsMap.remove(endPoint, connection);
            ioBalancer.connectionRemoved(connection);
            if (live) {
                ioService.getEventService().executeEventCallback(new StripedRunnable() {
                    @Override
                    public void run() {
                        for (ConnectionListener listener : connectionListeners) {
                            listener.connectionRemoved(connection);
                        }
                    }

                    @Override
                    public int getKey() {
                        return endPoint.hashCode();
                    }
                });
            }
        }
        if (connection.isAlive()) {
            connection.close();
            closedCount.inc();
        }
    }

    protected void initSocket(Socket socket) throws Exception {
        if (socketLingerSeconds > 0) {
            socket.setSoLinger(true, socketLingerSeconds);
        }
        socket.setKeepAlive(socketKeepAlive);
        socket.setTcpNoDelay(socketNoDelay);
        socket.setReceiveBufferSize(socketReceiveBufferSize);
        socket.setSendBufferSize(socketSendBufferSize);
    }

    @Override
    public synchronized void start() {
        if (live) {
            return;
        }
        live = true;
        log(Level.FINEST, "Starting ConnectionManager and IO selectors.");
        IOSelectorOutOfMemoryHandler oomeHandler = new IOSelectorOutOfMemoryHandler() {
            @Override
            public void handle(OutOfMemoryError error) {
                ioService.onOutOfMemory(error);
            }
        };
        for (int i = 0; i < inSelectors.length; i++) {
            InSelectorImpl inSelector = new InSelectorImpl(
                    ioService.getThreadGroup(),
                    ioService.getThreadPrefix() + "in-" + i,
                    ioService.getLogger(InSelectorImpl.class.getName()),
                    oomeHandler
            );
            inSelectors[i] = inSelector;
            metricRegistry.scanAndRegister(inSelector, "tcp." + inSelector.getName());
            inSelector.start();

            OutSelectorImpl outSelector = new OutSelectorImpl(
                    ioService.getThreadGroup(),
                    ioService.getThreadPrefix() + "out-" + i,
                    ioService.getLogger(OutSelectorImpl.class.getName()),
                    oomeHandler);
            outSelectors[i] = outSelector;
            metricRegistry.scanAndRegister(outSelector, "tcp." + outSelector.getName());
            outSelector.start();
        }
        startIOBalancer();

        if (socketAcceptorThread != null) {
            logger.warning("SocketAcceptor thread is already live! Shutting down old acceptor...");
            shutdownSocketAcceptor();
        }
        Runnable acceptRunnable = new SocketAcceptor(serverSocketChannel, this);
        socketAcceptorThread = new Thread(ioService.getThreadGroup(), acceptRunnable,
                ioService.getThreadPrefix() + "Acceptor");
        socketAcceptorThread.start();
    }

    private void startIOBalancer() {
        ioBalancer = new IOBalancer(inSelectors, outSelectors,
                hazelcastThreadGroup, ioService.getBalancerIntervalSeconds(), loggingService);
        ioBalancer.start();
        metricRegistry.scanAndRegister(ioBalancer, "tcp.balancer");
    }

    @Override
    public synchronized void restart() {
        stop();
        start();
    }

    @Override
    public synchronized void shutdown() {
        if (!live) {
            return;
        }
        live = false;
        shutdownSocketAcceptor();
        closeServerSocket();
        stop();
        connectionListeners.clear();
    }

    private void closeServerSocket() {
        try {
            if (logger.isFinestEnabled()) {
                log(Level.FINEST, "Closing server socket channel: " + serverSocketChannel);
            }
            serverSocketChannel.close();
        } catch (IOException ignore) {
            logger.finest(ignore);
        }
    }

    private void stop() {
        live = false;
        log(Level.FINEST, "Stopping ConnectionManager");
        ioBalancer.stop();
        shutdownSocketAcceptor();
        for (SocketChannelWrapper socketChannel : acceptedSockets) {
            IOUtil.closeResource(socketChannel);
        }
        for (Connection conn : connectionsMap.values()) {
            try {
                destroyConnection(conn);
            } catch (final Throwable ignore) {
                logger.finest(ignore);
            }
        }
        for (TcpIpConnection conn : activeConnections) {
            try {
                destroyConnection(conn);
            } catch (final Throwable ignore) {
                logger.finest(ignore);
            }
        }
        shutdownIOSelectors();
        acceptedSockets.clear();
        connectionsInProgress.clear();
        connectionsMap.clear();
        monitors.clear();
        activeConnections.clear();
    }

    private synchronized void shutdownIOSelectors() {
        if (logger.isFinestEnabled()) {
            log(Level.FINEST, "Shutting down IO selectors... Total: " + selectorThreadCount);
        }
        for (int i = 0; i < selectorThreadCount; i++) {
            IOSelector ioSelector = inSelectors[i];
            if (ioSelector != null) {
                ioSelector.shutdown();
            }
            inSelectors[i] = null;

            ioSelector = outSelectors[i];
            if (ioSelector != null) {
                ioSelector.shutdown();
            }
            outSelectors[i] = null;
        }
    }

    private void shutdownSocketAcceptor() {
        log(Level.FINEST, "Shutting down SocketAcceptor thread.");
        Thread killingThread = socketAcceptorThread;
        if (killingThread == null) {
            return;
        }
        socketAcceptorThread = null;
        killingThread.interrupt();
        try {
            killingThread.join(DEFAULT_KILL_THREAD_MILLIS);
        } catch (InterruptedException e) {
            logger.finest(e);
        }
    }

    @Probe(name = "clientCount")
    @Override
    public int getCurrentClientConnections() {
        int count = 0;
        for (TcpIpConnection conn : activeConnections) {
            if (conn.isAlive()) {
                if (conn.isClient()) {
                    count++;
                }
            }
        }
        return count;
    }

    public boolean isLive() {
        return live;
    }

    private void log(Level level, String message) {
        logger.log(level, message);
    }

    boolean useAnyOutboundPort() {
        return outboundPortCount == 0;
    }

    int getOutboundPortCount() {
        return outboundPortCount;
    }

    int acquireOutboundPort() {
        if (useAnyOutboundPort()) {
            return 0;
        }
        synchronized (outboundPorts) {
            final Integer port = outboundPorts.removeFirst();
            outboundPorts.addLast(port);
            return port;
        }
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder("Connections {");
        for (Connection conn : connectionsMap.values()) {
            sb.append("\n");
            sb.append(conn);
        }
        sb.append("\nlive=");
        sb.append(live);
        sb.append("\n}");
        return sb.toString();
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.cluster.impl.BindMessage;
import com.hazelcast.nio.IOService;
import com.hazelcast.nio.Packet;
import com.hazelcast.util.counters.Counter;

import java.nio.ByteBuffer;

public class DefaultPacketReader implements PacketReader {

    protected final TcpIpConnection connection;
    protected final IOService ioService;
    protected Packet packet;

    private final Counter normalPacketsRead;
    private final Counter priorityPacketsRead;

    public DefaultPacketReader(TcpIpConnection connection, IOService ioService) {
        this.connection = connection;
        this.ioService = ioService;
        this.normalPacketsRead = connection.getReadHandler().getNormalPacketsRead();
        this.priorityPacketsRead = connection.getReadHandler().getPriorityPacketsRead();
    }

    @Override
    public void readPacket(ByteBuffer inBuffer) throws Exception {
        while (inBuffer.hasRemaining()) {
            if (packet == null) {
                packet = obtainPacket();
            }
            boolean complete = packet.readFrom(inBuffer);
            if (complete) {
                handlePacket(packet);
                packet = null;
            } else {
                break;
            }
        }
    }

    protected void handlePacket(Packet packet) {
        if (packet.isHeaderSet(Packet.HEADER_URGENT)) {
            priorityPacketsRead.inc();
        } else {
            normalPacketsRead.inc();
        }

        packet.setConn(connection);
        if (packet.isHeaderSet(Packet.HEADER_BIND)) {
            handleBind(packet);
        } else {
            ioService.handleMemberPacket(packet);
        }
    }

    protected void handleBind(Packet packet) {
        TcpIpConnectionManager connectionManager = connection.getConnectionManager();
        BindMessage bind = (BindMessage) ioService.toObject(packet.getData());
        connectionManager.bind(connection, bind.getLocalAddress(), bind.getTargetAddress(), bind.shouldReply());
    }

    protected Packet obtainPacket() {
        return new Packet();
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.core.HazelcastException;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;

import java.io.IOException;
import java.nio.channels.SelectionKey;
import java.nio.channels.Selector;
import java.util.Iterator;
import java.util.Queue;
import java.util.Set;
import java.util.concurrent.ConcurrentLinkedQueue;

public abstract class AbstractIOSelector extends Thread implements IOSelector {

    private static final int SELECT_WAIT_TIME_MILLIS = 5000;
    private static final int SELECT_FAILURE_PAUSE_MILLIS = 1000;

    @Probe(name = "selectorQueueSize")
    protected final Queue<Runnable> selectorQueue = new ConcurrentLinkedQueue<Runnable>();

    private final ILogger logger;

    private final int waitTime;

    private final Selector selector;

    private final IOSelectorOutOfMemoryHandler oomeHandler;

    
    private boolean running = true;

    private volatile long lastSelectTimeMs;

    public AbstractIOSelector(ThreadGroup threadGroup, String threadName, ILogger logger,
                              IOSelectorOutOfMemoryHandler oomeHandler) {
        super(threadGroup, threadName);
        this.logger = logger;
        this.oomeHandler = oomeHandler;
        
        this.waitTime = SELECT_WAIT_TIME_MILLIS;
        try {
            selector = Selector.open();
        } catch (final IOException e) {
            throw new HazelcastException("Failed to open a Selector", e);
        }
    }

    @Override
    public final void shutdown() {
        selectorQueue.clear();
        try {
            addTask(new Runnable() {
                @Override
                public void run() {
                    running = false;
                }
            });
            interrupt();
        } catch (Throwable t) {
            logger.finest("Exception while waiting for shutdown", t);
        }
    }

    @Override
    public final void addTask(Runnable task) {
        selectorQueue.add(task);
    }

    @Override
    public final void addTaskAndWakeup(Runnable task) {
        selectorQueue.add(task);
        selector.wakeup();
    }

    
    @Probe
    private long idleTime() {
        return Math.max(System.currentTimeMillis() - lastSelectTimeMs, 0);
    }

    private void processSelectionQueue() {
        
        while (running) {
            final Runnable task = selectorQueue.poll();
            if (task == null) {
                return;
            }
            executeTask(task);
        }
    }

    private void executeTask(Runnable task) {
        IOSelector target = getTargetIOSelector(task);
        if (target == this) {
            task.run();
        } else {
            target.addTask(task);
        }
    }

    private IOSelector getTargetIOSelector(Runnable task) {
        if (task instanceof MigratableHandler) {
            return ((MigratableHandler) task).getOwner();
        } else {
            return this;
        }
    }

    @Override
    public final void run() {
        try {
            
            while (running) {
                processSelectionQueue();
                if (!running || isInterrupted()) {
                    if (logger.isFinestEnabled()) {
                        logger.finest(getName() + " is interrupted!");
                    }
                    running = false;
                    return;
                }

                try {
                    int selectedKeyCount = selector.select(waitTime);
                    lastSelectTimeMs = System.currentTimeMillis();

                    if (selectedKeyCount == 0) {
                        continue;
                    }
                } catch (Throwable e) {
                    handleSelectFailure(e);
                    continue;
                }
                handleSelectionKeys();
            }
        } catch (OutOfMemoryError e) {
            oomeHandler.handle(e);
        } catch (Throwable e) {
            logger.warning("Unhandled exception in " + getName(), e);
        } finally {
            closeSelector();
        }
    }

    private void closeSelector() {
        if (logger.isFinestEnabled()) {
            logger.finest("Closing selector " + getName());
        }

        try {
            selector.close();
        } catch (Exception e) {
            logger.finest("Exception while closing selector", e);
        }
    }

    protected abstract void handleSelectionKey(SelectionKey sk);

    private void handleSelectionKeys() {
        final Set<SelectionKey> setSelectedKeys = selector.selectedKeys();
        final Iterator<SelectionKey> it = setSelectedKeys.iterator();
        while (it.hasNext()) {
            final SelectionKey sk = it.next();
            it.remove();
            try {
                handleSelectionKey(sk);
            } catch (Throwable e) {
                handleSelectionKeyFailure(e);
            }
        }
    }

    public void handleSelectionKeyFailure(Throwable e) {
        logger.warning("Selector exception at  " + getName() + ", cause= " + e.toString(), e);
        if (e instanceof OutOfMemoryError) {
            oomeHandler.handle((OutOfMemoryError) e);
        }
    }

    @Override
    public final Selector getSelector() {
        return selector;
    }

    private void handleSelectFailure(Throwable e) {
        logger.warning(e.toString(), e);

        
        
        try {
            Thread.sleep(SELECT_FAILURE_PAUSE_MILLIS);
        } catch (InterruptedException i) {
            Thread.currentThread().interrupt();
        }
    }

    @Override
    public String toString() {
        return getName();
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.Protocols;
import com.hazelcast.nio.ascii.SocketTextReader;
import com.hazelcast.util.Clock;
import com.hazelcast.util.counters.Counter;
import com.hazelcast.util.counters.SwCounter;

import java.io.EOFException;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.SelectionKey;

import static com.hazelcast.util.StringUtil.bytesToString;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;


public final class ReadHandler extends AbstractSelectionHandler {

    private final ByteBuffer inputBuffer;

    @Probe(name = "in.bytesRead")
    private final SwCounter bytesRead = newSwCounter();
    @Probe(name = "in.normalPacketsRead")
    private final SwCounter normalPacketsRead = newSwCounter();
    @Probe(name = "in.priorityPacketsRead")
    private final SwCounter priorityPacketsRead = newSwCounter();
    @Probe(name = "in.exceptionCount")
    private final SwCounter exceptionCount = newSwCounter();
    private final MetricsRegistry metricRegistry;

    private SocketReader socketReader;

    private volatile long lastReadTime;

    
    @Probe(name = "in.eventCount")
    private final SwCounter eventCount = newSwCounter();

    public ReadHandler(TcpIpConnection connection, IOSelector ioSelector) {
        super(connection, ioSelector, SelectionKey.OP_READ);
        this.ioSelector = ioSelector;
        this.inputBuffer = ByteBuffer.allocate(connectionManager.socketReceiveBufferSize);

        this.metricRegistry = connection.getConnectionManager().getMetricRegistry();
        metricRegistry.scanAndRegister(this, "tcp.connection[" + connection.getMetricsId() + "]");
    }

    @Probe(name = "in.idleTimeMs")
    private long idleTimeMs() {
        return Math.max(System.currentTimeMillis() - lastReadTime, 0);
    }

    @Probe(name = "in.interestedOps")
    private long interestOps() {
        SelectionKey selectionKey = this.selectionKey;
        return selectionKey == null ? -1 : selectionKey.interestOps();
    }

    @Probe(name = "in.readyOps")
    private long readyOps() {
        SelectionKey selectionKey = this.selectionKey;
        return selectionKey == null ? -1 : selectionKey.readyOps();
    }

    public Counter getNormalPacketsRead() {
        return normalPacketsRead;
    }

    public Counter getPriorityPacketsRead() {
        return priorityPacketsRead;
    }

    public void start() {
        ioSelector.addTaskAndWakeup(new Runnable() {
            @Override
            public void run() {
                getSelectionKey();

            }
        });
    }

    @Override
    public long getEventCount() {
        return eventCount.get();
    }

    
    @Override
    public void requestMigration(IOSelector newOwner) {
        ioSelector.addTaskAndWakeup(new StartMigrationTask(newOwner));
    }

    @Override
    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "eventCount is accessed by a single thread only.")
    public void handle() {
        eventCount.inc();
        lastReadTime = Clock.currentTimeMillis();
        if (!connection.isAlive()) {
            String message = "We are being asked to read, but connection is not live so we won't";
            logger.finest(message);
            return;
        }
        try {
            if (socketReader == null) {
                initializeSocketReader();
                if (socketReader == null) {
                    
                    return;
                }
            }
            int readBytes = socketChannel.read(inputBuffer);

            if (readBytes == -1) {
                throw new EOFException("Remote socket closed!");
            } else {
                bytesRead.inc(readBytes);
            }
        } catch (Throwable e) {
            handleSocketException(e);
            return;
        }
        try {
            if (inputBuffer.position() == 0) {
                return;
            }
            inputBuffer.flip();
            socketReader.read(inputBuffer);
            if (inputBuffer.hasRemaining()) {
                inputBuffer.compact();
            } else {
                inputBuffer.clear();
            }
        } catch (Throwable t) {
            handleSocketException(t);
        }
    }

    @Override
    void handleSocketException(Throwable e) {
        exceptionCount.inc();
        super.handleSocketException(e);
    }

    private void initializeSocketReader()
            throws IOException {
        if (socketReader == null) {
            final ByteBuffer protocolBuffer = ByteBuffer.allocate(3);
            int readBytes = socketChannel.read(protocolBuffer);
            if (readBytes == -1) {
                throw new EOFException("Could not read protocol type!");
            }
            if (readBytes == 0 && connectionManager.isSSLEnabled()) {
                
                return;
            }
            if (!protocolBuffer.hasRemaining()) {
                String protocol = bytesToString(protocolBuffer.array());
                WriteHandler writeHandler = connection.getWriteHandler();
                if (Protocols.CLUSTER.equals(protocol)) {
                    connection.setType(ConnectionType.MEMBER);
                    writeHandler.setProtocol(Protocols.CLUSTER);
                    socketReader = new SocketPacketReader(connection);
                } else if (Protocols.CLIENT_BINARY.equals(protocol)) {
                    writeHandler.setProtocol(Protocols.CLIENT_BINARY);
                    socketReader = new SocketClientDataReader(connection);
                } else if (Protocols.CLIENT_BINARY_NEW.equals(protocol)) {
                    writeHandler.setProtocol(Protocols.CLIENT_BINARY_NEW);
                    socketReader = new SocketClientMessageReader(connection, socketChannel);
                } else {
                    writeHandler.setProtocol(Protocols.TEXT);
                    inputBuffer.put(protocolBuffer.array());
                    socketReader = new SocketTextReader(connection);
                    connection.getConnectionManager().incrementTextConnections();
                }
            }
            if (socketReader == null) {
                throw new IOException("Could not initialize SocketReader!");
            }
        }
    }

    long getLastReadTime() {
        return lastReadTime;
    }

    void shutdown() {
        
        
        metricRegistry.deregister(this);
        ioSelector.addTaskAndWakeup(new Runnable() {
            @Override
            public void run() {
                try {
                    socketChannel.closeInbound();
                } catch (IOException e) {
                    logger.finest("Error while closing inbound", e);
                }
            }
        });
    }

    @Override
    public String toString() {
        return connection + ".readHandler";
    }

    private class StartMigrationTask implements Runnable {
        private final IOSelector newOwner;

        public StartMigrationTask(IOSelector newOwner) {
            this.newOwner = newOwner;
        }

        @Override
        public void run() {
            
            if (ioSelector == newOwner) {
                return;
            }

            startMigration(newOwner);
        }
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.SocketWritable;

import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.Socket;
import java.net.SocketAddress;


public final class TcpIpConnection implements Connection {

    private final SocketChannelWrapper socketChannel;

    private final ReadHandler readHandler;

    private final WriteHandler writeHandler;

    private final TcpIpConnectionManager connectionManager;

    private volatile boolean live = true;

    private volatile ConnectionType type = ConnectionType.NONE;

    private Address endPoint;

    private final ILogger logger;

    private final int connectionId;

    private TcpIpConnectionMonitor monitor;

    public TcpIpConnection(TcpIpConnectionManager connectionManager,
                           IOSelector in,
                           IOSelector out,
                           int connectionId,
                           SocketChannelWrapper socketChannel) {
        this.connectionId = connectionId;
        this.logger = connectionManager.ioService.getLogger(TcpIpConnection.class.getName());
        this.connectionManager = connectionManager;
        this.socketChannel = socketChannel;
        this.writeHandler = new WriteHandler(this, out);
        this.readHandler = new ReadHandler(this, in);
    }

    
    public void start() {
        readHandler.start();
    }

    @Override
    public ConnectionType getType() {
        return type;
    }

    public TcpIpConnectionManager getConnectionManager() {
        return connectionManager;
    }

    @Override
    public boolean write(SocketWritable packet) {
        if (!live) {
            if (logger.isFinestEnabled()) {
                logger.finest("Connection is closed, won't write packet -> " + packet);
            }
            return false;
        }
        writeHandler.offer(packet);
        return true;
    }

    @Override
    public boolean isClient() {
        final ConnectionType t = type;
        return (t != null) && t != ConnectionType.NONE && t.isClient();
    }

    public void setType(ConnectionType type) {
        if (this.type == ConnectionType.NONE) {
            this.type = type;
        }
    }

    public SocketChannelWrapper getSocketChannelWrapper() {
        return socketChannel;
    }

    @Override
    public InetAddress getInetAddress() {
        return socketChannel.socket().getInetAddress();
    }

    @Override
    public int getPort() {
        return socketChannel.socket().getPort();
    }

    @Override
    public InetSocketAddress getRemoteSocketAddress() {
        return (InetSocketAddress) socketChannel.socket().getRemoteSocketAddress();
    }

    public ReadHandler getReadHandler() {
        return readHandler;
    }

    public WriteHandler getWriteHandler() {
        return writeHandler;
    }

    @Override
    public boolean isAlive() {
        return live;
    }

    @Override
    public long lastWriteTime() {
        return writeHandler.getLastWriteTime();
    }

    @Override
    public long lastReadTime() {
        return readHandler.getLastReadTime();
    }

    @Override
    public Address getEndPoint() {
        return endPoint;
    }

    public void setEndPoint(Address endPoint) {
        this.endPoint = endPoint;
    }

    public void setMonitor(TcpIpConnectionMonitor monitor) {
        this.monitor = monitor;
    }

    public TcpIpConnectionMonitor getMonitor() {
        return monitor;
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (!(o instanceof TcpIpConnection)) {
            return false;
        }
        TcpIpConnection that = (TcpIpConnection) o;
        return connectionId == that.getConnectionId();
    }

    @Override
    public int hashCode() {
        return connectionId;
    }

    private void close0() throws IOException {
        if (!live) {
            return;
        }
        live = false;

        if (socketChannel != null && socketChannel.isOpen()) {
            readHandler.shutdown();
            writeHandler.shutdown();
            socketChannel.close();
        }
    }

    @Override
    public void close() {
        close(null);
    }

    public void close(Throwable t) {
        if (!live) {
            return;
        }
        try {
            close0();
        } catch (Exception e) {
            logger.warning(e);
        }

        Object connAddress = getConnectionAddress();
        String message = "Connection [" + connAddress + "] lost. Reason: ";
        if (t != null) {
            message += t.getClass().getName() + "[" + t.getMessage() + "]";
        } else {
            message += "Socket explicitly closed";
        }

        logger.info(message);
        connectionManager.destroyConnection(this);
        connectionManager.ioService.onDisconnect(endPoint);
        if (t != null && monitor != null) {
            monitor.onError(t);
        }
    }

    Object getConnectionAddress() {
        return (endPoint == null) ? socketChannel.socket().getRemoteSocketAddress() : endPoint;
    }

    Object getMetricsId() {
        Socket socket = this.socketChannel.socket();
        SocketAddress localSocketAddress = socket != null ? socket.getLocalSocketAddress() : null;
        SocketAddress remoteSocketAddress = socket != null ? socket.getRemoteSocketAddress() : null;
        return getType() + "#" + localSocketAddress + "->" + remoteSocketAddress;
    }

    public int getConnectionId() {
        return connectionId;
    }

    @Override
    public String toString() {
        Socket socket = this.socketChannel.socket();
        SocketAddress localSocketAddress = socket != null ? socket.getLocalSocketAddress() : null;
        SocketAddress remoteSocketAddress = socket != null ? socket.getRemoteSocketAddress() : null;
        return "Connection [" + localSocketAddress + " -> " + remoteSocketAddress
                + "], endpoint=" + endPoint + ", live=" + live + ", type=" + type;
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.Protocols;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.nio.ascii.SocketTextWriter;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.counters.SwCounter;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.SelectionKey;
import java.util.Queue;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.logging.Level;

import static com.hazelcast.util.StringUtil.stringToBytes;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;


public final class WriteHandler extends AbstractSelectionHandler implements Runnable {

    private static final long TIMEOUT = 3;

    @Probe(name = "out.writeQueueSize")
    private final Queue<SocketWritable> writeQueue = new ConcurrentLinkedQueue<SocketWritable>();
    @Probe(name = "out.priorityWriteQueueSize")
    private final Queue<SocketWritable> urgentWriteQueue = new ConcurrentLinkedQueue<SocketWritable>();
    private final AtomicBoolean scheduled = new AtomicBoolean(false);
    private final ByteBuffer outputBuffer;
    @Probe(name = "out.bytesWritten")
    private final SwCounter bytesWritten = newSwCounter();
    @Probe(name = "out.normalPacketsWritten")
    private final SwCounter normalPacketsWritten = newSwCounter();
    @Probe(name = "out.priorityPacketsWritten")
    private final SwCounter priorityPacketsWritten = newSwCounter();
    @Probe(name = "out.exceptionCount")
    private final SwCounter exceptionCount = newSwCounter();
    private final MetricsRegistry metricsRegistry;

    private volatile SocketWritable currentPacket;
    private SocketWriter socketWriter;
    private volatile long lastWriteTime;
    
    @Probe(name = "out.eventCount")
    private volatile long eventCount;
    private boolean shutdown;
    
    
    
    private IOSelector newOwner;

    WriteHandler(TcpIpConnection connection, IOSelector ioSelector) {
        super(connection, ioSelector, SelectionKey.OP_WRITE);
        this.outputBuffer = ByteBuffer.allocate(connectionManager.socketSendBufferSize);

        
        this.metricsRegistry = connection.getConnectionManager().getMetricRegistry();
        metricsRegistry.scanAndRegister(this, "tcp.connection[" + connection.getMetricsId() + "]");
    }

    @Probe(name = "out.interestedOps")
    private long interestOps() {
        SelectionKey selectionKey = this.selectionKey;
        return selectionKey == null ? -1 : selectionKey.interestOps();
    }

    @Probe(name = "out.readyOps")
    private long readyOps() {
        SelectionKey selectionKey = this.selectionKey;
        return selectionKey == null ? -1 : selectionKey.readyOps();
    }

    long getLastWriteTime() {
        return lastWriteTime;
    }

    public SocketWriter getSocketWriter() {
        return socketWriter;
    }

    @Probe(name = "out.writeQueuePendingBytes")
    private long bytesPending() {
        return bytesPending(writeQueue);
    }

    @Probe(name = "out.priorityWriteQueuePendingBytes")
    private long priorityBytesPending() {
        return bytesPending(urgentWriteQueue);
    }

    private long bytesPending(Queue<SocketWritable> writeQueue) {
        long bytesPending = 0;
        for (SocketWritable writable : writeQueue) {
            if (writable instanceof Packet) {
                bytesPending += ((Packet) writable).size();
            }
        }
        return bytesPending;
    }

    @Probe(name = "out.currentPacketSet")
    private long currentPacketSet() {
        return currentPacket == null ? 0 : 1;
    }

    @Probe(name = "out.idleTimeMs")
    private long idleTimeMs() {
        return Math.max(System.currentTimeMillis() - lastWriteTime, 0);
    }

    @Probe(name = "out.isScheduled")
    private long isScheduled() {
        return scheduled.get() ? 1 : 0;
    }

    
    void setProtocol(final String protocol) {
        final CountDownLatch latch = new CountDownLatch(1);
        ioSelector.addTaskAndWakeup(new Runnable() {
            @Override
            public void run() {
                createWriter(protocol);
                latch.countDown();
            }
        });
        try {
            latch.await(TIMEOUT, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            logger.finest("CountDownLatch::await interrupted", e);
        }
    }

    private void createWriter(String protocol) {
        if (socketWriter == null) {
            if (Protocols.CLUSTER.equals(protocol)) {
                socketWriter = new SocketPacketWriter(connection);
                outputBuffer.put(stringToBytes(Protocols.CLUSTER));
                registerOp(SelectionKey.OP_WRITE);
            } else if (Protocols.CLIENT_BINARY.equals(protocol)) {
                socketWriter = new SocketClientDataWriter();
            } else if (Protocols.CLIENT_BINARY_NEW.equals(protocol)) {
                socketWriter = new SocketClientMessageWriter();
            } else {
                socketWriter = new SocketTextWriter(connection);
            }
        }
    }

    public void offer(SocketWritable packet) {
        if (packet.isUrgent()) {
            urgentWriteQueue.offer(packet);
        } else {
            writeQueue.offer(packet);
        }

        schedule();
    }

    private SocketWritable poll() {
        for (; ; ) {
            boolean urgent = true;
            SocketWritable packet = urgentWriteQueue.poll();

            if (packet == null) {
                urgent = false;
                packet = writeQueue.poll();
            }

            if (packet == null) {
                return null;
            }

            if (packet instanceof TaskPacket) {
                ((TaskPacket) packet).run();
                continue;
            }

            if (urgent) {
                priorityPacketsWritten.inc();
            } else {
                normalPacketsWritten.inc();
            }

            return packet;
        }
    }

    
    private void schedule() {
        if (scheduled.get()) {
            
            return;
        }

        if (!scheduled.compareAndSet(false, true)) {
            
            
            return;
        }

        
        
        ioSelector.addTaskAndWakeup(this);
    }

    
    private void unschedule() {
        if (dirtyOutputBuffer() || currentPacket != null) {
            
            
            registerOp(SelectionKey.OP_WRITE);

            
            
            return;
        }

        
        unregisterOp(SelectionKey.OP_WRITE);
        
        scheduled.set(false);

        if (writeQueue.isEmpty() && urgentWriteQueue.isEmpty()) {
            
            return;
        }

        
        

        if (!scheduled.compareAndSet(false, true)) {
            
            return;
        }

        
        
        
        ioSelector.addTask(this);
    }

    @Override
    public long getEventCount() {
        return eventCount;
    }

    @Override
    @SuppressWarnings("unchecked")
    @SuppressFBWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "eventCount is accessed by a single thread only.")
    public void handle() {
        eventCount++;
        lastWriteTime = Clock.currentTimeMillis();
        if (shutdown) {
            return;
        }

        if (socketWriter == null) {
            logger.log(Level.WARNING, "SocketWriter is not set, creating SocketWriter with CLUSTER protocol!");
            createWriter(Protocols.CLUSTER);
        }

        try {
            fillOutputBuffer();

            if (dirtyOutputBuffer()) {
                writeOutputBufferToSocket();
            }
        } catch (Throwable t) {
            exceptionCount.inc();
            logger.severe("Fatal Error at WriteHandler for endPoint: " + connection.getEndPoint(), t);
        }

        if (newOwner == null) {
            unschedule();
        } else {
            IOSelector newOwner = this.newOwner;
            this.newOwner = null;
            startMigration(newOwner);
        }
    }

    
    private boolean dirtyOutputBuffer() {
        return outputBuffer.position() > 0;
    }

    
    private void writeOutputBufferToSocket() throws Exception {
        
        outputBuffer.flip();
        try {
            int result = socketChannel.write(outputBuffer);
            this.bytesWritten.inc(result);
        } catch (Exception e) {
            currentPacket = null;
            handleSocketException(e);
            return;
        }
        
        if (!outputBuffer.hasRemaining()) {
            
            outputBuffer.clear();
            return;
        }
        
        
        outputBuffer.compact();
    }

    
    private void fillOutputBuffer() throws Exception {
        for (; ; ) {
            if (!outputBuffer.hasRemaining()) {
                
                return;
            }

            
            if (currentPacket == null) {
                currentPacket = poll();
                if (currentPacket == null) {
                    
                    return;
                }
            }

            
            if (!socketWriter.write(currentPacket, outputBuffer)) {
                
                return;
            }

            
            currentPacket = null;
        }
    }

    @Override
    public void run() {
        try {
            handle();
        } catch (Throwable e) {
            ioSelector.handleSelectionKeyFailure(e);
        }
    }

    public void shutdown() {
        metricsRegistry.deregister(this);
        writeQueue.clear();
        urgentWriteQueue.clear();

        ShutdownTask shutdownTask = new ShutdownTask();
        offer(shutdownTask);
        shutdownTask.awaitCompletion();
    }

    @Override
    public void requestMigration(IOSelector newOwner) {
        offer(new StartMigrationTask(newOwner));
    }

    @Override
    public String toString() {
        return connection + ".writeHandler";
    }

    
    private abstract class TaskPacket implements SocketWritable {
        abstract void run();

        @Override
        public boolean writeTo(ByteBuffer destination) {
            throw new UnsupportedOperationException();
        }

        @Override
        public boolean isUrgent() {
            return true;
        }
    }

    
    private class StartMigrationTask extends TaskPacket {
        
        
        private final IOSelector theNewOwner;

        public StartMigrationTask(IOSelector theNewOwner) {
            this.theNewOwner = theNewOwner;
        }

        @Override
        void run() {
            assert newOwner == null : "No migration can be in progress";

            if (ioSelector == theNewOwner) {
                
                return;
            }

            newOwner = theNewOwner;
        }
    }

    private class ShutdownTask extends TaskPacket {
        private final CountDownLatch latch = new CountDownLatch(1);

        @Override
        void run() {
            shutdown = true;
            try {
                socketChannel.closeOutbound();
            } catch (IOException e) {
                logger.finest("Error while closing outbound", e);
            } finally {
                latch.countDown();
            }
        }

        void awaitCompletion() {
            try {
                latch.await(TIMEOUT, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                EmptyStatement.ignore(e);
            }
        }
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.util.counters.SwCounter;

import java.nio.channels.SelectionKey;

import static com.hazelcast.util.counters.SwCounter.newSwCounter;

public final class InSelectorImpl extends AbstractIOSelector {

    
    @Probe
    private final SwCounter readEvents = newSwCounter();

    public InSelectorImpl(ThreadGroup threadGroup, String tname, ILogger logger,
                          IOSelectorOutOfMemoryHandler oomeHandler) {
        super(threadGroup, tname, logger, oomeHandler);
    }


    
    public long getReadEvents() {
        return readEvents.get();
    }

    @Override
    protected void handleSelectionKey(SelectionKey sk) {
        if (sk.isValid() && sk.isReadable()) {
            readEvents.inc();
            SelectionHandler handler = (SelectionHandler) sk.attachment();
            handler.handle();
        }
    }
}

<code block>


package com.hazelcast.nio.tcp.iobalancer;

import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.tcp.IOSelector;
import com.hazelcast.nio.tcp.InSelectorImpl;
import com.hazelcast.nio.tcp.MigratableHandler;
import com.hazelcast.nio.tcp.OutSelectorImpl;
import com.hazelcast.nio.tcp.ReadHandler;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.nio.tcp.WriteHandler;
import com.hazelcast.util.counters.MwCounter;
import com.hazelcast.util.counters.SwCounter;
import static com.hazelcast.util.counters.MwCounter.newMwCounter;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;

import static com.hazelcast.instance.GroupProperties.PROP_IO_BALANCER_INTERVAL_SECONDS;
import static com.hazelcast.instance.GroupProperties.PROP_IO_THREAD_COUNT;


public class IOBalancer {
    private static final String PROP_MONKEY_BALANCER = "hazelcast.io.balancer.monkey";
    private final ILogger logger;

    private final int balancerIntervalSeconds;
    private final MigrationStrategy strategy;

    private final LoadTracker inLoadTracker;
    private final LoadTracker outLoadTracker;

    private final HazelcastThreadGroup threadGroup;
    private volatile boolean enabled;
    private IOBalancerThread ioBalancerThread;

    
    @Probe
    private final SwCounter imbalanceDetectedCount = newSwCounter();

    
    @Probe
    private final MwCounter migrationCompletedCount = newMwCounter();

    public IOBalancer(InSelectorImpl[] inSelectors, OutSelectorImpl[] outSelectors, HazelcastThreadGroup threadGroup,
                      int balancerIntervalSeconds, LoggingService loggingService) {
        this.logger = loggingService.getLogger(IOBalancer.class);
        this.balancerIntervalSeconds = balancerIntervalSeconds;

        this.strategy = createMigrationStrategy();
        this.threadGroup = threadGroup;

        this.inLoadTracker = new LoadTracker(inSelectors, logger);
        this.outLoadTracker = new LoadTracker(outSelectors, logger);

        this.enabled = isEnabled(inSelectors, outSelectors);
    }

    public void connectionAdded(Connection connection) {
        if (!(connection instanceof TcpIpConnection)) {
            return;
        }

        TcpIpConnection tcpIpConnection = (TcpIpConnection) connection;
        ReadHandler readHandler = tcpIpConnection.getReadHandler();
        WriteHandler writeHandler = tcpIpConnection.getWriteHandler();

        if (logger.isFinestEnabled()) {
            logger.finest("Connection " + connection + " uses read handler "
                    + readHandler + " and write handler " + writeHandler);
        }

        inLoadTracker.addHandler(readHandler);
        outLoadTracker.addHandler(writeHandler);
    }

    public void connectionRemoved(Connection connection) {
        if (!(connection instanceof TcpIpConnection)) {
            return;
        }

        TcpIpConnection tcpIpConnection = (TcpIpConnection) connection;
        ReadHandler readHandler = tcpIpConnection.getReadHandler();
        if (logger.isFinestEnabled()) {
            logger.finest("Removing read handler " + readHandler);
        }
        inLoadTracker.removeHandler(readHandler);

        WriteHandler writeHandler = tcpIpConnection.getWriteHandler();
        if (logger.isFinestEnabled()) {
            logger.finest("Removing write handler " + readHandler);
        }
        outLoadTracker.removeHandler(writeHandler);
    }

    public void start() {
        if (enabled) {
            ioBalancerThread = new IOBalancerThread(this, balancerIntervalSeconds, threadGroup, logger);
            ioBalancerThread.start();
        }
    }

    public void stop() {
        if (ioBalancerThread != null) {
            ioBalancerThread.shutdown();
        }
    }

    void checkWriteHandlers() {
        scheduleMigrationIfNeeded(outLoadTracker);
    }

    void checkReadHandlers() {
        scheduleMigrationIfNeeded(inLoadTracker);
    }

    private void scheduleMigrationIfNeeded(LoadTracker loadTracker) {
        LoadImbalance loadImbalance = loadTracker.updateImbalance();
        if (strategy.imbalanceDetected(loadImbalance)) {
            imbalanceDetectedCount.inc();
            tryMigrate(loadImbalance);
        } else {
            if (logger.isFinestEnabled()) {
                long min = loadImbalance.minimumEvents;
                long max = loadImbalance.maximumEvents;
                logger.finest("No imbalance has been detected. Max. events: " + max + " Min events: " + min + ".");
            }
        }
    }

    private MigrationStrategy createMigrationStrategy() {
        if (Boolean.getBoolean(PROP_MONKEY_BALANCER)) {
            logger.warning("Using Monkey IO Balancer Strategy. This is for stress tests only. Do not user in production! "
                    + "Disable by not setting the property '" + PROP_MONKEY_BALANCER + "' to true.");
            return new MonkeyMigrationStrategy();
        } else {
            logger.finest("Using normal IO Balancer Strategy.");
            return new EventCountBasicMigrationStrategy();
        }
    }

    private boolean isEnabled(InSelectorImpl[] inSelectors, OutSelectorImpl[] outSelectors) {
        if (balancerIntervalSeconds <= 0) {
            logger.warning("I/O Balancer is disabled as the '"
                    + PROP_IO_BALANCER_INTERVAL_SECONDS + "' property is set to "
                    + balancerIntervalSeconds + ". Set the property to a value larger than 0 to enable the I/O Balancer.");
            return false;
        }

        if (inSelectors.length == 1 && outSelectors.length == 1) {
            logger.finest("I/O Balancer is disabled as there is only a single a pair of I/O threads. Use the '"
                    + PROP_IO_THREAD_COUNT + "' property to increase number of I/O Threads.");
            return false;
        }

        if (logger.isFinestEnabled()) {
            logger.finest("I/O Balancer is enabled. Scanning every " + balancerIntervalSeconds + " seconds for imbalances.");
        }

        return true;
    }

    private void tryMigrate(LoadImbalance loadImbalance) {
        MigratableHandler handler = strategy.findHandlerToMigrate(loadImbalance);
        if (handler == null) {
            logger.finest("I/O imbalance is detected, but no suitable migration candidate is found.");
            return;
        }

        IOSelector destinationSelector = loadImbalance.destinationSelector;
        if (logger.isFinestEnabled()) {
            IOSelector sourceSelector = loadImbalance.sourceSelector;
            logger.finest("Scheduling migration of handler " + handler
                    + " from selector thread " + sourceSelector + " to " + destinationSelector);
        }
        handler.requestMigration(destinationSelector);
    }

    public void signalMigrationComplete() {
        migrationCompletedCount.inc();
    }
}

<code block>


package com.hazelcast.nio.tcp.iobalancer;

import com.hazelcast.nio.tcp.MigratableHandler;
import java.util.Set;


class EventCountBasicMigrationStrategy implements MigrationStrategy {

    
    private static final double MIN_MAX_RATIO_MIGRATION_THRESHOLD = 0.8;

    
    private static final double MAXIMUM_NO_OF_EVENTS_AFTER_MIGRATION_COEFFICIENT = 0.9;

    
    @Override
    public boolean imbalanceDetected(LoadImbalance imbalance) {
        long min = imbalance.minimumEvents;
        long max = imbalance.maximumEvents;

        if (min == Long.MIN_VALUE || max == Long.MAX_VALUE) {
            return false;
        }
        long lowerBound = (long) (MIN_MAX_RATIO_MIGRATION_THRESHOLD * max);
        return min < lowerBound;
    }

    
    @Override
    public MigratableHandler findHandlerToMigrate(LoadImbalance imbalance) {
        Set<? extends MigratableHandler> candidates = imbalance.getHandlersOwnerBy(imbalance.sourceSelector);
        long migrationThreshold = (long) ((imbalance.maximumEvents - imbalance.minimumEvents)
                * MAXIMUM_NO_OF_EVENTS_AFTER_MIGRATION_COEFFICIENT);
        MigratableHandler candidate = null;
        long eventCountInSelectedHandler = 0;
        for (MigratableHandler handler : candidates) {
            long eventCount = imbalance.getEventCount(handler);
            if (eventCount > eventCountInSelectedHandler) {
                if (eventCount < migrationThreshold) {
                    eventCountInSelectedHandler = eventCount;
                    candidate = handler;
                }
            }
        }
        return candidate;
    }
}

<code block>
package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.HazelcastSerializationException;
import com.hazelcast.spi.AbstractOperation;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationResponseHandler;
import com.hazelcast.spi.WaitNotifyKey;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.test.ExpectedRuntimeException;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.spi.OperationAccessor.setCallId;
import static com.hazelcast.spi.OperationAccessor.setCallTimeout;
import static org.junit.Assert.assertEquals;
import static org.mockito.Matchers.any;
import static org.mockito.Matchers.same;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.never;
import static org.mockito.Mockito.verify;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class OperationRunnerImplTest extends HazelcastTestSupport {

    private HazelcastInstance local;
    private HazelcastInstance remote;
    private OperationRunnerImpl operationRunner;
    private OperationServiceImpl operationService;
    private ClusterService clusterService;
    private OperationResponseHandler responseHandler;

    @Before
    public void setup() {
        HazelcastInstance[] cluster = createHazelcastInstanceFactory(2).newInstances();
        local = cluster[0];
        remote = cluster[1];
        operationService = (OperationServiceImpl) getOperationService(local);
        clusterService = getClusterService(local);
        operationRunner = new OperationRunnerImpl(operationService, getPartitionId(local));
        responseHandler = mock(OperationResponseHandler.class);
    }

     @Test
    public void runTask() {
        final AtomicLong counter = new AtomicLong();
        operationRunner.run(new Runnable() {
            @Override
            public void run() {
                counter.incrementAndGet();
            }
        });
        assertEquals(1, counter.get());
    }

    @Test
    public void runOperation() {
        final AtomicLong counter = new AtomicLong();
        final Object response = "someresponse";
        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }

            @Override
            public Object getResponse() {
                return response;
            }
        };
        op.setPartitionId(operationRunner.getPartitionId());
        op.setOperationResponseHandler(responseHandler);

        operationRunner.run(op);
        assertEquals(1, counter.get());
        verify(responseHandler).sendResponse(op, response);
    }

    @Test
    public void runOperation_whenGeneric() {
        final AtomicLong counter = new AtomicLong();
        final Object response = "someresponse";

        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }

            @Override
            public Object getResponse() {
                return response;
            }
        };
        op.setPartitionId(-1);
        op.setOperationResponseHandler(responseHandler);

        operationRunner.run(op);

        assertEquals(1, counter.get());
        verify(responseHandler).sendResponse(op, response);
    }

    @Test
    public void runOperation_whenWrongPartition_thenTaskNotExecuted() {
        final AtomicLong counter = new AtomicLong();

        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }
        };
        op.setPartitionId(operationRunner.getPartitionId() + 1);
        op.setOperationResponseHandler(responseHandler);

        operationRunner.run(op);

        assertEquals(0, counter.get());
        verify(responseHandler).sendResponse(same(op), any(IllegalStateException.class));
    }

    @Test
    public void runOperation_whenRunThrowsException() {
        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                throw new ExpectedRuntimeException();
            }
        };
        op.setOperationResponseHandler(responseHandler);
        op.setPartitionId(operationRunner.getPartitionId());

        operationRunner.run(op);

        verify(responseHandler).sendResponse(same(op), any(ExpectedRuntimeException.class));
    }

    @Test
    public void runOperation_whenWaitingNeeded() {
        final AtomicLong counter = new AtomicLong();

        DummyWaitingOperation op = new DummyWaitingOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }
        };
        op.setPartitionId(operationRunner.getPartitionId());

        operationRunner.run(op);
        assertEquals(0, counter.get());
        
        verify(responseHandler, never()).sendResponse(same(op), any());
    }

    @Test
    public void runOperation_whenTimeout_thenOperationNotExecuted() {
        final AtomicLong counter = new AtomicLong();

        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }
        };
        setCallId(op, 10);
        setCallTimeout(op, clusterService.getClusterClock().getClusterTime() - 1);
        op.setPartitionId(operationRunner.getPartitionId());
        op.setOperationResponseHandler(responseHandler);

        operationRunner.run(op);
        assertEquals(0, counter.get());
        verify(responseHandler).sendResponse(same(op), any(CallTimeoutResponse.class));
    }

    @Test
    public void runPacket() throws Exception {
        Operation op = new DummyOperation();
        setCallId(op, 1000 * 1000);

        Packet packet = toPacket(remote, op);
        operationRunner.run(packet);
    }

    @Test(expected = HazelcastSerializationException.class)
    public void runPacket_whenBroken() throws Exception {
        Operation op = new DummyOperation();
        setCallId(op, 1000 * 1000);

        Packet packet = toPacket(remote, op);
        byte[] bytes = packet.getData().toByteArray();
        for (int k = 0; k < bytes.length; k++) {
            bytes[k]++;
        }
        operationRunner.run(packet);
    }

    public abstract class DummyWaitingOperation extends AbstractOperation implements WaitSupport {
        WaitNotifyKey waitNotifyKey = new WaitNotifyKey() {
            @Override
            public String getServiceName() {
                return "someservice";
            }

            @Override
            public String getObjectName() {
                return "someobject";
            }
        };

        @Override
        public WaitNotifyKey getWaitKey() {
            return waitNotifyKey;
        }

        @Override
        public boolean shouldWait() {
            return true;
        }

        @Override
        public void onWaitExpire() {
        }
    }
}
<code block>
package com.hazelcast.spi.impl.operationexecutor.classic;

import com.hazelcast.config.Config;
import com.hazelcast.instance.BuildInfo;
import com.hazelcast.instance.DefaultNodeExtension;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.logging.LoggingServiceImpl;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.impl.operationexecutor.OperationHostileThread;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.impl.DefaultSerializationServiceBuilder;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.spi.AbstractOperation;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.operationexecutor.ResponsePacketHandler;
import com.hazelcast.spi.impl.operationexecutor.OperationRunner;
import com.hazelcast.spi.impl.operationexecutor.OperationRunnerFactory;
import com.hazelcast.spi.impl.operationservice.impl.responses.Response;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastTestSupport;
import org.junit.After;
import org.junit.Before;

import java.io.IOException;
import java.util.LinkedList;
import java.util.List;

import static java.util.Collections.synchronizedList;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;


public abstract class AbstractClassicOperationExecutorTest extends HazelcastTestSupport {

    protected LoggingServiceImpl loggingService;
    protected GroupProperties groupProperties;
    protected Address thisAddress;
    protected HazelcastThreadGroup threadGroup;
    protected DefaultNodeExtension nodeExtension;
    protected OperationRunnerFactory handlerFactory;
    protected SerializationService serializationService;
    protected ResponsePacketHandler responsePacketHandler;
    protected ClassicOperationExecutor executor;
    protected Config config;
    protected MetricsRegistry metricsRegistry;

    @Before
    public void setup() throws Exception {
        loggingService = new LoggingServiceImpl("foo", "jdk", new BuildInfo("1", "1", "1", 1, false));

        serializationService = new DefaultSerializationServiceBuilder().build();
        config = new Config();
        config.setProperty(GroupProperties.PROP_PARTITION_COUNT, "10");
        config.setProperty(GroupProperties.PROP_PARTITION_OPERATION_THREAD_COUNT, "10");
        config.setProperty(GroupProperties.PROP_GENERIC_OPERATION_THREAD_COUNT, "10");
        thisAddress = new Address("localhost", 5701);
        threadGroup = new HazelcastThreadGroup(
                "foo",
                loggingService.getLogger(HazelcastThreadGroup.class),
                Thread.currentThread().getContextClassLoader());
        nodeExtension = new DefaultNodeExtension();
        handlerFactory = new DummyOperationRunnerFactory();

        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistry.class));
        responsePacketHandler = new DummyResponsePacketHandler();
    }

    protected ClassicOperationExecutor initExecutor() {
        groupProperties = new GroupProperties(config);
        executor = new ClassicOperationExecutor(
                groupProperties, loggingService, thisAddress, handlerFactory, responsePacketHandler,
                threadGroup, nodeExtension, metricsRegistry);
        return executor;
    }

    public static <E> void assertEqualsEventually(final PartitionSpecificCallable task, final E expected) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertTrue(task + " has not given a response", task.completed());
                assertEquals(expected, task.getResult());
            }
        });
    }

    protected class DummyResponsePacketHandler implements ResponsePacketHandler {
        protected List<Packet> packets = synchronizedList(new LinkedList<Packet>());
        protected List<Response> responses = synchronizedList(new LinkedList<Response>());

        @Override
        public void handle(Packet packet) throws Exception {
            packets.add(packet);
            Response response = serializationService.toObject(packet.getData());
            responses.add(response);
        }
    }

    @After
    public void teardown() {
        if (executor != null) {
            executor.shutdown();
        }
    }

    protected static class DummyGenericOperation extends DummyOperation {
        public DummyGenericOperation() {
            super(GENERIC_PARTITION_ID);
        }
    }

    protected static class DummyPartitionOperation extends DummyOperation {
        public DummyPartitionOperation() {
            this(0);
        }

        public DummyPartitionOperation(int partitionId) {
            super(partitionId);
        }
    }

    protected static class DummyOperation extends AbstractOperation {
        private int durationMs;

        public DummyOperation(int partitionId) {
            setPartitionId(partitionId);
        }

        public DummyOperation durationMs(int durationMs) {
            this.durationMs = durationMs;
            return this;
        }

        @Override
        public void run() throws Exception {
            try {
                Thread.sleep(durationMs);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }

        @Override
        protected void writeInternal(ObjectDataOutput out) throws IOException {
            super.writeInternal(out);
            out.writeInt(durationMs);
        }

        @Override
        protected void readInternal(ObjectDataInput in) throws IOException {
            super.readInternal(in);
            durationMs = in.readInt();
        }
    }

    protected class DummyOperationRunnerFactory implements OperationRunnerFactory {
        protected List<DummyOperationRunner> partitionOperationHandlers = new LinkedList<DummyOperationRunner>();
        protected List<DummyOperationRunner> genericOperationHandlers = new LinkedList<DummyOperationRunner>();
        protected DummyOperationRunner adhocHandler;

        @Override
        public OperationRunner createPartitionRunner(int partitionId) {
            DummyOperationRunner operationHandler = new DummyOperationRunner(partitionId);
            partitionOperationHandlers.add(operationHandler);
            return operationHandler;
        }

        @Override
        public OperationRunner createGenericRunner() {
            DummyOperationRunner operationHandler = new DummyOperationRunner(Operation.GENERIC_PARTITION_ID);
            genericOperationHandlers.add(operationHandler);
            return operationHandler;
        }

        @Override
        public OperationRunner createAdHocRunner() {
            if (adhocHandler != null) {
                throw new IllegalStateException("adHocHandler should only be created once");
            }
            
            DummyOperationRunner operationHandler = new DummyOperationRunner(-2);
            adhocHandler = operationHandler;
            return operationHandler;
        }
    }

    public class DummyOperationRunner extends OperationRunner {
        protected List<Packet> packets = synchronizedList(new LinkedList<Packet>());
        protected List<Operation> operations = synchronizedList(new LinkedList<Operation>());
        protected List<Runnable> tasks = synchronizedList(new LinkedList<Runnable>());

        public DummyOperationRunner(int partitionId) {
            super(partitionId);
        }

        @Override
        public void run(Runnable task) {
            tasks.add(task);
            task.run();
        }

        @Override
        public void run(Packet packet) throws Exception {
            packets.add(packet);
            Operation op = serializationService.toObject(packet.getData());
            run(op);
        }

        @Override
        public void run(Operation task) {
            operations.add(task);

            this.currentTask = task;
            try {
                task.run();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                currentTask = null;
            }
        }
    }

    protected static class DummyOperationHostileThread extends Thread implements OperationHostileThread {
        protected DummyOperationHostileThread(Runnable task) {
            super(task);
        }
    }
}

<code block>
package com.hazelcast.spi.impl.operationexecutor.classic;

import com.hazelcast.spi.Operation;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class ClassicOperationExecutorTest extends AbstractClassicOperationExecutorTest {

    @Test
    public void testConstruction() {
        initExecutor();

        assertEquals(groupProperties.PARTITION_COUNT.getInteger(), executor.getPartitionOperationRunners().length);
        assertEquals(executor.getGenericOperationThreadCount(), executor.getGenericOperationRunners().length);

        assertEquals(groupProperties.PARTITION_OPERATION_THREAD_COUNT.getInteger(),
                executor.getPartitionOperationThreadCount());

        assertEquals(groupProperties.GENERIC_OPERATION_THREAD_COUNT.getInteger(),
                executor.getGenericOperationThreadCount());
    }

    @Test
    public void test_getRunningOperationCount() {
        initExecutor();

        executor.execute(new DummyOperation(Operation.GENERIC_PARTITION_ID).durationMs(2000));
        executor.execute(new DummyOperation(Operation.GENERIC_PARTITION_ID).durationMs(2000));

        executor.execute(new DummyOperation(0).durationMs(2000));

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                int runningOperationCount = executor.getRunningOperationCount();
                System.out.println("runningOperationCount:" + runningOperationCount);
                assertEquals(3, runningOperationCount);
            }
        });
    }

    @Test
    public void test_getOperationExecutorQueueSize() {
        initExecutor();

        
        for (int k = 0; k < executor.getGenericOperationThreadCount(); k++) {
            executor.execute(new DummyOperation(Operation.GENERIC_PARTITION_ID).durationMs(2000));
        }
        for (int k = 0; k < executor.getPartitionOperationThreadCount(); k++) {
            executor.execute(new DummyOperation(k).durationMs(2000));
        }

        
        int count = 0;
        for (int l = 0; l < 3; l++) {
            for (int k = 0; k < executor.getGenericOperationThreadCount(); k++) {
                executor.execute(new DummyOperation(Operation.GENERIC_PARTITION_ID).durationMs(2000));
                count++;
            }
        }
        for (int l = 0; l < 5; l++) {
            for (int k = 0; k < executor.getPartitionOperationThreadCount(); k++) {
                executor.execute(new DummyOperation(k).durationMs(2000));
                count++;
            }
        }

        final int expectedCount = count;
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(expectedCount, executor.getOperationExecutorQueueSize());
            }
        });
    }
}

<code block>
package com.hazelcast.internal.monitors;

import com.hazelcast.config.Config;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastInstanceImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.spi.AbstractOperation;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.After;
import org.junit.AfterClass;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.lang.reflect.Field;

import static com.hazelcast.instance.GroupProperties.PROP_PERFORMANCE_MONITOR_DELAY_SECONDS;
import static com.hazelcast.instance.GroupProperties.PROP_PERFORMANCE_MONITOR_ENABLED;
import static com.hazelcast.instance.GroupProperties.PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT;
import static com.hazelcast.instance.GroupProperties.PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE_MB;
import static com.hazelcast.instance.GroupProperties.PROP_SLOW_OPERATION_DETECTOR_ENABLED;
import static com.hazelcast.instance.GroupProperties.PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class PerformanceMonitorTest extends HazelcastTestSupport {

    private PerformanceMonitor performanceMonitor;
    private PerformanceLogFile performanceLogFile;
    private InternalOperationService operationService;
    private MetricsRegistry metricsRegistry;
    private HazelcastInstance hz;

    @Before
    public void setup() {
        Config config = new Config();
        config.setProperty(PROP_PERFORMANCE_MONITOR_ENABLED, "true");
        config.setProperty(PROP_PERFORMANCE_MONITOR_DELAY_SECONDS, "1");
        config.setProperty(PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_SIZE_MB, "0.2");
        config.setProperty(PROP_PERFORMANCE_MONITOR_MAX_ROLLED_FILE_COUNT, "3");

        config.setProperty(PROP_SLOW_OPERATION_DETECTOR_ENABLED, "true");
        config.setProperty(PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS, "2000");

        hz = createHazelcastInstance(config);

        performanceMonitor = getPerformanceMonitor(hz);
        performanceLogFile = performanceMonitor.performanceLogFile;
        operationService = getOperationService(hz);
        metricsRegistry = getMetricsRegistry(hz);
    }

    @AfterClass
    public static void afterClass() {
        String userDir = System.getProperty("user.dir");

        for(File file: new File(userDir).listFiles()){
            String name = file.getName();
            System.out.println(name);
            if(name.startsWith("performance-_") && name.endsWith(".log")){
                file.delete();
            }
        }
    }

    @Test
    public void testDisabledByDefault() {
        GroupProperties groupProperties = new GroupProperties(new Config());
        assertFalse(groupProperties.PERFORMANCE_MONITOR_ENABLED.getBoolean());
    }

    @Test
    public void testHazelcastConfig() {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                String content = loadLogfile();
                assertNotNull(content);

                assertTrue(content.contains("Hazelcast Config"));
            }
        });
    }

    @Test
    public void testMetricsRegistry() {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                String content = loadLogfile();
                assertNotNull(content);

                assertTrue(content.contains("Metrics"));
                assertTrue(content.contains("operation.completed.count"));
            }
        });
    }

    @Test
    public void testSystemProperties() {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                String content = loadLogfile();
                assertNotNull(content);
                assertTrue(content.contains("System Properties"));
                assertTrue(content.contains("java.home"));
            }
        });
    }

    @Test
    public void testBuildInfo() {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                String content = loadLogfile();
                assertNotNull(content);

                assertTrue(content.contains("Build Info"));
                assertTrue(content.contains("BuildNumber"));
            }
        });
    }




















    @Test
    public void testSlowOperationTest() throws InterruptedException {
        operationService.invokeOnPartition(null, new MySlowOperation(), 1);

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                String content = loadLogfile();
                assertNotNull(content);

                assertTrue(content.contains("Slow Operations"));
                assertTrue(content.contains("MySlowOperation"));
            }
        });
    }

    private String loadLogfile() {
        File file = performanceLogFile.logFile;
        if (file == null || !file.exists()) {
            return null;
        }

        try {
            BufferedReader br = new BufferedReader(new FileReader(file));
            try {
                StringBuilder sb = new StringBuilder();
                String line = br.readLine();

                while (line != null) {
                    sb.append(line);
                    sb.append("\n");
                    line = br.readLine();
                }
                return sb.toString();
            } finally {
                br.close();
            }
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }

    public PerformanceMonitor getPerformanceMonitor(HazelcastInstance hazelcastInstance) {
        try {
            Field field = HazelcastInstanceImpl.class.getDeclaredField("performanceMonitor");
            Node node = getNode(hazelcastInstance);
            field.setAccessible(true);
            return (PerformanceMonitor) field.get(node.hazelcastInstance);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

    private static class MySlowOperation extends AbstractOperation {
        @Override
        public void run() throws Exception {
            Thread.sleep(10000);
        }
    }
}

<code block>
package com.hazelcast.internal.monitors;

import com.hazelcast.config.Config;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static com.hazelcast.instance.GroupProperties.PROP_HEALTH_MONITORING_DELAY_SECONDS;
import static com.hazelcast.instance.GroupProperties.PROP_HEALTH_MONITORING_LEVEL;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class HealthMonitorTest extends HazelcastTestSupport {
    private HealthMonitor healthMonitor;
    private HealthMonitor.HealthMetrics metrics;
    private MetricsRegistry metricsRegistry;

    @Before
    public void setup() {
        Config config = new Config();
        config.setProperty(PROP_HEALTH_MONITORING_LEVEL, HealthMonitorLevel.NOISY.toString());
        config.setProperty(PROP_HEALTH_MONITORING_DELAY_SECONDS, "1");

        HazelcastInstance hz = createHazelcastInstance(config);
        healthMonitor = new HealthMonitor(getNode(hz));
        metricsRegistry = getMetricsRegistry(hz);
        metrics = healthMonitor.healthMetrics;
    }

    private void registerMetric(Metric metric, final int value) {
        metricsRegistry.register(this, metric.getName(), new DoubleProbeFunction<HealthMonitorTest>() {
            @Override
            public double get(HealthMonitorTest source) throws Exception {
                return value;
            }
        });
    }

    @Test
    public void exceedsThreshold_when_notTooHigh() {
        registerMetric(metrics.osProcessCpuLoad, 0);
        registerMetric(metrics.operationServicePendingInvocationsPercentage, 0);
        registerMetric(metrics.osSystemCpuLoad, 0);
        registerMetric(metrics.runtimeUsedMemory, 0);
        registerMetric(metrics.runtimeMaxMemory, 100);

        boolean result = metrics.exceedsThreshold();
        assertFalse(result);
    }

    @Test
    public void exceedsThreshold_when_osProcessCpuLoad_tooHigh() {
        registerMetric(metrics.osProcessCpuLoad, 90);
        boolean result = metrics.exceedsThreshold();
        assertTrue(result);
    }

    @Test
    public void exceedsThreshold_when_osSystemCpuLoad_TooHigh() {
        registerMetric(metrics.osSystemCpuLoad, 90);
        boolean result = metrics.exceedsThreshold();
        assertTrue(result);
    }

    @Test
    public void exceedsThreshold_operationServicePendingInvocationsPercentage() {
        registerMetric(metrics.operationServicePendingInvocationsPercentage, 90);
        boolean result = metrics.exceedsThreshold();
        assertTrue(result);
    }

    @Test
    public void exceedsThreshold_memoryUsedOfMaxPercentage() {
        registerMetric(metrics.runtimeUsedMemory, 90);
        registerMetric(metrics.runtimeMaxMemory, 100);
        metrics.update();
        boolean result = metrics.exceedsThreshold();
        assertTrue(result);
    }

    @Test
    public void render() {
        String s = metrics.render();

        assertContains(s,"processors=");

        
        
    }

    private void assertContains(String s, String expected){
        boolean contains = s.contains(expected);
        assertTrue(contains);
    }
}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.management.ManagementFactory;
import java.util.concurrent.TimeUnit;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class RuntimeMetricSetTest extends HazelcastTestSupport {

    private final static int TEN_MB = 10 * 1024 * 1024;

    private MetricsRegistryImpl blackbox;
    private Runtime runtime;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
        runtime = Runtime.getRuntime();
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(RuntimeMetricSet.class);
    }

    @Test
    public void freeMemory() {
        final LongGauge gauge = blackbox.newLongGauge("runtime.freeMemory");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(runtime.freeMemory(), gauge.read(), TEN_MB);
            }
        });
    }

    @Test
    public void totalMemory() {
        final LongGauge gauge = blackbox.newLongGauge("runtime.totalMemory");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(runtime.totalMemory(), gauge.read(), TEN_MB);
            }
        });
    }

    @Test
    public void maxMemory() {
        final LongGauge gauge = blackbox.newLongGauge("runtime.maxMemory");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(runtime.maxMemory(), gauge.read(), TEN_MB);
            }
        });
    }

    @Test
    public void usedMemory() {
        final LongGauge gauge = blackbox.newLongGauge("runtime.usedMemory");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                double expected = runtime.totalMemory() - runtime.freeMemory();
                assertEquals(expected, gauge.read(), TEN_MB);
            }
        });
    }

    @Test
    public void availableProcessors() {
        LongGauge gauge = blackbox.newLongGauge("runtime.availableProcessors");
        assertEquals(runtime.availableProcessors(), gauge.read());
    }

    @Test
    public void uptime() {
        final LongGauge gauge = blackbox.newLongGauge("runtime.uptime");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                double expected = ManagementFactory.getRuntimeMXBean().getUptime();
                assertEquals(expected, gauge.read(), TimeUnit.MINUTES.toMillis(1));
            }
        });
    }
}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.management.ClassLoadingMXBean;
import java.lang.management.ManagementFactory;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class ClassLoadingMetricSetTest extends HazelcastTestSupport {

    private static final ClassLoadingMXBean BEAN = ManagementFactory.getClassLoadingMXBean();

    private MetricsRegistryImpl blackbox;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(ClassLoadingMetricSet.class);
    }

    @Test
    public void loadedClassesCount() {
        final LongGauge gauge = blackbox.newLongGauge("classloading.loadedClassesCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(BEAN.getLoadedClassCount(), gauge.read(), 100);
            }
        });
    }

    @Test
    public void totalLoadedClassesCount() {
        final LongGauge gauge = blackbox.newLongGauge("classloading.totalLoadedClassesCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(BEAN.getTotalLoadedClassCount(), gauge.read(), 100);
            }
        });
    }

    @Test
    public void unloadedClassCount() {
        final LongGauge gauge = blackbox.newLongGauge("classloading.unloadedClassCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(BEAN.getUnloadedClassCount(), gauge.read(), 100);
            }
        });
    }

}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.DoubleGauge;
import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.management.ManagementFactory;
import java.lang.management.OperatingSystemMXBean;

import static com.hazelcast.internal.metrics.metricsets.OperatingSystemMetricsSet.registerMethod;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import static org.junit.Assume.assumeTrue;



@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class OperatingSystemMetricSetTest extends HazelcastTestSupport {

    private MetricsRegistryImpl blackbox;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(OperatingSystemMetricsSet.class);
    }

    @Test
    public void testComSunManagementUnixOperatingSystem() {
        assertContainsSensor("os.systemLoadAverage");

        assumeOperatingSystemMXBean("com.sun.management.UnixOperatingSystem");

        assertContainsSensor("os.committedVirtualMemorySize");
        assertContainsSensor("os.freePhysicalMemorySize");
        assertContainsSensor("os.freeSwapSpaceSize");
        assertContainsSensor("os.processCpuTime");
        assertContainsSensor("os.totalPhysicalMemorySize");
        assertContainsSensor("os.totalSwapSpaceSize");
        assertContainsSensor("os.maxFileDescriptorCount");
        assertContainsSensor("os.openFileDescriptorCount");

        
        
        
    }

    @Test
    public void testSunManagementOperatingSystemImpl() {
        assertContainsSensor("os.systemLoadAverage");

        assumeOperatingSystemMXBean("sun.management.OperatingSystemImpl");

        assertContainsSensor("os.committedVirtualMemorySize");
        assertContainsSensor("os.freePhysicalMemorySize");
        assertContainsSensor("os.freeSwapSpaceSize");
        assertContainsSensor("os.processCpuTime");
        assertContainsSensor("os.totalPhysicalMemorySize");
        assertContainsSensor("os.totalSwapSpaceSize");
        assertContainsSensor("os.maxFileDescriptorCount");
        assertContainsSensor("os.openFileDescriptorCount");

        assertContainsSensor("os.processCpuLoad");
        assertContainsSensor("os.systemCpuLoad");
    }

    private void assertContainsSensor(String parameter) {
        boolean contains = blackbox.getNames().contains(parameter);
        assertTrue("sensor:" + parameter + " is not found", contains);
    }

    private void assumeOperatingSystemMXBean(String expected) {
        OperatingSystemMXBean bean = ManagementFactory.getOperatingSystemMXBean();

        String foundClass = bean.getClass().getName();

        assumeTrue(foundClass + " is not usable", expected.equals(foundClass));
    }

    @Test
    public void registerMethod_whenDouble() {
        FakeOperatingSystemBean fakeOperatingSystemBean = new FakeOperatingSystemBean();
        registerMethod(blackbox, fakeOperatingSystemBean, "doubleMethod", "doubleMethod");

        DoubleGauge gauge = blackbox.newDoubleGauge("doubleMethod");
        assertEquals(fakeOperatingSystemBean.doubleMethod(), gauge.read(), 0.1);
    }

    @Test
    public void registerMethod_whenLong() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));

        FakeOperatingSystemBean fakeOperatingSystemBean = new FakeOperatingSystemBean();
        registerMethod(blackbox, fakeOperatingSystemBean, "longMethod", "longMethod");

        LongGauge gauge = blackbox.newLongGauge("longMethod");
        assertEquals(fakeOperatingSystemBean.longMethod(), gauge.read());
    }

    @Test
    public void registerMethod_whenNotExist() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));

        FakeOperatingSystemBean fakeOperatingSystemBean = new FakeOperatingSystemBean();
        registerMethod(blackbox, fakeOperatingSystemBean, "notexist", "notexist");

        boolean parameterExist = blackbox.getNames().contains("notexist");
        assertFalse(parameterExist);
    }

    public class FakeOperatingSystemBean {
        double doubleMethod() {
            return 10;
        }

        long longMethod() {
            return 10;
        }
    }

}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.management.ManagementFactory;
import java.lang.management.ThreadMXBean;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class ThreadMetricSetTest extends HazelcastTestSupport {

    private static final ThreadMXBean MX_BEAN = ManagementFactory.getThreadMXBean();

    private MetricsRegistryImpl blackbox;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(ThreadMetricSet.class);
    }

    @Test
    public void threadCount() {
        final LongGauge gauge = blackbox.newLongGauge("thread.threadCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(MX_BEAN.getThreadCount(), gauge.read(), 10);
            }
        });
    }

    @Test
    public void peakThreadCount() {
        final LongGauge gauge = blackbox.newLongGauge("thread.peakThreadCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(MX_BEAN.getPeakThreadCount(), gauge.read(), 10);
            }
        });
    }

    @Test
    public void daemonThreadCount() {
        final LongGauge gauge = blackbox.newLongGauge("thread.daemonThreadCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(MX_BEAN.getDaemonThreadCount(), gauge.read(), 10);
            }
        });
    }

    @Test
    public void totalStartedThreadCount() {
        final LongGauge gauge = blackbox.newLongGauge("thread.totalStartedThreadCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(MX_BEAN.getTotalStartedThreadCount(), gauge.read(), 10);
            }
        });
    }
}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static java.util.concurrent.TimeUnit.SECONDS;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class GarbageCollectionMetricSetTest extends HazelcastTestSupport {

    private MetricsRegistryImpl blackbox;
    private GarbageCollectionMetricSet.GcStats gcStats;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
        gcStats = new GarbageCollectionMetricSet.GcStats();
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(GarbageCollectionMetricSet.class);
    }

    @Test
    public void minorCount() {
        final LongGauge gauge = blackbox.newLongGauge("gc.minorCount");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                 assertEquals(gcStats.minorCount, gauge.read(), 1);
            }
        });
    }

    @Test
    public void minorTime() throws InterruptedException {
        final LongGauge gauge = blackbox.newLongGauge("gc.minorTime");
         assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.minorTime, gauge.read(), SECONDS.toMillis(1));
            }
        });
    }

    @Test
    public void majorCount() {
        final LongGauge gauge = blackbox.newLongGauge("gc.majorCount");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.majorCount, gauge.read(), 1);
            }
        });
    }

    @Test
    public void majorTime() {
        final LongGauge gauge = blackbox.newLongGauge("gc.majorTime");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.majorTime, gauge.read(), SECONDS.toMillis(1));
            }
        });
    }


    @Test
    public void unknownCount() {
        final LongGauge gauge = blackbox.newLongGauge("gc.unknownCount");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.unknownCount, gauge.read(), 1);
            }
        });
    }

    @Test
    public void unknownTime() {
        final LongGauge gauge = blackbox.newLongGauge("gc.unknownTime");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.unknownTime, gauge.read(), SECONDS.toMillis(1));
            }
        });
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.internal.metrics.LongProbeFunction;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static java.lang.Math.round;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class LongGaugeImplTest {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    class SomeObject {
        @Probe
        long longField = 10;
        @Probe
        double doubleField = 10.8;
    }

    @Test
    public void getName() {
        LongGauge gauge = metricsRegistry.newLongGauge("foo");

        String actual = gauge.getName();

        assertEquals("foo", actual);
    }

    

    @Test
    public void whenNoProbeSet() {
        LongGauge gauge = metricsRegistry.newLongGauge("foo");

        long actual = gauge.read();

        assertEquals(0, actual);
    }

    @Test
    public void whenDoubleProbe() {
        metricsRegistry.register(this, "foo", new DoubleProbeFunction<LongGaugeImplTest>() {
            @Override
            public double get(LongGaugeImplTest source) throws Exception {
                return 10;
            }
        });

        LongGauge gauge = metricsRegistry.newLongGauge("foo");

        long actual = gauge.read();

        assertEquals(10, actual);
    }

    @Test
    public void whenLongProbe() {
        metricsRegistry.register(this, "foo", new LongProbeFunction() {
            @Override
            public long get(Object o) throws Exception {
                return 10;
            }
        });

        LongGauge gauge = metricsRegistry.newLongGauge("foo");
        assertEquals(10, gauge.read());
    }

    @Test
    public void whenProbeThrowsException() {
        metricsRegistry.register(this, "foo", new LongProbeFunction() {
            @Override
            public long get(Object o) {
                throw new RuntimeException();
            }
        });

        LongGauge gauge = metricsRegistry.newLongGauge("foo");

        long actual = gauge.read();

        assertEquals(0, actual);
    }

    @Test
    public void whenLongProbeField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.longField");
        assertEquals(10, gauge.read());
    }

    @Test
    public void whenDoubleProbeField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.doubleField");
        assertEquals(round(someObject.doubleField), gauge.read());
    }

    @Test
    public void whenReregister(){
        metricsRegistry.register(this, "foo", new LongProbeFunction() {
            @Override
            public long get(Object o) throws Exception {
                return 10;
            }
        });

        LongGauge gauge = metricsRegistry.newLongGauge("foo");

        gauge.read();

        metricsRegistry.register(this, "foo", new LongProbeFunction() {
            @Override
            public long get(Object o) throws Exception {
                return 11;
            }
        });

        assertEquals(11, gauge.read());
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.internal.metrics.impl.MethodProbe.LongMethodProbe;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import com.hazelcast.util.counters.Counter;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.reflect.Method;
import java.util.Arrays;
import java.util.Collection;
import java.util.Map;
import java.util.concurrent.Semaphore;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.internal.metrics.impl.MethodProbe.createMethodProbe;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class MethodProbeTest extends HazelcastTestSupport {

    @Test
    public void getLong() throws Exception {
        getLong("byteMethod", 10);
        getLong("shortMethod", 10);
        getLong("intMethod", 10);
        getLong("longMethod", 10);
        getLong("atomicLongMethod", 10);
        getLong("atomicIntegerMethod", 10);
        getLong("counterMethod", 10);
        getLong("collectionMethod", 10);
        getLong("mapMethod", 10);

        getLong("ByteMethod", 10);
        getLong("ShortMethod", 10);
        getLong("IntegerMethod", 10);
        getLong("LongMethod", 10);
        getLong("SemaphoreMethod", 10);

        getLong("nullAtomicLongMethod", 0);
        getLong("nullAtomicIntegerMethod", 0);
        getLong("nullCounterMethod", 0);
        getLong("nullCollectionMethod", 0);
        getLong("nullMapMethod", 0);
        getLong("nullByteMethod", 0);
        getLong("nullShortMethod", 0);
        getLong("nullIntegerMethod", 0);
        getLong("nullLongMethod", 0);
        getLong("nullSemaphoreMethod", 0);
    }

    public void getLong(String fieldName, int expectedValue) throws Exception {
        SomeSource source = new SomeSource();
        Method method = source.getClass().getDeclaredMethod(fieldName);
        Probe probe = method.getAnnotation(Probe.class);
        MethodProbe methodProbe = createMethodProbe(method, probe);

        LongMethodProbe longMethodProbe = assertInstanceOf(LongMethodProbe.class, methodProbe);

        long value = longMethodProbe.get(source);

        assertEquals(expectedValue, value);
    }


    @Test
    public void getDouble() throws Exception {
        getDouble("floatMethod", 10);
        getDouble("doubleMethod", 10);
        getDouble("DoubleMethod", 10);
        getDouble("FloatMethod", 10);
        getDouble("nullDoubleMethod", 0);
        getDouble("nullFloatMethod", 0);
    }

    public void getDouble(String fieldName, double expected) throws Exception {
        SomeSource source = new SomeSource();
        Method method = source.getClass().getDeclaredMethod(fieldName);
        Probe probe = method.getAnnotation(Probe.class);

        MethodProbe methodProbe = createMethodProbe(method, probe);

        MethodProbe.DoubleMethodProbe doubleMethodProbe = assertInstanceOf(MethodProbe.DoubleMethodProbe.class, methodProbe);
        double value = doubleMethodProbe.get(source);

        assertEquals(expected, value, 0.1);
    }


    private class SomeSource {
        @Probe
        private byte byteMethod() {
            return 10;
        }

        @Probe
        private short shortMethod() {
            return 10;
        }

        @Probe
        private int intMethod() {
            return 10;
        }

        @Probe
        private long longMethod() {
            return 10;
        }

        @Probe
        private float floatMethod() {
            return 10;
        }

        @Probe
        private double doubleMethod() {
            return 10;
        }

        @Probe
        private AtomicLong atomicLongMethod() {
            return new AtomicLong(10);

        }

        @Probe
        private AtomicLong nullAtomicLongMethod() {
            return null;
        }

        @Probe
        private AtomicInteger atomicIntegerMethod() {
            return new AtomicInteger(10);
        }

        @Probe
        private AtomicInteger nullAtomicIntegerMethod() {
            return null;
        }

        @Probe
        private Counter counterMethod() {
            return newSwCounter(10);
        }

        @Probe
        private Counter nullCounterMethod() {
            return null;
        }

        @Probe
        private Collection collectionMethod() {
            return Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);
        }

        @Probe
        private Collection nullCollectionMethod() {
            return null;
        }

        @Probe
        private Map mapMethod() {
            return MetricsUtils.createMap(10);
        }

        @Probe
        private Map nullMapMethod() {
            return null;
        }

        @Probe
        private Byte ByteMethod() {
            return (byte) 10;
        }

        @Probe
        private Short ShortMethod() {
            return (short) 10;
        }

        @Probe
        private Integer IntegerMethod() {
            return 10;
        }

        @Probe
        private Long LongMethod() {
            return (long) 10;
        }

        @Probe
        private Float FloatMethod() {
            return (float) 10;
        }

        @Probe
        private Double DoubleMethod() {
            return (double) 10;
        }

        @Probe
        private Semaphore SemaphoreMethod() {
            return new Semaphore(10);
        }

        @Probe
        private Byte nullByteMethod() {
            return null;
        }

        @Probe
        private Short nullShortMethod() {
            return null;
        }

        @Probe
        private Integer nullIntegerMethod() {
            return null;
        }

        @Probe
        private Long nullLongMethod() {
            return null;
        }

        @Probe
        private Float nullFloatMethod() {
            return null;
        }

        @Probe
        private Double nullDoubleMethod() {
            return null;
        }

        @Probe
        private Semaphore nullSemaphoreMethod() {
            return null;
        }
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.LongProbeFunction;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.HashSet;
import java.util.Set;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNotSame;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class MetricsRegistryImplTest extends HazelcastTestSupport {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void modCount() {
        long modCount = metricsRegistry.modCount();
        metricsRegistry.register(this, "foo", new LongProbeFunction() {
            @Override
            public long get(Object obj) throws Exception {
                return 1;
            }
        });
        assertEquals(modCount + 1, metricsRegistry.modCount());

        metricsRegistry.deregister(this);
        assertEquals(modCount + 2, metricsRegistry.modCount());
    }

    

    @Test(expected = NullPointerException.class)
    public void newGauge_whenNullName() {
        metricsRegistry.newLongGauge(null);
    }

    @Test
    public void newGauge_whenNotExistingMetric() {
        LongGaugeImpl gauge = metricsRegistry.newLongGauge("foo");

        assertNotNull(gauge);
        assertEquals("foo", gauge.getName());
        assertEquals(0, gauge.read());
    }

    @Test
    public void newGauge_whenExistingMetric() {
        LongGaugeImpl first = metricsRegistry.newLongGauge("foo");
        LongGaugeImpl second = metricsRegistry.newLongGauge("foo");

        assertNotSame(first, second);
    }

    

    @Test
    public void getNames() {
        Set<String> expected = new HashSet<String>();
        expected.add("first");
        expected.add("second");
        expected.add("third");

        for (String name : expected) {
            metricsRegistry.register(this, name, new LongProbeFunction() {
                @Override
                public long get(Object obj) throws Exception {
                    return 0;
                }
            });
        }

        Set<String> names = metricsRegistry.getNames();
        for (String name : expected) {
            assertTrue(names.contains(name));
        }
    }

    @Test
    public void shutdown() {
        metricsRegistry.shutdown();
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.internal.metrics.impl.FieldProbe.DoubleFieldProbe;
import com.hazelcast.internal.metrics.impl.FieldProbe.LongFieldProbe;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import com.hazelcast.util.counters.Counter;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.reflect.Field;
import java.util.Arrays;
import java.util.Collection;
import java.util.Map;
import java.util.concurrent.Semaphore;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.internal.metrics.impl.FieldProbe.createFieldProbe;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class FieldProbeTest extends HazelcastTestSupport {

    @Test(expected = IllegalArgumentException.class)
    public void whenUnknownType() throws NoSuchFieldException {
        UnknownFieldType unknownFieldType = new UnknownFieldType();
        Field field = unknownFieldType.getClass().getDeclaredField("field");
        Probe probe = field.getAnnotation(Probe.class);

        createFieldProbe(field, probe);
    }

    private class UnknownFieldType {
        @Probe
        private String field;
    }

    @Test
    public void getLong() throws Exception {
        getLong("byteField", 10);
        getLong("shortField", 10);
        getLong("intField", 10);
        getLong("longField", 10);
        getLong("atomicLongField", 10);
        getLong("atomicIntegerField", 10);
        getLong("counterField", 10);
        getLong("collectionField", 10);
        getLong("mapField", 10);
        getLong("semaphoreField", 10);

        getLong("ByteField", 10);
        getLong("ShortField", 10);
        getLong("IntegerField", 10);
        getLong("LongField", 10);

        getLong("nullAtomicLongField", 0);
        getLong("nullAtomicIntegerField", 0);
        getLong("nullCounterField", 0);
        getLong("nullCollectionField", 0);
        getLong("nullMapField", 0);
        getLong("nullByteField", 0);
        getLong("nullShortField", 0);
        getLong("nullIntegerField", 0);
        getLong("nullLongField", 0);
        getLong("nullSemaphoreField", 0);
    }

    public void getLong(String fieldName, int expectedValue) throws Exception {
        SomeSource source = new SomeSource();
        Field field = source.getClass().getDeclaredField(fieldName);
        Probe probe = field.getAnnotation(Probe.class);
        FieldProbe fieldProbe = createFieldProbe(field, probe);

        LongFieldProbe longFieldProbe = assertInstanceOf(LongFieldProbe.class, fieldProbe);

        long value = longFieldProbe.get(source);

        assertEquals(expectedValue, value);
    }

    @Test
    public void getDouble() throws Exception {
        getDouble("floatField", 10);
        getDouble("doubleField", 10);
        getDouble("DoubleField", 10);
        getDouble("FloatField", 10);
        getDouble("nullDoubleField", 0);
        getDouble("nullFloatField", 0);
    }

    public void getDouble(String fieldName, double expected) throws Exception {
        SomeSource source = new SomeSource();
        Field field = source.getClass().getDeclaredField(fieldName);
        Probe probe = field.getAnnotation(Probe.class);

        FieldProbe fieldProbe = createFieldProbe(field, probe);
        assertInstanceOf(DoubleFieldProbe.class, fieldProbe);

        DoubleFieldProbe doubleFieldProbe = (DoubleFieldProbe) fieldProbe;

        double value = doubleFieldProbe.get(source);

        assertEquals(expected, value, 0.1);
    }

    private class SomeSource {
        @Probe
        private byte byteField = 10;
        @Probe
        private short shortField = 10;
        @Probe
        private int intField = 10;
        @Probe
        private long longField = 10;

        @Probe
        private float floatField = 10;
        @Probe
        private double doubleField = 10;

        @Probe
        private AtomicLong atomicLongField = new AtomicLong(10);
        @Probe
        private AtomicLong nullAtomicLongField;
        @Probe
        private AtomicInteger atomicIntegerField = new AtomicInteger(10);
        @Probe
        private AtomicInteger nullAtomicIntegerField;
        @Probe
        private Counter counterField = newSwCounter(10);
        @Probe
        private Counter nullCounterField;
        @Probe
        private Collection collectionField = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);
        @Probe
        private Collection nullCollectionField;
        @Probe
        private Map mapField = MetricsUtils.createMap(10);
        @Probe
        private Map nullMapField;
        @Probe
        private Semaphore semaphoreField = new Semaphore(10);
        @Probe
        private Semaphore nullSemaphoreField;

        @Probe
        private Byte ByteField = (byte) 10;
        @Probe
        private Short ShortField = (short) 10;
        @Probe
        private Integer IntegerField = 10;
        @Probe
        private Long LongField = (long) 10;
        @Probe
        private Float FloatField = (float) 10;
        @Probe
        private Double DoubleField = (double) 10;

        @Probe
        private Byte nullByteField;
        @Probe
        private Short nullShortField;
        @Probe
        private Integer nullIntegerField;
        @Probe
        private Long nullLongField;
        @Probe
        private Float nullFloatField;
        @Probe
        private Double nullDoubleField;

    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleGauge;
import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.util.counters.Counter;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;

import static com.hazelcast.util.counters.SwCounter.newSwCounter;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class RegisterAnnotatedFieldsTest extends HazelcastTestSupport {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void register_customName() {
        ObjectLongGaugeFieldWithName object = new ObjectLongGaugeFieldWithName();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.myfield");
        object.field = 10;
        assertEquals(object.field, gauge.read());
    }

    public class ObjectLongGaugeFieldWithName {
        @Probe(name = "myfield")
        private long field;
    }

    @Test
    public void register_primitiveInteger() {
        PrimitiveIntegerField object = new PrimitiveIntegerField();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.field");
        object.field = 10;
        assertEquals(object.field, gauge.read());
    }

    public class PrimitiveIntegerField {
        @Probe
        private int field;
    }

    @Test
    public void register_primitiveLong() {
        PrimitiveLongField object = new PrimitiveLongField();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.field");
        object.field = 10;
        assertEquals(object.field, gauge.read());
    }

    public class PrimitiveLongField {
        @Probe
        private long field;
    }

    @Test
    public void register_primitiveDouble() {
        PrimitiveDoubleField object = new PrimitiveDoubleField();
        metricsRegistry.scanAndRegister(object, "foo");

        DoubleGauge gauge = metricsRegistry.newDoubleGauge("foo.field");
        object.field = 10;
        assertEquals(object.field, gauge.read(),0.1);
    }

    public class PrimitiveDoubleField {
        @Probe
        private double field;
    }

    @Test
    public void register_concurrentHashMap() {
        ConcurrentMapField object = new ConcurrentMapField();
        object.field.put("foo", "foo");
        object.field.put("bar", "bar");
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.field");
        assertEquals(object.field.size(), gauge.read());

        object.field = null;
        assertEquals(0, gauge.read());
    }

    public class ConcurrentMapField {
        @Probe
        private ConcurrentHashMap field = new ConcurrentHashMap();
    }

    @Test
    public void register_counterFields() {
        CounterField object = new CounterField();
        object.field.inc(10);
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.field");
        assertEquals(10, gauge.read());

        object.field = null;
        assertEquals(0, gauge.read());
    }

    public class CounterField {
        @Probe
        private Counter field = newSwCounter();
    }

    @Test
    public void register_staticField() {
        StaticField object = new StaticField();
        StaticField.field.set(10);
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.field");
        assertEquals(10, gauge.read());

        StaticField.field = null;
        assertEquals(0, gauge.read());
    }

    public static class StaticField {
        @Probe
        static AtomicInteger field = new AtomicInteger();
    }

    @Test
    public void register_superclassRegistration() {
        Subclass object = new Subclass();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.field");
        assertEquals(0, gauge.read());

        object.field = 10;
        assertEquals(10, gauge.read());
    }

    public static class SuperClass{
        @Probe
        int field;
    }

    public static class Subclass extends SuperClass{

    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleGauge;
import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.util.counters.Counter;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import freemarker.ext.util.IdentityHashMap;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.util.counters.SwCounter.newSwCounter;
import static org.junit.Assert.assertEquals;



@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class RegisterAnnotatedMethodsTest extends HazelcastTestSupport {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test(expected = IllegalArgumentException.class)
    public void register_methodWithArguments() {
        MethodWithArgument object = new MethodWithArgument();
        metricsRegistry.scanAndRegister(object, "foo");
    }

    public class MethodWithArgument {
        @Probe
        private long method(int x) {
            return 10;
        }
    }

    @Test
    public void register_withCustomName() {
        GaugeMethodWithName object = new GaugeMethodWithName();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.mymethod");
        assertEquals(10, gauge.read());
    }

    public class GaugeMethodWithName {
        @Probe(name = "mymethod")
        private long method() {
            return 10;
        }
    }

    @Test(expected = IllegalArgumentException.class)
    public void register_methodReturnsVoid() {
        VoidMethod object = new VoidMethod();
        metricsRegistry.scanAndRegister(object, "foo");
    }

    public class VoidMethod {
        @Probe
        private void method() {
        }
    }

    @Test
    public void register_primitiveByte() {
        PrimitiveByteMethod object = new PrimitiveByteMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(object.method(), gauge.read());
    }

    public class PrimitiveByteMethod {
        @Probe
        private byte method() {
            return 10;
        }
    }

    @Test
    public void register_primitiveShort() {
        PrimitiveShortMethod object = new PrimitiveShortMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(object.method(), gauge.read());
    }

    public class PrimitiveShortMethod {
        @Probe
        private short method() {
            return 10;
        }
    }


    @Test
    public void register_primitiveInt() {
        PrimitiveIntMethod object = new PrimitiveIntMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(10, gauge.read());
    }

    public class PrimitiveIntMethod {
        @Probe
        private int method() {
            return 10;
        }
    }

    @Test
    public void register_primitiveLong() {
        PrimitiveLongMethod object = new PrimitiveLongMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(10, gauge.read());
    }


    public class PrimitiveLongMethod {
        @Probe
        private long method() {
            return 10;
        }
    }

    @Test
    public void register_primitiveFloat() {
        PrimitiveFloatMethod object = new PrimitiveFloatMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        DoubleGauge gauge = metricsRegistry.newDoubleGauge("foo.method");
        assertEquals(object.method(), gauge.read(), 0.1);
    }

    public class PrimitiveFloatMethod {
        @Probe
        private float method() {
            return 10f;
        }
    }

    @Test
    public void register_primitiveDouble() {
        PrimitiveDoubleMethod object = new PrimitiveDoubleMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        DoubleGauge gauge = metricsRegistry.newDoubleGauge("foo.method");
        assertEquals(object.method(), gauge.read(), 0.1);
    }

    public class PrimitiveDoubleMethod {
        @Probe
        private double method() {
            return 10d;
        }
    }

    @Test
    public void register_atomicLong() {
        AtomicLongMethod object = new AtomicLongMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(object.method().get(), gauge.read());
    }

    public class AtomicLongMethod {
        @Probe
        private AtomicLong method() {
            return new AtomicLong(10);
        }
    }

    @Test
    public void register_atomicInteger() {
        AtomicIntegerMethod object = new AtomicIntegerMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(object.method().get(), gauge.read());
    }

    public class AtomicIntegerMethod {
        @Probe
        private AtomicInteger method() {
            return new AtomicInteger(10);
        }
    }

    @Test
    public void register_counter() {
        CounterMethod object = new CounterMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(object.method().get(), gauge.read());
    }

    public class CounterMethod {
        @Probe
        private Counter method() {
            Counter counter = newSwCounter();
            counter.inc(10);
            return counter;
        }
    }

    @Test
    public void register_collection() {
        CollectionMethod object = new CollectionMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(object.method().size(), gauge.read());
    }

    public class CollectionMethod {
        @Probe
        private Collection method() {
            ArrayList list = new ArrayList();
            for (int k = 0; k < 10; k++) {
                list.add(k);
            }
            return list;
        }
    }

    @Test
    public void register_map() {
        MapMethod object = new MapMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(object.method().size(), gauge.read());
    }

    public class MapMethod {
        @Probe
        private Map method() {
            HashMap map = new HashMap();
            for (int k = 0; k < 10; k++) {
                map.put(k, k);
            }
            return map;
        }
    }

    @Test
    public void register_subclass() {
        SubclassMethod object = new SubclassMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(object.method().size(), gauge.read());
    }

    public class SubclassMethod {
        @Probe
        private IdentityHashMap method() {
            IdentityHashMap map = new IdentityHashMap();
            for (int k = 0; k < 10; k++) {
                map.put(k, k);
            }
            return map;
        }
    }


    @Test
    public void register_staticMethod() {
        StaticMethod object = new StaticMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(StaticMethod.method(), gauge.read());
    }

    public static class StaticMethod {
        @Probe
        private static long method() {
            return 10;
        }
    }

    @Test
    public void register_interfaceWithGauges() {
        SomeInterfaceImplementation object = new SomeInterfaceImplementation();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge gauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(10, gauge.read());
    }

    public  interface SomeInterface{
        @Probe
        int method();
    }

    public static class SomeInterfaceImplementation implements SomeInterface{
        @Override
        public int method() {
            return 10;
        }
    }

    @Test
    public void register_superclassWithGaugeMethods() {
        SubclassWithGauges object = new SubclassWithGauges();
        metricsRegistry.scanAndRegister(object, "foo");

        LongGauge methodGauge = metricsRegistry.newLongGauge("foo.method");
        assertEquals(object.method(), methodGauge.read());

        LongGauge fieldGauge = metricsRegistry.newLongGauge("foo.field");
        assertEquals(object.field, fieldGauge.read());
    }

    public static abstract class ClassWithGauges {
        @Probe
        int method(){
            return 10;
        }

        @Probe
        int field=10;
    }

    public static class SubclassWithGauges extends ClassWithGauges {

    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static com.hazelcast.internal.metrics.impl.ProbeUtils.*;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class ProbeUtilsTest extends HazelcastTestSupport {

    @Test
    public void testPrivateConstructor(){
        assertUtilityConstructor(ProbeUtils.class);
    }

    @Test
    public void isDouble(){
        assertTrue(ProbeUtils.isDouble(TYPE_DOUBLE_NUMBER));
        assertTrue(ProbeUtils.isDouble(TYPE_DOUBLE_PRIMITIVE));

        assertFalse(ProbeUtils.isDouble(TYPE_PRIMITIVE_LONG));
        assertFalse(ProbeUtils.isDouble(TYPE_LONG_NUMBER));
        assertFalse(ProbeUtils.isDouble(TYPE_COLLECTION));
        assertFalse(ProbeUtils.isDouble(TYPE_MAP));
        assertFalse(ProbeUtils.isDouble(TYPE_COUNTER));
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.LongProbeFunction;
import com.hazelcast.internal.metrics.renderers.ProbeRenderer;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.ExpectedRuntimeException;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertSame;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.verifyNoMoreInteractions;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class RenderTest {
    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));

        for (String name : metricsRegistry.getNames()) {
            ProbeInstance probeInstance = metricsRegistry.getProbeInstance(name);
            if (probeInstance != null && probeInstance.source != null) {
                metricsRegistry.deregister(probeInstance.source);
            }
        }
    }

    private void registerLongMetric(String name, final int value) {
        metricsRegistry.register(this, name, new LongProbeFunction<RenderTest>() {
            @Override
            public long get(RenderTest source) throws Exception {
                return value;
            }
        });
    }


    private void registerDoubleMetric(String name, final int value) {
        metricsRegistry.register(this, name, new DoubleProbeFunction<RenderTest>() {
            @Override
            public double get(RenderTest source) throws Exception {
                return value;
            }
        });
    }

    @Test(expected = NullPointerException.class)
    public void whenCalledWithNullRenderer() {
        metricsRegistry.render(null);
    }

    @Test
    public void whenLongProbeFunctions() {
        ProbeRenderer renderer = mock(ProbeRenderer.class);

        registerLongMetric("foo", 10);
        registerLongMetric("bar", 20);

        metricsRegistry.render(renderer);

        verify(renderer).start();
        verify(renderer).renderLong("foo", 10);
        verify(renderer).renderLong("bar", 20);
        verify(renderer).finish();
        verifyNoMoreInteractions(renderer);
    }

    @Test
    public void whenDoubleProbeFunctions() {
        ProbeRenderer renderer = mock(ProbeRenderer.class);

        registerDoubleMetric("foo", 10);
        registerDoubleMetric("bar", 20);

        metricsRegistry.render(renderer);

        verify(renderer).start();
        verify(renderer).renderDouble("foo", 10);
        verify(renderer).renderDouble("bar", 20);
        verify(renderer).finish();
        verifyNoMoreInteractions(renderer);
    }

    @Test
    public void whenException() {
        ProbeRenderer renderer = mock(ProbeRenderer.class);

        final ExpectedRuntimeException ex = new ExpectedRuntimeException();

        metricsRegistry.register(this, "foo", new LongProbeFunction<RenderTest>() {
            @Override
            public long get(RenderTest source) throws Exception {
                throw ex;
            }
        });

        metricsRegistry.render(renderer);

        verify(renderer).start();
        verify(renderer).renderException("foo", ex);
        verify(renderer).finish();
        verifyNoMoreInteractions(renderer);
    }

    @Test
    public void getSortedProbes_whenProbeAdded() {
        SortedProbesInstances instances1 = metricsRegistry.getSortedProbeInstances();

        registerLongMetric("foo", 10);

        SortedProbesInstances instances2 = metricsRegistry.getSortedProbeInstances();

        assertEquals(instances1.modCount + 1, instances2.modCount);
    }

    @Test
    public void getSortedProbes_whenNoChange() {
        SortedProbesInstances instances1 = metricsRegistry.getSortedProbeInstances();

         SortedProbesInstances instances2 = metricsRegistry.getSortedProbeInstances();

        assertSame(instances1, instances2);
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.LongGauge;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.io.OutputStream;
import java.util.LinkedList;
import java.util.Set;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class RegisterMetricTest extends HazelcastTestSupport {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test(expected = NullPointerException.class)
    public void whenNamePrefixNull() {
        metricsRegistry.scanAndRegister(new SomeField(), null);
    }

    @Test(expected = NullPointerException.class)
    public void whenObjectNull() {
        metricsRegistry.scanAndRegister(null, "bar");
    }

    @Test(expected = IllegalArgumentException.class)
    public void whenUnrecognizedField() {
        metricsRegistry.scanAndRegister(new SomeUnrecognizedField(), "bar");
    }

    @Test
    public void whenNoGauges_thenIgnore() {
        metricsRegistry.scanAndRegister(new LinkedList(), "bar");

        for (String name : metricsRegistry.getNames()) {
            assertFalse(name.startsWith("bar"));
        }
    }

    public class SomeField {
        @Probe
        long field;
    }

    public class SomeUnrecognizedField {
        @Probe
        OutputStream field;
    }

    @Test
    public void deregister_whenNotRegistered() {
        MultiFieldAndMethod multiFieldAndMethod = new MultiFieldAndMethod();
        multiFieldAndMethod.field1 = 1;
        multiFieldAndMethod.field2 = 2;
        metricsRegistry.deregister(multiFieldAndMethod);

        
        Set<String> names = metricsRegistry.getNames();
        assertFalse(names.contains("foo.field1"));
        assertFalse(names.contains("foo.field2"));
        assertFalse(names.contains("foo.method1"));
        assertFalse(names.contains("foo.method2"));
 }

    public class MultiFieldAndMethod {
        @Probe
        long field1;
        @Probe
        long field2;

        @Probe
        int method1() {
            return 1;
        }

        @Probe
        int method2() {
            return 2;
        }
    }

    @Test
    public void deregister_whenRegistered() {
        MultiFieldAndMethod multiFieldAndMethod = new MultiFieldAndMethod();
        multiFieldAndMethod.field1 = 1;
        multiFieldAndMethod.field2 = 2;
        metricsRegistry.scanAndRegister(multiFieldAndMethod, "foo");

        LongGauge field1 = metricsRegistry.newLongGauge("foo.field1");
        LongGauge field2 = metricsRegistry.newLongGauge("foo.field2");
        LongGauge method1 = metricsRegistry.newLongGauge("foo.method1");
        LongGauge method2 = metricsRegistry.newLongGauge("foo.method2");

        metricsRegistry.deregister(multiFieldAndMethod);

        
        Set<String> names = metricsRegistry.getNames();
        assertFalse(names.contains("foo.field1"));
        assertFalse(names.contains("foo.field2"));
        assertFalse(names.contains("foo.method1"));
        assertFalse(names.contains("foo.method2"));

        
        assertEquals(0, field1.read());
        assertEquals(0, field2.read());
        assertEquals(0, method1.read());
        assertEquals(0, method2.read());
    }

    @Test
    public void deregister_whenAlreadyDeregistered() {
        MultiFieldAndMethod multiFieldAndMethod = new MultiFieldAndMethod();
        multiFieldAndMethod.field1 = 1;
        multiFieldAndMethod.field2 = 2;
        metricsRegistry.scanAndRegister(multiFieldAndMethod, "foo");
        metricsRegistry.deregister(multiFieldAndMethod);
        metricsRegistry.deregister(multiFieldAndMethod);

        
        Set<String> names = metricsRegistry.getNames();
        assertFalse(names.contains("foo.field1"));
        assertFalse(names.contains("foo.field2"));
        assertFalse(names.contains("foo.method1"));
        assertFalse(names.contains("foo.method2"));
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleGauge;
import com.hazelcast.internal.metrics.DoubleProbeFunction;
import com.hazelcast.internal.metrics.LongProbeFunction;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class DoubleGaugeImplTest {
    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    class SomeObject {
        @Probe
        long longField = 10;
        @Probe
        double doubleField = 10.8;
    }

    

    @Test
    public void whenNoProbeAvailable() {
        DoubleGauge gauge = metricsRegistry.newDoubleGauge("foo");

        double actual = gauge.read();

        assertEquals(0, actual, 0.1);
    }

    @Test
    public void whenProbeThrowsException() {
        metricsRegistry.register(this, "foo", new DoubleProbeFunction() {
            @Override
            public double get(Object o) {
                throw new RuntimeException();
            }
        });

        DoubleGauge gauge = metricsRegistry.newDoubleGauge("foo");

        double actual = gauge.read();

        assertEquals(0, actual, 0.1);
    }

    @Test
    public void whenDoubleProbe() {
        metricsRegistry.register(this, "foo", new DoubleProbeFunction() {
            @Override
            public double get(Object o) {
                return 10;
            }
        });
        DoubleGauge gauge = metricsRegistry.newDoubleGauge("foo");

        double actual = gauge.read();

        assertEquals(10, actual, 0.1);
    }

    @Test
    public void whenLongProbe() {
        metricsRegistry.register(this, "foo", new LongProbeFunction() {
            @Override
            public long get(Object o) throws Exception {
                return 10;
            }
        });
        DoubleGauge gauge = metricsRegistry.newDoubleGauge("foo");

        double actual = gauge.read();

        assertEquals(10, actual, 0.1);
    }

    @Test
    public void whenLongGaugeField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");

        DoubleGauge gauge = metricsRegistry.newDoubleGauge("foo.longField");
        assertEquals(someObject.longField, gauge.read(), 0.1);
    }

    @Test
    public void whenDoubleGaugeField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");

        DoubleGauge gauge = metricsRegistry.newDoubleGauge("foo.doubleField");
        assertEquals(someObject.doubleField, gauge.read(), 0.1);
    }
}

<code block>
package com.hazelcast.internal.metrics.renderers;

import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class HumanFriendlyProbeRendererTest extends HazelcastTestSupport {

    private HumanFriendlyProbeRenderer renderer;

    @Before
    public void setup() {
        renderer = new HumanFriendlyProbeRenderer();
    }

    @Test
    public void test() {
        renderer.start();
        renderer.renderLong("long", 1);
        renderer.renderDouble("double", 2);
        renderer.renderException("exception", new RuntimeException("somemessage"));
        renderer.renderNoValue("novalue");
        renderer.finish();

        String s = renderer.getResult();

        assertEquals("long=1\n" +
                "double=2.0\n" +
                "exception=somemessage\n" +
                "novalue=NA\n", s);
    }

}

<code block>
package com.hazelcast.internal.metrics.renderers;

import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertTrue;


@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class CommaSeparatedKeyValueProbeRendererTest {
    private CommaSeparatedKeyValueProbeRenderer renderer;

    @Before
    public void setup() {
        renderer = new CommaSeparatedKeyValueProbeRenderer();
    }

    @Test
    public void test() {
        renderer.start();
        renderer.renderLong("long", 1);
        renderer.renderDouble("double", 2);
        renderer.renderException("exception", new RuntimeException("somemessage"));
        renderer.renderNoValue("novalue");
        renderer.finish();

        String s = renderer.getResult();

        assertTrue(s.startsWith("{time="));
        assertTrue(s.endsWith(",long=1,double=2.0,exception=NA,novalue=NA}\n"));
    }
}

<code block>


package com.hazelcast.test;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.config.Config;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.Member;
import com.hazelcast.core.Partition;
import com.hazelcast.core.PartitionService;
import com.hazelcast.instance.HazelcastInstanceFactory;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.TestUtil;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.impl.InternalPartitionServiceState;
import com.hazelcast.replicatedmap.impl.record.VectorClockTimestamp;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import org.junit.After;
import org.junit.Assert;
import org.junit.ComparisonFailure;

import java.lang.reflect.Constructor;
import java.lang.reflect.Modifier;
import java.util.Collection;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.Set;
import java.util.UUID;
import java.util.concurrent.Callable;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.Future;
import java.util.concurrent.FutureTask;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

import static com.hazelcast.test.TestPartitionUtils.getInternalPartitionServiceState;
import static java.lang.String.format;
import static java.util.Arrays.asList;
import static java.util.concurrent.TimeUnit.MILLISECONDS;
import static java.util.concurrent.TimeUnit.NANOSECONDS;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

public abstract class HazelcastTestSupport {

    public static final int ASSERT_TRUE_EVENTUALLY_TIMEOUT;

    static {
        System.setProperty("hazelcast.repmap.hooks.allowed", "true");

        ASSERT_TRUE_EVENTUALLY_TIMEOUT = Integer.getInteger("hazelcast.assertTrueEventually.timeout", 120);
        System.out.println("ASSERT_TRUE_EVENTUALLY_TIMEOUT = " + ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    private TestHazelcastInstanceFactory factory;


    public static void assertUtilityConstructor(Class clazz) {
        Constructor[] constructors = clazz.getDeclaredConstructors();
        assertEquals("there are more than 1 constructors", 1, constructors.length);

        Constructor constructor = constructors[0];
        int modifiers = constructor.getModifiers();
        assertTrue("access modifier is not private", Modifier.isPrivate(modifiers));

        constructor.setAccessible(true);
        try {
            constructor.newInstance();
        } catch (Exception e) {
        }
    }

    public static void assertHappensBefore(VectorClockTimestamp clock1, VectorClockTimestamp clock2) {
        assertTrue(VectorClockTimestamp.happenedBefore(clock1, clock2));
    }

    public static void assertNotHappensBefore(VectorClockTimestamp clock1, VectorClockTimestamp clock2) {
        assertFalse(VectorClockTimestamp.happenedBefore(clock1, clock2));
    }

    public HazelcastInstance createHazelcastInstance() {
        return createHazelcastInstance(new Config());
    }

    public HazelcastInstance createHazelcastInstance(Config config) {
        return createHazelcastInstanceFactory(1).newHazelcastInstance(config);
    }

    public static int getPartitionId(HazelcastInstance hz, String name){
        PartitionService partitionService = hz.getPartitionService();
        Partition partition = partitionService.getPartition(name);
        return partition.getPartitionId();
    }

    protected final TestHazelcastInstanceFactory createHazelcastInstanceFactory(int nodeCount) {
        if (factory != null) {
            throw new IllegalStateException("Node factory is already created!");
        }
        return factory = new TestHazelcastInstanceFactory(nodeCount);
    }

    protected final TestHazelcastInstanceFactory createHazelcastInstanceFactory(String... addresses) {
        if (factory != null) {
            throw new IllegalStateException("Node factory is already created!");
        }
        return factory = new TestHazelcastInstanceFactory(addresses);
    }

    protected final TestHazelcastInstanceFactory createHazelcastInstanceFactory() {
        if (factory != null) {
            throw new IllegalStateException("Node factory is already created!");
        }
        return factory = new TestHazelcastInstanceFactory();
    }

    public static Future spawn(Runnable task) {
        FutureTask<Runnable> futureTask = new FutureTask<Runnable>(task, null);
        new Thread(futureTask).start();
        return futureTask;
    }

    public static <E> Future<E> spawn(Callable<E> task) {
        FutureTask<E> futureTask = new FutureTask<E>(task);
        new Thread(futureTask).start();
        return futureTask;
    }

    public static Address getAddress(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.clusterService.getThisAddress();
    }

    public static Packet toPacket(HazelcastInstance hz, Operation operation) {
        SerializationService serializationService = getSerializationService(hz);
        ConnectionManager connectionManager = getConnectionManager(hz);

        Data data = serializationService.toData(operation);
        Packet packet = new Packet(data, operation.getPartitionId());
        packet.setHeader(Packet.HEADER_OP);
        packet.setConn(connectionManager.getConnection(getAddress(hz)));
        return packet;
    }

    public static ConnectionManager getConnectionManager(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.connectionManager;
    }

    public static ClusterService getClusterService(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.clusterService;
    }

    public static SerializationService getSerializationService(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.getSerializationService();
    }

    public static InternalOperationService getOperationService(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.nodeEngine.getOperationService();
    }

    public static InternalPartitionService getPartitionService(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.partitionService;
    }

    public static NodeEngineImpl getNodeEngineImpl(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.nodeEngine;
    }

    public static MetricsRegistry getMetricsRegistry(HazelcastInstance hz){
        NodeEngineImpl nodeEngine = getNodeEngineImpl(hz);
        return nodeEngine.getMetricsRegistry();
    }

    @After
    public final void shutdownNodeFactory() {
        TestHazelcastInstanceFactory testHazelcastInstanceFactory = factory;
        if (testHazelcastInstanceFactory != null) {
            factory = null;
            testHazelcastInstanceFactory.terminateAll();
        }
    }

    public static void setLoggingNone() {
        System.setProperty("hazelcast.logging.type", "none");
    }

    public static void setLoggingLog4j() {
        System.setProperty("hazelcast.logging.type", "log4j");
    }

    public static void setLogLevel(org.apache.log4j.Level level) {
        if (isLog4jLoaded()) {
            org.apache.log4j.Logger.getRootLogger().setLevel(level);
        }
    }

    private static boolean isLog4jLoaded() {
        setLoggingLog4j();
        try {
            Class.forName("org.apache.log4j.Logger");
            Class.forName("org.apache.log4j.Level");
            return true;
        } catch (Throwable ignored) {
            return false;
        }
    }

    public static void sleepMillis(int millis) {
        try {
            MILLISECONDS.sleep(millis);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }

    public static void sleepSeconds(int seconds) {
        try {
            TimeUnit.SECONDS.sleep(seconds);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }

    
    public static void sleepAndStop(AtomicBoolean stop, long durationSeconds) {
        for (int k = 0; k < durationSeconds; k++) {
            if (stop.get()) {
                return;
            }
            sleepSeconds(1);
        }
        stop.set(true);
    }

    public static void sleepAtLeastMillis(long sleepFor) {
       boolean interrupted = false;
       try {
           long remainingNanos = MILLISECONDS.toNanos(sleepFor);
           final long sleepUntil = System.nanoTime() + remainingNanos;
           while (remainingNanos > 0) {
               try {
                   NANOSECONDS.sleep(remainingNanos);
               } catch (InterruptedException e) {
                   interrupted = true;
               } finally {
                   remainingNanos = sleepUntil - System.nanoTime();
               }
           }
       } finally {
           if (interrupted) {
               Thread.currentThread().interrupt();
           }
       }
    }

    public static void sleepAtLeastSeconds(long seconds) {
        sleepAtLeastMillis(seconds * 1000);
    }

    public static String generateRandomString(int length) {
        StringBuilder sb = new StringBuilder(length);
        Random random = new Random();
        for (int i = 0; i < length; i++) {
            char character = (char) (random.nextInt(26) + 'a');
            sb.append(character);
        }
        return sb.toString();
    }

    public static String randomString() {
        return UUID.randomUUID().toString();
    }

    public static String randomMapName() {
        return randomString();
    }

    public static String randomMapName(String namePrefix) {
        return namePrefix + randomString();
    }

    public static String randomName() {
        return randomString();
    }

    public static String randomNameOwnedBy(HazelcastInstance hz) {
        return randomNameOwnedBy(hz, "");
    }

    public static String randomNameOwnedBy(HazelcastInstance instance, String prefix) {
        Member localMember = instance.getCluster().getLocalMember();
        PartitionService partitionService = instance.getPartitionService();
        while (true) {
            String id = prefix + randomString();
            Partition partition = partitionService.getPartition(id);
            if (comparePartitionOwnership(true, localMember, partition)) {
                return id;
            }
        }
    }

    public static Partition randomPartitionOwnedBy(HazelcastInstance hz) {
        List<Partition> partitions = new LinkedList<Partition>();
        for (Partition partition : hz.getPartitionService().getPartitions()) {
            if (partition.getOwner().localMember()) {
                partitions.add(partition);
            }
        }
        if (partitions.isEmpty()) {
            throw new IllegalStateException("No partitions found for HazelcastInstance:" + hz.getName());
        }
        return partitions.get((int) (Math.random() * partitions.size()));
    }

    public static void printAllStackTraces() {
        Map liveThreads = Thread.getAllStackTraces();
        for (Object object : liveThreads.keySet()) {
            Thread key = (Thread) object;
            System.err.println("Thread " + key.getName());
            StackTraceElement[] trace = (StackTraceElement[]) liveThreads.get(key);
            for (StackTraceElement aTrace : trace) {
                System.err.println("\tat " + aTrace);
            }
        }
    }

    public static void interruptCurrentThread(final int delayMillis) {
        final Thread currentThread = Thread.currentThread();
        new Thread(new Runnable() {
            public void run() {
                sleepMillis(delayMillis);
                currentThread.interrupt();
            }
        }).start();
    }

    public static void consume(Object o) {
    }

    public static Node getNode(HazelcastInstance hz) {
        return TestUtil.getNode(hz);
    }

    public static void warmUpPartitions(HazelcastInstance... instances) {
        try {
            TestUtil.warmUpPartitions(instances);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

    public static void warmUpPartitions(Collection<HazelcastInstance> instances) {
        try {
            TestUtil.warmUpPartitions(instances);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

    
    public static int getPartitionId(HazelcastInstance hz) {
        warmUpPartitions(hz);

        InternalPartitionService partitionService = getPartitionService(hz);
        for (InternalPartition p : partitionService.getPartitions()) {
            if (p.isLocal()) {
                return p.getPartitionId();
            }
        }
        throw new RuntimeException("No local partitions are found for hz: " + hz.getName());
    }

    public static String generateKeyOwnedBy(HazelcastInstance instance) {
        return generateKeyOwnedBy(instance, true);
    }

    public static String generateKeyNotOwnedBy(HazelcastInstance instance) {
        return generateKeyOwnedBy(instance, false);
    }

    
    protected static String generateKeyOwnedBy(HazelcastInstance instance, boolean generateOwnedKey) {
        Cluster cluster = instance.getCluster();
        checkMemberCount(generateOwnedKey, cluster);
        checkPartitionCountGreaterOrEqualMemberCount(instance);

        Member localMember = cluster.getLocalMember();
        PartitionService partitionService = instance.getPartitionService();
        while (true) {
            String id = randomString();
            Partition partition = partitionService.getPartition(id);
            if (comparePartitionOwnership(generateOwnedKey, localMember, partition)) {
                return id;
            }
        }
    }

    private static void checkPartitionCountGreaterOrEqualMemberCount(HazelcastInstance instance) {
        Cluster cluster = instance.getCluster();
        int memberCount = cluster.getMembers().size();

        InternalPartitionService internalPartitionService = getPartitionService(instance);
        int partitionCount = internalPartitionService.getPartitionCount();

        if (partitionCount < memberCount) {
            throw new UnsupportedOperationException("Partition count should be equal or greater than member count!");
        }
    }

    private static void checkMemberCount(boolean generateOwnedKey, Cluster cluster) {
        if (generateOwnedKey) {
            return;
        }
        final Set<Member> members = cluster.getMembers();
        if (members.size() < 2) {
            throw new UnsupportedOperationException("Cluster has only one member, you can not generate a `not owned key`");
        }
    }

    private static boolean comparePartitionOwnership(boolean ownedBy, Member member, Partition partition) {
        final Member owner = partition.getOwner();
        if (ownedBy) {
            return member.equals(owner);
        } else {
            return !member.equals(owner);
        }
    }

    public static boolean isInstanceInSafeState(final HazelcastInstance instance) {
        final Node node = TestUtil.getNode(instance);
        if (node == null) {
            return true;
        }
        final InternalPartitionService ps = node.getPartitionService();
        return ps.isMemberStateSafe();
    }

    public static void waitInstanceForSafeState(final HazelcastInstance instance) {
        assertTrueEventually(new AssertTask() {
            public void run() {
                isInstanceInSafeState(instance);
            }
        });
    }

    public static boolean isClusterInSafeState(final HazelcastInstance instance) {
        final PartitionService ps = instance.getPartitionService();
        return ps.isClusterSafe();
    }

    public static void waitClusterForSafeState(final HazelcastInstance instance) {
        assertTrueEventually(new AssertTask() {
            public void run() {
                assertTrue(isClusterInSafeState(instance));
            }
        });
    }

    public static boolean isAllInSafeState() {
        final Set<HazelcastInstance> nodeSet = HazelcastInstanceFactory.getAllHazelcastInstances();
        return isAllInSafeState(nodeSet);
    }

    public static boolean isAllInSafeState(Collection<HazelcastInstance> nodes) {
        for (HazelcastInstance node : nodes) {
            if (!isInstanceInSafeState(node)) {
                return false;
            }
        }
        return true;
    }

    public static void waitAllForSafeState() {
       waitAllForSafeState(HazelcastInstanceFactory.getAllHazelcastInstances());
    }

    public static void waitAllForSafeState(final Collection<HazelcastInstance> instances) {
        waitAllForSafeState(instances, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void waitAllForSafeState(final Collection<HazelcastInstance> instances, int timeoutInSeconds) {
        assertTrueEventually(new AssertTask() {
            public void run() {
                final Map<Address, InternalPartitionServiceState> states = new HashMap<Address, InternalPartitionServiceState>();
                for (HazelcastInstance instance : instances) {
                    final InternalPartitionServiceState state = getInternalPartitionServiceState(instance);
                    if (state != InternalPartitionServiceState.SAFE) {
                        states.put(getNode(instance).getThisAddress(), state);
                    }
                }

                assertTrue("Instances not in safe state! " + states, states.isEmpty());
            }
        }, timeoutInSeconds);
    }

    public static void waitAllForSafeState(final HazelcastInstance... nodes) {
        waitAllForSafeState(asList(nodes));
    }

    public static void assertStartsWith(String expected, String actual) {
        if (actual != null && actual.startsWith(expected)) {
            return;
        }
        if (expected != null && actual != null) {
            throw new ComparisonFailure("", expected, actual);
        }
        fail(formatAssertMessage("", expected, null));
    }

    private static String formatAssertMessage(String message, Object expected, Object actual) {
        StringBuilder assertMessage = new StringBuilder();
        if (message != null && !message.isEmpty()) {
            assertMessage.append(message).append(" ");
        }
        String expectedString = String.valueOf(expected);
        String actualString = String.valueOf(actual);
        if (expectedString.equals(actualString)) {
            assertMessage.append("expected: ");
            formatClassAndValue(assertMessage, expected, expectedString);
            assertMessage.append(" but was: ");
            formatClassAndValue(assertMessage, actual, actualString);
        } else {
            assertMessage.append("expected: <").append(expectedString).append("> but was: <").append(actualString).append(">");
        }
        return assertMessage.toString();
    }

    private static void formatClassAndValue(StringBuilder message, Object value, String valueString) {
        message.append((value == null) ? "null" : value.getClass().getName()).append("<").append(valueString).append(">");
    }

    public static <E> E assertInstanceOf(Class<E> clazz, Object o) {
        Assert.assertNotNull(o);
        assertTrue(o + " is not an instanceof " + clazz.getName(), clazz.isAssignableFrom(o.getClass()));
        return (E)o;
    }

    public static void assertJoinable(Thread... threads) {
        assertJoinable(ASSERT_TRUE_EVENTUALLY_TIMEOUT, threads);
    }

    public static void assertIterableEquals(Iterable iterable, Object... values) {
        int counter = 0;
        for (Object object : iterable) {
            if (values.length < counter + 1) {
                throw new AssertionError("Iterator and values sizes are not equal");
            }
            assertEquals(values[counter], object);
            counter++;
        }

        assertEquals("Iterator and values sizes are not equal", values.length, counter);
    }

    public static void assertCompletesEventually(final Future future) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertTrue("Future has not completed", future.isDone());
            }
        });
    }

    public static void assertSizeEventually(int expectedSize, Collection c) {
        assertSizeEventually(expectedSize, c, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertSizeEventually(final int expectedSize, final Collection c, long timeoutSeconds) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() {
                assertEquals("the size of the collection is not correct: found-content:" + c, expectedSize, c.size());
            }
        }, timeoutSeconds);
    }

    public static void assertSizeEventually(int expectedSize, Map<?, ?> m) {
        assertSizeEventually(expectedSize, m, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertSizeEventually(final int expectedSize, final Map<?, ?> m, long timeoutSeconds) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() {
                assertEquals("the size of the map is not correct", expectedSize, m.size());
            }
        }, timeoutSeconds);
    }

    public static <E> void assertEqualsEventually(final FutureTask<E> task, final E value) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertTrue("FutureTask is not complete", task.isDone());
                assertEquals(value, task.get());
            }
        });
    }

    public static <E> void assertEqualsEventually(final Callable<E> task, final E value) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(value, task.call());
            }
        });
    }

    public static void assertClusterSize(int expectedSize, HazelcastInstance instance) {
        assertEquals("Cluster size is not correct", expectedSize, instance.getCluster().getMembers().size());
    }

    public static void assertClusterSizeEventually(int expectedSize, HazelcastInstance instance) {
        assertClusterSizeEventually(expectedSize, instance, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertClusterSizeEventually(final int expectedSize, final HazelcastInstance instance, long timeoutSeconds) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run()
                    throws Exception {
                assertEquals("the size of the cluster is not correct", expectedSize, instance.getCluster().getMembers().size());
            }
        }, timeoutSeconds);
    }

    public static void assertJoinable(long timeoutSeconds, Thread... threads) {
        try {
            long remainingTimeout = TimeUnit.SECONDS.toNanos(timeoutSeconds);
            for (Thread thread : threads) {
                long start = System.nanoTime();
                thread.join(remainingTimeout);

                if (thread.isAlive()) {
                    fail("Timeout waiting for thread " + thread.getName() + " to terminate");
                }

                long duration = System.nanoTime() - start;
                remainingTimeout -= duration;
                if (remainingTimeout <= 0) {
                    fail("Timeout waiting for thread " + thread.getName() + " to terminate");
                }
            }
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

    public static void assertOpenEventually(CountDownLatch latch) {
        assertOpenEventually(latch, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertOpenEventually(String message, CountDownLatch latch) {
        assertOpenEventually(message, latch, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertOpenEventually(CountDownLatch latch, long timeoutSeconds) {
        assertOpenEventually(null, latch, timeoutSeconds);
    }

    public static void assertOpenEventually(String message, CountDownLatch latch, long timeoutSeconds) {
        try {
            boolean completed = latch.await(timeoutSeconds, TimeUnit.SECONDS);
            if (message == null) {
                assertTrue(format("CountDownLatch failed to complete within %d seconds , count left: %d", timeoutSeconds,
                        latch.getCount()), completed);
            } else {
                assertTrue(format("%s, failed to complete within %d seconds , count left: %d", message, timeoutSeconds,
                        latch.getCount()), completed);
            }
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

    public static void assertTrueFiveSeconds(AssertTask task) {
        assertTrueAllTheTime(task, 5);
    }

    public static void assertTrueAllTheTime(AssertTask task, long durationSeconds) {
        for (int k = 0; k < durationSeconds; k++) {
            try {
                task.run();
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
            sleepSeconds(1);
        }
    }

    public static void assertTrueEventually(AssertTask task, long timeoutSeconds) {
        AssertionError error = null;
        
        long iterations = timeoutSeconds * 5;
        int sleepMillis = 200;
        for (int k = 0; k < iterations; k++) {
            try {
                try {
                    task.run();
                } catch (Exception e) {
                    throw new RuntimeException(e);
                }
                return;
            } catch (AssertionError e) {
                error = e;
            }
            sleepMillis(sleepMillis);
        }
        throw error;
    }

    public static void assertTrueEventually(AssertTask task) {
        assertTrueEventually(task, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertTrueDelayed5sec(AssertTask task) {
        assertTrueDelayed(5, task);
    }

    public static void assertTrueDelayed(int delaySeconds, AssertTask task) {
        sleepSeconds(delaySeconds);
        try {
            task.run();
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

    
    public static void assertEqualsStringFormat(String message, Object expected, Object actual) {
        assertEquals(String.format(message, expected, actual), expected, actual);
    }

    public static void closeConnectionBetween(HazelcastInstance h1, HazelcastInstance h2) {
        if (h1 == null || h2 == null) return;
        final Node n1 = TestUtil.getNode(h1);
        final Node n2 = TestUtil.getNode(h2);
        n1.clusterService.removeAddress(n2.address);
        n2.clusterService.removeAddress(n1.address);
    }
    public final class DummyUncheckedHazelcastTestException extends RuntimeException {
    }

    public static void assertExactlyOneSuccessfulRun(AssertTask task) {
        assertExactlyOneSuccessfulRun(task, ASSERT_TRUE_EVENTUALLY_TIMEOUT, TimeUnit.SECONDS);
    }

    public static void assertExactlyOneSuccessfulRun(AssertTask task, int giveUpTime, TimeUnit timeUnit) {
        long timeout = System.currentTimeMillis() + timeUnit.toMillis(giveUpTime);
        RuntimeException lastException = new RuntimeException("Did not try even once");
        while (System.currentTimeMillis() < timeout) {
            try {
                task.run();
                return;
            } catch (Exception e) {
                lastException = e instanceof RuntimeException ? (RuntimeException) e : new RuntimeException(e);
            }
            try {
                Thread.sleep(250);
            } catch (InterruptedException e) {
                lastException = new RuntimeException(e);
            }
        }
        throw lastException;
    }
}

<code block>


package com.hazelcast.test;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.AbstractJoiner;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.AddressPicker;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.NodeContext;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.IOService;
import com.hazelcast.nio.NodeIOService;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.executor.StripedRunnable;

import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.nio.channels.ServerSocketChannel;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.CopyOnWriteArraySet;

public final class TestNodeRegistry {

    private final ConcurrentMap<Address, NodeEngineImpl> nodes = new ConcurrentHashMap<Address, NodeEngineImpl>(10);
    private final Object joinerLock = new Object();
    private final CopyOnWriteArrayList<Address> joinAddresses;

    TestNodeRegistry(CopyOnWriteArrayList<Address> addresses) {
        this.joinAddresses = addresses;
    }

    public NodeContext createNodeContext(Address address) {
        return new MockNodeContext(joinAddresses, nodes, address, joinerLock);
    }

    public HazelcastInstance getInstance(Address address) {
        NodeEngineImpl nodeEngine = nodes.get(address);
        return nodeEngine != null && nodeEngine.isActive() ? nodeEngine.getHazelcastInstance() : null;
    }

    Collection<HazelcastInstance> getAllHazelcastInstances() {
        Collection<HazelcastInstance> all = new LinkedList<HazelcastInstance>();
        for (NodeEngineImpl nodeEngine : nodes.values()) {
            if (nodeEngine.isActive()) {
                all.add(nodeEngine.getHazelcastInstance());
            }
        }
        return all;
    }

    void shutdown() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            value.getHazelcastInstance().shutdown();
        }
    }

    void terminate() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            HazelcastInstance hz = value.getHazelcastInstance();
            hz.getLifecycleService().terminate();
        }
    }

    private static class MockNodeContext implements NodeContext {

        final CopyOnWriteArrayList<Address> joinAddresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Address thisAddress;
        final Object joinerLock;

        public MockNodeContext(CopyOnWriteArrayList<Address> addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Address thisAddress, Object joinerLock) {
            this.joinAddresses = addresses;
            this.nodes = nodes;
            this.thisAddress = thisAddress;
            this.joinerLock = joinerLock;
        }

        public AddressPicker createAddressPicker(Node node) {
            return new StaticAddressPicker(thisAddress);
        }

        public Joiner createJoiner(Node node) {
            return new MockJoiner(node, joinAddresses, nodes, joinerLock);
        }

        public ConnectionManager createConnectionManager(Node node, ServerSocketChannel serverSocketChannel) {
            NodeIOService ioService = new NodeIOService(node, node.nodeEngine);
            return new MockConnectionManager(ioService, nodes, node, joinerLock);
        }
    }

    private static class StaticAddressPicker implements AddressPicker {
        final Address thisAddress;

        private StaticAddressPicker(Address thisAddress) {
            this.thisAddress = thisAddress;
        }

        public void pickAddress() throws Exception {
        }

        public Address getBindAddress() {
            return thisAddress;
        }

        public Address getPublicAddress() {
            return thisAddress;
        }

        public ServerSocketChannel getServerSocketChannel() {
            return null;
        }
    }

    private static class MockJoiner extends AbstractJoiner {

        final CopyOnWriteArrayList<Address> joinAddresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Object joinerLock;

        MockJoiner(Node node, CopyOnWriteArrayList<Address> addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Object joinerLock) {
            super(node);
            this.joinAddresses = addresses;
            this.nodes = nodes;
            this.joinerLock = joinerLock;
        }

        public void doJoin() {
            NodeEngineImpl nodeEngine = null;
            synchronized (joinerLock) {
                for (Address address : joinAddresses) {
                    NodeEngineImpl ne = nodes.get(address);
                    if (ne != null && ne.getNode().isActive() && ne.getNode().joined()) {
                        nodeEngine = ne;
                        break;
                    }
                }
                Address master = null;
                if (nodeEngine != null) {
                    if (nodeEngine.getNode().isMaster()) {
                        master = nodeEngine.getThisAddress();
                    } else {
                        master = nodeEngine.getMasterAddress();
                    }
                }
                if (master == null) {
                    master = node.getThisAddress();
                }
                node.setMasterAddress(master);
                if (node.getMasterAddress().equals(node.getThisAddress())) {
                    node.setJoined();
                    node.setAsMaster();
                } else {
                    for (int i = 0; !node.joined() && i < 2000; i++) {
                        try {
                            node.clusterService.sendJoinRequest(node.getMasterAddress(), true);
                            Thread.sleep(50);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    if (!node.joined()) {
                        throw new AssertionError("Node[" + node.getThisAddress()
                                + "] should have been joined to " + node.getMasterAddress());
                    }
                }
            }
        }

        public void searchForOtherClusters() {
        }

        @Override
        public String getType() {
            return "mock";
        }

        public String toString() {
            return "MockJoiner";
        }

        @Override
        public void blacklist(Address address, boolean permanent) {
        }

        @Override
        public boolean unblacklist(Address address) {
            return false;
        }

        @Override
        public boolean isBlacklisted(Address address) {
            return false;
        }
    }

    private static class MockConnectionManager implements ConnectionManager {
        private final Set<ConnectionListener> connectionListeners = new CopyOnWriteArraySet<ConnectionListener>();
        private final IOService ioService;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Map<Address, MockConnection> mapConnections = new ConcurrentHashMap<Address, MockConnection>(10);
        final Node node;
        final Object joinerLock;

        MockConnectionManager(IOService ioService, ConcurrentMap<Address, NodeEngineImpl> nodes,
                              Node node, Object joinerLock) {
            this.ioService = ioService;
            this.nodes = nodes;
            this.node = node;
            this.joinerLock = joinerLock;
            synchronized (this.joinerLock) {
                this.nodes.put(node.getThisAddress(), node.nodeEngine);
            }
        }

        public Connection getConnection(Address address) {
            MockConnection conn = mapConnections.get(address);
            if (conn == null) {
                NodeEngineImpl nodeEngine = nodes.get(address);
                MockConnection thisConnection = new MockConnection(address, node.getThisAddress(), node.nodeEngine);
                conn = new MockConnection(node.getThisAddress(), address, nodeEngine);
                conn.localConnection = thisConnection;
                thisConnection.localConnection = conn;
                mapConnections.put(address, conn);
            }
            return conn;
        }

        public Connection getOrConnect(Address address) {
            return getConnection(address);
        }

        public Connection getOrConnect(Address address, boolean silent) {
            return getConnection(address);
        }

        public void shutdown() {
            for (Address address : nodes.keySet()) {
                if (address.equals(node.getThisAddress())) continue;

                final NodeEngineImpl nodeEngine = nodes.get(address);
                if (nodeEngine != null && nodeEngine.isActive()) {
                    nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                        public void run() {
                            final ClusterServiceImpl clusterService = (ClusterServiceImpl) nodeEngine.getClusterService();
                            clusterService.removeAddress(node.getThisAddress());
                        }
                    });
                }
            }
        }

        @Override
        public boolean registerConnection(final Address remoteEndpoint, final Connection connection) {
            mapConnections.put(remoteEndpoint, (MockConnection) connection);
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionAdded(connection);
                    }
                }

                @Override
                public int getKey() {
                    return remoteEndpoint.hashCode();
                }
            });
            return true;
        }

        public void start() {
        }

        public void addConnectionListener(ConnectionListener connectionListener) {
            connectionListeners.add(connectionListener);
        }

        public void destroyConnection(final Connection connection) {
            final Address endPoint = connection.getEndPoint();
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionRemoved(connection);
                    }
                }

                @Override
                public int getKey() {
                    return endPoint.hashCode();
                }
            });
        }


        public void restart() {
        }

        @Override
        public int getActiveConnectionCount() {
            return 0;
        }

        public int getCurrentClientConnections() {
            return 0;
        }

        @Override
        public int getConnectionCount() {
            return 0;
        }

        public int getAllTextConnections() {
            return 0;
        }
    }

    public static class MockConnection implements Connection {
        protected final Address localEndpoint;
        volatile Connection localConnection;
        final Address remoteEndpoint;
        protected final NodeEngineImpl nodeEngine;
        private volatile boolean live = true;

        public MockConnection(Address localEndpoint, Address remoteEndpoint, NodeEngineImpl nodeEngine) {
            this.localEndpoint = localEndpoint;
            this.remoteEndpoint = remoteEndpoint;
            this.nodeEngine = nodeEngine;
        }

        public Address getEndPoint() {
            return remoteEndpoint;
        }

        public boolean live() {
            return live;
        }

        public boolean write(SocketWritable socketWritable) {
            final Packet packet = (Packet) socketWritable;
            if (nodeEngine.getNode().isActive()) {
                Packet newPacket = readFromPacket(packet);
                MemberImpl member = nodeEngine.getClusterService().getMember(localEndpoint);
                if (member != null) {
                    member.didRead();
                }
                nodeEngine.getPacketTransceiver().receive(newPacket);
                return true;
            }
            return false;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }

            newPacket.setConn(localConnection);
            return newPacket;
        }

        public long lastReadTime() {
            return System.currentTimeMillis();
        }

        public long lastWriteTime() {
            return System.currentTimeMillis();
        }

        public void close() {
            if (!live) {
                return;
            }
            live = false;
            nodeEngine.getNode().connectionManager.destroyConnection(this);
        }

        public boolean isClient() {
            return false;
        }

        @Override
        public ConnectionType getType() {
            return ConnectionType.MEMBER;
        }

        public InetAddress getInetAddress() {
            try {
                return localEndpoint.getInetAddress();
            } catch (UnknownHostException e) {
                throw ExceptionUtil.rethrow(e);
            }
        }

        public InetSocketAddress getRemoteSocketAddress() {
            return new InetSocketAddress(getInetAddress(), getPort());
        }

        public int getPort() {
            return localEndpoint.getPort();
        }

        @Override
        public boolean isAlive() {
            return true;
        }

        @Override
        public String toString() {
            return "MockConnection{" +
                    "localEndpoint=" + localEndpoint +
                    ", remoteEndpoint=" + remoteEndpoint +
                    '}';
        }
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.cluster.MemberInfo;
import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.Member;
import com.hazelcast.core.MigrationEvent;
import com.hazelcast.core.MigrationEvent.MigrationStatus;
import com.hazelcast.core.MigrationListener;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionLostEvent;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationEndpoint;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.partition.PartitionEvent;
import com.hazelcast.partition.PartitionEventListener;
import com.hazelcast.partition.PartitionInfo;
import com.hazelcast.partition.PartitionLostEvent;
import com.hazelcast.partition.PartitionLostListener;
import com.hazelcast.partition.PartitionRuntimeState;
import com.hazelcast.partition.PartitionServiceProxy;
import com.hazelcast.partition.membergroup.MemberGroup;
import com.hazelcast.partition.membergroup.MemberGroupFactory;
import com.hazelcast.partition.membergroup.MemberGroupFactoryFactory;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationResponseHandler;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PartitionAwareService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.FutureUtil.ExceptionHandler;
import com.hazelcast.util.scheduler.CoalescingDelayedTrigger;
import com.hazelcast.util.scheduler.EntryTaskScheduler;
import com.hazelcast.util.scheduler.EntryTaskSchedulerFactory;
import com.hazelcast.util.scheduler.ScheduleType;
import com.hazelcast.util.scheduler.ScheduledEntry;
import com.hazelcast.util.scheduler.ScheduledEntryProcessor;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReferenceArray;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;

import static com.hazelcast.partition.impl.InternalPartitionServiceState.MIGRATION_LOCAL;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.MIGRATION_ON_MASTER;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.REPLICA_NOT_SYNC;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.SAFE;
import static com.hazelcast.spi.impl.OperationResponseHandlerFactory.createErrorLoggingResponseHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;



public class InternalPartitionServiceImpl implements InternalPartitionService, ManagedService,
        EventPublishingService<PartitionEvent, PartitionEventListener<PartitionEvent>>, PartitionAwareService {

    private static final String EXCEPTION_MSG_PARTITION_STATE_SYNC_TIMEOUT = "Partition state sync invocation timed out";

    private static final int DEFAULT_PAUSE_MILLIS = 1000;
    private static final int PARTITION_OWNERSHIP_WAIT_MILLIS = 10;
    private static final int REPLICA_SYNC_CHECK_TIMEOUT_SECONDS = 10;

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final ILogger logger;
    private final int partitionCount;
    private final InternalPartitionImpl[] partitions;
    private final PartitionReplicaVersions[] replicaVersions;
    private final AtomicReferenceArray<ReplicaSyncInfo> replicaSyncRequests;
    private final EntryTaskScheduler<Integer, ReplicaSyncInfo> replicaSyncScheduler;
    private final Semaphore replicaSyncProcessLock;
    private final MigrationThread migrationThread;
    private final long partitionMigrationInterval;
    private final long partitionMigrationTimeout;
    private final long backupSyncCheckInterval;
    private final int maxParallelReplications;
    private final PartitionStateGenerator partitionStateGenerator;
    private final MemberGroupFactory memberGroupFactory;
    private final PartitionServiceProxy proxy;
    private final Lock lock = new ReentrantLock();
    private final AtomicInteger stateVersion = new AtomicInteger();
    private final BlockingQueue<Runnable> migrationQueue = new LinkedBlockingQueue<Runnable>();
    private final AtomicBoolean migrationActive = new AtomicBoolean(true);
    private final AtomicLong lastRepartitionTime = new AtomicLong();
    private final CoalescingDelayedTrigger delayedResumeMigrationTrigger;

    private final ExceptionHandler partitionStateSyncTimeoutHandler;

    
    private volatile int memberGroupsSize;

    
    private volatile boolean initialized;

    
    private final ConcurrentMap<Integer, MigrationInfo> activeMigrations
            = new ConcurrentHashMap<Integer, MigrationInfo>(3, 0.75f, 1);

    
    private final LinkedList<MigrationInfo> completedMigrations = new LinkedList<MigrationInfo>();

    public InternalPartitionServiceImpl(Node node) {
        this.partitionCount = node.groupProperties.PARTITION_COUNT.getInteger();
        this.node = node;
        this.nodeEngine = node.nodeEngine;
        this.logger = node.getLogger(InternalPartitionService.class);
        partitionStateSyncTimeoutHandler =
                logAllExceptions(logger, EXCEPTION_MSG_PARTITION_STATE_SYNC_TIMEOUT, Level.FINEST);
        this.partitions = new InternalPartitionImpl[partitionCount];
        PartitionListener partitionListener = new LocalPartitionListener(this, node.getThisAddress());
        for (int i = 0; i < partitionCount; i++) {
            this.partitions[i] = new InternalPartitionImpl(i, partitionListener, node.getThisAddress());
        }
        replicaVersions = new PartitionReplicaVersions[partitionCount];
        for (int i = 0; i < replicaVersions.length; i++) {
            replicaVersions[i] = new PartitionReplicaVersions(i);
        }

        memberGroupFactory = MemberGroupFactoryFactory.newMemberGroupFactory(node.getConfig().getPartitionGroupConfig());
        partitionStateGenerator = new PartitionStateGeneratorImpl();

        long interval = node.groupProperties.PARTITION_MIGRATION_INTERVAL.getLong();
        partitionMigrationInterval = interval > 0 ? TimeUnit.SECONDS.toMillis(interval) : 0;

        partitionMigrationTimeout = TimeUnit.SECONDS.toMillis(
                node.groupProperties.PARTITION_MIGRATION_TIMEOUT.getLong());

        migrationThread = new MigrationThread(node);
        proxy = new PartitionServiceProxy(this);

        ExecutionService executionService = nodeEngine.getExecutionService();
        ScheduledExecutorService scheduledExecutor = executionService.getDefaultScheduledExecutor();

        
        
        
        
        
        
        
        replicaSyncScheduler = EntryTaskSchedulerFactory.newScheduler(scheduledExecutor,
                new ReplicaSyncEntryProcessor(this), ScheduleType.POSTPONE);

        replicaSyncRequests = new AtomicReferenceArray<ReplicaSyncInfo>(partitionCount);

        long maxMigrationDelayMs = calculateMaxMigrationDelayOnMemberRemoved();
        long minMigrationDelayMs = calculateMigrationDelayOnMemberRemoved(maxMigrationDelayMs);
        this.delayedResumeMigrationTrigger = new CoalescingDelayedTrigger(
                executionService, minMigrationDelayMs, maxMigrationDelayMs, new Runnable() {
            @Override
            public void run() {
                resumeMigration();
            }
        });

        long definedBackupSyncCheckInterval = node.groupProperties.PARTITION_BACKUP_SYNC_INTERVAL.getInteger();
        backupSyncCheckInterval = definedBackupSyncCheckInterval > 0 ? definedBackupSyncCheckInterval : 1;

        maxParallelReplications = node.groupProperties.PARTITION_MAX_PARALLEL_REPLICATIONS.getInteger();
        replicaSyncProcessLock = new Semaphore(maxParallelReplications);
    }

    private long calculateMaxMigrationDelayOnMemberRemoved() {
        
        return node.groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong() / 2;
    }

    private long calculateMigrationDelayOnMemberRemoved(long maxDelayMs) {
        long migrationDelayMs = node.groupProperties.MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS.getLong() * 1000;

        long connectionErrorDetectionIntervalMs = node.groupProperties.CONNECTION_MONITOR_INTERVAL.getLong()
                * node.groupProperties.CONNECTION_MONITOR_MAX_FAULTS.getInteger() * 5;
        migrationDelayMs = Math.max(migrationDelayMs, connectionErrorDetectionIntervalMs);

        long heartbeatIntervalMs = node.groupProperties.HEARTBEAT_INTERVAL_SECONDS.getLong() * 1000;
        migrationDelayMs = Math.max(migrationDelayMs, heartbeatIntervalMs * 3);

        migrationDelayMs = Math.min(migrationDelayMs, maxDelayMs);
        return migrationDelayMs;
    }

    @Override
    public void init(NodeEngine nodeEngine, Properties properties) {
        migrationThread.start();

        int partitionTableSendInterval = node.groupProperties.PARTITION_TABLE_SEND_INTERVAL.getInteger();
        if (partitionTableSendInterval <= 0) {
            partitionTableSendInterval = 1;
        }
        ExecutionService executionService = nodeEngine.getExecutionService();
        executionService.scheduleAtFixedRate(new SendClusterStateTask(),
                partitionTableSendInterval, partitionTableSendInterval, TimeUnit.SECONDS);

        executionService.scheduleWithFixedDelay(new SyncReplicaVersionTask(),
                backupSyncCheckInterval, backupSyncCheckInterval, TimeUnit.SECONDS);
    }

    @Override
    public Address getPartitionOwner(int partitionId) {
        if (!initialized) {
            firstArrangement();
        }
        if (partitions[partitionId].getOwnerOrNull() == null && !node.isMaster() && node.joined()) {
            notifyMasterToAssignPartitions();
        }
        return partitions[partitionId].getOwnerOrNull();
    }

    @Override
    public Address getPartitionOwnerOrWait(int partition) {
        Address owner = getPartitionOwner(partition);
        while (owner == null) {
            try {
                Thread.sleep(PARTITION_OWNERSHIP_WAIT_MILLIS);
            } catch (InterruptedException e) {
                ExceptionUtil.rethrow(e);
            }
            owner = getPartitionOwner(partition);
        }
        return owner;
    }

    private void notifyMasterToAssignPartitions() {
        if (initialized) {
            return;
        }
        if (lock.tryLock()) {
            try {
                if (!initialized && !node.isMaster() && node.getMasterAddress() != null && node.joined()) {
                    Future f = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, new AssignPartitions(),
                            node.getMasterAddress()).setTryCount(1).invoke();
                    f.get(1, TimeUnit.SECONDS);
                }
            } catch (Exception e) {
                logger.finest(e);
            } finally {
                lock.unlock();
            }
        }
    }

    @Override
    public void firstArrangement() {
        if (!node.isMaster() || !node.isActive()) {
            notifyMasterToAssignPartitions();
            return;
        }
        if (!initialized) {
            lock.lock();
            try {
                if (initialized) {
                    return;
                }
                PartitionStateGenerator psg = partitionStateGenerator;
                final Set<Member> members = node.getClusterService().getMembers();
                Collection<MemberGroup> memberGroups = memberGroupFactory.createMemberGroups(members);
                if (memberGroups.isEmpty()) {
                    logger.warning("No member group is available to assign partition ownership...");
                    return;
                }

                logger.info("Initializing cluster partition table first arrangement...");
                Address[][] newState = psg.initialize(memberGroups, partitionCount);
                if (newState.length != partitionCount) {
                    throw new HazelcastException("Invalid partition count! "
                            + "Expected: " + partitionCount + ", Actual: " + newState.length);
                }

                for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
                    InternalPartitionImpl partition = partitions[partitionId];
                    Address[] replicas = newState[partitionId];
                    partition.setReplicaAddresses(replicas);
                }
                initialized = true;
                publishPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
        }
    }

    private void updateMemberGroupsSize() {
        Set<Member> members = node.getClusterService().getMembers();
        final Collection<MemberGroup> groups = memberGroupFactory.createMemberGroups(members);
        int size = 0;
        for (MemberGroup group : groups) {
            if (group.size() > 0) {
                size++;
            }
        }
        memberGroupsSize = size;
    }

    @Override
    public int getMemberGroupsSize() {
        int size = memberGroupsSize;
        
        
        return size > 0 ? size : 1;
    }

    @Override
    public int getMaxBackupCount() {
        return Math.min(getMemberGroupsSize() - 1, InternalPartition.MAX_BACKUP_COUNT);
    }

    public void memberAdded(MemberImpl member) {
        if (!member.localMember()) {
            updateMemberGroupsSize();
        }
        if (node.isMaster() && node.isActive()) {
            lock.lock();
            try {
                migrationQueue.clear();
                if (initialized) {
                    migrationQueue.add(new RepartitioningTask());

                    
                    Collection<MemberImpl> members = node.clusterService.getMemberList();
                    PartitionStateOperation op = new PartitionStateOperation(createPartitionState(members));
                    nodeEngine.getOperationService().send(op, member.getAddress());
                }
            } finally {
                lock.unlock();
            }
        }
    }

    public void memberRemoved(final MemberImpl member) {
        updateMemberGroupsSize();
        final Address deadAddress = member.getAddress();
        final Address thisAddress = node.getThisAddress();
        if (deadAddress == null || deadAddress.equals(thisAddress)) {
            return;
        }
        lock.lock();
        try {
            migrationQueue.clear();
            if (!activeMigrations.isEmpty()) {
                if (node.isMaster()) {
                    rollbackActiveMigrationsFromPreviousMaster(node.getLocalMember().getUuid());
                }
                for (MigrationInfo migrationInfo : activeMigrations.values()) {
                    if (deadAddress.equals(migrationInfo.getSource()) || deadAddress.equals(migrationInfo.getDestination())) {
                        migrationInfo.invalidate();
                    }
                }
            }
            
            
            
            
            pauseMigration();
            cancelReplicaSyncRequestsTo(deadAddress);
            removeDeadAddress(deadAddress, thisAddress);

            if (node.isMaster() && initialized) {
                migrationQueue.add(new RepartitioningTask());
            }

            resumeMigrationEventually();
        } finally {
            lock.unlock();
        }
    }

    private void cancelReplicaSyncRequestsTo(Address deadAddress) {
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            ReplicaSyncInfo syncInfo = replicaSyncRequests.get(partitionId);
            if (syncInfo != null && deadAddress.equals(syncInfo.target)) {
                cancelReplicaSync(partitionId);
            }
        }
    }

    void cancelReplicaSync(int partitionId) {
        ReplicaSyncInfo syncInfo = replicaSyncRequests.get(partitionId);
        if (syncInfo != null && replicaSyncRequests.compareAndSet(partitionId, syncInfo, null)) {
            replicaSyncScheduler.cancel(partitionId);
            releaseReplicaSyncPermit();
        }
    }

    private void resumeMigrationEventually() {
        delayedResumeMigrationTrigger.executeWithDelay();
    }

    private void removeDeadAddress(Address deadAddress, Address thisAddress) {
        for (InternalPartitionImpl partition : partitions) {
            if (deadAddress.equals(partition.getOwnerOrNull()) && thisAddress.equals(partition.getReplicaAddress(1))) {
                partition.setMigrating(true);
            }
            
            partition.onDeadAddress(deadAddress);
            
            if (partition.onDeadAddress(deadAddress)) {
                throw new IllegalStateException("Duplicate address found in partition replicas!");
            }

        }
    }

    private void rollbackActiveMigrationsFromPreviousMaster(final String currentMasterUuid) {
        lock.lock();
        try {
            if (!activeMigrations.isEmpty()) {
                for (MigrationInfo migrationInfo : activeMigrations.values()) {
                    if (!currentMasterUuid.equals(migrationInfo.getMasterUuid())) {
                        
                        
                        logger.info("Rolling-back migration initiated by the old master -> " + migrationInfo);
                        finalizeActiveMigration(migrationInfo);
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private PartitionRuntimeState createPartitionState(Collection<MemberImpl> members) {
        lock.lock();
        try {
            List<MemberInfo> memberInfos = new ArrayList<MemberInfo>(members.size());
            for (MemberImpl member : members) {
                MemberInfo memberInfo = new MemberInfo(member.getAddress(), member.getUuid(), member.getAttributes());
                memberInfos.add(memberInfo);
            }
            ArrayList<MigrationInfo> migrationInfos = new ArrayList<MigrationInfo>(completedMigrations);
            ILogger logger = node.getLogger(PartitionRuntimeState.class);
            return new PartitionRuntimeState(logger, memberInfos, partitions, migrationInfos, stateVersion.get());
        } finally {
            lock.unlock();
        }
    }

    private void publishPartitionRuntimeState() {
        if (!initialized) {
            
            return;
        }

        if (!node.isMaster() || !node.isActive() || !node.joined()) {
            return;
        }

        if (!isMigrationActive()) {
            
            return;
        }

        lock.lock();
        try {
            Collection<MemberImpl> members = node.clusterService.getMemberList();
            PartitionRuntimeState partitionState = createPartitionState(members);
            PartitionStateOperation op = new PartitionStateOperation(partitionState);

            OperationService operationService = nodeEngine.getOperationService();
            for (MemberImpl member : members) {
                if (!member.localMember()) {
                    try {
                        operationService.send(op, member.getAddress());
                    } catch (Exception e) {
                        logger.finest(e);
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void syncPartitionRuntimeState() {
        syncPartitionRuntimeState(node.clusterService.getMemberList());
    }

    private void syncPartitionRuntimeState(Collection<MemberImpl> members) {
        if (!initialized) {
            
            return;
        }

        if (!node.isMaster() || !node.isActive() || !node.joined()) {
            return;
        }

        lock.lock();
        try {
            PartitionRuntimeState partitionState = createPartitionState(members);
            OperationService operationService = nodeEngine.getOperationService();

            List<Future> calls = firePartitionStateOperation(members, partitionState, operationService);
            waitWithDeadline(calls, 3, TimeUnit.SECONDS, partitionStateSyncTimeoutHandler);
        } finally {
            lock.unlock();
        }
    }

    private List<Future> firePartitionStateOperation(Collection<MemberImpl> members,
                                                     PartitionRuntimeState partitionState,
                                                     OperationService operationService) {
        List<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    Address address = member.getAddress();
                    PartitionStateOperation operation = new PartitionStateOperation(partitionState, true);
                    Future<Object> f = operationService.invokeOnTarget(SERVICE_NAME, operation, address);
                    calls.add(f);
                } catch (Exception e) {
                    logger.finest(e);
                }
            }
        }
        return calls;
    }

    void processPartitionRuntimeState(PartitionRuntimeState partitionState) {
        lock.lock();
        try {
            if (!node.isActive() || !node.joined()) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Node should be active(" + node.isActive() + ") and joined(" + node.joined()
                            + ") to be able to process partition table!");
                }
                return;
            }
            final Address sender = partitionState.getEndpoint();
            final Address master = node.getMasterAddress();
            if (node.isMaster()) {
                logger.warning("This is the master node and received a PartitionRuntimeState from "
                        + sender + ". Ignoring incoming state! ");
                return;
            } else {
                if (sender == null || !sender.equals(master)) {
                    if (node.clusterService.getMember(sender) == null) {
                        logger.severe("Received a ClusterRuntimeState from an unknown member!"
                                + " => Sender: " + sender + ", Master: " + master + "! ");
                        return;
                    } else {
                        logger.warning("Received a ClusterRuntimeState, but its sender doesn't seem to be master!"
                                + " => Sender: " + sender + ", Master: " + master + "! "
                                + "(Ignore if master node has changed recently.)");
                        return;
                    }
                }
            }

            stateVersion.set(partitionState.getVersion());
            initialized = true;

            PartitionInfo[] state = partitionState.getPartitions();
            filterAndLogUnknownAddressesInPartitionTable(sender, state);
            finalizeOrRollbackMigration(partitionState, state);
        } finally {
            lock.unlock();
        }
    }

    private void finalizeOrRollbackMigration(PartitionRuntimeState partitionState, PartitionInfo[] state) {
        Collection<MigrationInfo> completedMigrations = partitionState.getCompletedMigrations();
        for (MigrationInfo completedMigration : completedMigrations) {
            addCompletedMigration(completedMigration);
            int partitionId = completedMigration.getPartitionId();
            PartitionInfo partitionInfo = state[partitionId];
            
            
            
            
            
            
            updatePartition(partitionInfo);
            finalizeActiveMigration(completedMigration);
        }
        if (!activeMigrations.isEmpty()) {
            final MemberImpl masterMember = getMasterMember();
            rollbackActiveMigrationsFromPreviousMaster(masterMember.getUuid());
        }

        updateAllPartitions(state);
    }

    private void updatePartition(PartitionInfo partitionInfo) {
        InternalPartitionImpl partition = partitions[partitionInfo.getPartitionId()];
        Address[] replicas = partitionInfo.getReplicaAddresses();
        partition.setReplicaAddresses(replicas);
    }

    private void updateAllPartitions(PartitionInfo[] state) {
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            updatePartition(state[partitionId]);
        }
    }

    private void filterAndLogUnknownAddressesInPartitionTable(Address sender, PartitionInfo[] state) {
        final Set<Address> unknownAddresses = new HashSet<Address>();
        for (int partitionId = 0; partitionId < state.length; partitionId++) {
            PartitionInfo partitionInfo = state[partitionId];
            searchUnknownAddressesInPartitionTable(sender, unknownAddresses, partitionId, partitionInfo);
        }
        logUnknownAddressesInPartitionTable(sender, unknownAddresses);
    }

    private void logUnknownAddressesInPartitionTable(Address sender, Set<Address> unknownAddresses) {
        if (!unknownAddresses.isEmpty() && logger.isLoggable(Level.WARNING)) {
            StringBuilder s = new StringBuilder("Following unknown addresses are found in partition table")
                    .append(" sent from master[").append(sender).append("].")
                    .append(" (Probably they have recently joined or left the cluster.)")
                    .append(" {");
            for (Address address : unknownAddresses) {
                s.append("\n\t").append(address);
            }
            s.append("\n}");
            logger.warning(s.toString());
        }
    }

    private void searchUnknownAddressesInPartitionTable(Address sender, Set<Address> unknownAddresses, int partitionId,
                                                        PartitionInfo partitionInfo) {
        for (int index = 0; index < InternalPartition.MAX_REPLICA_COUNT; index++) {
            Address address = partitionInfo.getReplicaAddress(index);
            if (address != null && getMember(address) == null) {
                if (logger.isFinestEnabled()) {
                    logger.finest(
                            "Unknown " + address + " found in partition table sent from master "
                                    + sender + ". It has probably already left the cluster. partitionId="
                                    + partitionId);
                }
                unknownAddresses.add(address);
            }
        }
    }

    private void finalizeActiveMigration(final MigrationInfo migrationInfo) {
        if (activeMigrations.containsKey(migrationInfo.getPartitionId())) {
            lock.lock();
            try {
                if (activeMigrations.containsValue(migrationInfo)) {
                    if (migrationInfo.startProcessing()) {
                        processMigrationInfo(migrationInfo);
                    } else {
                        logger.info("Scheduling finalization of " + migrationInfo
                                + ", because migration process is currently running.");
                        nodeEngine.getExecutionService().schedule(new Runnable() {
                            @Override
                            public void run() {
                                finalizeActiveMigration(migrationInfo);
                            }
                        }, 3, TimeUnit.SECONDS);
                    }
                }
            } finally {
                lock.unlock();
            }
        }
    }

    private void processMigrationInfo(MigrationInfo migrationInfo) {
        try {
            Address thisAddress = node.getThisAddress();
            boolean source = thisAddress.equals(migrationInfo.getSource());
            boolean destination = thisAddress.equals(migrationInfo.getDestination());
            if (source || destination) {
                int partitionId = migrationInfo.getPartitionId();
                InternalPartitionImpl migratingPartition = getPartitionImpl(partitionId);
                Address ownerAddress = migratingPartition.getOwnerOrNull();
                boolean success = migrationInfo.getDestination().equals(ownerAddress);
                MigrationEndpoint endpoint = source ? MigrationEndpoint.SOURCE : MigrationEndpoint.DESTINATION;
                FinalizeMigrationOperation op = new FinalizeMigrationOperation(endpoint, success);
                op.setPartitionId(partitionId)
                        .setNodeEngine(nodeEngine)
                        .setValidateTarget(false)
                        .setService(this);
                nodeEngine.getOperationService().executeOperation(op);
            }
        } catch (Exception e) {
            logger.warning(e);
        } finally {
            migrationInfo.doneProcessing();
        }
    }

    void addActiveMigration(MigrationInfo migrationInfo) {
        lock.lock();
        try {
            int partitionId = migrationInfo.getPartitionId();
            partitions[partitionId].setMigrating(true);
            MigrationInfo currentMigrationInfo = activeMigrations.putIfAbsent(partitionId, migrationInfo);
            if (currentMigrationInfo != null) {
                boolean oldMaster = false;
                MigrationInfo oldMigration;
                MigrationInfo newMigration;
                MemberImpl masterMember = getMasterMember();
                String master = masterMember.getUuid();
                if (!master.equals(currentMigrationInfo.getMasterUuid())) {
                    
                    oldMigration = currentMigrationInfo;
                    newMigration = migrationInfo;
                    oldMaster = true;
                } else if (!master.equals(migrationInfo.getMasterUuid())) {
                    
                    oldMigration = migrationInfo;
                    newMigration = currentMigrationInfo;
                    oldMaster = true;
                } else if (!currentMigrationInfo.isProcessing() && migrationInfo.isProcessing()) {
                    
                    oldMigration = currentMigrationInfo;
                    newMigration = migrationInfo;
                } else {
                    String message = "Something is seriously wrong! There are two migration requests for the "
                            + "same partition! First -> " + currentMigrationInfo + ", Second -> " + migrationInfo;
                    IllegalStateException error = new IllegalStateException(message);
                    logger.severe(message, error);
                    throw error;
                }

                if (oldMaster) {
                    logger.info("Finalizing migration instantiated by the old master -> " + oldMigration);
                } else {
                    if (logger.isFinestEnabled()) {
                        logger.finest("Finalizing previous migration -> " + oldMigration);
                    }
                }
                finalizeActiveMigration(oldMigration);
                activeMigrations.put(partitionId, newMigration);
            }
        } finally {
            lock.unlock();
        }
    }

    private MemberImpl getMasterMember() {
        return node.clusterService.getMember(node.getMasterAddress());
    }

    MigrationInfo getActiveMigration(int partitionId) {
        return activeMigrations.get(partitionId);
    }

    MigrationInfo removeActiveMigration(int partitionId) {
        partitions[partitionId].setMigrating(false);
        return activeMigrations.remove(partitionId);
    }

    public Collection<MigrationInfo> getActiveMigrations() {
        return Collections.unmodifiableCollection(activeMigrations.values());
    }

    private void addCompletedMigration(MigrationInfo migrationInfo) {
        lock.lock();
        try {
            if (completedMigrations.size() > 25) {
                completedMigrations.removeFirst();
            }
            completedMigrations.add(migrationInfo);
        } finally {
            lock.unlock();
        }
    }

    private void evictCompletedMigrations() {
        lock.lock();
        try {
            if (!completedMigrations.isEmpty()) {
                completedMigrations.removeFirst();
            }
        } finally {
            lock.unlock();
        }
    }

    
    
    
    void triggerPartitionReplicaSync(int partitionId, int replicaIndex, long delayMillis) {
        if (replicaIndex < 0 || replicaIndex > InternalPartition.MAX_REPLICA_COUNT) {
            throw new IllegalArgumentException("Invalid replica index! replicaIndex=" + replicaIndex
                    + " for partitionId=" + partitionId);
        }

        if (!checkSyncPartitionTarget(partitionId, replicaIndex)) {
            return;
        }

        InternalPartitionImpl partition = getPartitionImpl(partitionId);
        Address target = partition.getOwnerOrNull();
        ReplicaSyncInfo syncInfo = new ReplicaSyncInfo(partitionId, replicaIndex, target);

        if (delayMillis > 0) {
            schedulePartitionReplicaSync(syncInfo, target, delayMillis);
            return;
        }

        
        
        
        if (!isMigrationActive() || partition.isMigrating()) {
            schedulePartitionReplicaSync(syncInfo, target, REPLICA_SYNC_RETRY_DELAY);
            return;
        }

        if (replicaSyncRequests.compareAndSet(partitionId, null, syncInfo)) {
            if (fireSyncReplicaRequest(syncInfo, target)) {
                return;
            }

            replicaSyncRequests.compareAndSet(partitionId, syncInfo, null);
            schedulePartitionReplicaSync(syncInfo, target, REPLICA_SYNC_RETRY_DELAY);
            return;
        }

        long scheduleDelay = getReplicaSyncScheduleDelay(partitionId);
        schedulePartitionReplicaSync(syncInfo, target, scheduleDelay);
    }

    private long getReplicaSyncScheduleDelay(int partitionId) {
        long scheduleDelay = DEFAULT_REPLICA_SYNC_DELAY;
        Address thisAddress = node.getThisAddress();
        InternalPartitionImpl partition = getPartitionImpl(partitionId);
        ReplicaSyncInfo currentSyncInfo = replicaSyncRequests.get(partitionId);
        if (currentSyncInfo != null
                && !thisAddress.equals(partition.getReplicaAddress(currentSyncInfo.replicaIndex))) {
            clearReplicaSyncRequest(partitionId, currentSyncInfo.replicaIndex);
            scheduleDelay = REPLICA_SYNC_RETRY_DELAY;
        }
        return scheduleDelay;
    }

    private boolean fireSyncReplicaRequest(ReplicaSyncInfo syncInfo, Address target) {
        if (tryToAcquireReplicaSyncPermit()) {
            int partitionId = syncInfo.partitionId;
            int replicaIndex = syncInfo.replicaIndex;
            replicaSyncScheduler.cancel(partitionId);

            if (logger.isFinestEnabled()) {
                logger.finest("Sending sync replica request to -> " + target + "; for partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex);
            }
            replicaSyncScheduler.schedule(partitionMigrationTimeout, partitionId, syncInfo);
            ReplicaSyncRequest syncRequest = new ReplicaSyncRequest(partitionId, replicaIndex);
            nodeEngine.getOperationService().send(syncRequest, target);
            return true;
        }
        return false;
    }

    private void schedulePartitionReplicaSync(ReplicaSyncInfo syncInfo, Address target, long delayMillis) {
        int partitionId = syncInfo.partitionId;
        int replicaIndex = syncInfo.replicaIndex;

        if (logger.isFinestEnabled()) {
            logger.finest("Scheduling [" + delayMillis + "ms] sync replica request to -> " + target
                    + "; for partitionId=" + partitionId + ", replicaIndex=" + replicaIndex);
        }
        replicaSyncScheduler.schedule(delayMillis, partitionId, syncInfo);
    }

    private boolean checkSyncPartitionTarget(int partitionId, int replicaIndex) {
        final InternalPartitionImpl partition = getPartitionImpl(partitionId);
        final Address target = partition.getOwnerOrNull();
        if (target == null) {
            logger.info("Sync replica target is null, no need to sync -> partitionId=" + partitionId + ", replicaIndex="
                    + replicaIndex);
            return false;
        }

        Address thisAddress = nodeEngine.getThisAddress();
        if (target.equals(thisAddress)) {
            if (logger.isFinestEnabled()) {
                logger.finest("This node is now owner of partition, cannot sync replica -> partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex + ", partition-info="
                        + getPartitionImpl(partitionId));
            }
            return false;
        }

        if (!partition.isOwnerOrBackup(thisAddress)) {
            if (logger.isFinestEnabled()) {
                logger.finest("This node is not backup replica of partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex + " anymore.");
            }
            return false;
        }
        return true;
    }

    @Override
    public InternalPartition[] getPartitions() {
        
        InternalPartition[] result = new InternalPartition[partitions.length];
        System.arraycopy(partitions, 0, result, 0, partitions.length);
        return result;
    }

    @Override
    public MemberImpl getMember(Address address) {
        return node.clusterService.getMember(address);
    }

    InternalPartitionImpl getPartitionImpl(int partitionId) {
        return partitions[partitionId];
    }

    @Override
    public InternalPartitionImpl getPartition(int partitionId) {
        return getPartition(partitionId, true);
    }

    @Override
    public InternalPartitionImpl getPartition(int partitionId, boolean triggerOwnerAssignment) {
        InternalPartitionImpl p = getPartitionImpl(partitionId);
        if (triggerOwnerAssignment && p.getOwnerOrNull() == null) {
            
            
            getPartitionOwner(partitionId);
        }
        return p;
    }

    @Override
    public boolean prepareToSafeShutdown(long timeout, TimeUnit unit) {
        long timeoutInMillis = unit.toMillis(timeout);
        long sleep = DEFAULT_PAUSE_MILLIS;
        while (timeoutInMillis > 0) {
            while (timeoutInMillis > 0 && shouldWaitMigrationOrBackups(Level.INFO)) {
                timeoutInMillis = sleepWithBusyWait(timeoutInMillis, sleep);
            }
            if (timeoutInMillis <= 0) {
                break;
            }

            if (node.isMaster()) {
                syncPartitionRuntimeState();
            } else {
                timeoutInMillis = waitForOngoingMigrations(timeoutInMillis, sleep);
                if (timeoutInMillis <= 0) {
                    break;
                }
            }

            long start = Clock.currentTimeMillis();
            boolean ok = checkReplicaSyncState();
            timeoutInMillis -= (Clock.currentTimeMillis() - start);
            if (ok) {
                logger.finest("Replica sync state before shutdown is OK");
                return true;
            } else {
                if (timeoutInMillis <= 0) {
                    break;
                }
                logger.info("Some backup replicas are inconsistent with primary, waiting for synchronization. Timeout: "
                        + timeoutInMillis + "ms");
                timeoutInMillis = sleepWithBusyWait(timeoutInMillis, sleep);
            }
        }
        return false;
    }

    private long waitForOngoingMigrations(long timeoutInMillis, long sleep) {
        long timeout = timeoutInMillis;
        while (timeout > 0 && hasOnGoingMigrationMaster(Level.WARNING)) {
            
            logger.info("Waiting for the master node to complete remaining migrations!");
            timeout = sleepWithBusyWait(timeout, sleep);
        }
        return timeout;
    }

    private long sleepWithBusyWait(long timeoutInMillis, long sleep) {
        try {
            
            Thread.sleep(sleep);
        } catch (InterruptedException ie) {
            logger.finest("Busy wait interrupted", ie);
        }
        return timeoutInMillis - sleep;
    }

    @Override
    public boolean isMemberStateSafe() {
        return getMemberState() == SAFE;
    }

    public InternalPartitionServiceState getMemberState() {
        if (hasOnGoingMigrationLocal()) {
            return MIGRATION_LOCAL;
        }

        if (!node.isMaster()) {
            if (hasOnGoingMigrationMaster(Level.OFF)) {
                return MIGRATION_ON_MASTER;
            }
        }

        return isReplicaInSyncState() ? SAFE : REPLICA_NOT_SYNC;
    }

    @Override
    public boolean hasOnGoingMigration() {
        return hasOnGoingMigrationLocal() || (!node.isMaster() && hasOnGoingMigrationMaster(Level.FINEST));
    }

    private boolean hasOnGoingMigrationMaster(Level level) {
        Address masterAddress = node.getMasterAddress();
        if (masterAddress == null) {
            return true;
        }
        Operation operation = new HasOngoingMigration();
        OperationService operationService = nodeEngine.getOperationService();
        InvocationBuilder invocationBuilder = operationService.createInvocationBuilder(SERVICE_NAME, operation,
                masterAddress);
        Future future = invocationBuilder.setTryCount(100).setTryPauseMillis(100).invoke();
        try {
            return (Boolean) future.get(1, TimeUnit.MINUTES);
        } catch (InterruptedException ie) {
            Logger.getLogger(InternalPartitionServiceImpl.class).finest("Future wait interrupted", ie);
        } catch (Exception e) {
            logger.log(level, "Could not get a response from master about migrations! -> " + e.toString());
        }
        return false;
    }

    @Override
    public boolean hasOnGoingMigrationLocal() {
        return !activeMigrations.isEmpty() || !migrationQueue.isEmpty()
                || !isMigrationActive()
                || migrationThread.isMigrating()
                || shouldWaitMigrationOrBackups(Level.OFF);
    }

    private boolean isReplicaInSyncState() {
        if (!initialized || getMemberGroupsSize() < 2) {
            return true;
        }
        final int replicaIndex = 1;
        final List<Future> futures = new ArrayList<Future>();
        final Address thisAddress = node.getThisAddress();
        for (InternalPartitionImpl partition : partitions) {
            final Address owner = partition.getOwnerOrNull();
            if (thisAddress.equals(owner)) {
                if (partition.getReplicaAddress(replicaIndex) != null) {
                    final int partitionId = partition.getPartitionId();
                    final long replicaVersion = getCurrentReplicaVersion(replicaIndex, partitionId);
                    final Operation operation = createReplicaSyncStateOperation(replicaVersion, partitionId);
                    final Future future = invoke(operation, replicaIndex, partitionId);
                    futures.add(future);
                }
            }
        }
        if (futures.isEmpty()) {
            return true;
        }
        for (Future future : futures) {
            boolean isSync = getFutureResult(future, REPLICA_SYNC_CHECK_TIMEOUT_SECONDS, TimeUnit.SECONDS);
            if (!isSync) {
                return false;
            }
        }
        return true;
    }

    private long getCurrentReplicaVersion(int replicaIndex, int partitionId) {
        final long[] versions = getPartitionReplicaVersions(partitionId);
        return versions[replicaIndex - 1];
    }

    private boolean getFutureResult(Future future, long seconds, TimeUnit unit) {
        boolean sync;
        try {
            sync = (Boolean) future.get(seconds, unit);
        } catch (Throwable t) {
            sync = false;
            logger.warning("Exception while getting future", t);
        }
        return sync;
    }

    private Future invoke(Operation operation, int replicaIndex, int partitionId) {
        final OperationService operationService = nodeEngine.getOperationService();
        return operationService.createInvocationBuilder(InternalPartitionService.SERVICE_NAME, operation, partitionId)
                .setTryCount(3)
                .setTryPauseMillis(250)
                .setReplicaIndex(replicaIndex)
                .invoke();
    }

    private Operation createReplicaSyncStateOperation(long replicaVersion, int partitionId) {
        final Operation op = new IsReplicaVersionSync(replicaVersion);
        op.setService(this);
        op.setNodeEngine(nodeEngine);
        op.setOperationResponseHandler(createErrorLoggingResponseHandler(node.getLogger(IsReplicaVersionSync.class)));
        op.setPartitionId(partitionId);

        return op;
    }

    private boolean checkReplicaSyncState() {
        if (!initialized) {
            return true;
        }

        if (getMemberGroupsSize() < 2) {
            return true;
        }

        final Address thisAddress = node.getThisAddress();
        final Semaphore s = new Semaphore(0);
        final AtomicBoolean ok = new AtomicBoolean(true);
        final ExecutionCallback<Object> callback = new ExecutionCallback<Object>() {
            @Override
            public void onResponse(Object response) {
                if (Boolean.FALSE.equals(response)) {
                    ok.compareAndSet(true, false);
                }
                s.release();
            }

            @Override
            public void onFailure(Throwable t) {
                ok.compareAndSet(true, false);
            }
        };
        int ownedCount = submitSyncReplicaOperations(thisAddress, s, ok, callback);
        try {
            if (ok.get()) {
                int permits = ownedCount * getMaxBackupCount();
                return s.tryAcquire(permits, REPLICA_SYNC_CHECK_TIMEOUT_SECONDS, TimeUnit.SECONDS) && ok.get();
            } else {
                return false;
            }
        } catch (InterruptedException ignored) {
            return false;
        }
    }

    private int submitSyncReplicaOperations(Address thisAddress, Semaphore s, AtomicBoolean ok,
                                            ExecutionCallback callback) {

        int ownedCount = 0;
        ILogger responseLogger = node.getLogger(SyncReplicaVersion.class);
        OperationResponseHandler responseHandler =
                createErrorLoggingResponseHandler(responseLogger);

        for (InternalPartitionImpl partition : partitions) {
            Address owner = partition.getOwnerOrNull();
            if (thisAddress.equals(owner)) {
                for (int i = 1; i <= getMaxBackupCount(); i++) {
                    if (partition.getReplicaAddress(i) != null) {
                        SyncReplicaVersion op = new SyncReplicaVersion(i, callback);
                        op.setService(this);
                        op.setNodeEngine(nodeEngine);
                        op.setOperationResponseHandler(responseHandler);
                        op.setPartitionId(partition.getPartitionId());
                        nodeEngine.getOperationService().executeOperation(op);
                    } else {
                        ok.set(false);
                        s.release();
                    }
                }
                ownedCount++;
            } else if (owner == null) {
                ok.set(false);
            }
        }
        return ownedCount;
    }

    private boolean shouldWaitMigrationOrBackups(Level level) {
        if (!preCheckShouldWaitMigrationOrBackups()) {
            return false;
        }

        if (checkForActiveMigrations(level)) {
            return true;
        }

        for (InternalPartitionImpl partition : partitions) {
            if (partition.getReplicaAddress(1) == null) {
                if (logger.isLoggable(level)) {
                    logger.log(level, "Should take backup of partitionId=" + partition.getPartitionId());
                }
                return true;
            }
        }
        int replicaSyncProcesses = maxParallelReplications - replicaSyncProcessLock.availablePermits();
        if (replicaSyncProcesses > 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Processing replica sync requests: " + replicaSyncProcesses);
            }
            return true;
        }
        return false;
    }

    private boolean preCheckShouldWaitMigrationOrBackups() {
        if (!initialized) {
            return false;
        }

        if (getMemberGroupsSize() < 2) {
            return false;
        }

        return true;
    }

    private boolean checkForActiveMigrations(Level level) {
        final int activeSize = activeMigrations.size();
        if (activeSize != 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Waiting for active migration tasks: " + activeSize);
            }
            return true;
        }

        int queueSize = migrationQueue.size();
        if (queueSize != 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Waiting for cluster migration tasks: " + queueSize);
            }
            return true;
        }
        return false;
    }

    @Override
    public final int getPartitionId(Data key) {
        int hash = key.getPartitionHash();
        if (hash == Integer.MIN_VALUE) {
            return 0;
        } else {
            return Math.abs(hash) % partitionCount;
        }
    }

    @Override
    public final int getPartitionId(Object key) {
        return getPartitionId(nodeEngine.toData(key));
    }

    @Override
    public final int getPartitionCount() {
        return partitionCount;
    }

    public long getPartitionMigrationTimeout() {
        return partitionMigrationTimeout;
    }

    
    
    @Override
    public long[] incrementPartitionReplicaVersions(int partitionId, int backupCount) {
        PartitionReplicaVersions replicaVersion = replicaVersions[partitionId];
        return replicaVersion.incrementAndGet(backupCount);
    }

    
    @Override
    public void updatePartitionReplicaVersions(int partitionId, long[] versions, int replicaIndex) {
        PartitionReplicaVersions partitionVersion = replicaVersions[partitionId];
        if (!partitionVersion.update(versions, replicaIndex)) {
            
            triggerPartitionReplicaSync(partitionId, replicaIndex, 0L);
        }
    }

    
    
    @Override
    public long[] getPartitionReplicaVersions(int partitionId) {
        return replicaVersions[partitionId].get();
    }

    
    @Override
    public void setPartitionReplicaVersions(int partitionId, long[] versions, int replicaOffset) {
        replicaVersions[partitionId].set(versions, replicaOffset);
    }

    @Override
    public void clearPartitionReplicaVersions(int partitionId) {
        replicaVersions[partitionId].clear();
    }

    
    void finalizeReplicaSync(int partitionId, int replicaIndex, long[] versions) {
        PartitionReplicaVersions replicaVersion = replicaVersions[partitionId];
        replicaVersion.clear();
        replicaVersion.set(versions, replicaIndex);
        clearReplicaSyncRequest(partitionId, replicaIndex);
    }

    
    void clearReplicaSyncRequest(int partitionId, int replicaIndex) {
        ReplicaSyncInfo syncInfo = new ReplicaSyncInfo(partitionId, replicaIndex, null);
        ReplicaSyncInfo currentSyncInfo = replicaSyncRequests.get(partitionId);

        replicaSyncScheduler.cancelIfExists(partitionId, syncInfo);

        if (syncInfo.equals(currentSyncInfo)
                && replicaSyncRequests.compareAndSet(partitionId, currentSyncInfo, null)) {

            releaseReplicaSyncPermit();
        } else if (currentSyncInfo != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("Not able to cancel sync! " + syncInfo + " VS Current " + currentSyncInfo);
            }
        }
    }

    boolean tryToAcquireReplicaSyncPermit() {
        return replicaSyncProcessLock.tryAcquire();
    }

    void releaseReplicaSyncPermit() {
        replicaSyncProcessLock.release();
    }

    @Override
    public Map<Address, List<Integer>> getMemberPartitionsMap() {
        final int members = node.getClusterService().getSize();
        Map<Address, List<Integer>> memberPartitions = new HashMap<Address, List<Integer>>(members);
        for (int i = 0; i < partitionCount; i++) {
            Address owner;
            while ((owner = getPartitionOwner(i)) == null) {
                try {
                    Thread.sleep(PARTITION_OWNERSHIP_WAIT_MILLIS);
                } catch (InterruptedException e) {
                    throw new HazelcastException(e);
                }
            }
            List<Integer> ownedPartitions = memberPartitions.get(owner);
            if (ownedPartitions == null) {
                ownedPartitions = new ArrayList<Integer>();
                memberPartitions.put(owner, ownedPartitions);
            }
            ownedPartitions.add(i);
        }
        return memberPartitions;
    }

    @Override
    public List<Integer> getMemberPartitions(Address target) {
        List<Integer> ownedPartitions = new LinkedList<Integer>();
        for (int i = 0; i < partitionCount; i++) {
            final Address owner = getPartitionOwner(i);
            if (target.equals(owner)) {
                ownedPartitions.add(i);
            }
        }
        return ownedPartitions;
    }

    @Override
    public void reset() {
        migrationQueue.clear();
        for (int k = 0; k < replicaSyncRequests.length(); k++) {
            replicaSyncRequests.set(k, null);
        }
        replicaSyncScheduler.cancelAll();
        
        
        replicaSyncProcessLock.drainPermits();
        replicaSyncProcessLock.release(maxParallelReplications);

        lock.lock();
        try {
            initialized = false;
            for (InternalPartitionImpl partition : partitions) {
                partition.reset();
            }
            activeMigrations.clear();
            completedMigrations.clear();
            stateVersion.set(0);
        } finally {
            lock.unlock();
        }
    }

    public void pauseMigration() {
        migrationActive.set(false);
    }

    public void resumeMigration() {
        migrationActive.set(true);
    }

    public boolean isMigrationActive() {
        return migrationActive.get();
    }

    @Override
    public void shutdown(boolean terminate) {
        logger.finest("Shutting down the partition service");
        migrationThread.stopNow();
        reset();
    }

    public long getMigrationQueueSize() {
        return migrationQueue.size();
    }

    public PartitionServiceProxy getPartitionServiceProxy() {
        return proxy;
    }

    private void sendMigrationEvent(final MigrationInfo migrationInfo, final MigrationStatus status) {
        MemberImpl current = getMember(migrationInfo.getSource());
        MemberImpl newOwner = getMember(migrationInfo.getDestination());
        MigrationEvent event = new MigrationEvent(migrationInfo.getPartitionId(), current, newOwner, status);
        EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, MIGRATION_EVENT_TOPIC);
        eventService.publishEvent(SERVICE_NAME, registrations, event, event.getPartitionId());
    }

    @Override
    public String addMigrationListener(MigrationListener listener) {
        if (listener == null) {
            throw new NullPointerException("listener can't be null");
        }

        final MigrationListenerAdapter adapter = new MigrationListenerAdapter(listener);

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration = eventService.registerListener(SERVICE_NAME, MIGRATION_EVENT_TOPIC, adapter);
        return registration.getId();
    }

    @Override
    public boolean removeMigrationListener(String registrationId) {
        if (registrationId == null) {
            throw new NullPointerException("registrationId can't be null");
        }

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, MIGRATION_EVENT_TOPIC, registrationId);
    }

    @Override
    public String addPartitionLostListener(PartitionLostListener listener) {
        if (listener == null) {
            throw new NullPointerException("listener can't be null");
        }

        final PartitionLostListenerAdapter adapter = new PartitionLostListenerAdapter(listener);

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration = eventService.registerListener(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC, adapter);
        return registration.getId();
    }

    @Override
    public boolean removePartitionLostListener(String registrationId) {
        if (registrationId == null) {
            throw new NullPointerException("registrationId can't be null");
        }

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC, registrationId);
    }

    @Override
    public void dispatchEvent(PartitionEvent partitionEvent, PartitionEventListener partitionEventListener) {
        partitionEventListener.onEvent(partitionEvent);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder("PartitionManager[" + stateVersion + "] {\n");
        sb.append("\n");
        sb.append("migrationQ: ").append(migrationQueue.size());
        sb.append("\n}");
        return sb.toString();
    }

    public Node getNode() {
        return node;
    }

    @Override
    public boolean isPartitionOwner(int partitionId) {
        InternalPartitionImpl partition = getPartition(partitionId);
        return node.getThisAddress().equals(partition.getOwnerOrNull());
    }

    @Override
    public int getPartitionStateVersion() {
        return stateVersion.get();
    }

    @Override
    public void onPartitionLost(InternalPartitionLostEvent event) {
        final PartitionLostEvent partitionLostEvent = new PartitionLostEvent(event.getPartitionId(), event.getLostReplicaIndex(),
                event.getEventSource());
        final EventService eventService = nodeEngine.getEventService();
        final Collection<EventRegistration> registrations = eventService
                .getRegistrations(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC);
        eventService.publishEvent(SERVICE_NAME, registrations, partitionLostEvent, event.getPartitionId());
    }

    
    public List<ReplicaSyncInfo> getOngoingReplicaSyncRequests() {
        final int length = replicaSyncRequests.length();
        final List<ReplicaSyncInfo> replicaSyncRequestsList = new ArrayList<ReplicaSyncInfo>(length);
        for (int i = 0; i < length; i++) {
            final ReplicaSyncInfo replicaSyncInfo = replicaSyncRequests.get(i);
            if (replicaSyncInfo != null) {
                replicaSyncRequestsList.add(replicaSyncInfo);
            }
        }

        return replicaSyncRequestsList;
    }

    
    public List<ScheduledEntry<Integer, ReplicaSyncInfo>> getScheduledReplicaSyncRequests() {
        final List<ScheduledEntry<Integer, ReplicaSyncInfo>> entries = new ArrayList<ScheduledEntry<Integer, ReplicaSyncInfo>>();
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            final ScheduledEntry<Integer, ReplicaSyncInfo> entry = replicaSyncScheduler.get(partitionId);
            if (entry != null) {
                entries.add(entry);
            }
        }

        return entries;
    }

    private class SendClusterStateTask implements Runnable {
        @Override
        public void run() {
            if (node.isMaster() && node.isActive()) {
                if (!migrationQueue.isEmpty() && isMigrationActive()) {
                    logger.info("Remaining migration tasks in queue => " + migrationQueue.size());
                }
                publishPartitionRuntimeState();
            }
        }
    }

    private class SyncReplicaVersionTask implements Runnable {
        @Override
        public void run() {
            if (node.isActive() && migrationActive.get()) {
                for (InternalPartitionImpl partition : partitions) {
                    if (partition.isLocal()) {
                        for (int index = 1; index < InternalPartition.MAX_REPLICA_COUNT; index++) {
                            if (partition.getReplicaAddress(index) != null) {
                                SyncReplicaVersion op = new SyncReplicaVersion(index, null);
                                op.setService(InternalPartitionServiceImpl.this);
                                op.setNodeEngine(nodeEngine);
                                op.setOperationResponseHandler(
                                        createErrorLoggingResponseHandler(node.getLogger(SyncReplicaVersion.class)));
                                op.setPartitionId(partition.getPartitionId());
                                nodeEngine.getOperationService().executeOperation(op);
                            }
                        }
                    }
                }
            }
        }
    }

    private class RepartitioningTask implements Runnable {
        @Override
        public void run() {
            if (node.isMaster() && node.isActive()) {
                lock.lock();
                try {
                    if (!initialized) {
                        return;
                    }
                    if (!isMigrationAllowed()) {
                        return;
                    }

                    migrationQueue.clear();
                    PartitionStateGenerator psg = partitionStateGenerator;
                    Collection<MemberImpl> members = node.getClusterService().getMemberList();
                    Collection<MemberGroup> memberGroups = memberGroupFactory.createMemberGroups(members);
                    Address[][] newState = psg.reArrange(memberGroups, partitions);

                    if (!isMigrationAllowed()) {
                        return;
                    }

                    int migrationCount = 0;
                    int lostCount = 0;
                    lastRepartitionTime.set(Clock.currentTimeMillis());
                    for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
                        Address[] replicas = newState[partitionId];
                        InternalPartitionImpl currentPartition = partitions[partitionId];
                        Address currentOwner = currentPartition.getOwnerOrNull();
                        Address newOwner = replicas[0];

                        if (currentOwner == null) {
                            
                            lostCount++;
                            assignNewPartitionOwner(partitionId, replicas, currentPartition, newOwner);
                        } else if (newOwner != null && !currentOwner.equals(newOwner)) {
                            if (logger.isFinestEnabled()) {
                                logger.finest("PartitionToMigrate partitionId=" + partitionId
                                        + " replicas=" + Arrays.toString(replicas) + " currentOwner="
                                        + currentOwner + " newOwner=" + newOwner);
                            }

                            migrationCount++;
                            migratePartitionToNewOwner(partitionId, replicas, currentOwner, newOwner);
                        } else {
                            currentPartition.setReplicaAddresses(replicas);
                        }
                    }
                    syncPartitionRuntimeState(members);
                    logMigrationStatistics(migrationCount, lostCount);
                } finally {
                    lock.unlock();
                }
            }
        }

        private void logMigrationStatistics(int migrationCount, int lostCount) {
            if (lostCount > 0) {
                logger.warning("Assigning new owners for " + lostCount + " LOST partitions!");
            }

            if (migrationCount > 0) {
                logger.info("Re-partitioning cluster data... Migration queue size: " + migrationCount);
            } else {
                logger.info("Partition balance is ok, no need to re-partition cluster data... ");
            }
        }

        private void migratePartitionToNewOwner(int partitionId, Address[] replicas, Address currentOwner, Address newOwner) {
            MigrationInfo info = new MigrationInfo(partitionId, currentOwner, newOwner);
            MigrateTask migrateTask = new MigrateTask(info, replicas);
            boolean offered = migrationQueue.offer(migrateTask);
            if (!offered) {
                logger.severe("Failed to offer: " + migrateTask);
            }
        }

        private void assignNewPartitionOwner(int partitionId, Address[] replicas, InternalPartitionImpl currentPartition,
                                             Address newOwner) {
            currentPartition.setReplicaAddresses(replicas);
            MigrationInfo migrationInfo = new MigrationInfo(partitionId, null, newOwner);
            sendMigrationEvent(migrationInfo, MigrationStatus.STARTED);
            sendMigrationEvent(migrationInfo, MigrationStatus.COMPLETED);
        }

        private boolean isMigrationAllowed() {
            if (isMigrationActive()) {
                return true;
            }
            migrationQueue.add(this);
            return false;
        }
    }

    private class MigrateTask implements Runnable {
        final MigrationInfo migrationInfo;
        final Address[] addresses;

        public MigrateTask(MigrationInfo migrationInfo, Address[] addresses) {
            this.migrationInfo = migrationInfo;
            this.addresses = addresses;
            final MemberImpl masterMember = getMasterMember();
            if (masterMember != null) {
                migrationInfo.setMasterUuid(masterMember.getUuid());
                migrationInfo.setMaster(masterMember.getAddress());
            }
        }

        @Override
        public void run() {
            if (!node.isActive() || !node.isMaster()) {
                return;
            }
            final MigrationRequestOperation migrationRequestOp = new MigrationRequestOperation(migrationInfo);
            try {
                MigrationInfo info = migrationInfo;
                InternalPartitionImpl partition = partitions[info.getPartitionId()];
                Address owner = partition.getOwnerOrNull();
                if (owner == null) {
                    logger.severe("ERROR: partition owner is not set! -> partitionId=" + info.getPartitionId()
                            + " , " + partition + " -VS- " + info);
                    return;
                }
                if (!owner.equals(info.getSource())) {
                    logger.severe("ERROR: partition owner is not the source of migration! -> partitionId="
                            + info.getPartitionId() + " , " + partition + " -VS- " + info + " found owner=" + owner);
                    return;
                }
                sendMigrationEvent(migrationInfo, MigrationStatus.STARTED);
                Boolean result;
                MemberImpl fromMember = getMember(migrationInfo.getSource());
                if (logger.isFinestEnabled()) {
                    logger.finest("Starting Migration: " + migrationInfo);
                }
                if (fromMember == null) {
                    
                    logger.warning("Partition is lost! Assign new owner and exit... partitionId=" + info.getPartitionId());
                    result = Boolean.TRUE;
                } else {
                    result = executeMigrateOperation(migrationRequestOp, fromMember);
                }
                processMigrationResult(result);
            } catch (Throwable t) {
                final Level level = migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Error [" + t.getClass() + ": " + t.getMessage() + "] while executing " + migrationRequestOp);
                logger.finest(t);
                migrationOperationFailed();
            }
        }

        private void processMigrationResult(Boolean result) {
            if (Boolean.TRUE.equals(result)) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Finished Migration: " + migrationInfo);
                }
                migrationOperationSucceeded();
            } else {
                final Level level = migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Migration failed: " + migrationInfo);
                migrationOperationFailed();
            }
        }

        private Boolean executeMigrateOperation(MigrationRequestOperation migrationRequestOp, MemberImpl fromMember) {
            Future future = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, migrationRequestOp,
                    migrationInfo.getSource())
                    .setCallTimeout(partitionMigrationTimeout)
                    .setTryPauseMillis(DEFAULT_PAUSE_MILLIS).invoke();

            try {
                Object response = future.get();
                return (Boolean) nodeEngine.toObject(response);
            } catch (Throwable e) {
                final Level level = node.isActive() && migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Failed migration from " + fromMember + " for " + migrationRequestOp.getMigrationInfo(), e);
            }
            return Boolean.FALSE;
        }

        private void migrationOperationFailed() {
            lock.lock();
            try {
                addCompletedMigration(migrationInfo);
                finalizeActiveMigration(migrationInfo);
                publishPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
            sendMigrationEvent(migrationInfo, MigrationStatus.FAILED);

            
            migrationQueue.add(new RepartitioningTask());
        }

        private void migrationOperationSucceeded() {
            lock.lock();
            try {
                final int partitionId = migrationInfo.getPartitionId();
                InternalPartitionImpl partition = partitions[partitionId];
                partition.setReplicaAddresses(addresses);
                addCompletedMigration(migrationInfo);
                finalizeActiveMigration(migrationInfo);
                syncPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
            sendMigrationEvent(migrationInfo, MigrationStatus.COMPLETED);
        }

        @Override
        public String toString() {
            return getClass().getSimpleName() + "{" + "migrationInfo=" + migrationInfo + '}';
        }
    }

    private class MigrationThread extends Thread implements Runnable {
        private final long sleepTime = Math.max(250L, partitionMigrationInterval);
        private volatile boolean migrating;

        MigrationThread(Node node) {
            super(node.getHazelcastThreadGroup().getInternalThreadGroup(),
                    node.getHazelcastThreadGroup().getThreadNamePrefix("migration"));
        }

        @Override
        public void run() {
            try {
                while (!isInterrupted()) {
                    doRun();
                }
            } catch (InterruptedException e) {
                if (logger.isFinestEnabled()) {
                    logger.finest("MigrationThread is interrupted: " + e.getMessage());
                }
            } catch (OutOfMemoryError e) {
                OutOfMemoryErrorDispatcher.onOutOfMemory(e);
            } finally {
                migrationQueue.clear();
            }
        }

        private void doRun() throws InterruptedException {
            for (; ; ) {
                if (!isMigrationActive()) {
                    break;
                }
                Runnable r = migrationQueue.poll(1, TimeUnit.SECONDS);
                if (r == null) {
                    break;
                }

                processTask(r);
                if (partitionMigrationInterval > 0) {
                    Thread.sleep(partitionMigrationInterval);
                }
            }
            boolean hasNoTasks = migrationQueue.isEmpty();
            if (hasNoTasks) {
                if (migrating) {
                    migrating = false;
                    logger.info("All migration tasks have been completed, queues are empty.");
                }
                evictCompletedMigrations();
                Thread.sleep(sleepTime);
            } else if (!isMigrationActive()) {
                Thread.sleep(sleepTime);
            }
        }

        boolean processTask(Runnable r) {
            if (r == null || isInterrupted()) {
                return false;
            }
            migrating = (r instanceof MigrateTask);
            try {
                r.run();
            } catch (Throwable t) {
                logger.warning(t);
            }
            return true;
        }

        void stopNow() {
            migrationQueue.clear();
            interrupt();
        }

        boolean isMigrating() {
            return migrating;
        }
    }

    private static final class LocalPartitionListener implements PartitionListener {
        final Address thisAddress;
        final InternalPartitionServiceImpl partitionService;

        private LocalPartitionListener(InternalPartitionServiceImpl partitionService, Address thisAddress) {
            this.thisAddress = thisAddress;
            this.partitionService = partitionService;
        }

        @Override
        public void replicaChanged(PartitionReplicaChangeEvent event) {
            final int partitionId = event.getPartitionId();
            final int replicaIndex = event.getReplicaIndex();
            final Address newAddress = event.getNewAddress();
            final Address oldAddress = event.getOldAddress();
            final PartitionReplicaChangeReason reason = event.getReason();

            final boolean initialAssignment = event.getOldAddress() == null;

            if (replicaIndex > 0) {
                
                if (thisAddress.equals(oldAddress)) {
                    clearPartition(partitionId, replicaIndex);
                } else if (thisAddress.equals(newAddress)) {
                    synchronizePartition(partitionId, replicaIndex, reason, initialAssignment);
                }
            } else {
                if (!initialAssignment && thisAddress.equals(newAddress)) {
                    
                    
                    
                    promoteFromBackups(partitionId, reason, oldAddress);
                }
                partitionService.cancelReplicaSync(partitionId);
            }

            Node node = partitionService.node;
            if (replicaIndex == 0 && newAddress == null && node.isActive() && node.joined()) {
                logOwnerOfPartitionIsRemoved(event);
            }
            if (node.isMaster()) {
                partitionService.stateVersion.incrementAndGet();
            }
        }

        private void clearPartition(final int partitionId, final int oldReplicaIndex) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            ClearReplicaOperation op = new ClearReplicaOperation(oldReplicaIndex);
            op.setPartitionId(partitionId).setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void synchronizePartition(int partitionId, int replicaIndex,
                                          PartitionReplicaChangeReason reason, boolean initialAssignment) {
            
            if (partitionService.initialized) {
                long delayMillis = 0L;
                if (replicaIndex > 1) {
                    
                    
                    
                    delayMillis = (long) (REPLICA_SYNC_RETRY_DELAY + (Math.random() * DEFAULT_REPLICA_SYNC_DELAY));
                }

                resetReplicaVersion(partitionId, replicaIndex, reason, initialAssignment);
                partitionService.triggerPartitionReplicaSync(partitionId, replicaIndex, delayMillis);
            }
        }

        private void resetReplicaVersion(int partitionId, int replicaIndex,
                                         PartitionReplicaChangeReason reason, boolean initialAssignment) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            ResetReplicaVersionOperation op = new ResetReplicaVersionOperation(reason, initialAssignment);
            op.setPartitionId(partitionId).setReplicaIndex(replicaIndex)
                    .setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void promoteFromBackups(int partitionId, PartitionReplicaChangeReason reason, Address oldAddress) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            PromoteFromBackupOperation op = new PromoteFromBackupOperation(reason, oldAddress);
            op.setPartitionId(partitionId).setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void logOwnerOfPartitionIsRemoved(PartitionReplicaChangeEvent event) {
            String warning = "Owner of partition is being removed! "
                    + "Possible data loss for partitionId=" + event.getPartitionId() + " , " + event;
            partitionService.logger.warning(warning);
        }
    }

    private static class ReplicaSyncEntryProcessor implements ScheduledEntryProcessor<Integer, ReplicaSyncInfo> {

        final InternalPartitionServiceImpl partitionService;

        ReplicaSyncEntryProcessor(InternalPartitionServiceImpl partitionService) {
            this.partitionService = partitionService;
        }

        @Override
        public void process(EntryTaskScheduler<Integer, ReplicaSyncInfo> scheduler,
                            Collection<ScheduledEntry<Integer, ReplicaSyncInfo>> entries) {

            for (ScheduledEntry<Integer, ReplicaSyncInfo> entry : entries) {
                ReplicaSyncInfo syncInfo = entry.getValue();
                int partitionId = syncInfo.partitionId;
                if (partitionService.replicaSyncRequests.compareAndSet(partitionId, syncInfo, null)) {
                    partitionService.releaseReplicaSyncPermit();
                }

                InternalPartitionImpl partition = partitionService.getPartitionImpl(partitionId);
                int currentReplicaIndex = partition.getReplicaIndex(partitionService.node.getThisAddress());
                if (currentReplicaIndex > 0) {
                    partitionService.triggerPartitionReplicaSync(partitionId, currentReplicaIndex, 0L);
                }
            }
        }
    }
}

<code block>


package com.hazelcast.instance;

import com.hazelcast.config.Config;
import com.hazelcast.core.IMap;
import com.hazelcast.internal.monitors.HealthMonitorLevel;
import com.hazelcast.map.QueryResultSizeExceededException;
import com.hazelcast.map.impl.QueryResultSizeLimiter;
import com.hazelcast.query.TruePredicate;


public class GroupProperties {

    
    public static final String PROP_APPLICATION_VALIDATION_TOKEN = "hazelcast.application.validation.token";

    public static final String PROP_HEALTH_MONITORING_LEVEL = "hazelcast.health.monitoring.level";
    public static final String PROP_HEALTH_MONITORING_DELAY_SECONDS = "hazelcast.health.monitoring.delay.seconds";

    
    public static final String PROP_PERFORMANCE_MONITORING_ENABLED = "hazelcast.performance.monitoring.enabled";
    
    public static final String PROP_PERFORMANCE_MONITORING_DELAY_SECONDS = "hazelcast.performance.monitoring.delay.seconds";

    public static final String PROP_VERSION_CHECK_ENABLED = "hazelcast.version.check.enabled";
    public static final String PROP_PREFER_IPv4_STACK = "hazelcast.prefer.ipv4.stack";
    public static final String PROP_IO_THREAD_COUNT = "hazelcast.io.thread.count";

    
    public static final String PROP_IO_BALANCER_INTERVAL_SECONDS = "hazelcast.io.balancer.interval.seconds";
    
    public static final String PROP_PARTITION_OPERATION_THREAD_COUNT = "hazelcast.operation.thread.count";
    public static final String PROP_GENERIC_OPERATION_THREAD_COUNT = "hazelcast.operation.generic.thread.count";
    public static final String PROP_EVENT_THREAD_COUNT = "hazelcast.event.thread.count";
    public static final String PROP_EVENT_QUEUE_CAPACITY = "hazelcast.event.queue.capacity";
    public static final String PROP_EVENT_QUEUE_TIMEOUT_MILLIS = "hazelcast.event.queue.timeout.millis";
    public static final String PROP_CONNECT_ALL_WAIT_SECONDS = "hazelcast.connect.all.wait.seconds";
    public static final String PROP_MEMCACHE_ENABLED = "hazelcast.memcache.enabled";
    public static final String PROP_REST_ENABLED = "hazelcast.rest.enabled";
    public static final String PROP_MAP_LOAD_CHUNK_SIZE = "hazelcast.map.load.chunk.size";
    public static final String PROP_MERGE_FIRST_RUN_DELAY_SECONDS = "hazelcast.merge.first.run.delay.seconds";
    public static final String PROP_MERGE_NEXT_RUN_DELAY_SECONDS = "hazelcast.merge.next.run.delay.seconds";
    public static final String PROP_OPERATION_CALL_TIMEOUT_MILLIS = "hazelcast.operation.call.timeout.millis";

    
    public static final String PROP_OPERATION_BACKUP_TIMEOUT_MILLIS = "hazelcast.operation.backup.timeout.millis";

    public static final String PROP_SOCKET_BIND_ANY = "hazelcast.socket.bind.any";
    public static final String PROP_SOCKET_SERVER_BIND_ANY = "hazelcast.socket.server.bind.any";
    public static final String PROP_SOCKET_CLIENT_BIND_ANY = "hazelcast.socket.client.bind.any";
    public static final String PROP_SOCKET_CLIENT_BIND = "hazelcast.socket.client.bind";
    
    public static final String PROP_CLIENT_ENGINE_THREAD_COUNT = "hazelcast.clientengine.thread.count";
    public static final String PROP_SOCKET_RECEIVE_BUFFER_SIZE = "hazelcast.socket.receive.buffer.size";
    public static final String PROP_SOCKET_SEND_BUFFER_SIZE = "hazelcast.socket.send.buffer.size";
    public static final String PROP_SOCKET_LINGER_SECONDS = "hazelcast.socket.linger.seconds";
    public static final String PROP_SOCKET_CONNECT_TIMEOUT_SECONDS = "hazelcast.socket.connect.timeout.seconds";
    public static final String PROP_SOCKET_KEEP_ALIVE = "hazelcast.socket.keep.alive";
    public static final String PROP_SOCKET_NO_DELAY = "hazelcast.socket.no.delay";
    public static final String PROP_SHUTDOWNHOOK_ENABLED = "hazelcast.shutdownhook.enabled";
    public static final String PROP_WAIT_SECONDS_BEFORE_JOIN = "hazelcast.wait.seconds.before.join";
    public static final String PROP_MAX_WAIT_SECONDS_BEFORE_JOIN = "hazelcast.max.wait.seconds.before.join";
    public static final String PROP_MAX_JOIN_SECONDS = "hazelcast.max.join.seconds";
    public static final String PROP_MAX_JOIN_MERGE_TARGET_SECONDS = "hazelcast.max.join.merge.target.seconds";
    public static final String PROP_HEARTBEAT_INTERVAL_SECONDS = "hazelcast.heartbeat.interval.seconds";
    public static final String PROP_MAX_NO_HEARTBEAT_SECONDS = "hazelcast.max.no.heartbeat.seconds";
    public static final String PROP_MAX_NO_MASTER_CONFIRMATION_SECONDS = "hazelcast.max.no.master.confirmation.seconds";
    public static final String PROP_MASTER_CONFIRMATION_INTERVAL_SECONDS
            = "hazelcast.master.confirmation.interval.seconds";
    public static final String PROP_MEMBER_LIST_PUBLISH_INTERVAL_SECONDS
            = "hazelcast.member.list.publish.interval.seconds";
    public static final String PROP_ICMP_ENABLED = "hazelcast.icmp.enabled";
    public static final String PROP_ICMP_TIMEOUT = "hazelcast.icmp.timeout";
    public static final String PROP_ICMP_TTL = "hazelcast.icmp.ttl";
    public static final String PROP_INITIAL_MIN_CLUSTER_SIZE = "hazelcast.initial.min.cluster.size";
    public static final String PROP_INITIAL_WAIT_SECONDS = "hazelcast.initial.wait.seconds";

    
    public static final String PROP_TCP_JOIN_PORT_TRY_COUNT = "hazelcast.tcp.join.port.try.count";
    public static final String PROP_MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS
            = "hazelcast.map.replica.scheduled.task.delay.seconds";
    
    public static final String PROP_MAP_EXPIRY_DELAY_SECONDS = "hazelcast.map.expiry.delay.seconds";
    public static final String PROP_PARTITION_COUNT = "hazelcast.partition.count";
    public static final String PROP_LOGGING_TYPE = "hazelcast.logging.type";
    public static final String PROP_ENABLE_JMX = "hazelcast.jmx";
    public static final String PROP_ENABLE_JMX_DETAILED = "hazelcast.jmx.detailed";
    public static final String PROP_MC_MAX_VISIBLE_INSTANCE_COUNT = "hazelcast.mc.max.visible.instance.count";
    public static final String PROP_MC_MAX_VISIBLE_SLOW_OPERATION_COUNT = "hazelcast.mc.max.visible.slow.operations.count";
    public static final String PROP_MC_URL_CHANGE_ENABLED = "hazelcast.mc.url.change.enabled";
    public static final String PROP_CONNECTION_MONITOR_INTERVAL = "hazelcast.connection.monitor.interval";
    public static final String PROP_CONNECTION_MONITOR_MAX_FAULTS = "hazelcast.connection.monitor.max.faults";
    public static final String PROP_PARTITION_MIGRATION_INTERVAL = "hazelcast.partition.migration.interval";
    public static final String PROP_PARTITION_MIGRATION_TIMEOUT = "hazelcast.partition.migration.timeout";
    public static final String PROP_PARTITION_MIGRATION_ZIP_ENABLED = "hazelcast.partition.migration.zip.enabled";
    public static final String PROP_PARTITION_TABLE_SEND_INTERVAL = "hazelcast.partition.table.send.interval";
    public static final String PROP_PARTITION_BACKUP_SYNC_INTERVAL = "hazelcast.partition.backup.sync.interval";
    public static final String PROP_PARTITION_MAX_PARALLEL_REPLICATIONS
            = "hazelcast.partition.max.parallel.replications";
    public static final String PROP_PARTITIONING_STRATEGY_CLASS = "hazelcast.partitioning.strategy.class";
    public static final String PROP_GRACEFUL_SHUTDOWN_MAX_WAIT = "hazelcast.graceful.shutdown.max.wait";
    public static final String PROP_SYSTEM_LOG_ENABLED = "hazelcast.system.log.enabled";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_ENABLED = "hazelcast.slow.operation.detector.enabled";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS
            = "hazelcast.slow.operation.detector.threshold.millis";


    
    public static final String PROP_SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS
            = "hazelcast.slow.invocation.detector.threshold.millis";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS
            = "hazelcast.slow.operation.detector.log.retention.seconds";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS
            = "hazelcast.slow.operation.detector.log.purge.interval.seconds";

    
    public static final String PROP_SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED
            = "hazelcast.slow.operation.detector.stacktrace.logging.enabled";

    
    public static final String PROP_ELASTIC_MEMORY_ENABLED = "hazelcast.elastic.memory.enabled";
    public static final String PROP_ELASTIC_MEMORY_TOTAL_SIZE = "hazelcast.elastic.memory.total.size";
    public static final String PROP_ELASTIC_MEMORY_CHUNK_SIZE = "hazelcast.elastic.memory.chunk.size";
    public static final String PROP_ELASTIC_MEMORY_SHARED_STORAGE = "hazelcast.elastic.memory.shared.storage";
    public static final String PROP_ELASTIC_MEMORY_UNSAFE_ENABLED = "hazelcast.elastic.memory.unsafe.enabled";
    public static final String PROP_ENTERPRISE_LICENSE_KEY = "hazelcast.enterprise.license.key";
    public static final String PROP_MAP_WRITE_BEHIND_QUEUE_CAPACITY = "hazelcast.map.write.behind.queue.capacity";

    
    public static final String PROP_ENTERPRISE_WAN_REP_QUEUE_CAPACITY = "hazelcast.enterprise.wanrep.queue.capacity";

    
    public static final String PROP_ENTERPRISE_WAN_REP_BATCH_SIZE = "hazelcast.enterprise.wanrep.batch.size";

    
    public static final String PROP_ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS
            = "hazelcast.enterprise.wanrep.batchfrequency.seconds";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED
            = "hazelcast.cache.invalidation.batch.enabled";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_SIZE
            = "hazelcast.cache.invalidation.batch.size";

    
    public static final String PROP_CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS
            = "hazelcast.cache.invalidation.batchfrequency.seconds";

    
    public static final String PROP_ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS
            = "hazelcast.enterprise.wanrep.optimeout.millis";

    public static final String PROP_CLIENT_MAX_NO_HEARTBEAT_SECONDS = "hazelcast.client.max.no.heartbeat.seconds";
    public static final String PROP_MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS
            = "hazelcast.migration.min.delay.on.member.removed.seconds";

    
    public static final String PROP_BACKPRESSURE_ENABLED = "hazelcast.backpressure.enabled";

    
    public static final String PROP_BACKPRESSURE_SYNCWINDOW = "hazelcast.backpressure.syncwindow";

    
    public static final String PROP_BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS
            = "hazelcast.backpressure.backoff.timeout.millis";

    
    public static final String PROP_BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION
            = "hazelcast.backpressure.max.concurrent.invocations.per.partition";


    
    public static final String PROP_QUERY_PREDICATE_PARALLEL_EVALUATION = "hazelcast.query.predicate.parallel.evaluation";


    
    public static final String PROP_JCACHE_PROVIDER_TYPE = "hazelcast.jcache.provider.type";

    
    public static final String PROP_QUERY_RESULT_SIZE_LIMIT = "hazelcast.query.result.size.limit";

    
    public static final String PROP_QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK
            = "hazelcast.query.max.local.partition.limit.for.precheck";

    public final GroupProperty CLIENT_ENGINE_THREAD_COUNT;

    public final GroupProperty PARTITION_OPERATION_THREAD_COUNT;

    public final GroupProperty GENERIC_OPERATION_THREAD_COUNT;

    public final GroupProperty EVENT_THREAD_COUNT;

    public final GroupProperty HEALTH_MONITORING_LEVEL;

    public final GroupProperty HEALTH_MONITORING_DELAY_SECONDS;

    public final GroupProperty PERFORMANCE_MONITORING_ENABLED;

    public final GroupProperty PERFORMANCE_MONITORING_DELAY_SECONDS;

    public final GroupProperty IO_THREAD_COUNT;

    public final GroupProperty IO_BALANCER_INTERVAL_SECONDS;

    public final GroupProperty EVENT_QUEUE_CAPACITY;

    public final GroupProperty EVENT_QUEUE_TIMEOUT_MILLIS;

    public final GroupProperty PREFER_IPv4_STACK;

    public final GroupProperty CONNECT_ALL_WAIT_SECONDS;

    public final GroupProperty VERSION_CHECK_ENABLED;

    public final GroupProperty MEMCACHE_ENABLED;

    public final GroupProperty REST_ENABLED;

    public final GroupProperty MAP_LOAD_CHUNK_SIZE;

    public final GroupProperty MERGE_FIRST_RUN_DELAY_SECONDS;

    public final GroupProperty MERGE_NEXT_RUN_DELAY_SECONDS;

    public final GroupProperty OPERATION_CALL_TIMEOUT_MILLIS;

    public final GroupProperty OPERATION_BACKUP_TIMEOUT_MILLIS;

    public final GroupProperty SOCKET_SERVER_BIND_ANY;

    public final GroupProperty SOCKET_CLIENT_BIND_ANY;

    public final GroupProperty SOCKET_CLIENT_BIND;

    
    public final GroupProperty SOCKET_RECEIVE_BUFFER_SIZE;

    
    public final GroupProperty SOCKET_SEND_BUFFER_SIZE;

    public final GroupProperty SOCKET_LINGER_SECONDS;

    public final GroupProperty SOCKET_CONNECT_TIMEOUT_SECONDS;

    public final GroupProperty SOCKET_KEEP_ALIVE;

    public final GroupProperty SOCKET_NO_DELAY;

    public final GroupProperty SHUTDOWNHOOK_ENABLED;

    public final GroupProperty WAIT_SECONDS_BEFORE_JOIN;

    public final GroupProperty MAX_WAIT_SECONDS_BEFORE_JOIN;

    public final GroupProperty MAX_JOIN_SECONDS;

    public final GroupProperty MAX_JOIN_MERGE_TARGET_SECONDS;

    public final GroupProperty MAX_NO_HEARTBEAT_SECONDS;

    public final GroupProperty HEARTBEAT_INTERVAL_SECONDS;

    public final GroupProperty MASTER_CONFIRMATION_INTERVAL_SECONDS;

    public final GroupProperty MAX_NO_MASTER_CONFIRMATION_SECONDS;

    public final GroupProperty MEMBER_LIST_PUBLISH_INTERVAL_SECONDS;

    public final GroupProperty ICMP_ENABLED;

    public final GroupProperty ICMP_TIMEOUT;

    public final GroupProperty ICMP_TTL;

    public final GroupProperty INITIAL_WAIT_SECONDS;

    public final GroupProperty INITIAL_MIN_CLUSTER_SIZE;

    public final GroupProperty TCP_JOIN_PORT_TRY_COUNT;

    public final GroupProperty MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS;

    public final GroupProperty MAP_EXPIRY_DELAY_SECONDS;

    public final GroupProperty PARTITION_COUNT;

    public final GroupProperty LOGGING_TYPE;

    public final GroupProperty ENABLE_JMX;

    public final GroupProperty ENABLE_JMX_DETAILED;

    public final GroupProperty MC_MAX_INSTANCE_COUNT;

    public final GroupProperty MC_MAX_SLOW_OPERATION_COUNT;

    public final GroupProperty MC_URL_CHANGE_ENABLED;

    public final GroupProperty CONNECTION_MONITOR_INTERVAL;

    public final GroupProperty CONNECTION_MONITOR_MAX_FAULTS;

    public final GroupProperty PARTITION_MIGRATION_INTERVAL;

    public final GroupProperty PARTITION_MIGRATION_TIMEOUT;

    public final GroupProperty PARTITION_MIGRATION_ZIP_ENABLED;

    public final GroupProperty PARTITION_TABLE_SEND_INTERVAL;

    public final GroupProperty PARTITION_BACKUP_SYNC_INTERVAL;

    public final GroupProperty PARTITION_MAX_PARALLEL_REPLICATIONS;

    public final GroupProperty PARTITIONING_STRATEGY_CLASS;

    public final GroupProperty GRACEFUL_SHUTDOWN_MAX_WAIT;

    public final GroupProperty SYSTEM_LOG_ENABLED;

    public final GroupProperty SLOW_OPERATION_DETECTOR_ENABLED;
    public final GroupProperty SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS;
    public final GroupProperty SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED;

    public final GroupProperty SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS;

    public final GroupProperty ELASTIC_MEMORY_ENABLED;

    public final GroupProperty ELASTIC_MEMORY_TOTAL_SIZE;

    public final GroupProperty ELASTIC_MEMORY_CHUNK_SIZE;

    public final GroupProperty ELASTIC_MEMORY_SHARED_STORAGE;

    public final GroupProperty ELASTIC_MEMORY_UNSAFE_ENABLED;

    public final GroupProperty ENTERPRISE_LICENSE_KEY;

    
    public final GroupProperty MAP_WRITE_BEHIND_QUEUE_CAPACITY;

    public final GroupProperty ENTERPRISE_WAN_REP_QUEUE_CAPACITY;
    public final GroupProperty ENTERPRISE_WAN_REP_BATCH_SIZE;
    public final GroupProperty ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS;
    public final GroupProperty ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS;

    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED;
    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_SIZE;
    public final GroupProperty CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS;

    public final GroupProperty CLIENT_HEARTBEAT_TIMEOUT_SECONDS;

    public final GroupProperty MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS;

    public final GroupProperty BACKPRESSURE_ENABLED;
    public final GroupProperty BACKPRESSURE_SYNCWINDOW;
    public final GroupProperty BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS;
    public final GroupProperty BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION;

    public final GroupProperty QUERY_RESULT_SIZE_LIMIT;
    public final GroupProperty QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK;

    public final GroupProperty QUERY_PREDICATE_PARALLEL_EVALUATION;

    public GroupProperties(Config config) {
        HEALTH_MONITORING_LEVEL
                = new GroupProperty(config, PROP_HEALTH_MONITORING_LEVEL, HealthMonitorLevel.SILENT.toString());
        HEALTH_MONITORING_DELAY_SECONDS = new GroupProperty(config, PROP_HEALTH_MONITORING_DELAY_SECONDS, "30");

        PERFORMANCE_MONITORING_ENABLED
                = new GroupProperty(config, PROP_PERFORMANCE_MONITORING_ENABLED, "false");
        PERFORMANCE_MONITORING_DELAY_SECONDS = new GroupProperty(config, PROP_PERFORMANCE_MONITORING_DELAY_SECONDS, "30");

        VERSION_CHECK_ENABLED = new GroupProperty(config, PROP_VERSION_CHECK_ENABLED, "true");
        PREFER_IPv4_STACK = new GroupProperty(config, PROP_PREFER_IPv4_STACK, "true");
        IO_THREAD_COUNT = new GroupProperty(config, PROP_IO_THREAD_COUNT, "3");
        IO_BALANCER_INTERVAL_SECONDS = new GroupProperty(config, PROP_IO_BALANCER_INTERVAL_SECONDS, "20");

        
        PARTITION_OPERATION_THREAD_COUNT = new GroupProperty(config, PROP_PARTITION_OPERATION_THREAD_COUNT, "-1");
        GENERIC_OPERATION_THREAD_COUNT = new GroupProperty(config, PROP_GENERIC_OPERATION_THREAD_COUNT, "-1");
        EVENT_THREAD_COUNT = new GroupProperty(config, PROP_EVENT_THREAD_COUNT, "5");
        EVENT_QUEUE_CAPACITY = new GroupProperty(config, PROP_EVENT_QUEUE_CAPACITY, "1000000");
        EVENT_QUEUE_TIMEOUT_MILLIS = new GroupProperty(config, PROP_EVENT_QUEUE_TIMEOUT_MILLIS, "250");
        CLIENT_ENGINE_THREAD_COUNT = new GroupProperty(config, PROP_CLIENT_ENGINE_THREAD_COUNT, "-1");

        CONNECT_ALL_WAIT_SECONDS = new GroupProperty(config, PROP_CONNECT_ALL_WAIT_SECONDS, "120");
        MEMCACHE_ENABLED = new GroupProperty(config, PROP_MEMCACHE_ENABLED, "true");
        REST_ENABLED = new GroupProperty(config, PROP_REST_ENABLED, "true");
        MAP_LOAD_CHUNK_SIZE = new GroupProperty(config, PROP_MAP_LOAD_CHUNK_SIZE, "1000");
        MERGE_FIRST_RUN_DELAY_SECONDS = new GroupProperty(config, PROP_MERGE_FIRST_RUN_DELAY_SECONDS, "300");
        MERGE_NEXT_RUN_DELAY_SECONDS = new GroupProperty(config, PROP_MERGE_NEXT_RUN_DELAY_SECONDS, "120");
        OPERATION_CALL_TIMEOUT_MILLIS = new GroupProperty(config, PROP_OPERATION_CALL_TIMEOUT_MILLIS, "60000");
        OPERATION_BACKUP_TIMEOUT_MILLIS = new GroupProperty(config, PROP_OPERATION_BACKUP_TIMEOUT_MILLIS, "5000");

        final GroupProperty SOCKET_BIND_ANY = new GroupProperty(config, PROP_SOCKET_BIND_ANY, "true");
        SOCKET_SERVER_BIND_ANY = new GroupProperty(config, PROP_SOCKET_SERVER_BIND_ANY, SOCKET_BIND_ANY);
        SOCKET_CLIENT_BIND_ANY = new GroupProperty(config, PROP_SOCKET_CLIENT_BIND_ANY, SOCKET_BIND_ANY);
        SOCKET_CLIENT_BIND = new GroupProperty(config, PROP_SOCKET_CLIENT_BIND, "true");
        SOCKET_RECEIVE_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_RECEIVE_BUFFER_SIZE, "32");
        SOCKET_SEND_BUFFER_SIZE = new GroupProperty(config, PROP_SOCKET_SEND_BUFFER_SIZE, "32");
        SOCKET_LINGER_SECONDS = new GroupProperty(config, PROP_SOCKET_LINGER_SECONDS, "0");
        SOCKET_CONNECT_TIMEOUT_SECONDS = new GroupProperty(config, PROP_SOCKET_CONNECT_TIMEOUT_SECONDS, "0");
        SOCKET_KEEP_ALIVE = new GroupProperty(config, PROP_SOCKET_KEEP_ALIVE, "true");
        SOCKET_NO_DELAY = new GroupProperty(config, PROP_SOCKET_NO_DELAY, "true");
        SHUTDOWNHOOK_ENABLED = new GroupProperty(config, PROP_SHUTDOWNHOOK_ENABLED, "true");
        WAIT_SECONDS_BEFORE_JOIN = new GroupProperty(config, PROP_WAIT_SECONDS_BEFORE_JOIN, "5");
        MAX_WAIT_SECONDS_BEFORE_JOIN = new GroupProperty(config, PROP_MAX_WAIT_SECONDS_BEFORE_JOIN, "20");
        MAX_JOIN_SECONDS = new GroupProperty(config, PROP_MAX_JOIN_SECONDS, "300");
        MAX_JOIN_MERGE_TARGET_SECONDS = new GroupProperty(config, PROP_MAX_JOIN_MERGE_TARGET_SECONDS, "20");
        HEARTBEAT_INTERVAL_SECONDS = new GroupProperty(config, PROP_HEARTBEAT_INTERVAL_SECONDS, "1");
        MAX_NO_HEARTBEAT_SECONDS = new GroupProperty(config, PROP_MAX_NO_HEARTBEAT_SECONDS, "300");
        MASTER_CONFIRMATION_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_MASTER_CONFIRMATION_INTERVAL_SECONDS, "30");
        MAX_NO_MASTER_CONFIRMATION_SECONDS = new GroupProperty(config, PROP_MAX_NO_MASTER_CONFIRMATION_SECONDS, "500");
        MEMBER_LIST_PUBLISH_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_MEMBER_LIST_PUBLISH_INTERVAL_SECONDS, "300");
        ICMP_ENABLED = new GroupProperty(config, PROP_ICMP_ENABLED, "false");
        ICMP_TIMEOUT = new GroupProperty(config, PROP_ICMP_TIMEOUT, "1000");
        ICMP_TTL = new GroupProperty(config, PROP_ICMP_TTL, "0");
        INITIAL_MIN_CLUSTER_SIZE = new GroupProperty(config, PROP_INITIAL_MIN_CLUSTER_SIZE, "0");
        INITIAL_WAIT_SECONDS = new GroupProperty(config, PROP_INITIAL_WAIT_SECONDS, "0");
        TCP_JOIN_PORT_TRY_COUNT = new GroupProperty(config, PROP_TCP_JOIN_PORT_TRY_COUNT, "3");
        MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS
                = new GroupProperty(config, PROP_MAP_REPLICA_SCHEDULED_TASK_DELAY_SECONDS, "10");
        MAP_EXPIRY_DELAY_SECONDS = new GroupProperty(config, PROP_MAP_EXPIRY_DELAY_SECONDS, "10");
        PARTITION_COUNT = new GroupProperty(config, PROP_PARTITION_COUNT, "271");
        LOGGING_TYPE = new GroupProperty(config, PROP_LOGGING_TYPE, "jdk");
        ENABLE_JMX = new GroupProperty(config, PROP_ENABLE_JMX, "false");
        ENABLE_JMX_DETAILED = new GroupProperty(config, PROP_ENABLE_JMX_DETAILED, "false");
        MC_MAX_INSTANCE_COUNT = new GroupProperty(config, PROP_MC_MAX_VISIBLE_INSTANCE_COUNT, "100");
        MC_MAX_SLOW_OPERATION_COUNT = new GroupProperty(config, PROP_MC_MAX_VISIBLE_SLOW_OPERATION_COUNT, "10");
        MC_URL_CHANGE_ENABLED = new GroupProperty(config, PROP_MC_URL_CHANGE_ENABLED, "true");
        CONNECTION_MONITOR_INTERVAL = new GroupProperty(config, PROP_CONNECTION_MONITOR_INTERVAL, "100");
        CONNECTION_MONITOR_MAX_FAULTS = new GroupProperty(config, PROP_CONNECTION_MONITOR_MAX_FAULTS, "3");
        PARTITION_MIGRATION_INTERVAL = new GroupProperty(config, PROP_PARTITION_MIGRATION_INTERVAL, "0");
        PARTITION_MIGRATION_TIMEOUT = new GroupProperty(config, PROP_PARTITION_MIGRATION_TIMEOUT, "300");
        PARTITION_MIGRATION_ZIP_ENABLED = new GroupProperty(config, PROP_PARTITION_MIGRATION_ZIP_ENABLED, "true");
        PARTITION_TABLE_SEND_INTERVAL = new GroupProperty(config, PROP_PARTITION_TABLE_SEND_INTERVAL, "15");
        PARTITION_BACKUP_SYNC_INTERVAL = new GroupProperty(config, PROP_PARTITION_BACKUP_SYNC_INTERVAL, "30");
        PARTITION_MAX_PARALLEL_REPLICATIONS = new GroupProperty(config, PROP_PARTITION_MAX_PARALLEL_REPLICATIONS, "5");
        PARTITIONING_STRATEGY_CLASS = new GroupProperty(config, PROP_PARTITIONING_STRATEGY_CLASS, "");
        GRACEFUL_SHUTDOWN_MAX_WAIT = new GroupProperty(config, PROP_GRACEFUL_SHUTDOWN_MAX_WAIT, "600");
        SYSTEM_LOG_ENABLED = new GroupProperty(config, PROP_SYSTEM_LOG_ENABLED, "true");

        SLOW_OPERATION_DETECTOR_ENABLED
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_ENABLED, "true");
        SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_THRESHOLD_MILLIS, "10000");
        SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_LOG_RETENTION_SECONDS, "3600");
        SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_LOG_PURGE_INTERVAL_SECONDS, "300");
        SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED
                = new GroupProperty(config, PROP_SLOW_OPERATION_DETECTOR_STACK_TRACE_LOGGING_ENABLED, "false");
        SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS
                = new GroupProperty(config, PROP_SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS, "-1");

        ELASTIC_MEMORY_ENABLED = new GroupProperty(config, PROP_ELASTIC_MEMORY_ENABLED, "false");
        ELASTIC_MEMORY_TOTAL_SIZE = new GroupProperty(config, PROP_ELASTIC_MEMORY_TOTAL_SIZE, "128M");
        ELASTIC_MEMORY_CHUNK_SIZE = new GroupProperty(config, PROP_ELASTIC_MEMORY_CHUNK_SIZE, "1K");
        ELASTIC_MEMORY_SHARED_STORAGE = new GroupProperty(config, PROP_ELASTIC_MEMORY_SHARED_STORAGE, "false");
        ELASTIC_MEMORY_UNSAFE_ENABLED = new GroupProperty(config, PROP_ELASTIC_MEMORY_UNSAFE_ENABLED, "false");
        ENTERPRISE_LICENSE_KEY = new GroupProperty(config, PROP_ENTERPRISE_LICENSE_KEY);
        MAP_WRITE_BEHIND_QUEUE_CAPACITY
                = new GroupProperty(config, PROP_MAP_WRITE_BEHIND_QUEUE_CAPACITY, "50000");

        ENTERPRISE_WAN_REP_QUEUE_CAPACITY = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_QUEUE_CAPACITY, "100000");
        ENTERPRISE_WAN_REP_BATCH_SIZE = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_BATCH_SIZE, "50");
        ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS
                = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_BATCH_FREQUENCY_SECONDS, "5");
        ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS = new GroupProperty(config, PROP_ENTERPRISE_WAN_REP_OP_TIMEOUT_MILLIS, "60000");

        CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_ENABLED, "true");
        CACHE_INVALIDATION_MESSAGE_BATCH_SIZE
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_SIZE, "100");
        CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS
                = new GroupProperty(config, PROP_CACHE_INVALIDATION_MESSAGE_BATCH_FREQUENCY_SECONDS, "10");

        CLIENT_HEARTBEAT_TIMEOUT_SECONDS = new GroupProperty(config, PROP_CLIENT_MAX_NO_HEARTBEAT_SECONDS, "300");
        MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS
                = new GroupProperty(config, PROP_MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS, "5");
        BACKPRESSURE_ENABLED
                = new GroupProperty(config, PROP_BACKPRESSURE_ENABLED, "false");
        BACKPRESSURE_SYNCWINDOW
                = new GroupProperty(config, PROP_BACKPRESSURE_SYNCWINDOW, "100");
        BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION
                = new GroupProperty(config, PROP_BACKPRESSURE_MAX_CONCURRENT_INVOCATIONS_PER_PARTITION, "100");
        BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS
                = new GroupProperty(config, PROP_BACKPRESSURE_BACKOFF_TIMEOUT_MILLIS, "60000");

        QUERY_RESULT_SIZE_LIMIT = new GroupProperty(config, PROP_QUERY_RESULT_SIZE_LIMIT, "-1");
        QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK
                = new GroupProperty(config, PROP_QUERY_MAX_LOCAL_PARTITION_LIMIT_FOR_PRE_CHECK, "3");

        QUERY_PREDICATE_PARALLEL_EVALUATION
                = new GroupProperty(config, PROP_QUERY_PREDICATE_PARALLEL_EVALUATION, "false");
    }

    public static class GroupProperty {

        private final String name;
        private final String value;

        GroupProperty(Config config, String name) {
            this(config, name, (String) null);
        }

        GroupProperty(Config config, String name, GroupProperty defaultValue) {
            this(config, name, defaultValue != null ? defaultValue.getString() : null);
        }

        GroupProperty(Config config, String name, String defaultValue) {
            this.name = name;
            String configValue = (config != null) ? config.getProperty(name) : null;
            if (configValue != null) {
                value = configValue;
            } else if (System.getProperty(name) != null) {
                value = System.getProperty(name);
            } else {
                value = defaultValue;
            }
        }

        public String getName() {
            return this.name;
        }

        public String getValue() {
            return value;
        }

        public int getInteger() {
            return Integer.parseInt(this.value);
        }

        public byte getByte() {
            return Byte.parseByte(this.value);
        }

        public boolean getBoolean() {
            return Boolean.valueOf(this.value);
        }

        public String getString() {
            return value;
        }

        public long getLong() {
            return Long.parseLong(this.value);
        }

        @Override
        public String toString() {
            return "GroupProperty [name=" + this.name + ", value=" + this.value + "]";
        }
    }
}

<code block>


package com.hazelcast.instance;

import com.hazelcast.client.impl.ClientServiceProxy;
import com.hazelcast.collection.impl.list.ListService;
import com.hazelcast.collection.impl.queue.QueueService;
import com.hazelcast.collection.impl.set.SetService;
import com.hazelcast.concurrent.atomiclong.AtomicLongService;
import com.hazelcast.concurrent.atomicreference.AtomicReferenceService;
import com.hazelcast.concurrent.countdownlatch.CountDownLatchService;
import com.hazelcast.concurrent.idgen.IdGeneratorService;
import com.hazelcast.concurrent.lock.LockProxy;
import com.hazelcast.concurrent.lock.LockService;
import com.hazelcast.concurrent.semaphore.SemaphoreService;
import com.hazelcast.config.Config;
import com.hazelcast.core.ClientService;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.DistributedObjectListener;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.HazelcastInstanceAware;
import com.hazelcast.core.IAtomicLong;
import com.hazelcast.core.IAtomicReference;
import com.hazelcast.core.ICountDownLatch;
import com.hazelcast.core.IExecutorService;
import com.hazelcast.core.IList;
import com.hazelcast.core.ILock;
import com.hazelcast.core.IMap;
import com.hazelcast.core.IQueue;
import com.hazelcast.core.ISemaphore;
import com.hazelcast.core.ISet;
import com.hazelcast.core.ITopic;
import com.hazelcast.core.IdGenerator;
import com.hazelcast.core.ManagedContext;
import com.hazelcast.core.Member;
import com.hazelcast.core.MultiMap;
import com.hazelcast.core.PartitionService;
import com.hazelcast.core.ReplicatedMap;
import com.hazelcast.executor.impl.DistributedExecutorService;
import com.hazelcast.internal.monitors.HealthMonitor;
import com.hazelcast.internal.monitors.HealthMonitorLevel;
import com.hazelcast.internal.monitors.PerformanceMonitor;
import com.hazelcast.jmx.ManagementService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.mapreduce.JobTracker;
import com.hazelcast.mapreduce.impl.MapReduceService;
import com.hazelcast.memory.MemoryStats;
import com.hazelcast.multimap.impl.MultiMapService;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.quorum.QuorumService;
import com.hazelcast.replicatedmap.impl.ReplicatedMapService;
import com.hazelcast.ringbuffer.Ringbuffer;
import com.hazelcast.ringbuffer.impl.RingbufferService;
import com.hazelcast.spi.ProxyService;
import com.hazelcast.spi.annotation.PrivateApi;
import com.hazelcast.topic.impl.TopicService;
import com.hazelcast.topic.impl.reliable.ReliableTopicService;
import com.hazelcast.transaction.HazelcastXAResource;
import com.hazelcast.transaction.TransactionContext;
import com.hazelcast.transaction.TransactionException;
import com.hazelcast.transaction.TransactionManagerService;
import com.hazelcast.transaction.TransactionOptions;
import com.hazelcast.transaction.TransactionalTask;
import com.hazelcast.transaction.impl.xa.XAService;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.ExceptionUtil;

import java.util.Collection;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import static com.hazelcast.core.LifecycleEvent.LifecycleState.STARTING;
import static com.hazelcast.util.Preconditions.checkNotNull;

@SuppressWarnings("unchecked")
@PrivateApi
public class HazelcastInstanceImpl implements HazelcastInstance {

    public final Node node;

    final ILogger logger;

    final String name;

    final ManagementService managementService;

    final LifecycleServiceImpl lifecycleService;

    final ManagedContext managedContext;

    final ConcurrentMap<String, Object> userContext = new ConcurrentHashMap<String, Object>();

    HazelcastInstanceImpl(String name, Config config, NodeContext nodeContext)
            throws Exception {
        this.name = name;
        lifecycleService = new LifecycleServiceImpl(this);
        ManagedContext configuredManagedContext = config.getManagedContext();
        managedContext = new HazelcastManagedContext(this, configuredManagedContext);

        
        
        
        userContext.putAll(config.getUserContext());
        node = new Node(this, config, nodeContext);

        try {
            logger = node.getLogger(getClass().getName());
            lifecycleService.fireLifecycleEvent(STARTING);

            node.start();
            if (!node.isActive()) {
                throw new IllegalStateException("Node failed to start!");
            }

            managementService = new ManagementService(this);
            initManagedContext(configuredManagedContext);
            initMonitors();
        } catch (Throwable e) {
            try {
                
                
                node.shutdown(true);
            } catch (Throwable ignored) {
                EmptyStatement.ignore(ignored);
            }
            throw ExceptionUtil.rethrow(e);
        }
    }

    private void initMonitors() {
        initHealthMonitor();
        initPerformanceMonitor();
    }

    private void initManagedContext(ManagedContext configuredManagedContext) {
        if (configuredManagedContext != null) {
            if (configuredManagedContext instanceof HazelcastInstanceAware) {
                ((HazelcastInstanceAware) configuredManagedContext).setHazelcastInstance(this);
            }
        }
    }

    private void initHealthMonitor() {
        String healthMonitorLevelString = node.getGroupProperties().HEALTH_MONITORING_LEVEL.getString();
        HealthMonitorLevel healthLevel = HealthMonitorLevel.valueOf(healthMonitorLevelString);
        if (healthLevel != HealthMonitorLevel.OFF) {
            logger.finest("Starting health monitor");
            int delaySeconds = node.getGroupProperties().HEALTH_MONITORING_DELAY_SECONDS.getInteger();
            new HealthMonitor(this, healthLevel, delaySeconds).start();
        }
    }

    private void initPerformanceMonitor() {
        boolean enabled = node.getGroupProperties().PERFORMANCE_MONITORING_ENABLED.getBoolean();
        if (!enabled) {
            return;
        }

        logger.finest("Starting performance monitor");
        int delaySeconds = node.getGroupProperties().PERFORMANCE_MONITORING_DELAY_SECONDS.getInteger();
        new PerformanceMonitor(this, delaySeconds).start();
    }

    public ManagementService getManagementService() {
        return managementService;
    }

    @Override
    public String getName() {
        return name;
    }

    @Override
    public <K, V> IMap<K, V> getMap(String name) {
        checkNotNull(name, "Retrieving a map instance with a null name is not allowed!");
        return getDistributedObject(MapService.SERVICE_NAME, name);
    }

    @Override
    public <E> IQueue<E> getQueue(String name) {
        checkNotNull(name, "Retrieving a queue instance with a null name is not allowed!");
        return getDistributedObject(QueueService.SERVICE_NAME, name);
    }

    @Override
    public <E> ITopic<E> getTopic(String name) {
        checkNotNull(name, "Retrieving a topic instance with a null name is not allowed!");
        return getDistributedObject(TopicService.SERVICE_NAME, name);
    }

    @Override
    public <E> ITopic<E> getReliableTopic(String name) {
        checkNotNull(name, "Retrieving a topic instance with a null name is not allowed!");
        return getDistributedObject(ReliableTopicService.SERVICE_NAME, name);
    }

    @Override
    public <E> ISet<E> getSet(String name) {
        checkNotNull(name, "Retrieving a set instance with a null name is not allowed!");
        return getDistributedObject(SetService.SERVICE_NAME, name);
    }

    @Override
    public <E> IList<E> getList(String name) {
        checkNotNull(name, "Retrieving a list instance with a null name is not allowed!");
        return getDistributedObject(ListService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> MultiMap<K, V> getMultiMap(String name) {
        checkNotNull(name, "Retrieving a multi-map instance with a null name is not allowed!");
        return getDistributedObject(MultiMapService.SERVICE_NAME, name);
    }

    @Override
    public JobTracker getJobTracker(String name) {
        checkNotNull(name, "Retrieving a job tracker instance with a null name is not allowed!");
        return getDistributedObject(MapReduceService.SERVICE_NAME, name);
    }

    @Override
    public <E> Ringbuffer<E> getRingbuffer(String name) {
        checkNotNull(name, "Retrieving a ringbuffer instance with a null name is not allowed!");
        return getDistributedObject(RingbufferService.SERVICE_NAME, name);
    }

    @Deprecated
    public ILock getLock(Object key) {
        checkNotNull(key, "Retrieving a lock instance with a null key is not allowed!");
        String name = LockProxy.convertToStringKey(key, node.getSerializationService());
        return getLock(name);
    }

    @Override
    public ILock getLock(String key) {
        checkNotNull(key, "Retrieving a lock instance with a null key is not allowed!");
        return getDistributedObject(LockService.SERVICE_NAME, key);
    }

    @Override
    public <T> T executeTransaction(TransactionalTask<T> task)
            throws TransactionException {
        return executeTransaction(TransactionOptions.getDefault(), task);
    }

    @Override
    public <T> T executeTransaction(TransactionOptions options, TransactionalTask<T> task)
            throws TransactionException {
        TransactionManagerService transactionManagerService = node.nodeEngine.getTransactionManagerService();
        return transactionManagerService.executeTransaction(options, task);
    }

    @Override
    public TransactionContext newTransactionContext() {
        return newTransactionContext(TransactionOptions.getDefault());
    }

    @Override
    public TransactionContext newTransactionContext(TransactionOptions options) {
        TransactionManagerService transactionManagerService = node.nodeEngine.getTransactionManagerService();
        return transactionManagerService.newTransactionContext(options);
    }

    @Override
    public IExecutorService getExecutorService(String name) {
        checkNotNull(name, "Retrieving an executor instance with a null name is not allowed!");
        return getDistributedObject(DistributedExecutorService.SERVICE_NAME, name);
    }

    @Override
    public IdGenerator getIdGenerator(String name) {
        checkNotNull(name, "Retrieving an id-generator instance with a null name is not allowed!");
        return getDistributedObject(IdGeneratorService.SERVICE_NAME, name);
    }

    @Override
    public IAtomicLong getAtomicLong(String name) {
        checkNotNull(name, "Retrieving an atomic-long instance with a null name is not allowed!");
        return getDistributedObject(AtomicLongService.SERVICE_NAME, name);
    }

    @Override
    public <E> IAtomicReference<E> getAtomicReference(String name) {
        checkNotNull(name, "Retrieving an atomic-reference instance with a null name is not allowed!");
        return getDistributedObject(AtomicReferenceService.SERVICE_NAME, name);
    }

    @Override
    public ICountDownLatch getCountDownLatch(String name) {
        checkNotNull(name, "Retrieving a countdown-latch instance with a null name is not allowed!");
        return getDistributedObject(CountDownLatchService.SERVICE_NAME, name);
    }

    @Override
    public ISemaphore getSemaphore(String name) {
        checkNotNull(name, "Retrieving a semaphore instance with a null name is not allowed!");
        return getDistributedObject(SemaphoreService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> ReplicatedMap<K, V> getReplicatedMap(String name) {
        checkNotNull(name, "Retrieving a replicated map instance with a null name is not allowed!");
        return getDistributedObject(ReplicatedMapService.SERVICE_NAME, name);
    }

    @Override
    public Cluster getCluster() {
        return node.clusterService.getClusterProxy();
    }

    @Override
    public Member getLocalEndpoint() {
        return node.clusterService.getLocalMember();
    }

    @Override
    public Collection<DistributedObject> getDistributedObjects() {
        ProxyService proxyService = node.nodeEngine.getProxyService();
        return proxyService.getAllDistributedObjects();
    }

    @Override
    public Config getConfig() {
        return node.getConfig();
    }

    @Override
    public ConcurrentMap<String, Object> getUserContext() {
        return userContext;
    }

    @Override
    public PartitionService getPartitionService() {
        return node.partitionService.getPartitionServiceProxy();
    }

    @Override
    public QuorumService getQuorumService() {
        return node.nodeEngine.getQuorumService();
    }

    @Override
    public ClientService getClientService() {
        return new ClientServiceProxy(node);
    }

    @Override
    public LoggingService getLoggingService() {
        return node.loggingService;
    }

    @Override
    public LifecycleServiceImpl getLifecycleService() {
        return lifecycleService;
    }

    @Override
    public void shutdown() {
        getLifecycleService().shutdown();
    }

    @Override
    public <T extends DistributedObject> T getDistributedObject(String serviceName, String name) {
        ProxyService proxyService = node.nodeEngine.getProxyService();
        return (T) proxyService.getDistributedObject(serviceName, name);
    }

    @Override
    public String addDistributedObjectListener(DistributedObjectListener distributedObjectListener) {
        final ProxyService proxyService = node.nodeEngine.getProxyService();
        return proxyService.addProxyListener(distributedObjectListener);
    }

    @Override
    public boolean removeDistributedObjectListener(String registrationId) {
        final ProxyService proxyService = node.nodeEngine.getProxyService();
        return proxyService.removeProxyListener(registrationId);
    }

    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    public MemoryStats getMemoryStats() {
        return node.getNodeExtension().getMemoryStats();
    }

    @Override
    public HazelcastXAResource getXAResource() {
        return getDistributedObject(XAService.SERVICE_NAME, XAService.SERVICE_NAME);
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (o == null || !(o instanceof HazelcastInstance)) {
            return false;
        }

        HazelcastInstance that = (HazelcastInstance) o;
        return !(name != null ? !name.equals(that.getName()) : that.getName() != null);
    }

    @Override
    public int hashCode() {
        return name != null ? name.hashCode() : 0;
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("HazelcastInstance");
        sb.append("{name='").append(name).append('\'');
        sb.append(", node=").append(node.getThisAddress());
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.spi.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.config.Config;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.management.ManagementCenterService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.quorum.impl.QuorumServiceImpl;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.PostJoinAwareService;
import com.hazelcast.spi.impl.servicemanager.ServiceInfo;
import com.hazelcast.spi.SharedService;
import com.hazelcast.internal.storage.DataRef;
import com.hazelcast.internal.storage.Storage;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import com.hazelcast.spi.impl.operationservice.impl.OperationServiceImpl;
import com.hazelcast.spi.impl.proxyservice.InternalProxyService;
import com.hazelcast.spi.impl.proxyservice.impl.ProxyServiceImpl;
import com.hazelcast.spi.impl.servicemanager.impl.ServiceManagerImpl;
import com.hazelcast.spi.impl.waitnotifyservice.InternalWaitNotifyService;
import com.hazelcast.spi.impl.waitnotifyservice.impl.WaitNotifyServiceImpl;
import com.hazelcast.spi.impl.eventservice.InternalEventService;
import com.hazelcast.spi.impl.eventservice.impl.EventServiceImpl;
import com.hazelcast.spi.impl.transceiver.PacketTransceiver;
import com.hazelcast.spi.impl.transceiver.impl.PacketTransceiverImpl;
import com.hazelcast.spi.impl.executionservice.InternalExecutionService;
import com.hazelcast.spi.impl.executionservice.impl.ExecutionServiceImpl;
import com.hazelcast.transaction.TransactionManagerService;
import com.hazelcast.transaction.impl.TransactionManagerServiceImpl;
import com.hazelcast.wan.WanReplicationService;

import java.util.Collection;
import java.util.LinkedList;


public class NodeEngineImpl implements NodeEngine {

    private final Node node;
    private final ILogger logger;
    private final EventServiceImpl eventService;
    private final OperationServiceImpl operationService;
    private final ExecutionServiceImpl executionService;
    private final WaitNotifyServiceImpl waitNotifyService;
    private final ServiceManagerImpl serviceManager;
    private final TransactionManagerServiceImpl transactionManagerService;
    private final ProxyServiceImpl proxyService;
    private final WanReplicationService wanReplicationService;
    private final PacketTransceiver packetTransceiver;
    private final QuorumServiceImpl quorumService;

    public NodeEngineImpl(Node node) {
        this.node = node;
        this.logger = node.getLogger(NodeEngine.class.getName());
        this.proxyService = new ProxyServiceImpl(this);
        this.serviceManager = new ServiceManagerImpl(this);
        this.executionService = new ExecutionServiceImpl(this);
        this.operationService = new OperationServiceImpl(this);
        this.eventService = new EventServiceImpl(this);
        this.waitNotifyService = new WaitNotifyServiceImpl(this);
        this.transactionManagerService = new TransactionManagerServiceImpl(this);
        this.wanReplicationService = node.getNodeExtension().createService(WanReplicationService.class);
        this.packetTransceiver = new PacketTransceiverImpl(
                node, logger, operationService, eventService, wanReplicationService, executionService);
        quorumService = new QuorumServiceImpl(this);
    }

    public PacketTransceiver getPacketTransceiver() {
        return packetTransceiver;
    }

    public void start() {
        serviceManager.start();
        proxyService.init();
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public MemberImpl getLocalMember() {
        return node.getLocalMember();
    }

    @Override
    public Config getConfig() {
        return node.getConfig();
    }

    @Override
    public ClassLoader getConfigClassLoader() {
        return node.getConfigClassLoader();
    }

    @Override
    public InternalEventService getEventService() {
        return eventService;
    }

    @Override
    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    @Override
    public InternalOperationService getOperationService() {
        return operationService;
    }

    @Override
    public InternalExecutionService getExecutionService() {
        return executionService;
    }

    @Override
    public InternalPartitionService getPartitionService() {
        return node.getPartitionService();
    }

    @Override
    public ClusterService getClusterService() {
        return node.getClusterService();
    }

    public ManagementCenterService getManagementCenterService() {
        return node.getManagementCenterService();
    }

    @Override
    public InternalProxyService getProxyService() {
        return proxyService;
    }

    @Override
    public InternalWaitNotifyService getWaitNotifyService() {
        return waitNotifyService;
    }

    @Override
    public WanReplicationService getWanReplicationService() {
        return wanReplicationService;
    }

    @Override
    public QuorumServiceImpl getQuorumService() {
        return quorumService;
    }

    @Override
    public TransactionManagerService getTransactionManagerService() {
        return transactionManagerService;
    }

    @Override
    public Data toData(final Object object) {
        return node.getSerializationService().toData(object);
    }

    @Override
    public Object toObject(final Object object) {
        if (object instanceof Data) {
            return node.getSerializationService().toObject(object);
        }
        return object;
    }

    @Override
    public boolean isActive() {
        return node.isActive();
    }

    @Override
    public HazelcastInstance getHazelcastInstance() {
        return node.hazelcastInstance;
    }

    @Override
    public ILogger getLogger(String name) {
        return node.getLogger(name);
    }

    @Override
    public ILogger getLogger(Class clazz) {
        return node.getLogger(clazz);
    }

    @Override
    public GroupProperties getGroupProperties() {
        return node.getGroupProperties();
    }

    public <T> T getService(String serviceName) {
        return serviceManager.getService(serviceName);
    }

    @Override
    public <T extends SharedService> T getSharedService(String serviceName) {
        return serviceManager.getSharedService(serviceName);
    }

    
    public <S> Collection<S> getServices(Class<S> serviceClass) {
        return serviceManager.getServices(serviceClass);
    }

    public Collection<ServiceInfo> getServiceInfos(Class serviceClass) {
        return serviceManager.getServiceInfos(serviceClass);
    }

    public Node getNode() {
        return node;
    }

    public void onMemberLeft(MemberImpl member) {
        waitNotifyService.onMemberLeft(member);
        operationService.onMemberLeft(member);
        eventService.onMemberLeft(member);
    }

    public void onClientDisconnected(String clientUuid) {
        waitNotifyService.onClientDisconnected(clientUuid);
    }

    public void onPartitionMigrate(MigrationInfo migrationInfo) {
        waitNotifyService.onPartitionMigrate(getThisAddress(), migrationInfo);
    }

    
    public Operation[] getPostJoinOperations() {
        final Collection<Operation> postJoinOps = new LinkedList<Operation>();
        Operation eventPostJoinOp = eventService.getPostJoinOperation();
        if (eventPostJoinOp != null) {
            postJoinOps.add(eventPostJoinOp);
        }
        Collection<PostJoinAwareService> services = getServices(PostJoinAwareService.class);
        for (PostJoinAwareService service : services) {
            final Operation postJoinOperation = service.getPostJoinOperation();
            if (postJoinOperation != null) {
                if (postJoinOperation.getPartitionId() >= 0) {
                    logger.severe(
                            "Post-join operations cannot implement PartitionAwareOperation! Service: "
                                    + service + ", Operation: "
                                    + postJoinOperation);
                    continue;
                }
                postJoinOps.add(postJoinOperation);
            }
        }
        return postJoinOps.isEmpty() ? null : postJoinOps.toArray(new Operation[postJoinOps.size()]);
    }

    @Override
    public Storage<DataRef> getOffHeapStorage() {
        return node.getNodeExtension().getNativeDataStorage();
    }

    public void reset() {
        waitNotifyService.reset();
        operationService.reset();
    }

    public void shutdown(final boolean terminate) {
        logger.finest("Shutting down services...");
        waitNotifyService.shutdown();
        proxyService.shutdown();
        serviceManager.shutdown(terminate);
        eventService.shutdown();
        operationService.shutdown();
        wanReplicationService.shutdown();
        executionService.shutdown();
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.internal.management.dto.SlowOperationDTO;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;

import java.util.List;


public interface InternalOperationService extends OperationService {

    
    double getInvocationUsagePercentage();

    
    int getPendingInvocationCount();

    
    boolean isCallTimedOut(Operation op);

    
    void execute(PartitionSpecificRunnable task);

    
    OperationExecutor getOperationExecutor();

    
    List<SlowOperationDTO> getSlowOperationDTOs();

    <V> void asyncInvokeOnPartition(String serviceName, Operation op, int partitionId, ExecutionCallback<V> callback);

    <V> void asyncInvokeOnTarget(String serviceName, Operation op, Address target, ExecutionCallback<V> callback);
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.MemberLeftException;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.ReplicaErrorLogger;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.executionservice.InternalExecutionService;
import com.hazelcast.spi.impl.operationexecutor.OperationHostileThread;
import com.hazelcast.spi.impl.operationservice.impl.responses.BackupResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.ErrorResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.NormalResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.Response;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;

import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.instance.OutOfMemoryErrorDispatcher.inspectOutputMemoryError;
import static com.hazelcast.spi.Operation.CALL_ID_LOCAL_SKIPPED;
import static com.hazelcast.spi.OperationAccessor.setCallId;


public class InvocationRegistry {
    private static final long SCHEDULE_DELAY = 1111;
    private static final int INITIAL_CAPACITY = 1000;
    private static final float LOAD_FACTOR = 0.75f;
    private static final int DELAY_MILLIS = 1000;
    private static final double HUNDRED_PERCENT = 100d;

    private final long backupTimeoutMillis;
    private final ConcurrentMap<Long, Invocation> invocations;
    private final NodeEngineImpl nodeEngine;
    private final ILogger logger;
    private final InspectionThread inspectionThread;
    private final CallIdSequence callIdSequence;
    private final long slowInvocationThresholdMs;

    public InvocationRegistry(NodeEngineImpl nodeEngine, ILogger logger, BackpressureRegulator backpressureRegulator,
                              int concurrencyLevel) {
        this.nodeEngine = nodeEngine;
        this.logger = logger;
        this.callIdSequence = backpressureRegulator.newCallIdSequence();

        GroupProperties props = nodeEngine.getGroupProperties();
        this.slowInvocationThresholdMs = initSlowInvocationThresholdMs(props);
        this.backupTimeoutMillis = props.OPERATION_BACKUP_TIMEOUT_MILLIS.getLong();
        this.invocations = new ConcurrentHashMap<Long, Invocation>(INITIAL_CAPACITY, LOAD_FACTOR, concurrencyLevel);
        this.inspectionThread = new InspectionThread();
        inspectionThread.start();
    }

    private long initSlowInvocationThresholdMs(GroupProperties props) {
        long thresholdMs = props.SLOW_INVOCATION_DETECTOR_THRESHOLD_MILLIS.getLong();
        if (thresholdMs > -1) {
            logger.info("Slow invocation detector enabled, using threshold: " + thresholdMs + " ms");
        }
        return thresholdMs;
    }

    public long getLastCallId() {
        return callIdSequence.getLastCallId();
    }

    
    public void register(Invocation invocation) {
        assert invocation.op.getCallId() == 0 : "can't register twice:" + invocation;

        long callId = callIdSequence.next(invocation);
        setCallId(invocation.op, callId);

        if (callId == CALL_ID_LOCAL_SKIPPED) {
            return;
        }

        invocations.put(callId, invocation);
    }

    
    public void deregister(Invocation invocation) {
        long callId = invocation.op.getCallId();

        callIdSequence.complete(invocation);

        setCallId(invocation.op, 0);

        if (callId == 0 || callId == CALL_ID_LOCAL_SKIPPED) {
            return;
        }

        boolean deleted = invocations.remove(callId) != null;
        assert deleted : "failed to deregister callId:" + callId + " " + invocation;
    }

    public double getInvocationUsagePercentage() {
        return (HUNDRED_PERCENT * invocations.size()) / callIdSequence.getMaxConcurrentInvocations();
    }

    
    public int size() {
        return invocations.size();
    }

    
    public Invocation get(long callId) {
        return invocations.get(callId);
    }

    
    public void notify(Response response) {
        if (response instanceof NormalResponse) {
            notifyNormalResponse((NormalResponse) response);
        } else if (response instanceof BackupResponse) {
            notifyBackupComplete(response.getCallId());
        } else if (response instanceof CallTimeoutResponse) {
            notifyCallTimeout((CallTimeoutResponse) response);
        } else if (response instanceof ErrorResponse) {
            notifyErrorResponse((ErrorResponse) response);
        } else {
            logger.severe("Unrecognized response: " + response);
        }
    }

    public void notifyBackupComplete(long callId) {
        try {
            Invocation invocation = invocations.get(callId);

            
            
            
            if (invocation == null) {
                if (logger.isFinestEnabled()) {
                    logger.finest("No Invocation found for BackupResponse with callId " + callId);
                }
                return;
            }

            invocation.notifySingleBackupComplete();
        } catch (Exception e) {
            ReplicaErrorLogger.log(e, logger);
        }
    }

    private void notifyErrorResponse(ErrorResponse response) {
        Invocation invocation = invocations.get(response.getCallId());

        if (invocation == null) {
            if (nodeEngine.isActive()) {
                logger.warning("No Invocation found for response: " + response);
            }
            return;
        }

        invocation.notifyError(response.getCause());
    }

    private void notifyNormalResponse(NormalResponse response) {
        Invocation invocation = invocations.get(response.getCallId());

        if (invocation == null) {
            if (nodeEngine.isActive()) {
                logger.warning("No Invocation found for response: " + response);
            }
            return;
        }
        invocation.notifyNormalResponse(response.getValue(), response.getBackupCount());
    }

    private void notifyCallTimeout(CallTimeoutResponse response) {
        Invocation invocation = invocations.get(response.getCallId());

        if (invocation == null) {
            if (nodeEngine.isActive()) {
                logger.warning("No Invocation found for response: " + response);
            }
            return;
        }
        invocation.notifyCallTimeout();
    }

    public void onMemberLeft(MemberImpl member) {
        
        InternalExecutionService executionService = nodeEngine.getExecutionService();
        Runnable task = new OnMemberLeftTask(member);
        executionService.schedule(task, SCHEDULE_DELAY, TimeUnit.MILLISECONDS);
    }

    public void reset() {
        for (Invocation invocation : invocations.values()) {
            try {
                invocation.notifyError(new MemberLeftException());
            } catch (Throwable e) {
                logger.warning(invocation + " could not be notified with reset message -> " + e.getMessage());
            }
        }
    }

    public void shutdown() {
        inspectionThread.shutdown();

        for (Invocation invocation : invocations.values()) {
            try {
                invocation.notifyError(new HazelcastInstanceNotActiveException());
            } catch (Throwable e) {
                logger.warning(invocation + " could not be notified with shutdown message -> " + e.getMessage(), e);
            }
        }
    }

    public void awaitTermination(long timeoutMillis) throws InterruptedException {
        inspectionThread.join(timeoutMillis);
    }

    
    class InspectionThread extends Thread implements OperationHostileThread {

        private volatile boolean shutdown;

        InspectionThread() {
            super(nodeEngine.getNode().getHazelcastThreadGroup().getThreadNamePrefix("InspectInvocationsThread"));
        }

        public void shutdown() {
            shutdown = true;
            interrupt();
        }

        @Override
        public void run() {
            try {
                while (!shutdown) {
                    scanHandleOperationTimeout();
                    if (!shutdown) {
                        sleep();
                    }
                }
            } catch (Throwable t) {
                inspectOutputMemoryError(t);
                logger.severe("Failed to run", t);
            }
        }

        private void sleep() {
            try {
                Thread.sleep(DELAY_MILLIS);
            } catch (InterruptedException ignore) {
                
                EmptyStatement.ignore(ignore);
            }
        }

        private void scanHandleOperationTimeout() {
            if (invocations.isEmpty()) {
                return;
            }

            long now = Clock.currentTimeMillis();

            
            int backupTimeouts = 0;
            int invocationTimeouts = 0;
            for (Invocation invocation : invocations.values()) {
                if (shutdown) {
                    return;
                }

                detectSlowInvocation(now, invocation);

                if (checkInvocationTimeout(invocation)) {
                    invocationTimeouts++;
                }

                if (checkBackupTimeout(invocation)) {
                    backupTimeouts++;
                }
            }

            log(backupTimeouts, invocationTimeouts);
        }

        private void detectSlowInvocation(long now, Invocation invocation) {
            if (slowInvocationThresholdMs > 0) {
                long durationMs = now - invocation.op.getInvocationTime();
                if (durationMs > slowInvocationThresholdMs) {
                    logger.info("Slow invocation: duration=" + durationMs + " ms, operation="
                            + invocation.op.getClass().getName() + " inv:" + invocation);
                }
            }
        }

        private boolean checkInvocationTimeout(Invocation invocation) {
            try {
                return invocation.checkInvocationTimeout();
            } catch (Throwable t) {
                inspectOutputMemoryError(t);
                logger.severe("Failed to handle operation timeout of invocation:" + invocation, t);
                return false;
            }
        }

        private boolean checkBackupTimeout(Invocation invocation) {
            try {
                return invocation.checkBackupTimeout(backupTimeoutMillis);
            } catch (Throwable t) {
                inspectOutputMemoryError(t);
                logger.severe("Failed to handle backup timeout of invocation:" + invocation, t);
                return false;
            }
        }

        private void log(int backupTimeouts, int invocationTimeouts) {
            if (backupTimeouts > 0 || invocationTimeouts > 0) {
                logger.info("Handled " + invocationTimeouts + " invocation timeouts and " + backupTimeouts + " backupTimeouts");
            }
        }
    }

    private class OnMemberLeftTask implements Runnable {
        private final MemberImpl leftMember;

        public OnMemberLeftTask(MemberImpl leftMember) {
            this.leftMember = leftMember;
        }

        @Override
        public void run() {
            for (Invocation invocation : invocations.values()) {
                if (hasMemberLeft(invocation)) {
                    invocation.notifyError(new MemberLeftException(leftMember));
                }
            }
        }

        private boolean hasMemberLeft(Invocation invocation) {
            MemberImpl targetMember = invocation.targetMember;
            if (targetMember == null) {
                Address invTarget = invocation.invTarget;
                return leftMember.getAddress().equals(invTarget);
            } else {
                return leftMember.getUuid().equals(targetMember.getUuid());
            }
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.IOUtil;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.quorum.impl.QuorumServiceImpl;
import com.hazelcast.spi.BackupAwareOperation;
import com.hazelcast.spi.Notifier;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationResponseHandler;
import com.hazelcast.spi.ReadonlyOperation;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.exception.CallerNotMemberException;
import com.hazelcast.spi.exception.PartitionMigratingException;
import com.hazelcast.spi.exception.RetryableException;
import com.hazelcast.spi.exception.WrongTargetException;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.operationexecutor.OperationRunner;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.ErrorResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.NormalResponse;
import com.hazelcast.util.ExceptionUtil;

import java.util.concurrent.atomic.AtomicLong;
import java.util.logging.Level;

import static com.hazelcast.spi.Operation.CALL_ID_LOCAL_SKIPPED;
import static com.hazelcast.spi.OperationAccessor.setCallerAddress;
import static com.hazelcast.spi.OperationAccessor.setConnection;
import static com.hazelcast.spi.impl.OperationResponseHandlerFactory.createEmptyResponseHandler;
import static com.hazelcast.spi.impl.operationutil.Operations.isJoinOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isMigrationOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isWanReplicationOperation;
import static java.util.logging.Level.FINEST;
import static java.util.logging.Level.SEVERE;
import static java.util.logging.Level.WARNING;


class OperationRunnerImpl extends OperationRunner {
    static final int AD_HOC_PARTITION_ID = -2;

    private final ILogger logger;
    private final OperationServiceImpl operationService;
    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final AtomicLong executedOperationsCount;

    
    
    private InternalPartition internalPartition;

    private final OperationResponseHandler remoteResponseHandler;

    
    
    
    
    
    public OperationRunnerImpl(OperationServiceImpl operationService, int partitionId) {
        super(partitionId);
        this.operationService = operationService;
        this.logger = operationService.logger;
        this.node = operationService.node;
        this.nodeEngine = operationService.nodeEngine;
        this.executedOperationsCount = operationService.executedOperationsCount;
        this.remoteResponseHandler = new RemoteInvocationResponseHandler(operationService);
    }

    @Override
    public void run(Runnable task) {
        boolean publishCurrentTask = publishCurrentTask();

        if (publishCurrentTask) {
            currentTask = task;
        }

        try {
            task.run();
        } finally {
            if (publishCurrentTask) {
                currentTask = null;
            }
        }
    }

    private boolean publishCurrentTask() {
        return (getPartitionId() != AD_HOC_PARTITION_ID && currentTask == null);
    }

    @Override
    public void run(Operation op) {
        executedOperationsCount.incrementAndGet();

        boolean publishCurrentTask = publishCurrentTask();

        if (publishCurrentTask) {
            currentTask = op;
        }

        try {
            if (timeout(op)) {
                return;
            }

            ensureNoPartitionProblems(op);

            ensureQuorumPresent(op);

            op.beforeRun();

            if (waitingNeeded(op)) {
                return;
            }

            op.run();
            handleResponse(op);
            afterRun(op);
        } catch (Throwable e) {
            handleOperationError(op, e);
        } finally {
            if (publishCurrentTask) {
                currentTask = null;
            }
        }
    }

    private void ensureQuorumPresent(Operation op) {
        QuorumServiceImpl quorumService = operationService.nodeEngine.getQuorumService();
        quorumService.ensureQuorumPresent(op);
    }

    private boolean waitingNeeded(Operation op) {
        if (!(op instanceof WaitSupport)) {
            return false;
        }

        WaitSupport waitSupport = (WaitSupport) op;
        if (waitSupport.shouldWait()) {
            nodeEngine.getWaitNotifyService().await(waitSupport);
            return true;
        }
        return false;
    }

    private boolean timeout(Operation op) {
        if (!operationService.isCallTimedOut(op)) {
            return false;
        }

        CallTimeoutResponse callTimeoutResponse = new CallTimeoutResponse(op.getCallId(), op.isUrgent());
        OperationResponseHandler responseHandler = op.getOperationResponseHandler();
        responseHandler.sendResponse(op, callTimeoutResponse);
        return true;
    }

    private void handleResponse(Operation op) throws Exception {
        boolean returnsResponse = op.returnsResponse();
        Object response = null;
        if (op instanceof BackupAwareOperation) {
            BackupAwareOperation backupAwareOp = (BackupAwareOperation) op;
            int syncBackupCount = 0;
            if (backupAwareOp.shouldBackup()) {
                syncBackupCount = operationService.operationBackupHandler.backup(backupAwareOp);
            }
            if (returnsResponse) {
                response = new NormalResponse(op.getResponse(), op.getCallId(), syncBackupCount, op.isUrgent());
            }
        }

        if (!returnsResponse) {
            return;
        }

        if (response == null) {
            response = op.getResponse();
        }

        OperationResponseHandler responseHandler = op.getOperationResponseHandler();
        if (responseHandler == null) {
            throw new IllegalStateException("ResponseHandler should not be null! " + op);
        }
        responseHandler.sendResponse(op, response);
    }

    private void afterRun(Operation op) {
        try {
            op.afterRun();
            if (op instanceof Notifier) {
                final Notifier notifier = (Notifier) op;
                if (notifier.shouldNotify()) {
                    operationService.nodeEngine.getWaitNotifyService().notify(notifier);
                }
            }
        } catch (Throwable e) {
            
            
            
            logOperationError(op, e);
        }
    }

    protected void ensureNoPartitionProblems(Operation op) {
        int partitionId = op.getPartitionId();

        if (partitionId < 0) {
            return;
        }

        if (partitionId != getPartitionId()) {
            throw new IllegalStateException("wrong partition, expected: " + getPartitionId() + " but found:" + partitionId);
        }

        if (internalPartition == null) {
            internalPartition = nodeEngine.getPartitionService().getPartition(partitionId);
        }

        if (retryDuringMigration(op) && internalPartition.isMigrating()) {
            throw new PartitionMigratingException(node.getThisAddress(), partitionId,
                    op.getClass().getName(), op.getServiceName());
        }

        Address owner = internalPartition.getReplicaAddress(op.getReplicaIndex());
        if (op.validatesTarget() && !node.getThisAddress().equals(owner)) {
            throw new WrongTargetException(node.getThisAddress(), owner, partitionId, op.getReplicaIndex(),
                    op.getClass().getName(), op.getServiceName());
        }
    }

    private boolean retryDuringMigration(Operation op) {
        return !(op instanceof ReadonlyOperation || isMigrationOperation(op));
    }

    private void handleOperationError(Operation operation, Throwable e) {
        if (e instanceof OutOfMemoryError) {
            OutOfMemoryErrorDispatcher.onOutOfMemory((OutOfMemoryError) e);
        }
        operation.logError(e);

        OperationResponseHandler responseHandler = operation.getOperationResponseHandler();
        if (operation.returnsResponse() && responseHandler != null) {
            try {
                if (node.isActive()) {
                    responseHandler.sendResponse(operation, e);
                } else if (responseHandler.isLocal()) {
                    responseHandler.sendResponse(operation, new HazelcastInstanceNotActiveException());
                }
            } catch (Throwable t) {
                logger.warning("While sending op error... op: " + operation + ", error: " + e, t);
            }
        }
    }

    private void logOperationError(Operation op, Throwable e) {
        if (e instanceof OutOfMemoryError) {
            OutOfMemoryErrorDispatcher.onOutOfMemory((OutOfMemoryError) e);
        }
        op.logError(e);
    }

    @Override
    public void run(Packet packet) throws Exception {
        boolean publishCurrentTask = publishCurrentTask();

        if (publishCurrentTask) {
            currentTask = packet;
        }

        Connection connection = packet.getConn();
        Address caller = connection.getEndPoint();
        Data data = packet.getData();
        try {
            Object object = nodeEngine.toObject(data);
            Operation op = (Operation) object;
            op.setNodeEngine(nodeEngine);
            setCallerAddress(op, caller);
            setConnection(op, connection);
            setCallerUuidIfNotSet(caller, op);
            setOperationResponseHandler(op);

            if (!ensureValidMember(op)) {
                return;
            }

            if (publishCurrentTask) {
                currentTask = null;
            }
            run(op);
        } catch (Throwable throwable) {
            
            long callId = IOUtil.extractOperationCallId(data, node.getSerializationService());
            operationService.send(new ErrorResponse(throwable, callId, packet.isUrgent()), caller);
            logOperationDeserializationException(throwable, callId);
            throw ExceptionUtil.rethrow(throwable);
        } finally {
            if (publishCurrentTask) {
                currentTask = null;
            }
        }
    }

    private void setOperationResponseHandler(Operation op) {
        OperationResponseHandler handler = remoteResponseHandler;
        if (op.getCallId() == 0 || op.getCallId() == CALL_ID_LOCAL_SKIPPED) {
            if (op.returnsResponse()) {
                throw new HazelcastException(
                        "Op: " + op + " can not return response without call-id!");
            }
            handler = createEmptyResponseHandler();
        }
        op.setOperationResponseHandler(handler);
    }

    private boolean ensureValidMember(Operation op) {
        if (node.clusterService.getMember(op.getCallerAddress()) != null
                || isJoinOperation(op)
                || isWanReplicationOperation(op)) {
            return true;
        }

        Exception error = new CallerNotMemberException(
                op.getCallerAddress(), op.getPartitionId(),
                op.getClass().getName(), op.getServiceName());
        handleOperationError(op, error);
        return false;
    }

    private void setCallerUuidIfNotSet(Address caller, Operation op) {
        if (op.getCallerUuid() != null) {
            return;

        }
        MemberImpl callerMember = node.clusterService.getMember(caller);
        if (callerMember != null) {
            op.setCallerUuid(callerMember.getUuid());
        }
    }

    public void logOperationDeserializationException(Throwable t, long callId) {
        boolean returnsResponse = callId != 0;

        if (t instanceof RetryableException) {
            final Level level = returnsResponse ? FINEST : WARNING;
            if (logger.isLoggable(level)) {
                logger.log(level, t.getClass().getName() + ": " + t.getMessage());
            }
        } else if (t instanceof OutOfMemoryError) {
            try {
                logger.log(SEVERE, t.getMessage(), t);
            } catch (Throwable ignored) {
                logger.log(SEVERE, ignored.getMessage(), t);
            }
        } else {
            final Level level = operationService.nodeEngine.isActive() ? SEVERE : FINEST;
            if (logger.isLoggable(level)) {
                logger.log(level, t.getMessage(), t);
            }
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.management.dto.SlowOperationDTO;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationFactory;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.UrgentSystemOperation;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;
import com.hazelcast.spi.impl.operationexecutor.classic.ClassicOperationExecutor;
import com.hazelcast.spi.impl.operationexecutor.slowoperationdetector.SlowOperationDetector;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import com.hazelcast.spi.impl.operationservice.impl.responses.Response;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.executor.ExecutorType;
import com.hazelcast.util.executor.ManagedExecutorService;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.spi.InvocationBuilder.DEFAULT_CALL_TIMEOUT;
import static com.hazelcast.spi.InvocationBuilder.DEFAULT_DESERIALIZE_RESULT;
import static com.hazelcast.spi.InvocationBuilder.DEFAULT_REPLICA_INDEX;
import static com.hazelcast.spi.InvocationBuilder.DEFAULT_TRY_COUNT;
import static com.hazelcast.spi.InvocationBuilder.DEFAULT_TRY_PAUSE_MILLIS;
import static java.lang.String.format;


public final class OperationServiceImpl implements InternalOperationService {

    private static final int CORE_SIZE_CHECK = 8;
    private static final int CORE_SIZE_FACTOR = 4;
    private static final int CONCURRENCY_LEVEL = 16;
    private static final int ASYNC_QUEUE_CAPACITY = 100000;
    private static final long TERMINATION_TIMEOUT_MILLIS = TimeUnit.SECONDS.toMillis(10);

    final InvocationRegistry invocationsRegistry;
    final OperationExecutor operationExecutor;
    final ILogger invocationLogger;
    final ManagedExecutorService asyncExecutor;
    final AtomicLong executedOperationsCount = new AtomicLong();

    final NodeEngineImpl nodeEngine;
    final Node node;
    final ILogger logger;
    final OperationBackupHandler operationBackupHandler;
    final BackpressureRegulator backpressureRegulator;
    final long defaultCallTimeoutMillis;

    private final SlowOperationDetector slowOperationDetector;
    private final IsStillRunningService isStillRunningService;

    public OperationServiceImpl(NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.node = nodeEngine.getNode();
        this.logger = node.getLogger(OperationService.class);
        this.invocationLogger = nodeEngine.getLogger(Invocation.class);
        GroupProperties groupProperties = node.getGroupProperties();
        this.defaultCallTimeoutMillis = groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong();

        this.backpressureRegulator = new BackpressureRegulator(groupProperties, logger);

        int coreSize = Runtime.getRuntime().availableProcessors();
        boolean reallyMultiCore = coreSize >= CORE_SIZE_CHECK;
        int concurrencyLevel = reallyMultiCore ? coreSize * CORE_SIZE_FACTOR : CONCURRENCY_LEVEL;

        this.invocationsRegistry = new InvocationRegistry(nodeEngine, logger, backpressureRegulator, concurrencyLevel);
        this.operationBackupHandler = new OperationBackupHandler(this);

        this.operationExecutor = new ClassicOperationExecutor(
                groupProperties,
                node.loggingService,
                node.getThisAddress(),
                new OperationRunnerFactoryImpl(this),
                new ResponsePacketHandlerImpl(this),
                node.getHazelcastThreadGroup(),
                node.getNodeExtension()
        );

        this.isStillRunningService = new IsStillRunningService(operationExecutor, nodeEngine, logger);

        ExecutionService executionService = nodeEngine.getExecutionService();
        this.asyncExecutor = executionService.register(ExecutionService.ASYNC_EXECUTOR, coreSize,
                ASYNC_QUEUE_CAPACITY, ExecutorType.CONCRETE);

        this.slowOperationDetector = initSlowOperationDetector();
    }

    private SlowOperationDetector initSlowOperationDetector() {
        return new SlowOperationDetector(node.loggingService,
                operationExecutor.getGenericOperationRunners(),
                operationExecutor.getPartitionOperationRunners(),
                node.groupProperties,
                node.getHazelcastThreadGroup());
    }

    public IsStillRunningService getIsStillRunningService() {
        return isStillRunningService;
    }

    @Override
    public void dumpPerformanceMetrics(StringBuffer sb) {
        sb.append("invocationsPending=")
                .append(invocationsRegistry.getInvocationUsagePercentage()).append('\n');
        sb.append("invocationsUsed=")
                .append(format("%.2f", invocationsRegistry.getInvocationUsagePercentage())).append("%\n");
        sb.append("invocationsMax=")
                .append(backpressureRegulator.getMaxConcurrentInvocations()).append('\n');
        operationExecutor.dumpPerformanceMetrics(sb);
    }

    @Override
    public List<SlowOperationDTO> getSlowOperationDTOs() {
        return slowOperationDetector.getSlowOperationDTOs();
    }

    public InvocationRegistry getInvocationsRegistry() {
        return invocationsRegistry;
    }

    @Override
    public int getPendingInvocationCount() {
        return invocationsRegistry.size();
    }

    @Override
    public double getInvocationUsagePercentage() {
        return invocationsRegistry.getInvocationUsagePercentage();
    }

    @Override
    public int getPartitionOperationThreadCount() {
        return operationExecutor.getPartitionOperationThreadCount();
    }

    @Override
    public int getGenericOperationThreadCount() {
        return operationExecutor.getGenericOperationThreadCount();
    }

    @Override
    public int getRunningOperationsCount() {
        return operationExecutor.getRunningOperationCount();
    }

    @Override
    public long getExecutedOperationCount() {
        return executedOperationsCount.get();
    }

    @Override
    public int getRemoteOperationsCount() {
        return invocationsRegistry.size();
    }

    @Override
    public int getResponseQueueSize() {
        return operationExecutor.getResponseQueueSize();
    }

    @Override
    public int getOperationExecutorQueueSize() {
        return operationExecutor.getOperationExecutorQueueSize();
    }

    @Override
    public int getPriorityOperationExecutorQueueSize() {
        return operationExecutor.getPriorityOperationExecutorQueueSize();
    }

    @Override
    public OperationExecutor getOperationExecutor() {
        return operationExecutor;
    }

    @Override
    public void execute(PartitionSpecificRunnable task) {
        operationExecutor.execute(task);
    }

    @Override
    public InvocationBuilder createInvocationBuilder(String serviceName, Operation op, int partitionId) {
        if (partitionId < 0) {
            throw new IllegalArgumentException("Partition id cannot be negative!");
        }
        return new InvocationBuilderImpl(nodeEngine, serviceName, op, partitionId);
    }

    @Override
    public InvocationBuilder createInvocationBuilder(String serviceName, Operation op, Address target) {
        if (target == null) {
            throw new IllegalArgumentException("Target cannot be null!");
        }
        return new InvocationBuilderImpl(nodeEngine, serviceName, op, target);
    }

    @Override
    public void runOperationOnCallingThread(Operation op) {
        operationExecutor.runOnCallingThread(op);
    }

    @Override
    public void executeOperation(Operation op) {
        operationExecutor.execute(op);
    }

    @Override
    public boolean isAllowedToRunOnCallingThread(Operation op) {
        return operationExecutor.isAllowedToRunInCurrentThread(op);
    }

    @Override
    @SuppressWarnings("unchecked")
    public <E> InternalCompletableFuture<E> invokeOnPartition(String serviceName, Operation op, int partitionId) {
        return new PartitionInvocation(
                nodeEngine, serviceName, op, partitionId, DEFAULT_REPLICA_INDEX,
                DEFAULT_TRY_COUNT, DEFAULT_TRY_PAUSE_MILLIS,
                DEFAULT_CALL_TIMEOUT, null, DEFAULT_DESERIALIZE_RESULT).invoke();
    }

    @Override
    @SuppressWarnings("unchecked")
    public <E> InternalCompletableFuture<E> invokeOnTarget(String serviceName, Operation op, Address target) {
        return new TargetInvocation(nodeEngine, serviceName, op, target, DEFAULT_TRY_COUNT,
                DEFAULT_TRY_PAUSE_MILLIS,
                DEFAULT_CALL_TIMEOUT, null, DEFAULT_DESERIALIZE_RESULT).invoke();
    }

    @Override
    @SuppressWarnings("unchecked")
    public <V> void asyncInvokeOnPartition(String serviceName, Operation op, int partitionId, ExecutionCallback<V> callback) {
        new PartitionInvocation(nodeEngine, serviceName, op, partitionId, DEFAULT_REPLICA_INDEX,
                DEFAULT_TRY_COUNT, DEFAULT_TRY_PAUSE_MILLIS,
                DEFAULT_CALL_TIMEOUT, callback, DEFAULT_DESERIALIZE_RESULT).invokeAsync();
    }

    @Override
    @SuppressWarnings("unchecked")
    public <V> void asyncInvokeOnTarget(String serviceName, Operation op, Address target, ExecutionCallback<V> callback) {
        new TargetInvocation(nodeEngine, serviceName, op, target, DEFAULT_TRY_COUNT,
                DEFAULT_TRY_PAUSE_MILLIS,
                DEFAULT_CALL_TIMEOUT, callback, DEFAULT_DESERIALIZE_RESULT).invokeAsync();
    }

    

    @Override
    public boolean isCallTimedOut(Operation op) {
        if (!op.returnsResponse() || op.getCallId() == 0) {
            return false;
        }

        long callTimeout = op.getCallTimeout();
        long invocationTime = op.getInvocationTime();
        long expireTime = invocationTime + callTimeout;

        if (expireTime <= 0 || expireTime >= Long.MAX_VALUE) {
            return false;
        }

        long now = nodeEngine.getClusterService().getClusterClock().getClusterTime();
        if (expireTime < now) {
            return true;
        }

        return false;
    }

    @Override
    public Map<Integer, Object> invokeOnAllPartitions(String serviceName, OperationFactory operationFactory) throws Exception {
        Map<Address, List<Integer>> memberPartitions = nodeEngine.getPartitionService().getMemberPartitionsMap();
        InvokeOnPartitions invokeOnPartitions = new InvokeOnPartitions(this, serviceName, operationFactory, memberPartitions);
        return invokeOnPartitions.invoke();
    }

    @Override
    public Map<Integer, Object> invokeOnPartitions(String serviceName, OperationFactory operationFactory,
                                                   Collection<Integer> partitions) throws Exception {
        Map<Address, List<Integer>> memberPartitions = new HashMap<Address, List<Integer>>(3);
        InternalPartitionService partitionService = nodeEngine.getPartitionService();
        for (int partition : partitions) {
            Address owner = partitionService.getPartitionOwnerOrWait(partition);

            if (!memberPartitions.containsKey(owner)) {
                memberPartitions.put(owner, new ArrayList<Integer>());
            }

            memberPartitions.get(owner).add(partition);
        }
        InvokeOnPartitions invokeOnPartitions = new InvokeOnPartitions(this, serviceName, operationFactory, memberPartitions);
        return invokeOnPartitions.invoke();
    }

    @Override
    public boolean send(Operation op, Address target) {
        if (target == null) {
            throw new IllegalArgumentException("Target is required!");
        }

        if (nodeEngine.getThisAddress().equals(target)) {
            throw new IllegalArgumentException("Target is this node! -> " + target + ", op: " + op);
        }

        Data data = nodeEngine.toData(op);
        int partitionId = op.getPartitionId();
        Packet packet = new Packet(data, partitionId);
        packet.setHeader(Packet.HEADER_OP);

        if (op instanceof UrgentSystemOperation) {
            packet.setHeader(Packet.HEADER_URGENT);
        }

        Connection connection = node.getConnectionManager().getOrConnect(target);
        return nodeEngine.getPacketTransceiver().transmit(packet, connection);
    }

    @Override
    public boolean send(Response response, Address target) {
        if (target == null) {
            throw new IllegalArgumentException("Target is required!");
        }

        if (nodeEngine.getThisAddress().equals(target)) {
            throw new IllegalArgumentException("Target is this node! -> " + target + ", response: " + response);
        }

        Data data = nodeEngine.toData(response);
        Packet packet = new Packet(data);
        packet.setHeader(Packet.HEADER_OP);
        packet.setHeader(Packet.HEADER_RESPONSE);

        if (response.isUrgent()) {
            packet.setHeader(Packet.HEADER_URGENT);
        }

        Connection connection = node.getConnectionManager().getOrConnect(target);
        return nodeEngine.getPacketTransceiver().transmit(packet, connection);
    }

    public void onMemberLeft(MemberImpl member) {
        invocationsRegistry.onMemberLeft(member);
    }

    public void reset() {
        invocationsRegistry.reset();
    }

    public void shutdown() {
        logger.finest("Shutting down OperationService");
        invocationsRegistry.shutdown();
        operationExecutor.shutdown();
        slowOperationDetector.shutdown();

        try {
            invocationsRegistry.awaitTermination(TERMINATION_TIMEOUT_MILLIS);
        } catch (InterruptedException e) {
            
            
            Thread.currentThread().interrupt();
            EmptyStatement.ignore(e);
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.OperationTimeoutException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationResponseHandler;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.exception.ResponseAlreadySentException;
import com.hazelcast.spi.exception.RetryableException;
import com.hazelcast.spi.exception.RetryableIOException;
import com.hazelcast.spi.exception.TargetNotMemberException;
import com.hazelcast.spi.exception.WrongTargetException;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.ErrorResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.NormalResponse;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;

import static com.hazelcast.spi.ExecutionService.ASYNC_EXECUTOR;
import static com.hazelcast.spi.OperationAccessor.setCallTimeout;
import static com.hazelcast.spi.OperationAccessor.setCallerAddress;
import static com.hazelcast.spi.OperationAccessor.setInvocationTime;
import static com.hazelcast.spi.impl.operationutil.Operations.isJoinOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isMigrationOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isWanReplicationOperation;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.INTERRUPTED_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.NULL_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.WAIT_RESPONSE;
import static java.lang.Boolean.FALSE;
import static java.lang.Boolean.TRUE;
import static java.util.logging.Level.WARNING;


abstract class Invocation implements OperationResponseHandler, Runnable {

    private static final AtomicReferenceFieldUpdater<Invocation, Boolean> RESPONSE_RECEIVED =
            AtomicReferenceFieldUpdater.newUpdater(Invocation.class, Boolean.class, "responseReceived");

    private static final AtomicIntegerFieldUpdater<Invocation> BACKUPS_COMPLETED =
            AtomicIntegerFieldUpdater.newUpdater(Invocation.class, "backupsCompleted");

    private static final long MIN_TIMEOUT = 10000;
    private static final int MAX_FAST_INVOCATION_COUNT = 5;
    
    private static final int LOG_MAX_INVOCATION_COUNT = 99;
    private static final int LOG_INVOCATION_COUNT_MOD = 10;

    
    volatile long pendingResponseReceivedMillis = -1;
    
    volatile Object pendingResponse;
    
    volatile int backupsExpected;
    
    volatile int backupsCompleted;
    
    volatile Boolean responseReceived = FALSE;

    final long callTimeout;
    final NodeEngineImpl nodeEngine;
    final String serviceName;
    final Operation op;
    final int partitionId;
    final int replicaIndex;
    final int tryCount;
    final long tryPauseMillis;
    final ILogger logger;
    final boolean resultDeserialized;
    boolean remote;
    Address invTarget;
    MemberImpl targetMember;
    final InvocationFuture invocationFuture;
    final OperationServiceImpl operationService;

    
    volatile int invokeCount;

    Invocation(NodeEngineImpl nodeEngine, String serviceName, Operation op, int partitionId,
               int replicaIndex, int tryCount, long tryPauseMillis, long callTimeout, ExecutionCallback callback,
               boolean resultDeserialized) {
        this.operationService = (OperationServiceImpl) nodeEngine.getOperationService();
        this.logger = operationService.invocationLogger;
        this.nodeEngine = nodeEngine;
        this.serviceName = serviceName;
        this.op = op;
        this.partitionId = partitionId;
        this.replicaIndex = replicaIndex;
        this.tryCount = tryCount;
        this.tryPauseMillis = tryPauseMillis;
        this.callTimeout = getCallTimeout(callTimeout);
        this.invocationFuture = new InvocationFuture(operationService, this, callback);
        this.resultDeserialized = resultDeserialized;
    }

    abstract ExceptionAction onException(Throwable t);

    protected abstract Address getTarget();

    InternalPartition getPartition() {
        return nodeEngine.getPartitionService().getPartition(partitionId);
    }

    @Override
    public boolean isLocal() {
        return true;
    }

    private long getCallTimeout(long callTimeout) {
        if (callTimeout > 0) {
            return callTimeout;
        }

        long defaultCallTimeout = operationService.defaultCallTimeoutMillis;
        if (!(op instanceof WaitSupport)) {
            return defaultCallTimeout;
        }

        long waitTimeoutMillis = op.getWaitTimeout();
        if (waitTimeoutMillis > 0 && waitTimeoutMillis < Long.MAX_VALUE) {
            
            long max = Math.max(waitTimeoutMillis, MIN_TIMEOUT);
            return Math.min(max, defaultCallTimeout);
        }
        return defaultCallTimeout;
    }

    public final InvocationFuture invoke() {
        invokeInternal(false);
        return invocationFuture;
    }

    public final void invokeAsync() {
        invokeInternal(true);
    }

    private void invokeInternal(boolean isAsync) {
        if (invokeCount > 0) {
            
            throw new IllegalStateException("An invocation can not be invoked more than once!");
        }

        if (op.getCallId() != 0) {
            throw new IllegalStateException("An operation[" + op + "] can not be used for multiple invocations!");
        }

        try {
            setCallTimeout(op, callTimeout);
            setCallerAddress(op, nodeEngine.getThisAddress());
            op.setNodeEngine(nodeEngine)
                    .setServiceName(serviceName)
                    .setPartitionId(partitionId)
                    .setReplicaIndex(replicaIndex);

            boolean isAllowed = operationService.operationExecutor.isInvocationAllowedFromCurrentThread(op, isAsync);
            if (!isAllowed && !isMigrationOperation(op)) {
                throw new IllegalThreadStateException(Thread.currentThread() + " cannot make remote call: " + op);
            }
            doInvoke(isAsync);
        } catch (Exception e) {
            handleInvocationException(e);
        }
    }

    private void handleInvocationException(Exception e) {
        if (e instanceof RetryableException) {
            notify(e);
        } else {
            throw ExceptionUtil.rethrow(e);
        }
    }

    @SuppressFBWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "We have the guarantee that only a single thread at any given time can change the volatile field")
    private void doInvoke(boolean isAsync) {
        if (!engineActive()) {
            return;
        }

        invokeCount++;

        
        if (!initInvocationTarget()) {
            return;
        }

        setInvocationTime(op, nodeEngine.getClusterService().getClusterClock().getClusterTime());
        operationService.invocationsRegistry.register(this);
        if (remote) {
            doInvokeRemote();
        } else {
            doInvokeLocal(isAsync);
        }
    }

    private void doInvokeLocal(boolean isAsync) {
        if (op.getCallerUuid() == null) {
            op.setCallerUuid(nodeEngine.getLocalMember().getUuid());
        }

        responseReceived = FALSE;
        op.setOperationResponseHandler(this);

        OperationExecutor executor = operationService.operationExecutor;
        if (isAsync) {
            executor.execute(op);
        } else {
            executor.runOnCallingThreadIfPossible(op);
        }

    }

    private void doInvokeRemote() {
        boolean sent = operationService.send(op, invTarget);
        if (!sent) {
            operationService.invocationsRegistry.deregister(this);
            notify(new RetryableIOException("Packet not send to -> " + invTarget));
        }
    }

    @Override
    public void run() {
        doInvoke(false);
    }

    private boolean engineActive() {
        if (nodeEngine.isActive()) {
            return true;
        }

        remote = false;
        notify(new HazelcastInstanceNotActiveException());
        return false;
    }

    
    boolean initInvocationTarget() {
        Address thisAddress = nodeEngine.getThisAddress();

        invTarget = getTarget();

        if (invTarget == null) {
            remote = false;
            if (nodeEngine.isActive()) {
                notify(new WrongTargetException(thisAddress, null, partitionId
                        , replicaIndex, op.getClass().getName(), serviceName));
            } else {
                notify(new HazelcastInstanceNotActiveException());
            }
            return false;
        }

        targetMember = nodeEngine.getClusterService().getMember(invTarget);
        if (targetMember == null && !(isJoinOperation(op) || isWanReplicationOperation(op))) {
            notify(new TargetNotMemberException(invTarget, partitionId, op.getClass().getName(), serviceName));
            return false;
        }

        if (op.getPartitionId() != partitionId) {
            notify(new IllegalStateException("Partition id of operation: " + op.getPartitionId()
                    + " is not equal to the partition id of invocation: " + partitionId));
            return false;
        }

        if (op.getReplicaIndex() != replicaIndex) {
            notify(new IllegalStateException("Replica index of operation: " + op.getReplicaIndex()
                    + " is not equal to the replica index of invocation: " + replicaIndex));
            return false;
        }

        remote = !thisAddress.equals(invTarget);
        return true;
    }

    @Override
    public void sendResponse(Operation op, Object obj) {
        if (!RESPONSE_RECEIVED.compareAndSet(this, FALSE, TRUE)) {
            throw new ResponseAlreadySentException("NormalResponse already responseReceived for callback: " + this
                    + ", current-response: : " + obj);
        }
        notify(obj);
    }

    
    
    void notify(Object response) {
        if (response == null) {
            response = NULL_RESPONSE;
        }

        if (response instanceof CallTimeoutResponse) {
            notifyCallTimeout();
            return;
        }

        if (response instanceof ErrorResponse || response instanceof Throwable) {
            notifyError(response);
            return;
        }

        if (response instanceof NormalResponse) {
            NormalResponse normalResponse = (NormalResponse) response;
            notifyNormalResponse(normalResponse.getValue(), normalResponse.getBackupCount());
            return;
        }

        
        invocationFuture.set(response);
    }

    void notifyError(Object error) {
        assert error != null;

        Throwable cause;
        if (error instanceof Throwable) {
            cause = (Throwable) error;
        } else {
            cause = ((ErrorResponse) error).getCause();
        }

        switch (onException(cause)) {
            case CONTINUE_WAIT:
                handleContinueWait();
                break;
            case THROW_EXCEPTION:
                notifyNormalResponse(cause, 0);
                break;
            case RETRY_INVOCATION:
                if (invokeCount < tryCount) {
                    
                    handleRetry(cause);
                } else {
                    
                    notifyNormalResponse(cause, 0);
                }
                break;
            default:
                throw new IllegalStateException("Unhandled ExceptionAction");
        }
    }

    void notifyNormalResponse(Object value, int expectedBackups) {
        if (value == null) {
            value = NULL_RESPONSE;
        }

        
        

        if (expectedBackups > backupsCompleted) {
            
            

            this.pendingResponseReceivedMillis = Clock.currentTimeMillis();

            this.backupsExpected = expectedBackups;

            
            
            this.pendingResponse = value;

            if (backupsCompleted != expectedBackups) {
                
                return;
            }
        }

        
        
        
        invocationFuture.set(value);
    }

    @SuppressFBWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "We have the guarantee that only a single thread at any given time can change the volatile field")
    void notifyCallTimeout() {
        if (logger.isFinestEnabled()) {
            logger.finest("Call timed-out during wait-notify phase, retrying call: " + toString());
        }

        if (op instanceof WaitSupport) {
            
            long waitTimeout = op.getWaitTimeout();
            waitTimeout -= callTimeout;
            op.setWaitTimeout(waitTimeout);
        }

        invokeCount--;
        handleRetry("invocation timeout");
    }

    void notifySingleBackupComplete() {
        int newBackupsCompleted = BACKUPS_COMPLETED.incrementAndGet(this);

        Object pendingResponse = this.pendingResponse;
        if (pendingResponse == null) {
            
            return;
        }

        
        int backupsExpected = this.backupsExpected;
        if (backupsExpected < newBackupsCompleted) {
            
            return;
        }

        if (backupsExpected != newBackupsCompleted) {
            
            return;
        }

        
        
        invocationFuture.set(pendingResponse);
    }

    boolean checkInvocationTimeout() {
        long maxCallTimeout = invocationFuture.getMaxCallTimeout();
        long expirationTime = op.getInvocationTime() + maxCallTimeout;

        boolean hasResponse = pendingResponse != null;
        boolean hasWaitingThreads = invocationFuture.getWaitingThreadsCount() > 0;
        boolean notExpired = maxCallTimeout == Long.MAX_VALUE
                || expirationTime < 0
                || expirationTime >= Clock.currentTimeMillis();

        if (hasResponse || hasWaitingThreads || notExpired) {
            return false;
        }

        operationService.getIsStillRunningService().timeoutInvocationIfNotExecuting(this);
        return true;
    }

    Object newOperationTimeoutException(long totalTimeoutMs) {
        boolean hasResponse = this.pendingResponse != null;
        int backupsExpected = this.backupsExpected;
        int backupsCompleted = this.backupsCompleted;

        if (hasResponse) {
            return new OperationTimeoutException("No response for " + totalTimeoutMs + " ms."
                    + " Aborting invocation! " + toString()
                    + " Not all backups have completed! "
                    + " backups-expected:" + backupsExpected
                    + " backups-completed: " + backupsCompleted);
        } else {
            return new OperationTimeoutException("No response for " + totalTimeoutMs + " ms."
                    + " Aborting invocation! " + toString()
                    + " No response has been received! "
                    + " backups-expected:" + backupsExpected
                    + " backups-completed: " + backupsCompleted);
        }
    }

    private void handleContinueWait() {
        invocationFuture.set(WAIT_RESPONSE);
    }

    private void handleRetry(Object cause) {
        if (invokeCount > LOG_MAX_INVOCATION_COUNT && invokeCount % LOG_INVOCATION_COUNT_MOD == 0) {
            if (logger.isLoggable(WARNING)) {
                logger.warning("Retrying invocation: " + toString() + ", Reason: " + cause);
            }
        }

        operationService.invocationsRegistry.deregister(this);

        if (invocationFuture.interrupted) {
            invocationFuture.set(INTERRUPTED_RESPONSE);
            return;
        }

        invocationFuture.set(WAIT_RESPONSE);
        ExecutionService ex = nodeEngine.getExecutionService();
        
        if (invokeCount < MAX_FAST_INVOCATION_COUNT) {
            operationService.asyncExecutor.execute(this);
        } else {
            ex.schedule(ASYNC_EXECUTOR, this, tryPauseMillis, TimeUnit.MILLISECONDS);
        }
    }

    boolean checkBackupTimeout(long timeoutMillis) {
        
        
        
        boolean allBackupsComplete = backupsExpected == backupsCompleted;
        long responseReceivedMillis = pendingResponseReceivedMillis;

        
        long expirationTime = responseReceivedMillis + timeoutMillis;
        boolean timeout = expirationTime > 0 && expirationTime < Clock.currentTimeMillis();

        
        
        boolean responseReceived = pendingResponse != null;

        if (allBackupsComplete || !responseReceived || !timeout) {
            return false;
        }

        boolean targetDead = nodeEngine.getClusterService().getMember(invTarget) == null;
        if (targetDead) {
            
            
            
            
            
            
            resetAndReInvoke();
            return false;
        }

         
        invocationFuture.set(pendingResponse);
        return true;
    }

    private void resetAndReInvoke() {
        operationService.invocationsRegistry.deregister(this);
        invokeCount = 0;
        pendingResponse = null;
        pendingResponseReceivedMillis = -1;
        backupsExpected = 0;
        backupsCompleted = 0;
        doInvoke(false);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder();
        sb.append("Invocation");
        sb.append("{ serviceName='").append(serviceName).append('\'');
        sb.append(", op=").append(op);
        sb.append(", partitionId=").append(partitionId);
        sb.append(", replicaIndex=").append(replicaIndex);
        sb.append(", tryCount=").append(tryCount);
        sb.append(", tryPauseMillis=").append(tryPauseMillis);
        sb.append(", invokeCount=").append(invokeCount);
        sb.append(", callTimeout=").append(callTimeout);
        sb.append(", target=").append(invTarget);
        sb.append(", backupsExpected=").append(backupsExpected);
        sb.append(", backupsCompleted=").append(backupsCompleted);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.spi.impl.eventservice.impl;

import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.spi.EventFilter;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.eventservice.InternalEventService;
import com.hazelcast.spi.impl.eventservice.impl.operations.DeregistrationOperation;
import com.hazelcast.spi.impl.eventservice.impl.operations.PostJoinRegistrationOperation;
import com.hazelcast.spi.impl.eventservice.impl.operations.RegistrationOperation;
import com.hazelcast.spi.impl.eventservice.impl.operations.SendEventOperation;
import com.hazelcast.util.ConcurrencyUtil;
import com.hazelcast.util.ConstructorFunction;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.executor.StripedExecutor;

import java.io.Closeable;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.LinkedList;
import java.util.UUID;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
import java.util.logging.Level;

import static com.hazelcast.util.EmptyStatement.ignore;
import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;

public class EventServiceImpl implements InternalEventService {

    private static final EventRegistration[] EMPTY_REGISTRATIONS = new EventRegistration[0];

    private static final int EVENT_SYNC_FREQUENCY = 100000;
    private static final int SEND_RETRY_COUNT = 50;
    private static final int SEND_EVENT_TIMEOUT_SECONDS = 5;
    private static final int REGISTRATION_TIMEOUT_SECONDS = 5;
    private static final int DEREGISTER_TIMEOUT_SECONDS = 5;
    private static final int WARNING_LOG_FREQUENCY = 1000;

    final ILogger logger;
    final NodeEngineImpl nodeEngine;

    private final ExceptionHandler registrationExceptionHandler;
    private final ExceptionHandler deregistrationExceptionHandler;
    private final ConcurrentMap<String, EventServiceSegment> segments;
    private final StripedExecutor eventExecutor;
    private final int eventQueueTimeoutMs;
    private final int eventThreadCount;
    private final int eventQueueCapacity;
    private final AtomicLong totalFailures = new AtomicLong();

    public EventServiceImpl(NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.logger = nodeEngine.getLogger(EventService.class.getName());
        final Node node = nodeEngine.getNode();
        GroupProperties groupProperties = node.getGroupProperties();
        this.eventThreadCount = groupProperties.EVENT_THREAD_COUNT.getInteger();
        this.eventQueueCapacity = groupProperties.EVENT_QUEUE_CAPACITY.getInteger();
        this.eventQueueTimeoutMs = groupProperties.EVENT_QUEUE_TIMEOUT_MILLIS.getInteger();
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        this.eventExecutor = new StripedExecutor(
                node.getLogger(EventServiceImpl.class),
                threadGroup.getThreadNamePrefix("event"),
                threadGroup.getInternalThreadGroup(),
                eventThreadCount,
                eventQueueCapacity);
        this.registrationExceptionHandler
                = new FutureUtilExceptionHandler(logger, "Member left while registering listener...");
        this.deregistrationExceptionHandler
                = new FutureUtilExceptionHandler(logger, "Member left while de-registering listener...");
        this.segments = new ConcurrentHashMap<String, EventServiceSegment>();
    }

    @Override
    public void close(EventRegistration eventRegistration) {
        Registration registration = (Registration) eventRegistration;

        Object listener = registration.getListener();
        if (!(listener instanceof Closeable)) {
            return;
        }

        try {
            ((Closeable) listener).close();
        } catch (IOException e) {
            EmptyStatement.ignore(e);
        }
    }

    @Override
    public int getEventThreadCount() {
        return eventThreadCount;
    }

    @Override
    public int getEventQueueCapacity() {
        return eventQueueCapacity;
    }

    @Override
    public int getEventQueueSize() {
        return eventExecutor.getWorkQueueSize();
    }

    @Override
    public EventRegistration registerLocalListener(String serviceName, String topic, Object listener) {
        return registerListenerInternal(serviceName, topic, new EmptyFilter(), listener, true);
    }

    @Override
    public EventRegistration registerLocalListener(String serviceName, String topic, EventFilter filter, Object listener) {
        return registerListenerInternal(serviceName, topic, filter, listener, true);
    }

    @Override
    public EventRegistration registerListener(String serviceName, String topic, Object listener) {
        return registerListenerInternal(serviceName, topic, new EmptyFilter(), listener, false);
    }

    @Override
    public EventRegistration registerListener(String serviceName, String topic, EventFilter filter, Object listener) {
        return registerListenerInternal(serviceName, topic, filter, listener, false);
    }

    private EventRegistration registerListenerInternal(String serviceName, String topic, EventFilter filter,
                                                       Object listener, boolean localOnly) {
        if (listener == null) {
            throw new IllegalArgumentException("Listener required!");
        }
        if (filter == null) {
            throw new IllegalArgumentException("EventFilter required!");
        }
        EventServiceSegment segment = getSegment(serviceName, true);
        Registration reg = new Registration(UUID.randomUUID().toString(), serviceName, topic, filter,
                nodeEngine.getThisAddress(), listener, localOnly);
        if (!segment.addRegistration(topic, reg)) {
            return null;
        }

        if (!localOnly) {
            invokeRegistrationOnOtherNodes(serviceName, reg);
        }
        return reg;
    }

    public boolean handleRegistration(Registration reg) {
        if (nodeEngine.getThisAddress().equals(reg.getSubscriber())) {
            return false;
        }
        EventServiceSegment segment = getSegment(reg.getServiceName(), true);
        return segment.addRegistration(reg.getTopic(), reg);
    }

    @Override
    public boolean deregisterListener(String serviceName, String topic, Object id) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            final Registration reg = segment.removeRegistration(topic, String.valueOf(id));
            if (reg != null && !reg.isLocalOnly()) {
                invokeDeregistrationOnOtherNodes(serviceName, topic, String.valueOf(id));
            }
            return reg != null;
        }
        return false;
    }

    @Override
    public void deregisterAllListeners(String serviceName, String topic) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            segment.removeRegistrations(topic);
        }
    }

    private void invokeRegistrationOnOtherNodes(String serviceName, Registration reg) {
        OperationService operationService = nodeEngine.getOperationService();
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        Collection<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                RegistrationOperation operation = new RegistrationOperation(reg);
                Future f = operationService.invokeOnTarget(serviceName, operation, member.getAddress());
                calls.add(f);
            }
        }

        waitWithDeadline(calls, REGISTRATION_TIMEOUT_SECONDS, TimeUnit.SECONDS, registrationExceptionHandler);
    }

    private void invokeDeregistrationOnOtherNodes(String serviceName, String topic, String id) {
        OperationService operationService = nodeEngine.getOperationService();
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        Collection<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                DeregistrationOperation operation = new DeregistrationOperation(topic, id);
                Future f = operationService.invokeOnTarget(serviceName, operation, member.getAddress());
                calls.add(f);
            }
        }

        waitWithDeadline(calls, DEREGISTER_TIMEOUT_SECONDS, TimeUnit.SECONDS, deregistrationExceptionHandler);
    }

    @Override
    public EventRegistration[] getRegistrationsAsArray(String serviceName, String topic) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            final Collection<Registration> registrations = segment.getRegistrations(topic, false);
            if (registrations == null || registrations.isEmpty()) {
                return EMPTY_REGISTRATIONS;
            } else {
                return registrations.toArray(new Registration[registrations.size()]);
            }
        }
        return EMPTY_REGISTRATIONS;
    }

    @Override
    public Collection<EventRegistration> getRegistrations(String serviceName, String topic) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            final Collection<Registration> registrations = segment.getRegistrations(topic, false);
            if (registrations == null || registrations.isEmpty()) {
                return Collections.<EventRegistration>emptySet();
            } else {
                return Collections.<EventRegistration>unmodifiableCollection(registrations);
            }
        }
        return Collections.emptySet();
    }

    @Override
    public boolean hasEventRegistration(String serviceName, String topic) {
        final EventServiceSegment segment = getSegment(serviceName, false);
        if (segment != null) {
            return segment.hasRegistration(topic);
        }
        return false;
    }

    @Override
    public void publishEvent(String serviceName, String topic, Object event, int orderKey) {
        Collection<EventRegistration> registrations = getRegistrations(serviceName, topic);
        publishEvent(serviceName, registrations, event, orderKey);
    }

    @Override
    public void publishEvent(String serviceName, EventRegistration registration, Object event, int orderKey) {
        if (!(registration instanceof Registration)) {
            throw new IllegalArgumentException();
        }
        if (isLocal(registration)) {
            executeLocal(serviceName, event, registration, orderKey);
        } else {
            final Address subscriber = registration.getSubscriber();
            sendEventPacket(subscriber, new EventPacket(registration.getId(), serviceName, event), orderKey);
        }
    }

    @Override
    public void publishEvent(String serviceName, Collection<EventRegistration> registrations, Object event, int orderKey) {
        Data eventData = null;
        for (EventRegistration registration : registrations) {
            if (!(registration instanceof Registration)) {
                throw new IllegalArgumentException();
            }
            if (isLocal(registration)) {
                executeLocal(serviceName, event, registration, orderKey);
                continue;
            }

            if (eventData == null) {
                eventData = nodeEngine.toData(event);
            }
            EventPacket eventPacket = new EventPacket(registration.getId(), serviceName, eventData);
            sendEventPacket(registration.getSubscriber(), eventPacket, orderKey);
        }
    }

    @Override
    public void publishRemoteEvent(String serviceName, Collection<EventRegistration> registrations, Object event, int orderKey) {
        if (registrations.isEmpty()) {
            return;
        }
        Data eventData = nodeEngine.toData(event);
        for (EventRegistration registration : registrations) {
            if (!(registration instanceof Registration)) {
                throw new IllegalArgumentException();
            }
            if (isLocal(registration)) {
                continue;
            }
            EventPacket eventPacket = new EventPacket(registration.getId(), serviceName, eventData);
            sendEventPacket(registration.getSubscriber(), eventPacket, orderKey);
        }
    }

    private void executeLocal(String serviceName, Object event, EventRegistration registration, int orderKey) {
        if (nodeEngine.isActive()) {
            Registration reg = (Registration) registration;
            try {
                if (reg.getListener() != null) {
                    eventExecutor.execute(new LocalEventDispatcher(this, serviceName, event, reg.getListener()
                            , orderKey, eventQueueTimeoutMs));
                } else {
                    logger.warning("Something seems wrong! Listener instance is null! -> " + reg);
                }
            } catch (RejectedExecutionException e) {
                if (eventExecutor.isLive()) {
                    logFailure("EventQueue overloaded! %s failed to publish to %s:%s",
                            event, reg.getServiceName(), reg.getTopic());
                }
            }
        }
    }

    private void sendEventPacket(Address subscriber, EventPacket eventPacket, int orderKey) {
        final String serviceName = eventPacket.getServiceName();
        final EventServiceSegment segment = getSegment(serviceName, true);
        boolean sync = segment.incrementPublish() % EVENT_SYNC_FREQUENCY == 0;

        if (sync) {
            SendEventOperation op = new SendEventOperation(eventPacket, orderKey);
            Future f = nodeEngine.getOperationService()
                    .createInvocationBuilder(serviceName, op, subscriber)
                    .setTryCount(SEND_RETRY_COUNT).invoke();
            try {
                f.get(SEND_EVENT_TIMEOUT_SECONDS, TimeUnit.SECONDS);
            } catch (Exception ignored) {
                ignore(ignored);
            }
        } else {
            final Packet packet = new Packet(nodeEngine.toData(eventPacket), orderKey);
            packet.setHeader(Packet.HEADER_EVENT);
            if (!nodeEngine.getPacketTransceiver().transmit(packet, subscriber)) {
                if (nodeEngine.isActive()) {
                    logFailure("IO Queue overloaded! Failed to send event packet to: %s", subscriber);
                }
            }
        }
    }

    public EventServiceSegment getSegment(String service, boolean forceCreate) {
        EventServiceSegment segment = segments.get(service);
        if (segment == null && forceCreate) {
            ConstructorFunction<String, EventServiceSegment> func
                    = new ConstructorFunction<String, EventServiceSegment>() {
                @Override
                public EventServiceSegment createNew(String key) {
                    return new EventServiceSegment(key, nodeEngine.getService(key));
                }
            };
            return ConcurrencyUtil.getOrPutIfAbsent(segments, service, func);
        }
        return segment;
    }

    boolean isLocal(EventRegistration reg) {
        return nodeEngine.getThisAddress().equals(reg.getSubscriber());
    }

    @Override
    public void executeEventCallback(Runnable callback) {
        if (nodeEngine.isActive()) {
            try {
                eventExecutor.execute(callback);
            } catch (RejectedExecutionException e) {
                if (eventExecutor.isLive()) {
                    logFailure("EventQueue overloaded! Failed to execute event callback: %s", callback);
                }
            }
        }
    }

    @Override
    public void handleEvent(Packet packet) {
        try {
            eventExecutor.execute(new RemoteEventPacketProcessor(this, packet));
        } catch (RejectedExecutionException e) {
            if (eventExecutor.isLive()) {
                Connection conn = packet.getConn();
                String endpoint = conn.getEndPoint() != null ? conn.getEndPoint().toString() : conn.toString();
                logFailure("EventQueue overloaded! Failed to process event packet sent from: %s", endpoint);
            }
        }
    }

    public PostJoinRegistrationOperation getPostJoinOperation() {
        final Collection<Registration> registrations = new LinkedList<Registration>();
        for (EventServiceSegment segment : segments.values()) {
            
            for (Registration reg : (Iterable<Registration>) segment.getRegistrationIdMap().values()) {
                if (!reg.isLocalOnly()) {
                    registrations.add(reg);
                }
            }
        }
        return registrations.isEmpty() ? null : new PostJoinRegistrationOperation(registrations);
    }

    public void shutdown() {
        logger.finest("Stopping event executor...");
        eventExecutor.shutdown();
        for (EventServiceSegment segment : segments.values()) {
            segment.clear();
        }
        segments.clear();
    }

    public void onMemberLeft(MemberImpl member) {
        final Address address = member.getAddress();
        for (EventServiceSegment segment : segments.values()) {
            segment.onMemberLeft(address);
        }
    }

    private void logFailure(String message, Object... args) {
        Level level = totalFailures.getAndIncrement() % WARNING_LOG_FREQUENCY == 0
                ? Level.WARNING : Level.FINEST;

        if (logger.isLoggable(level)) {
            logger.log(level, String.format(message, args));
        }
    }

}

<code block>


package com.hazelcast.spi.impl.eventservice.impl;

import com.hazelcast.nio.Address;
import com.hazelcast.spi.EventFilter;
import com.hazelcast.spi.ListenerWrapperEventFilter;
import com.hazelcast.spi.NotifiableEventListener;
import com.hazelcast.util.ConcurrencyUtil;
import com.hazelcast.util.ConstructorFunction;

import java.util.Collection;
import java.util.Collections;
import java.util.Iterator;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.atomic.AtomicLong;

public class EventServiceSegment<S> {

    private final String serviceName;
    private final S service;

    private final ConcurrentMap<String, Collection<Registration>> registrations
            = new ConcurrentHashMap<String, Collection<Registration>>();
    private final ConcurrentMap<String, Registration> registrationIdMap
            = new ConcurrentHashMap<String, Registration>();
    private final AtomicLong totalPublishes = new AtomicLong();

    public EventServiceSegment(String serviceName, S service) {
        this.serviceName = serviceName;
        this.service = service;
    }

    private void pingNotifiableEventListenerIfAvailable(String topic, Registration registration, boolean register) {
        Object listener = registration.getListener();
        if (!(listener instanceof NotifiableEventListener)) {
            EventFilter filter = registration.getFilter();
            if (filter instanceof ListenerWrapperEventFilter) {
                listener = ((ListenerWrapperEventFilter) filter).getListener();
            }
        }
        if (listener instanceof NotifiableEventListener) {
            NotifiableEventListener notifiableEventListener = (NotifiableEventListener) listener;
            if (register) {
                notifiableEventListener.onRegister(service, serviceName, topic, registration);
            } else {
                notifiableEventListener.onDeregister(service, serviceName, topic, registration);
            }
        }
    }

    public Collection<Registration> getRegistrations(String topic, boolean forceCreate) {
        Collection<Registration> listenerList = registrations.get(topic);
        if (listenerList == null && forceCreate) {
            ConstructorFunction<String, Collection<Registration>> func
                    = new ConstructorFunction<String, Collection<Registration>>() {
                public Collection<Registration> createNew(String key) {
                    return Collections.newSetFromMap(new ConcurrentHashMap<Registration, Boolean>());
                }
            };
            return ConcurrencyUtil.getOrPutIfAbsent(registrations, topic, func);
        }
        return listenerList;
    }

    public ConcurrentMap<String, Registration> getRegistrationIdMap() {
        return registrationIdMap;
    }

    public boolean addRegistration(String topic, Registration registration) {
        final Collection<Registration> registrations = getRegistrations(topic, true);
        if (registrations.add(registration)) {
            registrationIdMap.put(registration.getId(), registration);
            pingNotifiableEventListenerIfAvailable(topic, registration, true);
            return true;
        }
        return false;
    }

    public Registration removeRegistration(String topic, String id) {
        final Registration registration = registrationIdMap.remove(id);
        if (registration != null) {
            final Collection<Registration> all = registrations.get(topic);
            if (all != null) {
                all.remove(registration);
            }
            pingNotifiableEventListenerIfAvailable(topic, registration, false);
        }
        return registration;
    }

    void removeRegistrations(String topic) {
        final Collection<Registration> all = registrations.remove(topic);
        if (all != null) {
            for (Registration reg : all) {
                registrationIdMap.remove(reg.getId());
                pingNotifiableEventListenerIfAvailable(topic, reg, false);
            }
        }
    }

    void clear() {
        for (Collection<Registration> all : registrations.values()) {
            Iterator<Registration> iter = all.iterator();
            while (iter.hasNext()) {
                Registration reg = iter.next();
                iter.remove();
                registrationIdMap.remove(reg.getId());
                pingNotifiableEventListenerIfAvailable(reg.getTopic(), reg, false);
            }
        }
    }

    void onMemberLeft(Address address) {
        for (Collection<Registration> all : registrations.values()) {
            Iterator<Registration> iter = all.iterator();
            while (iter.hasNext()) {
                Registration reg = iter.next();
                if (address.equals(reg.getSubscriber())) {
                    iter.remove();
                    registrationIdMap.remove(reg.getId());
                    pingNotifiableEventListenerIfAvailable(reg.getTopic(), reg, false);
                }
            }
        }
    }

    long incrementPublish() {
        return totalPublishes.incrementAndGet();
    }

    boolean hasRegistration(String topic) {
        Collection<Registration> topicRegistrations = registrations.get(topic);
        return !(topicRegistrations == null || topicRegistrations.isEmpty());
    }
}

<code block>


package com.hazelcast.spi.impl.executionservice.impl;

import com.hazelcast.config.ExecutorConfig;
import com.hazelcast.core.ICompletableFuture;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.executionservice.InternalExecutionService;
import com.hazelcast.util.ConcurrencyUtil;
import com.hazelcast.util.ConstructorFunction;
import com.hazelcast.util.executor.CachedExecutorServiceDelegate;
import com.hazelcast.util.executor.ExecutorType;
import com.hazelcast.util.executor.ManagedExecutorService;
import com.hazelcast.util.executor.NamedThreadPoolExecutor;
import com.hazelcast.util.executor.PoolExecutorThreadFactory;
import com.hazelcast.util.executor.SingleExecutorThreadFactory;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.util.concurrent.Callable;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.RejectedExecutionHandler;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.SynchronousQueue;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.util.EmptyStatement.ignore;

public final class ExecutionServiceImpl implements InternalExecutionService {

    private static final int CORE_POOL_SIZE = 3;
    private static final long KEEP_ALIVE_TIME = 60L;
    private static final long INITIAL_DELAY = 1000;
    private static final long PERIOD = 100;
    private static final int BEGIN_INDEX = 3;
    private static final long AWAIT_TIME = 3;
    private static final int POOL_MULTIPLIER = 2;
    private static final int QUEUE_MULTIPLIER = 100000;

    private final NodeEngineImpl nodeEngine;
    private final ExecutorService cachedExecutorService;
    private final ScheduledExecutorService scheduledExecutorService;
    private final ScheduledExecutorService defaultScheduledExecutorServiceDelegate;
    private final ILogger logger;
    private final CompletableFutureTask completableFutureTask;

    private final ConcurrentMap<String, ManagedExecutorService> executors
            = new ConcurrentHashMap<String, ManagedExecutorService>();

    private final ConstructorFunction<String, ManagedExecutorService> constructor =
            new ConstructorFunction<String, ManagedExecutorService>() {
                @Override
                public ManagedExecutorService createNew(String name) {
                    final ExecutorConfig cfg = nodeEngine.getConfig().findExecutorConfig(name);
                    final int queueCapacity = cfg.getQueueCapacity() <= 0 ? Integer.MAX_VALUE : cfg.getQueueCapacity();
                    return createExecutor(name, cfg.getPoolSize(), queueCapacity, ExecutorType.CACHED);
                }
            };

    public ExecutionServiceImpl(NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        final Node node = nodeEngine.getNode();
        logger = node.getLogger(ExecutionService.class.getName());
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        final ThreadFactory threadFactory = new PoolExecutorThreadFactory(threadGroup, "cached");

        cachedExecutorService = new ThreadPoolExecutor(
                CORE_POOL_SIZE, Integer.MAX_VALUE, KEEP_ALIVE_TIME, TimeUnit.SECONDS,
                new SynchronousQueue<Runnable>(), threadFactory, new RejectedExecutionHandler() {
            public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Node is shutting down; discarding the task: " + r);
                }
            }
        }
        );

        scheduledExecutorService = new ScheduledThreadPoolExecutor(1, new SingleExecutorThreadFactory(threadGroup, "scheduled"));
        enableRemoveOnCancelIfAvailable();

        final int coreSize = Runtime.getRuntime().availableProcessors();
        
        register(SYSTEM_EXECUTOR, coreSize, Integer.MAX_VALUE, ExecutorType.CACHED);
        register(SCHEDULED_EXECUTOR, coreSize * POOL_MULTIPLIER, coreSize * QUEUE_MULTIPLIER, ExecutorType.CACHED);
        defaultScheduledExecutorServiceDelegate = getScheduledExecutor(SCHEDULED_EXECUTOR);

        
        completableFutureTask = new CompletableFutureTask();
        scheduleWithFixedDelay(completableFutureTask, INITIAL_DELAY, PERIOD, TimeUnit.MILLISECONDS);
    }

    private void enableRemoveOnCancelIfAvailable() {
        try {
            final Method m = scheduledExecutorService.getClass().getMethod("setRemoveOnCancelPolicy", boolean.class);
            m.invoke(scheduledExecutorService, true);
        } catch (NoSuchMethodException ignored) {
            ignore(ignored);
        } catch (InvocationTargetException ignored) {
            ignore(ignored);
        } catch (IllegalAccessException ignored) {
            ignore(ignored);
        }
    }

    @Override
    public ManagedExecutorService register(String name, int defaultPoolSize, int defaultQueueCapacity,
                                           ExecutorType type) {
        ExecutorConfig cfg = nodeEngine.getConfig().getExecutorConfigs().get(name);

        int poolSize = defaultPoolSize;
        int queueCapacity = defaultQueueCapacity;
        if (cfg != null) {
            poolSize = cfg.getPoolSize();
            if (cfg.getQueueCapacity() <= 0) {
                queueCapacity = Integer.MAX_VALUE;
            } else {
                queueCapacity = cfg.getQueueCapacity();
            }
        }

        ManagedExecutorService executor = createExecutor(name, poolSize, queueCapacity, type);
        if (executors.putIfAbsent(name, executor) != null) {
            throw new IllegalArgumentException("ExecutorService['" + name + "'] already exists!");
        }
        return executor;
    }

    private ManagedExecutorService createExecutor(String name, int poolSize, int queueCapacity, ExecutorType type) {
        ManagedExecutorService executor;
        if (type == ExecutorType.CACHED) {
            executor = new CachedExecutorServiceDelegate(nodeEngine, name, cachedExecutorService, poolSize, queueCapacity);
        } else if (type == ExecutorType.CONCRETE) {
            Node node = nodeEngine.getNode();
            String internalName = name.startsWith("hz:") ? name.substring(BEGIN_INDEX) : name;
            HazelcastThreadGroup hazelcastThreadGroup = node.getHazelcastThreadGroup();
            PoolExecutorThreadFactory threadFactory = new PoolExecutorThreadFactory(hazelcastThreadGroup,
                    hazelcastThreadGroup.getThreadPoolNamePrefix(internalName));
            NamedThreadPoolExecutor pool = new NamedThreadPoolExecutor(name, poolSize, poolSize,
                    KEEP_ALIVE_TIME, TimeUnit.SECONDS,
                    new LinkedBlockingQueue<Runnable>(queueCapacity),
                    threadFactory
            );
            pool.allowCoreThreadTimeOut(true);
            executor = pool;
        } else {
            throw new IllegalArgumentException("Unknown executor type: " + type);
        }
        return executor;
    }

    @Override
    public ManagedExecutorService getExecutor(String name) {
        return ConcurrencyUtil.getOrPutIfAbsent(executors, name, constructor);
    }

    @Override
    public <V> ICompletableFuture<V> asCompletableFuture(Future<V> future) {
        if (future == null) {
            throw new IllegalArgumentException("future must not be null");
        }
        if (future instanceof ICompletableFuture) {
            return (ICompletableFuture<V>) future;
        }
        return registerCompletableFuture(future);
    }

    @Override
    public void execute(String name, Runnable command) {
        getExecutor(name).execute(command);
    }

    @Override
    public Future<?> submit(String name, Runnable task) {
        return getExecutor(name).submit(task);
    }

    @Override
    public <T> Future<T> submit(String name, Callable<T> task) {
        return getExecutor(name).submit(task);
    }

    @Override
    public ScheduledFuture<?> schedule(Runnable command, long delay, TimeUnit unit) {
        return defaultScheduledExecutorServiceDelegate.schedule(command, delay, unit);
    }

    @Override
    public ScheduledFuture<?> schedule(String name, Runnable command, long delay, TimeUnit unit) {
        return getScheduledExecutor(name).schedule(command, delay, unit);
    }

    @Override
    public ScheduledFuture<?> scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) {
        return defaultScheduledExecutorServiceDelegate.scheduleAtFixedRate(command, initialDelay, period, unit);
    }

    @Override
    public ScheduledFuture<?> scheduleAtFixedRate(String name, Runnable command, long initialDelay,
                                                  long period, TimeUnit unit) {
        return getScheduledExecutor(name).scheduleAtFixedRate(command, initialDelay, period, unit);
    }

    @Override
    public ScheduledFuture<?> scheduleWithFixedDelay(Runnable command, long initialDelay, long period, TimeUnit unit) {
        return defaultScheduledExecutorServiceDelegate.scheduleWithFixedDelay(command, initialDelay, period, unit);
    }

    @Override
    public ScheduledFuture<?> scheduleWithFixedDelay(String name, Runnable command, long initialDelay,
                                                     long period, TimeUnit unit) {
        return getScheduledExecutor(name).scheduleWithFixedDelay(command, initialDelay, period, unit);
    }

    @Override
    public ScheduledExecutorService getDefaultScheduledExecutor() {
        return defaultScheduledExecutorServiceDelegate;
    }

    @Override
    public ScheduledExecutorService getScheduledExecutor(String name) {
        return new ScheduledExecutorServiceDelegate(scheduledExecutorService, getExecutor(name));
    }

    public void shutdown() {
        logger.finest("Stopping executors...");
        for (ExecutorService executorService : executors.values()) {
            executorService.shutdown();
        }
        scheduledExecutorService.shutdownNow();
        cachedExecutorService.shutdown();
        try {
            scheduledExecutorService.awaitTermination(AWAIT_TIME, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            logger.finest(e);
        }
        try {
            cachedExecutorService.awaitTermination(AWAIT_TIME, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            logger.finest(e);
        }
        executors.clear();
    }

    @Override
    public void shutdownExecutor(String name) {
        final ExecutorService ex = executors.remove(name);
        if (ex != null) {
            ex.shutdown();
        }
    }

    private <V> ICompletableFuture<V> registerCompletableFuture(Future<V> future) {
        CompletableFutureEntry<V> entry = new CompletableFutureEntry<V>(future, nodeEngine);
        completableFutureTask.registerCompletableFutureEntry(entry);
        return entry.completableFuture;
    }
}

<code block>


package com.hazelcast.spi.impl.operationexecutor;

import com.hazelcast.nio.Packet;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;


public interface OperationExecutor {

    
    @Deprecated
    int getRunningOperationCount();

    
    @Deprecated
    int getOperationExecutorQueueSize();

    
    @Deprecated
    int getPriorityOperationExecutorQueueSize();

    
    @Deprecated
    int getResponseQueueSize();

    
    @Deprecated
    int getPartitionOperationThreadCount();

    
    @Deprecated
    int getGenericOperationThreadCount();

    
    @Deprecated
    void dumpPerformanceMetrics(StringBuffer sb);

    
    OperationRunner[] getPartitionOperationRunners();

    
    OperationRunner[] getGenericOperationRunners();

    
    void execute(Operation op);

    
    void execute(PartitionSpecificRunnable task);

    
    void execute(Packet packet);

    
    void runOnCallingThread(Operation op);

    
    void runOnCallingThreadIfPossible(Operation op);

    
    @Deprecated
    boolean isAllowedToRunInCurrentThread(Operation op);

    
    boolean isOperationThread();

    
    boolean isInvocationAllowedFromCurrentThread(Operation op, boolean isAsync);

    
    void shutdown();

}

<code block>


package com.hazelcast.spi.impl.operationexecutor.classic;

import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.NodeExtension;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Packet;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.operationexecutor.OperationRunner;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.util.executor.HazelcastManagedThread;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.util.concurrent.TimeUnit;

import static com.hazelcast.instance.OutOfMemoryErrorDispatcher.inspectOutputMemoryError;


public abstract class OperationThread extends HazelcastManagedThread {

    final int threadId;
    final ScheduleQueue scheduleQueue;
    
    volatile long processedCount;

    private final NodeExtension nodeExtension;
    private final ILogger logger;
    private volatile boolean shutdown;

    
    
    private OperationRunner currentOperationRunner;

    public OperationThread(String name, int threadId, ScheduleQueue scheduleQueue,
                           ILogger logger, HazelcastThreadGroup threadGroup, NodeExtension nodeExtension) {
        super(threadGroup.getInternalThreadGroup(), name);
        setContextClassLoader(threadGroup.getClassLoader());
        this.scheduleQueue = scheduleQueue;
        this.threadId = threadId;
        this.logger = logger;
        this.nodeExtension = nodeExtension;
    }

    public OperationRunner getCurrentOperationRunner() {
        return currentOperationRunner;
    }

    public abstract OperationRunner getOperationRunner(int partitionId);

    @Override
    public final void run() {
        nodeExtension.onThreadStart(this);
        try {
            doRun();
        } catch (Throwable t) {
            inspectOutputMemoryError(t);
            logger.severe(t);
        } finally {
            nodeExtension.onThreadStop(this);
        }
    }

    private void doRun() {
        for (; ; ) {
            Object task;
            try {
                task = scheduleQueue.take();
            } catch (InterruptedException e) {
                if (shutdown) {
                    return;
                }
                continue;
            }

            if (shutdown) {
                return;
            }

            process(task);
        }
    }

    @SuppressFBWarnings({"VO_VOLATILE_INCREMENT" })
    private void process(Object task) {
        processedCount++;

        if (task instanceof Operation) {
            processOperation((Operation) task);
            return;
        }

        if (task instanceof Packet) {
            processPacket((Packet) task);
            return;
        }

        if (task instanceof PartitionSpecificRunnable) {
            processPartitionSpecificRunnable((PartitionSpecificRunnable) task);
            return;
        }

        throw new IllegalStateException("Unhandled task type for task:" + task);
    }

    private void processPartitionSpecificRunnable(PartitionSpecificRunnable runnable) {
        currentOperationRunner = getOperationRunner(runnable.getPartitionId());
        try {
            currentOperationRunner.run(runnable);
        } catch (Throwable e) {
            inspectOutputMemoryError(e);
            logger.severe("Failed to process task: " + runnable + " on " + getName(), e);
        } finally {
            currentOperationRunner = null;
        }
    }

    private void processPacket(Packet packet) {
        currentOperationRunner = getOperationRunner(packet.getPartitionId());
        try {
            currentOperationRunner.run(packet);
        } catch (Throwable e) {
            inspectOutputMemoryError(e);
            logger.severe("Failed to process packet: " + packet + " on " + getName(), e);
        } finally {
            currentOperationRunner = null;
        }
    }

    private void processOperation(Operation operation) {
        currentOperationRunner = getOperationRunner(operation.getPartitionId());
        try {
            currentOperationRunner.run(operation);
        } catch (Throwable e) {
            inspectOutputMemoryError(e);
            logger.severe("Failed to process operation: " + operation + " on " + getName(), e);
        } finally {
            currentOperationRunner = null;
        }
    }

    public final void shutdown() {
        shutdown = true;
        interrupt();
    }

    public final void awaitTermination(int timeout, TimeUnit unit) throws InterruptedException {
        long timeoutMs = unit.toMillis(timeout);
        join(timeoutMs);
    }
}

<code block>


package com.hazelcast.spi.impl.operationexecutor.classic;

import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.NodeExtension;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Packet;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;
import com.hazelcast.spi.impl.operationexecutor.OperationHostileThread;
import com.hazelcast.spi.impl.operationexecutor.OperationRunner;
import com.hazelcast.spi.impl.operationexecutor.OperationRunnerFactory;
import com.hazelcast.spi.impl.operationexecutor.ResponsePacketHandler;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.util.concurrent.TimeUnit;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class ClassicOperationExecutor implements OperationExecutor {

    public static final int TERMINATION_TIMEOUT_SECONDS = 3;

    private final ILogger logger;

    
    private final PartitionOperationThread[] partitionOperationThreads;
    private final OperationRunner[] partitionOperationRunners;

    private final ScheduleQueue genericScheduleQueue;

    
    private final GenericOperationThread[] genericOperationThreads;
    private final OperationRunner[] genericOperationRunners;

    private final ResponseThread responseThread;
    private final ResponsePacketHandler responsePacketHandler;
    private final Address thisAddress;
    private final NodeExtension nodeExtension;
    private final HazelcastThreadGroup threadGroup;
    private final OperationRunner adHocOperationRunner;

    public ClassicOperationExecutor(GroupProperties properties,
                                    LoggingService loggerService,
                                    Address thisAddress,
                                    OperationRunnerFactory operationRunnerFactory,
                                    ResponsePacketHandler responsePacketHandler,
                                    HazelcastThreadGroup hazelcastThreadGroup,
                                    NodeExtension nodeExtension) {
        this.thisAddress = thisAddress;
        this.nodeExtension = nodeExtension;
        this.threadGroup = hazelcastThreadGroup;
        this.logger = loggerService.getLogger(ClassicOperationExecutor.class);
        this.responsePacketHandler = responsePacketHandler;
        this.genericScheduleQueue = new DefaultScheduleQueue();

        this.adHocOperationRunner = operationRunnerFactory.createAdHocRunner();

        this.partitionOperationRunners = initPartitionOperationRunners(properties, operationRunnerFactory);
        this.partitionOperationThreads = initPartitionThreads(properties);

        this.genericOperationRunners = initGenericOperationRunners(properties, operationRunnerFactory);
        this.genericOperationThreads = initGenericThreads();

        this.responseThread = initResponseThread();

        logger.info("Starting with " + genericOperationThreads.length + " generic operation threads and "
                + partitionOperationThreads.length + " partition operation threads.");
    }

    private OperationRunner[] initPartitionOperationRunners(GroupProperties properties, OperationRunnerFactory handlerFactory) {
        OperationRunner[] operationRunners = new OperationRunner[properties.PARTITION_COUNT.getInteger()];
        for (int partitionId = 0; partitionId < operationRunners.length; partitionId++) {
            operationRunners[partitionId] = handlerFactory.createPartitionRunner(partitionId);
        }
        return operationRunners;
    }

    private OperationRunner[] initGenericOperationRunners(GroupProperties properties, OperationRunnerFactory runnerFactory) {
        int genericThreadCount = properties.GENERIC_OPERATION_THREAD_COUNT.getInteger();
        if (genericThreadCount <= 0) {
            
            int coreSize = Runtime.getRuntime().availableProcessors();
            genericThreadCount = Math.max(2, coreSize / 2);
        }

        OperationRunner[] operationRunners = new OperationRunner[genericThreadCount];
        for (int partitionId = 0; partitionId < operationRunners.length; partitionId++) {
            operationRunners[partitionId] = runnerFactory.createGenericRunner();
        }
        return operationRunners;
    }

    private PartitionOperationThread[] initPartitionThreads(GroupProperties properties) {
        int threadCount = properties.PARTITION_OPERATION_THREAD_COUNT.getInteger();
        if (threadCount <= 0) {
            
            int coreSize = Runtime.getRuntime().availableProcessors();
            threadCount = Math.max(2, coreSize);
        }

        PartitionOperationThread[] threads = new PartitionOperationThread[threadCount];
        for (int threadId = 0; threadId < threads.length; threadId++) {
            String threadName = threadGroup.getThreadPoolNamePrefix("partition-operation") + threadId;
            ScheduleQueue scheduleQueue = new DefaultScheduleQueue();

            PartitionOperationThread operationThread = new PartitionOperationThread(threadName, threadId, scheduleQueue, logger,
                    threadGroup, nodeExtension, partitionOperationRunners);

            threads[threadId] = operationThread;
            operationThread.start();
        }

        
        for (int partitionId = 0; partitionId < partitionOperationRunners.length; partitionId++) {
            int threadId = partitionId % threadCount;
            Thread thread = threads[threadId];
            OperationRunner runner = partitionOperationRunners[partitionId];
            runner.setCurrentThread(thread);
        }

        return threads;
    }

    private GenericOperationThread[] initGenericThreads() {
        
        int threadCount = genericOperationRunners.length;
        GenericOperationThread[] threads = new GenericOperationThread[threadCount];

        for (int threadId = 0; threadId < threads.length; threadId++) {
            String threadName = threadGroup.getThreadPoolNamePrefix("generic-operation") + threadId;
            OperationRunner operationRunner = genericOperationRunners[threadId];

            GenericOperationThread operationThread = new GenericOperationThread(
                    threadName, threadId, genericScheduleQueue,
                    logger, threadGroup, nodeExtension, operationRunner);

            threads[threadId] = operationThread;
            operationThread.start();

            operationRunner.setCurrentThread(operationThread);
        }

        return threads;
    }

    private ResponseThread initResponseThread() {
        ResponseThread thread = new ResponseThread(threadGroup, logger, responsePacketHandler);
        thread.start();
        return thread;
    }

    @SuppressFBWarnings({"EI_EXPOSE_REP" })
    @Override
    public OperationRunner[] getPartitionOperationRunners() {
        return partitionOperationRunners;
    }

    @SuppressFBWarnings({"EI_EXPOSE_REP" })
    @Override
    public OperationRunner[] getGenericOperationRunners() {
        return genericOperationRunners;
    }

    @Override
    public boolean isAllowedToRunInCurrentThread(Operation op) {
        checkNotNull(op, "op can't be null");

        Thread currentThread = Thread.currentThread();

        
        if (currentThread instanceof OperationHostileThread) {
            return false;
        }

        int partitionId = op.getPartitionId();
        
        if (partitionId < 0) {
            return true;
        }

        
        if (!(currentThread instanceof PartitionOperationThread)) {
            return false;
        }

        PartitionOperationThread partitionThread = (PartitionOperationThread) currentThread;

        
        
        return toPartitionThreadIndex(partitionId) == partitionThread.threadId;
    }

    @Override
    public boolean isOperationThread() {
        return Thread.currentThread() instanceof OperationThread;
    }

    @Override
    public boolean isInvocationAllowedFromCurrentThread(Operation op, boolean isAsync) {
        checkNotNull(op, "op can't be null");

        Thread currentThread = Thread.currentThread();

        
        if (currentThread instanceof OperationHostileThread) {
            return false;
        }

        
        if (isAsync) {
            return true;
        }

        if (op.getPartitionId() < 0) {
            return true;
        }

        
        if (!(currentThread instanceof PartitionOperationThread)) {
            return true;
        }

        
        
        PartitionOperationThread partitionThread = (PartitionOperationThread) currentThread;
        return toPartitionThreadIndex(op.getPartitionId()) == partitionThread.threadId;
    }

    @Override
    public int getRunningOperationCount() {
        int result = 0;
        for (OperationRunner handler : partitionOperationRunners) {
            if (handler.currentTask() != null) {
                result++;
            }
        }
        for (OperationRunner handler : genericOperationRunners) {
            if (handler.currentTask() != null) {
                result++;
            }
        }
        return result;
    }

    @Override
    public int getOperationExecutorQueueSize() {
        int size = 0;

        for (PartitionOperationThread t : partitionOperationThreads) {
            size += t.scheduleQueue.normalSize();
        }

        size += genericScheduleQueue.normalSize();

        return size;
    }

    @Override
    public int getPriorityOperationExecutorQueueSize() {
        int size = 0;

        for (PartitionOperationThread t : partitionOperationThreads) {
            size += t.scheduleQueue.prioritySize();
        }

        size += genericScheduleQueue.prioritySize();
        return size;
    }

    @Override
    public int getResponseQueueSize() {
        return responseThread.workQueue.size();
    }

    @Override
    public int getPartitionOperationThreadCount() {
        return partitionOperationThreads.length;
    }

    @Override
    public int getGenericOperationThreadCount() {
        return genericOperationThreads.length;
    }

    @Override
    public void execute(Operation op) {
        checkNotNull(op, "op can't be null");

        execute(op, op.getPartitionId(), op.isUrgent());
    }

    @Override
    public void execute(PartitionSpecificRunnable task) {
        checkNotNull(task, "task can't be null");

        execute(task, task.getPartitionId(), false);
    }

    @Override
    public void runOnCallingThreadIfPossible(Operation op) {
        if (isAllowedToRunInCurrentThread(op)) {
            runOnCallingThread(op);
        } else {
            execute(op);
        }
    }

    @Override
    public void execute(Packet packet) {
        checkNotNull(packet, "packet can't be null");
        checkOpPacket(packet);

        if (packet.isHeaderSet(Packet.HEADER_RESPONSE)) {
            
            responseThread.workQueue.add(packet);
        } else {
            
            int partitionId = packet.getPartitionId();
            boolean hasPriority = packet.isUrgent();
            execute(packet, partitionId, hasPriority);
        }
    }

    private void checkOpPacket(Packet packet) {
        if (!packet.isHeaderSet(Packet.HEADER_OP)) {
            throw new IllegalStateException("Packet " + packet + " doesn't have Packet.HEADER_OP set");
        }
    }

    @Override
    public void runOnCallingThread(Operation operation) {
        checkNotNull(operation, "operation can't be null");

        if (!isAllowedToRunInCurrentThread(operation)) {
            throw new IllegalThreadStateException("Operation '" + operation + "' cannot be run in current thread: "
                    + Thread.currentThread());
        }

        OperationRunner operationRunner = getOperationRunner(operation);
        operationRunner.run(operation);
    }

    OperationRunner getOperationRunner(Operation operation) {
        checkNotNull(operation, "operation can't be null");

        if (operation.getPartitionId() >= 0) {
            
            return partitionOperationRunners[operation.getPartitionId()];
        }

        Thread thread = Thread.currentThread();
        if (!(thread instanceof OperationThread)) {
            
            return adHocOperationRunner;
        }

        
        
        
        OperationThread operationThread = (OperationThread) thread;
        return operationThread.getCurrentOperationRunner();
    }

    private void execute(Object task, int partitionId, boolean priority) {
        ScheduleQueue scheduleQueue;

        if (partitionId < 0) {
            scheduleQueue = genericScheduleQueue;
        } else {
            OperationThread partitionOperationThread = partitionOperationThreads[toPartitionThreadIndex(partitionId)];
            scheduleQueue = partitionOperationThread.scheduleQueue;
        }

        if (priority) {
            scheduleQueue.addUrgent(task);
        } else {
            scheduleQueue.add(task);
        }
    }

    public int toPartitionThreadIndex(int partitionId) {
        return partitionId % partitionOperationThreads.length;
    }

    @Override
    public void shutdown() {
        responseThread.shutdown();
        shutdownAll(partitionOperationThreads);
        shutdownAll(genericOperationThreads);
        awaitTermination(partitionOperationThreads);
        awaitTermination(genericOperationThreads);
    }

    private static void shutdownAll(OperationThread[] operationThreads) {
        for (OperationThread thread : operationThreads) {
            thread.shutdown();
        }
    }

    private static void awaitTermination(OperationThread[] operationThreads) {
        for (OperationThread thread : operationThreads) {
            try {
                thread.awaitTermination(TERMINATION_TIMEOUT_SECONDS, TimeUnit.SECONDS);
            } catch (InterruptedException ignored) {
                Thread.currentThread().interrupt();
            }
        }
    }

    @Override
    public void dumpPerformanceMetrics(StringBuffer sb) {
        for (PartitionOperationThread operationThread : partitionOperationThreads) {
            sb.append(operationThread.getName())
                    .append(" processedCount=").append(operationThread.processedCount)
                    .append(" pendingCount=").append(operationThread.scheduleQueue.size())
                    .append('\n');
        }
        sb.append("pending generic operations ").append(genericScheduleQueue.size()).append('\n');
        for (GenericOperationThread operationThread : genericOperationThreads) {
            sb.append(operationThread.getName())
                    .append(" processedCount=").append(operationThread.processedCount).append('\n');
        }
        sb.append(responseThread.getName())
                .append(" processedCount=").append(responseThread.processedResponses)
                .append(" pendingCount=").append(responseThread.workQueue.size()).append('\n');
    }

    @Override
    public String toString() {
        return "ClassicOperationExecutor{"
                + "node=" + thisAddress
                + '}';
    }
}

<code block>


package com.hazelcast.spi.impl.proxyservice.impl;

import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.DistributedObjectListener;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PostJoinAwareService;
import com.hazelcast.spi.ProxyService;
import com.hazelcast.spi.RemoteService;
import com.hazelcast.spi.exception.DistributedObjectDestroyedException;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.proxyservice.InternalProxyService;
import com.hazelcast.spi.impl.proxyservice.impl.operations.DistributedObjectDestroyOperation;
import com.hazelcast.spi.impl.proxyservice.impl.operations.PostJoinProxyOperation;
import com.hazelcast.util.ConstructorFunction;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.FutureUtil.ExceptionHandler;
import com.hazelcast.util.UuidUtil;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.LinkedList;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.logging.Level;

import static com.hazelcast.core.DistributedObjectEvent.EventType.CREATED;
import static com.hazelcast.util.ConcurrencyUtil.getOrPutIfAbsent;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;
import static com.hazelcast.util.Preconditions.checkNotNull;

public class ProxyServiceImpl
        implements InternalProxyService, PostJoinAwareService, EventPublishingService<DistributedObjectEventPacket, Object> {

    public static final String SERVICE_NAME = "hz:core:proxyService";

    private static final ExceptionHandler DESTROY_PROXY_EXCEPTION_HANDLER = logAllExceptions(Level.WARNING);

    private static final int TRY_COUNT = 10;
    private static final long DESTROY_TIMEOUT_SECONDS = 30;

    final NodeEngineImpl nodeEngine;
    final ILogger logger;
    final ConcurrentMap<String, DistributedObjectListener> listeners =
            new ConcurrentHashMap<String, DistributedObjectListener>();

    private final ConstructorFunction<String, ProxyRegistry> registryConstructor =
            new ConstructorFunction<String, ProxyRegistry>() {
                public ProxyRegistry createNew(String serviceName) {
                    return new ProxyRegistry(ProxyServiceImpl.this, serviceName);
                }
            };

    private final ConcurrentMap<String, ProxyRegistry> registries =
            new ConcurrentHashMap<String, ProxyRegistry>();

    public ProxyServiceImpl(NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.logger = nodeEngine.getLogger(ProxyService.class.getName());
    }

    public void init() {
        nodeEngine.getEventService().registerListener(SERVICE_NAME, SERVICE_NAME, new Object());
    }

    @Override
    public int getProxyCount() {
        int count = 0;
        for (ProxyRegistry registry : registries.values()) {
            count += registry.getProxyCount();
        }

        return count;
    }

    @Override
    public void initializeDistributedObject(String serviceName, String name) {
        checkServiceNameNotNull(serviceName);
        checkObjectNameNotNull(name);

        ProxyRegistry registry = getOrCreateRegistry(serviceName);
        registry.createProxy(name, true, true);
    }

    public ProxyRegistry getOrCreateRegistry(String serviceName) {
        return getOrPutIfAbsent(registries, serviceName, registryConstructor);
    }

    @Override
    public DistributedObject getDistributedObject(String serviceName, String name) {
        checkServiceNameNotNull(serviceName);
        checkObjectNameNotNull(name);

        ProxyRegistry registry = getOrCreateRegistry(serviceName);
        return registry.getOrCreateProxy(name, true, true);
    }

    @Override
    public void destroyDistributedObject(String serviceName, String name) {
        checkServiceNameNotNull(serviceName);
        checkObjectNameNotNull(name);

        OperationService operationService = nodeEngine.getOperationService();
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        Collection<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (member.localMember()) {
                continue;
            }

            DistributedObjectDestroyOperation operation = new DistributedObjectDestroyOperation(serviceName, name);
            Future f = operationService.createInvocationBuilder(SERVICE_NAME, operation, member.getAddress())
                    .setTryCount(TRY_COUNT).invoke();
            calls.add(f);
        }

        destroyLocalDistributedObject(serviceName, name, true);

        waitWithDeadline(calls, DESTROY_TIMEOUT_SECONDS, TimeUnit.SECONDS, DESTROY_PROXY_EXCEPTION_HANDLER);
    }

    public void destroyLocalDistributedObject(String serviceName, String name, boolean fireEvent) {
        ProxyRegistry registry = registries.get(serviceName);
        if (registry != null) {
            registry.destroyProxy(name, fireEvent);
        }
        RemoteService service = nodeEngine.getService(serviceName);
        if (service != null) {
            service.destroyDistributedObject(name);
        }
        String message = "DistributedObject[" + service + " -> " + name + "] has been destroyed!";
        Throwable cause = new DistributedObjectDestroyedException(message);
        nodeEngine.getWaitNotifyService().cancelWaitingOps(serviceName, name, cause);
    }

    @Override
    public Collection<DistributedObject> getDistributedObjects(String serviceName) {
        checkServiceNameNotNull(serviceName);

        Collection<DistributedObject> result = new LinkedList<DistributedObject>();
        ProxyRegistry registry = registries.get(serviceName);
        if (registry != null) {
            registry.getDistributedObjects(result);
        }

        return result;
    }

    @Override
    public Collection<String> getDistributedObjectNames(String serviceName) {
        checkServiceNameNotNull(serviceName);

        ProxyRegistry registry = registries.get(serviceName);
        if (registry == null) {
            return Collections.EMPTY_SET;
        } else {
            return registry.getDistributedObjectNames();
        }
    }

    @Override
    public Collection<DistributedObject> getAllDistributedObjects() {
        Collection<DistributedObject> result = new LinkedList<DistributedObject>();
        for (ProxyRegistry registry : registries.values()) {
            registry.getDistributedObjects(result);
        }
        return result;
    }

    @Override
    public String addProxyListener(DistributedObjectListener distributedObjectListener) {
        String id = UuidUtil.buildRandomUuidString();
        listeners.put(id, distributedObjectListener);
        return id;
    }

    @Override
    public boolean removeProxyListener(String registrationId) {
        return listeners.remove(registrationId) != null;
    }

    @Override
    public void dispatchEvent(final DistributedObjectEventPacket eventPacket, Object ignore) {
        String serviceName = eventPacket.getServiceName();
        if (eventPacket.getEventType() == CREATED) {
            try {
                final ProxyRegistry registry = getOrCreateRegistry(serviceName);
                if (!registry.contains(eventPacket.getName())) {
                    registry.createProxy(eventPacket.getName(), false,
                            true);
                    
                }
            } catch (HazelcastInstanceNotActiveException ignored) {
                EmptyStatement.ignore(ignored);
            }
        } else {
            final ProxyRegistry registry = registries.get(serviceName);
            if (registry != null) {
                registry.destroyProxy(eventPacket.getName(), false);
            }
        }
    }

    @Override
    public Operation getPostJoinOperation() {
        Collection<ProxyInfo> proxies = new LinkedList<ProxyInfo>();
        for (ProxyRegistry registry : registries.values()) {
            registry.getProxyInfos(proxies);
        }
        return proxies.isEmpty() ? null : new PostJoinProxyOperation(proxies);
    }

    public void shutdown() {
        for (ProxyRegistry registry : registries.values()) {
            registry.destroy();
        }
        registries.clear();
        listeners.clear();
    }

    private static String checkServiceNameNotNull(String serviceName) {
        return checkNotNull(serviceName, "Service name is required!");
    }

    private static String checkObjectNameNotNull(String name) {
        return checkNotNull(name, "Object name is required!");
    }
}

<code block>


package com.hazelcast.internal.monitors;

import com.hazelcast.client.impl.ClientEngineImpl;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.instance.HazelcastInstanceImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.logging.ILogger;
import com.hazelcast.memory.GarbageCollectorStats;
import com.hazelcast.memory.MemoryStats;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.ProxyService;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;

import java.lang.management.ManagementFactory;
import java.lang.management.ThreadMXBean;
import java.util.concurrent.TimeUnit;
import java.util.logging.Level;

import static com.hazelcast.memory.MemoryStatsSupport.freePhysicalMemory;
import static com.hazelcast.memory.MemoryStatsSupport.freeSwapSpace;
import static com.hazelcast.memory.MemoryStatsSupport.totalPhysicalMemory;
import static com.hazelcast.memory.MemoryStatsSupport.totalSwapSpace;
import static com.hazelcast.util.OperatingSystemMXBeanSupport.getSystemLoadAverage;
import static com.hazelcast.util.OperatingSystemMXBeanSupport.readLongAttribute;
import static java.lang.String.format;



public class HealthMonitor extends Thread {

    private static final String[] UNITS = new String[]{"", "K", "M", "G", "T", "P", "E"};
    private static final double PERCENTAGE_MULTIPLIER = 100d;
    private static final double THRESHOLD = 70;

    private final ILogger logger;
    private final Node node;
    private final Runtime runtime;
    private final HealthMonitorLevel logLevel;
    private final int delaySeconds;
    private final ClusterServiceImpl clusterService;
    private final ExecutionService executionService;
    private final EventService eventService;
    private final InternalOperationService operationService;
    private final ProxyService proxyService;
    private final ConnectionManager connectionManager;
    private final ClientEngineImpl clientEngine;
    private final ThreadMXBean threadMxBean;

    public HealthMonitor(HazelcastInstanceImpl hazelcastInstance, HealthMonitorLevel logLevel, int delaySeconds) {
        super(hazelcastInstance.node.getHazelcastThreadGroup().getInternalThreadGroup(),
                hazelcastInstance.node.getHazelcastThreadGroup().getThreadNamePrefix("HealthMonitor"));
        setDaemon(true);

        this.node = hazelcastInstance.node;
        this.logger = node.getLogger(HealthMonitor.class);
        this.runtime = Runtime.getRuntime();
        this.logLevel = logLevel;
        this.delaySeconds = delaySeconds;
        this.threadMxBean = ManagementFactory.getThreadMXBean();
        this.clusterService = node.getClusterService();
        this.executionService = node.nodeEngine.getExecutionService();
        this.eventService = node.nodeEngine.getEventService();
        this.operationService = node.nodeEngine.getOperationService();
        this.proxyService = node.nodeEngine.getProxyService();
        this.clientEngine = node.clientEngine;
        this.connectionManager = node.connectionManager;
    }

    @Override
    public void run() {
        if (logLevel == HealthMonitorLevel.OFF) {
            return;
        }

        try {
            while (node.isActive()) {
                HealthMetrics metrics;
                switch (logLevel) {
                    case NOISY:
                        metrics = new HealthMetrics();
                        logger.log(Level.INFO, metrics.toString());
                        break;
                    case SILENT:
                        metrics = new HealthMetrics();
                        if (metrics.exceedsThreshold()) {
                            logger.log(Level.INFO, metrics.toString());
                        }
                        break;
                    default:
                        throw new IllegalStateException("unrecognized logLevel:" + logLevel);
                }

                try {
                    Thread.sleep(TimeUnit.SECONDS.toMillis(delaySeconds));
                } catch (InterruptedException e) {
                    return;
                }
            }
        } catch (OutOfMemoryError e) {
            OutOfMemoryErrorDispatcher.onOutOfMemory(e);
        }
    }

    
    private class HealthMetrics {
        private final long memoryFree;
        private final long memoryTotal;
        private final long memoryUsed;
        private final long memoryMax;
        private final double memoryUsedOfTotalPercentage;
        private final double memoryUsedOfMaxPercentage;
        
        private final double processCpuLoad;
        private final double systemLoadAverage;
        private final double systemCpuLoad;
        private final int threadCount;
        private final int peakThreadCount;
        private final long clusterTimeDiff;
        private final int asyncExecutorQueueSize;
        private final int clientExecutorQueueSize;
        private final int queryExecutorQueueSize;
        private final int scheduledExecutorQueueSize;
        private final int systemExecutorQueueSize;
        private final int eventQueueSize;
        private final int pendingInvocationsCount;
        private final double pendingInvocationsPercentage;
        private final int operationServiceOperationExecutorQueueSize;
        private final int operationServiceOperationPriorityExecutorQueueSize;
        private final int operationServiceOperationResponseQueueSize;
        private final int runningOperationsCount;
        private final int remoteOperationsCount;
        private final int proxyCount;
        private final int clientEndpointCount;
        private final int activeConnectionCount;
        private final int currentClientConnectionCount;
        private final int connectionCount;
        private final int ioExecutorQueueSize;

        
        public HealthMetrics() {
            memoryFree = runtime.freeMemory();
            memoryTotal = runtime.totalMemory();
            memoryUsed = memoryTotal - memoryFree;
            memoryMax = runtime.maxMemory();
            memoryUsedOfTotalPercentage = PERCENTAGE_MULTIPLIER * memoryUsed / memoryTotal;
            memoryUsedOfMaxPercentage = PERCENTAGE_MULTIPLIER * memoryUsed / memoryMax;
            processCpuLoad = readLongAttribute("ProcessCpuLoad", -1L);
            systemLoadAverage = getSystemLoadAverage();
            systemCpuLoad = readLongAttribute("SystemCpuLoad", -1L);
            threadCount = threadMxBean.getThreadCount();
            peakThreadCount = threadMxBean.getPeakThreadCount();
            clusterTimeDiff = clusterService.getClusterClock().getClusterTimeDiff();
            asyncExecutorQueueSize = executionService.getExecutor(ExecutionService.ASYNC_EXECUTOR).getQueueSize();
            clientExecutorQueueSize = executionService.getExecutor(ExecutionService.CLIENT_EXECUTOR).getQueueSize();
            queryExecutorQueueSize = executionService.getExecutor(ExecutionService.QUERY_EXECUTOR).getQueueSize();
            scheduledExecutorQueueSize = executionService.getExecutor(ExecutionService.SCHEDULED_EXECUTOR).getQueueSize();
            systemExecutorQueueSize = executionService.getExecutor(ExecutionService.SYSTEM_EXECUTOR).getQueueSize();
            ioExecutorQueueSize = executionService.getExecutor(ExecutionService.IO_EXECUTOR).getQueueSize();
            eventQueueSize = eventService.getEventQueueSize();
            operationServiceOperationExecutorQueueSize = operationService.getOperationExecutorQueueSize();
            operationServiceOperationPriorityExecutorQueueSize = operationService.getPriorityOperationExecutorQueueSize();
            operationServiceOperationResponseQueueSize = operationService.getResponseQueueSize();
            runningOperationsCount = operationService.getRunningOperationsCount();
            remoteOperationsCount = operationService.getRemoteOperationsCount();
            pendingInvocationsCount = operationService.getPendingInvocationCount();
            pendingInvocationsPercentage = operationService.getInvocationUsagePercentage();
            proxyCount = proxyService.getProxyCount();
            clientEndpointCount = clientEngine.getClientEndpointCount();
            activeConnectionCount = connectionManager.getActiveConnectionCount();
            currentClientConnectionCount = connectionManager.getCurrentClientConnections();
            connectionCount = connectionManager.getConnectionCount();
        }
        

        public boolean exceedsThreshold() {
            if (memoryUsedOfMaxPercentage > THRESHOLD) {
                return true;
            }

            if (processCpuLoad > THRESHOLD) {
                return true;
            }

            if (systemCpuLoad > THRESHOLD) {
                return true;
            }

            if (pendingInvocationsPercentage > THRESHOLD) {
                return true;
            }

            return false;
        }

        public String toString() {
            StringBuilder sb = new StringBuilder();
            sb.append("processors=").append(runtime.availableProcessors()).append(", ");
            sb.append("physical.memory.total=").append(numberToUnit(totalPhysicalMemory())).append(", ");
            sb.append("physical.memory.free=").append(numberToUnit(freePhysicalMemory())).append(", ");
            sb.append("swap.space.total=").append(numberToUnit(totalSwapSpace())).append(", ");
            sb.append("swap.space.free=").append(numberToUnit(freeSwapSpace())).append(", ");
            sb.append("heap.memory.used=").append(numberToUnit(memoryUsed)).append(", ");
            sb.append("heap.memory.free=").append(numberToUnit(memoryFree)).append(", ");
            sb.append("heap.memory.total=").append(numberToUnit(memoryTotal)).append(", ");
            sb.append("heap.memory.max=").append(numberToUnit(memoryMax)).append(", ");
            sb.append("heap.memory.used/total=").append(percentageString(memoryUsedOfTotalPercentage)).append(", ");
            sb.append("heap.memory.used/max=").append(percentageString(memoryUsedOfMaxPercentage)).append((", "));

            MemoryStats memoryStats = node.getNodeExtension().getMemoryStats();
            if (memoryStats.getMaxNativeMemory() > 0L) {
                sb.append("native.memory.used=").append(numberToUnit(memoryStats.getUsedNativeMemory())).append(", ");
                sb.append("native.memory.free=").append(numberToUnit(memoryStats.getFreeNativeMemory())).append(", ");
                sb.append("native.memory.total=").append(numberToUnit(memoryStats.getCommittedNativeMemory())).append(", ");
                sb.append("native.memory.max=").append(numberToUnit(memoryStats.getMaxNativeMemory())).append(", ");
            }

            GarbageCollectorStats gcStats = memoryStats.getGCStats();
            sb.append("minor.gc.count=").append(gcStats.getMinorCollectionCount()).append(", ");
            sb.append("minor.gc.time=").append(gcStats.getMinorCollectionTime()).append("ms, ");
            sb.append("major.gc.count=").append(gcStats.getMajorCollectionCount()).append(", ");
            sb.append("major.gc.time=").append(gcStats.getMajorCollectionTime()).append("ms, ");
            if (gcStats.getUnknownCollectionCount() > 0) {
                sb.append("unknown.gc.count=").append(gcStats.getUnknownCollectionCount()).append(", ");
                sb.append("unknown.gc.time=").append(gcStats.getUnknownCollectionTime()).append("ms, ");
            }

            sb.append("load.process=").append(format("%.2f", processCpuLoad)).append("%, ");
            sb.append("load.system=").append(format("%.2f", systemCpuLoad)).append("%, ");
            sb.append("load.systemAverage=").append(systemLoadAverage >= 0 ? format("%.2f, ", systemLoadAverage) : "n/a, ");
            sb.append("thread.count=").append(threadCount).append(", ");
            sb.append("thread.peakCount=").append(peakThreadCount).append(", ");
            sb.append("cluster.timeDiff=").append(clusterTimeDiff).append(", ");
            sb.append("event.q.size=").append(eventQueueSize).append(", ");
            sb.append("executor.q.async.size=").append(asyncExecutorQueueSize).append(", ");
            sb.append("executor.q.client.size=").append(clientExecutorQueueSize).append(", ");
            sb.append("executor.q.query.size=").append(queryExecutorQueueSize).append(", ");
            sb.append("executor.q.scheduled.size=").append(scheduledExecutorQueueSize).append(", ");
            sb.append("executor.q.io.size=").append(ioExecutorQueueSize).append(", ");
            sb.append("executor.q.system.size=").append(systemExecutorQueueSize).append(", ");
            sb.append("executor.q.operation.size=").append(operationServiceOperationExecutorQueueSize).append(", ");
            sb.append("executor.q.priorityOperation.size=").
                    append(operationServiceOperationPriorityExecutorQueueSize).append(", ");
            sb.append("executor.q.response.size=").append(operationServiceOperationResponseQueueSize).append(", ");
            sb.append("operations.remote.size=").append(remoteOperationsCount).append(", ");
            sb.append("operations.running.size=").append(runningOperationsCount).append(", ");
            sb.append("operations.pending.invocations.count=")
                    .append(pendingInvocationsCount).append(", ");
            sb.append("operations.pending.invocations.percentage=")
                    .append(format("%.2f", pendingInvocationsPercentage)).append("%, ");
            sb.append("proxy.count=").append(proxyCount).append(", ");
            sb.append("clientEndpoint.count=").append(clientEndpointCount).append(", ");
            sb.append("connection.active.count=").append(activeConnectionCount).append(", ");
            sb.append("client.connection.count=").append(currentClientConnectionCount).append(", ");
            sb.append("connection.count=").append(connectionCount);
            return sb.toString();
        }
    }

    
    public static String percentageString(double p) {
        return format("%.2f", p) + "%";
    }

    public static String numberToUnit(long number) {
        
        for (int i = 6; i > 0; i--) {
            double step = Math.pow(1024, i); 
            if (number > step) {
                return format("%3.1f%s", number / step, UNITS[i]);
            }
        }
        
        return Long.toString(number);
    }

}

<code block>


package com.hazelcast.internal.monitors;

import com.hazelcast.instance.HazelcastInstanceImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;

import java.util.concurrent.TimeUnit;


public class PerformanceMonitor extends Thread {

    private final ILogger logger;
    private final Node node;
    private final int delaySeconds;
    private final InternalOperationService operationService;
    private final ConnectionManager connectionManager;

    public PerformanceMonitor(HazelcastInstanceImpl hazelcastInstance, int delaySeconds) {
        super(hazelcastInstance.node.getHazelcastThreadGroup().getInternalThreadGroup(),
                hazelcastInstance.node.getHazelcastThreadGroup().getThreadNamePrefix("PerformanceMonitor"));
        setDaemon(true);

        this.delaySeconds = delaySeconds;
        this.node = hazelcastInstance.node;
        this.logger = node.getLogger(PerformanceMonitor.class.getName());
        this.operationService = node.nodeEngine.getOperationService();
        this.connectionManager = node.connectionManager;
    }

    @Override
    public void run() {
        StringBuffer sb = new StringBuffer();

        while (node.isActive()) {
            sb.append("\n");
            sb.append("ConnectionManager metrics\n");
            connectionManager.dumpPerformanceMetrics(sb);
            sb.append("OperationService metrics\n");
            operationService.dumpPerformanceMetrics(sb);

            logger.info(sb.toString());

            sb.setLength(0);
            try {
                Thread.sleep(TimeUnit.SECONDS.toMillis(delaySeconds));
            } catch (InterruptedException e) {
                return;
            }
        }
    }
}

<code block>


package com.hazelcast.internal.metrics;

import java.lang.annotation.Retention;
import java.lang.annotation.Target;

import static java.lang.annotation.ElementType.FIELD;
import static java.lang.annotation.ElementType.METHOD;
import static java.lang.annotation.RetentionPolicy.RUNTIME;


@Retention(value = RUNTIME)
@Target({FIELD, METHOD })
public @interface Probe {

    
    String name() default "";
}

<code block>


package com.hazelcast.internal.metrics;

import java.util.Set;
import java.util.concurrent.TimeUnit;


public interface MetricsRegistry {

    
    <S> void scanAndRegister(S source, String namePrefix);

    
    <S> void register(S source, String name, LongProbe<S> input);

    
    <S> void register(S source, String name, DoubleProbe<S> input);


    
    <S> void deregister(S source);

    
    void scheduleAtFixedRate(Runnable publisher, long period, TimeUnit timeUnit);

    
    Gauge getGauge(String name);

    
    Set<String> getNames();

    
    int modCount();
}

<code block>


package com.hazelcast.internal.metrics;


public interface Metric {

    
    String getName();

    
    void render(StringBuilder sb);
}

<code block>


package com.hazelcast.internal.metrics;


public interface LongProbe<S> {

    
    long get(S source) throws Exception;
}

<code block>


package com.hazelcast.internal.metrics;


public interface Gauge extends Metric {

    
    long readLong();

    
    double readDouble();
}

<code block>


package com.hazelcast.internal.metrics;


public interface DoubleProbe<S> {

    
    double get(S source) throws Exception;
}

<code block>


package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.LongProbe;

import java.lang.management.ClassLoadingMXBean;
import java.lang.management.ManagementFactory;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class ClassLoadingMetricSet {

    private ClassLoadingMetricSet() {
    }

    
    public static void register(MetricsRegistry metricsRegistry) {
        checkNotNull(metricsRegistry, "metricsRegistry");

        ClassLoadingMXBean mxBean = ManagementFactory.getClassLoadingMXBean();

        metricsRegistry.register(mxBean, "classloading.loadedClassesCount",
                new LongProbe<ClassLoadingMXBean>() {
                    @Override
                    public long get(ClassLoadingMXBean classLoadingMXBean) {
                        return classLoadingMXBean.getLoadedClassCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "classloading.totalLoadedClassesCount",
                new LongProbe<ClassLoadingMXBean>() {
                    @Override
                    public long get(ClassLoadingMXBean classLoadingMXBean) {
                        return classLoadingMXBean.getTotalLoadedClassCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "classloading.unloadedClassCount",
                new LongProbe<ClassLoadingMXBean>() {
                    @Override
                    public long get(ClassLoadingMXBean classLoadingMXBean) {
                        return classLoadingMXBean.getUnloadedClassCount();
                    }
                }
        );
    }
}

<code block>


package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.DoubleProbe;
import com.hazelcast.internal.metrics.LongProbe;

import java.lang.management.ManagementFactory;
import java.lang.management.OperatingSystemMXBean;
import java.lang.reflect.Method;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class OperatingSystemMetricsSet {

    private static final double PERCENTAGE_MULTIPLIER = 100d;

    private OperatingSystemMetricsSet() {
    }

    
    public static void register(MetricsRegistry metricsRegistry) {
        checkNotNull(metricsRegistry, "metricsRegistry");

        OperatingSystemMXBean mxBean = ManagementFactory.getOperatingSystemMXBean();

        registerMethod(metricsRegistry, mxBean, "getCommittedVirtualMemorySize", "os.committedVirtualMemorySize");
        registerMethod(metricsRegistry, mxBean, "getFreePhysicalMemorySize", "os.freePhysicalMemorySize");
        registerMethod(metricsRegistry, mxBean, "getFreeSwapSpaceSize", "os.freeSwapSpaceSize");
        registerMethod(metricsRegistry, mxBean, "getProcessCpuTime", "os.processCpuTime");
        registerMethod(metricsRegistry, mxBean, "getTotalPhysicalMemorySize", "os.totalPhysicalMemorySize");
        registerMethod(metricsRegistry, mxBean, "getTotalSwapSpaceSize", "os.totalSwapSpaceSize");
        registerMethod(metricsRegistry, mxBean, "getMaxFileDescriptorCount", "os.maxFileDescriptorCount");
        registerMethod(metricsRegistry, mxBean, "getOpenFileDescriptorCount", "os.openFileDescriptorCount");
        registerMethod(metricsRegistry, mxBean, "getProcessCpuLoad", "os.processCpuLoad");
        registerMethod(metricsRegistry, mxBean, "getSystemCpuLoad", "os.systemCpuLoad");

        metricsRegistry.register(mxBean, "os.systemLoadAverage",
                new DoubleProbe<OperatingSystemMXBean>() {
                    @Override
                    public double get(OperatingSystemMXBean bean) {
                        return PERCENTAGE_MULTIPLIER * bean.getSystemLoadAverage();
                    }
                }
        );
    }


    
    
    static void registerMethod(MetricsRegistry metricsRegistry, Object osBean, String methodName, String name) {
        final Method method = getMethod(osBean, methodName);

        if (method == null) {
            return;
        }

        if (long.class.equals(method.getReturnType())) {
            metricsRegistry.register(osBean, name,
                    new LongProbe() {
                        @Override
                        public long get(Object bean) throws Exception {
                            return (Long) method.invoke(bean);
                        }
                    });
        } else {
            metricsRegistry.register(osBean, name,
                    new DoubleProbe() {
                        @Override
                        public double get(Object bean) throws Exception {
                            return (Double) method.invoke(bean);
                        }
                    });
        }
    }

    
    private static Method getMethod(Object source, String methodName) {
        try {
            Method method = source.getClass().getDeclaredMethod(methodName);
            method.setAccessible(true);
            return method;
        } catch (Exception e) {
            return null;
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.LongProbe;

import java.lang.management.ManagementFactory;
import java.lang.management.ThreadMXBean;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class ThreadMetricSet {

    private ThreadMetricSet() {
    }

    
    public static void register(MetricsRegistry metricsRegistry) {
        checkNotNull(metricsRegistry, "metricsRegistry");

        ThreadMXBean mxBean = ManagementFactory.getThreadMXBean();

        metricsRegistry.register(mxBean, "thread.threadCount", new LongProbe<ThreadMXBean>() {
                    @Override
                    public long get(ThreadMXBean threadMXBean) {
                        return threadMXBean.getThreadCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "thread.peakThreadCount", new LongProbe<ThreadMXBean>() {
                    @Override
                    public long get(ThreadMXBean threadMXBean) {
                        return threadMXBean.getPeakThreadCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "thread.daemonThreadCount", new LongProbe<ThreadMXBean>() {
                    @Override
                    public long get(ThreadMXBean threadMXBean) {
                        return threadMXBean.getDaemonThreadCount();
                    }
                }
        );

        metricsRegistry.register(mxBean, "thread.totalStartedThreadCount", new LongProbe<ThreadMXBean>() {
                    @Override
                    public long get(ThreadMXBean threadMXBean) {
                        return threadMXBean.getTotalStartedThreadCount();
                    }
                }
        );
    }
}

<code block>


package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.LongProbe;

import java.lang.management.ManagementFactory;
import java.lang.management.RuntimeMXBean;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class RuntimeMetricSet {

    private RuntimeMetricSet() {
    }

    
    public static void register(MetricsRegistry metricsRegistry) {
        checkNotNull(metricsRegistry, "metricsRegistry");

        Runtime runtime = Runtime.getRuntime();
        RuntimeMXBean mxBean = ManagementFactory.getRuntimeMXBean();

        metricsRegistry.register(runtime, "runtime.freeMemory", new LongProbe<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.freeMemory();
                    }
                }
        );

        metricsRegistry.register(runtime, "runtime.totalMemory", new LongProbe<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.totalMemory();
                    }
                }
        );

        metricsRegistry.register(runtime, "runtime.maxMemory", new LongProbe<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.maxMemory();
                    }
                }
        );

        metricsRegistry.register(runtime, "runtime.usedMemory", new LongProbe<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.totalMemory() - runtime.freeMemory();
                    }
                }
        );

        metricsRegistry.register(runtime, "runtime.availableProcessors", new LongProbe<Runtime>() {
                    @Override
                    public long get(Runtime runtime) {
                        return runtime.availableProcessors();
                    }
                }
        );

        metricsRegistry.register(mxBean, "runtime.uptime", new LongProbe<RuntimeMXBean>() {
                    @Override
                    public long get(RuntimeMXBean runtimeMXBean) {
                        return runtimeMXBean.getUptime();
                    }
                }
        );
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbe;
import com.hazelcast.internal.metrics.LongProbe;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.util.counters.Counter;

import java.lang.reflect.Field;
import java.util.Collection;
import java.util.Map;

import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_COLLECTION;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_COUNTER;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_DOUBLE_NUMBER;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_DOUBLE_PRIMITIVE;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_LONG_NUMBER;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_MAP;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_PRIMITIVE_LONG;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.getType;
import static java.lang.String.format;


abstract class FieldProbe {

    final Probe probe;
    final Field field;
    final int type;

    FieldProbe(Field field, Probe probe, int type) {
        this.field = field;
        this.probe = probe;
        this.type = type;
        field.setAccessible(true);
    }

     void register(MetricsRegistryImpl metricsRegistry, Object source, String namePrefix) {
        String name = getName(namePrefix);
        metricsRegistry.registerInternal(source, name, this);
    }

    private String getName(String namePrefix) {
        String name = field.getName();
        if (!probe.name().equals("")) {
            name = probe.name();
        }

        return namePrefix + "." + name;
    }

    static <S> FieldProbe createFieldProbe(Field field, Probe probe) {
        int type = getType(field.getType());
        if (type == -1) {
            throw new IllegalArgumentException(format("@Probe field '%s' is of an unhandled type", field));
        }

        if (AccessibleObjectProbe.isDouble(type)) {
            return new DoubleFieldProbe<S>(field, probe, type);
        } else {
            return new LongFieldProbe<S>(field, probe, type);
        }
    }

    static class LongFieldProbe<S> extends FieldProbe implements LongProbe<S> {

        public LongFieldProbe(Field field, Probe probe, int type) {
            super(field, probe, type);
        }

        @Override
        public long get(S source) throws Exception {
            switch (type) {
                case TYPE_PRIMITIVE_LONG:
                    return field.getLong(source);
                case TYPE_LONG_NUMBER:
                    Number longNumber = (Number) field.get(source);
                    return longNumber == null ? 0 : longNumber.longValue();
                case TYPE_MAP:
                    Map<?, ?> map = (Map<?, ?>) field.get(source);
                    return map == null ? 0 : map.size();
                case TYPE_COLLECTION:
                    Collection<?> collection = (Collection<?>) field.get(source);
                    return collection == null ? 0 : collection.size();
                case TYPE_COUNTER:
                    Counter counter = (Counter) field.get(source);
                    return counter == null ? 0 : counter.get();
                default:
                    throw new IllegalStateException("Unhandled type:" + type);
            }
        }
    }

   static class DoubleFieldProbe<S> extends FieldProbe implements DoubleProbe<S> {

        public DoubleFieldProbe(Field field, Probe probe, int type) {
            super(field, probe, type);
        }

        @Override
        public double get(S source) throws Exception {
            switch (type) {
                case TYPE_DOUBLE_PRIMITIVE:
                    return field.getDouble(source);
                case TYPE_DOUBLE_NUMBER:
                    Number doubleNumber = (Number) field.get(source);
                    return doubleNumber == null ? 0 : doubleNumber.doubleValue();
                default:
                    throw new IllegalStateException("Unhandled type:" + type);
            }
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbe;
import com.hazelcast.internal.metrics.LongProbe;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.util.counters.Counter;

import java.lang.reflect.Method;
import java.util.Collection;
import java.util.Map;

import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_COLLECTION;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_COUNTER;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_DOUBLE_NUMBER;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_DOUBLE_PRIMITIVE;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_LONG_NUMBER;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_MAP;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.TYPE_PRIMITIVE_LONG;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.getType;
import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.isDouble;
import static java.lang.String.format;


abstract class MethodProbe {

    final Method method;
    final Probe probe;
    final int type;

    MethodProbe(Method method, Probe probe, int type) {
        this.method = method;
        this.probe = probe;
        this.type = type;
        method.setAccessible(true);
    }

    void register(MetricsRegistryImpl metricsRegistry, Object source, String namePrefix) {
        String name = getName(namePrefix);
        metricsRegistry.registerInternal(source, name, this);
    }

    private String getName(String namePrefix) {
        String name = method.getName();
        if (!probe.name().equals("")) {
            name = probe.name();
        }

        return namePrefix + "." + name;
    }

    static <S> MethodProbe createMethodProbe(Method method, Probe probe) {
        int type = getType(method.getReturnType());
        if (type == -1) {
            throw new IllegalArgumentException(format("@Probe method '%s.%s() has an unsupported return type'",
                    method.getDeclaringClass().getName(), method.getName()));
        }

        if (method.getParameterTypes().length != 0) {
            throw new IllegalArgumentException(format("@Probe method '%s.%s' can't have arguments",
                    method.getDeclaringClass().getName(), method.getName()));
        }

        if (isDouble(type)) {
            return new DoubleMethodProbe<S>(method, probe, type);
        } else {
            return new LongMethodProbe<S>(method, probe, type);
        }
    }

    static class LongMethodProbe<S> extends MethodProbe implements LongProbe<S> {

        public LongMethodProbe(Method method, Probe probe, int type) {
            super(method, probe, type);
        }

        @Override
        public long get(S source) throws Exception {
            switch (type) {
                case TYPE_PRIMITIVE_LONG:
                    return ((Number) method.invoke(source)).longValue();
                case TYPE_LONG_NUMBER:
                    Number longNumber = (Number) method.invoke(source);
                    return longNumber == null ? 0 : longNumber.longValue();
                case TYPE_MAP:
                    Map<?, ?> map = (Map<?, ?>) method.invoke(source);
                    return map == null ? 0 : map.size();
                case TYPE_COLLECTION:
                    Collection<?> collection = (Collection<?>) method.invoke(source);
                    return collection == null ? 0 : collection.size();
                case TYPE_COUNTER:
                    Counter counter = (Counter) method.invoke(source);
                    return counter == null ? 0 : counter.get();
                default:
                    throw new IllegalStateException("Unrecognized type:" + type);
            }
        }
    }

    static class DoubleMethodProbe<S> extends MethodProbe implements DoubleProbe<S> {

        public DoubleMethodProbe(Method method, Probe probe, int type) {
            super(method, probe, type);
        }

        @Override
        public double get(S source) throws Exception {
            switch (type) {
                case TYPE_DOUBLE_PRIMITIVE:
                case TYPE_DOUBLE_NUMBER:
                    Number result = (Number) method.invoke(source);
                    return result == null ? 0 : result.doubleValue();
                default:
                    throw new IllegalStateException("Unrecognized type:" + type);
            }
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbe;
import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.LongProbe;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.logging.ILogger;

import static com.hazelcast.util.Preconditions.checkNotNull;


public class GaugeImpl<S> implements Gauge {

    volatile Object input;
    volatile S source;

    private final ILogger logger;
    private final String name;

    public GaugeImpl(String name, ILogger logger) {
        this.name = name;
        this.logger = logger;
    }

    @Override
    public String getName() {
        return name;
    }

    @Override
    public void render(StringBuilder sb) {
        checkNotNull(sb, "sb can't be null");

        sb.append(name).append('=');

        Object input = this.input;
        S source = this.source;

        if (input == null || source == null) {
            sb.append("NA");
            return;
        }

        try {
            if (input instanceof LongProbe) {
                LongProbe<S> function = (LongProbe) input;
                sb.append(function.get(source));
            } else {
                DoubleProbe<S> function = (DoubleProbe) input;
                sb.append(function.get(source));
            }
        } catch (Exception e) {
            logger.warning("Failed to update metric:" + name, e);
            sb.append("NA");
        }
    }

    @Override
    public long readLong() {
        Object input = this.input;
        S source = this.source;
        long result = 0;

        if (input == null || source == null) {
            return result;
        }

        try {
            if (input instanceof LongProbe) {
                LongProbe<S> longInput = (LongProbe<S>) input;
                result = longInput.get(source);
            } else {
                DoubleProbe<S> doubleInput = (DoubleProbe<S>) input;
                double doubleResult = doubleInput.get(source);
                result = Math.round(doubleResult);
            }
            return result;
        } catch (Exception e) {
            logger.warning("Failed to update metric:" + name, e);
            return result;
        }
    }

    @Override
    public double readDouble() {
        Object input = this.input;
        S source = this.source;
        double result = 0;

        if (input == null || source == null) {
            return result;
        }

        try {
            if (input instanceof LongProbe) {
                LongProbe<S> longInput = (LongProbe<S>) input;
                result = longInput.get(source);
            } else {
                DoubleProbe<S> doubleInput = (DoubleProbe<S>) input;
                result = doubleInput.get(source);
            }
            return result;
        } catch (Exception e) {
            logger.warning("Failed to update metric:" + name, e);
            return result;
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Probe;

import java.lang.reflect.Field;
import java.lang.reflect.Method;
import java.util.ArrayList;
import java.util.List;

import static com.hazelcast.internal.metrics.impl.AccessibleObjectProbe.flatten;
import static com.hazelcast.internal.metrics.impl.FieldProbe.createFieldProbe;
import static com.hazelcast.internal.metrics.impl.MethodProbe.createMethodProbe;


final class SourceMetadata {
    private final List<FieldProbe> fields = new ArrayList<FieldProbe>();
    private final List<MethodProbe> methods = new ArrayList<MethodProbe>();

    SourceMetadata(Class clazz) {
        
        List<Class<?>> classList = new ArrayList<Class<?>>();
        flatten(clazz, classList);

        for (Class flattenedClass : classList) {
            scanFields(flattenedClass);
            scanMethods(flattenedClass);
        }
    }

    void register(MetricsRegistryImpl metricsRegistry, Object source, String namePrefix) {
        for (FieldProbe field : fields) {
            field.register(metricsRegistry, source, namePrefix);
        }

        for (MethodProbe method : methods) {
            method.register(metricsRegistry, source, namePrefix);
        }
    }

    void scanFields(Class<?> clazz) {
        for (Field field : clazz.getDeclaredFields()) {
            Probe probe = field.getAnnotation(Probe.class);

            if (probe == null) {
                continue;
            }

            FieldProbe fieldProbe = createFieldProbe(field, probe);
            fields.add(fieldProbe);
        }
    }

    void scanMethods(Class<?> clazz) {
        for (Method method : clazz.getDeclaredMethods()) {
            Probe probe = method.getAnnotation(Probe.class);

            if (probe == null) {
                continue;
            }

            MethodProbe methodProbe = createMethodProbe(method, probe);
            methods.add(methodProbe);
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.util.counters.Counter;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;


abstract class AccessibleObjectProbe {

    static final int TYPE_PRIMITIVE_LONG = 1;
    static final int TYPE_LONG_NUMBER = 2;

    static final int TYPE_DOUBLE_PRIMITIVE = 3;
    static final int TYPE_DOUBLE_NUMBER = 4;

    static final int TYPE_COLLECTION = 5;
    static final int TYPE_MAP = 6;
    static final int TYPE_COUNTER = 7;

    private static final Map<Class<?>, Integer> TYPES = new HashMap<Class<?>, Integer>();

    static {
        TYPES.put(byte.class, TYPE_PRIMITIVE_LONG);
        TYPES.put(short.class, TYPE_PRIMITIVE_LONG);
        TYPES.put(int.class, TYPE_PRIMITIVE_LONG);
        TYPES.put(long.class, TYPE_PRIMITIVE_LONG);

        TYPES.put(Byte.class, TYPE_LONG_NUMBER);
        TYPES.put(Short.class, TYPE_LONG_NUMBER);
        TYPES.put(Integer.class, TYPE_LONG_NUMBER);
        TYPES.put(Long.class, TYPE_LONG_NUMBER);
        TYPES.put(AtomicInteger.class, TYPE_LONG_NUMBER);
        TYPES.put(AtomicLong.class, TYPE_LONG_NUMBER);

        TYPES.put(double.class, TYPE_DOUBLE_PRIMITIVE);
        TYPES.put(float.class, TYPE_DOUBLE_PRIMITIVE);

        TYPES.put(Double.class, TYPE_DOUBLE_NUMBER);
        TYPES.put(Float.class, TYPE_DOUBLE_NUMBER);

        TYPES.put(Collection.class, TYPE_COLLECTION);
        TYPES.put(Map.class, TYPE_MAP);
        TYPES.put(Counter.class, TYPE_COUNTER);
    }

    static boolean isDouble(int type) {
        return type == TYPE_DOUBLE_PRIMITIVE || type == TYPE_DOUBLE_NUMBER;
    }

    
    static int getType(Class classType) {
        Integer type = TYPES.get(classType);
        if (type != null) {
            return type;
        }

        List<Class<?>> flattenedClasses = new ArrayList<Class<?>>();

        flatten(classType, flattenedClasses);

        for (Class<?> clazz : flattenedClasses) {
            type = TYPES.get(clazz);
            if (type != null) {
                return type;
            }
        }

        return -1;
    }

    static void flatten(Class clazz, List<Class<?>> result) {
        if (!result.contains(clazz)) {
            result.add(clazz);
        }

        if (clazz.getSuperclass() != null) {
            flatten(clazz.getSuperclass(), result);
        }

        for (Class interfaze : clazz.getInterfaces()) {
            if (!result.contains(interfaze)) {
                result.add(interfaze);
            }

            flatten(interfaze, result);
        }
    }
}

<code block>


package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbe;
import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.LongProbe;
import com.hazelcast.internal.metrics.MetricsRegistry;
import com.hazelcast.internal.metrics.metricsets.ClassLoadingMetricSet;
import com.hazelcast.internal.metrics.metricsets.GarbageCollectionMetricSet;
import com.hazelcast.internal.metrics.metricsets.OperatingSystemMetricsSet;
import com.hazelcast.internal.metrics.metricsets.RuntimeMetricSet;
import com.hazelcast.internal.metrics.metricsets.ThreadMetricSet;
import com.hazelcast.logging.ILogger;

import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

import static com.hazelcast.util.Preconditions.checkNotNull;
import static java.lang.String.format;


public class MetricsRegistryImpl implements MetricsRegistry {

    private final ILogger logger;
    private final ScheduledExecutorService scheduledExecutorService = new ScheduledThreadPoolExecutor(2);
    private final AtomicInteger modCount = new AtomicInteger();
    private final ConcurrentMap<String, GaugeImpl> metrics = new ConcurrentHashMap<String, GaugeImpl>();
    private final ConcurrentMap<Class<?>, SourceMetadata> metadataMap
            = new ConcurrentHashMap<Class<?>, SourceMetadata>();

    
    public MetricsRegistryImpl(ILogger logger) {
        this.logger = checkNotNull(logger, "Logger can't be null");

        RuntimeMetricSet.register(this);
        GarbageCollectionMetricSet.register(this);
        OperatingSystemMetricsSet.register(this);
        ThreadMetricSet.register(this);
        ClassLoadingMetricSet.register(this);
    }

    @Override
    public int modCount() {
        return modCount.get();
    }

    @Override
    public Set<String> getNames() {
        return metrics.keySet();
    }

    SourceMetadata getObjectMetadata(Class<?> clazz) {
        SourceMetadata metadata = metadataMap.get(clazz);
        if (metadata == null) {
            metadata = new SourceMetadata(clazz);
            SourceMetadata found = metadataMap.putIfAbsent(clazz, metadata);
            metadata = found == null ? metadata : found;
        }

        return metadata;
    }

    @Override
    public synchronized <S> void scanAndRegister(S source, String namePrefix) {
        checkNotNull(source, "source can't be null");
        checkNotNull(namePrefix, "namePrefix can't be null");

        SourceMetadata metadata = getObjectMetadata(source.getClass());
        metadata.register(this, source, namePrefix);
    }

    @Override
    public synchronized <S> void register(S source, String name, LongProbe<S> input) {
        checkNotNull(name, "source can't be null");
        checkNotNull(name, "name can't be null");
        checkNotNull(name, "input can't be null");

        registerInternal(source, name, input);
    }

    @Override
    public synchronized <S> void register(S source, String name, DoubleProbe<S> input) {
        checkNotNull(name, "source can't be null");
        checkNotNull(name, "name can't be null");
        checkNotNull(name, "input can't be null");

        registerInternal(source, name, input);
    }

    <S> void registerInternal(S source, String name, Object input) {
        GaugeImpl gauge = metrics.get(name);
        if (gauge == null) {
            gauge = new GaugeImpl<S>(name, logger);
            metrics.put(name, gauge);
        }

        logOverwrite(name, gauge);

        if (logger.isFinestEnabled()) {
            logger.finest("Registered gauge " + name);
        }

        gauge.source = source;
        gauge.input = input;

        modCount.incrementAndGet();
    }

    
    private void logOverwrite(String name, GaugeImpl gauge) {
        
        if (gauge.input != null) {
            logger.warning(format("Duplicate registration, a input for Metric '%s' already exists", name));
        }

        
        if (gauge.source != null) {
            logger.warning(format("Duplicate registration, a input for Metric '%s' already exists", name));
        }
    }

    @Override
    public synchronized Gauge getGauge(String name) {
        checkNotNull(name, "name can't be null");

        GaugeImpl gauge = metrics.get(name);

        if (gauge == null) {
            gauge = new GaugeImpl(name, logger);
            metrics.put(name, gauge);
        }

        return gauge;
    }

    @Override
    public synchronized <S> void deregister(S source) {
        checkNotNull(source, "source can't be null");

        boolean changed = false;
        for (Map.Entry<String, GaugeImpl> entry : metrics.entrySet()) {
            GaugeImpl gauge = entry.getValue();
            if (gauge.source != source) {
                continue;
            }

            String name = entry.getKey();
            changed = true;
            metrics.remove(name);
            gauge.source = null;
            gauge.input = null;

            if (logger.isFinestEnabled()) {
                logger.finest("Destroying gauge " + name);
            }
        }

        if (changed) {
            modCount.incrementAndGet();
        }
    }

    @Override
    public void scheduleAtFixedRate(final Runnable publisher, long period, TimeUnit timeUnit) {
        scheduledExecutorService.scheduleAtFixedRate(publisher, 0, period, timeUnit);
    }

    public void shutdown() {
        scheduledExecutorService.shutdown();
    }
}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.ClusterClock;
import com.hazelcast.logging.ILogger;
import com.hazelcast.util.Clock;


public class ClusterClockImpl implements ClusterClock {

    private final ILogger logger;
    private volatile long clusterTimeDiff = Long.MAX_VALUE;
    private volatile long clusterStartTime = Long.MIN_VALUE;

    public ClusterClockImpl(ILogger logger) {
        this.logger = logger;
    }

    @Override
    public long getClusterTime() {
        return Clock.currentTimeMillis() + ((clusterTimeDiff == Long.MAX_VALUE) ? 0 : clusterTimeDiff);
    }

    public void setMasterTime(long masterTime) {
        long diff = masterTime - Clock.currentTimeMillis();
        if (logger.isFinestEnabled()) {
            logger.finest("Setting cluster time diff to " + diff + "ms.");
        }
        this.clusterTimeDiff = diff;
    }

    @Override
    public long getClusterTimeDiff() {
        return (clusterTimeDiff == Long.MAX_VALUE) ? 0 : clusterTimeDiff;
    }

    @Override
    public long getClusterUpTime() {
        return Clock.currentTimeMillis() - clusterStartTime;
    }

    public void setClusterStartTime(long startTime) {
        if (this.clusterStartTime == Long.MIN_VALUE) {
            this.clusterStartTime = startTime;
        }
    }

    public long getClusterStartTime() {
       return clusterStartTime;
    }

}

<code block>


package com.hazelcast.cluster.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.cluster.MemberAttributeOperationType;
import com.hazelcast.cluster.MemberInfo;
import com.hazelcast.cluster.impl.operations.AuthenticationFailureOperation;
import com.hazelcast.cluster.impl.operations.BeforeJoinCheckFailureOperation;
import com.hazelcast.cluster.impl.operations.ConfigMismatchOperation;
import com.hazelcast.cluster.impl.operations.FinalizeJoinOperation;
import com.hazelcast.cluster.impl.operations.GroupMismatchOperation;
import com.hazelcast.cluster.impl.operations.HeartbeatOperation;
import com.hazelcast.cluster.impl.operations.JoinCheckOperation;
import com.hazelcast.cluster.impl.operations.JoinRequestOperation;
import com.hazelcast.cluster.impl.operations.MasterConfirmationOperation;
import com.hazelcast.cluster.impl.operations.MasterDiscoveryOperation;
import com.hazelcast.cluster.impl.operations.MemberInfoUpdateOperation;
import com.hazelcast.cluster.impl.operations.MemberRemoveOperation;
import com.hazelcast.cluster.impl.operations.PostJoinOperation;
import com.hazelcast.cluster.impl.operations.SetMasterOperation;
import com.hazelcast.cluster.impl.operations.TriggerMemberListPublishOperation;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.InitialMembershipEvent;
import com.hazelcast.core.InitialMembershipListener;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberAttributeEvent;
import com.hazelcast.core.MembershipEvent;
import com.hazelcast.core.MembershipListener;
import com.hazelcast.instance.BuildInfo;
import com.hazelcast.instance.HazelcastInstanceImpl;
import com.hazelcast.instance.LifecycleServiceImpl;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.Packet;
import com.hazelcast.security.Credentials;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.MemberAttributeServiceEvent;
import com.hazelcast.spi.MembershipAwareService;
import com.hazelcast.spi.MembershipServiceEvent;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.SplitBrainHandlerService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;
import com.hazelcast.util.executor.ExecutorType;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import javax.security.auth.login.LoginContext;
import javax.security.auth.login.LoginException;
import java.net.ConnectException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.Date;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.LinkedHashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;

import static com.hazelcast.cluster.impl.operations.FinalizeJoinOperation.FINALIZE_JOIN_MAX_TIMEOUT;
import static com.hazelcast.cluster.impl.operations.FinalizeJoinOperation.FINALIZE_JOIN_TIMEOUT_FACTOR;
import static com.hazelcast.core.LifecycleEvent.LifecycleState.MERGED;
import static com.hazelcast.core.LifecycleEvent.LifecycleState.MERGING;
import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;
import static com.hazelcast.util.Preconditions.checkNotNull;
import static com.hazelcast.util.Preconditions.isNotNull;
import static java.util.Collections.unmodifiableMap;
import static java.util.Collections.unmodifiableSet;

public final class ClusterServiceImpl implements ClusterService, ConnectionListener, ManagedService,
        EventPublishingService<MembershipEvent, MembershipListener> {

    public static final String SERVICE_NAME = "hz:core:clusterService";

    private static final String EXECUTOR_NAME = "hz:cluster";
    private static final int HEARTBEAT_INTERVAL = 500;
    private static final long HEARTBEAT_LOG_THRESHOLD = 10000L;
    private static final int PING_INTERVAL = 5000;

    private final Node node;

    private final NodeEngineImpl nodeEngine;

    private final ILogger logger;

    protected final Address thisAddress;

    protected final MemberImpl thisMember;

    private final long waitMillisBeforeJoin;

    private final long maxWaitMillisBeforeJoin;

    private final long heartbeatInterval;

    private final long maxNoHeartbeatMillis;

    private final long maxNoMasterConfirmationMillis;

    private final boolean icmpEnabled;

    private final int icmpTtl;

    private final int icmpTimeout;

    private final Lock lock = new ReentrantLock();

    private final Set<MemberInfo> setJoins = new LinkedHashSet<MemberInfo>(100);

    private final AtomicReference<Map<Address, MemberImpl>> membersMapRef
            = new AtomicReference<Map<Address, MemberImpl>>(Collections.<Address, MemberImpl>emptyMap());

    private final AtomicReference<Set<MemberImpl>> membersRef = new AtomicReference<Set<MemberImpl>>(Collections.<MemberImpl>emptySet());

    private final AtomicBoolean preparingToMerge = new AtomicBoolean(false);

    private volatile boolean joinInProgress = false;

    private volatile long lastHeartBeat = 0L;

    private long timeToStartJoin = 0;

    private long firstJoinRequest = 0;

    private final ConcurrentMap<MemberImpl, Long> masterConfirmationTimes = new ConcurrentHashMap<MemberImpl, Long>();

    private final ExceptionHandler whileFinalizeJoinsExceptionHandler;

    private final ClusterClockImpl clusterClock;

    private String clusterId = null;

    public ClusterServiceImpl(final Node node) {
        this.node = node;
        nodeEngine = node.nodeEngine;
        logger = node.getLogger(ClusterService.class.getName());
        clusterClock = new ClusterClockImpl(logger);
        whileFinalizeJoinsExceptionHandler =
                logAllExceptions(logger, "While waiting finalize join calls...", Level.WARNING);
        thisAddress = node.getThisAddress();
        thisMember = node.getLocalMember();
        setMembers(thisMember);
        waitMillisBeforeJoin = node.groupProperties.WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L;
        maxWaitMillisBeforeJoin = node.groupProperties.MAX_WAIT_SECONDS_BEFORE_JOIN.getInteger() * 1000L;
        long heartbeatIntervalSeconds = node.groupProperties.HEARTBEAT_INTERVAL_SECONDS.getInteger();
        heartbeatIntervalSeconds = heartbeatIntervalSeconds <= 0 ? 1 : heartbeatIntervalSeconds;
        heartbeatInterval = heartbeatIntervalSeconds;
        maxNoHeartbeatMillis = node.groupProperties.MAX_NO_HEARTBEAT_SECONDS.getInteger() * 1000L;
        maxNoMasterConfirmationMillis = node.groupProperties.MAX_NO_MASTER_CONFIRMATION_SECONDS.getInteger() * 1000L;
        icmpEnabled = node.groupProperties.ICMP_ENABLED.getBoolean();
        icmpTtl = node.groupProperties.ICMP_TTL.getInteger();
        icmpTimeout = node.groupProperties.ICMP_TIMEOUT.getInteger();
        node.connectionManager.addConnectionListener(this);
    }

    @Override
    public ClusterClockImpl getClusterClock() {
        return clusterClock;
    }

    @Override
    public String getClusterId() {
        return clusterId;
    }

    public void setClusterId(String clusterId) {
        if (this.clusterId == null) {
            this.clusterId = clusterId;
        }
    }

    @Override
    public void init(final NodeEngine nodeEngine, Properties properties) {
        long mergeFirstRunDelay = node.getGroupProperties().MERGE_FIRST_RUN_DELAY_SECONDS.getLong() * 1000;
        mergeFirstRunDelay = mergeFirstRunDelay <= 0 ? 100 : mergeFirstRunDelay; 

        ExecutionService executionService = nodeEngine.getExecutionService();
        executionService.register(EXECUTOR_NAME, 2, 1000, ExecutorType.CACHED);

        long mergeNextRunDelay = node.getGroupProperties().MERGE_NEXT_RUN_DELAY_SECONDS.getLong() * 1000;
        mergeNextRunDelay = mergeNextRunDelay <= 0 ? 100 : mergeNextRunDelay; 
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new SplitBrainHandler(node),
                mergeFirstRunDelay, mergeNextRunDelay, TimeUnit.MILLISECONDS);

        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                heartBeater();
            }
        }, heartbeatInterval, heartbeatInterval, TimeUnit.SECONDS);

        long masterConfirmationInterval = node.groupProperties.MASTER_CONFIRMATION_INTERVAL_SECONDS.getInteger();
        masterConfirmationInterval = masterConfirmationInterval <= 0 ? 1 : masterConfirmationInterval;
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                sendMasterConfirmation();
            }
        }, masterConfirmationInterval, masterConfirmationInterval, TimeUnit.SECONDS);

        long memberListPublishInterval = node.groupProperties.MEMBER_LIST_PUBLISH_INTERVAL_SECONDS.getInteger();
        memberListPublishInterval = memberListPublishInterval <= 0 ? 1 : memberListPublishInterval;
        executionService.scheduleWithFixedDelay(EXECUTOR_NAME, new Runnable() {
            public void run() {
                sendMemberListToOthers();
            }
        }, memberListPublishInterval, memberListPublishInterval, TimeUnit.SECONDS);
    }

    public boolean isJoinInProgress() {
        if (joinInProgress) {
            return true;
        }

        lock.lock();
        try {
            return joinInProgress || !setJoins.isEmpty();
        } finally {
            lock.unlock();
        }
    }

    public JoinRequest checkJoinInfo(Address target) {
        Future f = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME,
                new JoinCheckOperation(node.createJoinRequest()), target)
                .setTryCount(1).invoke();
        try {
            return (JoinRequest) nodeEngine.toObject(f.get());
        } catch (Exception e) {
            logger.warning("Error during join check!", e);
        }
        return null;
    }

    public boolean validateJoinMessage(JoinMessage joinMessage) throws Exception {
        boolean valid = Packet.VERSION == joinMessage.getPacketVersion();
        if (valid) {
            try {
                ConfigCheck newMemberConfigCheck = joinMessage.getConfigCheck();
                ConfigCheck clusterConfigCheck = node.createConfigCheck();
                valid = clusterConfigCheck.isCompatible(newMemberConfigCheck);
            } catch (Exception e) {
                final String message = "Invalid join request from: " + joinMessage.getAddress() + ", reason:" + e.getMessage();
                logger.warning(message);
                throw e;
            }
        }
        return valid;
    }

    private boolean isValidJoinMessage(JoinMessage joinMessage) {
        boolean validJoinRequest;
        try {
            validJoinRequest = validateJoinMessage(joinMessage);
        } catch (ConfigMismatchException e) {
            throw e;
        } catch (Exception e) {
            validJoinRequest = false;
        }
        return validJoinRequest;
    }

    private void logIfConnectionToEndpointIsMissing(long now, MemberImpl member) {
        if ((now - member.getLastRead()) >= PING_INTERVAL && (now - member.getLastPing()) >= PING_INTERVAL) {
            Connection conn = node.connectionManager.getOrConnect(member.getAddress());
            if (conn == null || !conn.isAlive()) {
                logger.warning("This node does not have a connection to " + member);
            }
        }
    }

    private void heartBeater() {
        if (!node.joined() || !node.isActive()) {
            return;
        }

        long now = Clock.currentTimeMillis();

        
        long clockJump = 0L;
        if (lastHeartBeat != 0L) {
            clockJump = now - lastHeartBeat - TimeUnit.SECONDS.toMillis(heartbeatInterval);
            if (Math.abs(clockJump) > HEARTBEAT_LOG_THRESHOLD) {
                SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS");
                logger.info("System clock apparently jumped from " + sdf.format(new Date(lastHeartBeat)) + " to " +
                        sdf.format(new Date(now)) + " since last heartbeat (" + String.format("%+d", clockJump) + "ms).");
            }
            clockJump = Math.max(0L, clockJump);

            if (clockJump >= maxNoMasterConfirmationMillis / 2) {
                logger.warning(
                        "Resetting master confirmation timestamps because of huge system clock jump! " + "Clock-Jump: "
                                + clockJump + "ms, Master-Confirmation-Timeout: " + maxNoMasterConfirmationMillis
                                + "ms.");
                resetMemberMasterConfirmations();
            }
        }
        lastHeartBeat = now;

        if (node.isMaster()) {
            heartBeaterMaster(now, clockJump);
        } else {
            heartBeaterSlave(now, clockJump);
        }
    }

    private void heartBeaterMaster(long now, long clockJump) {
        Collection<MemberImpl> members = getMemberList();
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    logIfConnectionToEndpointIsMissing(now, member);
                    if (removeMemberIfNotHeartBeating(now - clockJump, member)) {
                        continue;
                    }

                    if (removeMemberIfMasterConfirmationExpired(now - clockJump, member)) {
                        continue;
                    }

                    pingMemberIfRequired(now, member);
                    sendHearBeatIfRequired(now, member);
                } catch (Throwable e) {
                    logger.severe(e);
                }
            }
        }
    }

    private boolean removeMemberIfNotHeartBeating(long now, MemberImpl member) {
        if ((now - member.getLastRead()) > maxNoHeartbeatMillis) {
            logger.warning("Removing " + member + " because it has not sent any heartbeats for " +
                    maxNoHeartbeatMillis + " ms.");
            removeAddress(member.getAddress());
            return true;
        }
        return false;
    }

    private boolean removeMemberIfMasterConfirmationExpired(long now, MemberImpl member) {
        Long lastConfirmation = masterConfirmationTimes.get(member);
        if (lastConfirmation == null ||
                (now - lastConfirmation > maxNoMasterConfirmationMillis)) {
            logger.warning("Removing " + member + " because it has not sent any master confirmation " +
                    " for " + maxNoMasterConfirmationMillis + " ms.");
            removeAddress(member.getAddress());
            return true;
        }
        return false;
    }

    private void heartBeaterSlave(long now, long clockJump) {
        Collection<MemberImpl> members = getMemberList();

        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    logIfConnectionToEndpointIsMissing(now, member);

                    if (isMaster(member)) {
                        if (removeMemberIfNotHeartBeating(now - clockJump, member)) {
                            continue;
                        }
                    }

                    pingMemberIfRequired(now, member);
                    sendHearBeatIfRequired(now, member);
                } catch (Throwable e) {
                    logger.severe(e);
                }
            }
        }
    }

    private boolean isMaster(MemberImpl member) {
        return member.getAddress().equals(getMasterAddress());
    }

    private void sendHearBeatIfRequired(long now, MemberImpl member) {
        if ((now - member.getLastWrite()) > HEARTBEAT_INTERVAL) {
            sendHeartbeat(member.getAddress());
        }
    }

    private void pingMemberIfRequired(long now, MemberImpl member) {
        if ((now - member.getLastRead()) >= PING_INTERVAL && (now - member.getLastPing()) >= PING_INTERVAL) {
            ping(member);
        }
    }

    private void ping(final MemberImpl memberImpl) {
        memberImpl.didPing();
        if (!icmpEnabled) {
            return;
        }
        nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
            public void run() {
                try {
                    final Address address = memberImpl.getAddress();
                    logger.warning(thisAddress + " will ping " + address);
                    for (int i = 0; i < 5; i++) {
                        try {
                            if (address.getInetAddress().isReachable(null, icmpTtl, icmpTimeout)) {
                                logger.info(thisAddress + " pings successfully. Target: " + address);
                                return;
                            }
                        } catch (ConnectException ignored) {
                            
                            
                        }
                    }
                    logger.warning(thisAddress + " couldn't ping " + address);
                    
                    removeAddress(address);
                } catch (Throwable ignored) {
                }
            }
        });
    }

    private void sendHeartbeat(Address target) {
        if (target == null) return;
        try {
            node.nodeEngine.getOperationService().send(new HeartbeatOperation(), target);
        } catch (Exception e) {
            if (logger.isFinestEnabled()) {
                logger.finest("Error while sending heartbeat -> "
                        + e.getClass().getName() + "[" + e.getMessage() + "]");
            }
        }
    }

    private void sendMasterConfirmation() {
        if (!node.joined() || !node.isActive() || isMaster()) {
            return;
        }
        final Address masterAddress = getMasterAddress();
        if (masterAddress == null) {
            logger.finest("Could not send MasterConfirmation, master is null!");
            return;
        }
        final MemberImpl masterMember = getMember(masterAddress);
        if (masterMember == null) {
            logger.finest("Could not send MasterConfirmation, master is null!");
            return;
        }
        if (logger.isFinestEnabled()) {
            logger.finest("Sending MasterConfirmation to " + masterMember);
        }
        nodeEngine.getOperationService().send(new MasterConfirmationOperation(), masterAddress);
    }

    
    private void resetMemberMasterConfirmations() {
        final Collection<MemberImpl> memberList = getMemberList();
        for (MemberImpl member : memberList) {
            masterConfirmationTimes.put(member, Clock.currentTimeMillis());
        }
    }


    public void sendMemberListToMember(Address target) {
        if (!isMaster()) {
            return;
        }
        if (thisAddress.equals(target)) {
            return;
        }
        final Collection<MemberImpl> members = getMemberList();
        MemberInfoUpdateOperation op = new MemberInfoUpdateOperation(
                createMemberInfoList(members), clusterClock.getClusterTime(), false);
        nodeEngine.getOperationService().send(op, target);
    }

    private void sendMemberListToOthers() {
        if (!isMaster()) {
            return;
        }
        final Collection<MemberImpl> members = getMemberList();
        MemberInfoUpdateOperation op = new MemberInfoUpdateOperation(
                createMemberInfoList(members), clusterClock.getClusterTime(), false);
        for (MemberImpl member : members) {
            if (member.equals(thisMember)) {
                continue;
            }
            nodeEngine.getOperationService().send(op, member.getAddress());
        }
    }

    public void removeAddress(Address deadAddress) {
        doRemoveAddress(deadAddress, true);
    }

    private void doRemoveAddress(Address deadAddress, boolean destroyConnection) {
        if (preparingToMerge.get()) {
            logger.warning("Cluster-merge process is ongoing, won't process member removal: " + deadAddress);
            return;
        }
        if (!node.joined()) {
            return;
        }
        if (deadAddress.equals(thisAddress)) {
            return;
        }
        lock.lock();
        try {
            if (deadAddress.equals(node.getMasterAddress())) {
                assignNewMaster();
            }
            if (node.isMaster()) {
                setJoins.remove(new MemberInfo(deadAddress));
                resetMemberMasterConfirmations();
            }
            final Connection conn = node.connectionManager.getConnection(deadAddress);
            if (destroyConnection && conn != null) {
                node.connectionManager.destroyConnection(conn);
            }
            MemberImpl deadMember = getMember(deadAddress);
            if (deadMember != null) {
                removeMember(deadMember);
                logger.info(membersString());
            }
        } finally {
            lock.unlock();
        }
    }

    private void assignNewMaster() {
        final Address oldMasterAddress = node.getMasterAddress();
        if (node.joined()) {
            final Collection<MemberImpl> members = getMemberList();
            MemberImpl newMaster = null;
            final int size = members.size();
            if (size > 1) {
                final Iterator<MemberImpl> iter = members.iterator();
                final MemberImpl member = iter.next();
                if (member.getAddress().equals(oldMasterAddress)) {
                    newMaster = iter.next();
                } else {
                    logger.severe("Old master " + oldMasterAddress
                            + " is dead but the first of member list is a different member " +
                            member + "!");
                    newMaster = member;
                }
            } else {
                logger.warning("Old master is dead and this node is not master " +
                        "but member list contains only " + size + " members! -> " + members);
            }
            logger.info("Master " + oldMasterAddress + " left the cluster. Assigning new master " + newMaster);
            if (newMaster != null) {
                node.setMasterAddress(newMaster.getAddress());
            } else {
                node.setMasterAddress(null);
            }
        } else {
            node.setMasterAddress(null);
        }
        if (logger.isFinestEnabled()) {
            logger.finest("Now Master " + node.getMasterAddress());
        }
    }

    public void answerMasterQuestion(JoinMessage joinMessage) {
        if (!ensureValidConfiguration(joinMessage)) {
            return;
        }

        if (node.getMasterAddress() != null) {
            sendMasterAnswer(joinMessage.getAddress());
        } else {
            if (logger.isFinestEnabled()) {
                logger.finest("Received a master question from " + joinMessage.getAddress()
                        + ", but this node is not master itself or doesn't have a master yet!");
            }
        }
    }

    public void handleJoinRequest(JoinRequest joinRequest, Connection connection) {
        if (!node.joined() || !node.isActive()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Node is not ready to process join request...");
            }
            return;
        }

        if (!ensureValidConfiguration(joinRequest)) {
            return;
        }

        Address target = joinRequest.getAddress();
        boolean isRequestFromCurrentMaster = target.equals(node.getMasterAddress());
        
        
        if (!node.isMaster() && !isRequestFromCurrentMaster) {
            sendMasterAnswer(target);
            return;
        }

        if (joinInProgress) {
            if (logger.isFinestEnabled()) {
                logger.finest("Join is in-progress. Cannot handle join request from "
                        + target + " at the moment.");
            }
            return;
        }

        lock.lock();
        try {
            if (isJoinRequestFromAnExistingMember(joinRequest, connection)) {
                return;
            }

            long now = Clock.currentTimeMillis();
            if (logger.isFinestEnabled()) {
                String msg = "Handling join from " + target + ", inProgress: " + joinInProgress
                        + (timeToStartJoin > 0 ? ", timeToStart: " + (timeToStartJoin - now) : "");
                logger.finest(msg);
            }

            MemberInfo memberInfo = new MemberInfo(target, joinRequest.getUuid(),
                    joinRequest.getAttributes());

            if (!setJoins.contains(memberInfo)) {
                try {
                    checkSecureLogin(joinRequest, memberInfo);
                } catch (Exception e) {
                    ILogger securityLogger = node.loggingService.getLogger("com.hazelcast.security");
                    sendAuthenticationFailure(target);
                    securityLogger.severe(e);
                    return;
                }
            }

            if (node.isMaster()) {
                try {
                    node.getNodeExtension().beforeJoin();
                } catch (Exception e) {
                    logger.warning(e.getMessage());
                    sendBeforeJoinCheckFailure(target, e.getMessage());
                    return;
                }
            }

            if (firstJoinRequest == 0) {
                firstJoinRequest = now;
            }

            if (setJoins.add(memberInfo)) {
                sendMasterAnswer(target);
                if (now - firstJoinRequest < maxWaitMillisBeforeJoin) {
                    timeToStartJoin = now + waitMillisBeforeJoin;
                }
            }
            if (now > timeToStartJoin) {
                startJoin();
            }
        } finally {
            lock.unlock();
        }
    }

    private boolean ensureValidConfiguration(JoinMessage joinMessage) {
        try {
            if (isValidJoinMessage(joinMessage)) {
                return true;
            }

            logger.warning("Received an invalid join request from " + joinMessage.getAddress()
                    + ", cause: clusters part of different cluster-groups");

            nodeEngine.getOperationService().send(new GroupMismatchOperation(), joinMessage.getAddress());
        } catch (ConfigMismatchException e) {
            logger.warning("Received an invalid join request from " + joinMessage.getAddress()
                    + ", cause:" + e.getMessage());
            sendConfigurationMismatchFailure(joinMessage.getAddress(), e.getMessage());
        }
        return false;
    }

    private void sendAuthenticationFailure(Address target) {
        nodeEngine.getOperationService().send(new AuthenticationFailureOperation(), target);
    }

    private void sendBeforeJoinCheckFailure(Address target, String message) {
        nodeEngine.getOperationService().send(new BeforeJoinCheckFailureOperation(message), target);
    }

    private void sendConfigurationMismatchFailure(Address target, String msg) {
        OperationService operationService = nodeEngine.getOperationService();
        operationService.send(new ConfigMismatchOperation(msg), target);
    }

    private void checkSecureLogin(JoinRequest joinRequest, MemberInfo newMemberInfo) {
        if (node.securityContext != null && !setJoins.contains(newMemberInfo)) {
            Credentials cr = joinRequest.getCredentials();
            if (cr == null) {
                throw new SecurityException("Expecting security credentials " +
                        "but credentials could not be found in JoinRequest!");
            }

            try {
                LoginContext lc = node.securityContext.createMemberLoginContext(cr);
                lc.login();
            } catch (LoginException e) {
                throw new SecurityException(
                        "Authentication has failed for " + cr.getPrincipal() + '@' + cr.getEndpoint()
                                + " => (" + e.getMessage() + ")");
            }
        }
    }

    private boolean isJoinRequestFromAnExistingMember(JoinRequest joinRequest, Connection connection) {
        MemberImpl member = getMember(joinRequest.getAddress());
        if (member == null) {
            return false;
        }

        Address target = member.getAddress();
        if (joinRequest.getUuid().equals(member.getUuid())) {
            if (node.isMaster()) {
                if (logger.isFinestEnabled()) {
                    String message = "Ignoring join request, member already exists.. => " + joinRequest;
                    logger.finest(message);
                }
                
                final Operation[] postJoinOps = nodeEngine.getPostJoinOperations();
                final PostJoinOperation postJoinOp = postJoinOps != null && postJoinOps.length > 0
                        ? new PostJoinOperation(postJoinOps) : null;

                Operation op = new FinalizeJoinOperation(createMemberInfoList(getMemberList()), postJoinOp,
                        clusterClock.getClusterTime(), false);
                nodeEngine.getOperationService().send(op, target);
            } else {
                sendMasterAnswer(target);
            }
            return true;
        }

        
        
        
        
        if (node.isMaster() || target.equals(node.getMasterAddress())) {
            logger.warning("New join request has been received from an existing endpoint! => " + member
                    + " Removing old member and processing join request...");

            doRemoveAddress(target, false);
            Connection existing = node.connectionManager.getConnection(target);
            if (existing != connection) {
                node.connectionManager.destroyConnection(existing);
                node.connectionManager.registerConnection(target, connection);
            }
            return false;
        }
        return true;
    }

    private void sendMasterAnswer(Address target) {
        Address masterAddress = node.getMasterAddress();
        if (masterAddress == null) {
            logger.info("Cannot send master answer to " + target + " since master node is not known yet");
            return;
        }
        SetMasterOperation op = new SetMasterOperation(masterAddress);
        nodeEngine.getOperationService().send(op, target);
    }

    public void handleMaster(Address masterAddress, Address callerAddress) {
        if (node.joined()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Ignoring master response: " + masterAddress + " from: " + callerAddress
                        + ". This node is already joined...");
            }
            return;
        }

        if (node.getThisAddress().equals(masterAddress)) {
            if (node.isMaster()) {
                logger.finest("Ignoring master response: " + masterAddress + " from: " + callerAddress
                        + ". This node is already master...");
            } else {
                node.setAsMaster();
            }
            return;
        }

        lock.lock();
        try {
            if (logger.isFinestEnabled()) {
                logger.finest("Handling master response: " + masterAddress + " from: " + callerAddress);
            }
            final Address currentMaster = node.getMasterAddress();
            if (currentMaster == null || currentMaster.equals(masterAddress)) {
                setMasterAndJoin(masterAddress);
            } else if (currentMaster.equals(callerAddress)) {
                logger.info("Setting master to: " + masterAddress + ", since "
                        + currentMaster + " says it's not master anymore.");
                setMasterAndJoin(masterAddress);
            } else {
                final Connection conn = node.connectionManager.getConnection(currentMaster);
                if (conn != null && conn.isAlive()) {
                    logger.info("Ignoring master response: " + masterAddress + " from: " + callerAddress
                            + ", since this node has an active master: " + currentMaster);
                    sendJoinRequest(currentMaster, true);
                } else {
                    logger.warning("Ambiguous master response, this node has a master: " + currentMaster
                            + ", but doesn't have a connection to. " + callerAddress + " sent master response as: "
                            + masterAddress + ". Master field will be unset now...");
                    node.setMasterAddress(null);
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void setMasterAndJoin(Address masterAddress) {
        node.setMasterAddress(masterAddress);
        node.connectionManager.getOrConnect(masterAddress);
        if (!sendJoinRequest(masterAddress, true)) {
            logger.warning("Could not create connection to possible master " + masterAddress);
        }
    }

    public void acceptMasterConfirmation(MemberImpl member) {
        if (member != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("MasterConfirmation has been received from " + member);
            }
            masterConfirmationTimes.put(member, Clock.currentTimeMillis());
        }
    }

    public void prepareToMerge(final Address newTargetAddress) {
        preparingToMerge.set(true);
        node.getJoiner().setTargetAddress(newTargetAddress);
        nodeEngine.getExecutionService().schedule(new Runnable() {
            public void run() {
                merge(newTargetAddress);
            }
        }, 10, TimeUnit.SECONDS);
    }

    public void merge(Address newTargetAddress) {
        if (preparingToMerge.compareAndSet(true, false)) {
            node.getJoiner().setTargetAddress(newTargetAddress);
            final LifecycleServiceImpl lifecycleService = node.hazelcastInstance.getLifecycleService();
            lifecycleService.runUnderLifecycleLock(new Runnable() {
                public void run() {
                    lifecycleService.fireLifecycleEvent(MERGING);
                    final NodeEngineImpl nodeEngine = node.nodeEngine;
                    final Collection<SplitBrainHandlerService> services = nodeEngine
                            .getServices(SplitBrainHandlerService.class);
                    final Collection<Runnable> tasks = new LinkedList<Runnable>();
                    for (SplitBrainHandlerService service : services) {
                        final Runnable runnable = service.prepareMergeRunnable();
                        if (runnable != null) {
                            tasks.add(runnable);
                        }
                    }
                    final Collection<ManagedService> managedServices = nodeEngine.getServices(ManagedService.class);
                    for (ManagedService service : managedServices) {
                        service.reset();
                    }
                    node.onRestart();
                    node.nodeEngine.reset();
                    node.connectionManager.restart();
                    node.rejoin();
                    final Collection<Future> futures = new LinkedList<Future>();
                    for (Runnable task : tasks) {
                        Future f = nodeEngine.getExecutionService().submit("hz:system", task);
                        futures.add(f);
                    }
                    long callTimeout = node.groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong();
                    for (Future f : futures) {
                        try {
                            waitOnFutureInterruptible(f, callTimeout, TimeUnit.MILLISECONDS);
                        } catch (HazelcastInstanceNotActiveException e) {
                            EmptyStatement.ignore(e);
                        } catch (Exception e) {
                            logger.severe("While merging...", e);
                        }
                    }
                    if (node.isActive() && node.joined()) {
                        lifecycleService.fireLifecycleEvent(MERGED);
                    }
                }
            });
        }
    }

    private <V> V waitOnFutureInterruptible(Future<V> future, long timeout, TimeUnit timeUnit)
            throws ExecutionException, InterruptedException, TimeoutException {

        isNotNull(timeUnit, "timeUnit");
        long deadline = Clock.currentTimeMillis() + timeUnit.toMillis(timeout);
        while (true) {
            long localTimeout = Math.min(1000 * 10, deadline);
            try {
                return future.get(localTimeout, TimeUnit.MILLISECONDS);
            } catch (TimeoutException te) {
                deadline -= localTimeout;
                if (deadline <= 0) {
                    throw te;
                }
                if (!node.isActive()) {
                    future.cancel(true);
                    throw new HazelcastInstanceNotActiveException();
                }
            }
        }
    }

    private void joinReset() {
        lock.lock();
        try {
            joinInProgress = false;
            setJoins.clear();
            timeToStartJoin = Clock.currentTimeMillis() + waitMillisBeforeJoin;
            firstJoinRequest = 0;
        } finally {
            lock.unlock();
        }
    }

    @Override
    public void reset() {
        lock.lock();
        try {
            joinInProgress = false;
            setJoins.clear();
            timeToStartJoin = 0;
            setMembersRef(Collections.singletonMap(thisAddress, thisMember));
            masterConfirmationTimes.clear();
        } finally {
            lock.unlock();
        }
    }

    private void startJoin() {
        logger.finest("Starting Join.");
        lock.lock();
        try {
            try {
                joinInProgress = true;
                
                node.getPartitionService().pauseMigration();
                final Collection<MemberImpl> members = getMemberList();
                final Collection<MemberInfo> memberInfos = createMemberInfoList(members);
                for (MemberInfo memberJoining : setJoins) {
                    memberInfos.add(memberJoining);
                }
                final long time = clusterClock.getClusterTime();
                
                
                final Operation[] postJoinOps = nodeEngine.getPostJoinOperations();
                final PostJoinOperation postJoinOp = postJoinOps != null && postJoinOps.length > 0
                        ? new PostJoinOperation(postJoinOps) : null;
                final int count = members.size() - 1 + setJoins.size();
                final List<Future> calls = new ArrayList<Future>(count);
                for (MemberInfo member : setJoins) {
                    final long startTime = clusterClock.getClusterStartTime();
                    calls.add(invokeClusterOperation(new FinalizeJoinOperation(memberInfos, postJoinOp, time,
                            clusterId, startTime), member.getAddress()));
                }
                for (MemberImpl member : members) {
                    if (!member.getAddress().equals(thisAddress)) {
                        calls.add(invokeClusterOperation(new MemberInfoUpdateOperation(memberInfos, time, true), member.getAddress()));
                    }
                }
                updateMembers(memberInfos);
                int timeout = Math.min(calls.size() * FINALIZE_JOIN_TIMEOUT_FACTOR, FINALIZE_JOIN_MAX_TIMEOUT);
                waitWithDeadline(calls, timeout, TimeUnit.SECONDS, whileFinalizeJoinsExceptionHandler);
            } finally {
                node.getPartitionService().resumeMigration();
            }
        } finally {
            lock.unlock();
        }
    }

    private static List<MemberInfo> createMemberInfoList(Collection<MemberImpl> members) {
        final List<MemberInfo> memberInfos = new LinkedList<MemberInfo>();
        for (MemberImpl member : members) {
            memberInfos.add(new MemberInfo(member));
        }
        return memberInfos;
    }

    private static Set<MemberInfo> createMemberInfoSet(Collection<MemberImpl> members) {
        final Set<MemberInfo> memberInfos = new HashSet<MemberInfo>();
        for (MemberImpl member : members) {
            memberInfos.add(new MemberInfo(member));
        }
        return memberInfos;
    }

    public void updateMembers(Collection<MemberInfo> members) {
        lock.lock();
        try {
            Map<Address, MemberImpl> currentMemberMap = membersMapRef.get();

            if (!shouldProcessMemberUpdate(currentMemberMap, members)) {
                return;
            }

            MemberImpl[] newMembers = new MemberImpl[members.size()];
            int k = 0;
            for (MemberInfo memberInfo : members) {
                MemberImpl member = currentMemberMap.get(memberInfo.getAddress());
                if (member == null) {
                    member = createMember(memberInfo.getAddress(), memberInfo.getUuid(),
                            thisAddress.getScopeId(), memberInfo.getAttributes());
                }
                newMembers[k++] = member;
                member.didRead();
            }
            setMembers(newMembers);
            if (!getMemberList().contains(thisMember)) {
                throw new HazelcastException("Member list doesn't contain local member!");
            }
            joinReset();
            heartBeater();
            node.setJoined();
            logger.info(membersString());
        } finally {
            lock.unlock();
        }
    }

    private boolean shouldProcessMemberUpdate(Map<Address, MemberImpl> currentMembers,
                                              Collection<MemberInfo> newMemberInfos) {

        int currentMembersSize = currentMembers.size();
        int newMembersSize = newMemberInfos.size();

        if (currentMembersSize > newMembersSize) {
            logger.warning("Received an older member update, no need to process...");
            nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            return false;
        }

        
        if (currentMembersSize == newMembersSize) {
            Set<MemberInfo> currentMemberInfos = createMemberInfoSet(currentMembers.values());
            if (currentMemberInfos.containsAll(newMemberInfos)) {
                logger.finest("Received a periodic member update, no need to process...");
            } else {
                logger.warning("Received an inconsistent member update "
                        + "which contains new members and removes some of the current members! "
                        + "Ignoring and requesting a new member update...");
                nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            }
            return false;
        }

        Set<MemberInfo> currentMemberInfos = createMemberInfoSet(currentMembers.values());
        currentMemberInfos.removeAll(newMemberInfos);
        if (currentMemberInfos.isEmpty()) {
            return true;
        } else {
            logger.warning("Received an inconsistent member update, it has more members but "
                    + "but also removes some of the current members! "
                    + "Ignoring and requesting a new member update...");
            nodeEngine.getOperationService().send(new TriggerMemberListPublishOperation(), getMasterAddress());
            return false;
        }
    }

    public void updateMemberAttribute(String uuid, MemberAttributeOperationType operationType, String key, Object value) {
        lock.lock();
        try {
            Map<Address, MemberImpl> memberMap = membersMapRef.get();
            for (MemberImpl member : memberMap.values()) {
                if (member.getUuid().equals(uuid)) {
                    if (!member.equals(getLocalMember())) {
                        member.updateAttribute(operationType, key, value);
                    }
                    sendMemberAttributeEvent(member, operationType, key, value);
                    break;
                }
            }
        } finally {
            lock.unlock();
        }
    }

    public boolean sendJoinRequest(Address toAddress, boolean withCredentials) {
        if (toAddress == null) {
            toAddress = node.getMasterAddress();
        }
        JoinRequestOperation joinRequest = new JoinRequestOperation(node.createJoinRequest(withCredentials));
        return nodeEngine.getOperationService().send(joinRequest, toAddress);
    }

    public boolean sendMasterQuestion(Address toAddress) {
        checkNotNull(toAddress, "No endpoint is specified!");

        BuildInfo buildInfo = node.getBuildInfo();
        JoinMessage joinMessage = new JoinMessage(Packet.VERSION, buildInfo.getBuildNumber(), thisAddress,
                thisMember.getUuid(), node.createConfigCheck(), getSize());
        return nodeEngine.getOperationService().send(new MasterDiscoveryOperation(joinMessage), toAddress);
    }

    @Override
    public void connectionAdded(final Connection connection) {
        MemberImpl member = getMember(connection.getEndPoint());
        if (member != null) {
            member.didRead();
        }
    }

    @Override
    public void connectionRemoved(Connection connection) {
        if (logger.isFinestEnabled()) {
            logger.finest("Connection is removed " + connection.getEndPoint());
        }
        if (!node.joined()) {
            final Address masterAddress = node.getMasterAddress();
            if (masterAddress != null && masterAddress.equals(connection.getEndPoint())) {
                node.setMasterAddress(null);
            }
        }
    }

    private Future invokeClusterOperation(Operation op, Address target) {
        return nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, op, target)
                .setTryCount(100).invoke();
    }

    public NodeEngineImpl getNodeEngine() {
        return nodeEngine;
    }

    private void setMembers(MemberImpl... members) {
        if (members == null || members.length == 0) return;
        if (logger.isFinestEnabled()) {
            logger.finest("Updating members -> " + Arrays.toString(members));
        }
        lock.lock();
        try {
            Map<Address, MemberImpl> oldMemberMap = membersMapRef.get();
            final Map<Address, MemberImpl> memberMap = new LinkedHashMap<Address, MemberImpl>();  
            final Collection<MemberImpl> newMembers = new LinkedList<MemberImpl>();
            for (MemberImpl member : members) {
                MemberImpl currentMember = oldMemberMap.get(member.getAddress());
                if (currentMember == null) {
                    newMembers.add(member);
                    masterConfirmationTimes.put(member, Clock.currentTimeMillis());
                }
                memberMap.put(member.getAddress(), member);
            }
            setMembersRef(memberMap);

            if (!newMembers.isEmpty()) {
                Set<Member> eventMembers = new LinkedHashSet<Member>(oldMemberMap.values());
                if (newMembers.size() == 1) {
                    MemberImpl newMember = newMembers.iterator().next();
                    node.getPartitionService().memberAdded(newMember); 
                    eventMembers.add(newMember);
                    sendMembershipEventNotifications(newMember, unmodifiableSet(eventMembers), true); 
                } else {
                    for (MemberImpl newMember : newMembers) {
                        node.getPartitionService().memberAdded(newMember); 
                        eventMembers.add(newMember);
                        sendMembershipEventNotifications(newMember, unmodifiableSet(new LinkedHashSet<Member>(eventMembers)), true); 
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void removeMember(MemberImpl deadMember) {
        logger.info("Removing " + deadMember);
        lock.lock();
        try {
            final Map<Address, MemberImpl> members = membersMapRef.get();
            if (members.containsKey(deadMember.getAddress())) {
                Map<Address, MemberImpl> newMembers = new LinkedHashMap<Address, MemberImpl>(members);  
                newMembers.remove(deadMember.getAddress());
                masterConfirmationTimes.remove(deadMember);
                setMembersRef(newMembers);
                node.getPartitionService().memberRemoved(deadMember); 
                nodeEngine.onMemberLeft(deadMember);                  
                if (node.isMaster()) {
                    if (logger.isFinestEnabled()) {
                        logger.finest(deadMember + " is dead. Sending remove to all other members.");
                    }
                    invokeMemberRemoveOperation(deadMember.getAddress());
                }
                
                sendMembershipEventNotifications(deadMember, unmodifiableSet(new LinkedHashSet<Member>(newMembers.values())), false);
            }
        } finally {
            lock.unlock();
        }
    }

    private void invokeMemberRemoveOperation(final Address deadAddress) {
        for (MemberImpl member : getMemberList()) {
            Address address = member.getAddress();
            if (!thisAddress.equals(address) && !address.equals(deadAddress)) {
                nodeEngine.getOperationService().send(new MemberRemoveOperation(deadAddress), address);
            }
        }
    }

    public void sendShutdownMessage() {
        invokeMemberRemoveOperation(thisAddress);
    }

    private void sendMembershipEventNotifications(final MemberImpl member, Set<Member> members, final boolean added) {
        final int eventType = added ? MembershipEvent.MEMBER_ADDED : MembershipEvent.MEMBER_REMOVED;
        final MembershipEvent membershipEvent = new MembershipEvent(getClusterProxy(), member, eventType, members);
        final Collection<MembershipAwareService> membershipAwareServices = nodeEngine.getServices(MembershipAwareService.class);
        if (membershipAwareServices != null && !membershipAwareServices.isEmpty()) {
            final MembershipServiceEvent event = new MembershipServiceEvent(membershipEvent);
            for (final MembershipAwareService service : membershipAwareServices) {
                
                nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                    public void run() {
                        if (added) {
                            service.memberAdded(event);
                        } else {
                            service.memberRemoved(event);
                        }
                    }
                });
            }
        }
        final EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        for (EventRegistration reg : registrations) {
            eventService.publishEvent(SERVICE_NAME, reg, membershipEvent, reg.getId().hashCode());
        }
    }

    private void sendMemberAttributeEvent(MemberImpl member, MemberAttributeOperationType operationType, String key, Object value) {
        final MemberAttributeEvent memberAttributeEvent = new MemberAttributeEvent(getClusterProxy(), member, operationType, key, value);
        final Collection<MembershipAwareService> membershipAwareServices = nodeEngine.getServices(MembershipAwareService.class);
        final MemberAttributeServiceEvent event = new MemberAttributeServiceEvent(getClusterProxy(), member, operationType, key, value);
        if (membershipAwareServices != null && !membershipAwareServices.isEmpty()) {
            for (final MembershipAwareService service : membershipAwareServices) {
                
                nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                    public void run() {
                        service.memberAttributeChanged(event);
                    }
                });
            }
        }
        final EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        for (EventRegistration reg : registrations) {
            eventService.publishEvent(SERVICE_NAME, reg, memberAttributeEvent, reg.getId().hashCode());
        }
    }

    protected MemberImpl createMember(Address address, String nodeUuid, String ipV6ScopeId, Map<String, Object> attributes) {
        address.setScopeId(ipV6ScopeId);
        return new MemberImpl(address, thisAddress.equals(address), nodeUuid,
                (HazelcastInstanceImpl) nodeEngine.getHazelcastInstance(), attributes);
    }

    @Override
    public MemberImpl getMember(Address address) {
        if (address == null) {
            return null;
        }
        Map<Address, MemberImpl> memberMap = membersMapRef.get();
        return memberMap.get(address);
    }

    @Override
    public MemberImpl getMember(String uuid) {
        if (uuid == null) {
            return null;
        }

        Map<Address, MemberImpl> memberMap = membersMapRef.get();
        for (MemberImpl member : memberMap.values()) {
            if (uuid.equals(member.getUuid())) {
                return member;
            }
        }
        return null;
    }

    private void setMembersRef(Map<Address, MemberImpl> memberMap) {
        memberMap = unmodifiableMap(memberMap);
        
        memberMap.values();
        memberMap.keySet();
        memberMap.entrySet();
        membersMapRef.set(memberMap);
        membersRef.set(unmodifiableSet(new LinkedHashSet<MemberImpl>(memberMap.values())));
    }

    @Override
    public Collection<MemberImpl> getMemberList() {
        return membersRef.get();
    }

    @Override
    public Set<Member> getMembers() {
        return (Set) membersRef.get();
    }

    @Override
    public void shutdown(boolean terminate) {
        reset();
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public boolean isMaster() {
        return node.isMaster();
    }

    @Override
    public Address getThisAddress() {
        return thisAddress;
    }

    public Member getLocalMember() {
        return node.getLocalMember();
    }

    @Override
    public int getSize() {
        final Collection<MemberImpl> members = getMemberList();
        return members != null ? members.size() : 0;
    }

    public String addMembershipListener(MembershipListener listener) {
        checkNotNull(listener, "listener can't be null");

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration;
        if (listener instanceof InitialMembershipListener) {
            lock.lock();
            try {
                ((InitialMembershipListener) listener).init(new InitialMembershipEvent(getClusterProxy(), getMembers()));
                registration = eventService.registerLocalListener(SERVICE_NAME, SERVICE_NAME, listener);
            } finally {
                lock.unlock();
            }
        } else {
            registration = eventService.registerLocalListener(SERVICE_NAME, SERVICE_NAME, listener);
        }

        return registration.getId();
    }

    public boolean removeMembershipListener(String registrationId) {
        checkNotNull(registrationId, "registrationId can't be null");

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, SERVICE_NAME, registrationId);
    }

    @SuppressFBWarnings("BC_UNCONFIRMED_CAST")
    @Override
    public void dispatchEvent(MembershipEvent event, MembershipListener listener) {
        switch (event.getEventType()) {
            case MembershipEvent.MEMBER_ADDED:
                listener.memberAdded(event);
                break;
            case MembershipEvent.MEMBER_REMOVED:
                listener.memberRemoved(event);
                break;
            case MembershipEvent.MEMBER_ATTRIBUTE_CHANGED:
                MemberAttributeEvent memberAttributeEvent = (MemberAttributeEvent) event;
                listener.memberAttributeChanged(memberAttributeEvent);
                break;
            default:
                throw new IllegalArgumentException("Unhandled event:" + event);
        }
    }

    public Cluster getClusterProxy() {
        return new ClusterProxy(this);
    }

    public String membersString() {
        StringBuilder sb = new StringBuilder("\n\nMembers [");
        final Collection<MemberImpl> members = getMemberList();
        sb.append(members != null ? members.size() : 0);
        sb.append("] {");
        if (members != null) {
            for (Member member : members) {
                sb.append("\n\t").append(member);
            }
        }
        sb.append("\n}\n");
        return sb.toString();
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append("ClusterService");
        sb.append("{address=").append(thisAddress);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.client.impl;

import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.ClientEndpointManager;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Connection;
import com.hazelcast.spi.NodeEngine;

import javax.security.auth.login.LoginException;
import java.util.Collection;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.util.Preconditions.checkNotNull;


public class ClientEndpointManagerImpl implements ClientEndpointManager {

    private static final int DESTROY_ENDPOINT_DELAY_MS = 1111;

    private final ILogger logger;
    private final ClientEngineImpl clientEngine;
    private final NodeEngine nodeEngine;
    private final ConcurrentMap<Connection, ClientEndpoint> endpoints =
            new ConcurrentHashMap<Connection, ClientEndpoint>();

    public ClientEndpointManagerImpl(ClientEngineImpl clientEngine, NodeEngine nodeEngine) {
        this.clientEngine = clientEngine;
        this.nodeEngine = nodeEngine;
        this.logger = nodeEngine.getLogger(ClientEndpointManager.class);
    }

    @Override
    public Set<ClientEndpoint> getEndpoints(String clientUuid) {
        checkNotNull(clientUuid, "clientUuid can't be null");

        Set<ClientEndpoint> endpointSet = new HashSet<ClientEndpoint>();
        for (ClientEndpoint endpoint : endpoints.values()) {
            if (clientUuid.equals(endpoint.getUuid())) {
                endpointSet.add(endpoint);
            }
        }
        return endpointSet;
    }

    @Override
    public ClientEndpoint getEndpoint(Connection connection) {
        checkNotNull(connection, "connection can't be null");

        return endpoints.get(connection);
    }

    @Override
    public void registerEndpoint(ClientEndpoint endpoint) {
        checkNotNull(endpoint, "endpoint can't be null");

        final Connection conn = endpoint.getConnection();
        if (endpoints.putIfAbsent(conn, endpoint) != null) {
            logger.severe("An endpoint already exists for connection:" + conn);
        }
    }

    @Override
    public void removeEndpoint(ClientEndpoint endpoint) {
        removeEndpoint(endpoint, false);
    }

    @Override
    public void removeEndpoint(final ClientEndpoint ce, boolean closeImmediately) {
        checkNotNull(ce, "endpoint can't be null");

        ClientEndpointImpl endpoint = (ClientEndpointImpl) ce;

        endpoints.remove(endpoint.getConnection());
        logger.info("Destroying " + endpoint);
        try {
            endpoint.destroy();
        } catch (LoginException e) {
            logger.warning(e);
        }

        final Connection connection = endpoint.getConnection();
        if (closeImmediately) {
            try {
                connection.close();
            } catch (Throwable e) {
                logger.warning("While closing client connection: " + connection, e);
            }
        } else {
            nodeEngine.getExecutionService().schedule(new Runnable() {
                public void run() {
                    if (connection.isAlive()) {
                        try {
                            connection.close();
                        } catch (Throwable e) {
                            logger.warning("While closing client connection: " + e.toString());
                        }
                    }
                }
            }, DESTROY_ENDPOINT_DELAY_MS, TimeUnit.MILLISECONDS);
        }
        clientEngine.sendClientEvent(endpoint);
    }

    public void removeEndpoints(String memberUuid) {
        Iterator<ClientEndpoint> iterator = endpoints.values().iterator();
        while (iterator.hasNext()) {
            ClientEndpoint endpoint = iterator.next();
            String ownerUuid = endpoint.getPrincipal().getOwnerUuid();
            if (memberUuid.equals(ownerUuid)) {
                iterator.remove();
                removeEndpoint(endpoint, true);
            }
        }
    }

    @Override
    public void clear() {
        endpoints.clear();
    }

    @Override
    public Collection<ClientEndpoint> getEndpoints() {
        return endpoints.values();
    }

    @Override
    public int size() {
        return endpoints.size();
    }
}

<code block>


package com.hazelcast.util.executor;

import java.util.concurrent.ExecutorService;

public interface ManagedExecutorService extends ExecutorService {

    String getName();

    long getCompletedTaskCount();

    int getMaximumPoolSize();

    int getPoolSize();

    int getQueueSize();

    int getRemainingQueueCapacity();
}

<code block>


package com.hazelcast.nio;


public interface ConnectionManager {

    int getCurrentClientConnections();

    int getConnectionCount();

    int getAllTextConnections();

    int getActiveConnectionCount();

    Connection getConnection(Address address);

    Connection getOrConnect(Address address);

    Connection getOrConnect(Address address, boolean silent);

    boolean registerConnection(Address address, Connection connection);

    void destroyConnection(Connection conn);

    void shutdown();

    void start();

    void restart();

    void addConnectionListener(ConnectionListener connectionListener);

    
    void dumpPerformanceMetrics(StringBuffer sb);
}

<code block>


package com.hazelcast.nio;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.internal.ascii.TextCommandService;
import com.hazelcast.config.NetworkConfig;
import com.hazelcast.config.SSLConfig;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.config.SymmetricEncryptionConfig;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.PacketReader;
import com.hazelcast.nio.tcp.PacketWriter;
import com.hazelcast.nio.tcp.SocketChannelWrapperFactory;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.transceiver.PacketTransceiver;

import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.Set;

public class NodeIOService implements IOService {

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final PacketTransceiver packetTransceiver;

    public NodeIOService(Node node, NodeEngineImpl nodeEngine) {
        this.node = node;
        this.nodeEngine = nodeEngine;
        this.packetTransceiver = nodeEngine.getPacketTransceiver();
    }

    @Override
    public boolean isActive() {
        return node.isActive();
    }

    @Override
    public ILogger getLogger(String name) {
        return node.getLogger(name);
    }

    @Override
    public void onOutOfMemory(OutOfMemoryError oom) {
        OutOfMemoryErrorDispatcher.onOutOfMemory(oom);
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public void onFatalError(Exception e) {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        new Thread(threadGroup.getInternalThreadGroup(), threadGroup.getThreadNamePrefix("io.error.shutdown")) {
            public void run() {
                node.shutdown(false);
            }
        } .start();
    }

    @Override
    public SocketInterceptorConfig getSocketInterceptorConfig() {
        return node.getConfig().getNetworkConfig().getSocketInterceptorConfig();
    }

    @Override
    public SymmetricEncryptionConfig getSymmetricEncryptionConfig() {
        return node.getConfig().getNetworkConfig().getSymmetricEncryptionConfig();
    }

    @Override
    public SSLConfig getSSLConfig() {
        return node.getConfig().getNetworkConfig().getSSLConfig();
    }

    @Override
    public void handleMemberPacket(final Packet packet) {
        final Address endPoint = packet.getConn().getEndPoint();
        if (endPoint != null) {
            final MemberImpl member = node.clusterService.getMember(endPoint);
            if (member != null) {
                member.didRead();
            }
        }
        packetTransceiver.receive(packet);
    }

    @Override
    public void handleClientPacket(Packet p) {
        node.clientEngine.handlePacket(p);
    }

    @Override
    public void handleClientMessage(ClientMessage cm, Connection connection) {
        node.clientEngine.handleClientMessage(cm, connection);
    }

    @Override
    public TextCommandService getTextCommandService() {
        return node.getTextCommandService();
    }

    @Override
    public boolean isMemcacheEnabled() {
        return node.groupProperties.MEMCACHE_ENABLED.getBoolean();
    }

    @Override
    public boolean isRestEnabled() {
        return node.groupProperties.REST_ENABLED.getBoolean();
    }

    @Override
    public void removeEndpoint(final Address endPoint) {
        nodeEngine.getExecutionService().execute(ExecutionService.IO_EXECUTOR, new Runnable() {
            @Override
            public void run() {
                node.clusterService.removeAddress(endPoint);
            }
        });
    }

    @Override
    public String getThreadPrefix() {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        return threadGroup.getThreadPoolNamePrefix("IO");
    }

    @Override
    public ThreadGroup getThreadGroup() {
        HazelcastThreadGroup threadGroup = node.getHazelcastThreadGroup();
        return threadGroup.getInternalThreadGroup();
    }

    @Override
    public void onSuccessfulConnection(Address address) {
        if (!node.joined()) {
            node.getJoiner().unblacklist(address);
        }
    }

    @Override
    public void onFailedConnection(Address address) {
        if (!node.joined()) {
            node.getJoiner().blacklist(address, false);
        }
    }

    @Override
    public void shouldConnectTo(Address address) {
        if (node.getThisAddress().equals(address)) {
            throw new RuntimeException("Connecting to self! " + address);
        }
    }

    @Override
    public boolean isSocketBind() {
        return node.groupProperties.SOCKET_CLIENT_BIND.getBoolean();
    }

    @Override
    public boolean isSocketBindAny() {
        return node.groupProperties.SOCKET_CLIENT_BIND_ANY.getBoolean();
    }

    @Override
    public int getSocketReceiveBufferSize() {
        return this.node.getGroupProperties().SOCKET_RECEIVE_BUFFER_SIZE.getInteger();
    }

    @Override
    public int getSocketSendBufferSize() {
        return this.node.getGroupProperties().SOCKET_SEND_BUFFER_SIZE.getInteger();
    }

    @Override
    public int getSocketLingerSeconds() {
        return this.node.getGroupProperties().SOCKET_LINGER_SECONDS.getInteger();
    }

    @Override
    public int getSocketConnectTimeoutSeconds() {
        return this.node.getGroupProperties().SOCKET_CONNECT_TIMEOUT_SECONDS.getInteger();
    }

    @Override
    public boolean getSocketKeepAlive() {
        return this.node.getGroupProperties().SOCKET_KEEP_ALIVE.getBoolean();
    }

    @Override
    public boolean getSocketNoDelay() {
        return this.node.getGroupProperties().SOCKET_NO_DELAY.getBoolean();
    }

    @Override
    public int getSelectorThreadCount() {
        return node.groupProperties.IO_THREAD_COUNT.getInteger();
    }

    @Override
    public void onDisconnect(final Address endpoint) {
    }

    @Override
    public boolean isClient() {
        return false;
    }

    @Override
    public long getConnectionMonitorInterval() {
        return node.groupProperties.CONNECTION_MONITOR_INTERVAL.getLong();
    }

    @Override
    public int getConnectionMonitorMaxFaults() {
        return node.groupProperties.CONNECTION_MONITOR_MAX_FAULTS.getInteger();
    }

    @Override
    public int getBalancerIntervalSeconds() {
        return node.groupProperties.IO_BALANCER_INTERVAL_SECONDS.getInteger();
    }

    @Override
    public void executeAsync(final Runnable runnable) {
        nodeEngine.getExecutionService().execute(ExecutionService.IO_EXECUTOR, runnable);
    }

    @Override
    public EventService getEventService() {
        return nodeEngine.getEventService();
    }

    @Override
    public Data toData(Object obj) {
        return nodeEngine.toData(obj);
    }

    @Override
    public Object toObject(Data data) {
        return nodeEngine.toObject(data);
    }

    @Override
    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    @Override
    public SocketChannelWrapperFactory getSocketChannelWrapperFactory() {
        return node.getNodeExtension().getSocketChannelWrapperFactory();
    }

    @Override
    public MemberSocketInterceptor getMemberSocketInterceptor() {
        return node.getNodeExtension().getMemberSocketInterceptor();
    }

    @Override
    public PacketReader createPacketReader(TcpIpConnection connection) {
        return node.getNodeExtension().createPacketReader(connection, this);
    }

    @Override
    public PacketWriter createPacketWriter(TcpIpConnection connection) {
        return node.getNodeExtension().createPacketWriter(connection, this);
    }

    @Override
    public Collection<Integer> getOutboundPorts() {
        final NetworkConfig networkConfig = node.getConfig().getNetworkConfig();
        final Collection<String> portDefinitions = getPortDefinitions(networkConfig);
        final Set<Integer> ports = getPorts(networkConfig);
        if (portDefinitions.isEmpty() && ports.isEmpty()) {
            
            return Collections.emptySet();
        }
        if (portDefinitions.contains("*") || portDefinitions.contains("0")) {
            
            return Collections.emptySet();
        }
        transformPortDefinitionsToPorts(portDefinitions, ports);
        if (ports.contains(0)) {
            
            return Collections.emptySet();
        }
        return ports;
    }

    private void transformPortDefinitionsToPorts(Collection<String> portDefinitions, Set<Integer> ports) {
        
        for (String portDef : portDefinitions) {
            String[] portDefs = portDef.split("[,; ]");
            for (String def : portDefs) {
                def = def.trim();
                if (def.isEmpty()) {
                    continue;
                }
                final int dashPos = def.indexOf('-');
                if (dashPos > 0) {
                    final int start = Integer.parseInt(def.substring(0, dashPos));
                    final int end = Integer.parseInt(def.substring(dashPos + 1));
                    for (int port = start; port <= end; port++) {
                        ports.add(port);
                    }
                } else {
                    ports.add(Integer.parseInt(def));
                }
            }
        }
    }

    private Set<Integer> getPorts(NetworkConfig networkConfig) {
        return networkConfig.getOutboundPorts() == null
                ? new HashSet<Integer>() : new HashSet<Integer>(networkConfig.getOutboundPorts());
    }

    private Collection<String> getPortDefinitions(NetworkConfig networkConfig) {
        return networkConfig.getOutboundPortDefinitions() == null
                ? Collections.<String>emptySet() : networkConfig.getOutboundPortDefinitions();
    }
}


<code block>


package com.hazelcast.nio;

import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.internal.ascii.TextCommandService;
import com.hazelcast.config.SSLConfig;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.config.SymmetricEncryptionConfig;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.PacketReader;
import com.hazelcast.nio.tcp.PacketWriter;
import com.hazelcast.nio.tcp.SocketChannelWrapperFactory;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.spi.EventService;

import java.util.Collection;

public interface IOService {

    int KILO_BYTE = 1024;

    boolean isActive();

    ILogger getLogger(String name);

    void onOutOfMemory(OutOfMemoryError oom);

    Address getThisAddress();

    void onFatalError(Exception e);

    SocketInterceptorConfig getSocketInterceptorConfig();

    SymmetricEncryptionConfig getSymmetricEncryptionConfig();

    SSLConfig getSSLConfig();

    void handleMemberPacket(Packet p);

    void handleClientPacket(Packet p);

    void handleClientMessage(ClientMessage cm, Connection connection);

    TextCommandService getTextCommandService();

    boolean isMemcacheEnabled();

    boolean isRestEnabled();

    void removeEndpoint(Address endpoint);

    String getThreadPrefix();

    ThreadGroup getThreadGroup();

    void onSuccessfulConnection(Address address);

    void onFailedConnection(Address address);

    void shouldConnectTo(Address address);

    boolean isSocketBind();

    boolean isSocketBindAny();

    int getSocketReceiveBufferSize();

    int getSocketSendBufferSize();

    int getSocketLingerSeconds();

    int getSocketConnectTimeoutSeconds();

    boolean getSocketKeepAlive();

    boolean getSocketNoDelay();

    int getSelectorThreadCount();

    long getConnectionMonitorInterval();

    int getConnectionMonitorMaxFaults();

    
    int getBalancerIntervalSeconds();

    void onDisconnect(Address endpoint);

    boolean isClient();

    void executeAsync(Runnable runnable);

    EventService getEventService();

    Collection<Integer> getOutboundPorts();

    Data toData(Object obj);

    Object toObject(Data data);

    SerializationService getSerializationService();

    SocketChannelWrapperFactory getSocketChannelWrapperFactory();

    MemberSocketInterceptor getMemberSocketInterceptor();

    PacketReader createPacketReader(TcpIpConnection connection);

    PacketWriter createPacketWriter(TcpIpConnection connection);
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.ConnectionType;

import java.io.IOException;
import java.nio.channels.ClosedChannelException;
import java.nio.channels.SelectionKey;
import java.nio.channels.Selector;
import java.util.logging.Level;

public abstract class AbstractSelectionHandler implements MigratableHandler {

    protected final ILogger logger;
    protected final SocketChannelWrapper socketChannel;
    protected final TcpIpConnection connection;
    protected final TcpIpConnectionManager connectionManager;
    protected Selector selector;
    protected IOSelector ioSelector;

    private SelectionKey selectionKey;
    private final int initialOps;

    public AbstractSelectionHandler(TcpIpConnection connection, IOSelector ioSelector, int initialOps) {
        this.connection = connection;
        this.ioSelector = ioSelector;
        this.selector = ioSelector.getSelector();
        this.socketChannel = connection.getSocketChannelWrapper();
        this.connectionManager = connection.getConnectionManager();
        this.logger = connectionManager.ioService.getLogger(this.getClass().getName());
        this.initialOps = initialOps;
    }

    protected SelectionKey getSelectionKey() {
        if (selectionKey == null) {
            try {
                selectionKey = socketChannel.register(selector, initialOps, this);
            } catch (ClosedChannelException e) {
                handleSocketException(e);
            }
        }
        return selectionKey;
    }

    final void handleSocketException(Throwable e) {
        if (e instanceof OutOfMemoryError) {
            connectionManager.ioService.onOutOfMemory((OutOfMemoryError) e);
        }
        if (selectionKey != null) {
            selectionKey.cancel();
        }
        connection.close(e);
        ConnectionType connectionType = connection.getType();
        if (connectionType.isClient() && !connectionType.isBinary()) {
            return;
        }
        StringBuilder sb = new StringBuilder();
        sb.append(Thread.currentThread().getName());
        sb.append(" Closing socket to endpoint ");
        sb.append(connection.getEndPoint());
        sb.append(", Cause:").append(e);
        Level level = connectionManager.ioService.isActive() ? Level.WARNING : Level.FINEST;
        if (e instanceof IOException) {
            logger.log(level, sb.toString());
        } else {
            logger.log(level, sb.toString(), e);
        }
    }

    final void registerOp(int operation) {
        SelectionKey selectionKey = getSelectionKey();

        try {
            selectionKey.interestOps(selectionKey.interestOps() | operation);
        } catch (Throwable e) {
            handleSocketException(e);
        }
    }

    final void unregisterOp(int operation) {
        SelectionKey selectionKey = getSelectionKey();
        try {
            selectionKey.interestOps(selectionKey.interestOps() & ~operation);
        } catch (Throwable e) {
            handleSocketException(e);
        }
    }

    
    public IOSelector getOwner() {
        return ioSelector;
    }

    
    void startMigration(final IOSelector newOwner) {
        assert ioSelector == Thread.currentThread() : "startMigration can only run on the owning IOSelector thread";
        assert ioSelector != newOwner : "newOwner can't be the same as the existing owner";

        if (!socketChannel.isOpen()) {
            
            return;
        }

        unregisterOp(initialOps);
        ioSelector = newOwner;
        selectionKey.cancel();
        selectionKey = null;
        selector = null;

        newOwner.addTaskAndWakeup(new Runnable() {
            @Override
            public void run() {
                completeMigration(newOwner);
            }
        });
    }

    private void completeMigration(IOSelector newOwner) {
        assert ioSelector == newOwner;

        if (!socketChannel.isOpen()) {
            return;
        }

        selector = newOwner.getSelector();
        selectionKey = getSelectionKey();
        registerOp(initialOps);
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.logging.ILogger;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.nio.channels.SelectionKey;

public final class OutSelectorImpl extends AbstractIOSelector {

    
    private volatile long writeEvents;

    public OutSelectorImpl(ThreadGroup threadGroup, String tname, ILogger logger, IOSelectorOutOfMemoryHandler oomeHandler) {
        super(threadGroup, tname, logger, oomeHandler);
    }

    
    public long getWriteEvents() {
        return writeEvents;
    }

    @Override
    @SuppressFBWarnings({"VO_VOLATILE_INCREMENT" })
    protected void handleSelectionKey(SelectionKey sk) {
        if (sk.isValid() && sk.isWritable()) {
            writeEvents++;
            SelectionHandler handler = (SelectionHandler) sk.attachment();
            handler.handle();
        }
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.cluster.impl.BindMessage;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.IOService;
import com.hazelcast.nio.IOUtil;
import com.hazelcast.nio.MemberSocketInterceptor;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.tcp.iobalancer.IOBalancer;
import com.hazelcast.util.ConcurrencyUtil;
import com.hazelcast.util.ConstructorFunction;
import com.hazelcast.util.executor.StripedRunnable;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.io.IOException;
import java.net.Socket;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;
import java.util.Collection;
import java.util.Collections;
import java.util.LinkedList;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CopyOnWriteArraySet;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.logging.Level;

public class TcpIpConnectionManager implements ConnectionManager {

    private static final int DEFAULT_KILL_THREAD_MILLIS = 1000 * 10;

    final int socketReceiveBufferSize;

    final IOService ioService;

    final int socketSendBufferSize;

    private final ConstructorFunction<Address, TcpIpConnectionMonitor> monitorConstructor
            = new ConstructorFunction<Address, TcpIpConnectionMonitor>() {
        public TcpIpConnectionMonitor createNew(Address endpoint) {
            return new TcpIpConnectionMonitor(TcpIpConnectionManager.this, endpoint);
        }
    };

    private final ILogger logger;

    private final int socketLingerSeconds;

    private final int socketConnectTimeoutSeconds;

    private final boolean socketKeepAlive;

    private final boolean socketNoDelay;

    private final ConcurrentHashMap<Address, Connection> connectionsMap = new ConcurrentHashMap<Address, Connection>(100);

    private final ConcurrentHashMap<Address, TcpIpConnectionMonitor> monitors =
            new ConcurrentHashMap<Address, TcpIpConnectionMonitor>(100);

    private final Set<Address> connectionsInProgress =
            Collections.newSetFromMap(new ConcurrentHashMap<Address, Boolean>());

    private final Set<ConnectionListener> connectionListeners = new CopyOnWriteArraySet<ConnectionListener>();

    private final Set<SocketChannelWrapper> acceptedSockets =
            Collections.newSetFromMap(new ConcurrentHashMap<SocketChannelWrapper, Boolean>());

    private final Set<TcpIpConnection> activeConnections =
            Collections.newSetFromMap(new ConcurrentHashMap<TcpIpConnection, Boolean>());

    private final AtomicInteger allTextConnections = new AtomicInteger();

    private final AtomicInteger connectionIdGen = new AtomicInteger();

    private volatile boolean live;

    private final ServerSocketChannel serverSocketChannel;

    private final int selectorThreadCount;

    private final InSelectorImpl[] inSelectors;

    private final OutSelectorImpl[] outSelectors;

    private final AtomicInteger nextSelectorIndex = new AtomicInteger();

    private final SocketChannelWrapperFactory socketChannelWrapperFactory;

    private final int outboundPortCount;

    private final HazelcastThreadGroup hazelcastThreadGroup;

    
    private final LinkedList<Integer> outboundPorts = new LinkedList<Integer>();

    
    private volatile Thread socketAcceptorThread;

    private IOBalancer ioBalancer;
    private final LoggingService loggingService;

    public TcpIpConnectionManager(IOService ioService, ServerSocketChannel serverSocketChannel,
                                  HazelcastThreadGroup hazelcastThreadGroup, LoggingService loggingService) {
        this.ioService = ioService;
        this.hazelcastThreadGroup = hazelcastThreadGroup;
        this.serverSocketChannel = serverSocketChannel;
        this.logger = loggingService.getLogger(TcpIpConnectionManager.class.getName());
        this.socketReceiveBufferSize = ioService.getSocketReceiveBufferSize() * IOService.KILO_BYTE;
        this.socketSendBufferSize = ioService.getSocketSendBufferSize() * IOService.KILO_BYTE;
        this.socketLingerSeconds = ioService.getSocketLingerSeconds();
        this.socketConnectTimeoutSeconds = ioService.getSocketConnectTimeoutSeconds();
        this.socketKeepAlive = ioService.getSocketKeepAlive();
        this.socketNoDelay = ioService.getSocketNoDelay();
        this.selectorThreadCount = ioService.getSelectorThreadCount();
        this.inSelectors = new InSelectorImpl[selectorThreadCount];
        this.outSelectors = new OutSelectorImpl[selectorThreadCount];
        final Collection<Integer> ports = ioService.getOutboundPorts();
        this.outboundPortCount = ports.size();
        this.outboundPorts.addAll(ports);
        this.socketChannelWrapperFactory = ioService.getSocketChannelWrapperFactory();
        this.loggingService = loggingService;
    }


    public void interceptSocket(Socket socket, boolean onAccept) throws IOException {
        if (!isSocketInterceptorEnabled()) {
            return;
        }
        final MemberSocketInterceptor memberSocketInterceptor = ioService.getMemberSocketInterceptor();
        if (memberSocketInterceptor == null) {
            return;
        }
        if (onAccept) {
            memberSocketInterceptor.onAccept(socket);
        } else {
            memberSocketInterceptor.onConnect(socket);
        }
    }

    public boolean isSocketInterceptorEnabled() {
        final SocketInterceptorConfig socketInterceptorConfig = ioService.getSocketInterceptorConfig();
        if (socketInterceptorConfig != null && socketInterceptorConfig.isEnabled()) {
            return true;
        }
        return false;
    }

    public PacketReader createPacketReader(TcpIpConnection connection) {
        return ioService.createPacketReader(connection);
    }

    public PacketWriter createPacketWriter(TcpIpConnection connection) {
        return ioService.createPacketWriter(connection);
    }

    
    public Set<TcpIpConnection> getActiveConnections() {
        return activeConnections;
    }

    @SuppressFBWarnings(value = "EI_EXPOSE_REP", justification = "used only for testing")
    public InSelectorImpl[] getInSelectors() {
        return inSelectors;
    }

    @SuppressFBWarnings(value = "EI_EXPOSE_REP", justification = "used only for testing")
    public OutSelectorImpl[] getOutSelectors() {
        return outSelectors;
    }

    @Override
    public int getActiveConnectionCount() {
        return activeConnections.size();
    }

    public int getAllTextConnections() {
        return allTextConnections.get();
    }

    @Override
    public int getConnectionCount() {
        return connectionsMap.size();
    }

    public boolean isSSLEnabled() {
        return socketChannelWrapperFactory.isSSlEnabled();
    }

    public void incrementTextConnections() {
        allTextConnections.incrementAndGet();
    }

    public IOService getIOHandler() {
        return ioService;
    }

    public int getSocketConnectTimeoutSeconds() {
        return socketConnectTimeoutSeconds;
    }

    @Override
    public void addConnectionListener(ConnectionListener listener) {
        connectionListeners.add(listener);
    }

    public boolean bind(TcpIpConnection connection, Address remoteEndPoint, Address localEndpoint, boolean reply) {
        if (logger.isFinestEnabled()) {
            log(Level.FINEST, "Binding " + connection + " to " + remoteEndPoint + ", reply is " + reply);
        }
        final Address thisAddress = ioService.getThisAddress();
        if (ioService.isSocketBindAny() && !connection.isClient() && !thisAddress.equals(localEndpoint)) {
            log(Level.WARNING, "Wrong bind request from " + remoteEndPoint
                    + "! This node is not requested endpoint: " + localEndpoint);
            connection.close();
            return false;
        }
        connection.setEndPoint(remoteEndPoint);
        ioService.onSuccessfulConnection(remoteEndPoint);
        if (reply) {
            sendBindRequest(connection, remoteEndPoint, false);
        }
        if (checkAlreadyConnected(connection, remoteEndPoint)) {
            return false;
        }
        if (!registerConnection(remoteEndPoint, connection)) {
            return false;
        }
        return true;
    }

    public boolean registerConnection(final Address remoteEndPoint, final Connection connection) {
        if (remoteEndPoint.equals(ioService.getThisAddress())) {
            return false;
        }

        if (connection instanceof TcpIpConnection) {
            TcpIpConnection tcpConnection = (TcpIpConnection) connection;
            Address currentEndPoint = tcpConnection.getEndPoint();
            if (currentEndPoint != null && !currentEndPoint.equals(remoteEndPoint)) {
                throw new IllegalArgumentException(connection + " has already a different endpoint than: "
                        + remoteEndPoint);
            }
            tcpConnection.setEndPoint(remoteEndPoint);

            if (!connection.isClient()) {
                TcpIpConnectionMonitor connectionMonitor = getConnectionMonitor(remoteEndPoint, true);
                tcpConnection.setMonitor(connectionMonitor);
            }
        }
        connectionsMap.put(remoteEndPoint, connection);
        connectionsInProgress.remove(remoteEndPoint);
        ioService.getEventService().executeEventCallback(new StripedRunnable() {
            @Override
            public void run() {
                for (ConnectionListener listener : connectionListeners) {
                    listener.connectionAdded(connection);
                }
            }

            @Override
            public int getKey() {
                return remoteEndPoint.hashCode();
            }
        });
        return true;
    }

    private boolean checkAlreadyConnected(TcpIpConnection connection, Address remoteEndPoint) {
        final Connection existingConnection = connectionsMap.get(remoteEndPoint);
        if (existingConnection != null && existingConnection.isAlive()) {
            if (existingConnection != connection) {
                if (logger.isFinestEnabled()) {
                    log(Level.FINEST, existingConnection + " is already bound to " + remoteEndPoint
                            + ", new one is " + connection);
                }
                activeConnections.add(connection);
            }
            return true;
        }
        return false;
    }

    void sendBindRequest(TcpIpConnection connection, Address remoteEndPoint, boolean replyBack) {
        connection.setEndPoint(remoteEndPoint);
        ioService.onSuccessfulConnection(remoteEndPoint);
        
        if (logger.isFinestEnabled()) {
            log(Level.FINEST, "Sending bind packet to " + remoteEndPoint);
        }
        BindMessage bind = new BindMessage(ioService.getThisAddress(), remoteEndPoint, replyBack);
        Data bindData = ioService.toData(bind);
        Packet packet = new Packet(bindData);
        packet.setHeader(Packet.HEADER_BIND);
        connection.write(packet);
        
    }

    private int nextSelectorIndex() {
        return Math.abs(nextSelectorIndex.getAndIncrement()) % selectorThreadCount;
    }

    SocketChannelWrapper wrapSocketChannel(SocketChannel socketChannel, boolean client) throws Exception {
        SocketChannelWrapper wrapper = socketChannelWrapperFactory.wrapSocketChannel(socketChannel, client);
        acceptedSockets.add(wrapper);
        return wrapper;
    }

    TcpIpConnection assignSocketChannel(SocketChannelWrapper channel, Address endpoint) {
        int index = nextSelectorIndex();

        final TcpIpConnection connection = new TcpIpConnection(this, inSelectors[index],
                outSelectors[index], connectionIdGen.incrementAndGet(), channel);

        connection.setEndPoint(endpoint);
        activeConnections.add(connection);
        acceptedSockets.remove(channel);

        connection.start();
        ioBalancer.connectionAdded(connection);

        log(Level.INFO, "Established socket connection between " + channel.socket().getLocalSocketAddress());

        return connection;
    }

    void failedConnection(Address address, Throwable t, boolean silent) {
        connectionsInProgress.remove(address);
        ioService.onFailedConnection(address);
        if (!silent) {
            getConnectionMonitor(address, false).onError(t);
        }
    }

    @Override
    public Connection getConnection(Address address) {
        return connectionsMap.get(address);
    }

    @Override
    public Connection getOrConnect(Address address) {
        return getOrConnect(address, false);
    }

    @Override
    public Connection getOrConnect(final Address address, final boolean silent) {
        Connection connection = connectionsMap.get(address);
        if (connection == null && live) {
            if (connectionsInProgress.add(address)) {
                ioService.shouldConnectTo(address);
                ioService.executeAsync(new SocketConnector(this, address, silent));
            }
        }
        return connection;
    }

    private TcpIpConnectionMonitor getConnectionMonitor(Address endpoint, boolean reset) {
        TcpIpConnectionMonitor monitor = ConcurrencyUtil.getOrPutIfAbsent(monitors, endpoint, monitorConstructor);
        if (reset) {
            monitor.reset();
        }
        return monitor;
    }

    @Override
    public void destroyConnection(final Connection connection) {
        if (connection == null) {
            return;
        }
        if (logger.isFinestEnabled()) {
            log(Level.FINEST, "Destroying " + connection);
        }
        activeConnections.remove(connection);
        final Address endPoint = connection.getEndPoint();
        if (endPoint != null) {
            connectionsInProgress.remove(endPoint);
            connectionsMap.remove(endPoint, connection);
            ioBalancer.connectionRemoved(connection);
            if (live) {
                ioService.getEventService().executeEventCallback(new StripedRunnable() {
                    @Override
                    public void run() {
                        for (ConnectionListener listener : connectionListeners) {
                            listener.connectionRemoved(connection);
                        }
                    }

                    @Override
                    public int getKey() {
                        return endPoint.hashCode();
                    }
                });
            }
        }
        if (connection.isAlive()) {
            connection.close();
        }
    }

    protected void initSocket(Socket socket) throws Exception {
        if (socketLingerSeconds > 0) {
            socket.setSoLinger(true, socketLingerSeconds);
        }
        socket.setKeepAlive(socketKeepAlive);
        socket.setTcpNoDelay(socketNoDelay);
        socket.setReceiveBufferSize(socketReceiveBufferSize);
        socket.setSendBufferSize(socketSendBufferSize);
    }

    @Override
    public synchronized void start() {
        if (live) {
            return;
        }
        live = true;
        log(Level.FINEST, "Starting ConnectionManager and IO selectors.");
        IOSelectorOutOfMemoryHandler oomeHandler = new IOSelectorOutOfMemoryHandler() {
            @Override
            public void handle(OutOfMemoryError error) {
                ioService.onOutOfMemory(error);
            }
        };
        for (int i = 0; i < inSelectors.length; i++) {
            inSelectors[i] = new InSelectorImpl(
                    ioService.getThreadGroup(),
                    ioService.getThreadPrefix() + "in-" + i,
                    ioService.getLogger(InSelectorImpl.class.getName()),
                    oomeHandler);
            outSelectors[i] = new OutSelectorImpl(
                    ioService.getThreadGroup(),
                    ioService.getThreadPrefix() + "out-" + i,
                    ioService.getLogger(OutSelectorImpl.class.getName()),
                    oomeHandler);
            inSelectors[i].start();
            outSelectors[i].start();
        }
        startIOBalancer();

        if (socketAcceptorThread != null) {
            logger.warning("SocketAcceptor thread is already live! Shutting down old acceptor...");
            shutdownSocketAcceptor();
        }
        Runnable acceptRunnable = new SocketAcceptor(serverSocketChannel, this);
        socketAcceptorThread = new Thread(ioService.getThreadGroup(), acceptRunnable,
                ioService.getThreadPrefix() + "Acceptor");
        socketAcceptorThread.start();
    }

    private void startIOBalancer() {
        ioBalancer = new IOBalancer(inSelectors, outSelectors,
                hazelcastThreadGroup, ioService.getBalancerIntervalSeconds(), loggingService);
        ioBalancer.start();
    }

    @Override
    public synchronized void restart() {
        stop();
        start();
    }

    @Override
    public synchronized void shutdown() {
        if (!live) {
            return;
        }
        live = false;
        shutdownSocketAcceptor();
        closeServerSocket();
        stop();
        connectionListeners.clear();
    }

    private void closeServerSocket() {
        try {
            if (logger.isFinestEnabled()) {
                log(Level.FINEST, "Closing server socket channel: " + serverSocketChannel);
            }
            serverSocketChannel.close();
        } catch (IOException ignore) {
            logger.finest(ignore);
        }
    }

    private void stop() {
        live = false;
        log(Level.FINEST, "Stopping ConnectionManager");
        ioBalancer.stop();
        shutdownSocketAcceptor();
        for (SocketChannelWrapper socketChannel : acceptedSockets) {
            IOUtil.closeResource(socketChannel);
        }
        for (Connection conn : connectionsMap.values()) {
            try {
                destroyConnection(conn);
            } catch (final Throwable ignore) {
                logger.finest(ignore);
            }
        }
        for (TcpIpConnection conn : activeConnections) {
            try {
                destroyConnection(conn);
            } catch (final Throwable ignore) {
                logger.finest(ignore);
            }
        }
        shutdownIOSelectors();
        acceptedSockets.clear();
        connectionsInProgress.clear();
        connectionsMap.clear();
        monitors.clear();
        activeConnections.clear();
    }

    private synchronized void shutdownIOSelectors() {
        if (logger.isFinestEnabled()) {
            log(Level.FINEST, "Shutting down IO selectors... Total: " + selectorThreadCount);
        }
        for (int i = 0; i < selectorThreadCount; i++) {
            IOSelector ioSelector = inSelectors[i];
            if (ioSelector != null) {
                ioSelector.shutdown();
            }
            inSelectors[i] = null;

            ioSelector = outSelectors[i];
            if (ioSelector != null) {
                ioSelector.shutdown();
            }
            outSelectors[i] = null;
        }
    }

    private void shutdownSocketAcceptor() {
        log(Level.FINEST, "Shutting down SocketAcceptor thread.");
        Thread killingThread = socketAcceptorThread;
        if (killingThread == null) {
            return;
        }
        socketAcceptorThread = null;
        killingThread.interrupt();
        try {
            killingThread.join(DEFAULT_KILL_THREAD_MILLIS);
        } catch (InterruptedException e) {
            logger.finest(e);
        }
    }

    @Override
    public int getCurrentClientConnections() {
        int count = 0;
        for (TcpIpConnection conn : activeConnections) {
            if (conn.isAlive()) {
                if (conn.isClient()) {
                    count++;
                }
            }
        }
        return count;
    }

    public boolean isLive() {
        return live;
    }

    private void log(Level level, String message) {
        logger.log(level, message);
    }

    boolean useAnyOutboundPort() {
        return outboundPortCount == 0;
    }

    int getOutboundPortCount() {
        return outboundPortCount;
    }

    int acquireOutboundPort() {
        if (useAnyOutboundPort()) {
            return 0;
        }
        synchronized (outboundPorts) {
            final Integer port = outboundPorts.removeFirst();
            outboundPorts.addLast(port);
            return port;
        }
    }

    @Override
    public void dumpPerformanceMetrics(StringBuffer sb) {
        for (int k = 0; k < inSelectors.length; k++) {
            InSelectorImpl inSelector = inSelectors[k];
            sb.append(inSelector.getName()).append(".readEvents=")
                    .append(inSelector.getReadEvents()).append("\n");
        }

        for (int k = 0; k < outSelectors.length; k++) {
            OutSelectorImpl outSelector = outSelectors[k];
            sb.append(outSelector.getName()).append(".writeEvents=")
                    .append(outSelector.getWriteEvents()).append("\n");
        }
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder("Connections {");
        for (Connection conn : connectionsMap.values()) {
            sb.append("\n");
            sb.append(conn);
        }
        sb.append("\nlive=");
        sb.append(live);
        sb.append("\n}");
        return sb.toString();
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.cluster.impl.BindMessage;
import com.hazelcast.nio.IOService;
import com.hazelcast.nio.Packet;

import java.nio.ByteBuffer;

public class DefaultPacketReader implements PacketReader {

    protected final TcpIpConnection connection;

    protected final IOService ioService;

    protected Packet packet;

    public DefaultPacketReader(TcpIpConnection connection, IOService ioService) {
        this.connection = connection;
        this.ioService = ioService;
    }

    @Override
    public void readPacket(ByteBuffer inBuffer) throws Exception {
        while (inBuffer.hasRemaining()) {
            if (packet == null) {
                packet = obtainPacket();
            }
            boolean complete = packet.readFrom(inBuffer);
            if (complete) {
                handlePacket(packet);
                packet = null;
            } else {
                break;
            }
        }
    }

    protected void handlePacket(Packet packet) {
        packet.setConn(connection);
        if (packet.isHeaderSet(Packet.HEADER_BIND)) {
            handleBind(packet);
        } else {
            ioService.handleMemberPacket(packet);
        }
    }

    protected void handleBind(Packet packet) {
        TcpIpConnectionManager connectionManager = connection.getConnectionManager();
        BindMessage bind = (BindMessage) ioService.toObject(packet.getData());
        connectionManager.bind(connection, bind.getLocalAddress(), bind.getTargetAddress(), bind.shouldReply());
    }

    protected Packet obtainPacket() {
        return new Packet();
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.core.HazelcastException;
import com.hazelcast.logging.ILogger;

import java.io.IOException;
import java.nio.channels.SelectionKey;
import java.nio.channels.Selector;
import java.util.Iterator;
import java.util.Queue;
import java.util.Set;
import java.util.concurrent.ConcurrentLinkedQueue;

public abstract class AbstractIOSelector extends Thread implements IOSelector {

    private static final int SELECT_WAIT_TIME_MILLIS = 5000;
    private static final int SELECT_FAILURE_PAUSE_MILLIS = 1000;

    private final ILogger logger;

    private final Queue<Runnable> selectorQueue = new ConcurrentLinkedQueue<Runnable>();

    private final int waitTime;

    private final Selector selector;

    private final IOSelectorOutOfMemoryHandler oomeHandler;

    
    private boolean running = true;

    public AbstractIOSelector(ThreadGroup threadGroup, String threadName, ILogger logger,
                              IOSelectorOutOfMemoryHandler oomeHandler) {
        super(threadGroup, threadName);
        this.logger = logger;
        this.oomeHandler = oomeHandler;
        
        this.waitTime = SELECT_WAIT_TIME_MILLIS;
        try {
            selector = Selector.open();
        } catch (final IOException e) {
            throw new HazelcastException("Failed to open a Selector", e);
        }
    }

    @Override
    public final void shutdown() {
        selectorQueue.clear();
        try {
            addTask(new Runnable() {
                @Override
                public void run() {
                    running = false;
                }
            });
            interrupt();
        } catch (Throwable t) {
            logger.finest("Exception while waiting for shutdown", t);
        }
    }

    @Override
    public final void addTask(Runnable task) {
        selectorQueue.add(task);
    }

    @Override
    public final void addTaskAndWakeup(Runnable task) {
        selectorQueue.add(task);
        selector.wakeup();
    }

    private void processSelectionQueue() {
        
        while (running) {
            final Runnable task = selectorQueue.poll();
            if (task == null) {
                return;
            }
            executeTask(task);
        }
    }

    private void executeTask(Runnable task) {
        IOSelector target = getTargetIOSelector(task);
        if (target == this) {
            task.run();
        } else {
            target.addTask(task);
        }
    }

    private IOSelector getTargetIOSelector(Runnable task) {
        if (task instanceof MigratableHandler) {
            return ((MigratableHandler) task).getOwner();
        } else {
            return this;
        }
    }

    @Override
    public final void run() {
        try {
            
            while (running) {
                processSelectionQueue();
                if (!running || isInterrupted()) {
                    if (logger.isFinestEnabled()) {
                        logger.finest(getName() + " is interrupted!");
                    }
                    running = false;
                    return;
                }

                try {
                    int selectedKeyCount = selector.select(waitTime);
                    if (selectedKeyCount == 0) {
                        continue;
                    }
                } catch (Throwable e) {
                    handleSelectFailure(e);
                    continue;
                }
                handleSelectionKeys();
            }
        } catch (OutOfMemoryError e) {
            oomeHandler.handle(e);
        } catch (Throwable e) {
            logger.warning("Unhandled exception in " + getName(), e);
        } finally {
            closeSelector();
        }
    }

    private void closeSelector() {
        if (logger.isFinestEnabled()) {
            logger.finest("Closing selector " + getName());
        }

        try {
            selector.close();
        } catch (Exception e) {
            logger.finest("Exception while closing selector", e);
        }
    }

    protected abstract void handleSelectionKey(SelectionKey sk);

    private void handleSelectionKeys() {
        final Set<SelectionKey> setSelectedKeys = selector.selectedKeys();
        final Iterator<SelectionKey> it = setSelectedKeys.iterator();
        while (it.hasNext()) {
            final SelectionKey sk = it.next();
            it.remove();
            try {
                handleSelectionKey(sk);
            } catch (Throwable e) {
                handleSelectionKeyFailure(e);
            }
        }
    }

    public void handleSelectionKeyFailure(Throwable e) {
        logger.warning("Selector exception at  " + getName() + ", cause= " + e.toString(), e);
        if (e instanceof OutOfMemoryError) {
            oomeHandler.handle((OutOfMemoryError) e);
        }
    }

    @Override
    public final Selector getSelector() {
        return selector;
    }

    private void handleSelectFailure(Throwable e) {
        logger.warning(e.toString(), e);

        
        
        try {
            Thread.sleep(SELECT_FAILURE_PAUSE_MILLIS);
        } catch (InterruptedException i) {
            Thread.currentThread().interrupt();
        }
    }

    @Override
    public String toString() {
        return getName();
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.Protocols;
import com.hazelcast.nio.ascii.SocketTextReader;
import com.hazelcast.util.Clock;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.io.EOFException;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.SelectionKey;

import static com.hazelcast.util.StringUtil.bytesToString;


public final class ReadHandler extends AbstractSelectionHandler {

    private final ByteBuffer inputBuffer;

    private SocketReader socketReader;

    private volatile long lastHandle;

    
    private volatile long eventCount;

    public ReadHandler(TcpIpConnection connection, IOSelector ioSelector) {
        super(connection, ioSelector, SelectionKey.OP_READ);
        this.ioSelector = ioSelector;
        this.inputBuffer = ByteBuffer.allocate(connectionManager.socketReceiveBufferSize);
    }

    public void start() {
        ioSelector.addTaskAndWakeup(new Runnable() {
            @Override
            public void run() {
                getSelectionKey();

            }
        });
    }

    @Override
    public long getEventCount() {
        return eventCount;
    }

    
    @Override
    public void requestMigration(IOSelector newOwner) {
        ioSelector.addTaskAndWakeup(new StartMigrationTask(newOwner));
    }

    @Override
    @SuppressFBWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "eventCount is accessed by a single thread only.")
    public void handle() {
        eventCount++;
        lastHandle = Clock.currentTimeMillis();
        if (!connection.isAlive()) {
            String message = "We are being asked to read, but connection is not live so we won't";
            logger.finest(message);
            return;
        }
        try {
            if (socketReader == null) {
                initializeSocketReader();
                if (socketReader == null) {
                    
                    return;
                }
            }
            int readBytes = socketChannel.read(inputBuffer);
            if (readBytes == -1) {
                throw new EOFException("Remote socket closed!");
            }
        } catch (Throwable e) {
            handleSocketException(e);
            return;
        }
        try {
            if (inputBuffer.position() == 0) {
                return;
            }
            inputBuffer.flip();
            socketReader.read(inputBuffer);
            if (inputBuffer.hasRemaining()) {
                inputBuffer.compact();
            } else {
                inputBuffer.clear();
            }
        } catch (Throwable t) {
            handleSocketException(t);
        }
    }

    private void initializeSocketReader()
            throws IOException {
        if (socketReader == null) {
            final ByteBuffer protocolBuffer = ByteBuffer.allocate(3);
            int readBytes = socketChannel.read(protocolBuffer);
            if (readBytes == -1) {
                throw new EOFException("Could not read protocol type!");
            }
            if (readBytes == 0 && connectionManager.isSSLEnabled()) {
                
                return;
            }
            if (!protocolBuffer.hasRemaining()) {
                String protocol = bytesToString(protocolBuffer.array());
                WriteHandler writeHandler = connection.getWriteHandler();
                if (Protocols.CLUSTER.equals(protocol)) {
                    connection.setType(ConnectionType.MEMBER);
                    writeHandler.setProtocol(Protocols.CLUSTER);
                    socketReader = new SocketPacketReader(connection);
                } else if (Protocols.CLIENT_BINARY.equals(protocol)) {
                    writeHandler.setProtocol(Protocols.CLIENT_BINARY);
                    socketReader = new SocketClientDataReader(connection);
                } else if (Protocols.CLIENT_BINARY_NEW.equals(protocol)) {
                    writeHandler.setProtocol(Protocols.CLIENT_BINARY_NEW);
                    socketReader = new SocketClientMessageReader(connection, socketChannel);
                } else {
                    writeHandler.setProtocol(Protocols.TEXT);
                    inputBuffer.put(protocolBuffer.array());
                    socketReader = new SocketTextReader(connection);
                    connection.getConnectionManager().incrementTextConnections();
                }
            }
            if (socketReader == null) {
                throw new IOException("Could not initialize SocketReader!");
            }
        }
    }

    long getLastHandle() {
        return lastHandle;
    }

    void shutdown() {
        
        
        ioSelector.addTaskAndWakeup(new Runnable() {
            @Override
            public void run() {
                try {
                    socketChannel.closeInbound();
                } catch (IOException e) {
                    logger.finest("Error while closing inbound", e);
                }
            }
        });
    }

    @Override
    public String toString() {
        return connection + ".readHandler";
    }

    private class StartMigrationTask implements Runnable {
        private final IOSelector newOwner;

        public StartMigrationTask(IOSelector newOwner) {
            this.newOwner = newOwner;
        }

        @Override
        public void run() {
            
            if (ioSelector == newOwner) {
                return;
            }

            startMigration(newOwner);
        }
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.SocketWritable;

import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.Socket;
import java.net.SocketAddress;


public final class TcpIpConnection implements Connection {

    private final SocketChannelWrapper socketChannel;

    private final ReadHandler readHandler;

    private final WriteHandler writeHandler;

    private final TcpIpConnectionManager connectionManager;

    private volatile boolean live = true;

    private volatile ConnectionType type = ConnectionType.NONE;

    private Address endPoint;

    private final ILogger logger;

    private final int connectionId;

    private TcpIpConnectionMonitor monitor;

    public TcpIpConnection(TcpIpConnectionManager connectionManager, IOSelector in, IOSelector out,
                           int connectionId, SocketChannelWrapper socketChannel) {
        this.connectionId = connectionId;
        this.logger = connectionManager.ioService.getLogger(TcpIpConnection.class.getName());
        this.connectionManager = connectionManager;
        this.socketChannel = socketChannel;
        this.writeHandler = new WriteHandler(this, out);
        this.readHandler = new ReadHandler(this, in);
    }

    
    public void start() {
        readHandler.start();
    }

    @Override
    public ConnectionType getType() {
        return type;
    }

    public TcpIpConnectionManager getConnectionManager() {
        return connectionManager;
    }

    @Override
    public boolean write(SocketWritable packet) {
        if (!live) {
            if (logger.isFinestEnabled()) {
                logger.finest("Connection is closed, won't write packet -> " + packet);
            }
            return false;
        }
        writeHandler.offer(packet);
        return true;
    }

    @Override
    public boolean isClient() {
        final ConnectionType t = type;
        return (t != null) && t != ConnectionType.NONE && t.isClient();
    }

    public void setType(ConnectionType type) {
        if (this.type == ConnectionType.NONE) {
            this.type = type;
        }
    }

    public SocketChannelWrapper getSocketChannelWrapper() {
        return socketChannel;
    }

    @Override
    public InetAddress getInetAddress() {
        return socketChannel.socket().getInetAddress();
    }

    @Override
    public int getPort() {
        return socketChannel.socket().getPort();
    }

    @Override
    public InetSocketAddress getRemoteSocketAddress() {
        return (InetSocketAddress) socketChannel.socket().getRemoteSocketAddress();
    }

    public ReadHandler getReadHandler() {
        return readHandler;
    }

    public WriteHandler getWriteHandler() {
        return writeHandler;
    }

    @Override
    public boolean isAlive() {
        return live;
    }

    @Override
    public long lastWriteTime() {
        return writeHandler.getLastHandle();
    }

    @Override
    public long lastReadTime() {
        return readHandler.getLastHandle();
    }

    @Override
    public Address getEndPoint() {
        return endPoint;
    }

    public void setEndPoint(Address endPoint) {
        this.endPoint = endPoint;
    }

    public void setMonitor(TcpIpConnectionMonitor monitor) {
        this.monitor = monitor;
    }

    public TcpIpConnectionMonitor getMonitor() {
        return monitor;
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (!(o instanceof TcpIpConnection)) {
            return false;
        }
        TcpIpConnection that = (TcpIpConnection) o;
        return connectionId == that.getConnectionId();
    }

    @Override
    public int hashCode() {
        return connectionId;
    }

    private void close0() throws IOException {
        if (!live) {
            return;
        }
        live = false;

        if (socketChannel != null && socketChannel.isOpen()) {
            readHandler.shutdown();
            writeHandler.shutdown();
            socketChannel.close();
        }
    }

    @Override
    public void close() {
        close(null);
    }

    public void close(Throwable t) {
        if (!live) {
            return;
        }
        try {
            close0();
        } catch (Exception e) {
            logger.warning(e);
        }
        Object connAddress = (endPoint == null) ? socketChannel.socket().getRemoteSocketAddress() : endPoint;
        String message = "Connection [" + connAddress + "] lost. Reason: ";
        if (t != null) {
            message += t.getClass().getName() + "[" + t.getMessage() + "]";
        } else {
            message += "Socket explicitly closed";
        }

        logger.info(message);
        connectionManager.destroyConnection(this);
        connectionManager.ioService.onDisconnect(endPoint);
        if (t != null && monitor != null) {
            monitor.onError(t);
        }
    }

    public int getConnectionId() {
        return connectionId;
    }

    @Override
    public String toString() {
        Socket socket = this.socketChannel.socket();
        SocketAddress localSocketAddress = socket != null ? socket.getLocalSocketAddress() : null;
        SocketAddress remoteSocketAddress = socket != null ? socket.getRemoteSocketAddress() : null;
        return "Connection [" + localSocketAddress + " -> " + remoteSocketAddress
                + "], endpoint=" + endPoint + ", live=" + live + ", type=" + type;
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.nio.Protocols;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.nio.ascii.SocketTextWriter;
import com.hazelcast.util.Clock;
import com.hazelcast.util.EmptyStatement;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.SelectionKey;
import java.util.Queue;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.logging.Level;

import static com.hazelcast.util.StringUtil.stringToBytes;


public final class WriteHandler extends AbstractSelectionHandler implements Runnable {

    private static final long TIMEOUT = 3;

    private final Queue<SocketWritable> writeQueue = new ConcurrentLinkedQueue<SocketWritable>();
    private final Queue<SocketWritable> urgentWriteQueue = new ConcurrentLinkedQueue<SocketWritable>();
    private final AtomicBoolean scheduled = new AtomicBoolean(false);
    private final ByteBuffer outputBuffer;
    private SocketWritable currentPacket;
    private SocketWriter socketWriter;
    private volatile long lastHandle;
    
    private volatile long eventCount;
    private boolean shutdown;
    
    
    
    private IOSelector newOwner;

    WriteHandler(TcpIpConnection connection, IOSelector ioSelector) {
        super(connection, ioSelector, SelectionKey.OP_WRITE);
        this.outputBuffer = ByteBuffer.allocate(connectionManager.socketSendBufferSize);
    }

    long getLastHandle() {
        return lastHandle;
    }

    public SocketWriter getSocketWriter() {
        return socketWriter;
    }

    
    void setProtocol(final String protocol) {
        final CountDownLatch latch = new CountDownLatch(1);
        ioSelector.addTaskAndWakeup(new Runnable() {
            @Override
            public void run() {
                createWriter(protocol);
                latch.countDown();
            }
        });
        try {
            latch.await(TIMEOUT, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            logger.finest("CountDownLatch::await interrupted", e);
        }
    }

    private void createWriter(String protocol) {
        if (socketWriter == null) {
            if (Protocols.CLUSTER.equals(protocol)) {
                socketWriter = new SocketPacketWriter(connection);
                outputBuffer.put(stringToBytes(Protocols.CLUSTER));
                registerOp(SelectionKey.OP_WRITE);
            } else if (Protocols.CLIENT_BINARY.equals(protocol)) {
                socketWriter = new SocketClientDataWriter();
            } else if (Protocols.CLIENT_BINARY_NEW.equals(protocol)) {
                socketWriter = new SocketClientMessageWriter();
            } else {
                socketWriter = new SocketTextWriter(connection);
            }
        }
    }

    public void offer(SocketWritable packet) {
        if (packet.isUrgent()) {
            urgentWriteQueue.offer(packet);
        } else {
            writeQueue.offer(packet);
        }

        schedule();
    }

    private SocketWritable poll() {
        for (; ; ) {
            SocketWritable packet = urgentWriteQueue.poll();

            if (packet == null) {
                packet = writeQueue.poll();
            }

            if (packet instanceof TaskPacket) {
                ((TaskPacket) packet).run();
                continue;
            }

            return packet;
        }
    }

    
    private void schedule() {
        if (scheduled.get()) {
            
            return;
        }

        if (!scheduled.compareAndSet(false, true)) {
            
            
            return;
        }

        
        
        ioSelector.addTaskAndWakeup(this);
    }

    
    private void unschedule() {
        if (dirtyOutputBuffer() || currentPacket != null) {
            
            
            registerOp(SelectionKey.OP_WRITE);

            
            
            return;
        }

        
        unregisterOp(SelectionKey.OP_WRITE);
        
        scheduled.set(false);

        if (writeQueue.isEmpty() && urgentWriteQueue.isEmpty()) {
            
            return;
        }

        
        

        if (!scheduled.compareAndSet(false, true)) {
            
            return;
        }

        
        
        
        ioSelector.addTask(this);
    }

    @Override
    public long getEventCount() {
        return eventCount;
    }

    @Override
    @SuppressWarnings("unchecked")
    @SuppressFBWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "eventCount is accessed by a single thread only.")
    public void handle() {
        eventCount++;
        lastHandle = Clock.currentTimeMillis();
        if (shutdown) {
            return;
        }

        if (socketWriter == null) {
            logger.log(Level.WARNING, "SocketWriter is not set, creating SocketWriter with CLUSTER protocol!");
            createWriter(Protocols.CLUSTER);
        }

        try {
            fillOutputBuffer();

            if (dirtyOutputBuffer()) {
                writeOutputBufferToSocket();
            }
        } catch (Throwable t) {
            logger.severe("Fatal Error at WriteHandler for endPoint: " + connection.getEndPoint(), t);
        }

        if (newOwner == null) {
            unschedule();
        } else {
            IOSelector newOwner = this.newOwner;
            this.newOwner = null;
            startMigration(newOwner);
        }
    }

    
    private boolean dirtyOutputBuffer() {
        return outputBuffer.position() > 0;
    }

    
    private void writeOutputBufferToSocket() throws Exception {
        
        outputBuffer.flip();
        try {
            socketChannel.write(outputBuffer);
        } catch (Exception e) {
            currentPacket = null;
            handleSocketException(e);
            return;
        }
        
        if (!outputBuffer.hasRemaining()) {
            
            outputBuffer.clear();
            return;
        }
        
        
        outputBuffer.compact();
    }

    
    private void fillOutputBuffer() throws Exception {
        for (; ; ) {
            if (!outputBuffer.hasRemaining()) {
                
                return;
            }

            
            if (currentPacket == null) {
                currentPacket = poll();
                if (currentPacket == null) {
                    
                    return;
                }
            }

            
            if (!socketWriter.write(currentPacket, outputBuffer)) {
                
                return;
            }

            
            currentPacket = null;
        }
    }

    @Override
    public void run() {
        try {
            handle();
        } catch (Throwable e) {
            ioSelector.handleSelectionKeyFailure(e);
        }
    }

    public void shutdown() {
        writeQueue.clear();
        urgentWriteQueue.clear();

        ShutdownTask shutdownTask = new ShutdownTask();
        offer(shutdownTask);
        shutdownTask.awaitCompletion();
    }

    @Override
    public void requestMigration(IOSelector newOwner) {
        offer(new StartMigrationTask(newOwner));
    }

    @Override
    public String toString() {
        return connection + ".writeHandler";
    }

    
    private abstract class TaskPacket implements SocketWritable {
        abstract void run();

        @Override
        public boolean writeTo(ByteBuffer destination) {
            throw new UnsupportedOperationException();
        }

        @Override
        public boolean isUrgent() {
            return true;
        }
    }

    
    private class StartMigrationTask extends TaskPacket {
        
        
        private final IOSelector theNewOwner;

        public StartMigrationTask(IOSelector theNewOwner) {
            this.theNewOwner = theNewOwner;
        }

        @Override
        void run() {
            assert newOwner == null : "No migration can be in progress";

            if (ioSelector == theNewOwner) {
                
                return;
            }

            newOwner = theNewOwner;
        }
    }

    private class ShutdownTask extends TaskPacket {
        private final CountDownLatch latch = new CountDownLatch(1);

        @Override
        void run() {
            shutdown = true;
            try {
                socketChannel.closeOutbound();
            } catch (IOException e) {
                logger.finest("Error while closing outbound", e);
            } finally {
                latch.countDown();
            }
        }

        void awaitCompletion() {
            try {
                latch.await(TIMEOUT, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                EmptyStatement.ignore(e);
            }
        }
    }
}

<code block>


package com.hazelcast.nio.tcp;

import com.hazelcast.logging.ILogger;
import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;

import java.nio.channels.SelectionKey;

public final class InSelectorImpl extends AbstractIOSelector {

    
    private volatile long readEvents;

    public InSelectorImpl(ThreadGroup threadGroup, String tname, ILogger logger, IOSelectorOutOfMemoryHandler oomeHandler) {
        super(threadGroup, tname, logger, oomeHandler);
    }

    
    public long getReadEvents() {
        return readEvents;
    }

    @Override
    @SuppressFBWarnings({"VO_VOLATILE_INCREMENT" })
    protected void handleSelectionKey(SelectionKey sk) {
        if (sk.isValid() && sk.isReadable()) {
            readEvents++;
            SelectionHandler handler = (SelectionHandler) sk.attachment();
            handler.handle();
        }
    }
}

<code block>


package com.hazelcast.nio.tcp.iobalancer;

import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.tcp.IOSelector;
import com.hazelcast.nio.tcp.InSelectorImpl;
import com.hazelcast.nio.tcp.MigratableHandler;
import com.hazelcast.nio.tcp.OutSelectorImpl;
import com.hazelcast.nio.tcp.ReadHandler;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.nio.tcp.WriteHandler;

import static com.hazelcast.instance.GroupProperties.PROP_IO_BALANCER_INTERVAL_SECONDS;
import static com.hazelcast.instance.GroupProperties.PROP_IO_THREAD_COUNT;


public class IOBalancer {
    private static final String PROP_MONKEY_BALANCER = "hazelcast.io.balancer.monkey";
    private final ILogger logger;

    private final int balancerIntervalSeconds;
    private final MigrationStrategy strategy;

    private final LoadTracker inLoadTracker;
    private final LoadTracker outLoadTracker;

    private final HazelcastThreadGroup threadGroup;
    private volatile boolean enabled;
    private IOBalancerThread ioBalancerThread;

    public IOBalancer(InSelectorImpl[] inSelectors, OutSelectorImpl[] outSelectors, HazelcastThreadGroup threadGroup,
                      int balancerIntervalSeconds, LoggingService loggingService) {
        this.logger = loggingService.getLogger(IOBalancer.class);
        this.balancerIntervalSeconds = balancerIntervalSeconds;

        this.strategy = createMigrationStrategy();
        this.threadGroup = threadGroup;

        this.inLoadTracker = new LoadTracker(inSelectors, logger);
        this.outLoadTracker = new LoadTracker(outSelectors, logger);

        this.enabled = isEnabled(inSelectors, outSelectors);
    }

    public void connectionAdded(Connection connection) {
        if (!(connection instanceof TcpIpConnection)) {
            return;
        }

        TcpIpConnection tcpIpConnection = (TcpIpConnection) connection;
        ReadHandler readHandler = tcpIpConnection.getReadHandler();
        WriteHandler writeHandler = tcpIpConnection.getWriteHandler();

        if (logger.isFinestEnabled()) {
            logger.finest("Connection " + connection + " uses read handler "
                    + readHandler + " and write handler " + writeHandler);
        }

        inLoadTracker.addHandler(readHandler);
        outLoadTracker.addHandler(writeHandler);
    }

    public void connectionRemoved(Connection connection) {
        if (!(connection instanceof TcpIpConnection)) {
            return;
        }

        TcpIpConnection tcpIpConnection = (TcpIpConnection) connection;
        ReadHandler readHandler = tcpIpConnection.getReadHandler();
        if (logger.isFinestEnabled()) {
            logger.finest("Removing read handler " + readHandler);
        }
        inLoadTracker.removeHandler(readHandler);

        WriteHandler writeHandler = tcpIpConnection.getWriteHandler();
        if (logger.isFinestEnabled()) {
            logger.finest("Removing write handler " + readHandler);
        }
        outLoadTracker.removeHandler(writeHandler);
    }

    public void start() {
        if (enabled) {
            ioBalancerThread = new IOBalancerThread(this, balancerIntervalSeconds, threadGroup, logger);
            ioBalancerThread.start();
        }
    }

    public void stop() {
        if (ioBalancerThread != null) {
            ioBalancerThread.shutdown();
        }
    }

    void checkWriteHandlers() {
        scheduleMigrationIfNeeded(outLoadTracker);
    }

    void checkReadHandlers() {
        scheduleMigrationIfNeeded(inLoadTracker);
    }

    private void scheduleMigrationIfNeeded(LoadTracker loadTracker) {
        LoadImbalance loadImbalance = loadTracker.updateImbalance();
        if (strategy.imbalanceDetected(loadImbalance)) {
            tryMigrate(loadImbalance);
        } else {
            if (logger.isFinestEnabled()) {
                long min = loadImbalance.minimumEvents;
                long max = loadImbalance.maximumEvents;
                logger.finest("No imbalance has been detected. Max. events: " + max + " Min events: " + min + ".");
            }
        }
    }

    private MigrationStrategy createMigrationStrategy() {
        if (Boolean.getBoolean(PROP_MONKEY_BALANCER)) {
            logger.warning("Using Monkey IO Balancer Strategy. This is for stress tests only. Do not user in production! "
                    + "Disable by not setting the property '" + PROP_MONKEY_BALANCER + "' to true.");
            return new MonkeyMigrationStrategy();
        } else {
            logger.finest("Using normal IO Balancer Strategy.");
            return new EventCountBasicMigrationStrategy();
        }
    }

    private boolean isEnabled(InSelectorImpl[] inSelectors, OutSelectorImpl[] outSelectors) {
        if (balancerIntervalSeconds <= 0) {
            logger.warning("I/O Balancer is disabled as the '"
                    + PROP_IO_BALANCER_INTERVAL_SECONDS + "' property is set to "
                    + balancerIntervalSeconds + ". Set the property to a value larger than 0 to enable the I/O Balancer.");
            return false;
        }

        if (inSelectors.length == 1 && outSelectors.length == 1) {
            logger.finest("I/O Balancer is disabled as there is only a single a pair of I/O threads. Use the '"
                    + PROP_IO_THREAD_COUNT + "' property to increase number of I/O Threads.");
            return false;
        }

        if (logger.isFinestEnabled()) {
            logger.finest("I/O Balancer is enabled. Scanning every " + balancerIntervalSeconds + " seconds for imbalances.");
        }

        return true;
    }

    private void tryMigrate(LoadImbalance loadImbalance) {
        MigratableHandler handler = strategy.findHandlerToMigrate(loadImbalance);
        if (handler == null) {
            logger.finest("I/O imbalance is detected, but no suitable migration candidate is found.");
            return;
        }

        IOSelector destinationSelector = loadImbalance.destinationSelector;
        if (logger.isFinestEnabled()) {
            IOSelector sourceSelector = loadImbalance.sourceSelector;
            logger.finest("Scheduling migration of handler " + handler
                    + " from selector thread " + sourceSelector + " to " + destinationSelector);
        }
        handler.requestMigration(destinationSelector);
    }
}

<code block>


package com.hazelcast.nio.tcp.iobalancer;

import com.hazelcast.nio.tcp.MigratableHandler;
import java.util.Set;


class EventCountBasicMigrationStrategy implements MigrationStrategy {

    
    private static final double MIN_MAX_RATIO_MIGRATION_THRESHOLD = 0.8;

    
    private static final double MAXIMUM_NO_OF_EVENTS_AFTER_MIGRATION_COEFFICIENT = 0.9;

    
    @Override
    public boolean imbalanceDetected(LoadImbalance imbalance) {
        long min = imbalance.minimumEvents;
        long max = imbalance.maximumEvents;

        if (min == Long.MIN_VALUE || max == Long.MAX_VALUE) {
            return false;
        }
        long lowerBound = (long) (MIN_MAX_RATIO_MIGRATION_THRESHOLD * max);
        return min < lowerBound;
    }

    
     @Override
     public MigratableHandler findHandlerToMigrate(LoadImbalance imbalance) {
        Set<? extends MigratableHandler> candidates = imbalance.getHandlersOwnerBy(imbalance.sourceSelector);
        long migrationThreshold = (long) ((imbalance.maximumEvents - imbalance.minimumEvents)
                * MAXIMUM_NO_OF_EVENTS_AFTER_MIGRATION_COEFFICIENT);
        MigratableHandler candidate = null;
        long eventCountInSelectedHandler = 0;
        for (MigratableHandler handler : candidates) {
            long eventCount = imbalance.getEventCount(handler);
            if (eventCount > eventCountInSelectedHandler) {
                if (eventCount < migrationThreshold) {
                    eventCountInSelectedHandler = eventCount;
                    candidate = handler;
                }
            }
        }
        return candidate;
    }
}

<code block>
package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.HazelcastSerializationException;
import com.hazelcast.spi.AbstractOperation;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationResponseHandler;
import com.hazelcast.spi.WaitNotifyKey;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.test.ExpectedRuntimeException;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.spi.OperationAccessor.setCallId;
import static com.hazelcast.spi.OperationAccessor.setCallTimeout;
import static org.junit.Assert.assertEquals;
import static org.mockito.Matchers.any;
import static org.mockito.Matchers.same;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.never;
import static org.mockito.Mockito.verify;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class OperationRunnerImplTest extends HazelcastTestSupport {

    private HazelcastInstance local;
    private HazelcastInstance remote;
    private OperationRunnerImpl operationRunner;
    private OperationServiceImpl operationService;
    private ClusterService clusterService;
    private OperationResponseHandler responseHandler;

    @Before
    public void setup() {
        HazelcastInstance[] cluster = createHazelcastInstanceFactory(2).newInstances();
        local = cluster[0];
        remote = cluster[1];
        operationService = (OperationServiceImpl) getOperationService(local);
        clusterService = getClusterService(local);
        operationRunner = new OperationRunnerImpl(operationService, getPartitionId(local));
        responseHandler = mock(OperationResponseHandler.class);
    }

    @Test
    public void runTask() {
        final AtomicLong counter = new AtomicLong();
        operationRunner.run(new Runnable() {
            @Override
            public void run() {
                counter.incrementAndGet();
            }
        });
        assertEquals(1, counter.get());
    }

    @Test
    public void runOperation() {
        final AtomicLong counter = new AtomicLong();
        final Object response = "someresponse";
        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }

            @Override
            public Object getResponse() {
                return response;
            }
        };
        op.setPartitionId(operationRunner.getPartitionId());
        op.setOperationResponseHandler(responseHandler);

        operationRunner.run(op);
        assertEquals(1, counter.get());
        verify(responseHandler).sendResponse(op, response);
    }

    @Test
    public void runOperation_whenGeneric() {
        final AtomicLong counter = new AtomicLong();
        final Object response = "someresponse";

        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }

            @Override
            public Object getResponse() {
                return response;
            }
        };
        op.setPartitionId(-1);
        op.setOperationResponseHandler(responseHandler);

        operationRunner.run(op);

        assertEquals(1, counter.get());
        verify(responseHandler).sendResponse(op, response);
    }

    @Test
    public void runOperation_whenWrongPartition_thenTaskNotExecuted() {
        final AtomicLong counter = new AtomicLong();

        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }
        };
        op.setPartitionId(operationRunner.getPartitionId() + 1);
        op.setOperationResponseHandler(responseHandler);

        operationRunner.run(op);

        assertEquals(0, counter.get());
        verify(responseHandler).sendResponse(same(op), any(IllegalStateException.class));
    }

    @Test
    public void runOperation_whenRunThrowsException() {
        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                throw new ExpectedRuntimeException();
            }
        };
        op.setOperationResponseHandler(responseHandler);
        op.setPartitionId(operationRunner.getPartitionId());

        operationRunner.run(op);

        verify(responseHandler).sendResponse(same(op), any(ExpectedRuntimeException.class));
    }

    @Test
    public void runOperation_whenWaitingNeeded() {
        final AtomicLong counter = new AtomicLong();

        DummyWaitingOperation op = new DummyWaitingOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }
        };
        op.setPartitionId(operationRunner.getPartitionId());

        operationRunner.run(op);
        assertEquals(0, counter.get());
        
        verify(responseHandler, never()).sendResponse(same(op), any());
    }

    @Test
    public void runOperation_whenTimeout_thenOperationNotExecuted() {
        final AtomicLong counter = new AtomicLong();

        Operation op = new AbstractOperation() {
            @Override
            public void run() throws Exception {
                counter.incrementAndGet();
            }
        };
        setCallId(op, 10);
        setCallTimeout(op, clusterService.getClusterClock().getClusterTime() - 1);
        op.setPartitionId(operationRunner.getPartitionId());
        op.setOperationResponseHandler(responseHandler);

        operationRunner.run(op);
        assertEquals(0, counter.get());
        verify(responseHandler).sendResponse(same(op), any(CallTimeoutResponse.class));
    }

    @Test
    public void runPacket() throws Exception {
        Operation op = new DummyOperation();
        setCallId(op, 1000 * 1000);

        Packet packet = toPacket(remote, op);
        operationRunner.run(packet);
    }

    @Test(expected = HazelcastSerializationException.class)
    public void runPacket_whenBroken() throws Exception {
        Operation op = new DummyOperation();
        setCallId(op, 1000 * 1000);

        Packet packet = toPacket(remote, op);
        byte[] bytes = packet.getData().toByteArray();
        for (int k = 0; k < bytes.length; k++) {
            bytes[k]++;
        }
        operationRunner.run(packet);
    }

    public abstract class DummyWaitingOperation extends AbstractOperation implements WaitSupport {
        WaitNotifyKey waitNotifyKey = new WaitNotifyKey() {
            @Override
            public String getServiceName() {
                return "someservice";
            }

            @Override
            public String getObjectName() {
                return "someobject";
            }
        };

        @Override
        public WaitNotifyKey getWaitKey() {
            return waitNotifyKey;
        }

        @Override
        public boolean shouldWait() {
            return true;
        }

        @Override
        public void onWaitExpire() {
        }
    }
}
<code block>
package com.hazelcast.spi.impl.operationexecutor.classic;

import com.hazelcast.config.Config;
import com.hazelcast.instance.BuildInfo;
import com.hazelcast.instance.DefaultNodeExtension;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastThreadGroup;
import com.hazelcast.logging.LoggingServiceImpl;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.impl.operationexecutor.OperationHostileThread;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.impl.DefaultSerializationServiceBuilder;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.spi.AbstractOperation;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.operationexecutor.ResponsePacketHandler;
import com.hazelcast.spi.impl.operationexecutor.OperationRunner;
import com.hazelcast.spi.impl.operationexecutor.OperationRunnerFactory;
import com.hazelcast.spi.impl.operationservice.impl.responses.Response;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastTestSupport;
import org.junit.After;
import org.junit.Before;

import java.io.IOException;
import java.util.LinkedList;
import java.util.List;

import static java.util.Collections.synchronizedList;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;


public abstract class AbstractClassicOperationExecutorTest extends HazelcastTestSupport {

    protected LoggingServiceImpl loggingService;
    protected GroupProperties groupProperties;
    protected Address thisAddress;
    protected HazelcastThreadGroup threadGroup;
    protected DefaultNodeExtension nodeExtension;
    protected OperationRunnerFactory handlerFactory;
    protected SerializationService serializationService;
    protected ResponsePacketHandler responsePacketHandler;
    protected ClassicOperationExecutor executor;
    protected Config config;

    @Before
    public void setup() throws Exception {
        loggingService = new LoggingServiceImpl("foo", "jdk", new BuildInfo("1", "1", "1", 1, false));

        serializationService = new DefaultSerializationServiceBuilder().build();
        config = new Config();
        config.setProperty(GroupProperties.PROP_PARTITION_COUNT, "10");
        config.setProperty(GroupProperties.PROP_PARTITION_OPERATION_THREAD_COUNT, "10");
        config.setProperty(GroupProperties.PROP_GENERIC_OPERATION_THREAD_COUNT, "10");
        thisAddress = new Address("localhost", 5701);
        threadGroup = new HazelcastThreadGroup(
                "foo",
                loggingService.getLogger(HazelcastThreadGroup.class),
                Thread.currentThread().getContextClassLoader());
        nodeExtension = new DefaultNodeExtension();
        handlerFactory = new DummyOperationRunnerFactory();

        responsePacketHandler = new DummyResponsePacketHandler();
    }

    protected ClassicOperationExecutor initExecutor() {
        groupProperties = new GroupProperties(config);
        executor = new ClassicOperationExecutor(
                groupProperties, loggingService, thisAddress, handlerFactory, responsePacketHandler,
                threadGroup, nodeExtension);
        return executor;
    }

    public static <E> void assertEqualsEventually(final PartitionSpecificCallable task, final E expected) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertTrue(task + " has not given a response", task.completed());
                assertEquals(expected, task.getResult());
            }
        });
    }

    protected class DummyResponsePacketHandler implements ResponsePacketHandler {
        protected List<Packet> packets = synchronizedList(new LinkedList<Packet>());
        protected List<Response> responses = synchronizedList(new LinkedList<Response>());

        @Override
        public void handle(Packet packet) throws Exception {
            packets.add(packet);
            Response response = serializationService.toObject(packet.getData());
            responses.add(response);
        }
    }

    @After
    public void teardown() {
        if (executor != null) {
            executor.shutdown();
        }
    }

    protected static class DummyGenericOperation extends DummyOperation {
        public DummyGenericOperation() {
            super(GENERIC_PARTITION_ID);
        }
    }

    protected static class DummyPartitionOperation extends DummyOperation {
        public DummyPartitionOperation() {
            this(0);
        }

        public DummyPartitionOperation(int partitionId) {
            super(partitionId);
        }
    }

    protected static class DummyOperation extends AbstractOperation {
        private int durationMs;

        public DummyOperation(int partitionId) {
            setPartitionId(partitionId);
        }

        public DummyOperation durationMs(int durationMs) {
            this.durationMs = durationMs;
            return this;
        }

        @Override
        public void run() throws Exception {
            try {
                Thread.sleep(durationMs);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }

        @Override
        protected void writeInternal(ObjectDataOutput out) throws IOException {
            super.writeInternal(out);
            out.writeInt(durationMs);
        }

        @Override
        protected void readInternal(ObjectDataInput in) throws IOException {
            super.readInternal(in);
            durationMs = in.readInt();
        }
    }

    protected class DummyOperationRunnerFactory implements OperationRunnerFactory {
        protected List<DummyOperationRunner> partitionOperationHandlers = new LinkedList<DummyOperationRunner>();
        protected List<DummyOperationRunner> genericOperationHandlers = new LinkedList<DummyOperationRunner>();
        protected DummyOperationRunner adhocHandler;

        @Override
        public OperationRunner createPartitionRunner(int partitionId) {
            DummyOperationRunner operationHandler = new DummyOperationRunner(partitionId);
            partitionOperationHandlers.add(operationHandler);
            return operationHandler;
        }

        @Override
        public OperationRunner createGenericRunner() {
            DummyOperationRunner operationHandler = new DummyOperationRunner(Operation.GENERIC_PARTITION_ID);
            genericOperationHandlers.add(operationHandler);
            return operationHandler;
        }

        @Override
        public OperationRunner createAdHocRunner() {
            if (adhocHandler != null) {
                throw new IllegalStateException("adHocHandler should only be created once");
            }
            
            DummyOperationRunner operationHandler = new DummyOperationRunner(-2);
            adhocHandler = operationHandler;
            return operationHandler;
        }
    }

    public class DummyOperationRunner extends OperationRunner {
        protected List<Packet> packets = synchronizedList(new LinkedList<Packet>());
        protected List<Operation> operations = synchronizedList(new LinkedList<Operation>());
        protected List<Runnable> tasks = synchronizedList(new LinkedList<Runnable>());

        public DummyOperationRunner(int partitionId) {
            super(partitionId);
        }

        @Override
        public void run(Runnable task) {
            tasks.add(task);
            task.run();
        }

        @Override
        public void run(Packet packet) throws Exception {
            packets.add(packet);
            Operation op = serializationService.toObject(packet.getData());
            run(op);
        }

        @Override
        public void run(Operation task) {
            operations.add(task);

            this.currentTask = task;
            try {
                task.run();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                currentTask = null;
            }
        }
    }

    protected static class DummyOperationHostileThread extends Thread implements OperationHostileThread {
        protected DummyOperationHostileThread(Runnable task) {
            super(task);
        }
    }
}

<code block>
package com.hazelcast.spi.impl.operationexecutor.classic;

import com.hazelcast.spi.Operation;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class ClassicOperationExecutorTest extends AbstractClassicOperationExecutorTest {

    @Test
    public void testConstruction() {
        initExecutor();

        assertEquals(groupProperties.PARTITION_COUNT.getInteger(), executor.getPartitionOperationRunners().length);
        assertEquals(executor.getGenericOperationThreadCount(), executor.getGenericOperationRunners().length);

        assertEquals(groupProperties.PARTITION_OPERATION_THREAD_COUNT.getInteger(),
                executor.getPartitionOperationThreadCount());

        assertEquals(groupProperties.GENERIC_OPERATION_THREAD_COUNT.getInteger(),
                executor.getGenericOperationThreadCount());
    }

    @Test
    public void test_getRunningOperationCount() {
        initExecutor();

        executor.execute(new DummyOperation(Operation.GENERIC_PARTITION_ID).durationMs(2000));
        executor.execute(new DummyOperation(Operation.GENERIC_PARTITION_ID).durationMs(2000));

        executor.execute(new DummyOperation(0).durationMs(2000));

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                int runningOperationCount = executor.getRunningOperationCount();
                System.out.println("runningOperationCount:" + runningOperationCount);
                assertEquals(3, runningOperationCount);
            }
        });
    }

    @Test
    public void test_getOperationExecutorQueueSize() {
        initExecutor();

        
        for (int k = 0; k < executor.getGenericOperationThreadCount(); k++) {
            executor.execute(new DummyOperation(Operation.GENERIC_PARTITION_ID).durationMs(2000));
        }
        for (int k = 0; k < executor.getPartitionOperationThreadCount(); k++) {
            executor.execute(new DummyOperation(k).durationMs(2000));
        }

        
        int count = 0;
        for (int l = 0; l < 3; l++) {
            for (int k = 0; k < executor.getGenericOperationThreadCount(); k++) {
                executor.execute(new DummyOperation(Operation.GENERIC_PARTITION_ID).durationMs(2000));
                count++;
            }
        }
        for (int l = 0; l < 5; l++) {
            for (int k = 0; k < executor.getPartitionOperationThreadCount(); k++) {
                executor.execute(new DummyOperation(k).durationMs(2000));
                count++;
            }
        }

        final int expectedCount = count;
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(expectedCount, executor.getOperationExecutorQueueSize());
            }
        });
    }

    @Test
    public void test_dumpPerformanceMetrics() {
        initExecutor();

        StringBuffer sb = new StringBuffer();
        executor.dumpPerformanceMetrics(sb);
        String content = sb.toString();


        assertTrue(content.contains("processedCount="));
    }
}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.management.ManagementFactory;
import java.util.concurrent.TimeUnit;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class RuntimeMetricSetTest extends HazelcastTestSupport {

    private final static int TEN_MB = 10 * 1024 * 1024;

    private MetricsRegistryImpl blackbox;
    private Runtime runtime;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
        runtime = Runtime.getRuntime();
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(RuntimeMetricSet.class);
    }

    @Test
    public void freeMemory() {
        final Gauge gauge = blackbox.getGauge("runtime.freeMemory");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(runtime.freeMemory(), gauge.readLong(), TEN_MB);
            }
        });
    }

    @Test
    public void totalMemory() {
        final Gauge gauge = blackbox.getGauge("runtime.totalMemory");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(runtime.totalMemory(), gauge.readLong(), TEN_MB);
            }
        });
    }

    @Test
    public void maxMemory() {
        final Gauge gauge = blackbox.getGauge("runtime.maxMemory");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(runtime.maxMemory(), gauge.readLong(), TEN_MB);
            }
        });
    }

    @Test
    public void usedMemory() {
        final Gauge gauge = blackbox.getGauge("runtime.usedMemory");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                double expected = runtime.totalMemory() - runtime.freeMemory();
                assertEquals(expected, gauge.readLong(), TEN_MB);
            }
        });
    }

    @Test
    public void availableProcessors() {
        Gauge gauge = blackbox.getGauge("runtime.availableProcessors");
        assertEquals(runtime.availableProcessors(), gauge.readLong());
    }

    @Test
    public void uptime() {
        final Gauge gauge = blackbox.getGauge("runtime.uptime");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                double expected = ManagementFactory.getRuntimeMXBean().getUptime();
                assertEquals(expected, gauge.readLong(), TimeUnit.MINUTES.toMillis(1));
            }
        });
    }
}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.management.ClassLoadingMXBean;
import java.lang.management.ManagementFactory;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class ClassLoadingMetricSetTest extends HazelcastTestSupport {

    private static final ClassLoadingMXBean BEAN = ManagementFactory.getClassLoadingMXBean();

    private MetricsRegistryImpl blackbox;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(ClassLoadingMetricSet.class);
    }

    @Test
    public void loadedClassesCount() {
        final Gauge gauge = blackbox.getGauge("classloading.loadedClassesCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(BEAN.getLoadedClassCount(), gauge.readLong(), 100);
            }
        });
    }

    @Test
    public void totalLoadedClassesCount() {
        final Gauge gauge = blackbox.getGauge("classloading.totalLoadedClassesCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(BEAN.getTotalLoadedClassCount(), gauge.readLong(), 100);
            }
        });
    }

    @Test
    public void unloadedClassCount() {
        final Gauge gauge = blackbox.getGauge("classloading.unloadedClassCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(BEAN.getUnloadedClassCount(), gauge.readLong(), 100);
            }
        });
    }

}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.management.ManagementFactory;
import java.lang.management.OperatingSystemMXBean;

import static com.hazelcast.internal.metrics.metricsets.OperatingSystemMetricsSet.registerMethod;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import static org.junit.Assume.assumeTrue;



@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class OperatingSystemMetricSetTest extends HazelcastTestSupport {

    private MetricsRegistryImpl blackbox;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(OperatingSystemMetricsSet.class);
    }

    @Test
    public void testComSunManagementUnixOperatingSystem() {
        assertContainsSensor("os.systemLoadAverage");

        assumeOperatingSystemMXBean("com.sun.management.UnixOperatingSystem");

        assertContainsSensor("os.committedVirtualMemorySize");
        assertContainsSensor("os.freePhysicalMemorySize");
        assertContainsSensor("os.freeSwapSpaceSize");
        assertContainsSensor("os.processCpuTime");
        assertContainsSensor("os.totalPhysicalMemorySize");
        assertContainsSensor("os.totalSwapSpaceSize");
        assertContainsSensor("os.maxFileDescriptorCount");
        assertContainsSensor("os.openFileDescriptorCount");

        
        
        
    }

    @Test
    public void testSunManagementOperatingSystemImpl() {
        assertContainsSensor("os.systemLoadAverage");

        assumeOperatingSystemMXBean("sun.management.OperatingSystemImpl");

        assertContainsSensor("os.committedVirtualMemorySize");
        assertContainsSensor("os.freePhysicalMemorySize");
        assertContainsSensor("os.freeSwapSpaceSize");
        assertContainsSensor("os.processCpuTime");
        assertContainsSensor("os.totalPhysicalMemorySize");
        assertContainsSensor("os.totalSwapSpaceSize");
        assertContainsSensor("os.maxFileDescriptorCount");
        assertContainsSensor("os.openFileDescriptorCount");

        assertContainsSensor("os.processCpuLoad");
        assertContainsSensor("os.systemCpuLoad");
    }

    private void assertContainsSensor(String parameter) {
        boolean contains = blackbox.getNames().contains(parameter);
        assertTrue("sensor:" + parameter + " is not found", contains);
    }

    private void assumeOperatingSystemMXBean(String expected) {
        OperatingSystemMXBean bean = ManagementFactory.getOperatingSystemMXBean();

        String foundClass = bean.getClass().getName();

        assumeTrue(foundClass + " is not usable", expected.equals(foundClass));
    }

    @Test
    public void registerMethod_whenDouble() {
        FakeOperatingSystemBean fakeOperatingSystemBean = new FakeOperatingSystemBean();
        registerMethod(blackbox, fakeOperatingSystemBean, "doubleMethod", "doubleMethod");

        Gauge gauge = blackbox.getGauge("doubleMethod");
        assertEquals(fakeOperatingSystemBean.doubleMethod(), gauge.readDouble(), 0.1);
    }

    @Test
    public void registerMethod_whenLong() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));

        FakeOperatingSystemBean fakeOperatingSystemBean = new FakeOperatingSystemBean();
        registerMethod(blackbox, fakeOperatingSystemBean, "longMethod", "longMethod");

        Gauge gauge = blackbox.getGauge("longMethod");
        assertEquals(fakeOperatingSystemBean.longMethod(), gauge.readLong());
    }

    @Test
    public void registerMethod_whenNotExist() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));

        FakeOperatingSystemBean fakeOperatingSystemBean = new FakeOperatingSystemBean();
        registerMethod(blackbox, fakeOperatingSystemBean, "notexist", "notexist");

        boolean parameterExist = blackbox.getNames().contains("notexist");
        assertFalse(parameterExist);
    }

    public class FakeOperatingSystemBean {
        double doubleMethod() {
            return 10;
        }

        long longMethod() {
            return 10;
        }
    }

}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.management.ManagementFactory;
import java.lang.management.ThreadMXBean;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class ThreadMetricSetTest extends HazelcastTestSupport {

    private static final ThreadMXBean MX_BEAN = ManagementFactory.getThreadMXBean();

    private MetricsRegistryImpl blackbox;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(ThreadMetricSet.class);
    }

    @Test
    public void threadCount() {
        final Gauge gauge = blackbox.getGauge("thread.threadCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(MX_BEAN.getThreadCount(), gauge.readLong(), 10);
            }
        });
    }

    @Test
    public void peakThreadCount() {
        final Gauge gauge = blackbox.getGauge("thread.peakThreadCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(MX_BEAN.getPeakThreadCount(), gauge.readLong(), 10);
            }
        });
    }

    @Test
    public void daemonThreadCount() {
        final Gauge gauge = blackbox.getGauge("thread.daemonThreadCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(MX_BEAN.getDaemonThreadCount(), gauge.readLong(), 10);
            }
        });
    }

    @Test
    public void totalStartedThreadCount() {
        final Gauge gauge = blackbox.getGauge("thread.totalStartedThreadCount");

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(MX_BEAN.getTotalStartedThreadCount(), gauge.readLong(), 10);
            }
        });
    }
}

<code block>
package com.hazelcast.internal.metrics.metricsets;

import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.internal.metrics.impl.MetricsRegistryImpl;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static java.util.concurrent.TimeUnit.SECONDS;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class GarbageCollectionMetricSetTest extends HazelcastTestSupport {

    private MetricsRegistryImpl blackbox;
    private GarbageCollectionMetricSet.GcStats gcStats;

    @Before
    public void setup() {
        blackbox = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
        gcStats = new GarbageCollectionMetricSet.GcStats();
    }

    @Test
    public void utilityConstructor(){
        assertUtilityConstructor(GarbageCollectionMetricSet.class);
    }

    @Test
    public void minorCount() {
        final Gauge gauge = blackbox.getGauge("gc.minorCount");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                 assertEquals(gcStats.minorCount, gauge.readLong(), 1);
            }
        });
    }

    @Test
    public void minorTime() throws InterruptedException {
        final Gauge gauge = blackbox.getGauge("gc.minorTime");
         assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.minorTime, gauge.readLong(), SECONDS.toMillis(1));
            }
        });
    }

    @Test
    public void majorCount() {
        final Gauge gauge = blackbox.getGauge("gc.majorCount");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.majorCount, gauge.readLong(), 1);
            }
        });
    }

    @Test
    public void majorTime() {
        final Gauge gauge = blackbox.getGauge("gc.majorTime");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.majorTime, gauge.readLong(), SECONDS.toMillis(1));
            }
        });
    }


    @Test
    public void unknownCount() {
        final Gauge gauge = blackbox.getGauge("gc.unknownCount");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.unknownCount, gauge.readLong(), 1);
            }
        });
    }

    @Test
    public void unknownTime() {
        final Gauge gauge = blackbox.getGauge("gc.unknownTime");
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                gcStats.run();
                assertEquals(gcStats.unknownTime, gauge.readLong(), SECONDS.toMillis(1));
            }
        });
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.internal.metrics.impl.MethodProbe.LongMethodProbe;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import com.hazelcast.util.counters.Counter;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.reflect.Method;
import java.util.Arrays;
import java.util.Collection;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.internal.metrics.impl.MethodProbe.createMethodProbe;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class MethodProbeTest extends HazelcastTestSupport {

    @Test
    public void getLong() throws Exception {
        getLong("byteMethod", 10);
        getLong("shortMethod", 10);
        getLong("intMethod", 10);
        getLong("longMethod", 10);
        getLong("atomicLongMethod", 10);
        getLong("atomicIntegerMethod", 10);
        getLong("counterMethod", 10);
        getLong("collectionMethod", 10);
        getLong("mapMethod", 10);

        getLong("ByteMethod", 10);
        getLong("ShortMethod", 10);
        getLong("IntegerMethod", 10);
        getLong("LongMethod", 10);

        getLong("nullAtomicLongMethod", 0);
        getLong("nullAtomicIntegerMethod", 0);
        getLong("nullCounterMethod", 0);
        getLong("nullCollectionMethod", 0);
        getLong("nullMapMethod", 0);
        getLong("nullByteMethod", 0);
        getLong("nullShortMethod", 0);
        getLong("nullIntegerMethod", 0);
        getLong("nullLongMethod", 0);
    }

    public void getLong(String fieldName, int expectedValue) throws Exception {
        SomeSource source = new SomeSource();
        Method method = source.getClass().getDeclaredMethod(fieldName);
        Probe probe = method.getAnnotation(Probe.class);
        MethodProbe methodProbe = createMethodProbe(method, probe);

        LongMethodProbe longMethodProbe = assertInstanceOf(LongMethodProbe.class, methodProbe);

        long value = longMethodProbe.get(source);

        assertEquals(expectedValue, value);
    }


    @Test
    public void getDouble() throws Exception {
        getDouble("floatMethod", 10);
        getDouble("doubleMethod", 10);
        getDouble("DoubleMethod", 10);
        getDouble("FloatMethod", 10);
        getDouble("nullDoubleMethod", 0);
        getDouble("nullFloatMethod", 0);
    }

    public void getDouble(String fieldName, double expected) throws Exception {
        SomeSource source = new SomeSource();
        Method method = source.getClass().getDeclaredMethod(fieldName);
        Probe probe = method.getAnnotation(Probe.class);

        MethodProbe methodProbe = createMethodProbe(method, probe);

        MethodProbe.DoubleMethodProbe doubleMethodProbe = assertInstanceOf(MethodProbe.DoubleMethodProbe.class, methodProbe);
        double value = doubleMethodProbe.get(source);

        assertEquals(expected, value, 0.1);
    }


    private class SomeSource {
        @Probe
        private byte byteMethod() {
            return 10;
        }

        @Probe
        private short shortMethod() {
            return 10;
        }

        @Probe
        private int intMethod() {
            return 10;
        }

        @Probe
        private long longMethod() {
            return 10;
        }

        @Probe
        private float floatMethod() {
            return 10;
        }

        @Probe
        private double doubleMethod() {
            return 10;
        }

        @Probe
        private AtomicLong atomicLongMethod() {
            return new AtomicLong(10);

        }

        @Probe
        private AtomicLong nullAtomicLongMethod() {
            return null;
        }

        @Probe
        private AtomicInteger atomicIntegerMethod() {
            return new AtomicInteger(10);
        }

        @Probe
        private AtomicInteger nullAtomicIntegerMethod() {
            return null;
        }

        @Probe
        private Counter counterMethod() {
            return newSwCounter(10);
        }

        @Probe
        private Counter nullCounterMethod() {
            return null;
        }

        @Probe
        private Collection collectionMethod() {
            return Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);
        }

        @Probe
        private Collection nullCollectionMethod() {
            return null;
        }

        @Probe
        private Map mapMethod() {
            return MetricsUtils.createMap(10);
        }

        @Probe
        private Map nullMapMethod() {
            return null;
        }

        @Probe
        private Byte ByteMethod() {
            return (byte) 10;
        }

        @Probe
        private Short ShortMethod() {
            return (short) 10;
        }

        @Probe
        private Integer IntegerMethod() {
            return 10;
        }

        @Probe
        private Long LongMethod() {
            return (long) 10;
        }

        @Probe
        private Float FloatMethod() {
            return (float) 10;
        }

        @Probe
        private Double DoubleMethod() {
            return (double) 10;
        }

        @Probe
        private Byte nullByteMethod() {
            return null;
        }

        @Probe
        private Short nullShortMethod() {
            return null;
        }

        @Probe
        private Integer nullIntegerMethod() {
            return null;
        }

        @Probe
        private Long nullLongMethod() {
            return null;
        }

        @Probe
        private Float nullFloatMethod() {
            return null;
        }

        @Probe
        private Double nullDoubleMethod() {
            return null;
        }
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.LongProbe;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.HashSet;
import java.util.Set;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertSame;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class MetricsRegistryImplTest extends HazelcastTestSupport {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void modCount() {
        long modCount = metricsRegistry.modCount();
        metricsRegistry.register(this, "foo", new LongProbe() {
            @Override
            public long get(Object obj) throws Exception {
                return 1;
            }
        });
        assertEquals(modCount + 1, metricsRegistry.modCount());

        metricsRegistry.deregister(this);
        assertEquals(modCount + 2, metricsRegistry.modCount());
    }

    

    @Test(expected = NullPointerException.class)
    public void getMetric_whenNullName() {
        metricsRegistry.getGauge(null);
    }

    @Test
    public void getMetric_whenNotExistingMetric() {
        Gauge gauge = metricsRegistry.getGauge("foo");

        assertNotNull(gauge);
        assertEquals("foo", gauge.getName());
        assertEquals(0, gauge.readLong());
    }

    @Test
    public void getMetric_whenExistingMetric() {
        Gauge first = metricsRegistry.getGauge("foo");
        Gauge second = metricsRegistry.getGauge("foo");

        assertSame(first, second);
    }

    @Test
    public void getNames() {
        Set<String> expected = new HashSet<String>();
        expected.add("first");
        expected.add("second");
        expected.add("third");

        for (String name : expected) {
            metricsRegistry.register(this, name, new LongProbe() {
                @Override
                public long get(Object obj) throws Exception {
                    return 0;
                }
            });
        }

        Set<String> names = metricsRegistry.getNames();
        for (String name : expected) {
            assertTrue(names.contains(name));
        }
    }

    @Test
    public void shutdown(){
        metricsRegistry.shutdown();
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.internal.metrics.impl.FieldProbe.DoubleFieldProbe;
import com.hazelcast.internal.metrics.impl.FieldProbe.LongFieldProbe;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import com.hazelcast.util.counters.Counter;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.lang.reflect.Field;
import java.util.Arrays;
import java.util.Collection;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.internal.metrics.impl.FieldProbe.createFieldProbe;
import static com.hazelcast.util.counters.SwCounter.newSwCounter;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class FieldProbeTest extends HazelcastTestSupport {

    @Test(expected = IllegalArgumentException.class)
    public void whenUnknownType() throws NoSuchFieldException {
        UnknownFieldType unknownFieldType = new UnknownFieldType();
        Field field = unknownFieldType.getClass().getDeclaredField("field");
        Probe probe = field.getAnnotation(Probe.class);

        createFieldProbe(field, probe);
    }

    private class UnknownFieldType {
        @Probe
        private String field;
    }

    @Test
    public void getLong() throws Exception {
        getLong("byteField", 10);
        getLong("shortField", 10);
        getLong("intField", 10);
        getLong("longField", 10);
        getLong("atomicLongField", 10);
        getLong("atomicIntegerField", 10);
        getLong("counterField", 10);
        getLong("collectionField", 10);
        getLong("mapField", 10);

        getLong("ByteField", 10);
        getLong("ShortField", 10);
        getLong("IntegerField", 10);
        getLong("LongField", 10);

        getLong("nullAtomicLongField", 0);
        getLong("nullAtomicIntegerField", 0);
        getLong("nullCounterField", 0);
        getLong("nullCollectionField", 0);
        getLong("nullMapField", 0);
        getLong("nullByteField", 0);
        getLong("nullShortField", 0);
        getLong("nullIntegerField", 0);
        getLong("nullLongField", 0);
    }

    public void getLong(String fieldName, int expectedValue) throws Exception {
        SomeSource source = new SomeSource();
        Field field = source.getClass().getDeclaredField(fieldName);
        Probe probe = field.getAnnotation(Probe.class);
        FieldProbe fieldProbe = createFieldProbe(field, probe);

        LongFieldProbe longFieldProbe = assertInstanceOf(LongFieldProbe.class, fieldProbe);

        long value = longFieldProbe.get(source);

        assertEquals(expectedValue, value);
    }

    @Test
    public void getDouble() throws Exception {
        getDouble("floatField", 10);
        getDouble("doubleField", 10);
        getDouble("DoubleField", 10);
        getDouble("FloatField", 10);
        getDouble("nullDoubleField", 0);
        getDouble("nullFloatField", 0);
    }

    public void getDouble(String fieldName, double expected) throws Exception {
        SomeSource source = new SomeSource();
        Field field = source.getClass().getDeclaredField(fieldName);
        Probe probe = field.getAnnotation(Probe.class);

        FieldProbe fieldProbe = createFieldProbe(field, probe);
        assertInstanceOf(DoubleFieldProbe.class, fieldProbe);

        DoubleFieldProbe doubleFieldProbe = (DoubleFieldProbe) fieldProbe;

        double value = doubleFieldProbe.get(source);

        assertEquals(expected, value, 0.1);
    }

    private class SomeSource {
        @Probe
        private byte byteField = 10;
        @Probe
        private short shortField = 10;
        @Probe
        private int intField = 10;
        @Probe
        private long longField = 10;

        @Probe
        private float floatField = 10;
        @Probe
        private double doubleField = 10;

        @Probe
        private AtomicLong atomicLongField = new AtomicLong(10);
        @Probe
        private AtomicLong nullAtomicLongField;
        @Probe
        private AtomicInteger atomicIntegerField = new AtomicInteger(10);
        @Probe
        private AtomicInteger nullAtomicIntegerField;
        @Probe
        private Counter counterField = newSwCounter(10);
        @Probe
        private Counter nullCounterField;
        @Probe
        private Collection collectionField = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);
        @Probe
        private Collection nullCollectionField;
        @Probe
        private Map mapField = MetricsUtils.createMap(10);
        @Probe
        private Map nullMapField;


        @Probe
        private Byte ByteField = (byte) 10;
        @Probe
        private Short ShortField = (short) 10;
        @Probe
        private Integer IntegerField = 10;
        @Probe
        private Long LongField = (long) 10;
        @Probe
        private Float FloatField = (float) 10;
        @Probe
        private Double DoubleField = (double) 10;

        @Probe
        private Byte nullByteField;
        @Probe
        private Short nullShortField;
        @Probe
        private Integer nullIntegerField;
        @Probe
        private Long nullLongField;
        @Probe
        private Float nullFloatField;
        @Probe
        private Double nullDoubleField;
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.util.counters.Counter;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;

import static com.hazelcast.util.counters.SwCounter.newSwCounter;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class RegisterAnnotatedFieldsTest extends HazelcastTestSupport {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test
    public void register_customName() {
        ObjectLongGaugeFieldWithName object = new ObjectLongGaugeFieldWithName();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.myfield");
        object.field = 10;
        assertEquals(object.field, gauge.readLong());
    }

    public class ObjectLongGaugeFieldWithName {
        @Probe(name = "myfield")
        private long field;
    }

    @Test
    public void register_primitiveInteger() {
        PrimitiveIntegerField object = new PrimitiveIntegerField();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.field");
        object.field = 10;
        assertEquals(object.field, gauge.readLong());
    }

    public class PrimitiveIntegerField {
        @Probe
        private int field;
    }

    @Test
    public void register_primitiveLong() {
        PrimitiveLongField object = new PrimitiveLongField();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.field");
        object.field = 10;
        assertEquals(object.field, gauge.readLong());
    }

    public class PrimitiveLongField {
        @Probe
        private long field;
    }

    @Test
    public void register_primitiveDouble() {
        PrimitiveDoubleField object = new PrimitiveDoubleField();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.field");
        object.field = 10;
        assertEquals(object.field, gauge.readDouble(),0.1);
    }

    public class PrimitiveDoubleField {
        @Probe
        private double field;
    }

    @Test
    public void register_concurrentHashMap() {
        ConcurrentMapField object = new ConcurrentMapField();
        object.field.put("foo", "foo");
        object.field.put("bar", "bar");
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.field");
        assertEquals(object.field.size(), gauge.readLong());

        object.field = null;
        assertEquals(0, gauge.readLong());
    }

    public class ConcurrentMapField {
        @Probe
        private ConcurrentHashMap field = new ConcurrentHashMap();
    }

    @Test
    public void register_counterFields() {
        CounterField object = new CounterField();
        object.field.inc(10);
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.field");
        assertEquals(10, gauge.readLong());

        object.field = null;
        assertEquals(0, gauge.readLong());
    }

    public class CounterField {
        @Probe
        private Counter field = newSwCounter();
    }

    @Test
    public void register_staticField() {
        StaticField object = new StaticField();
        StaticField.field.set(10);
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.field");
        assertEquals(10, gauge.readLong());

        StaticField.field = null;
        assertEquals(0, gauge.readLong());
    }

    public static class StaticField {
        @Probe
        static AtomicInteger field = new AtomicInteger();
    }

    @Test
    public void register_superclassRegistration() {
        Subclass object = new Subclass();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.field");
        assertEquals(0, gauge.readLong());

        object.field = 10;
        assertEquals(10, gauge.readLong());
    }

    public static class SuperClass{
        @Probe
        int field;
    }

    public static class Subclass extends SuperClass{

    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.util.counters.Counter;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import freemarker.ext.util.IdentityHashMap;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

import static com.hazelcast.util.counters.SwCounter.newSwCounter;
import static org.junit.Assert.assertEquals;



@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class RegisterAnnotatedMethodsTest extends HazelcastTestSupport {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test(expected = IllegalArgumentException.class)
    public void register_methodWithArguments() {
        MethodWithArgument object = new MethodWithArgument();
        metricsRegistry.scanAndRegister(object, "foo");
    }

    public class MethodWithArgument {
        @Probe
        private long method(int x) {
            return 10;
        }
    }

    @Test
    public void register_withCustomName() {
        GaugeMethodWithName object = new GaugeMethodWithName();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.mymethod");
        assertEquals(10, gauge.readLong());
    }

    public class GaugeMethodWithName {
        @Probe(name = "mymethod")
        private long method() {
            return 10;
        }
    }

    @Test(expected = IllegalArgumentException.class)
    public void register_methodReturnsVoid() {
        VoidMethod object = new VoidMethod();
        metricsRegistry.scanAndRegister(object, "foo");
    }

    public class VoidMethod {
        @Probe
        private void method() {
        }
    }

    @Test
    public void register_primitiveByte() {
        PrimitiveByteMethod object = new PrimitiveByteMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method(), gauge.readLong());
    }

    public class PrimitiveByteMethod {
        @Probe
        private byte method() {
            return 10;
        }
    }

    @Test
    public void register_primitiveShort() {
        PrimitiveShortMethod object = new PrimitiveShortMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method(), gauge.readLong());
    }

    public class PrimitiveShortMethod {
        @Probe
        private short method() {
            return 10;
        }
    }


    @Test
    public void register_primitiveInt() {
        PrimitiveIntMethod object = new PrimitiveIntMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(10, gauge.readLong());
    }

    public class PrimitiveIntMethod {
        @Probe
        private int method() {
            return 10;
        }
    }

    @Test
    public void register_primitiveLong() {
        PrimitiveLongMethod object = new PrimitiveLongMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(10, gauge.readLong());
    }


    public class PrimitiveLongMethod {
        @Probe
        private long method() {
            return 10;
        }
    }

    @Test
    public void register_primitiveFloat() {
        PrimitiveFloatMethod object = new PrimitiveFloatMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method(), gauge.readDouble(), 0.1);
    }

    public class PrimitiveFloatMethod {
        @Probe
        private float method() {
            return 10f;
        }
    }

    @Test
    public void register_primitiveDouble() {
        PrimitiveDoubleMethod object = new PrimitiveDoubleMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method(), gauge.readDouble(), 0.1);
    }

    public class PrimitiveDoubleMethod {
        @Probe
        private double method() {
            return 10d;
        }
    }

    @Test
    public void register_atomicLong() {
        AtomicLongMethod object = new AtomicLongMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method().get(), gauge.readLong());
    }

    public class AtomicLongMethod {
        @Probe
        private AtomicLong method() {
            return new AtomicLong(10);
        }
    }

    @Test
    public void register_atomicInteger() {
        AtomicIntegerMethod object = new AtomicIntegerMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method().get(), gauge.readLong());
    }

    public class AtomicIntegerMethod {
        @Probe
        private AtomicInteger method() {
            return new AtomicInteger(10);
        }
    }

    @Test
    public void register_counter() {
        CounterMethod object = new CounterMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method().get(), gauge.readLong());
    }

    public class CounterMethod {
        @Probe
        private Counter method() {
            Counter counter = newSwCounter();
            counter.inc(10);
            return counter;
        }
    }

    @Test
    public void register_collection() {
        CollectionMethod object = new CollectionMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method().size(), gauge.readLong());
    }

    public class CollectionMethod {
        @Probe
        private Collection method() {
            ArrayList list = new ArrayList();
            for (int k = 0; k < 10; k++) {
                list.add(k);
            }
            return list;
        }
    }

    @Test
    public void register_map() {
        MapMethod object = new MapMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method().size(), gauge.readLong());
    }

    public class MapMethod {
        @Probe
        private Map method() {
            HashMap map = new HashMap();
            for (int k = 0; k < 10; k++) {
                map.put(k, k);
            }
            return map;
        }
    }

    @Test
    public void register_subclass() {
        SubclassMethod object = new SubclassMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method().size(), gauge.readLong());
    }

    public class SubclassMethod {
        @Probe
        private IdentityHashMap method() {
            IdentityHashMap map = new IdentityHashMap();
            for (int k = 0; k < 10; k++) {
                map.put(k, k);
            }
            return map;
        }
    }


    @Test
    public void register_staticMethod() {
        StaticMethod object = new StaticMethod();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(StaticMethod.method(), gauge.readLong());
    }

    public static class StaticMethod {
        @Probe
        private static long method() {
            return 10;
        }
    }

    @Test
    public void register_interfaceWithGauges() {
        SomeInterfaceImplementation object = new SomeInterfaceImplementation();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.method");
        assertEquals(10, gauge.readLong());
    }

    public  interface SomeInterface{
        @Probe
        int method();
    }

    public static class SomeInterfaceImplementation implements SomeInterface{
        @Override
        public int method() {
            return 10;
        }
    }

    @Test
    public void register_superclassWithGaugeMethods() {
        SubclassWithGauges object = new SubclassWithGauges();
        metricsRegistry.scanAndRegister(object, "foo");

        Gauge methodGauge = metricsRegistry.getGauge("foo.method");
        assertEquals(object.method(), methodGauge.readLong());

        Gauge fieldGauge = metricsRegistry.getGauge("foo.field");
        assertEquals(object.field, fieldGauge.readLong());
    }

    public static abstract class ClassWithGauges {
        @Probe
        int method(){
            return 10;
        }

        @Probe
        int field=10;
    }

    public static class SubclassWithGauges extends ClassWithGauges {

    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.DoubleProbe;
import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.LongProbe;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static java.lang.Math.round;
import static org.junit.Assert.assertEquals;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class GaugeImplTest {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    class SomeObject {
        @Probe
        long longField = 10;
        @Probe
        double doubleField = 10.8;
    }

    @Test
    public void getName() {
        Gauge gauge = metricsRegistry.getGauge("foo");

        String actual = gauge.getName();

        assertEquals("foo", actual);
    }

    

    @Test
    public void readLong_whenNoInput() {
        Gauge gauge = metricsRegistry.getGauge("foo");

        long actual = gauge.readLong();

        assertEquals(0, actual);
    }

    @Test
    public void readLong_whenDoubleGauge() {
        metricsRegistry.register(this, "foo", new DoubleProbe<GaugeImplTest>() {
            @Override
            public double get(GaugeImplTest source) throws Exception {
                return 10;
            }
        });

        Gauge gauge = metricsRegistry.getGauge("foo");

        long actual = gauge.readLong();

        assertEquals(10, actual);
    }

    @Test
    public void readLong_whenLongGauge() {
        metricsRegistry.register(this, "foo", new LongProbe() {
            @Override
            public long get(Object o) throws Exception {
                return 10;
            }
        });

        Gauge gauge = metricsRegistry.getGauge("foo");
        assertEquals(10, gauge.readLong());
    }

    @Test
    public void readLong_whenExceptionalInput() {
        metricsRegistry.register(this, "foo", new LongProbe() {
            @Override
            public long get(Object o) {
                throw new RuntimeException();
            }
        });

        Gauge gauge = metricsRegistry.getGauge("foo");

        long actual = gauge.readLong();

        assertEquals(0, actual);
    }

    @Test
    public void readLong_whenLongGaugeField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.longField");
        assertEquals(10, gauge.readLong());
    }

    @Test
    public void readLong_whenDoubleGaugeField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.doubleField");
        assertEquals(round(someObject.doubleField), gauge.readLong());
    }

    

    @Test
    public void readDouble_whenNoMetricInput() {
        Gauge gauge = metricsRegistry.getGauge("foo");

        double actual = gauge.readDouble();

        assertEquals(0, actual, 0.1);
    }

    @Test
    public void readDouble_whenExceptionalInput() {
        metricsRegistry.register(this, "foo", new DoubleProbe() {
            @Override
            public double get(Object o) {
                throw new RuntimeException();
            }
        });

        Gauge gauge = metricsRegistry.getGauge("foo");

        double actual = gauge.readDouble();

        assertEquals(0, actual, 0.1);
    }

    @Test
    public void readDouble_whenDoubleGauge() {
        metricsRegistry.register(this, "foo", new DoubleProbe() {
            @Override
            public double get(Object o) {
                return 10;
            }
        });
        Gauge gauge = metricsRegistry.getGauge("foo");

        double actual = gauge.readDouble();

        assertEquals(10, actual, 0.1);
    }

    @Test
    public void readDouble_whenLongGauge() {
        metricsRegistry.register(this, "foo", new LongProbe() {
            @Override
            public long get(Object o) throws Exception {
                return 10;
            }
        });
        Gauge gauge = metricsRegistry.getGauge("foo");

        double actual = gauge.readDouble();

        assertEquals(10, actual, 0.1);
    }

    @Test
    public void readDouble_whenLongGaugeField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.longField");
        assertEquals(someObject.longField, gauge.readDouble(), 0.1);
    }

    @Test
    public void readDouble_whenDoubleGaugeField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");

        Gauge gauge = metricsRegistry.getGauge("foo.doubleField");
        assertEquals(someObject.doubleField, gauge.readDouble(), 0.1);
    }

    

    @Test
    public void render_whenDoubleGauge() {
        metricsRegistry.register(this, "foo", new DoubleProbe() {
            @Override
            public double get(Object o) {
                return 10;
            }
        });
        Gauge gauge = metricsRegistry.getGauge("foo");
        StringBuilder sb = new StringBuilder();

        gauge.render(sb);

        assertEquals("foo=10.0", sb.toString());
    }

    @Test
    public void render_whenLongGauge() {
        metricsRegistry.register(this, "foo", new LongProbe() {
            @Override
            public long get(Object o) {
                return 10;
            }
        });
        Gauge gauge = metricsRegistry.getGauge("foo");
        StringBuilder sb = new StringBuilder();

        gauge.render(sb);

        assertEquals("foo=10", sb.toString());
    }

    @Test
    public void render_whenNoInput() {
        Gauge gauge = metricsRegistry.getGauge("foo");
        StringBuilder sb = new StringBuilder();

        gauge.render(sb);

        assertEquals("foo=NA", sb.toString());
    }

    @Test
    public void render_whenNoSource() {
        Gauge gauge = metricsRegistry.getGauge("foo");
        StringBuilder sb = new StringBuilder();

        gauge.render(sb);

        assertEquals("foo=NA", sb.toString());
    }

    @Test
    public void render_whenDoubleField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");
        Gauge gauge = metricsRegistry.getGauge("foo.doubleField");
        StringBuilder sb = new StringBuilder();

        gauge.render(sb);
        assertEquals("foo.doubleField=10.8", sb.toString());
    }

    @Test
    public void render_whenLongField() {
        SomeObject someObject = new SomeObject();
        metricsRegistry.scanAndRegister(someObject, "foo");
        Gauge gauge = metricsRegistry.getGauge("foo.longField");
        StringBuilder sb = new StringBuilder();

        gauge.render(sb);
        assertEquals("foo.longField=10", sb.toString());
    }

    @Test
    public void render_whenException() {
        metricsRegistry.register(this, "foo", new LongProbe() {
            @Override
            public long get(Object o) {
                throw new RuntimeException();
            }
        });
        Gauge gauge = metricsRegistry.getGauge("foo");
        StringBuilder sb = new StringBuilder();

        gauge.render(sb);

        assertEquals("foo=NA", sb.toString());
    }
}

<code block>
package com.hazelcast.internal.metrics.impl;

import com.hazelcast.internal.metrics.Gauge;
import com.hazelcast.internal.metrics.Probe;
import com.hazelcast.internal.metrics.Metric;
import com.hazelcast.logging.Logger;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.io.OutputStream;
import java.util.LinkedList;
import java.util.Set;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class RegisterMetricTest extends HazelcastTestSupport {

    private MetricsRegistryImpl metricsRegistry;

    @Before
    public void setup() {
        metricsRegistry = new MetricsRegistryImpl(Logger.getLogger(MetricsRegistryImpl.class));
    }

    @Test(expected = NullPointerException.class)
    public void whenNamePrefixNull() {
        metricsRegistry.scanAndRegister(new SomeField(), null);
    }

    @Test(expected = NullPointerException.class)
    public void whenObjectNull() {
        metricsRegistry.scanAndRegister(null, "bar");
    }

    @Test(expected = IllegalArgumentException.class)
    public void whenUnrecognizedField() {
        metricsRegistry.scanAndRegister(new SomeUnrecognizedField(), "bar");
    }

    @Test
    public void whenNoGauges_thenIgnore() {
        metricsRegistry.scanAndRegister(new LinkedList(), "bar");

        for (String name : metricsRegistry.getNames()) {
            assertFalse(name.startsWith("bar"));
        }
    }

    public class SomeField {
        @Probe
        long field;
    }

    public class SomeUnrecognizedField {
        @Probe
        OutputStream field;
    }

    @Test
    public void deregister_whenNotRegistered() {
        MultiFieldAndMethod multiFieldAndMethod = new MultiFieldAndMethod();
        multiFieldAndMethod.field1 = 1;
        multiFieldAndMethod.field2 = 2;
        metricsRegistry.deregister(multiFieldAndMethod);

        
        Set<String> names = metricsRegistry.getNames();
        assertFalse(names.contains("foo.field1"));
        assertFalse(names.contains("foo.field2"));
        assertFalse(names.contains("foo.method1"));
        assertFalse(names.contains("foo.method2"));
 }

    public class MultiFieldAndMethod {
        @Probe
        long field1;
        @Probe
        long field2;

        @Probe
        int method1() {
            return 1;
        }

        @Probe
        int method2() {
            return 2;
        }
    }

    @Test
    public void deregister_whenRegistered() {
        MultiFieldAndMethod multiFieldAndMethod = new MultiFieldAndMethod();
        multiFieldAndMethod.field1 = 1;
        multiFieldAndMethod.field2 = 2;
        metricsRegistry.scanAndRegister(multiFieldAndMethod, "foo");

        Gauge field1 = metricsRegistry.getGauge("foo.field1");
        Gauge field2 = metricsRegistry.getGauge("foo.field2");
        Gauge method1 = metricsRegistry.getGauge("foo.method1");
        Gauge method2 = metricsRegistry.getGauge("foo.method2");

        metricsRegistry.deregister(multiFieldAndMethod);

        
        Set<String> names = metricsRegistry.getNames();
        assertFalse(names.contains("foo.field1"));
        assertFalse(names.contains("foo.field2"));
        assertFalse(names.contains("foo.method1"));
        assertFalse(names.contains("foo.method2"));

        
        assertEquals(0, field1.readLong());
        assertEquals(0, field2.readLong());
        assertEquals(0, method1.readLong());
        assertEquals(0, method2.readLong());
    }

    @Test
    public void deregister_whenAlreadyDeregistered() {
        MultiFieldAndMethod multiFieldAndMethod = new MultiFieldAndMethod();
        multiFieldAndMethod.field1 = 1;
        multiFieldAndMethod.field2 = 2;
        metricsRegistry.scanAndRegister(multiFieldAndMethod, "foo");
        metricsRegistry.deregister(multiFieldAndMethod);
        metricsRegistry.deregister(multiFieldAndMethod);

        
        Set<String> names = metricsRegistry.getNames();
        assertFalse(names.contains("foo.field1"));
        assertFalse(names.contains("foo.field2"));
        assertFalse(names.contains("foo.method1"));
        assertFalse(names.contains("foo.method2"));
    }
}

<code block>


package com.hazelcast.test;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.config.Config;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.Member;
import com.hazelcast.core.Partition;
import com.hazelcast.core.PartitionService;
import com.hazelcast.instance.HazelcastInstanceFactory;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.TestUtil;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.impl.InternalPartitionServiceState;
import com.hazelcast.replicatedmap.impl.record.VectorClockTimestamp;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import org.junit.After;
import org.junit.Assert;
import org.junit.ComparisonFailure;

import java.lang.reflect.Constructor;
import java.lang.reflect.Modifier;
import java.util.Collection;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.Set;
import java.util.UUID;
import java.util.concurrent.Callable;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.Future;
import java.util.concurrent.FutureTask;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

import static com.hazelcast.test.TestPartitionUtils.getInternalPartitionServiceState;
import static java.lang.String.format;
import static java.util.Arrays.asList;
import static java.util.concurrent.TimeUnit.MILLISECONDS;
import static java.util.concurrent.TimeUnit.NANOSECONDS;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

public abstract class HazelcastTestSupport {

    public static final int ASSERT_TRUE_EVENTUALLY_TIMEOUT;

    static {
        System.setProperty("hazelcast.repmap.hooks.allowed", "true");

        ASSERT_TRUE_EVENTUALLY_TIMEOUT = Integer.getInteger("hazelcast.assertTrueEventually.timeout", 120);
        System.out.println("ASSERT_TRUE_EVENTUALLY_TIMEOUT = " + ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    private TestHazelcastInstanceFactory factory;


    public static void assertUtilityConstructor(Class clazz) {
        Constructor[] constructors = clazz.getDeclaredConstructors();
        assertEquals("there are more than 1 constructors", 1, constructors.length);

        Constructor constructor = constructors[0];
        int modifiers = constructor.getModifiers();
        assertTrue("access modifier is not private", Modifier.isPrivate(modifiers));

        constructor.setAccessible(true);
        try {
            constructor.newInstance();
        } catch (Exception e) {
        }
    }

    public static void assertHappensBefore(VectorClockTimestamp clock1, VectorClockTimestamp clock2) {
        assertTrue(VectorClockTimestamp.happenedBefore(clock1, clock2));
    }

    public static void assertNotHappensBefore(VectorClockTimestamp clock1, VectorClockTimestamp clock2) {
        assertFalse(VectorClockTimestamp.happenedBefore(clock1, clock2));
    }

    public HazelcastInstance createHazelcastInstance() {
        return createHazelcastInstance(new Config());
    }

    public HazelcastInstance createHazelcastInstance(Config config) {
        return createHazelcastInstanceFactory(1).newHazelcastInstance(config);
    }

    public static int getPartitionId(HazelcastInstance hz, String name){
        PartitionService partitionService = hz.getPartitionService();
        Partition partition = partitionService.getPartition(name);
        return partition.getPartitionId();
    }

    protected final TestHazelcastInstanceFactory createHazelcastInstanceFactory(int nodeCount) {
        if (factory != null) {
            throw new IllegalStateException("Node factory is already created!");
        }
        return factory = new TestHazelcastInstanceFactory(nodeCount);
    }

    protected final TestHazelcastInstanceFactory createHazelcastInstanceFactory(String... addresses) {
        if (factory != null) {
            throw new IllegalStateException("Node factory is already created!");
        }
        return factory = new TestHazelcastInstanceFactory(addresses);
    }

    protected final TestHazelcastInstanceFactory createHazelcastInstanceFactory() {
        if (factory != null) {
            throw new IllegalStateException("Node factory is already created!");
        }
        return factory = new TestHazelcastInstanceFactory();
    }

    public static Future spawn(Runnable task) {
        FutureTask<Runnable> futureTask = new FutureTask<Runnable>(task, null);
        new Thread(futureTask).start();
        return futureTask;
    }

    public static <E> Future<E> spawn(Callable<E> task) {
        FutureTask<E> futureTask = new FutureTask<E>(task);
        new Thread(futureTask).start();
        return futureTask;
    }

    public static Address getAddress(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.clusterService.getThisAddress();
    }

    public static Packet toPacket(HazelcastInstance hz, Operation operation){
        SerializationService serializationService = getSerializationService(hz);
        ConnectionManager connectionManager = getConnectionManager(hz);

        Data data = serializationService.toData(operation);
        Packet packet = new Packet(data, operation.getPartitionId());
        packet.setHeader(Packet.HEADER_OP);
        packet.setConn(connectionManager.getConnection(getAddress(hz)));
        return packet;
    }

    public static ConnectionManager getConnectionManager(HazelcastInstance hz){
        Node node = getNode(hz);
        return node.connectionManager;
    }

    public static ClusterService getClusterService(HazelcastInstance hz){
        Node node = getNode(hz);
        return node.clusterService;
    }

    public static SerializationService getSerializationService(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.getSerializationService();
    }

    public static InternalOperationService getOperationService(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.nodeEngine.getOperationService();
    }

    public static InternalPartitionService getPartitionService(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.partitionService;
    }

    public static NodeEngineImpl getNodeEngineImpl(HazelcastInstance hz) {
        Node node = getNode(hz);
        return node.nodeEngine;
    }

    @After
    public final void shutdownNodeFactory() {
        TestHazelcastInstanceFactory testHazelcastInstanceFactory = factory;
        if (testHazelcastInstanceFactory != null) {
            factory = null;
            testHazelcastInstanceFactory.terminateAll();
        }
    }

    public static void setLoggingNone() {
        System.setProperty("hazelcast.logging.type", "none");
    }

    public static void setLoggingLog4j() {
        System.setProperty("hazelcast.logging.type", "log4j");
    }

    public static void setLogLevel(org.apache.log4j.Level level) {
        if (isLog4jLoaded()) {
            org.apache.log4j.Logger.getRootLogger().setLevel(level);
        }
    }

    private static boolean isLog4jLoaded() {
        setLoggingLog4j();
        try {
            Class.forName("org.apache.log4j.Logger");
            Class.forName("org.apache.log4j.Level");
            return true;
        } catch (Throwable ignored) {
            return false;
        }
    }

    public static void sleepMillis(int millis) {
        try {
            MILLISECONDS.sleep(millis);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }

    public static void sleepSeconds(int seconds) {
        try {
            TimeUnit.SECONDS.sleep(seconds);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }

    
    public static void sleepAndStop(AtomicBoolean stop, long durationSeconds) {
        for (int k = 0; k < durationSeconds; k++) {
            if (stop.get()) {
                return;
            }
            sleepSeconds(1);
        }
        stop.set(true);
    }

    public static void sleepAtLeastMillis(long sleepFor) {
       boolean interrupted = false;
       try {
           long remainingNanos = MILLISECONDS.toNanos(sleepFor);
           final long sleepUntil = System.nanoTime() + remainingNanos;
           while (remainingNanos > 0) {
               try {
                   NANOSECONDS.sleep(remainingNanos);
               } catch (InterruptedException e) {
                   interrupted = true;
               } finally {
                   remainingNanos = sleepUntil - System.nanoTime();
               }
           }
       } finally {
           if (interrupted) {
               Thread.currentThread().interrupt();
           }
       }
    }

    public static void sleepAtLeastSeconds(long seconds) {
        sleepAtLeastMillis(seconds * 1000);
    }

    public static String generateRandomString(int length) {
        StringBuilder sb = new StringBuilder(length);
        Random random = new Random();
        for (int i = 0; i < length; i++) {
            char character = (char) (random.nextInt(26) + 'a');
            sb.append(character);
        }
        return sb.toString();
    }

    public static String randomString() {
        return UUID.randomUUID().toString();
    }

    public static String randomMapName() {
        return randomString();
    }

    public static String randomMapName(String namePrefix) {
        return namePrefix + randomString();
    }

    public static String randomName() {
        return randomString();
    }

    public static String randomNameOwnedBy(HazelcastInstance hz) {
        return randomNameOwnedBy(hz, "");
    }

    public static String randomNameOwnedBy(HazelcastInstance instance, String prefix) {
        Member localMember = instance.getCluster().getLocalMember();
        PartitionService partitionService = instance.getPartitionService();
        while (true) {
            String id = prefix + randomString();
            Partition partition = partitionService.getPartition(id);
            if (comparePartitionOwnership(true, localMember, partition)) {
                return id;
            }
        }
    }

    public static Partition randomPartitionOwnedBy(HazelcastInstance hz) {
        List<Partition> partitions = new LinkedList<Partition>();
        for (Partition partition : hz.getPartitionService().getPartitions()) {
            if (partition.getOwner().localMember()) {
                partitions.add(partition);
            }
        }
        if (partitions.isEmpty()) {
            throw new IllegalStateException("No partitions found for HazelcastInstance:" + hz.getName());
        }
        return partitions.get((int) (Math.random() * partitions.size()));
    }

    public static void printAllStackTraces() {
        Map liveThreads = Thread.getAllStackTraces();
        for (Object object : liveThreads.keySet()) {
            Thread key = (Thread) object;
            System.err.println("Thread " + key.getName());
            StackTraceElement[] trace = (StackTraceElement[]) liveThreads.get(key);
            for (StackTraceElement aTrace : trace) {
                System.err.println("\tat " + aTrace);
            }
        }
    }

    public static void interruptCurrentThread(final int delayMillis) {
        final Thread currentThread = Thread.currentThread();
        new Thread(new Runnable() {
            public void run() {
                sleepMillis(delayMillis);
                currentThread.interrupt();
            }
        }).start();
    }

    public static void consume(Object o) {
    }

    public static Node getNode(HazelcastInstance hz) {
        return TestUtil.getNode(hz);
    }

    public static void warmUpPartitions(HazelcastInstance... instances) {
        try {
            TestUtil.warmUpPartitions(instances);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

    public static void warmUpPartitions(Collection<HazelcastInstance> instances) {
        try {
            TestUtil.warmUpPartitions(instances);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

    
    public static int getPartitionId(HazelcastInstance hz) {
        warmUpPartitions(hz);

        InternalPartitionService partitionService = getPartitionService(hz);
        for (InternalPartition p : partitionService.getPartitions()) {
            if (p.isLocal()) {
                return p.getPartitionId();
            }
        }
        throw new RuntimeException("No local partitions are found for hz: " + hz.getName());
    }

    public static String generateKeyOwnedBy(HazelcastInstance instance) {
        return generateKeyOwnedBy(instance, true);
    }

    public static String generateKeyNotOwnedBy(HazelcastInstance instance) {
        return generateKeyOwnedBy(instance, false);
    }

    
    protected static String generateKeyOwnedBy(HazelcastInstance instance, boolean generateOwnedKey) {
        Cluster cluster = instance.getCluster();
        checkMemberCount(generateOwnedKey, cluster);
        checkPartitionCountGreaterOrEqualMemberCount(instance);

        Member localMember = cluster.getLocalMember();
        PartitionService partitionService = instance.getPartitionService();
        while (true) {
            String id = randomString();
            Partition partition = partitionService.getPartition(id);
            if (comparePartitionOwnership(generateOwnedKey, localMember, partition)) {
                return id;
            }
        }
    }

    private static void checkPartitionCountGreaterOrEqualMemberCount(HazelcastInstance instance) {
        Cluster cluster = instance.getCluster();
        int memberCount = cluster.getMembers().size();

        InternalPartitionService internalPartitionService = getPartitionService(instance);
        int partitionCount = internalPartitionService.getPartitionCount();

        if (partitionCount < memberCount) {
            throw new UnsupportedOperationException("Partition count should be equal or greater than member count!");
        }
    }

    private static void checkMemberCount(boolean generateOwnedKey, Cluster cluster) {
        if (generateOwnedKey) {
            return;
        }
        final Set<Member> members = cluster.getMembers();
        if (members.size() < 2) {
            throw new UnsupportedOperationException("Cluster has only one member, you can not generate a `not owned key`");
        }
    }

    private static boolean comparePartitionOwnership(boolean ownedBy, Member member, Partition partition) {
        final Member owner = partition.getOwner();
        if (ownedBy) {
            return member.equals(owner);
        } else {
            return !member.equals(owner);
        }
    }

    public static boolean isInstanceInSafeState(final HazelcastInstance instance) {
        final Node node = TestUtil.getNode(instance);
        if (node == null) {
            return true;
        }
        final InternalPartitionService ps = node.getPartitionService();
        return ps.isMemberStateSafe();
    }

    public static void waitInstanceForSafeState(final HazelcastInstance instance) {
        assertTrueEventually(new AssertTask() {
            public void run() {
                isInstanceInSafeState(instance);
            }
        });
    }

    public static boolean isClusterInSafeState(final HazelcastInstance instance) {
        final PartitionService ps = instance.getPartitionService();
        return ps.isClusterSafe();
    }

    public static void waitClusterForSafeState(final HazelcastInstance instance) {
        assertTrueEventually(new AssertTask() {
            public void run() {
                assertTrue(isClusterInSafeState(instance));
            }
        });
    }

    public static boolean isAllInSafeState() {
        final Set<HazelcastInstance> nodeSet = HazelcastInstanceFactory.getAllHazelcastInstances();
        return isAllInSafeState(nodeSet);
    }

    public static boolean isAllInSafeState(Collection<HazelcastInstance> nodes) {
        for (HazelcastInstance node : nodes) {
            if (!isInstanceInSafeState(node)) {
                return false;
            }
        }
        return true;
    }

    public static void waitAllForSafeState() {
       waitAllForSafeState(HazelcastInstanceFactory.getAllHazelcastInstances());
    }

    public static void waitAllForSafeState(final Collection<HazelcastInstance> instances) {
        waitAllForSafeState(instances, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void waitAllForSafeState(final Collection<HazelcastInstance> instances, int timeoutInSeconds) {
        assertTrueEventually(new AssertTask() {
            public void run() {
                final Map<Address, InternalPartitionServiceState> states = new HashMap<Address, InternalPartitionServiceState>();
                for (HazelcastInstance instance : instances) {
                    final InternalPartitionServiceState state = getInternalPartitionServiceState(instance);
                    if (state != InternalPartitionServiceState.SAFE) {
                        states.put(getNode(instance).getThisAddress(), state);
                    }
                }

                assertTrue("Instances not in safe state! " + states, states.isEmpty());
            }
        }, timeoutInSeconds);
    }

    public static void waitAllForSafeState(final HazelcastInstance... nodes) {
        waitAllForSafeState(asList(nodes));
    }

    public static void assertStartsWith(String expected, String actual) {
        if (actual != null && actual.startsWith(expected)) {
            return;
        }
        if (expected != null && actual != null) {
            throw new ComparisonFailure("", expected, actual);
        }
        fail(formatAssertMessage("", expected, null));
    }

    private static String formatAssertMessage(String message, Object expected, Object actual) {
        StringBuilder assertMessage = new StringBuilder();
        if (message != null && !message.isEmpty()) {
            assertMessage.append(message).append(" ");
        }
        String expectedString = String.valueOf(expected);
        String actualString = String.valueOf(actual);
        if (expectedString.equals(actualString)) {
            assertMessage.append("expected: ");
            formatClassAndValue(assertMessage, expected, expectedString);
            assertMessage.append(" but was: ");
            formatClassAndValue(assertMessage, actual, actualString);
        } else {
            assertMessage.append("expected: <").append(expectedString).append("> but was: <").append(actualString).append(">");
        }
        return assertMessage.toString();
    }

    private static void formatClassAndValue(StringBuilder message, Object value, String valueString) {
        message.append((value == null) ? "null" : value.getClass().getName()).append("<").append(valueString).append(">");
    }

    public static <E> E assertInstanceOf(Class<E> clazz, Object o) {
        Assert.assertNotNull(o);
        assertTrue(o + " is not an instanceof " + clazz.getName(), clazz.isAssignableFrom(o.getClass()));
        return (E)o;
    }

    public static void assertJoinable(Thread... threads) {
        assertJoinable(ASSERT_TRUE_EVENTUALLY_TIMEOUT, threads);
    }

    public static void assertIterableEquals(Iterable iterable, Object... values) {
        int counter = 0;
        for (Object object : iterable) {
            if (values.length < counter + 1) {
                throw new AssertionError("Iterator and values sizes are not equal");
            }
            assertEquals(values[counter], object);
            counter++;
        }

        assertEquals("Iterator and values sizes are not equal", values.length, counter);
    }

    public static void assertCompletesEventually(final Future future) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertTrue("Future has not completed", future.isDone());
            }
        });
    }

    public static void assertSizeEventually(int expectedSize, Collection c) {
        assertSizeEventually(expectedSize, c, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertSizeEventually(final int expectedSize, final Collection c, long timeoutSeconds) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() {
                assertEquals("the size of the collection is not correct: found-content:" + c, expectedSize, c.size());
            }
        }, timeoutSeconds);
    }

    public static void assertSizeEventually(int expectedSize, Map<?, ?> m) {
        assertSizeEventually(expectedSize, m, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertSizeEventually(final int expectedSize, final Map<?, ?> m, long timeoutSeconds) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() {
                assertEquals("the size of the map is not correct", expectedSize, m.size());
            }
        }, timeoutSeconds);
    }

    public static <E> void assertEqualsEventually(final FutureTask<E> task, final E value) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertTrue("FutureTask is not complete", task.isDone());
                assertEquals(value, task.get());
            }
        });
    }

    public static <E> void assertEqualsEventually(final Callable<E> task, final E value) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(value, task.call());
            }
        });
    }

    public static void assertClusterSize(int expectedSize, HazelcastInstance instance) {
        assertEquals("Cluster size is not correct", expectedSize, instance.getCluster().getMembers().size());
    }

    public static void assertClusterSizeEventually(int expectedSize, HazelcastInstance instance) {
        assertClusterSizeEventually(expectedSize, instance, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertClusterSizeEventually(final int expectedSize, final HazelcastInstance instance, long timeoutSeconds) {
        assertTrueEventually(new AssertTask() {
            @Override
            public void run()
                    throws Exception {
                assertEquals("the size of the cluster is not correct", expectedSize, instance.getCluster().getMembers().size());
            }
        }, timeoutSeconds);
    }

    public static void assertJoinable(long timeoutSeconds, Thread... threads) {
        try {
            long remainingTimeout = TimeUnit.SECONDS.toNanos(timeoutSeconds);
            for (Thread thread : threads) {
                long start = System.nanoTime();
                thread.join(remainingTimeout);

                if (thread.isAlive()) {
                    fail("Timeout waiting for thread " + thread.getName() + " to terminate");
                }

                long duration = System.nanoTime() - start;
                remainingTimeout -= duration;
                if (remainingTimeout <= 0) {
                    fail("Timeout waiting for thread " + thread.getName() + " to terminate");
                }
            }
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

    public static void assertOpenEventually(CountDownLatch latch) {
        assertOpenEventually(latch, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertOpenEventually(String message, CountDownLatch latch) {
        assertOpenEventually(message, latch, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertOpenEventually(CountDownLatch latch, long timeoutSeconds) {
        assertOpenEventually(null, latch, timeoutSeconds);
    }

    public static void assertOpenEventually(String message, CountDownLatch latch, long timeoutSeconds) {
        try {
            boolean completed = latch.await(timeoutSeconds, TimeUnit.SECONDS);
            if (message == null) {
                assertTrue(format("CountDownLatch failed to complete within %d seconds , count left: %d", timeoutSeconds,
                        latch.getCount()), completed);
            } else {
                assertTrue(format("%s, failed to complete within %d seconds , count left: %d", message, timeoutSeconds,
                        latch.getCount()), completed);
            }
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

    public static void assertTrueFiveSeconds(AssertTask task) {
        assertTrueAllTheTime(task, 5);
    }

    public static void assertTrueAllTheTime(AssertTask task, long durationSeconds) {
        for (int k = 0; k < durationSeconds; k++) {
            try {
                task.run();
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
            sleepSeconds(1);
        }
    }

    public static void assertTrueEventually(AssertTask task, long timeoutSeconds) {
        AssertionError error = null;
        
        long iterations = timeoutSeconds * 5;
        int sleepMillis = 200;
        for (int k = 0; k < iterations; k++) {
            try {
                try {
                    task.run();
                } catch (Exception e) {
                    throw new RuntimeException(e);
                }
                return;
            } catch (AssertionError e) {
                error = e;
            }
            sleepMillis(sleepMillis);
        }
        throw error;
    }

    public static void assertTrueEventually(AssertTask task) {
        assertTrueEventually(task, ASSERT_TRUE_EVENTUALLY_TIMEOUT);
    }

    public static void assertTrueDelayed5sec(AssertTask task) {
        assertTrueDelayed(5, task);
    }

    public static void assertTrueDelayed(int delaySeconds, AssertTask task) {
        sleepSeconds(delaySeconds);
        try {
            task.run();
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

    
    public static void assertEqualsStringFormat(String message, Object expected, Object actual) {
        assertEquals(String.format(message, expected, actual), expected, actual);
    }

    public static void closeConnectionBetween(HazelcastInstance h1, HazelcastInstance h2) {
        if (h1 == null || h2 == null) return;
        final Node n1 = TestUtil.getNode(h1);
        final Node n2 = TestUtil.getNode(h2);
        n1.clusterService.removeAddress(n2.address);
        n2.clusterService.removeAddress(n1.address);
    }
    public final class DummyUncheckedHazelcastTestException extends RuntimeException {
    }

    public static void assertExactlyOneSuccessfulRun(AssertTask task) {
        assertExactlyOneSuccessfulRun(task, ASSERT_TRUE_EVENTUALLY_TIMEOUT, TimeUnit.SECONDS);
    }

    public static void assertExactlyOneSuccessfulRun(AssertTask task, int giveUpTime, TimeUnit timeUnit) {
        long timeout = System.currentTimeMillis() + timeUnit.toMillis(giveUpTime);
        RuntimeException lastException = new RuntimeException("Did not try even once");
        while (System.currentTimeMillis() < timeout) {
            try {
                task.run();
                return;
            } catch (Exception e) {
                lastException = e instanceof RuntimeException ? (RuntimeException) e : new RuntimeException(e);
            }
            try {
                Thread.sleep(250);
            } catch (InterruptedException e) {
                lastException = new RuntimeException(e);
            }
        }
        throw lastException;
    }
}

<code block>


package com.hazelcast.test;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.AbstractJoiner;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.AddressPicker;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.NodeContext;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.IOService;
import com.hazelcast.nio.NodeIOService;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.executor.StripedRunnable;

import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.nio.channels.ServerSocketChannel;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.CopyOnWriteArraySet;

public final class TestNodeRegistry {

    private final ConcurrentMap<Address, NodeEngineImpl> nodes = new ConcurrentHashMap<Address, NodeEngineImpl>(10);
    private final Object joinerLock = new Object();
    private final CopyOnWriteArrayList<Address> joinAddresses;

    TestNodeRegistry(CopyOnWriteArrayList<Address> addresses) {
        this.joinAddresses = addresses;
    }

    public NodeContext createNodeContext(Address address) {
        return new MockNodeContext(joinAddresses, nodes, address, joinerLock);
    }

    public HazelcastInstance getInstance(Address address) {
        NodeEngineImpl nodeEngine = nodes.get(address);
        return nodeEngine != null && nodeEngine.isActive() ? nodeEngine.getHazelcastInstance() : null;
    }

    Collection<HazelcastInstance> getAllHazelcastInstances() {
        Collection<HazelcastInstance> all = new LinkedList<HazelcastInstance>();
        for (NodeEngineImpl nodeEngine : nodes.values()) {
            if (nodeEngine.isActive()) {
                all.add(nodeEngine.getHazelcastInstance());
            }
        }
        return all;
    }

    void shutdown() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            value.getHazelcastInstance().shutdown();
        }
    }

    void terminate() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            HazelcastInstance hz = value.getHazelcastInstance();
            hz.getLifecycleService().terminate();
        }
    }

    private static class MockNodeContext implements NodeContext {

        final CopyOnWriteArrayList<Address> joinAddresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Address thisAddress;
        final Object joinerLock;

        public MockNodeContext(CopyOnWriteArrayList<Address> addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Address thisAddress, Object joinerLock) {
            this.joinAddresses = addresses;
            this.nodes = nodes;
            this.thisAddress = thisAddress;
            this.joinerLock = joinerLock;
        }

        public AddressPicker createAddressPicker(Node node) {
            return new StaticAddressPicker(thisAddress);
        }

        public Joiner createJoiner(Node node) {
            return new MockJoiner(node, joinAddresses, nodes, joinerLock);
        }

        public ConnectionManager createConnectionManager(Node node, ServerSocketChannel serverSocketChannel) {
            NodeIOService ioService = new NodeIOService(node, node.nodeEngine);
            return new MockConnectionManager(ioService, nodes, node, joinerLock);
        }
    }

    private static class StaticAddressPicker implements AddressPicker {
        final Address thisAddress;

        private StaticAddressPicker(Address thisAddress) {
            this.thisAddress = thisAddress;
        }

        public void pickAddress() throws Exception {
        }

        public Address getBindAddress() {
            return thisAddress;
        }

        public Address getPublicAddress() {
            return thisAddress;
        }

        public ServerSocketChannel getServerSocketChannel() {
            return null;
        }
    }

    private static class MockJoiner extends AbstractJoiner {

        final CopyOnWriteArrayList<Address> joinAddresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Object joinerLock;

        MockJoiner(Node node, CopyOnWriteArrayList<Address> addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Object joinerLock) {
            super(node);
            this.joinAddresses = addresses;
            this.nodes = nodes;
            this.joinerLock = joinerLock;
        }

        public void doJoin() {
            NodeEngineImpl nodeEngine = null;
            synchronized (joinerLock) {
                for (Address address : joinAddresses) {
                    NodeEngineImpl ne = nodes.get(address);
                    if (ne != null && ne.getNode().isActive() && ne.getNode().joined()) {
                        nodeEngine = ne;
                        break;
                    }
                }
                Address master = null;
                if (nodeEngine != null) {
                    if (nodeEngine.getNode().isMaster()) {
                        master = nodeEngine.getThisAddress();
                    } else {
                        master = nodeEngine.getMasterAddress();
                    }
                }
                if (master == null) {
                    master = node.getThisAddress();
                }
                node.setMasterAddress(master);
                if (node.getMasterAddress().equals(node.getThisAddress())) {
                    node.setJoined();
                    node.setAsMaster();
                } else {
                    for (int i = 0; !node.joined() && i < 2000; i++) {
                        try {
                            node.clusterService.sendJoinRequest(node.getMasterAddress(), true);
                            Thread.sleep(50);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    if (!node.joined()) {
                        throw new AssertionError("Node[" + node.getThisAddress()
                                + "] should have been joined to " + node.getMasterAddress());
                    }
                }
            }
        }

        public void searchForOtherClusters() {
        }

        @Override
        public String getType() {
            return "mock";
        }

        public String toString() {
            return "MockJoiner";
        }

        @Override
        public void blacklist(Address address, boolean permanent) {
        }

        @Override
        public boolean unblacklist(Address address) {
            return false;
        }

        @Override
        public boolean isBlacklisted(Address address) {
            return false;
        }
    }

    private static class MockConnectionManager implements ConnectionManager {
        private final Set<ConnectionListener> connectionListeners = new CopyOnWriteArraySet<ConnectionListener>();
        private final IOService ioService;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Map<Address, MockConnection> mapConnections = new ConcurrentHashMap<Address, MockConnection>(10);
        final Node node;
        final Object joinerLock;

        MockConnectionManager(IOService ioService, ConcurrentMap<Address, NodeEngineImpl> nodes,
                              Node node, Object joinerLock) {
            this.ioService = ioService;
            this.nodes = nodes;
            this.node = node;
            this.joinerLock = joinerLock;
            synchronized (this.joinerLock) {
                this.nodes.put(node.getThisAddress(), node.nodeEngine);
            }
        }

        @Override
        public void dumpPerformanceMetrics(StringBuffer sb) {
        }

        public Connection getConnection(Address address) {
            MockConnection conn = mapConnections.get(address);
            if (conn == null) {
                NodeEngineImpl nodeEngine = nodes.get(address);
                MockConnection thisConnection = new MockConnection(address, node.getThisAddress(), node.nodeEngine);
                conn = new MockConnection(node.getThisAddress(), address, nodeEngine);
                conn.localConnection = thisConnection;
                thisConnection.localConnection = conn;
                mapConnections.put(address, conn);
            }
            return conn;
        }

        public Connection getOrConnect(Address address) {
            return getConnection(address);
        }

        public Connection getOrConnect(Address address, boolean silent) {
            return getConnection(address);
        }

        public void shutdown() {
            for (Address address : nodes.keySet()) {
                if (address.equals(node.getThisAddress())) continue;

                final NodeEngineImpl nodeEngine = nodes.get(address);
                if (nodeEngine != null && nodeEngine.isActive()) {
                    nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                        public void run() {
                            final ClusterServiceImpl clusterService = (ClusterServiceImpl) nodeEngine.getClusterService();
                            clusterService.removeAddress(node.getThisAddress());
                        }
                    });
                }
            }
        }

        @Override
        public boolean registerConnection(final Address remoteEndpoint, final Connection connection) {
            mapConnections.put(remoteEndpoint, (MockConnection) connection);
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionAdded(connection);
                    }
                }

                @Override
                public int getKey() {
                    return remoteEndpoint.hashCode();
                }
            });
            return true;
        }

        public void start() {
        }

        public void addConnectionListener(ConnectionListener connectionListener) {
            connectionListeners.add(connectionListener);
        }

        public void destroyConnection(final Connection connection) {
            final Address endPoint = connection.getEndPoint();
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionRemoved(connection);
                    }
                }

                @Override
                public int getKey() {
                    return endPoint.hashCode();
                }
            });
        }


        public void restart() {
        }

        @Override
        public int getActiveConnectionCount() {
            return 0;
        }

        public int getCurrentClientConnections() {
            return 0;
        }

        @Override
        public int getConnectionCount() {
            return 0;
        }

        public int getAllTextConnections() {
            return 0;
        }
    }

    public static class MockConnection implements Connection {
        protected final Address localEndpoint;
        volatile Connection localConnection;
        final Address remoteEndpoint;
        protected final NodeEngineImpl nodeEngine;
        private volatile boolean live = true;

        public MockConnection(Address localEndpoint, Address remoteEndpoint, NodeEngineImpl nodeEngine) {
            this.localEndpoint = localEndpoint;
            this.remoteEndpoint = remoteEndpoint;
            this.nodeEngine = nodeEngine;
        }

        public Address getEndPoint() {
            return remoteEndpoint;
        }

        public boolean live() {
            return live;
        }

        public boolean write(SocketWritable socketWritable) {
            final Packet packet = (Packet) socketWritable;
            if (nodeEngine.getNode().isActive()) {
                Packet newPacket = readFromPacket(packet);
                MemberImpl member = nodeEngine.getClusterService().getMember(localEndpoint);
                if (member != null) {
                    member.didRead();
                }
                nodeEngine.getPacketTransceiver().receive(newPacket);
                return true;
            }
            return false;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }

            newPacket.setConn(localConnection);
            return newPacket;
        }

        public long lastReadTime() {
            return System.currentTimeMillis();
        }

        public long lastWriteTime() {
            return System.currentTimeMillis();
        }

        public void close() {
            if (!live) {
                return;
            }
            live = false;
            nodeEngine.getNode().connectionManager.destroyConnection(this);
        }

        public boolean isClient() {
            return false;
        }

        @Override
        public ConnectionType getType() {
            return ConnectionType.MEMBER;
        }

        public InetAddress getInetAddress() {
            try {
                return localEndpoint.getInetAddress();
            } catch (UnknownHostException e) {
                throw ExceptionUtil.rethrow(e);
            }
        }

        public InetSocketAddress getRemoteSocketAddress() {
            return new InetSocketAddress(getInetAddress(), getPort());
        }

        public int getPort() {
            return localEndpoint.getPort();
        }

        @Override
        public boolean isAlive() {
            return true;
        }

        @Override
        public String toString() {
            return "MockConnection{" +
                    "localEndpoint=" + localEndpoint +
                    ", remoteEndpoint=" + remoteEndpoint +
                    '}';
        }
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationCycleOperation;
import com.hazelcast.partition.ReplicaErrorLogger;
import com.hazelcast.spi.MigrationAwareService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PartitionAwareOperation;
import com.hazelcast.spi.PartitionReplicationEvent;
import com.hazelcast.spi.impl.servicemanager.ServiceInfo;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;
import java.util.Arrays;
import java.util.Collection;
import java.util.LinkedList;
import java.util.List;

public final class ReplicaSyncRequest extends Operation implements PartitionAwareOperation, MigrationCycleOperation {

    public ReplicaSyncRequest() {
    }

    public ReplicaSyncRequest(int partitionId, int replicaIndex) {
        setPartitionId(partitionId);
        setReplicaIndex(replicaIndex);
    }

    @Override
    public void beforeRun() throws Exception {
        int syncReplicaIndex = getReplicaIndex();
        if (syncReplicaIndex < 1 || syncReplicaIndex > InternalPartition.MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("Replica index should be in range [1-"
                    + InternalPartition.MAX_BACKUP_COUNT + "]");
        }
    }

    @Override
    public void run() throws Exception {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        InternalPartitionServiceImpl partitionService = (InternalPartitionServiceImpl) nodeEngine.getPartitionService();
        int partitionId = getPartitionId();
        int replicaIndex = getReplicaIndex();

        if (!partitionService.isMigrationActive()) {
            ILogger logger = getLogger();
            if (logger.isFinestEnabled()) {
                logger.finest("Migration is paused! Cannot run replica sync -> " + toString());
            }
            sendRetryResponse();
            return;
        }

        if (!preCheckReplicaSync(nodeEngine, partitionId, replicaIndex)) {
            return;
        }

        try {
            List<Operation> tasks = createReplicationOperations();
            if (tasks.isEmpty()) {
                logNoReplicaDataFound(partitionId, replicaIndex);
                sendEmptyResponse();
            } else {
                sendResponse(tasks);
            }
        } finally {
            partitionService.releaseReplicaSyncPermit();
        }
    }

    private boolean preCheckReplicaSync(NodeEngineImpl nodeEngine, int partitionId, int replicaIndex) throws IOException {
        InternalPartitionServiceImpl partitionService = (InternalPartitionServiceImpl) nodeEngine.getPartitionService();
        InternalPartitionImpl partition = partitionService.getPartition(partitionId);
        Address owner = partition.getOwnerOrNull();
        long[] replicaVersions = partitionService.getPartitionReplicaVersions(partitionId);
        long currentVersion = replicaVersions[replicaIndex - 1];

        ILogger logger = getLogger();
        if (!nodeEngine.getThisAddress().equals(owner)) {
            if (logger.isFinestEnabled()) {
                logger.finest("Wrong target! " + toString() + " cannot be processed! Target should be: " + owner);
            }
            sendRetryResponse();
            return false;
        }

        if (currentVersion == 0) {
            if (logger.isFinestEnabled()) {
                logger.finest("Current replicaVersion=0, sending empty response for partitionId="
                        + getPartitionId() + ", replicaIndex=" + getReplicaIndex() + ", replicaVersions="
                        + Arrays.toString(replicaVersions));
            }
            sendEmptyResponse();
            return false;
        }

        if (!partitionService.tryToAcquireReplicaSyncPermit()) {
            if (logger.isFinestEnabled()) {
                logger.finest(
                        "Max parallel replication process limit exceeded! Could not run replica sync -> " + toString());
            }
            sendRetryResponse();
            return false;
        }
        return true;
    }

    private void sendRetryResponse() {
        NodeEngine nodeEngine = getNodeEngine();
        int partitionId = getPartitionId();
        int replicaIndex = getReplicaIndex();

        ReplicaSyncRetryResponse response = new ReplicaSyncRetryResponse();
        response.setPartitionId(partitionId).setReplicaIndex(replicaIndex);
        Address target = getCallerAddress();
        OperationService operationService = nodeEngine.getOperationService();
        operationService.send(response, target);
    }

    private List<Operation> createReplicationOperations() {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        Collection<ServiceInfo> services = nodeEngine.getServiceInfos(MigrationAwareService.class);
        PartitionReplicationEvent event = new PartitionReplicationEvent(getPartitionId(), getReplicaIndex());
        List<Operation> tasks = new LinkedList<Operation>();
        for (ServiceInfo serviceInfo : services) {
            MigrationAwareService service = (MigrationAwareService) serviceInfo.getService();
            Operation op = service.prepareReplicationOperation(event);
            if (op != null) {
                op.setServiceName(serviceInfo.getName());
                tasks.add(op);
            }
        }
        return tasks;
    }

    private void sendEmptyResponse() throws IOException {
        sendResponse(null);
    }

    private void sendResponse(List<Operation> data) throws IOException {
        NodeEngine nodeEngine = getNodeEngine();

        ReplicaSyncResponse syncResponse = createResponse(data);
        Address target = getCallerAddress();
        ILogger logger = getLogger();
        if (logger.isFinestEnabled()) {
            logger.finest("Sending sync response to -> " + target + " for partitionId="
                    + getPartitionId() + ", replicaIndex=" + getReplicaIndex());
        }
        OperationService operationService = nodeEngine.getOperationService();
        operationService.send(syncResponse, target);
    }

    private ReplicaSyncResponse createResponse(List<Operation> data) throws IOException {
        int partitionId = getPartitionId();
        NodeEngine nodeEngine = getNodeEngine();
        InternalPartitionService partitionService = nodeEngine.getPartitionService();
        long[] replicaVersions = partitionService.getPartitionReplicaVersions(partitionId);

        ReplicaSyncResponse syncResponse = new ReplicaSyncResponse(data, replicaVersions);
        syncResponse.setPartitionId(partitionId).setReplicaIndex(getReplicaIndex());
        return syncResponse;
    }

    private void logNoReplicaDataFound(int partitionId, int replicaIndex) {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        ILogger logger = nodeEngine.getLogger(getClass());

        if (logger.isFinestEnabled()) {
            logger.finest("No replica data is found for partitionId=" + partitionId + ", replicaIndex=" + replicaIndex);
        }
    }

    @Override
    public void afterRun() throws Exception {
    }

    @Override
    public boolean returnsResponse() {
        return false;
    }

    @Override
    public Object getResponse() {
        return Boolean.TRUE;
    }

    @Override
    public boolean validatesTarget() {
        return false;
    }

    @Override
    public void logError(Throwable e) {
        ReplicaErrorLogger.log(e, getLogger());
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
    }

    @Override
    public String toString() {
        return getClass().getSimpleName() + "{partitionId=" + getPartitionId() + ", replicaIndex=" + getReplicaIndex() + '}';
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberLeftException;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationEndpoint;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.MigrationAwareService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.PartitionMigrationEvent;
import com.hazelcast.spi.PartitionReplicationEvent;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.impl.servicemanager.ServiceInfo;
import com.hazelcast.spi.exception.RetryableHazelcastException;
import com.hazelcast.spi.exception.TargetNotMemberException;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;
import java.util.Collection;
import java.util.LinkedList;
import java.util.concurrent.ExecutionException;
import java.util.logging.Level;

public final class MigrationRequestOperation extends BaseMigrationOperation {

    private static final int TRY_PAUSE_MILLIS = 1000;

    private boolean returnResponse = true;

    public MigrationRequestOperation() {
    }

    public MigrationRequestOperation(MigrationInfo migrationInfo) {
        super(migrationInfo);
    }

    public void run() {
        NodeEngine nodeEngine = getNodeEngine();
        verifyGoodMaster(nodeEngine);

        Address source = migrationInfo.getSource();
        Address destination = migrationInfo.getDestination();
        verifyExistingTarget(nodeEngine, destination);

        if (destination.equals(source)) {
            getLogger().warning("Source and destination addresses are the same! => " + toString());
            success = false;
            return;
        }

        verifyNotThisNode(nodeEngine, source);

        InternalPartitionServiceImpl partitionService = getService();
        InternalPartition partition = partitionService.getPartition(migrationInfo.getPartitionId());
        Address owner = partition.getOwnerOrNull();
        verifyOwnerExists(owner);

        if (!migrationInfo.startProcessing()) {
            getLogger().warning("Migration is cancelled -> " + migrationInfo);
            success = false;
            return;
        }

        try {
            verifyOwner(source, partition, owner);
            partitionService.addActiveMigration(migrationInfo);
            Collection<Operation> tasks = prepareMigrationTasks();
            if (tasks.size() > 0) {
                long[] replicaVersions = partitionService.getPartitionReplicaVersions(migrationInfo.getPartitionId());
                invokeMigrationOperation(destination, replicaVersions, tasks);
                returnResponse = false;
            } else {
                success = true;
            }
        } catch (Throwable e) {
            logThrowable(e);
            success = false;
        } finally {
            migrationInfo.doneProcessing();
        }
    }

    private void logThrowable(Throwable t) {
        Throwable throwableToLog = t;
        if (throwableToLog instanceof ExecutionException) {
            throwableToLog = throwableToLog.getCause() != null ? throwableToLog.getCause() : throwableToLog;
        }
        Level level = getLogLevel(throwableToLog);
        getLogger().log(level, throwableToLog.getMessage(), throwableToLog);
    }

    private Level getLogLevel(Throwable e) {
        return (e instanceof MemberLeftException || e instanceof InterruptedException)
                || !getNodeEngine().isActive() ? Level.INFO : Level.WARNING;
    }

    private void verifyNotThisNode(NodeEngine nodeEngine, Address source) {
        if (source == null || !source.equals(nodeEngine.getThisAddress())) {
            throw new RetryableHazelcastException("Source of migration is not this node! => " + toString());
        }
    }

    private void verifyOwnerExists(Address owner) {
        if (owner == null) {
            throw new RetryableHazelcastException("Cannot migrate at the moment! Owner of the partition is null => "
                    + migrationInfo);
        }
    }

    private void verifyOwner(Address source, InternalPartition partition, Address owner) {
        if (!source.equals(owner)) {
            throw new HazelcastException("Cannot migrate! This node is not owner of the partition => "
                    + migrationInfo + " -> partitionId=" + partition.getPartitionId() + " , " + partition);
        }
    }

    private void invokeMigrationOperation(Address destination, long[] replicaVersions, Collection<Operation> tasks)
            throws IOException {

        MigrationOperation operation = new MigrationOperation(migrationInfo, replicaVersions, tasks);

        NodeEngine nodeEngine = getNodeEngine();
        InternalPartitionServiceImpl partitionService = getService();

        nodeEngine.getOperationService()
                .createInvocationBuilder(InternalPartitionService.SERVICE_NAME, operation, destination)
                .setCallback(new MigrationCallback(migrationInfo, getResponseHandler()))
                .setResultDeserialized(true)
                .setCallTimeout(partitionService.getPartitionMigrationTimeout())
                .setTryPauseMillis(TRY_PAUSE_MILLIS)
                .setReplicaIndex(getReplicaIndex())
                .invoke();
    }

    private void verifyGoodMaster(NodeEngine nodeEngine) {
        Address masterAddress = nodeEngine.getMasterAddress();
        if (!masterAddress.equals(migrationInfo.getMaster())) {
            throw new RetryableHazelcastException("Migration initiator is not master node! => " + toString());
        }
        if (!masterAddress.equals(getCallerAddress())) {
            throw new RetryableHazelcastException("Caller is not master node! => " + toString());
        }
    }

    private void verifyExistingTarget(NodeEngine nodeEngine, Address destination) {
        Member target = nodeEngine.getClusterService().getMember(destination);
        if (target == null) {
            throw new TargetNotMemberException("Destination of migration could not be found! => " + toString());
        }
    }

    @Override
    public ExceptionAction onException(Throwable throwable) {
        if (throwable instanceof TargetNotMemberException) {
            return ExceptionAction.THROW_EXCEPTION;
        }
        return super.onException(throwable);
    }

    @Override
    public Object getResponse() {
        return success;
    }

    @Override
    public boolean returnsResponse() {
        return returnResponse;
    }

    private Collection<Operation> prepareMigrationTasks() {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        PartitionReplicationEvent replicationEvent = new PartitionReplicationEvent(migrationInfo.getPartitionId(), 0);
        PartitionMigrationEvent migrationEvent
                = new PartitionMigrationEvent(MigrationEndpoint.SOURCE, migrationInfo.getPartitionId());

        Collection<Operation> tasks = new LinkedList<Operation>();
        for (ServiceInfo serviceInfo : nodeEngine.getServiceInfos(MigrationAwareService.class)) {
            MigrationAwareService service = (MigrationAwareService) serviceInfo.getService();
            service.beforeMigration(migrationEvent);
            Operation op = service.prepareReplicationOperation(replicationEvent);
            if (op != null) {
                op.setServiceName(serviceInfo.getName());
                tasks.add(op);
            }
        }
        return tasks;
    }

    private static final class MigrationCallback implements Callback<Object> {

        final MigrationInfo migrationInfo;
        final ResponseHandler responseHandler;

        private MigrationCallback(MigrationInfo migrationInfo, ResponseHandler responseHandler) {
            this.migrationInfo = migrationInfo;
            this.responseHandler = responseHandler;
        }

        @Override
        public void notify(Object result) {
            migrationInfo.doneProcessing();
            responseHandler.sendResponse(result);
        }
    }
}

<code block>


package com.hazelcast.spi.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.config.Config;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.management.ManagementCenterService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.quorum.impl.QuorumServiceImpl;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.PostJoinAwareService;
import com.hazelcast.spi.impl.servicemanager.ServiceInfo;
import com.hazelcast.spi.SharedService;
import com.hazelcast.internal.storage.DataRef;
import com.hazelcast.internal.storage.Storage;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import com.hazelcast.spi.impl.operationservice.impl.OperationServiceImpl;
import com.hazelcast.spi.impl.proxyservice.InternalProxyService;
import com.hazelcast.spi.impl.proxyservice.impl.ProxyServiceImpl;
import com.hazelcast.spi.impl.servicemanager.impl.ServiceManagerImpl;
import com.hazelcast.spi.impl.waitnotifyservice.InternalWaitNotifyService;
import com.hazelcast.spi.impl.waitnotifyservice.impl.WaitNotifyServiceImpl;
import com.hazelcast.spi.impl.eventservice.InternalEventService;
import com.hazelcast.spi.impl.eventservice.impl.EventServiceImpl;
import com.hazelcast.spi.impl.transceiver.PacketTransceiver;
import com.hazelcast.spi.impl.transceiver.impl.PacketTransceiverImpl;
import com.hazelcast.spi.impl.executionservice.InternalExecutionService;
import com.hazelcast.spi.impl.executionservice.impl.ExecutionServiceImpl;
import com.hazelcast.transaction.TransactionManagerService;
import com.hazelcast.transaction.impl.TransactionManagerServiceImpl;
import com.hazelcast.wan.WanReplicationService;

import java.util.Collection;
import java.util.LinkedList;


public class NodeEngineImpl implements NodeEngine {

    private final Node node;
    private final ILogger logger;
    private final EventServiceImpl eventService;
    private final OperationServiceImpl operationService;
    private final ExecutionServiceImpl executionService;
    private final WaitNotifyServiceImpl waitNotifyService;
    private final ServiceManagerImpl serviceManager;
    private final TransactionManagerServiceImpl transactionManagerService;
    private final ProxyServiceImpl proxyService;
    private final WanReplicationService wanReplicationService;
    private final PacketTransceiver packetTransceiver;
    private final QuorumServiceImpl quorumService;

    public NodeEngineImpl(Node node) {
        this.node = node;
        this.logger = node.getLogger(NodeEngine.class.getName());
        this.proxyService = new ProxyServiceImpl(this);
        this.serviceManager = new ServiceManagerImpl(this);
        this.executionService = new ExecutionServiceImpl(this);
        this.operationService = new OperationServiceImpl(this);
        this.eventService = new EventServiceImpl(this);
        this.waitNotifyService = new WaitNotifyServiceImpl(this);
        this.transactionManagerService = new TransactionManagerServiceImpl(this);
        this.wanReplicationService = node.getNodeExtension().createService(WanReplicationService.class);
        this.packetTransceiver = new PacketTransceiverImpl(
                node, logger, operationService, eventService, wanReplicationService, executionService);
        quorumService = new QuorumServiceImpl(this);
    }

    public PacketTransceiver getPacketTransceiver() {
        return packetTransceiver;
    }

    public void start() {
        serviceManager.start();
        proxyService.init();
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public MemberImpl getLocalMember() {
        return node.getLocalMember();
    }

    @Override
    public Config getConfig() {
        return node.getConfig();
    }

    @Override
    public ClassLoader getConfigClassLoader() {
        return node.getConfigClassLoader();
    }

    @Override
    public InternalEventService getEventService() {
        return eventService;
    }

    @Override
    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    @Override
    public InternalOperationService getOperationService() {
        return operationService;
    }

    @Override
    public InternalExecutionService getExecutionService() {
        return executionService;
    }

    @Override
    public InternalPartitionService getPartitionService() {
        return node.getPartitionService();
    }

    @Override
    public ClusterService getClusterService() {
        return node.getClusterService();
    }

    public ManagementCenterService getManagementCenterService() {
        return node.getManagementCenterService();
    }

    @Override
    public InternalProxyService getProxyService() {
        return proxyService;
    }

    @Override
    public InternalWaitNotifyService getWaitNotifyService() {
        return waitNotifyService;
    }

    @Override
    public WanReplicationService getWanReplicationService() {
        return wanReplicationService;
    }

    @Override
    public QuorumServiceImpl getQuorumService() {
        return quorumService;
    }

    @Override
    public TransactionManagerService getTransactionManagerService() {
        return transactionManagerService;
    }

    @Override
    public Data toData(final Object object) {
        return node.getSerializationService().toData(object);
    }

    @Override
    public Object toObject(final Object object) {
        if (object instanceof Data) {
            return node.getSerializationService().toObject(object);
        }
        return object;
    }

    @Override
    public boolean isActive() {
        return node.isActive();
    }

    @Override
    public HazelcastInstance getHazelcastInstance() {
        return node.hazelcastInstance;
    }

    @Override
    public ILogger getLogger(String name) {
        return node.getLogger(name);
    }

    @Override
    public ILogger getLogger(Class clazz) {
        return node.getLogger(clazz);
    }

    @Override
    public GroupProperties getGroupProperties() {
        return node.getGroupProperties();
    }

    public <T> T getService(String serviceName) {
        return serviceManager.getService(serviceName);
    }

    @Override
    public <T extends SharedService> T getSharedService(String serviceName) {
        return serviceManager.getSharedService(serviceName);
    }

    
    public <S> Collection<S> getServices(Class<S> serviceClass) {
        return serviceManager.getServices(serviceClass);
    }

    public Collection<ServiceInfo> getServiceInfos(Class serviceClass) {
        return serviceManager.getServiceInfos(serviceClass);
    }

    public Node getNode() {
        return node;
    }

    public void onMemberLeft(MemberImpl member) {
        waitNotifyService.onMemberLeft(member);
        operationService.onMemberLeft(member);
        eventService.onMemberLeft(member);
    }

    public void onClientDisconnected(String clientUuid) {
        waitNotifyService.onClientDisconnected(clientUuid);
    }

    public void onPartitionMigrate(MigrationInfo migrationInfo) {
        waitNotifyService.onPartitionMigrate(getThisAddress(), migrationInfo);
    }

    
    public Operation[] getPostJoinOperations() {
        final Collection<Operation> postJoinOps = new LinkedList<Operation>();
        Operation eventPostJoinOp = eventService.getPostJoinOperation();
        if (eventPostJoinOp != null) {
            postJoinOps.add(eventPostJoinOp);
        }
        Collection<PostJoinAwareService> services = getServices(PostJoinAwareService.class);
        for (PostJoinAwareService service : services) {
            final Operation postJoinOperation = service.getPostJoinOperation();
            if (postJoinOperation != null) {
                if (postJoinOperation.getPartitionId() >= 0) {
                    logger.severe(
                            "Post-join operations cannot implement PartitionAwareOperation! Service: "
                                    + service + ", Operation: "
                                    + postJoinOperation);
                    continue;
                }
                postJoinOps.add(postJoinOperation);
            }
        }
        return postJoinOps.isEmpty() ? null : postJoinOps.toArray(new Operation[postJoinOps.size()]);
    }

    @Override
    public Storage<DataRef> getOffHeapStorage() {
        return node.getNodeExtension().getNativeDataStorage();
    }

    public void reset() {
        waitNotifyService.reset();
        operationService.reset();
    }

    public void shutdown(final boolean terminate) {
        logger.finest("Shutting down services...");
        waitNotifyService.shutdown();
        proxyService.shutdown();
        serviceManager.shutdown(terminate);
        eventService.shutdown();
        operationService.shutdown();
        wanReplicationService.shutdown();
        executionService.shutdown();
    }
}

<code block>


package com.hazelcast.spi.impl.servicemanager;

import com.hazelcast.spi.SharedService;

import java.util.List;


public interface ServiceManager {

    
    ServiceInfo getServiceInfo(String serviceName);

    
    List<ServiceInfo> getServiceInfos(Class serviceClass);

    
    <T> T getService(String serviceName);

    
    <S> List<S> getServices(Class<S> serviceClass);

    
    <T extends SharedService> T getSharedService(String serviceName);
}

<code block>


package com.hazelcast.spi.impl.servicemanager;

import com.hazelcast.spi.ConfigurableService;
import com.hazelcast.spi.CoreService;
import com.hazelcast.spi.ManagedService;


public final class ServiceInfo {

    private final String name;
    private final Object service;

    public ServiceInfo(String name, Object service) {
        this.name = name;
        this.service = service;
    }

    public String getName() {
        return name;
    }

    public Object getService() {
        return service;
    }

    public boolean isCoreService() {
        return service instanceof CoreService;
    }

    public boolean isManagedService() {
        return service instanceof ManagedService;
    }

    public boolean isConfigurableService() {
        return service instanceof ConfigurableService;
    }

    @SuppressWarnings("unchecked")
    public boolean isInstanceOf(Class type) {
        return type.isAssignableFrom(service.getClass());
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (o == null || getClass() != o.getClass()) {
            return false;
        }

        ServiceInfo that = (ServiceInfo) o;

        if (name != null ? !name.equals(that.name) : that.name != null) {
            return false;
        }

        return true;
    }

    @Override
    public int hashCode() {
        return name != null ? name.hashCode() : 0;
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder("ServiceInfo{");
        sb.append("name='").append(name).append('\'');
        sb.append(", service=").append(service);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.spi.impl.servicemanager.impl;

import com.hazelcast.cache.impl.ICacheService;
import com.hazelcast.client.impl.ClientEngineImpl;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.collection.impl.list.ListService;
import com.hazelcast.collection.impl.set.SetService;
import com.hazelcast.concurrent.atomiclong.AtomicLongService;
import com.hazelcast.concurrent.atomicreference.AtomicReferenceService;
import com.hazelcast.concurrent.countdownlatch.CountDownLatchService;
import com.hazelcast.concurrent.idgen.IdGeneratorService;
import com.hazelcast.concurrent.lock.LockService;
import com.hazelcast.concurrent.lock.LockServiceImpl;
import com.hazelcast.concurrent.semaphore.SemaphoreService;
import com.hazelcast.config.ServiceConfig;
import com.hazelcast.config.ServicesConfig;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.executor.impl.DistributedExecutorService;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.NodeExtension;
import com.hazelcast.logging.ILogger;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.mapreduce.impl.MapReduceService;
import com.hazelcast.multimap.impl.MultiMapService;
import com.hazelcast.nio.ClassLoaderUtil;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.collection.impl.queue.QueueService;
import com.hazelcast.quorum.impl.QuorumServiceImpl;
import com.hazelcast.replicatedmap.impl.ReplicatedMapService;
import com.hazelcast.ringbuffer.impl.RingbufferService;
import com.hazelcast.spi.ConfigurableService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.impl.servicemanager.ServiceInfo;
import com.hazelcast.spi.SharedService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.proxyservice.impl.ProxyServiceImpl;
import com.hazelcast.spi.impl.servicemanager.ServiceManager;
import com.hazelcast.topic.impl.reliable.ReliableTopicService;
import com.hazelcast.topic.impl.TopicService;
import com.hazelcast.transaction.impl.xa.XAService;
import com.hazelcast.transaction.impl.TransactionManagerServiceImpl;
import java.lang.reflect.Constructor;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import static com.hazelcast.util.EmptyStatement.ignore;

public final class ServiceManagerImpl implements ServiceManager {

    private final NodeEngineImpl nodeEngine;
    private final ILogger logger;
    private final ConcurrentMap<String, ServiceInfo> services = new ConcurrentHashMap<String, ServiceInfo>(20, .75f, 1);

    public ServiceManagerImpl(final NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.logger = nodeEngine.getLogger(ServiceManagerImpl.class);
    }

    public synchronized void start() {
        Map<String, Properties> serviceProps = new HashMap<String, Properties>();
        Map<String, Object> serviceConfigObjects = new HashMap<String, Object>();

        registerServices(serviceProps, serviceConfigObjects);
        initServices(serviceProps, serviceConfigObjects);
    }

    private void registerServices(Map<String, Properties> serviceProps, Map<String, Object> serviceConfigObjects) {
        registerCoreServices();

        Node node = nodeEngine.getNode();
        ServicesConfig servicesConfig = node.getConfig().getServicesConfig();
        if (servicesConfig != null) {
            registerDefaultServices(servicesConfig);
            registerUserServices(servicesConfig, serviceProps, serviceConfigObjects);
        }
    }

    private void registerCoreServices() {
        logger.finest("Registering core services...");

        Node node = nodeEngine.getNode();
        registerService(ClusterServiceImpl.SERVICE_NAME, node.getClusterService());
        registerService(InternalPartitionService.SERVICE_NAME, node.getPartitionService());
        registerService(ProxyServiceImpl.SERVICE_NAME, nodeEngine.getProxyService());
        registerService(TransactionManagerServiceImpl.SERVICE_NAME, nodeEngine.getTransactionManagerService());
        registerService(ClientEngineImpl.SERVICE_NAME, node.clientEngine);
        registerService(QuorumServiceImpl.SERVICE_NAME, nodeEngine.getQuorumService());
    }

    private void registerDefaultServices(ServicesConfig servicesConfig) {
        if (!servicesConfig.isEnableDefaults()) {
            return;
        }

        logger.finest("Registering default services...");
        registerService(MapService.SERVICE_NAME, createService(MapService.class));
        registerService(LockService.SERVICE_NAME, new LockServiceImpl(nodeEngine));
        registerService(QueueService.SERVICE_NAME, new QueueService(nodeEngine));
        registerService(TopicService.SERVICE_NAME, new TopicService());
        registerService(ReliableTopicService.SERVICE_NAME, new ReliableTopicService(nodeEngine));
        registerService(MultiMapService.SERVICE_NAME, new MultiMapService(nodeEngine));
        registerService(ListService.SERVICE_NAME, new ListService(nodeEngine));
        registerService(SetService.SERVICE_NAME, new SetService(nodeEngine));
        registerService(DistributedExecutorService.SERVICE_NAME, new DistributedExecutorService());
        registerService(AtomicLongService.SERVICE_NAME, new AtomicLongService());
        registerService(AtomicReferenceService.SERVICE_NAME, new AtomicReferenceService());
        registerService(CountDownLatchService.SERVICE_NAME, new CountDownLatchService());
        registerService(SemaphoreService.SERVICE_NAME, new SemaphoreService(nodeEngine));
        registerService(IdGeneratorService.SERVICE_NAME, new IdGeneratorService(nodeEngine));
        registerService(MapReduceService.SERVICE_NAME, new MapReduceService(nodeEngine));
        registerService(ReplicatedMapService.SERVICE_NAME, new ReplicatedMapService(nodeEngine));
        registerService(RingbufferService.SERVICE_NAME, new RingbufferService(nodeEngine));
        registerService(XAService.SERVICE_NAME, new XAService(nodeEngine));
        registerCacheServiceIfAvailable();
    }

    private <T> T createService(Class<T> service) {
        Node node = nodeEngine.getNode();
        NodeExtension nodeExtension = node.getNodeExtension();
        return nodeExtension.createService(service);
    }

    private void registerCacheServiceIfAvailable() {
        
        try {
            
            final String localClassName = "javax.cache.Caching";
            ClassLoader classLoader = nodeEngine.getConfigClassLoader();
            Class theClass = ClassLoaderUtil.loadClass(classLoader, localClassName);
            if (theClass != null) {
                ICacheService service = createService(ICacheService.class);
                registerService(ICacheService.SERVICE_NAME, service);
            }
        } catch (ClassNotFoundException e) {
            logger.finest("javax.cache api is not detected on classpath. Skipping CacheService...");
        }
    }

    private void initServices(Map<String, Properties> serviceProps, Map<String, Object> serviceConfigObjects) {
        for (ServiceInfo serviceInfo : services.values()) {
            initService(serviceProps, serviceConfigObjects, serviceInfo);
        }
    }

    private void initService(Map<String, Properties> serviceProps, Map<String, Object> serviceConfigObjects,
                             ServiceInfo serviceInfo) {
        final Object service = serviceInfo.getService();
        if (serviceInfo.isConfigurableService()) {
            try {
                if (logger.isFinestEnabled()) {
                    logger.finest("Configuring service -> " + service);
                }
                final Object configObject = serviceConfigObjects.get(serviceInfo.getName());
                ((ConfigurableService) service).configure(configObject);
            } catch (Throwable t) {
                logger.severe("Error while configuring service: " + t.getMessage(), t);
            }
        }
        if (serviceInfo.isManagedService()) {
            try {
                if (logger.isFinestEnabled()) {
                    logger.finest("Initializing service -> " + service);
                }
                final Properties props = serviceProps.get(serviceInfo.getName());
                ((ManagedService) service).init(nodeEngine, props != null ? props : new Properties());
            } catch (Throwable t) {
                logger.severe("Error while initializing service: " + t.getMessage(), t);
            }
        }
    }

    private void registerUserServices(ServicesConfig servicesConfig, Map<String, Properties> serviceProps,
                                      Map<String, Object> serviceConfigObjects) {
        logger.finest("Registering user defined services...");
        Collection<ServiceConfig> serviceConfigs = servicesConfig.getServiceConfigs();
        for (ServiceConfig serviceConfig : serviceConfigs) {
            registerUserService(serviceProps, serviceConfigObjects, serviceConfig);
        }
    }

    private void registerUserService(Map<String, Properties> serviceProps, Map<String, Object> serviceConfigObjects,
                                     ServiceConfig serviceConfig) {
        if (!serviceConfig.isEnabled()) {
            return;
        }

        Object service = serviceConfig.getServiceImpl();
        if (service == null) {
            service = createServiceObject(serviceConfig.getClassName());
        }
        if (service != null) {
            registerService(serviceConfig.getName(), service);
            serviceProps.put(serviceConfig.getName(), serviceConfig.getProperties());
            if (serviceConfig.getConfigObject() != null) {
                serviceConfigObjects.put(serviceConfig.getName(), serviceConfig.getConfigObject());
            }
        }
    }

    @SuppressWarnings("unchecked")
    private Object createServiceObject(String className) {
        try {
            ClassLoader classLoader = nodeEngine.getConfigClassLoader();
            Class serviceClass = ClassLoaderUtil.loadClass(classLoader, className);
            try {
                Constructor constructor = serviceClass.getConstructor(NodeEngine.class);
                return constructor.newInstance(nodeEngine);
            } catch (NoSuchMethodException ignored) {
                ignore(ignored);
            }
            return ClassLoaderUtil.newInstance(serviceClass, classLoader, className);
        } catch (Exception e) {
            logger.severe(e);
        }
        return null;
    }

    public synchronized void shutdown(boolean terminate) {
        logger.finest("Stopping services...");
        final List<ManagedService> managedServices = getServices(ManagedService.class);
        
        Collections.reverse(managedServices);
        services.clear();
        for (ManagedService service : managedServices) {
            shutdownService(service, terminate);
        }
    }

    private void shutdownService(final ManagedService service, final boolean terminate) {
        try {
            if (logger.isFinestEnabled()) {
                logger.finest("Shutting down service -> " + service);
            }
            service.shutdown(terminate);
        } catch (Throwable t) {
            logger.severe("Error while shutting down service[" + service + "]: " + t.getMessage(), t);
        }
    }

    private synchronized void registerService(String serviceName, Object service) {
        if (logger.isFinestEnabled()) {
            logger.finest("Registering service: '" + serviceName + "'");
        }
        final ServiceInfo serviceInfo = new ServiceInfo(serviceName, service);
        final ServiceInfo currentServiceInfo = services.putIfAbsent(serviceName, serviceInfo);
        if (currentServiceInfo != null) {
            logger.warning("Replacing " + currentServiceInfo + " with " + serviceInfo);
            if (currentServiceInfo.isCoreService()) {
                throw new HazelcastException("Can not replace a CoreService! Name: " + serviceName
                        + ", Service: " + currentServiceInfo.getService());
            }
            if (currentServiceInfo.isManagedService()) {
                shutdownService((ManagedService) currentServiceInfo.getService(), false);
            }
            services.put(serviceName, serviceInfo);
        }
    }

    @Override
    public ServiceInfo getServiceInfo(String serviceName) {
        return services.get(serviceName);
    }

    @Override
    public <S> List<S> getServices(Class<S> serviceClass) {
        final LinkedList<S> result = new LinkedList<S>();
        for (ServiceInfo serviceInfo : services.values()) {
            if (serviceInfo.isInstanceOf(serviceClass)) {
                final S service = (S) serviceInfo.getService();
                if (serviceInfo.isCoreService()) {
                    result.addFirst(service);
                } else {
                    result.addLast(service);
                }
            }
        }
        return result;
    }

    @Override
    public <T> T getService(String serviceName) {
        final ServiceInfo serviceInfo = getServiceInfo(serviceName);
        return serviceInfo != null ? (T) serviceInfo.getService() : null;
    }

    @Override
    public <T extends SharedService> T getSharedService(String serviceName) {
        final Object service = getService(serviceName);
        if (service == null) {
            return null;
        }

        if (service instanceof SharedService) {
            return (T) service;
        }

        throw new IllegalArgumentException("No SharedService registered with name: " + serviceName);
    }

    
    @Override
    public List<ServiceInfo> getServiceInfos(Class serviceClass) {
        final LinkedList<ServiceInfo> result = new LinkedList<ServiceInfo>();
        for (ServiceInfo serviceInfo : services.values()) {
            if (serviceInfo.isInstanceOf(serviceClass)) {
                if (serviceInfo.isCoreService()) {
                    result.addFirst(serviceInfo);
                } else {
                    result.addLast(serviceInfo);
                }
            }
        }
        return result;
    }
}

<code block>
package com.hazelcast.spi.impl.servicemanager.impl;

import com.hazelcast.concurrent.lock.LockService;
import com.hazelcast.config.Config;
import com.hazelcast.config.ServiceConfig;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.spi.ConfigurableService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.impl.servicemanager.ServiceInfo;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.swing.*;
import java.util.List;
import java.util.Properties;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class ServiceManagerImplTest extends HazelcastTestSupport {

    private ServiceManagerImpl serviceManager;

    @Before
    public void setup() {
        Config config = new Config();

        ServiceConfig serviceConfig = new ServiceConfig()
                .setClassName(FooService.class.getName())
                .setEnabled(true)
                .setName("fooService");
        config.getServicesConfig().addServiceConfig(serviceConfig);

        HazelcastInstance hz = createHazelcastInstance(config);
        NodeEngineImpl nodeEngine = getNodeEngineImpl(hz);
        serviceManager = new ServiceManagerImpl(nodeEngine);
        serviceManager.start();
    }

    static class FooService implements ManagedService, ConfigurableService{
        volatile boolean initCalled;
        volatile boolean configureCalled;

        @Override
        public void configure(Object configObject) {
            this.configureCalled = true;
        }

        @Override
        public void init(NodeEngine nodeEngine, Properties properties) {
            this.initCalled = true;
        }

        @Override
        public void reset() {

        }

        @Override
        public void shutdown(boolean terminate) {

        }
    }

    


    @Test
    public void getServiceInfo() {
        ServiceInfo result = serviceManager.getServiceInfo(MapService.SERVICE_NAME);
        assertNotNull(result);
        assertEquals(MapService.SERVICE_NAME, result.getName());
        assertInstanceOf(MapService.class, result.getService());
    }

    @Test
    public void getServiceInfo_notExisting() {
        ServiceInfo result = serviceManager.getServiceInfo("notexisting");
        assertNull(result);
    }

    

    @Test
    public void getServiceInfos() {
        List<ServiceInfo> result = serviceManager.getServiceInfos(MapService.class);
        assertNotNull(result);
        assertEquals(1, result.size());

        ServiceInfo serviceInfo = result.get(0);
        assertEquals(MapService.SERVICE_NAME, serviceInfo.getName());
        assertInstanceOf(MapService.class, serviceInfo.getService());
    }

    @Test
    public void getServiceInfos_notExisting() {
        List<ServiceInfo> result = serviceManager.getServiceInfos(JPanel.class);
        assertNotNull(result);
        assertEquals(0, result.size());
    }

    

    @Test
    public void getService() {
        Object result = serviceManager.getService(MapService.SERVICE_NAME);
        assertInstanceOf(MapService.class, result);
    }

    @Test
    public void getService_notExisting() {
        Object result = serviceManager.getService("notexisting");
        assertNull(result);
    }

    

    @Test
    public void getSharedService() {
        Object result = serviceManager.getSharedService(LockService.SERVICE_NAME);
        assertInstanceOf(LockService.class, result);
    }

    @Test
    public void getSharedService_notExisting() {
        Object result = serviceManager.getSharedService("notexisting");
        assertNull(result);
    }

    @Test(expected = IllegalArgumentException.class)
    public void getSharedService_notSharedService() {
        serviceManager.getSharedService(MapService.SERVICE_NAME);
    }

    

    @Test
    public void getServices() {
        List<MapService> result = serviceManager.getServices(MapService.class);
        assertNotNull(result);
        assertEquals(1, result.size());
        assertInstanceOf(MapService.class, result.get(0));
    }

    @Test
    public void getServices_notExisting() {
        List<JPanel> result = serviceManager.getServices(JPanel.class);
        assertNotNull(result);
        assertTrue(result.isEmpty());
    }

    

    @Test
    public void userService() {
        Object result = serviceManager.getService("fooService");
        FooService fooService = assertInstanceOf(FooService.class, result);

        assertTrue(fooService.initCalled);
        assertTrue(fooService.configureCalled);
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationCycleOperation;
import com.hazelcast.partition.ReplicaErrorLogger;
import com.hazelcast.spi.MigrationAwareService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PartitionAwareOperation;
import com.hazelcast.spi.PartitionReplicationEvent;
import com.hazelcast.spi.ServiceInfo;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;
import java.util.Arrays;
import java.util.Collection;
import java.util.LinkedList;
import java.util.List;

public final class ReplicaSyncRequest extends Operation implements PartitionAwareOperation, MigrationCycleOperation {

    public ReplicaSyncRequest() {
    }

    public ReplicaSyncRequest(int partitionId, int replicaIndex) {
        setPartitionId(partitionId);
        setReplicaIndex(replicaIndex);
    }

    @Override
    public void beforeRun() throws Exception {
        int syncReplicaIndex = getReplicaIndex();
        if (syncReplicaIndex < 1 || syncReplicaIndex > InternalPartition.MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("Replica index should be in range [1-"
                    + InternalPartition.MAX_BACKUP_COUNT + "]");
        }
    }

    @Override
    public void run() throws Exception {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        InternalPartitionServiceImpl partitionService = (InternalPartitionServiceImpl) nodeEngine.getPartitionService();
        int partitionId = getPartitionId();
        int replicaIndex = getReplicaIndex();

        if (!partitionService.isMigrationActive()) {
            ILogger logger = getLogger();
            if (logger.isFinestEnabled()) {
                logger.finest("Migration is paused! Cannot run replica sync -> " + toString());
            }
            sendRetryResponse();
            return;
        }

        if (!preCheckReplicaSync(nodeEngine, partitionId, replicaIndex)) {
            return;
        }

        try {
            List<Operation> tasks = createReplicationOperations();
            if (tasks.isEmpty()) {
                logNoReplicaDataFound(partitionId, replicaIndex);
                sendEmptyResponse();
            } else {
                sendResponse(tasks);
            }
        } finally {
            partitionService.releaseReplicaSyncPermit();
        }
    }

    private boolean preCheckReplicaSync(NodeEngineImpl nodeEngine, int partitionId, int replicaIndex) throws IOException {
        InternalPartitionServiceImpl partitionService = (InternalPartitionServiceImpl) nodeEngine.getPartitionService();
        InternalPartitionImpl partition = partitionService.getPartition(partitionId);
        Address owner = partition.getOwnerOrNull();
        long[] replicaVersions = partitionService.getPartitionReplicaVersions(partitionId);
        long currentVersion = replicaVersions[replicaIndex - 1];

        ILogger logger = getLogger();
        if (!nodeEngine.getThisAddress().equals(owner)) {
            if (logger.isFinestEnabled()) {
                logger.finest("Wrong target! " + toString() + " cannot be processed! Target should be: " + owner);
            }
            sendRetryResponse();
            return false;
        }

        if (currentVersion == 0) {
            if (logger.isFinestEnabled()) {
                logger.finest("Current replicaVersion=0, sending empty response for partitionId="
                        + getPartitionId() + ", replicaIndex=" + getReplicaIndex() + ", replicaVersions="
                        + Arrays.toString(replicaVersions));
            }
            sendEmptyResponse();
            return false;
        }

        if (!partitionService.tryToAcquireReplicaSyncPermit()) {
            if (logger.isFinestEnabled()) {
                logger.finest(
                        "Max parallel replication process limit exceeded! Could not run replica sync -> " + toString());
            }
            sendRetryResponse();
            return false;
        }
        return true;
    }

    private void sendRetryResponse() {
        NodeEngine nodeEngine = getNodeEngine();
        int partitionId = getPartitionId();
        int replicaIndex = getReplicaIndex();

        ReplicaSyncRetryResponse response = new ReplicaSyncRetryResponse();
        response.setPartitionId(partitionId).setReplicaIndex(replicaIndex);
        Address target = getCallerAddress();
        OperationService operationService = nodeEngine.getOperationService();
        operationService.send(response, target);
    }

    private List<Operation> createReplicationOperations() {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        Collection<ServiceInfo> services = nodeEngine.getServiceInfos(MigrationAwareService.class);
        PartitionReplicationEvent event = new PartitionReplicationEvent(getPartitionId(), getReplicaIndex());
        List<Operation> tasks = new LinkedList<Operation>();
        for (ServiceInfo serviceInfo : services) {
            MigrationAwareService service = (MigrationAwareService) serviceInfo.getService();
            Operation op = service.prepareReplicationOperation(event);
            if (op != null) {
                op.setServiceName(serviceInfo.getName());
                tasks.add(op);
            }
        }
        return tasks;
    }

    private void sendEmptyResponse() throws IOException {
        sendResponse(null);
    }

    private void sendResponse(List<Operation> data) throws IOException {
        NodeEngine nodeEngine = getNodeEngine();

        ReplicaSyncResponse syncResponse = createResponse(data);
        Address target = getCallerAddress();
        ILogger logger = getLogger();
        if (logger.isFinestEnabled()) {
            logger.finest("Sending sync response to -> " + target + " for partitionId="
                    + getPartitionId() + ", replicaIndex=" + getReplicaIndex());
        }
        OperationService operationService = nodeEngine.getOperationService();
        operationService.send(syncResponse, target);
    }

    private ReplicaSyncResponse createResponse(List<Operation> data) throws IOException {
        int partitionId = getPartitionId();
        NodeEngine nodeEngine = getNodeEngine();
        InternalPartitionService partitionService = nodeEngine.getPartitionService();
        long[] replicaVersions = partitionService.getPartitionReplicaVersions(partitionId);

        ReplicaSyncResponse syncResponse = new ReplicaSyncResponse(data, replicaVersions);
        syncResponse.setPartitionId(partitionId).setReplicaIndex(getReplicaIndex());
        return syncResponse;
    }

    private void logNoReplicaDataFound(int partitionId, int replicaIndex) {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        ILogger logger = nodeEngine.getLogger(getClass());

        if (logger.isFinestEnabled()) {
            logger.finest("No replica data is found for partitionId=" + partitionId + ", replicaIndex=" + replicaIndex);
        }
    }

    @Override
    public void afterRun() throws Exception {
    }

    @Override
    public boolean returnsResponse() {
        return false;
    }

    @Override
    public Object getResponse() {
        return Boolean.TRUE;
    }

    @Override
    public boolean validatesTarget() {
        return false;
    }

    @Override
    public void logError(Throwable e) {
        ReplicaErrorLogger.log(e, getLogger());
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
    }

    @Override
    public String toString() {
        return getClass().getSimpleName() + "{partitionId=" + getPartitionId() + ", replicaIndex=" + getReplicaIndex() + '}';
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberLeftException;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationEndpoint;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.MigrationAwareService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.PartitionMigrationEvent;
import com.hazelcast.spi.PartitionReplicationEvent;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.ServiceInfo;
import com.hazelcast.spi.exception.RetryableHazelcastException;
import com.hazelcast.spi.exception.TargetNotMemberException;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;
import java.util.Collection;
import java.util.LinkedList;
import java.util.concurrent.ExecutionException;
import java.util.logging.Level;

public final class MigrationRequestOperation extends BaseMigrationOperation {

    private static final int TRY_PAUSE_MILLIS = 1000;

    private boolean returnResponse = true;

    public MigrationRequestOperation() {
    }

    public MigrationRequestOperation(MigrationInfo migrationInfo) {
        super(migrationInfo);
    }

    public void run() {
        NodeEngine nodeEngine = getNodeEngine();
        verifyGoodMaster(nodeEngine);

        Address source = migrationInfo.getSource();
        Address destination = migrationInfo.getDestination();
        verifyExistingTarget(nodeEngine, destination);

        if (destination.equals(source)) {
            getLogger().warning("Source and destination addresses are the same! => " + toString());
            success = false;
            return;
        }

        verifyNotThisNode(nodeEngine, source);

        InternalPartitionServiceImpl partitionService = getService();
        InternalPartition partition = partitionService.getPartition(migrationInfo.getPartitionId());
        Address owner = partition.getOwnerOrNull();
        verifyOwnerExists(owner);

        if (!migrationInfo.startProcessing()) {
            getLogger().warning("Migration is cancelled -> " + migrationInfo);
            success = false;
            return;
        }

        try {
            verifyOwner(source, partition, owner);
            partitionService.addActiveMigration(migrationInfo);
            Collection<Operation> tasks = prepareMigrationTasks();
            if (tasks.size() > 0) {
                long[] replicaVersions = partitionService.getPartitionReplicaVersions(migrationInfo.getPartitionId());
                invokeMigrationOperation(destination, replicaVersions, tasks);
                returnResponse = false;
            } else {
                success = true;
            }
        } catch (Throwable e) {
            logThrowable(e);
            success = false;
        } finally {
            migrationInfo.doneProcessing();
        }
    }

    private void logThrowable(Throwable t) {
        Throwable throwableToLog = t;
        if (throwableToLog instanceof ExecutionException) {
            throwableToLog = throwableToLog.getCause() != null ? throwableToLog.getCause() : throwableToLog;
        }
        Level level = getLogLevel(throwableToLog);
        getLogger().log(level, throwableToLog.getMessage(), throwableToLog);
    }

    private Level getLogLevel(Throwable e) {
        return (e instanceof MemberLeftException || e instanceof InterruptedException)
                || !getNodeEngine().isActive() ? Level.INFO : Level.WARNING;
    }

    private void verifyNotThisNode(NodeEngine nodeEngine, Address source) {
        if (source == null || !source.equals(nodeEngine.getThisAddress())) {
            throw new RetryableHazelcastException("Source of migration is not this node! => " + toString());
        }
    }

    private void verifyOwnerExists(Address owner) {
        if (owner == null) {
            throw new RetryableHazelcastException("Cannot migrate at the moment! Owner of the partition is null => "
                    + migrationInfo);
        }
    }

    private void verifyOwner(Address source, InternalPartition partition, Address owner) {
        if (!source.equals(owner)) {
            throw new HazelcastException("Cannot migrate! This node is not owner of the partition => "
                    + migrationInfo + " -> partitionId=" + partition.getPartitionId() + " , " + partition);
        }
    }

    private void invokeMigrationOperation(Address destination, long[] replicaVersions, Collection<Operation> tasks)
            throws IOException {

        MigrationOperation operation = new MigrationOperation(migrationInfo, replicaVersions, tasks);

        NodeEngine nodeEngine = getNodeEngine();
        InternalPartitionServiceImpl partitionService = getService();

        nodeEngine.getOperationService()
                .createInvocationBuilder(InternalPartitionService.SERVICE_NAME, operation, destination)
                .setCallback(new MigrationCallback(migrationInfo, getResponseHandler()))
                .setResultDeserialized(true)
                .setCallTimeout(partitionService.getPartitionMigrationTimeout())
                .setTryPauseMillis(TRY_PAUSE_MILLIS)
                .setReplicaIndex(getReplicaIndex())
                .invoke();
    }

    private void verifyGoodMaster(NodeEngine nodeEngine) {
        Address masterAddress = nodeEngine.getMasterAddress();
        if (!masterAddress.equals(migrationInfo.getMaster())) {
            throw new RetryableHazelcastException("Migration initiator is not master node! => " + toString());
        }
        if (!masterAddress.equals(getCallerAddress())) {
            throw new RetryableHazelcastException("Caller is not master node! => " + toString());
        }
    }

    private void verifyExistingTarget(NodeEngine nodeEngine, Address destination) {
        Member target = nodeEngine.getClusterService().getMember(destination);
        if (target == null) {
            throw new TargetNotMemberException("Destination of migration could not be found! => " + toString());
        }
    }

    @Override
    public ExceptionAction onException(Throwable throwable) {
        if (throwable instanceof TargetNotMemberException) {
            return ExceptionAction.THROW_EXCEPTION;
        }
        return super.onException(throwable);
    }

    @Override
    public Object getResponse() {
        return success;
    }

    @Override
    public boolean returnsResponse() {
        return returnResponse;
    }

    private Collection<Operation> prepareMigrationTasks() {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        PartitionReplicationEvent replicationEvent = new PartitionReplicationEvent(migrationInfo.getPartitionId(), 0);
        PartitionMigrationEvent migrationEvent
                = new PartitionMigrationEvent(MigrationEndpoint.SOURCE, migrationInfo.getPartitionId());

        Collection<Operation> tasks = new LinkedList<Operation>();
        for (ServiceInfo serviceInfo : nodeEngine.getServiceInfos(MigrationAwareService.class)) {
            MigrationAwareService service = (MigrationAwareService) serviceInfo.getService();
            service.beforeMigration(migrationEvent);
            Operation op = service.prepareReplicationOperation(replicationEvent);
            if (op != null) {
                op.setServiceName(serviceInfo.getName());
                tasks.add(op);
            }
        }
        return tasks;
    }

    private static final class MigrationCallback implements Callback<Object> {

        final MigrationInfo migrationInfo;
        final ResponseHandler responseHandler;

        private MigrationCallback(MigrationInfo migrationInfo, ResponseHandler responseHandler) {
            this.migrationInfo = migrationInfo;
            this.responseHandler = responseHandler;
        }

        @Override
        public void notify(Object result) {
            migrationInfo.doneProcessing();
            responseHandler.sendResponse(result);
        }
    }
}

<code block>


package com.hazelcast.spi;


public final class ServiceInfo {

    private final String name;
    private final Object service;

    public ServiceInfo(String name, Object service) {
        this.name = name;
        this.service = service;
    }

    public String getName() {
        return name;
    }

    public Object getService() {
        return service;
    }

    public boolean isCoreService() {
        return service instanceof CoreService;
    }

    public boolean isManagedService() {
        return service instanceof ManagedService;
    }

    public boolean isConfigurableService() {
        return service instanceof ConfigurableService;
    }

    @SuppressWarnings("unchecked")
    public boolean isInstanceOf(Class type) {
        return type.isAssignableFrom(service.getClass());
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (o == null || getClass() != o.getClass()) {
            return false;
        }

        ServiceInfo that = (ServiceInfo) o;

        if (name != null ? !name.equals(that.name) : that.name != null) {
            return false;
        }

        return true;
    }

    @Override
    public int hashCode() {
        return name != null ? name.hashCode() : 0;
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder("ServiceInfo{");
        sb.append("name='").append(name).append('\'');
        sb.append(", service=").append(service);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.spi.impl;

import com.hazelcast.cluster.ClusterService;
import com.hazelcast.config.Config;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.internal.management.ManagementCenterService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.quorum.impl.QuorumServiceImpl;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.PostJoinAwareService;
import com.hazelcast.spi.ServiceInfo;
import com.hazelcast.spi.SharedService;
import com.hazelcast.internal.storage.DataRef;
import com.hazelcast.internal.storage.Storage;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import com.hazelcast.spi.impl.operationservice.impl.OperationServiceImpl;
import com.hazelcast.spi.impl.proxyservice.InternalProxyService;
import com.hazelcast.spi.impl.proxyservice.impl.ProxyServiceImpl;
import com.hazelcast.spi.impl.servicemanager.impl.ServiceManagerImpl;
import com.hazelcast.spi.impl.waitnotifyservice.InternalWaitNotifyService;
import com.hazelcast.spi.impl.waitnotifyservice.impl.WaitNotifyServiceImpl;
import com.hazelcast.spi.impl.eventservice.InternalEventService;
import com.hazelcast.spi.impl.eventservice.impl.EventServiceImpl;
import com.hazelcast.spi.impl.transceiver.PacketTransceiver;
import com.hazelcast.spi.impl.transceiver.impl.PacketTransceiverImpl;
import com.hazelcast.spi.impl.executionservice.InternalExecutionService;
import com.hazelcast.spi.impl.executionservice.impl.ExecutionServiceImpl;
import com.hazelcast.transaction.TransactionManagerService;
import com.hazelcast.transaction.impl.TransactionManagerServiceImpl;
import com.hazelcast.wan.WanReplicationService;

import java.util.Collection;
import java.util.LinkedList;


public class NodeEngineImpl implements NodeEngine {

    private final Node node;
    private final ILogger logger;
    private final EventServiceImpl eventService;
    private final OperationServiceImpl operationService;
    private final ExecutionServiceImpl executionService;
    private final WaitNotifyServiceImpl waitNotifyService;
    private final ServiceManagerImpl serviceManager;
    private final TransactionManagerServiceImpl transactionManagerService;
    private final ProxyServiceImpl proxyService;
    private final WanReplicationService wanReplicationService;
    private final PacketTransceiver packetTransceiver;
    private final QuorumServiceImpl quorumService;

    public NodeEngineImpl(Node node) {
        this.node = node;
        this.logger = node.getLogger(NodeEngine.class.getName());
        this.proxyService = new ProxyServiceImpl(this);
        this.serviceManager = new ServiceManagerImpl(this);
        this.executionService = new ExecutionServiceImpl(this);
        this.operationService = new OperationServiceImpl(this);
        this.eventService = new EventServiceImpl(this);
        this.waitNotifyService = new WaitNotifyServiceImpl(this);
        this.transactionManagerService = new TransactionManagerServiceImpl(this);
        this.wanReplicationService = node.getNodeExtension().createService(WanReplicationService.class);
        this.packetTransceiver = new PacketTransceiverImpl(
                node, logger, operationService, eventService, wanReplicationService, executionService);
        quorumService = new QuorumServiceImpl(this);
    }

    public PacketTransceiver getPacketTransceiver() {
        return packetTransceiver;
    }

    public void start() {
        serviceManager.start();
        proxyService.init();
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public MemberImpl getLocalMember() {
        return node.getLocalMember();
    }

    @Override
    public Config getConfig() {
        return node.getConfig();
    }

    @Override
    public ClassLoader getConfigClassLoader() {
        return node.getConfigClassLoader();
    }

    @Override
    public InternalEventService getEventService() {
        return eventService;
    }

    @Override
    public SerializationService getSerializationService() {
        return node.getSerializationService();
    }

    @Override
    public InternalOperationService getOperationService() {
        return operationService;
    }

    @Override
    public InternalExecutionService getExecutionService() {
        return executionService;
    }

    @Override
    public InternalPartitionService getPartitionService() {
        return node.getPartitionService();
    }

    @Override
    public ClusterService getClusterService() {
        return node.getClusterService();
    }

    public ManagementCenterService getManagementCenterService() {
        return node.getManagementCenterService();
    }

    @Override
    public InternalProxyService getProxyService() {
        return proxyService;
    }

    @Override
    public InternalWaitNotifyService getWaitNotifyService() {
        return waitNotifyService;
    }

    @Override
    public WanReplicationService getWanReplicationService() {
        return wanReplicationService;
    }

    @Override
    public QuorumServiceImpl getQuorumService() {
        return quorumService;
    }

    @Override
    public TransactionManagerService getTransactionManagerService() {
        return transactionManagerService;
    }

    @Override
    public Data toData(final Object object) {
        return node.getSerializationService().toData(object);
    }

    @Override
    public Object toObject(final Object object) {
        if (object instanceof Data) {
            return node.getSerializationService().toObject(object);
        }
        return object;
    }

    @Override
    public boolean isActive() {
        return node.isActive();
    }

    @Override
    public HazelcastInstance getHazelcastInstance() {
        return node.hazelcastInstance;
    }

    @Override
    public ILogger getLogger(String name) {
        return node.getLogger(name);
    }

    @Override
    public ILogger getLogger(Class clazz) {
        return node.getLogger(clazz);
    }

    @Override
    public GroupProperties getGroupProperties() {
        return node.getGroupProperties();
    }

    public <T> T getService(String serviceName) {
        return serviceManager.getService(serviceName);
    }

    @Override
    public <T extends SharedService> T getSharedService(String serviceName) {
        return serviceManager.getSharedService(serviceName);
    }

    
    public <S> Collection<S> getServices(Class<S> serviceClass) {
        return serviceManager.getServices(serviceClass);
    }

    public Collection<ServiceInfo> getServiceInfos(Class serviceClass) {
        return serviceManager.getServiceInfos(serviceClass);
    }

    public Node getNode() {
        return node;
    }

    public void onMemberLeft(MemberImpl member) {
        waitNotifyService.onMemberLeft(member);
        operationService.onMemberLeft(member);
        eventService.onMemberLeft(member);
    }

    public void onClientDisconnected(String clientUuid) {
        waitNotifyService.onClientDisconnected(clientUuid);
    }

    public void onPartitionMigrate(MigrationInfo migrationInfo) {
        waitNotifyService.onPartitionMigrate(getThisAddress(), migrationInfo);
    }

    
    public Operation[] getPostJoinOperations() {
        final Collection<Operation> postJoinOps = new LinkedList<Operation>();
        Operation eventPostJoinOp = eventService.getPostJoinOperation();
        if (eventPostJoinOp != null) {
            postJoinOps.add(eventPostJoinOp);
        }
        Collection<PostJoinAwareService> services = getServices(PostJoinAwareService.class);
        for (PostJoinAwareService service : services) {
            final Operation postJoinOperation = service.getPostJoinOperation();
            if (postJoinOperation != null) {
                if (postJoinOperation.getPartitionId() >= 0) {
                    logger.severe(
                            "Post-join operations cannot implement PartitionAwareOperation! Service: "
                                    + service + ", Operation: "
                                    + postJoinOperation);
                    continue;
                }
                postJoinOps.add(postJoinOperation);
            }
        }
        return postJoinOps.isEmpty() ? null : postJoinOps.toArray(new Operation[postJoinOps.size()]);
    }

    @Override
    public Storage<DataRef> getOffHeapStorage() {
        return node.getNodeExtension().getNativeDataStorage();
    }

    public void reset() {
        waitNotifyService.reset();
        operationService.reset();
    }

    public void shutdown(final boolean terminate) {
        logger.finest("Shutting down services...");
        waitNotifyService.shutdown();
        proxyService.shutdown();
        serviceManager.shutdown(terminate);
        eventService.shutdown();
        operationService.shutdown();
        wanReplicationService.shutdown();
        executionService.shutdown();
    }
}

<code block>


package com.hazelcast.spi.impl.servicemanager;

import com.hazelcast.spi.ServiceInfo;
import com.hazelcast.spi.SharedService;

import java.util.List;


public interface ServiceManager {

    
    ServiceInfo getServiceInfo(String serviceName);

    
    List<ServiceInfo> getServiceInfos(Class serviceClass);

    
    <T> T getService(String serviceName);

    
    <S> List<S> getServices(Class<S> serviceClass);

    
    <T extends SharedService> T getSharedService(String serviceName);
}

<code block>


package com.hazelcast.spi.impl.servicemanager.impl;

import com.hazelcast.cache.impl.ICacheService;
import com.hazelcast.client.impl.ClientEngineImpl;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.collection.impl.list.ListService;
import com.hazelcast.collection.impl.set.SetService;
import com.hazelcast.concurrent.atomiclong.AtomicLongService;
import com.hazelcast.concurrent.atomicreference.AtomicReferenceService;
import com.hazelcast.concurrent.countdownlatch.CountDownLatchService;
import com.hazelcast.concurrent.idgen.IdGeneratorService;
import com.hazelcast.concurrent.lock.LockService;
import com.hazelcast.concurrent.lock.LockServiceImpl;
import com.hazelcast.concurrent.semaphore.SemaphoreService;
import com.hazelcast.config.ServiceConfig;
import com.hazelcast.config.ServicesConfig;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.executor.impl.DistributedExecutorService;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.NodeExtension;
import com.hazelcast.logging.ILogger;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.mapreduce.impl.MapReduceService;
import com.hazelcast.multimap.impl.MultiMapService;
import com.hazelcast.nio.ClassLoaderUtil;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.collection.impl.queue.QueueService;
import com.hazelcast.quorum.impl.QuorumServiceImpl;
import com.hazelcast.replicatedmap.impl.ReplicatedMapService;
import com.hazelcast.ringbuffer.impl.RingbufferService;
import com.hazelcast.spi.ConfigurableService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.ServiceInfo;
import com.hazelcast.spi.SharedService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.proxyservice.impl.ProxyServiceImpl;
import com.hazelcast.spi.impl.servicemanager.ServiceManager;
import com.hazelcast.topic.impl.reliable.ReliableTopicService;
import com.hazelcast.topic.impl.TopicService;
import com.hazelcast.transaction.impl.xa.XAService;
import com.hazelcast.transaction.impl.TransactionManagerServiceImpl;
import java.lang.reflect.Constructor;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import static com.hazelcast.util.EmptyStatement.ignore;

public final class ServiceManagerImpl implements ServiceManager {

    private final NodeEngineImpl nodeEngine;
    private final ILogger logger;
    private final ConcurrentMap<String, ServiceInfo> services = new ConcurrentHashMap<String, ServiceInfo>(20, .75f, 1);

    public ServiceManagerImpl(final NodeEngineImpl nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.logger = nodeEngine.getLogger(ServiceManagerImpl.class);
    }

    public synchronized void start() {
        Map<String, Properties> serviceProps = new HashMap<String, Properties>();
        Map<String, Object> serviceConfigObjects = new HashMap<String, Object>();

        registerServices(serviceProps, serviceConfigObjects);
        initServices(serviceProps, serviceConfigObjects);
    }

    private void registerServices(Map<String, Properties> serviceProps, Map<String, Object> serviceConfigObjects) {
        registerCoreServices();

        Node node = nodeEngine.getNode();
        ServicesConfig servicesConfig = node.getConfig().getServicesConfig();
        if (servicesConfig != null) {
            registerDefaultServices(servicesConfig);
            registerUserServices(servicesConfig, serviceProps, serviceConfigObjects);
        }
    }

    private void registerCoreServices() {
        logger.finest("Registering core services...");

        Node node = nodeEngine.getNode();
        registerService(ClusterServiceImpl.SERVICE_NAME, node.getClusterService());
        registerService(InternalPartitionService.SERVICE_NAME, node.getPartitionService());
        registerService(ProxyServiceImpl.SERVICE_NAME, nodeEngine.getProxyService());
        registerService(TransactionManagerServiceImpl.SERVICE_NAME, nodeEngine.getTransactionManagerService());
        registerService(ClientEngineImpl.SERVICE_NAME, node.clientEngine);
        registerService(QuorumServiceImpl.SERVICE_NAME, nodeEngine.getQuorumService());
    }

    private void registerDefaultServices(ServicesConfig servicesConfig) {
        if (!servicesConfig.isEnableDefaults()) {
            return;
        }

        logger.finest("Registering default services...");
        registerService(MapService.SERVICE_NAME, createService(MapService.class));
        registerService(LockService.SERVICE_NAME, new LockServiceImpl(nodeEngine));
        registerService(QueueService.SERVICE_NAME, new QueueService(nodeEngine));
        registerService(TopicService.SERVICE_NAME, new TopicService());
        registerService(ReliableTopicService.SERVICE_NAME, new ReliableTopicService(nodeEngine));
        registerService(MultiMapService.SERVICE_NAME, new MultiMapService(nodeEngine));
        registerService(ListService.SERVICE_NAME, new ListService(nodeEngine));
        registerService(SetService.SERVICE_NAME, new SetService(nodeEngine));
        registerService(DistributedExecutorService.SERVICE_NAME, new DistributedExecutorService());
        registerService(AtomicLongService.SERVICE_NAME, new AtomicLongService());
        registerService(AtomicReferenceService.SERVICE_NAME, new AtomicReferenceService());
        registerService(CountDownLatchService.SERVICE_NAME, new CountDownLatchService());
        registerService(SemaphoreService.SERVICE_NAME, new SemaphoreService(nodeEngine));
        registerService(IdGeneratorService.SERVICE_NAME, new IdGeneratorService(nodeEngine));
        registerService(MapReduceService.SERVICE_NAME, new MapReduceService(nodeEngine));
        registerService(ReplicatedMapService.SERVICE_NAME, new ReplicatedMapService(nodeEngine));
        registerService(RingbufferService.SERVICE_NAME, new RingbufferService(nodeEngine));
        registerService(XAService.SERVICE_NAME, new XAService(nodeEngine));
        registerCacheServiceIfAvailable();
    }

    private <T> T createService(Class<T> service) {
        Node node = nodeEngine.getNode();
        NodeExtension nodeExtension = node.getNodeExtension();
        return nodeExtension.createService(service);
    }

    private void registerCacheServiceIfAvailable() {
        
        try {
            
            final String localClassName = "javax.cache.Caching";
            ClassLoader classLoader = nodeEngine.getConfigClassLoader();
            Class theClass = ClassLoaderUtil.loadClass(classLoader, localClassName);
            if (theClass != null) {
                ICacheService service = createService(ICacheService.class);
                registerService(ICacheService.SERVICE_NAME, service);
            }
        } catch (ClassNotFoundException e) {
            logger.finest("javax.cache api is not detected on classpath. Skipping CacheService...");
        }
    }

    private void initServices(Map<String, Properties> serviceProps, Map<String, Object> serviceConfigObjects) {
        for (ServiceInfo serviceInfo : services.values()) {
            initService(serviceProps, serviceConfigObjects, serviceInfo);
        }
    }

    private void initService(Map<String, Properties> serviceProps, Map<String, Object> serviceConfigObjects,
                             ServiceInfo serviceInfo) {
        final Object service = serviceInfo.getService();
        if (serviceInfo.isConfigurableService()) {
            try {
                if (logger.isFinestEnabled()) {
                    logger.finest("Configuring service -> " + service);
                }
                final Object configObject = serviceConfigObjects.get(serviceInfo.getName());
                ((ConfigurableService) service).configure(configObject);
            } catch (Throwable t) {
                logger.severe("Error while configuring service: " + t.getMessage(), t);
            }
        }
        if (serviceInfo.isManagedService()) {
            try {
                if (logger.isFinestEnabled()) {
                    logger.finest("Initializing service -> " + service);
                }
                final Properties props = serviceProps.get(serviceInfo.getName());
                ((ManagedService) service).init(nodeEngine, props != null ? props : new Properties());
            } catch (Throwable t) {
                logger.severe("Error while initializing service: " + t.getMessage(), t);
            }
        }
    }

    private void registerUserServices(ServicesConfig servicesConfig, Map<String, Properties> serviceProps,
                                      Map<String, Object> serviceConfigObjects) {
        logger.finest("Registering user defined services...");
        Collection<ServiceConfig> serviceConfigs = servicesConfig.getServiceConfigs();
        for (ServiceConfig serviceConfig : serviceConfigs) {
            registerUserService(serviceProps, serviceConfigObjects, serviceConfig);
        }
    }

    private void registerUserService(Map<String, Properties> serviceProps, Map<String, Object> serviceConfigObjects,
                                     ServiceConfig serviceConfig) {
        if (!serviceConfig.isEnabled()) {
            return;
        }

        Object service = serviceConfig.getServiceImpl();
        if (service == null) {
            service = createServiceObject(serviceConfig.getClassName());
        }
        if (service != null) {
            registerService(serviceConfig.getName(), service);
            serviceProps.put(serviceConfig.getName(), serviceConfig.getProperties());
            if (serviceConfig.getConfigObject() != null) {
                serviceConfigObjects.put(serviceConfig.getName(), serviceConfig.getConfigObject());
            }
        }
    }

    @SuppressWarnings("unchecked")
    private Object createServiceObject(String className) {
        try {
            ClassLoader classLoader = nodeEngine.getConfigClassLoader();
            Class serviceClass = ClassLoaderUtil.loadClass(classLoader, className);
            try {
                Constructor constructor = serviceClass.getConstructor(NodeEngine.class);
                return constructor.newInstance(nodeEngine);
            } catch (NoSuchMethodException ignored) {
                ignore(ignored);
            }
            return ClassLoaderUtil.newInstance(serviceClass, classLoader, className);
        } catch (Exception e) {
            logger.severe(e);
        }
        return null;
    }

    public synchronized void shutdown(boolean terminate) {
        logger.finest("Stopping services...");
        final List<ManagedService> managedServices = getServices(ManagedService.class);
        
        Collections.reverse(managedServices);
        services.clear();
        for (ManagedService service : managedServices) {
            shutdownService(service, terminate);
        }
    }

    private void shutdownService(final ManagedService service, final boolean terminate) {
        try {
            if (logger.isFinestEnabled()) {
                logger.finest("Shutting down service -> " + service);
            }
            service.shutdown(terminate);
        } catch (Throwable t) {
            logger.severe("Error while shutting down service[" + service + "]: " + t.getMessage(), t);
        }
    }

    private synchronized void registerService(String serviceName, Object service) {
        if (logger.isFinestEnabled()) {
            logger.finest("Registering service: '" + serviceName + "'");
        }
        final ServiceInfo serviceInfo = new ServiceInfo(serviceName, service);
        final ServiceInfo currentServiceInfo = services.putIfAbsent(serviceName, serviceInfo);
        if (currentServiceInfo != null) {
            logger.warning("Replacing " + currentServiceInfo + " with " + serviceInfo);
            if (currentServiceInfo.isCoreService()) {
                throw new HazelcastException("Can not replace a CoreService! Name: " + serviceName
                        + ", Service: " + currentServiceInfo.getService());
            }
            if (currentServiceInfo.isManagedService()) {
                shutdownService((ManagedService) currentServiceInfo.getService(), false);
            }
            services.put(serviceName, serviceInfo);
        }
    }

    @Override
    public ServiceInfo getServiceInfo(String serviceName) {
        return services.get(serviceName);
    }

    @Override
    public <S> List<S> getServices(Class<S> serviceClass) {
        final LinkedList<S> result = new LinkedList<S>();
        for (ServiceInfo serviceInfo : services.values()) {
            if (serviceInfo.isInstanceOf(serviceClass)) {
                final S service = (S) serviceInfo.getService();
                if (serviceInfo.isCoreService()) {
                    result.addFirst(service);
                } else {
                    result.addLast(service);
                }
            }
        }
        return result;
    }

    @Override
    public <T> T getService(String serviceName) {
        final ServiceInfo serviceInfo = getServiceInfo(serviceName);
        return serviceInfo != null ? (T) serviceInfo.getService() : null;
    }

    @Override
    public <T extends SharedService> T getSharedService(String serviceName) {
        final Object service = getService(serviceName);
        if (service == null) {
            return null;
        }

        if (service instanceof SharedService) {
            return (T) service;
        }

        throw new IllegalArgumentException("No SharedService registered with name: " + serviceName);
    }

    
    @Override
    public List<ServiceInfo> getServiceInfos(Class serviceClass) {
        final LinkedList<ServiceInfo> result = new LinkedList<ServiceInfo>();
        for (ServiceInfo serviceInfo : services.values()) {
            if (serviceInfo.isInstanceOf(serviceClass)) {
                if (serviceInfo.isCoreService()) {
                    result.addFirst(serviceInfo);
                } else {
                    result.addLast(serviceInfo);
                }
            }
        }
        return result;
    }
}

<code block>
package com.hazelcast.spi.impl.servicemanager.impl;

import com.hazelcast.concurrent.lock.LockService;
import com.hazelcast.config.Config;
import com.hazelcast.config.ServiceConfig;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.spi.ConfigurableService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.ServiceInfo;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.swing.*;
import java.util.List;
import java.util.Properties;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class ServiceManagerImplTest extends HazelcastTestSupport {

    private ServiceManagerImpl serviceManager;

    @Before
    public void setup() {
        Config config = new Config();

        ServiceConfig serviceConfig = new ServiceConfig()
                .setClassName(FooService.class.getName())
                .setEnabled(true)
                .setName("fooService");
        config.getServicesConfig().addServiceConfig(serviceConfig);

        HazelcastInstance hz = createHazelcastInstance(config);
        NodeEngineImpl nodeEngine = getNodeEngineImpl(hz);
        serviceManager = new ServiceManagerImpl(nodeEngine);
        serviceManager.start();
    }

    static class FooService implements ManagedService, ConfigurableService{
        volatile boolean initCalled;
        volatile boolean configureCalled;

        @Override
        public void configure(Object configObject) {
            this.configureCalled = true;
        }

        @Override
        public void init(NodeEngine nodeEngine, Properties properties) {
            this.initCalled = true;
        }

        @Override
        public void reset() {

        }

        @Override
        public void shutdown(boolean terminate) {

        }
    }

    


    @Test
    public void getServiceInfo() {
        ServiceInfo result = serviceManager.getServiceInfo(MapService.SERVICE_NAME);
        assertNotNull(result);
        assertEquals(MapService.SERVICE_NAME, result.getName());
        assertInstanceOf(MapService.class, result.getService());
    }

    @Test
    public void getServiceInfo_notExisting() {
        ServiceInfo result = serviceManager.getServiceInfo("notexisting");
        assertNull(result);
    }

    

    @Test
    public void getServiceInfos() {
        List<ServiceInfo> result = serviceManager.getServiceInfos(MapService.class);
        assertNotNull(result);
        assertEquals(1, result.size());

        ServiceInfo serviceInfo = result.get(0);
        assertEquals(MapService.SERVICE_NAME, serviceInfo.getName());
        assertInstanceOf(MapService.class, serviceInfo.getService());
    }

    @Test
    public void getServiceInfos_notExisting() {
        List<ServiceInfo> result = serviceManager.getServiceInfos(JPanel.class);
        assertNotNull(result);
        assertEquals(0, result.size());
    }

    

    @Test
    public void getService() {
        Object result = serviceManager.getService(MapService.SERVICE_NAME);
        assertInstanceOf(MapService.class, result);
    }

    @Test
    public void getService_notExisting() {
        Object result = serviceManager.getService("notexisting");
        assertNull(result);
    }

    

    @Test
    public void getSharedService() {
        Object result = serviceManager.getSharedService(LockService.SERVICE_NAME);
        assertInstanceOf(LockService.class, result);
    }

    @Test
    public void getSharedService_notExisting() {
        Object result = serviceManager.getSharedService("notexisting");
        assertNull(result);
    }

    @Test(expected = IllegalArgumentException.class)
    public void getSharedService_notSharedService() {
        serviceManager.getSharedService(MapService.SERVICE_NAME);
    }

    

    @Test
    public void getServices() {
        List<MapService> result = serviceManager.getServices(MapService.class);
        assertNotNull(result);
        assertEquals(1, result.size());
        assertInstanceOf(MapService.class, result.get(0));
    }

    @Test
    public void getServices_notExisting() {
        List<JPanel> result = serviceManager.getServices(JPanel.class);
        assertNotNull(result);
        assertTrue(result.isEmpty());
    }

    

    @Test
    public void userService() {
        Object result = serviceManager.getService("fooService");
        FooService fooService = assertInstanceOf(FooService.class, result);

        assertTrue(fooService.initCalled);
        assertTrue(fooService.configureCalled);
    }
}

<code block>


package com.hazelcast.jca;

import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;

import javax.naming.NamingException;
import javax.naming.Reference;
import javax.resource.ResourceException;
import javax.resource.cci.ConnectionSpec;
import javax.resource.cci.RecordFactory;
import javax.resource.cci.ResourceAdapterMetaData;
import javax.resource.spi.ConnectionManager;
import java.util.concurrent.atomic.AtomicInteger;


public class ConnectionFactoryImpl implements HazelcastConnectionFactory {
    
    private static final AtomicInteger ID_GEN = new AtomicInteger();
    
    private static final ILogger LOGGER = Logger.getLogger("com.hazelcast.jca");
    
    private static final long serialVersionUID = -5909363703528221650L;
    
    private ManagedConnectionFactoryImpl mcf;
    
    private ConnectionManager cm;
    
    private Reference ref;

    private transient int id;

    public ConnectionFactoryImpl() {
        setId(ID_GEN.incrementAndGet());
    }

    public ConnectionFactoryImpl(ManagedConnectionFactoryImpl mcf, ConnectionManager cm) {
        this();
        this.mcf = mcf;
        this.cm = cm;
    }

    
    public HazelcastConnection getConnection() throws ResourceException {
        LOGGER.finest("getConnection");
        return this.getConnection(null);
    }

    
    public HazelcastConnection getConnection(ConnectionSpec connSpec) throws ResourceException {
        if (LOGGER.isFinestEnabled()) {
            LOGGER.finest("getConnection spec: " + connSpec);
        }
        return (HazelcastConnectionImpl) cm.allocateConnection(mcf, null);
    }

    
    public ResourceAdapterMetaData getMetaData() throws ResourceException {
        return new ConnectionFactoryMetaData();
    }

    
    public RecordFactory getRecordFactory() throws ResourceException {
        return null;
    }

    
    public void setReference(Reference ref) {
        this.ref = ref;
    }

    
    public Reference getReference() throws NamingException {
        return ref;
    }

    @Override
    public String toString() {
        return "hazelcast.ConnectionFactoryImpl [" + id + "]";
    }

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + id;
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj) {
            return true;
        }
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        ConnectionFactoryImpl other = (ConnectionFactoryImpl) obj;
        if (id != other.id) {
            return false;
        }
        return true;
    }

    public void setId(int id) {
        this.id = id;
    }


}

<code block>


package com.hazelcast.jca;

import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.BeforeClass;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

@Category(QuickTest.class)
@RunWith(HazelcastSerialClassRunner.class)
public class HazelcastConnectionContractTest {

    static HazelcastConnectionImpl connection;

    @BeforeClass
    public static void setup() {
       connection = new HazelcastConnectionImpl(null,null);
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testGetLifecycleService() {
        connection.getLifecycleService();
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testShutdown() {
        connection.shutdown();
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testExecuteTransaction() {
        connection.executeTransaction(null);
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testExecuteTransactionTwoArgs() {
        connection.executeTransaction(null,null);
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testNewTransactionContext() {
        connection.newTransactionContext();
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testNewTransactionContext2() {
        connection.newTransactionContext(null);
    }
}
<code block>


package com.hazelcast.jca;

import com.hazelcast.core.TransactionalMap;
import com.hazelcast.test.annotation.SlowTest;
import org.h2.jdbcx.JdbcConnectionPool;
import org.jboss.arquillian.junit.Arquillian;
import org.junit.BeforeClass;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.naming.InitialContext;
import javax.naming.NamingException;
import javax.resource.cci.LocalTransaction;
import javax.sql.DataSource;
import javax.transaction.UserTransaction;
import java.sql.Connection;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;



@RunWith(Arquillian.class)
@Category(SlowTest.class)
public class XATransactionTest extends AbstractDeploymentTest {

    private static HazelcastConnectionFactory connectionFactory;

    private static UserTransaction userTx;

    private static DataSource h2Datasource;

    private static boolean isDbInit = false;

    @BeforeClass
    public static void init() throws SQLException, NamingException {
        InitialContext context = new InitialContext();
        userTx = (UserTransaction) context.lookup("java:comp/UserTransaction");
        connectionFactory = (HazelcastConnectionFactory) context.lookup ( "HazelcastCF" );
        if (!isDbInit) {
            isDbInit = true;

            h2Datasource = JdbcConnectionPool.create("jdbc:h2:mem:test", "sa", "sa");

            Connection con = h2Datasource.getConnection();
            Statement stmt = null;
            try {
                stmt = con.createStatement();
                stmt.execute("create table TEST (A varchar(3))");
            } finally {
                if (stmt != null) {
                    stmt.close();
                }
                con.close();
            }
        }
    }

    @Test
    public void testTransactionCommit() throws Throwable {
        userTx.begin();
        HazelcastConnection c = getConnection();
        try {
            TransactionalMap<String, String> m = c.getTransactionalMap("testTransactionCommit");
            m.put("key", "value");
            doSql();
            assertEquals("value", m.get("key"));
        } finally {
            c.close();
        }
        userTx.commit();
        HazelcastConnection con2 = getConnection();

        try {
            assertEquals("value", con2.getMap("testTransactionCommit").get("key"));
            validateSQLdata(true);
        } finally {
            con2.close();
        }
    }

    @Test
    public void testTransactionRollback() throws Throwable {
        userTx.begin();

        HazelcastConnection c = getConnection();
        try {
            TransactionalMap<String, String> m = c.getTransactionalMap("testTransactionRollback");
            m.put("key", "value");
            assertEquals("value", m.get("key"));
            doSql();
        } finally {
            c.close();
        }

        userTx.rollback();
        HazelcastConnection con2 = getConnection();
        try {
            assertEquals(null, con2.getMap("testTransactionRollback").get("key"));
            validateSQLdata(false);
        } finally {
            con2.close();
        }
    }

    @Test
    public void testLocalTransaction() throws Throwable {
        HazelcastConnection c = getConnection();
        LocalTransaction lt = c.getLocalTransaction();
        lt.begin();
        try {
            TransactionalMap<String, String> m = c.getTransactionalMap("testTransactionCommit");
            m.put("key", "value");
            doSql();
            assertEquals("value", m.get("key"));
        } finally {
            c.close();
        }
        lt.commit();
        HazelcastConnection con2 = getConnection();

        try {
            assertEquals("value", con2.getMap("testTransactionCommit").get("key"));
        } finally {
            con2.close();
        }
    }

    protected HazelcastConnection getConnection() throws Throwable{
        assertNotNull(connectionFactory);
        HazelcastConnection c = connectionFactory.getConnection();
        assertNotNull(c);
        return c;
    }

    protected void doSql() throws NamingException, SQLException {

        Connection con = h2Datasource.getConnection();
        Statement stmt = null;
        try {
            stmt = con.createStatement();
            stmt.execute("INSERT INTO TEST VALUES ('txt')");
        } finally {
            if (stmt != null) {
                stmt.close();
            }
            con.close();
        }
    }

    protected void validateSQLdata(boolean hasdata) throws NamingException, SQLException {

        Connection con = h2Datasource.getConnection();
        Statement stmt = null;

        try {
            stmt = con.createStatement();

            ResultSet resultSet = null;
            try {
                resultSet = stmt.executeQuery("SELECT * FROM TEST");

            } catch (SQLException e) {
            }
            if (hasdata) {
                assertNotNull(resultSet);
                assertTrue(resultSet.first());
                assertEquals("txt", resultSet.getString("A"));
            } else {
                assertTrue(resultSet == null || resultSet.getFetchSize() == 0);
            }

        } finally {
            if (stmt != null) {
                stmt.close();
            }
            con.close();
        }
    }


}

<code block>


package com.hazelcast.jca;

import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.DistributedObjectListener;

import javax.ejb.Local;
import javax.resource.ResourceException;
import javax.resource.cci.LocalTransaction;
import java.util.Collection;

@Local
public interface ITestBean {
    void insertToMap(String mapname, String key, String value);

    String getFromMap(String mapname, String key);

    void offerToQueue(String queuename, String key);

    String pollFromQueue(String queuename);

    void insertToSet(String setname, String key);

    boolean removeFromSet(String setname, String key);

    int getSetSize(String setname);

    void addToList(String listname, String key);

    boolean removeFromList(String listname, String key);

    int getListSize(String listname);

    void addDistributedObjectListener(DistributedObjectListener obj);

    void removeDistributedObjectListener(String regId);

    Collection<DistributedObject> getDistributedObjects();
}

<code block>


package com.hazelcast.jca;

import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.DistributedObjectListener;
import com.hazelcast.core.TransactionalList;
import com.hazelcast.core.TransactionalMap;
import com.hazelcast.core.TransactionalQueue;
import com.hazelcast.core.TransactionalSet;

import javax.annotation.Resource;
import javax.ejb.Stateful;
import javax.resource.ResourceException;
import javax.resource.cci.ConnectionFactory;
import java.util.Collection;
import java.util.logging.Level;
import java.util.logging.Logger;

@Stateful
public class TestBean implements ITestBean {
    private final static Logger log = Logger.getLogger(TestBean.class.getName());

    @Resource(mappedName = "HazelcastCF")
    protected ConnectionFactory connectionFactory;

    @Override
    public void insertToMap(String mapname, String key, String value) {
        HazelcastConnection hzConn = null;
        try {
            hzConn = getConnection();
            TransactionalMap<String,String> txmap = hzConn.getTransactionalMap(mapname);
            txmap.put(key, value);
        } finally {
            closeConnection(hzConn);
        }
    }

    @Override
    public String getFromMap(String mapname, String key) {
        HazelcastConnection hzConn = null;
        try {
            hzConn = getConnection();
            TransactionalMap<String,String> txmap = hzConn.getTransactionalMap(mapname);
            return txmap.get(key);
        } finally {
            closeConnection(hzConn);
        }
    }

    @Override
    public void offerToQueue(String queuename, String key) {
        HazelcastConnection hzConn = null;
        try {
            hzConn = getConnection();
            TransactionalQueue<String> txqueue = hzConn.getTransactionalQueue(queuename);
            txqueue.offer(key);
        } finally {
            closeConnection(hzConn);
        }
    }

    @Override
    public String pollFromQueue(String queuename) {
        HazelcastConnection hzConn = null;
        try {
            hzConn = getConnection();
            TransactionalQueue<String> txqueue = hzConn.getTransactionalQueue(queuename);
            return txqueue.poll();
        } finally {
            closeConnection(hzConn);
        }
    }

    @Override
    public void insertToSet(String setname, String key) {
        HazelcastConnection hzConn = null;
        try {
            hzConn = getConnection();
            TransactionalSet<String> txset = hzConn.getTransactionalSet(setname);
            txset.add(key);
        } finally {
            closeConnection(hzConn);
        }
    }

    @Override
    public boolean removeFromSet(String setname, String key) {
        HazelcastConnection hzConn = null;
        try {
            hzConn = getConnection();
            TransactionalSet<String> txset = hzConn.getTransactionalSet(setname);
            return txset.remove(key);
        } finally {
            closeConnection(hzConn);
        }
    }

    @Override
    public int getSetSize(String setname) {
        HazelcastConnection hzConn = null;
        try {
            hzConn = getConnection();
            TransactionalSet<String> txset = hzConn.getTransactionalSet(setname);
            return txset.size();
        } finally {
            closeConnection(hzConn);
        }
    }

    @Override
    public void addToList(String listname, String key) {
        HazelcastConnection hzConn = null;
        try {
            hzConn = getConnection();
            TransactionalList<String> txlist = hzConn.getTransactionalList(listname);
            txlist.add(listname);
        } finally {
            closeConnection(hzConn);
        }
    }

    @Override
    public boolean removeFromList(String listname, String key) {
        HazelcastConnection hzConn = null;
        boolean retVal = false;
        try {
            hzConn = getConnection();
            TransactionalList<String> txlist = hzConn.getTransactionalList(listname);
            retVal = txlist.remove(key);
        } finally {
            closeConnection(hzConn);
        }
        return retVal;
    }

    @Override
    public int getListSize(String listname) {
        HazelcastConnection hzConn = null;
        try {
            hzConn = getConnection();
            TransactionalList<String> txlist = hzConn.getTransactionalList(listname);
            return txlist.size();
        } finally {
            closeConnection(hzConn);
        }
    }

    @Override
    public void addDistributedObjectListener(DistributedObjectListener obj) {
        getConnection().addDistributedObjectListener(obj);
    }

    @Override
    public void removeDistributedObjectListener(String regId) {
        getConnection().removeDistributedObjectListener(regId);
    }

    @Override
    public Collection<DistributedObject> getDistributedObjects() {
        return getConnection().getDistributedObjects();
    }

    private HazelcastConnection getConnection() {
        try {
            return (HazelcastConnection) connectionFactory.getConnection();
        } catch (ResourceException e) {
            throw new RuntimeException("Error while getting Hazelcast connection", e);
        }
    }

    private void closeConnection(HazelcastConnection hzConn) {
        if (hzConn != null) {
            try {
                hzConn.close();
            } catch (ResourceException e) {
                log.log(Level.WARNING, "Error while closing Hazelcast connection.", e);
            }
        }
    }
}
<code block>


package com.hazelcast.jca;

import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.naming.NamingException;
import javax.naming.Reference;
import javax.resource.Referenceable;
import java.io.Serializable;

import static org.junit.Assert.assertSame;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class ConnectionFactoryImplTest extends HazelcastTestSupport {

    private HazelcastConnectionFactory connectionFactory;
    private Reference ref;

    @Before
    public void setup() throws Exception {
        connectionFactory = new ConnectionFactoryImpl();
        ref = new Reference(randomString());
        connectionFactory.setReference(ref);
    }

    @Test
    public void testJNDI() throws NamingException {
        assertSame(ref,connectionFactory.getReference());
        assertTrue(connectionFactory instanceof Referenceable);
        assertTrue(connectionFactory instanceof Serializable);
    }
}

<code block>


package com.hazelcast.jca;

import org.jboss.arquillian.container.test.api.Deployment;
import org.jboss.shrinkwrap.api.ShrinkWrap;
import org.jboss.shrinkwrap.api.asset.EmptyAsset;
import org.jboss.shrinkwrap.api.spec.JavaArchive;
import org.jboss.shrinkwrap.api.spec.ResourceAdapterArchive;
import org.jboss.shrinkwrap.api.spec.WebArchive;


public class AbstractDeploymentTest {

    @Deployment(testable = false, name = "rar-deployment", order = 1)
    public static ResourceAdapterArchive createResourceAdapterDeployment() {
        ResourceAdapterArchive raa = ShrinkWrap.create(ResourceAdapterArchive.class, "raa.rar");

        raa.addAsResource("ra.xml", "META-INF/ra.xml");
        raa.addAsResource("ironjacamar.xml", "META-INF/ironjacamar.xml");
        raa.addAsResource("sun-ra.xml", "META-INF/sun-ra.xml");

        return raa;
    }

    @Deployment(name = "war-deployment", order = 2)
    public static WebArchive createWebDeployment() {
        WebArchive wa = ShrinkWrap.create(WebArchive.class, "waa.war");
        wa.addAsResource("h2-xa-ds.xml","h2-xa-ds.xml");
        wa.addClass(TestBean.class);
        wa.addClass(ITestBean.class);
        wa.addClass(TestInContainer.class);
        wa.add(EmptyAsset.INSTANCE, "WEB-INF/beans.xml");

        return wa;
    }
}
<code block>

package com.hazelcast.jca;

import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.IMap;
import com.hazelcast.core.IQueue;
import com.hazelcast.core.MultiMap;
import com.hazelcast.core.TransactionalList;
import com.hazelcast.core.TransactionalMap;
import com.hazelcast.core.TransactionalMultiMap;
import com.hazelcast.core.TransactionalQueue;
import com.hazelcast.core.TransactionalSet;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import com.hazelcast.transaction.impl.xa.SerializableXID;
import com.hazelcast.util.ExceptionUtil;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.resource.ResourceException;
import javax.resource.spi.ConnectionEvent;
import javax.resource.spi.ConnectionEventListener;
import javax.resource.spi.ConnectionManager;
import javax.resource.spi.ConnectionRequestInfo;
import javax.resource.spi.ManagedConnection;
import javax.resource.spi.ManagedConnectionFactory;
import javax.transaction.xa.XAException;
import javax.transaction.xa.XAResource;
import javax.transaction.xa.Xid;
import java.util.Collection;
import java.util.List;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class XATestWithJCA extends HazelcastTestSupport {

    private HazelcastConnection connection;
    private HazelcastInstance instance;

    @Before
    public void setup() throws Exception {
        instance = createHazelcastInstance();
        ResourceAdapterImpl resourceAdapter = new ResourceAdapterImpl();
        resourceAdapter.setHazelcastInstance(instance);
        ManagedConnectionFactoryImpl managedConnectionFactory = new ManagedConnectionFactoryImpl();
        managedConnectionFactory.setResourceAdapter(resourceAdapter);
        managedConnectionFactory.setConnectionTracingDetail(true);
        managedConnectionFactory.setConnectionTracingEvents("FACTORY_INIT, CREATE, TX_START, TX_COMPLETE, CLEANUP, DESTROY");
        TestConnectionManager connectionManager = new TestConnectionManager();
        ConnectionFactoryImpl factory = new ConnectionFactoryImpl(managedConnectionFactory, connectionManager);
        connection = factory.getConnection();
    }

    @Test
    public void testPut() throws ResourceException {
        String name = randomString();
        String key = randomString();
        String val = randomString();

        TransactionalMap<String, String> map = connection.getTransactionalMap(name);
        map.put(key, val);
        connection.close();

        IMap<String, String> m = instance.getMap(name);
        assertEquals(val, m.get(key));
    }

    @Test
    public void testTransactionalQueueShouldPollWhatWasOffered() throws ResourceException {
        String name = randomString();
        String item = randomString();

        TransactionalQueue<String> queue = connection.getTransactionalQueue(name);
        queue.offer(item);

        connection.close();

        IQueue<String> q = instance.getQueue(name);
        assertEquals(item,q.poll());
    }

    @Test
    public void testTransactionalMultiMapShouldHaveWhatIsInserted() throws ResourceException {
        String name = randomString();
        String key = randomString();
        String val1 = randomString();
        String val2 = randomString();

        TransactionalMultiMap<String, String> multiMap = connection.getTransactionalMultiMap(name);
        multiMap.put(key,val1);
        multiMap.put(key,val2);

        connection.close();

        MultiMap<String, String> m = instance.getMultiMap(name);
        Collection<String> vals = m.get(key);
        assertTrue(vals.contains(val1));
        assertTrue(vals.contains(val2));
        assertEquals(vals.size(), 2);
    }

    @Test
    public void testTransactionalListShouldHaveWhatIsInserted() throws ResourceException {
        String name = randomString();
        String item = randomString();

        TransactionalList<String> list = connection.getTransactionalList(name);
        list.add(item);

        connection.close();

        List<String> l = instance.getList(name);
        assertEquals(item,l.get(0));
    }


    @Test
    public void testTransactionalSetShouldHaveWhatIsInserted() throws ResourceException {
        String name = randomString();
        String item = randomString();

        TransactionalSet<String> set = connection.getTransactionalSet(name);
        set.add(item);

        connection.close();

        Set<String> s = instance.getSet(name);
        assertTrue(s.contains(item));
    }

    static class TestConnectionManager implements ConnectionManager, ConnectionEventListener {

        ConcurrentMap<HazelcastConnection, Xid> transactionIdMap = new ConcurrentHashMap<HazelcastConnection, Xid>();

        private static Xid createXid() {
            String s = randomString();
            return new SerializableXID(s.length(), s.getBytes(), s.getBytes());
        }

        @Override
        public Object allocateConnection(ManagedConnectionFactory mcf, ConnectionRequestInfo cxRequestInfo)
                throws ResourceException {
            ManagedConnection managedConnection = mcf.createManagedConnection(null, cxRequestInfo);
            XAResource xaResource = managedConnection.getXAResource();
            managedConnection.addConnectionEventListener(this);
            Xid xid = createXid();
            try {
                xaResource.start(xid, XAResource.TMNOFLAGS);
            } catch (XAException e) {
                throw ExceptionUtil.rethrow(e);
            }
            HazelcastConnection connection = (HazelcastConnection) managedConnection.getConnection(null, cxRequestInfo);
            transactionIdMap.put(connection, xid);
            return connection;
        }

        @Override
        public void connectionClosed(ConnectionEvent event) {
            ManagedConnection managedConnection = (ManagedConnection) event.getSource();
            HazelcastConnection connection = (HazelcastConnection) event.getConnectionHandle();
            Xid xid = transactionIdMap.remove(connection);
            try {
                XAResource xaResource = managedConnection.getXAResource();
                xaResource.end(xid, XAResource.TMSUCCESS);

                xaResource.commit(xid, true);
            } catch (Exception e) {
                throw ExceptionUtil.rethrow(e);
            }

        }

        @Override
        public void localTransactionStarted(ConnectionEvent event) {

        }

        @Override
        public void localTransactionCommitted(ConnectionEvent event) {

        }

        @Override
        public void localTransactionRolledback(ConnectionEvent event) {

        }

        @Override
        public void connectionErrorOccurred(ConnectionEvent event) {

        }

    }

}

<code block>


package com.hazelcast.jca;

import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.resource.ResourceException;
import javax.resource.spi.ConnectionRequestInfo;
import javax.resource.spi.ManagedConnection;
import javax.resource.spi.ManagedConnectionFactory;
import java.util.Arrays;
import java.util.HashSet;

import static org.junit.Assert.*;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.when;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class ManagedConnectionFactoryImplTest extends HazelcastTestSupport {

    private ManagedConnectionFactory connectionFactory;

    @Before
    public void setup() throws Exception {
        connectionFactory = new ManagedConnectionFactoryImpl();
    }

    @Test
    public void testSetConnectionTracingEvents() {
        ManagedConnectionFactoryImpl fact = (ManagedConnectionFactoryImpl)connectionFactory;
        String controlStr = "DESTROY,  TX_START  , CLEANUP,TX_COMPLETE";

        fact.setConnectionTracingEvents(controlStr);
        String[] returnItems = delimitedStringToArray(fact.getConnectionTracingEvents(), ",");
        String[] controlItems = delimitedStringToArray(controlStr, ",");

        Arrays.sort(controlItems);
        Arrays.sort(returnItems);

        assertArrayEquals(controlItems, returnItems);
    }

    @Test
    public void testMatchExistingManagedConnection() throws ResourceException {
        ResourceAdapterImpl mockResourceAdapter = mock(ResourceAdapterImpl.class);
        when(mockResourceAdapter.getHazelcastInstance()).thenReturn(null);
        ((ManagedConnectionFactoryImpl)connectionFactory).setResourceAdapter(mockResourceAdapter);

        ((ManagedConnectionFactoryImpl)connectionFactory).setConnectionTracingEvents(null);

        HashSet<ManagedConnection> managedConnections = new HashSet<ManagedConnection>();
        for (int i=0; i < 9; i++) {
            ConnectionRequestInfo cxInfo = mock(ConnectionRequestInfo.class);
            managedConnections.add(connectionFactory.createManagedConnection(null,cxInfo));
        }
        ManagedConnection nullSecurityConnection = connectionFactory.createManagedConnection(null, null);
        managedConnections.add(nullSecurityConnection);

        ManagedConnection retConnection = connectionFactory.matchManagedConnections(managedConnections, null, null);
        assertSame(retConnection, nullSecurityConnection);
    }

    private String[] delimitedStringToArray(String str, String delimiter) {
        str = str.trim();
        if (str.startsWith("[")) {
            str = str.substring(1);
        }
        if (str.endsWith("]")) {
            str = str.substring(0,str.length()-1);
        }
        String ret[] = str.split(delimiter);
        for (int i=0; i< ret.length; i++) {
            ret[i] = ret[i].trim();
        }
        return ret;
    }
}

<code block>


package com.hazelcast.jca;

import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.resource.ResourceException;
import javax.resource.spi.ConnectionEvent;
import javax.resource.spi.ConnectionEventListener;
import javax.resource.spi.ManagedConnection;

import static org.mockito.Matchers.any;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.verifyZeroInteractions;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class HazelcastTransactionImplTest extends HazelcastTestSupport{

    private HazelcastInstance instance;
    private HazelcastTransaction transaction;
    private ManagedConnection managedConnection;
    private ConnectionEventListener mockEventListener;

    @Before
    public void setup() throws ResourceException {
        instance = createHazelcastInstance();
        ResourceAdapterImpl resourceAdapter = new ResourceAdapterImpl();
        resourceAdapter.setHazelcastInstance(instance);
        ManagedConnectionFactoryImpl managedConnectionFactory = new ManagedConnectionFactoryImpl();
        managedConnectionFactory.setResourceAdapter(resourceAdapter);
        managedConnectionFactory.setConnectionTracingEvents(null);
        mockEventListener = mock(ConnectionEventListener.class);
        managedConnection = managedConnectionFactory.createManagedConnection(null, null);
        managedConnection.addConnectionEventListener(mockEventListener);
        transaction = new HazelcastTransactionImpl(managedConnectionFactory, (ManagedConnectionImpl) managedConnection);
    }

    @Test
    @Ignore
    public void testTransactionBeginShouldFireEventHandler() throws ResourceException {
        transaction.begin();
        verify(mockEventListener).localTransactionStarted(any(ConnectionEvent.class));
    }

    @Test
    public void testTransactionCommitShouldFireEventHandler() throws ResourceException {
        transaction.begin();
        transaction.commit();
        verify(mockEventListener).localTransactionCommitted(any(ConnectionEvent.class));
    }

    @Test
    public void testTransactionRollbackShouldFireEventHandler() throws ResourceException {
        transaction.begin();
        transaction.rollback();
        verify(mockEventListener).localTransactionRolledback(any(ConnectionEvent.class));
        verifyZeroInteractions(mockEventListener);
    }

    @Test
    public void testTransactionCommitShouldNotFireRemovedEventListener() throws ResourceException {
        managedConnection.removeConnectionEventListener(mockEventListener);
        transaction.begin();
        transaction.commit();
        verifyZeroInteractions(mockEventListener);
    }

}
<code block>


package com.hazelcast.jca;

import com.hazelcast.config.Config;
import com.hazelcast.core.ClientService;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.Endpoint;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.IAtomicLong;
import com.hazelcast.core.IAtomicReference;
import com.hazelcast.core.IList;
import com.hazelcast.core.ILock;
import com.hazelcast.core.IMap;
import com.hazelcast.core.IQueue;
import com.hazelcast.core.ISemaphore;
import com.hazelcast.core.ITopic;
import com.hazelcast.core.IdGenerator;
import com.hazelcast.core.MultiMap;
import com.hazelcast.core.PartitionService;
import com.hazelcast.core.ReplicatedMap;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.mapreduce.JobTracker;
import com.hazelcast.quorum.QuorumService;
import com.hazelcast.ringbuffer.Ringbuffer;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.transaction.xa.XAResource;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ExecutorService;

import static org.junit.Assert.assertNotSame;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertSame;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.when;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class HazelcastConnectionImplTest extends HazelcastTestSupport {

    private HazelcastInstance hz;
    private HazelcastConnectionImpl connection;

    @Before
    public void setup() {
        hz = createHazelcastInstance();
        ManagedConnectionImpl managedConnection = mock(ManagedConnectionImpl.class);
        when(managedConnection.getHazelcastInstance()).thenReturn(hz);
        connection = new HazelcastConnectionImpl(managedConnection, null);
    }

    @Test
    public void getRingbuffer() {
        Ringbuffer rb = connection.getRingbuffer("ringbuffer");
        assertSame(hz.getRingbuffer("ringbuffer"), rb);
    }

    @Test
    public void getReliableTopic() {
        ITopic topic = connection.getReliableTopic("reliableTopic");
        assertSame(hz.getReliableTopic("reliableTopic"), topic);
    }

    @Test
    public void getTopic() {
        ITopic topic = connection.getTopic("reliableTopic");
        assertSame(hz.getTopic("reliableTopic"), topic);
    }

    @Test
    public void getMap() {
        IMap topic = connection.getMap("map");
        assertSame(hz.getMap("map"), topic);
    }

    @Test
    public void getQueue() {
        IQueue queue = connection.getQueue("queue");
        assertSame(hz.getQueue("queue"), queue);
    }

    @Test
    public void getMultiMap() {
        MultiMap multiMap = connection.getMultiMap("multiMap");
        assertSame(hz.getMultiMap("multiMap"), multiMap);
    }

    @Test
    public void getReplicatedMap() {
        ReplicatedMap replicatedMap = connection.getReplicatedMap("replicatedMap");
        assertSame(hz.getReplicatedMap("replicatedMap"), replicatedMap);
    }

    @Test
    public void getSet() {
        Set set = connection.getSet("set");
        assertSame(hz.getSet("set"), set);
    }

    @Test
    public void getList() {
        IList list = connection.getList("list");
        assertSame(hz.getList("list"), list);
    }

    @Test
    public void getSemaphore() {
        ISemaphore semaphore = connection.getSemaphore("s");
        assertSame(hz.getSemaphore("s"), semaphore);
    }

    @Test
    public void getLock() {
        ILock lock = connection.getLock("lock");
        assertSame(hz.getLock("lock"), lock);
    }

    @Test
    public void getExecutorService() {
        ExecutorService ex = connection.getExecutorService("ex");
        assertSame(hz.getExecutorService("ex"), ex);
    }

    @Test
    public void getAtomicLong() {
        IAtomicLong atomicLong = connection.getAtomicLong("atomicLong");
        assertSame(hz.getAtomicLong("atomicLong"), atomicLong);
    }

    @Test
    public void getIdGenerator() {
        IdGenerator idGenerator = connection.getIdGenerator("id");
        assertSame(hz.getIdGenerator("id"), idGenerator);
    }

    @Test
    public void getDistributedObject() {
        DistributedObject obj = connection.getDistributedObject(MapService.SERVICE_NAME, "id");
        assertSame(hz.getDistributedObject(MapService.SERVICE_NAME, "id"), obj);
    }

    @Test
    public void getAtomicReference() {
        IAtomicReference ref = connection.getAtomicReference("ref");
        assertSame(hz.getAtomicReference("ref"), ref);
    }

    @Test
    public void getName() {
        String name = connection.getName();
        assertSame(name, hz.getName());
    }

    @Test
    public void getConfig() {
        Config config = connection.getConfig();
        assertSame(config, hz.getConfig());
    }

    @Test
    public void getJobTracker() {
        JobTracker jobTracker = connection.getJobTracker("jobTracker");
        assertSame(jobTracker, hz.getJobTracker("jobTracker"));
    }

    @Test
    public void getCluster() {
        Cluster cluster = connection.getCluster();
        assertNotSame(cluster, hz.getCluster());
    }

    @Test
    public void getQuorumService() {
        QuorumService quorumService = connection.getQuorumService();
        assertSame(quorumService, hz.getQuorumService());
    }

    @Test
    public void getClientService() {
        ClientService clientService = connection.getClientService();
        assertNotSame(clientService, hz.getClientService());
    }

    @Test
    public void getLoggingService() {
        LoggingService loggingService = connection.getLoggingService();
        assertSame(loggingService, hz.getLoggingService());
    }

    @Test
    public void getUserContext() {
        Map userContext = connection.getUserContext();
        assertSame(userContext, hz.getUserContext());
    }

    @Test
    public void getPartitionService() {
        PartitionService partitionService = connection.getPartitionService();
        assertSame(partitionService, hz.getPartitionService());
    }

    @Test
    public void getLocalEndpoint() {
        Endpoint endpoint = connection.getLocalEndpoint();
        assertSame(endpoint, hz.getLocalEndpoint());
    }

    @Test
    public void getXAResource() {
        XAResource resource = connection.getXAResource();
        assertNull(resource);
    }
}

<code block>


package com.hazelcast.jca;

import com.hazelcast.core.DistributedObject;
import com.hazelcast.test.annotation.SlowTest;
import org.jboss.arquillian.container.test.api.OperateOnDeployment;
import org.jboss.arquillian.junit.Arquillian;
import org.junit.Ignore;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.inject.Inject;
import javax.resource.ResourceException;
import java.util.Collection;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;

@Category(SlowTest.class)
@RunWith(Arquillian.class)
public class TestInContainer extends AbstractDeploymentTest {

    @Inject
    protected ITestBean testBean;

    @Test
    @OperateOnDeployment("war-deployment")
    public void testTransactionalMap() throws ResourceException {
        String mapname = "txmap";
        String key = "key";
        String value = "value";

        testBean.insertToMap(mapname, key, value);
        assertEquals(testBean.getFromMap(mapname, key), value);
    }

    @Test
    @OperateOnDeployment("war-deployment")
    public void testTransactionalQueue() throws ResourceException {
        String mapname = "txqueue";
        String key = "key";

        testBean.offerToQueue(mapname, key);
        assertEquals(testBean.pollFromQueue(mapname), key);
    }

    @Test
    @OperateOnDeployment("war-deployment")
    public void testTransactionalSet() throws ResourceException {
        String setname = "txset";
        String key = "key";

        testBean.insertToSet(setname, key);
        assertEquals(1, testBean.getSetSize(setname));
        assertTrue(testBean.removeFromSet(setname, key));
        assertEquals(0, testBean.getSetSize(setname));
    }

    @Test
    @OperateOnDeployment("war-deployment")
    @Ignore
    public void testTransactionalList() throws ResourceException {
        String listname = "txlist";
        String key = "key";

        testBean.addToList(listname, key);
        assertEquals(1, testBean.getListSize(listname));
        assertTrue(testBean.removeFromList(listname, key));
        assertEquals(0,testBean.getListSize(listname));
    }

    @Test
    @OperateOnDeployment("war-deployment")
    public void testLocalTransactionContext() throws ResourceException {
        String mapname = "txmap";
        String key = "key";
        String value = "value";

        testBean.insertToMap(mapname, key, value);
        testBean.insertToMap("fsdfd", key, value);

        assertNotNull(testBean.getDistributedObjects());
        Collection<DistributedObject> distributedObjectCollection = testBean.getDistributedObjects();
        
        assertEquals(3, distributedObjectCollection.size());
    }
}

<code block>


package com.hazelcast.jca;

import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;

import javax.naming.NamingException;
import javax.naming.Reference;
import javax.resource.ResourceException;
import javax.resource.cci.ConnectionSpec;
import javax.resource.cci.RecordFactory;
import javax.resource.cci.ResourceAdapterMetaData;
import javax.resource.spi.ConnectionManager;
import java.util.concurrent.atomic.AtomicInteger;


public class ConnectionFactoryImpl implements HazelcastConnectionFactory {
    
    private static final AtomicInteger ID_GEN = new AtomicInteger();
    
    private static final ILogger LOGGER = Logger.getLogger("com.hazelcast.jca");
    
    private static final long serialVersionUID = -5909363703528221650L;
    
    private ManagedConnectionFactoryImpl mcf;
    
    private ConnectionManager cm;
    
    private Reference ref;

    private transient int id;

    public ConnectionFactoryImpl() {
        setId(ID_GEN.incrementAndGet());
    }

    public ConnectionFactoryImpl(ManagedConnectionFactoryImpl mcf, ConnectionManager cm) {
        this();
        this.mcf = mcf;
        this.cm = cm;
    }

    
    public HazelcastConnection getConnection() throws ResourceException {
        LOGGER.finest("getConnection");
        return this.getConnection(null);
    }

    
    public HazelcastConnection getConnection(ConnectionSpec connSpec) throws ResourceException {
        if (LOGGER.isFinestEnabled()) {
            LOGGER.finest("getConnection spec: " + connSpec);
        }
        return (HazelcastConnectionImpl) cm.allocateConnection(mcf, null);
    }

    
    public ResourceAdapterMetaData getMetaData() throws ResourceException {
        return new ConnectionFactoryMetaData();
    }

    
    public RecordFactory getRecordFactory() throws ResourceException {
        return null;
    }

    
    public void setReference(Reference ref) {
        this.ref = ref;
    }

    
    public Reference getReference() throws NamingException {
        return ref;
    }

    @Override
    public String toString() {
        return "hazelcast.ConnectionFactoryImpl [" + id + "]";
    }

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + id;
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj) {
            return true;
        }
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        ConnectionFactoryImpl other = (ConnectionFactoryImpl) obj;
        if (id != other.id) {
            return false;
        }
        return true;
    }
    public void setId(int id) {
        this.id = id;
    }


}

<code block>
package com.hazelcast.jca;


import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.BeforeClass;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;


@Category(QuickTest.class)
@RunWith(HazelcastSerialClassRunner.class)
public class HazelcastConnectionContractTest {

    static HazelcastConnectionImpl connection;

    @BeforeClass
    public static void setup() {
       connection = new HazelcastConnectionImpl(null,null);
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testGetLifecycleService() {
        connection.getLifecycleService();
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testShutdown() {
        connection.shutdown();
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testExecuteTransaction() {
        connection.executeTransaction(null);
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testExecuteTransactionTwoArgs() {
        connection.executeTransaction(null,null);
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testNewTransactionContext() {
        connection.newTransactionContext();
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testNewTransactionContext2() {
        connection.newTransactionContext(null);
    }
}
<code block>


package com.hazelcast.jca;

import com.hazelcast.core.TransactionalMap;
import org.jboss.arquillian.junit.InSequence;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Test;

import javax.annotation.Resource;
import javax.naming.NamingException;
import javax.sql.DataSource;
import javax.transaction.UserTransaction;
import java.sql.Connection;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;



@Ignore
public class XATransactionTest extends AbstractDeploymentTest {


    
    

    @Resource(mappedName = "java:jboss/UserTransaction")
    private UserTransaction userTx;


    @Resource(mappedName = "java:jboss/datasources/ExampleDS")
    
    protected DataSource h2Datasource;

    private static boolean isDbInit = false;

    @Before
    public void Init() throws SQLException {
        if (!isDbInit) {
            isDbInit = true;
            Connection con = h2Datasource.getConnection();
            Statement stmt = null;
            try {
                stmt = con.createStatement();
                stmt.execute("create table TEST (A varchar(3))");
            } finally {
                if (stmt != null) {
                    stmt.close();
                }
                con.close();
            }
        }
    }


    @Test
    @InSequence(2)
    @Ignore
    public void testTransactionCommit() throws Throwable {
        userTx.begin();
        HazelcastConnection c = getConnection();
        try {
            TransactionalMap<String, String> m = c.getTransactionalMap("testTransactionCommit");

            m.put("key", "value");

            doSql();

            assertEquals("value", m.get("key"));
        } finally {
            c.close();
        }
        userTx.commit();
        HazelcastConnection con2 = getConnection();

        try {
            assertEquals("value", con2.getMap("testTransactionCommit").get("key"));
            validateSQLdata(true);
        } finally {
            con2.close();
        }
    }

    @Test
    @InSequence(1)
    @Ignore
    public void testTransactionRollback() throws Throwable {
        userTx.begin();

        HazelcastConnection c = getConnection();
        try {
            TransactionalMap<String, String> m = c.getTransactionalMap("testTransactionRollback");
            m.put("key", "value");
            assertEquals("value", m.get("key"));
            doSql();
        } finally {
            c.close();
        }

        userTx.rollback();

        HazelcastConnection con2 = getConnection();

        try {
            assertEquals(null, con2.getMap("testTransactionRollback").get("key"));
            validateSQLdata(false);
        } finally {
            con2.close();
        }

    }

    private void doSql() throws NamingException, SQLException {

        Connection con = h2Datasource.getConnection();
        Statement stmt = null;
        try {
            stmt = con.createStatement();
            stmt.execute("INSERT INTO TEST VALUES ('txt')");
        } finally {
            if (stmt != null) {
                stmt.close();
            }
            con.close();
        }
    }

    private void validateSQLdata(boolean hasdata) throws NamingException, SQLException {

        Connection con = h2Datasource.getConnection();
        Statement stmt = null;

        try {
            stmt = con.createStatement();

            ResultSet resultSet = null;
            try {
                resultSet = stmt.executeQuery("SELECT * FROM TEST");

            } catch (SQLException e) {
            }
            if (hasdata) {
                assertNotNull(resultSet);
                assertTrue(resultSet.first());
                assertEquals("txt", resultSet.getString("A"));
            } else {
                assertTrue(resultSet == null || resultSet.getFetchSize() == 0);
            }

        } finally {
            if (stmt != null) {
                stmt.close();
            }
            con.close();
        }
    }


}

<code block>


package com.hazelcast.jca;

import org.jboss.arquillian.container.test.api.Deployment;
import org.jboss.shrinkwrap.api.ShrinkWrap;
import org.jboss.shrinkwrap.api.asset.EmptyAsset;
import org.jboss.shrinkwrap.api.spec.JavaArchive;
import org.jboss.shrinkwrap.api.spec.ResourceAdapterArchive;

import javax.annotation.Resource;
import java.util.UUID;

import static org.junit.Assert.assertNotNull;


public class AbstractDeploymentTest {

    private final static String deploymentName="hazelcast-jca-rar";











    @Deployment
    public static ResourceAdapterArchive deploymentHzRar(){
        ResourceAdapterArchive raa = ShrinkWrap.create(ResourceAdapterArchive.class, deploymentName + ".rar");

        JavaArchive ja = ShrinkWrap.create(JavaArchive.class, UUID.randomUUID().toString() + ".jar");
        ja.addPackage(JcaBase.class.getPackage());
        ja.setManifest("MANIFEST.MF");


        raa.addAsLibrary(ja);
        raa.addAsManifestResource("ra.xml","ra.xml");
        raa.addAsManifestResource("ironjacamar.xml","ironjacamar.xml");

        return raa;
    }

    @Resource(mappedName = "java:/HazelcastCF")
    protected HazelcastConnectionFactory connectionFactory;

    protected HazelcastConnection getConnection() throws Throwable{
        assertNotNull(connectionFactory);
        HazelcastConnection c = connectionFactory.getConnection();
        assertNotNull(c);
        return c;
    }

}
<code block>


package com.hazelcast.jca;

import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.IMap;
import com.hazelcast.core.TransactionalMap;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import com.hazelcast.transaction.impl.xa.SerializableXID;
import com.hazelcast.util.ExceptionUtil;

import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.resource.ResourceException;
import javax.resource.spi.ConnectionEvent;
import javax.resource.spi.ConnectionEventListener;
import javax.resource.spi.ConnectionManager;
import javax.resource.spi.ConnectionRequestInfo;
import javax.resource.spi.ManagedConnection;
import javax.resource.spi.ManagedConnectionFactory;
import javax.transaction.xa.XAException;
import javax.transaction.xa.XAResource;
import javax.transaction.xa.Xid;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class XATestWithJCA extends HazelcastTestSupport {

    HazelcastConnection connection;
    HazelcastInstance instance;

    @Before
    public void setup() throws Exception {
        instance = createHazelcastInstance();
        ResourceAdapterImpl resourceAdapter = new ResourceAdapterImpl();
        resourceAdapter.setHazelcastInstance(instance);
        ManagedConnectionFactoryImpl managedConnectionFactory = new ManagedConnectionFactoryImpl();
        managedConnectionFactory.setResourceAdapter(resourceAdapter);
        managedConnectionFactory.setConnectionTracingEvents(null);
        TestConnectionManager connectionManager = new TestConnectionManager();
        ConnectionFactoryImpl factory = new ConnectionFactoryImpl(managedConnectionFactory, connectionManager);
        connection = factory.getConnection();
    }

    @Test
    public void testPut() throws ResourceException {
        String name = randomString();
        String key = randomString();
        String val = randomString();

        TransactionalMap<String, String> map = connection.getTransactionalMap(name);
        map.put(key, val);
        connection.close();

        IMap<String, String> m = instance.getMap(name);
        assertEquals(val, m.get(key));
    }

    static class TestConnectionManager implements ConnectionManager, ConnectionEventListener {

        ConcurrentMap<HazelcastConnection, Xid> transactionIdMap = new ConcurrentHashMap<HazelcastConnection, Xid>();

        private static Xid createXid() {
            String s = randomString();
            return new SerializableXID(s.length(), s.getBytes(), s.getBytes());
        }

        @Override
        public Object allocateConnection(ManagedConnectionFactory mcf, ConnectionRequestInfo cxRequestInfo)
                throws ResourceException {
            ManagedConnection managedConnection = mcf.createManagedConnection(null, cxRequestInfo);
            XAResource xaResource = managedConnection.getXAResource();
            managedConnection.addConnectionEventListener(this);
            Xid xid = createXid();
            try {
                xaResource.start(xid, XAResource.TMNOFLAGS);
            } catch (XAException e) {
                throw ExceptionUtil.rethrow(e);
            }
            HazelcastConnection connection = (HazelcastConnection) managedConnection.getConnection(null, cxRequestInfo);
            transactionIdMap.put(connection, xid);
            return connection;
        }

        @Override
        public void connectionClosed(ConnectionEvent event) {
            ManagedConnection managedConnection = (ManagedConnection) event.getSource();
            HazelcastConnection connection = (HazelcastConnection) event.getConnectionHandle();
            Xid xid = transactionIdMap.remove(connection);
            try {
                XAResource xaResource = managedConnection.getXAResource();
                xaResource.end(xid, XAResource.TMSUCCESS);

                xaResource.commit(xid, true);
            } catch (Exception e) {
                throw ExceptionUtil.rethrow(e);
            }

        }

        @Override
        public void localTransactionStarted(ConnectionEvent event) {

        }

        @Override
        public void localTransactionCommitted(ConnectionEvent event) {

        }

        @Override
        public void localTransactionRolledback(ConnectionEvent event) {

        }

        @Override
        public void connectionErrorOccurred(ConnectionEvent event) {

        }
    }

}

<code block>
package com.hazelcast.jca;

import com.hazelcast.config.Config;
import com.hazelcast.core.ClientService;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.Endpoint;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.IAtomicLong;
import com.hazelcast.core.IAtomicReference;
import com.hazelcast.core.IList;
import com.hazelcast.core.ILock;
import com.hazelcast.core.IMap;
import com.hazelcast.core.IQueue;
import com.hazelcast.core.ISemaphore;
import com.hazelcast.core.ITopic;
import com.hazelcast.core.IdGenerator;
import com.hazelcast.core.MultiMap;
import com.hazelcast.core.PartitionService;
import com.hazelcast.core.ReplicatedMap;
import com.hazelcast.core.TransactionalMap;
import com.hazelcast.core.TransactionalQueue;
import com.hazelcast.executor.impl.ExecutorServiceProxy;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.map.impl.MapDataSerializerHook;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.mapreduce.JobTracker;
import com.hazelcast.quorum.QuorumService;
import com.hazelcast.quorum.impl.QuorumServiceImpl;
import com.hazelcast.ringbuffer.Ringbuffer;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import com.hazelcast.transaction.TransactionContext;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import javax.transaction.xa.XAResource;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ExecutorService;

import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNotSame;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertSame;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.when;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class HazelcastConnectionImplTest extends HazelcastTestSupport {

    private HazelcastInstance hz;
    private HazelcastConnectionImpl connection;

    @Before
    public void setup() {
        hz = createHazelcastInstance();
        ManagedConnectionImpl managedConnection = mock(ManagedConnectionImpl.class);
        when(managedConnection.getHazelcastInstance()).thenReturn(hz);
        connection = new HazelcastConnectionImpl(managedConnection, null);

    }

    @Test
    public void getRingbuffer() {
        Ringbuffer rb = connection.getRingbuffer("ringbuffer");
        assertSame(hz.getRingbuffer("ringbuffer"), rb);
    }

    @Test
    public void getReliableTopic() {
        ITopic topic = connection.getReliableTopic("reliableTopic");
        assertSame(hz.getReliableTopic("reliableTopic"), topic);
    }

    @Test
    public void getTopic() {
        ITopic topic = connection.getTopic("reliableTopic");
        assertSame(hz.getTopic("reliableTopic"), topic);
    }

    @Test
    public void getMap() {
        IMap topic = connection.getMap("map");
        assertSame(hz.getMap("map"), topic);
    }

    @Test
    public void getQueue() {
        IQueue queue = connection.getQueue("queue");
        assertSame(hz.getQueue("queue"), queue);
    }

    @Test
    public void getMultiMap() {
        MultiMap multiMap = connection.getMultiMap("multiMap");
        assertSame(hz.getMultiMap("multiMap"), multiMap);
    }

    @Test
    public void getReplicatedMap() {
        ReplicatedMap replicatedMap = connection.getReplicatedMap("replicatedMap");
        assertSame(hz.getReplicatedMap("replicatedMap"), replicatedMap);
    }

    @Test
    public void getSet() {
        Set set = connection.getSet("set");
        assertSame(hz.getSet("set"), set);
    }

    @Test
    public void getList() {
        IList list = connection.getList("list");
        assertSame(hz.getList("list"), list);
    }

    @Test
    public void getSemaphore() {
        ISemaphore semaphore = connection.getSemaphore("s");
        assertSame(hz.getSemaphore("s"), semaphore);
    }

    @Test
    public void getLock() {
        ILock lock = connection.getLock("lock");
        assertSame(hz.getLock("lock"), lock);
    }

    @Test
    public void getExecutorService() {
        ExecutorService ex = connection.getExecutorService("ex");
        assertSame(hz.getExecutorService("ex"), ex);
    }

    @Test
    public void getAtomicLong() {
        IAtomicLong atomicLong = connection.getAtomicLong("atomicLong");
        assertSame(hz.getAtomicLong("atomicLong"), atomicLong);
    }

    @Test
    public void getIdGenerator() {
        IdGenerator idGenerator = connection.getIdGenerator("id");
        assertSame(hz.getIdGenerator("id"), idGenerator);
    }

    @Test
    public void getDistributedObject() {
        DistributedObject obj = connection.getDistributedObject(MapService.SERVICE_NAME, "id");
        assertSame(hz.getDistributedObject(MapService.SERVICE_NAME, "id"), obj);
    }

    @Test
    @Ignore
    public void getTransactionalQueue() {
        
    }

    @Test
    @Ignore
    public void getTransactionalMap() {
        
    }

    @Test
    @Ignore
    public void getTransactionalList() {
        
    }

    @Test
    @Ignore
    public void getTransactionalSet() {
        
    }

    @Test
    public void getAtomicReference() {
        IAtomicReference ref = connection.getAtomicReference("ref");
        assertSame(hz.getAtomicReference("ref"), ref);
    }

    @Test
    public void getName() {
        String name = connection.getName();
        assertSame(name, hz.getName());
    }

    @Test
    public void getConfig() {
        Config config = connection.getConfig();
        assertSame(config, hz.getConfig());
    }

    @Test
    public void getJobTracker() {
        JobTracker jobTracker = connection.getJobTracker("jobTracker");
        assertSame(jobTracker, hz.getJobTracker("jobTracker"));
    }

    @Test
    public void getCluster() {
        Cluster cluster = connection.getCluster();
        assertNotSame(cluster, hz.getCluster());
    }

    @Test
    public void getQuorumService() {
        QuorumService quorumService = connection.getQuorumService();
        assertSame(quorumService, hz.getQuorumService());
    }

    @Test
    public void getClientService() {
        ClientService clientService = connection.getClientService();
        assertNotSame(clientService, hz.getClientService());
    }

    @Test
    public void getLoggingService() {
        LoggingService loggingService = connection.getLoggingService();
        assertSame(loggingService, hz.getLoggingService());
    }

    @Test
    public void getUserContext() {
        Map userContext = connection.getUserContext();
        assertSame(userContext, hz.getUserContext());
    }

    @Test
    public void getPartitionService() {
        PartitionService partitionService = connection.getPartitionService();
        assertSame(partitionService, hz.getPartitionService());
    }

    @Test
    public void getLocalEndpoint() {
        Endpoint endpoint = connection.getLocalEndpoint();
        assertSame(endpoint, hz.getLocalEndpoint());
    }

    @Test
    public void getXAResource() {
        XAResource resource = connection.getXAResource();
        assertNull(resource);
    }
}

<code block>


package com.hazelcast.client.impl;

import com.hazelcast.client.AuthenticationException;
import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.ClientEndpointManager;
import com.hazelcast.client.ClientEngine;
import com.hazelcast.client.impl.client.AuthenticationRequest;
import com.hazelcast.client.impl.client.ClientRequest;
import com.hazelcast.client.impl.client.ClientResponse;
import com.hazelcast.client.impl.operations.ClientDisconnectionOperation;
import com.hazelcast.client.impl.operations.GetConnectedClientsOperation;
import com.hazelcast.client.impl.operations.PostJoinClientOperation;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.MessageTaskFactory;
import com.hazelcast.client.impl.protocol.task.MessageTask;
import com.hazelcast.cluster.ClusterService;
import com.hazelcast.config.Config;
import com.hazelcast.core.Client;
import com.hazelcast.core.ClientListener;
import com.hazelcast.core.ClientType;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.PortableReader;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.security.Credentials;
import com.hazelcast.security.SecurityContext;
import com.hazelcast.spi.CoreService;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.MemberAttributeServiceEvent;
import com.hazelcast.spi.MembershipAwareService;
import com.hazelcast.spi.MembershipServiceEvent;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PostJoinAwareService;
import com.hazelcast.spi.ProxyService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import com.hazelcast.transaction.TransactionManagerService;
import com.hazelcast.util.executor.ExecutorType;

import javax.security.auth.login.LoginException;
import java.security.Permission;
import java.util.Collection;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Executor;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.Future;
import java.util.logging.Level;

import static com.hazelcast.spi.impl.OperationResponseHandlerFactory.createEmptyResponseHandler;


public class ClientEngineImpl implements ClientEngine, CoreService, PostJoinAwareService,
        ManagedService, MembershipAwareService, EventPublishingService<ClientEndpointImpl, ClientListener> {

    
    public static final String SERVICE_NAME = "hz:core:clientEngine";
    private static final int ENDPOINT_REMOVE_DELAY_SECONDS = 10;
    private static final int EXECUTOR_QUEUE_CAPACITY_PER_CORE = 100000;
    private static final int THREADS_PER_CORE = 20;

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final Executor executor;

    private final SerializationService serializationService;
    
    private final ConcurrentMap<String, String> ownershipMappings = new ConcurrentHashMap<String, String>();

    private final ClientEndpointManagerImpl endpointManager;
    private final ILogger logger;
    private final ConnectionListener connectionListener = new ConnectionListenerImpl();

    private final MessageTaskFactory messageTaskFactory;

    public ClientEngineImpl(Node node) {
        this.logger = node.getLogger(ClientEngine.class);
        this.node = node;
        this.serializationService = node.getSerializationService();
        this.nodeEngine = node.nodeEngine;
        this.endpointManager = new ClientEndpointManagerImpl(this, nodeEngine);
        this.executor = newExecutor();
        this.messageTaskFactory = node.getNodeExtension().createMessageTaskFactory(node);

        ClientHeartbeatMonitor heartBeatMonitor = new ClientHeartbeatMonitor(
                endpointManager, this, nodeEngine.getExecutionService(), node.groupProperties);
        heartBeatMonitor.start();
    }

    private Executor newExecutor() {
        final ExecutionService executionService = nodeEngine.getExecutionService();
        int coreSize = Runtime.getRuntime().availableProcessors();

        int threadCount = node.getGroupProperties().CLIENT_ENGINE_THREAD_COUNT.getInteger();
        if (threadCount <= 0) {
            threadCount = coreSize * THREADS_PER_CORE;
        }

        return executionService.register(ExecutionService.CLIENT_EXECUTOR,
                threadCount, coreSize * EXECUTOR_QUEUE_CAPACITY_PER_CORE,
                ExecutorType.CONCRETE);
    }

    
    public ConnectionListener getConnectionListener() {
        return connectionListener;
    }

    @Override
    public int getClientEndpointCount() {
        return endpointManager.size();
    }

    public void handlePacket(Packet packet) {
        int partitionId = packet.getPartitionId();
        if (partitionId < 0) {
            executor.execute(new ClientPacketProcessor(packet));
        } else {
            InternalOperationService operationService = nodeEngine.getOperationService();
            operationService.execute(new ClientPacketProcessor(packet));
        }
    }

    public void handleClientMessage(ClientMessage clientMessage, Connection connection) {

        
        int partitionId = clientMessage.getPartitionId();
        final MessageTask messageTask = messageTaskFactory.create(clientMessage, connection);
        if (partitionId < 0) {
            executor.execute(messageTask);
        } else {
            InternalOperationService operationService = nodeEngine.getOperationService();
            operationService.execute(messageTask);
        }
    }

    @Override
    public InternalPartitionService getPartitionService() {
        return nodeEngine.getPartitionService();
    }

    @Override
    public ClusterService getClusterService() {
        return nodeEngine.getClusterService();
    }

    @Override
    public EventService getEventService() {
        return nodeEngine.getEventService();
    }

    @Override
    public ProxyService getProxyService() {
        return nodeEngine.getProxyService();
    }

    public void sendResponse(ClientEndpoint endpoint, Object key, Object response, int callId, boolean isError, boolean isEvent) {
        Data data = serializationService.toData(response);
        ClientResponse clientResponse = new ClientResponse(data, callId, isError);
        Data responseData = serializationService.toData(clientResponse);
        int partitionId = key == null ? -1 : getPartitionService().getPartitionId(key);
        final Packet packet = new Packet(responseData, partitionId);
        if (isEvent) {
            packet.setHeader(Packet.HEADER_EVENT);
        }
        Connection conn = endpoint.getConnection();
        conn.write(packet);
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public MemberImpl getLocalMember() {
        return node.getLocalMember();
    }

    @Override
    public Config getConfig() {
        return node.getConfig();
    }

    @Override
    public ILogger getLogger(Class clazz) {
        return node.getLogger(clazz);
    }

    public ClientEndpointManager getEndpointManager() {
        return endpointManager;
    }

    @Override
    public SecurityContext getSecurityContext() {
        return node.securityContext;
    }

    public void bind(final ClientEndpoint endpoint) {
        final Connection conn = endpoint.getConnection();
        if (conn instanceof TcpIpConnection) {
            Address address = new Address(conn.getRemoteSocketAddress());
            ((TcpIpConnection) conn).setEndPoint(address);
        }
        sendClientEvent(endpoint);
    }

    void sendClientEvent(ClientEndpoint endpoint) {
        final EventService eventService = nodeEngine.getEventService();
        final Collection<EventRegistration> regs = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        String uuid = endpoint.getUuid();
        eventService.publishEvent(SERVICE_NAME, regs, endpoint, uuid.hashCode());
    }

    @Override
    public void dispatchEvent(ClientEndpointImpl event, ClientListener listener) {
        if (event.isAuthenticated()) {
            listener.clientConnected(event);
        } else {
            listener.clientDisconnected(event);
        }
    }

    @Override
    public void memberAdded(MembershipServiceEvent event) {
    }

    @Override
    public void memberRemoved(MembershipServiceEvent event) {
        if (event.getMember().localMember()) {
            return;
        }

        final String deadMemberUuid = event.getMember().getUuid();
        try {
            nodeEngine.getExecutionService().schedule(new DestroyEndpointTask(deadMemberUuid),
                    ENDPOINT_REMOVE_DELAY_SECONDS, TimeUnit.SECONDS);

        } catch (RejectedExecutionException e) {
            if (logger.isFinestEnabled()) {
                logger.finest(e);
            }
        }
    }

    @Override
    public void memberAttributeChanged(MemberAttributeServiceEvent event) {
    }

    public Collection<Client> getClients() {
        final HashSet<Client> clients = new HashSet<Client>();
        for (ClientEndpoint endpoint : endpointManager.getEndpoints()) {
            clients.add((Client) endpoint);
        }
        return clients;
    }

    @Override
    public void init(NodeEngine nodeEngine, Properties properties) {
        node.getConnectionManager().addConnectionListener(connectionListener);
    }

    @Override
    public void reset() {
    }

    @Override
    public void shutdown(boolean terminate) {
        for (ClientEndpoint ce : endpointManager.getEndpoints()) {
            ClientEndpointImpl endpoint = (ClientEndpointImpl) ce;
            try {
                endpoint.destroy();
            } catch (LoginException e) {
                logger.finest(e.getMessage());
            }
            try {
                final Connection conn = endpoint.getConnection();
                if (conn.isAlive()) {
                    conn.close();
                }
            } catch (Exception e) {
                logger.finest(e);
            }
        }
        endpointManager.clear();
        ownershipMappings.clear();
    }

    public void addOwnershipMapping(String clientUuid, String ownerUuid) {
        ownershipMappings.put(clientUuid, ownerUuid);
    }

    public void removeOwnershipMapping(String clientUuid) {
        ownershipMappings.remove(clientUuid);
    }

    public TransactionManagerService getTransactionManagerService() {
        return node.nodeEngine.getTransactionManagerService();
    }

    private final class ClientPacketProcessor implements PartitionSpecificRunnable {
        final Packet packet;

        private ClientPacketProcessor(Packet packet) {
            this.packet = packet;
        }

        @Override
        public int getPartitionId() {
            return packet.getPartitionId();
        }

        @Override
        public void run() {
            Connection conn = packet.getConn();
            ClientEndpointImpl endpoint = (ClientEndpointImpl) endpointManager.getEndpoint(conn);
            ClientRequest request = null;
            try {
                request = loadRequest();
                if (request == null) {
                    handlePacketWithNullRequest();
                } else if (request instanceof AuthenticationRequest) {
                    if (conn.isAlive()) {
                        endpoint = new ClientEndpointImpl(ClientEngineImpl.this, conn);
                        processRequest(endpoint, request);
                    } else {
                        handleEndpointNotCreatedConnectionNotAlive();
                    }
                } else if (endpoint == null) {
                    handleMissingEndpoint(conn);
                } else if (endpoint.isAuthenticated()) {
                    processRequest(endpoint, request);
                } else {
                    handleAuthenticationFailure(endpoint, request);
                }
            } catch (Throwable e) {
                logProcessingFailure(request, e);
                handleProcessingFailure(endpoint, request, packet.getData(), e);
            }
        }

        private ClientRequest loadRequest() {
            Data data = packet.getData();
            return serializationService.toObject(data);
        }

        private void handleEndpointNotCreatedConnectionNotAlive() {
            logger.warning("Dropped: " + packet + " -> endpoint not created for AuthenticationRequest, "
                    + "connection not alive");
        }

        private void handlePacketWithNullRequest() {
            logger.warning("Dropped: " + packet + " -> null request");
        }

        private void handleMissingEndpoint(Connection conn) {
            if (conn.isAlive()) {
                logger.severe("Dropping: " + packet + " -> no endpoint found for live connection.");
            } else {
                if (logger.isFinestEnabled()) {
                    logger.finest("Dropping: " + packet + " -> no endpoint found for dead connection.");
                }
            }
        }

        private void logProcessingFailure(ClientRequest request, Throwable e) {
            Level level = nodeEngine.isActive() ? Level.SEVERE : Level.FINEST;
            if (logger.isLoggable(level)) {
                if (request == null) {
                    logger.log(level, e.getMessage(), e);
                } else {
                    logger.log(level, "While executing request: " + request + " -> " + e.getMessage(), e);
                }
            }
        }

        private void handleProcessingFailure(ClientEndpointImpl endpoint, ClientRequest request, Data data, Throwable e) {
            if (request != null && endpoint != null) {
                endpoint.sendResponse(e, request.getCallId());
            } else if (data != null && endpoint != null) {
                int callId = extractCallId(data);
                if (callId != -1) {
                    endpoint.sendResponse(e, callId);
                }
                
            }
        }

        private int extractCallId(Data data) {
            try {
                PortableReader portableReader = serializationService.createPortableReader(data);
                return portableReader.readInt("cId");

            } catch (Throwable e) {
                Level level = nodeEngine.isActive() ? Level.SEVERE : Level.FINEST;
                if (logger.isLoggable(level)) {
                    logger.log(level, e.getMessage(), e);
                }
            }
            return -1;
        }

        private void processRequest(ClientEndpointImpl endpoint, ClientRequest request) throws Exception {
            if (!node.joined()) {
                throw new HazelcastInstanceNotActiveException("Hazelcast instance is not ready yet!");
            }

            request.setEndpoint(endpoint);
            initService(request);
            request.setClientEngine(ClientEngineImpl.this);
            final Credentials credentials = endpoint.getCredentials();
            request.setSerializationService(serializationService);
            request.setOperationService(nodeEngine.getOperationService());
            interceptBefore(credentials, request);
            checkPermissions(endpoint, request);
            request.process();
            interceptAfter(credentials, request);
        }

        private void interceptBefore(Credentials credentials, ClientRequest request) {
            final SecurityContext securityContext = getSecurityContext();
            final String methodName = request.getMethodName();
            if (securityContext != null && methodName != null) {
                final String objectType = request.getDistributedObjectType();
                final String objectName = request.getDistributedObjectName();
                securityContext.interceptBefore(credentials, objectType, objectName, methodName, request.getParameters());
            }
        }

        private void interceptAfter(Credentials credentials, ClientRequest request) {
            final SecurityContext securityContext = getSecurityContext();
            final String methodName = request.getMethodName();
            if (securityContext != null && methodName != null) {
                final String objectType = request.getDistributedObjectType();
                final String objectName = request.getDistributedObjectName();
                securityContext.interceptAfter(credentials, objectType, objectName, methodName);
            }
        }

        private void checkPermissions(ClientEndpointImpl endpoint, ClientRequest request) {
            SecurityContext securityContext = getSecurityContext();
            if (securityContext != null) {
                Permission permission = request.getRequiredPermission();
                if (permission != null) {
                    securityContext.checkPermission(endpoint.getSubject(), permission);
                }
            }
        }

        private void initService(ClientRequest request) {
            String serviceName = request.getServiceName();
            if (serviceName == null) {
                return;
            }

            Object service = nodeEngine.getService(serviceName);
            if (service == null) {
                if (nodeEngine.isActive()) {
                    throw new IllegalArgumentException("No service registered with name: " + serviceName);
                }
                throw new HazelcastInstanceNotActiveException();
            }
            request.setService(service);
        }

        private void handleAuthenticationFailure(ClientEndpointImpl endpoint, ClientRequest request) {
            Exception exception;
            if (nodeEngine.isActive()) {
                String message = "Client " + endpoint + " must authenticate before any operation.";
                logger.severe(message);
                exception = new AuthenticationException(message);
            } else {
                exception = new HazelcastInstanceNotActiveException();
            }
            endpoint.sendResponse(exception, request.getCallId());
            endpointManager.removeEndpoint(endpoint);
        }
    }

    private final class ConnectionListenerImpl implements ConnectionListener {

        @Override
        public void connectionAdded(Connection conn) {
            
            
            
        }

        @Override
        public void connectionRemoved(Connection connection) {
            if (connection.isClient() && nodeEngine.isActive()) {
                ClientEndpointImpl endpoint = (ClientEndpointImpl) endpointManager.getEndpoint(connection);
                if (endpoint == null) {
                    return;
                }

                if (!endpoint.isFirstConnection()) {
                    return;
                }

                String localMemberUuid = node.getLocalMember().getUuid();
                String ownerUuid = endpoint.getPrincipal().getOwnerUuid();
                if (localMemberUuid.equals(ownerUuid)) {
                    callDisconnectionOperation(endpoint);
                }
            }
        }

        private void callDisconnectionOperation(ClientEndpointImpl endpoint) {
            Collection<MemberImpl> memberList = nodeEngine.getClusterService().getMemberList();
            OperationService operationService = nodeEngine.getOperationService();
            ClientDisconnectionOperation op = createClientDisconnectionOperation(endpoint.getUuid());
            operationService.runOperationOnCallingThread(op);

            for (MemberImpl member : memberList) {
                if (!member.localMember()) {
                    op = createClientDisconnectionOperation(endpoint.getUuid());
                    operationService.send(op, member.getAddress());
                }
            }
        }
    }

    private ClientDisconnectionOperation createClientDisconnectionOperation(String clientUuid) {
        ClientDisconnectionOperation op = new ClientDisconnectionOperation(clientUuid);
        op.setNodeEngine(nodeEngine)
                .setServiceName(SERVICE_NAME)
                .setService(this)
                .setOperationResponseHandler(createEmptyResponseHandler());
        return op;
    }

    private class DestroyEndpointTask implements Runnable {
        private final String deadMemberUuid;

        public DestroyEndpointTask(String deadMemberUuid) {
            this.deadMemberUuid = deadMemberUuid;
        }

        @Override
        public void run() {
            endpointManager.removeEndpoints(deadMemberUuid);
            removeMappings();
        }

        void removeMappings() {
            Iterator<Map.Entry<String, String>> iterator = ownershipMappings.entrySet().iterator();
            while (iterator.hasNext()) {
                Map.Entry<String, String> entry = iterator.next();
                String clientUuid = entry.getKey();
                String memberUuid = entry.getValue();
                if (deadMemberUuid.equals(memberUuid)) {
                    iterator.remove();
                    ClientDisconnectionOperation op = createClientDisconnectionOperation(clientUuid);
                    nodeEngine.getOperationService().runOperationOnCallingThread(op);
                }
            }
        }
    }

    @Override
    public Operation getPostJoinOperation() {
        return ownershipMappings.isEmpty() ? null : new PostJoinClientOperation(ownershipMappings);
    }

    @Override
    public Map<ClientType, Integer> getConnectedClientStats() {

        int numberOfCppClients    = 0;
        int numberOfDotNetClients = 0;
        int numberOfJavaClients   = 0;
        int numberOfOtherClients  = 0;

        Operation clientInfoOperation = new GetConnectedClientsOperation();
        OperationService operationService = node.nodeEngine.getOperationService();
        Map<ClientType, Integer> resultMap = new HashMap<ClientType, Integer>();
        Map<String, ClientType> clientsMap = new HashMap<String, ClientType>();

        for (MemberImpl member : node.getClusterService().getMemberList()) {
            Address target = member.getAddress();
            Future<Map<String, ClientType>> future
                    = operationService.invokeOnTarget(SERVICE_NAME, clientInfoOperation, target);
            try {
                Map<String, ClientType> endpoints = future.get();
                if (endpoints == null) {
                    continue;
                }
                
                for (Map.Entry<String, ClientType> entry : endpoints.entrySet()) {
                    clientsMap.put(entry.getKey(), entry.getValue());
                }
            } catch (Exception e) {
                logger.warning("Cannot get client information from: " + target.toString(), e);
            }
        }

        
        for (ClientType clientType : clientsMap.values()) {
            switch (clientType) {
                case JAVA:
                    numberOfJavaClients++;
                    break;
                case CSHARP:
                    numberOfDotNetClients++;
                    break;
                case CPP:
                    numberOfCppClients++;
                    break;
                default:
                    numberOfOtherClients++;
            }
        }

        resultMap.put(ClientType.CPP, numberOfCppClients);
        resultMap.put(ClientType.CSHARP, numberOfDotNetClients);
        resultMap.put(ClientType.JAVA, numberOfJavaClients);
        resultMap.put(ClientType.OTHER, numberOfOtherClients);

        return resultMap;
    }
}

<code block>


package com.hazelcast.mapreduce;

import com.hazelcast.core.*;
import com.hazelcast.mapreduce.helpers.Employee;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.TestHazelcastInstanceFactory;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.io.IOException;
import java.math.BigInteger;
import java.util.*;
import java.util.concurrent.CancellationException;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Semaphore;
import java.util.logging.Logger;

import static org.junit.Assert.*;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
@SuppressWarnings("unused")
public class MapReduceTest
        extends HazelcastTestSupport {
    final static Logger logger = Logger.getLogger("test");

    private static final String MAP_NAME = "default";

    private void tripTerminate(HazelcastInstance... instances) {
        for (HazelcastInstance instance : instances) {
            try {
                instance.getLifecycleService().terminate();
            } catch (Throwable ex) {
                logger.log(java.util.logging.Level.INFO, ex.getMessage(), ex);
            }
        }
    }

    @Test(timeout = 60000)
    public void test_early_finalization_combiner_github_5283() throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            KeyValueSource<Integer, Integer> kvs = KeyValueSource.fromMap(m1);
            KeyValueSource<Integer, Integer> wrapper = new MapKeyValueSourceAdapter<Integer, Integer>(kvs);
            Job<Integer, Integer> job = tracker.newJob(wrapper);

            ICompletableFuture<Map<String, List<Integer>>> future =
                    job.mapper(new TestMapper())
                            .combiner(new FinalizingCombinerFactory())
                            .reducer(new ListBasedReducerFactory()).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(100, result.size());
            for (List<Integer> value : result.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testPartitionPostpone()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            KeyValueSource<Integer, Integer> kvs = KeyValueSource.fromMap(m1);
            KeyValueSource<Integer, Integer> wrapper = new MapKeyValueSourceAdapter<Integer, Integer>(kvs);
            Job<Integer, Integer> job = tracker.newJob(wrapper);
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new TestMapper()).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(100, result.size());
            for (List<Integer> value : result.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void test_collide_user_provided_combiner_list_result_github_3614() throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            KeyValueSource<Integer, Integer> kvs = KeyValueSource.fromMap(m1);
            KeyValueSource<Integer, Integer> wrapper = new MapKeyValueSourceAdapter<Integer, Integer>(kvs);
            Job<Integer, Integer> job = tracker.newJob(wrapper);
            ICompletableFuture<Map<String, List<Integer>>> future =
                    job.mapper(new TestMapper())
                            .combiner(new ListResultingCombinerFactory())
                            .reducer(new ListBasedReducerFactory()).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(100, result.size());
            for (List<Integer> value : result.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 30000, expected = ExecutionException.class)
    public void testExceptionDistributionWithCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new ExceptionThrowingMapper())
                    .submit(new Collator<Map.Entry<String, List<Integer>>, Map<String, List<Integer>>>() {
                        @Override
                        public Map<String, List<Integer>> collate(
                                Iterable<Map.Entry<String, List<Integer>>> values) {
                            return null;
                        }
                    });

            try {
                Map<String, List<Integer>> result = future.get();
                fail();

            } catch (Exception e) {
                e.printStackTrace();
                assertTrue(e.getCause() instanceof NullPointerException);
                throw e;
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 30000, expected = ExecutionException.class)
    public void testExceptionDistribution()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new ExceptionThrowingMapper()).submit();

            try {
                Map<String, List<Integer>> result = future.get();
                fail();

            } catch (Exception e) {
                e.printStackTrace();
                assertTrue(e.getCause() instanceof NullPointerException);
                throw e;
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 30000, expected = CancellationException.class)
    public void testInProcessCancellation()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new TimeConsumingMapper()).submit();

            future.cancel(true);

            try {
                Map<String, List<Integer>> result = future.get();
                fail();

            } catch (Exception e) {
                e.printStackTrace();
                throw e;
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapper()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new TestMapper()).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(100, result.size());
            for (List<Integer> value : result.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testKeyedMapperCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 10000; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.onKeys(50).mapper(new TestMapper()).submit(new GroupingTestCollator());

            int result = future.get();

            assertEquals(50, result);
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testKeyPredicateMapperCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 10000; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.keyPredicate(new TestKeyPredicate()).mapper(new TestMapper())
                    .submit(new GroupingTestCollator());

            int result = future.get();

            assertEquals(50, result);
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperComplexMapping()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new GroupingTestMapper(2)).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(1, result.size());
            assertEquals(25, result.values().iterator().next().size());
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperReducer()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, Integer>> future = job.mapper(new GroupingTestMapper()).reducer(new TestReducerFactory())
                    .submit();

            Map<String, Integer> result = future.get();

            
            int[] expectedResults = new int[4];
            for (int i = 0; i < 100; i++) {
                int index = i % 4;
                expectedResults[index] += i;
            }

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResults[i], (int) result.get(String.valueOf(i)));
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperReducerChunked()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            final IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 10000; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            JobCompletableFuture<Map<String, Integer>> future = job.chunkSize(10).mapper(new GroupingTestMapper())
                    .reducer(new TestReducerFactory()).submit();

            final TrackableJob trackableJob = tracker.getTrackableJob(future.getJobId());
            final JobProcessInformation processInformation = trackableJob.getJobProcessInformation();
            Map<String, Integer> result = future.get();

            
            int[] expectedResults = new int[4];
            for (int i = 0; i < 10000; i++) {
                int index = i % 4;
                expectedResults[index] += i;
            }

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResults[i], (int) result.get(String.valueOf(i)));
            }

            assertTrueEventually(new AssertTask() {
                @Override
                public void run() {
                    if (processInformation.getProcessedRecords() < 10000) {
                        System.err.println(processInformation.getProcessedRecords());
                    }
                    assertEquals(10000, processInformation.getProcessedRecords());
                }
            });
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.mapper(new GroupingTestMapper()).submit(new GroupingTestCollator());

            int result = future.get();

            
            int expectedResult = 0;
            for (int i = 0; i < 100; i++) {
                expectedResult += i;
            }

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResult, result);
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperReducerCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.mapper(new GroupingTestMapper()).reducer(new TestReducerFactory())
                    .submit(new TestCollator());

            int result = future.get();

            
            int expectedResult = 0;
            for (int i = 0; i < 100; i++) {
                expectedResult += i;
            }

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResult, result);
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testAsyncMapper()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final Map<String, List<Integer>> listenerResults = new HashMap<String, List<Integer>>();
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new TestMapper()).submit();

            future.andThen(new ExecutionCallback<Map<String, List<Integer>>>() {
                @Override
                public void onResponse(Map<String, List<Integer>> response) {
                    try {
                        listenerResults.putAll(response);
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });


            semaphore.acquire();

            assertEquals(100, listenerResults.size());
            for (List<Integer> value : listenerResults.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testKeyedAsyncMapper()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);


        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final Map<String, List<Integer>> listenerResults = new HashMap<String, List<Integer>>();
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.onKeys(50).mapper(new TestMapper()).submit();

            future.andThen(new ExecutionCallback<Map<String, List<Integer>>>() {
                @Override
                public void onResponse(Map<String, List<Integer>> response) {
                    try {
                        listenerResults.putAll(response);
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });

            semaphore.acquire();

            assertEquals(1, listenerResults.size());
            for (List<Integer> value : listenerResults.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testAsyncMapperReducer()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final Map<String, Integer> listenerResults = new HashMap<String, Integer>();
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, Integer>> future = job.mapper(new GroupingTestMapper()).reducer(new TestReducerFactory())
                    .submit();

            future.andThen(new ExecutionCallback<Map<String, Integer>>() {
                @Override
                public void onResponse(Map<String, Integer> response) {
                    try {
                        listenerResults.putAll(response);
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });

            
            int[] expectedResults = new int[4];
            for (int i = 0; i < 100; i++) {
                int index = i % 4;
                expectedResults[index] += i;
            }

            semaphore.acquire();

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResults[i], (int) listenerResults.get(String.valueOf(i)));
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testAsyncMapperCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final int[] result = new int[1];
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.mapper(new GroupingTestMapper()).submit(new GroupingTestCollator());

            future.andThen(new ExecutionCallback<Integer>() {
                @Override
                public void onResponse(Integer response) {
                    try {
                        result[0] = response.intValue();
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });

            
            int expectedResult = 0;
            for (int i = 0; i < 100; i++) {
                expectedResult += i;
            }

            semaphore.acquire();

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResult, result[0]);
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testAsyncMapperReducerCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final int[] result = new int[1];
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.mapper(new GroupingTestMapper()).reducer(new TestReducerFactory())
                    .submit(new TestCollator());

            future.andThen(new ExecutionCallback<Integer>() {
                @Override
                public void onResponse(Integer response) {
                    try {
                        result[0] = response.intValue();
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });

            
            int expectedResult = 0;
            for (int i = 0; i < 100; i++) {
                expectedResult += i;
            }

            semaphore.acquire();

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResult, result[0]);
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testNullFromObjectCombiner()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker jobTracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = jobTracker.newJob(KeyValueSource.fromMap(m1));
            JobCompletableFuture<Map<String, BigInteger>> future = job.chunkSize(10).mapper(new GroupingTestMapper())
                    .combiner(new ObjectCombinerFactory())
                    .reducer(new ObjectReducerFactory()).submit();

            int[] expectedResults = new int[4];
            for (int i = 0; i < 100; i++) {
                int index = i % 4;
                expectedResults[index] += i;
            }

            Map<String, BigInteger> map = future.get();
            for (int i = 0; i < 4; i++) {
                assertEquals(BigInteger.valueOf(expectedResults[i]), map.get(String.valueOf(i)));
            }
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testNullFromObjectReducer()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        try {

            assertClusterSizeEventually(3, h1);
            assertClusterSizeEventually(3, h2);
            assertClusterSizeEventually(3, h3);

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker jobTracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = jobTracker.newJob(KeyValueSource.fromMap(m1));
            JobCompletableFuture<Map<String, BigInteger>> future = job.chunkSize(10).mapper(new GroupingTestMapper())
                    .combiner(new ObjectCombinerFactory())
                    .reducer(new NullReducerFactory()).submit();

            Map<String, BigInteger> map = future.get();
            assertEquals(0, map.size());
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testDataSerializableIntermediateObject()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
        for (int i = 0; i < 100; i++) {
            m1.put(i, i);
        }

        JobTracker jobTracker = h1.getJobTracker("default");
        Job<Integer, Integer> job = jobTracker.newJob(KeyValueSource.fromMap(m1));
        ICompletableFuture<Integer> future = job.mapper(new TestMapper())
                .combiner(new DataSerializableIntermediateCombinerFactory())
                .reducer(new DataSerializableIntermediateReducerFactory())
                .submit(new DataSerializableIntermediateCollator());

        
        int expectedResult = 0;
        for (int i = 0; i < 100; i++) {
            expectedResult += i;
        }
        expectedResult = (int) ((double) expectedResult / 100);

        assertEquals(expectedResult, (int) future.get());
    }

    @Test(timeout = 60000)
    public void employeeMapReduceTest() throws Exception {

        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);
        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        try {
            final IMap map = h1.getMap(randomString());

            final int keyCount = 100;
            for (int id = 0; id < keyCount; id++) {
                map.put(id, new Employee(id));
            }

            JobTracker tracker = h1.getJobTracker(randomString());
            Job<Integer, Employee> job = tracker.newJob(KeyValueSource.fromMap(map));

            ICompletableFuture<Map<Integer, Set<Employee>>> future = job
                    .mapper(new ModIdMapper(2))
                    .combiner(new RangeIdCombinerFactory(10, 30))
                    .reducer(new IdReducerFactory(10, 20, 30))
                    .submit();

            Map<Integer, Set<Employee>> result = future.get();

            assertEquals("expected 8 Employees with id's ending 2, 4, 6, 8", 8, result.size());
        } finally {
            tripTerminate(h1, h2, h3);
        }
    }


    public static class ModIdMapper implements Mapper<Integer, Employee, Integer, Employee> {

        private int mod = 0;

        public ModIdMapper(int mod) {
            this.mod = mod;
        }

        public void map(Integer key, Employee e, Context<Integer, Employee> context) {
            if (e.getId() % mod == 0) {
                context.emit(key, e);
            }
        }
    }

    public static class RangeIdCombinerFactory implements CombinerFactory<Integer, Employee, Set<Employee>> {

        private int min = 0, max = 0;

        public RangeIdCombinerFactory(int min, int max) {
            this.min = min;
            this.max = max;
        }

        public Combiner<Employee, Set<Employee>> newCombiner(Integer key) {
            return new EmployeeCombiner();
        }

        private class EmployeeCombiner extends Combiner<Employee, Set<Employee>> {
            private Set<Employee> passed = new HashSet<Employee>();

            public void combine(Employee e) {
                if (e.getId() >= min && e.getId() <= max) {
                    passed.add(e);
                }
            }

            public Set<Employee> finalizeChunk() {
                if (passed.isEmpty()) {
                    return null;
                }
                return passed;
            }

            public void reset() {
                passed = new HashSet<Employee>();
            }
        }
    }


    public static class IdReducerFactory implements ReducerFactory<Integer, Set<Employee>, Set<Employee>> {

        private int[] removeIds = null;

        public IdReducerFactory(int... removeIds) {
            this.removeIds = removeIds;
        }

        public Reducer<Set<Employee>, Set<Employee>> newReducer(Integer key) {
            return new EmployeeReducer();
        }

        private class EmployeeReducer extends Reducer<Set<Employee>, Set<Employee>> {

            private volatile Set<Employee> passed = new HashSet<Employee>();

            public void reduce(Set<Employee> set) {
                for (Employee e : set) {
                    boolean add = true;
                    for (int id : removeIds) {
                        if (e.getId() == id) {
                            add = false;
                            break;
                        }
                    }
                    if (add) {
                        passed.add(e);
                    }
                }
            }

            public Set<Employee> finalizeReduce() {
                if (passed.isEmpty()) {
                    return null;
                }
                return passed;
            }
        }
    }


    public static class EmployeeCollator implements Collator<Map.Entry<Integer, Set<Employee>>, Map<Integer, Set<Employee>>> {

        public Map<Integer, Set<Employee>> collate(Iterable<Map.Entry<Integer, Set<Employee>>> values) {
            Map<Integer, Set<Employee>> result = new HashMap();
            for (Map.Entry<Integer, Set<Employee>> entry : values) {
                for (Employee e : entry.getValue()) {
                    result.put(e.getId(), entry.getValue());
                }
            }
            return result;
        }
    }


    public static class TupleIntInt
            implements DataSerializable {

        private int count;
        private int amount;

        public TupleIntInt() {
        }

        public TupleIntInt(int count, int amount) {
            this.count = count;
            this.amount = amount;
        }

        @Override
        public void writeData(ObjectDataOutput out)
                throws IOException {

            out.writeInt(count);
            out.writeInt(amount);
        }

        @Override
        public void readData(ObjectDataInput in)
                throws IOException {

            count = in.readInt();
            amount = in.readInt();
        }
    }

    public static class ObjectCombinerFactory
            implements CombinerFactory<String, Integer, BigInteger> {

        @Override
        public Combiner<Integer, BigInteger> newCombiner(String key) {
            return new ObjectCombiner();
        }
    }

    public static class ObjectCombiner
            extends Combiner<Integer, BigInteger> {

        private BigInteger count;

        @Override
        public void combine(Integer value) {
            count = count == null ? BigInteger.valueOf(value) : count.add(BigInteger.valueOf(value));
        }

        @Override
        public BigInteger finalizeChunk() {
            return count;
        }

        @Override
        public void reset() {
            count = null;
        }
    }

    public static class ObjectReducerFactory
            implements ReducerFactory<String, BigInteger, BigInteger> {

        @Override
        public Reducer<BigInteger, BigInteger> newReducer(String key) {
            return new ObjectReducer();
        }
    }

    public static class ObjectReducer
            extends Reducer<BigInteger, BigInteger> {

        private BigInteger count;

        @Override
        public void reduce(BigInteger value) {
            count = count == null ? value : value.add(count);
        }

        @Override
        public BigInteger finalizeReduce() {
            return count;
        }
    }

    public static class DataSerializableIntermediateCombinerFactory
            implements CombinerFactory<String, Integer, TupleIntInt> {

        @Override
        public Combiner<Integer, TupleIntInt> newCombiner(String key) {
            return new DataSerializableIntermediateCombiner();
        }
    }

    public static class DataSerializableIntermediateCombiner
            extends Combiner<Integer, TupleIntInt> {

        private int count;
        private int amount;

        @Override
        public void combine(Integer value) {
            count++;
            amount += value;
        }

        @Override
        public TupleIntInt finalizeChunk() {
            int count = this.count;
            int amount = this.amount;
            this.count = 0;
            this.amount = 0;
            return new TupleIntInt(count, amount);
        }
    }

    public static class DataSerializableIntermediateReducerFactory
            implements ReducerFactory<String, TupleIntInt, TupleIntInt> {

        @Override
        public Reducer<TupleIntInt, TupleIntInt> newReducer(String key) {
            return new DataSerializableIntermediateReducer();
        }
    }

    public static class DataSerializableIntermediateReducer
            extends Reducer<TupleIntInt, TupleIntInt> {

        private volatile int count;
        private volatile int amount;

        @Override
        public void reduce(TupleIntInt value) {
            count += value.count;
            amount += value.amount;
        }

        @Override
        public TupleIntInt finalizeReduce() {
            return new TupleIntInt(count, amount);
        }
    }

    public static class DataSerializableIntermediateCollator
            implements Collator<Map.Entry<String, TupleIntInt>, Integer> {

        @Override
        public Integer collate(Iterable<Map.Entry<String, TupleIntInt>> values) {
            int count = 0;
            int amount = 0;
            for (Map.Entry<String, TupleIntInt> value : values) {
                TupleIntInt tuple = value.getValue();
                count += tuple.count;
                amount += tuple.amount;
            }
            return (int) ((double) amount / count);
        }
    }

    public static class ExceptionThrowingMapper
            implements Mapper<Integer, Integer, String, Integer> {

        @Override
        public void map(Integer key, Integer value, Context<String, Integer> context) {
            throw new NullPointerException("BUMM!");
        }
    }

    public static class TimeConsumingMapper
            implements Mapper<Integer, Integer, String, Integer> {

        @Override
        public void map(Integer key, Integer value, Context<String, Integer> collector) {
            try {
                Thread.sleep(1000);
            } catch (Exception ignore) {
            }
            collector.emit(String.valueOf(key), value);
        }
    }

    public static class TestKeyPredicate
            implements KeyPredicate<Integer> {

        @Override
        public boolean evaluate(Integer key) {
            return key == 50;
        }
    }

    public static class TestMapper
            implements Mapper<Integer, Integer, String, Integer> {

        @Override
        public void map(Integer key, Integer value, Context<String, Integer> collector) {
            collector.emit(String.valueOf(key), value);
        }
    }

    public static class GroupingTestMapper
            implements Mapper<Integer, Integer, String, Integer> {

        private int moduleKey = -1;

        public GroupingTestMapper() {
        }

        public GroupingTestMapper(int moduleKey) {
            this.moduleKey = moduleKey;
        }

        @Override
        public void map(Integer key, Integer value, Context<String, Integer> collector) {
            if (moduleKey == -1 || (key % 4) == moduleKey) {
                collector.emit(String.valueOf(key % 4), value);
            }
        }
    }

    public static class TestReducer
            extends Reducer<Integer, Integer> {

        private volatile int sum = 0;

        @Override
        public void reduce(Integer value) {
            sum += value;
        }

        @Override
        public Integer finalizeReduce() {
            return sum;
        }
    }

    public static class TestReducerFactory
            implements ReducerFactory<String, Integer, Integer> {

        public TestReducerFactory() {
        }

        @Override
        public Reducer<Integer, Integer> newReducer(String key) {
            return new TestReducer();
        }
    }

    public static class GroupingTestCollator
            implements Collator<Map.Entry<String, List<Integer>>, Integer> {

        @Override
        public Integer collate(Iterable<Map.Entry<String, List<Integer>>> values) {
            int sum = 0;
            for (Map.Entry<String, List<Integer>> entry : values) {
                for (Integer value : entry.getValue()) {
                    sum += value;
                }
            }
            return sum;
        }
    }

    public static class TestCollator
            implements Collator<Map.Entry<String, Integer>, Integer> {

        @Override
        public Integer collate(Iterable<Map.Entry<String, Integer>> values) {
            int sum = 0;
            for (Map.Entry<String, Integer> entry : values) {
                sum += entry.getValue();
            }
            return sum;
        }
    }

    public static class NullReducerFactory
            implements ReducerFactory<String, BigInteger, BigInteger> {

        @Override
        public Reducer<BigInteger, BigInteger> newReducer(String key) {
            return new NullReducer();
        }
    }

    public static class NullReducer
            extends Reducer<BigInteger, BigInteger> {

        @Override
        public void reduce(BigInteger value) {
        }

        @Override
        public BigInteger finalizeReduce() {
            return null;
        }
    }

    public static class MapKeyValueSourceAdapter<K, V>
            extends KeyValueSource<K, V>
            implements DataSerializable, PartitionIdAware {

        private volatile KeyValueSource<K, V> keyValueSource;
        private int openCount = 0;

        public MapKeyValueSourceAdapter() {
        }

        public MapKeyValueSourceAdapter(KeyValueSource<K, V> keyValueSource) {
            this.keyValueSource = keyValueSource;
        }

        @Override
        public boolean open(NodeEngine nodeEngine) {
            if (openCount < 2) {
                openCount++;
                return false;
            }
            return keyValueSource.open(nodeEngine);
        }

        @Override
        public boolean hasNext() {
            return keyValueSource.hasNext();
        }

        @Override
        public K key() {
            return keyValueSource.key();
        }

        @Override
        public Map.Entry<K, V> element() {
            return keyValueSource.element();
        }

        @Override
        public boolean reset() {
            return keyValueSource.reset();
        }

        @Override
        public boolean isAllKeysSupported() {
            return keyValueSource.isAllKeysSupported();
        }

        @Override
        public Collection<K> getAllKeys0() {
            return keyValueSource.getAllKeys0();
        }

        public static <K1, V1> KeyValueSource<K1, V1> fromMap(IMap<K1, V1> map) {
            return KeyValueSource.fromMap(map);
        }

        public static <K1, V1> KeyValueSource<K1, V1> fromMultiMap(MultiMap<K1, V1> multiMap) {
            return KeyValueSource.fromMultiMap(multiMap);
        }

        public static <V1> KeyValueSource<String, V1> fromList(IList<V1> list) {
            return KeyValueSource.fromList(list);
        }

        public static <V1> KeyValueSource<String, V1> fromSet(ISet<V1> set) {
            return KeyValueSource.fromSet(set);
        }

        @Override
        public void close()
                throws IOException {
            keyValueSource.close();
        }

        @Override
        public void writeData(ObjectDataOutput out)
                throws IOException {
            out.writeObject(keyValueSource);
        }

        @Override
        public void readData(ObjectDataInput in)
                throws IOException {
            keyValueSource = in.readObject();
        }

        @Override
        public void setPartitionId(int partitionId) {
            if (keyValueSource instanceof PartitionIdAware) {
                ((PartitionIdAware) keyValueSource).setPartitionId(partitionId);
            }
        }
    }

    public static class ListResultingCombinerFactory implements CombinerFactory<String, Integer, List<Integer>> {

        @Override
        public Combiner<Integer, List<Integer>> newCombiner(String key) {
            return new ListResultingCombiner();
        }

        private class ListResultingCombiner extends Combiner<Integer, List<Integer>> {

            private final List<Integer> result = new ArrayList<Integer>();

            @Override
            public void combine(Integer value) {
                result.add(value);
            }

            @Override
            public List<Integer> finalizeChunk() {
                return new ArrayList<Integer>(result);
            }

            @Override
            public void reset() {
                result.clear();
            }
        }
    }

    public static class ListBasedReducerFactory implements ReducerFactory<String, List<Integer>, List<Integer>> {

        @Override
        public Reducer<List<Integer>, List<Integer>> newReducer(String key) {
            return new ListBasedReducer();
        }

        private class ListBasedReducer extends Reducer<List<Integer>, List<Integer>> {

            private final List<Integer> result = new ArrayList<Integer>();

            @Override
            public void reduce(List<Integer> value) {
                result.addAll(value);
            }

            @Override
            public List<Integer> finalizeReduce() {
                return result;
            }
        }
    }

    public static class FinalizingCombinerFactory implements CombinerFactory<String, Integer, List<Integer>> {

        @Override
        public Combiner<Integer, List<Integer>> newCombiner(String key) {
            return new FinalizingCombiner();
        }

        private class FinalizingCombiner extends Combiner<Integer, List<Integer>> {

            private List<Integer> result = new ArrayList<Integer>();

            @Override
            public void combine(Integer value) {
                result.add(value);
            }

            @Override
            public List<Integer> finalizeChunk() {
                return new ArrayList<Integer>(result);
            }

            @Override
            public void reset() {
                result.clear();
            }

            @Override
            public void finalizeCombine() {
                result = null;
            }
        }
    }
}

<code block>


package com.hazelcast.util;

import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.TestHazelcastInstanceFactory;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class HazelcastInstanceFactoryTest extends HazelcastTestSupport {

    @Test
    public void testTestHazelcastInstanceFactory() {
        TestHazelcastInstanceFactory instanceFactory = new TestHazelcastInstanceFactory();
        final HazelcastInstance instance1 = instanceFactory.newHazelcastInstance();
        final HazelcastInstance instance2 = instanceFactory.newHazelcastInstance();
        final HazelcastInstance instance3 = instanceFactory.newHazelcastInstance();


        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(3, instance1.getCluster().getMembers().size());
                assertEquals(3, instance2.getCluster().getMembers().size());
                assertEquals(3, instance3.getCluster().getMembers().size());
            }
        });

        instanceFactory.terminateAll();

    }

    @Test
    public void testTestHazelcastInstanceFactory_withTwoFactories() {
        TestHazelcastInstanceFactory instanceFactory = new TestHazelcastInstanceFactory();
        final HazelcastInstance instance1 = instanceFactory.newHazelcastInstance();
        final HazelcastInstance instance2 = instanceFactory.newHazelcastInstance();
        final HazelcastInstance instance3 = instanceFactory.newHazelcastInstance();

        TestHazelcastInstanceFactory instanceFactory2 = new TestHazelcastInstanceFactory();
        final HazelcastInstance instance1_2 = instanceFactory2.newHazelcastInstance();
        final HazelcastInstance instance2_2 = instanceFactory2.newHazelcastInstance();


        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(2, instance1_2.getCluster().getMembers().size());
                assertEquals(2, instance2_2.getCluster().getMembers().size());
            }
        });

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(3, instance1.getCluster().getMembers().size());
                assertEquals(3, instance2.getCluster().getMembers().size());
                assertEquals(3, instance3.getCluster().getMembers().size());
            }
        });

        instanceFactory.terminateAll();
        instanceFactory2.terminateAll();

    }
}

<code block>


package com.hazelcast.test;


public final class TestEnvironment {

    public static final String HAZELCAST_TEST_USE_NETWORK = "hazelcast.test.use.network";

    private TestEnvironment() {
    }

    public static boolean isMockNetwork() {
        return !Boolean.getBoolean(HAZELCAST_TEST_USE_NETWORK);
    }

}

<code block>


package com.hazelcast.test;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.AbstractJoiner;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.AddressPicker;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.NodeContext;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.IOService;
import com.hazelcast.nio.NodeIOService;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.executor.StripedRunnable;

import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.nio.channels.ServerSocketChannel;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.CopyOnWriteArraySet;

public final class TestNodeRegistry {

    private final ConcurrentMap<Address, NodeEngineImpl> nodes = new ConcurrentHashMap<Address, NodeEngineImpl>(10);
    private final Object joinerLock = new Object();

    public NodeContext createNodeContext(Address address) {
        return new MockNodeContext(nodes, address, joinerLock);
    }

    public HazelcastInstance getInstance(Address address) {
        NodeEngineImpl nodeEngine = nodes.get(address);
        return nodeEngine != null && nodeEngine.isActive() ? nodeEngine.getHazelcastInstance() : null;
    }

    Collection<HazelcastInstance> getAllHazelcastInstances() {
        Collection<HazelcastInstance> all = new LinkedList<HazelcastInstance>();
        for (NodeEngineImpl nodeEngine : nodes.values()) {
            if (nodeEngine.isActive()) {
                all.add(nodeEngine.getHazelcastInstance());
            }
        }
        return all;
    }

    void shutdown() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            value.getHazelcastInstance().shutdown();
        }
    }

    void terminate() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            HazelcastInstance hz = value.getHazelcastInstance();
            hz.getLifecycleService().terminate();
        }
    }

    private static class MockNodeContext implements NodeContext {

        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Address thisAddress;
        final Object joinerLock;

        public MockNodeContext(ConcurrentMap<Address, NodeEngineImpl> nodes, Address thisAddress, Object joinerLock) {
            this.nodes = nodes;
            this.thisAddress = thisAddress;
            this.joinerLock = joinerLock;
        }

        public AddressPicker createAddressPicker(Node node) {
            return new StaticAddressPicker(thisAddress);
        }

        public Joiner createJoiner(Node node) {
            return new MockJoiner(node, nodes, joinerLock);
        }

        public ConnectionManager createConnectionManager(Node node, ServerSocketChannel serverSocketChannel) {
            NodeIOService ioService = new NodeIOService(node, node.nodeEngine);
            return new MockConnectionManager(ioService, nodes, node, joinerLock);
        }
    }

    private static class StaticAddressPicker implements AddressPicker {
        final Address thisAddress;

        private StaticAddressPicker(Address thisAddress) {
            this.thisAddress = thisAddress;
        }

        public void pickAddress() throws Exception {
        }

        public Address getBindAddress() {
            return thisAddress;
        }

        public Address getPublicAddress() {
            return thisAddress;
        }

        public ServerSocketChannel getServerSocketChannel() {
            return null;
        }
    }

    private static class MockJoiner extends AbstractJoiner {

        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Object joinerLock;

        MockJoiner(Node node, ConcurrentMap<Address, NodeEngineImpl> nodes, Object joinerLock) {
            super(node);
            this.nodes = nodes;
            this.joinerLock = joinerLock;
        }

        public void doJoin() {
            NodeEngineImpl nodeEngine = null;
            synchronized (joinerLock) {
                for (Address address : nodes.keySet()) {
                    NodeEngineImpl ne = nodes.get(address);
                    if (ne != null && ne.getNode().isActive() && ne.getNode().joined()) {
                        nodeEngine = ne;
                        break;
                    }
                }
                Address master = null;
                if (nodeEngine != null) {
                    if (nodeEngine.getNode().isMaster()) {
                        master = nodeEngine.getThisAddress();
                    } else {
                        master = nodeEngine.getMasterAddress();
                    }
                }
                if (master == null) {
                    master = node.getThisAddress();
                }
                node.setMasterAddress(master);
                if (node.getMasterAddress().equals(node.getThisAddress())) {
                    node.setJoined();
                    node.setAsMaster();
                } else {
                    for (int i = 0; !node.joined() && i < 2000; i++) {
                        try {
                            node.clusterService.sendJoinRequest(node.getMasterAddress(), true);
                            Thread.sleep(50);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    if (!node.joined()) {
                        throw new AssertionError("Node[" + node.getThisAddress()
                                + "] should have been joined to " + node.getMasterAddress());
                    }
                }
            }
        }

        public void searchForOtherClusters() {
        }

        @Override
        public String getType() {
            return "mock";
        }

        public String toString() {
            return "MockJoiner";
        }

        @Override
        public void blacklist(Address address, boolean permanent) {
        }

        @Override
        public boolean unblacklist(Address address) {
            return false;
        }

        @Override
        public boolean isBlacklisted(Address address) {
            return false;
        }
    }

    private static class MockConnectionManager implements ConnectionManager {
        private final Set<ConnectionListener> connectionListeners = new CopyOnWriteArraySet<ConnectionListener>();
        private final IOService ioService;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Map<Address, MockConnection> mapConnections = new ConcurrentHashMap<Address, MockConnection>(10);
        final Node node;
        final Object joinerLock;

        MockConnectionManager(IOService ioService, ConcurrentMap<Address, NodeEngineImpl> nodes,
                              Node node, Object joinerLock) {
            this.ioService = ioService;
            this.nodes = nodes;
            this.node = node;
            this.joinerLock = joinerLock;
            synchronized (this.joinerLock) {
                this.nodes.put(node.getThisAddress(), node.nodeEngine);
            }
        }

        @Override
        public void dumpPerformanceMetrics(StringBuffer sb) {
        }

        public Connection getConnection(Address address) {
            MockConnection conn = mapConnections.get(address);
            if (conn == null) {
                NodeEngineImpl nodeEngine = nodes.get(address);
                MockConnection thisConnection = new MockConnection(address, node.getThisAddress(), node.nodeEngine);
                conn = new MockConnection(node.getThisAddress(), address, nodeEngine);
                conn.localConnection = thisConnection;
                thisConnection.localConnection = conn;
                mapConnections.put(address, conn);
            }
            return conn;
        }

        public Connection getOrConnect(Address address) {
            return getConnection(address);
        }

        public Connection getOrConnect(Address address, boolean silent) {
            return getConnection(address);
        }

        public void shutdown() {
            for (Address address : nodes.keySet()) {
                if (address.equals(node.getThisAddress())) continue;

                final NodeEngineImpl nodeEngine = nodes.get(address);
                if (nodeEngine != null && nodeEngine.isActive()) {
                    nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                        public void run() {
                            final ClusterServiceImpl clusterService = (ClusterServiceImpl) nodeEngine.getClusterService();
                            clusterService.removeAddress(node.getThisAddress());
                        }
                    });
                }
            }
        }

        @Override
        public boolean registerConnection(final Address remoteEndpoint, final Connection connection) {
            mapConnections.put(remoteEndpoint, (MockConnection) connection);
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionAdded(connection);
                    }
                }

                @Override
                public int getKey() {
                    return remoteEndpoint.hashCode();
                }
            });
            return true;
        }

        public void start() {
        }

        public void addConnectionListener(ConnectionListener connectionListener) {
            connectionListeners.add(connectionListener);
        }

        public void destroyConnection(final Connection connection) {
            final Address endPoint = connection.getEndPoint();
            ioService.getEventService().executeEventCallback(new StripedRunnable() {
                @Override
                public void run() {
                    for (ConnectionListener listener : connectionListeners) {
                        listener.connectionRemoved(connection);
                    }
                }

                @Override
                public int getKey() {
                    return endPoint.hashCode();
                }
            });
        }


        public void restart() {
        }

        @Override
        public int getActiveConnectionCount() {
            return 0;
        }

        public int getCurrentClientConnections() {
            return 0;
        }

        @Override
        public int getConnectionCount() {
            return 0;
        }

        public int getAllTextConnections() {
            return 0;
        }
    }

    public static class MockConnection implements Connection {
        protected final Address localEndpoint;
        volatile Connection localConnection;
        final Address remoteEndpoint;
        protected final NodeEngineImpl nodeEngine;
        private volatile boolean live = true;

        public MockConnection(Address localEndpoint, Address remoteEndpoint, NodeEngineImpl nodeEngine) {
            this.localEndpoint = localEndpoint;
            this.remoteEndpoint = remoteEndpoint;
            this.nodeEngine = nodeEngine;
        }

        public Address getEndPoint() {
            return remoteEndpoint;
        }

        public boolean live() {
            return live;
        }

        public boolean write(SocketWritable socketWritable) {
            final Packet packet = (Packet) socketWritable;
            if (nodeEngine.getNode().isActive()) {
                Packet newPacket = readFromPacket(packet);
                MemberImpl member = nodeEngine.getClusterService().getMember(localEndpoint);
                if (member != null) {
                    member.didRead();
                }
                nodeEngine.getPacketTransceiver().receive(newPacket);
                return true;
            }
            return false;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }

            newPacket.setConn(localConnection);
            return newPacket;
        }

        public long lastReadTime() {
            return System.currentTimeMillis();
        }

        public long lastWriteTime() {
            return System.currentTimeMillis();
        }

        public void close() {
            if (!live) {
                return;
            }
            live = false;
            nodeEngine.getNode().connectionManager.destroyConnection(this);
        }

        public boolean isClient() {
            return false;
        }

        @Override
        public ConnectionType getType() {
            return ConnectionType.MEMBER;
        }

        public InetAddress getInetAddress() {
            try {
                return localEndpoint.getInetAddress();
            } catch (UnknownHostException e) {
                throw ExceptionUtil.rethrow(e);
            }
        }

        public InetSocketAddress getRemoteSocketAddress() {
            return new InetSocketAddress(getInetAddress(), getPort());
        }

        public int getPort() {
            return localEndpoint.getPort();
        }

        @Override
        public boolean isAlive() {
            return true;
        }

        @Override
        public String toString() {
            return "MockConnection{" +
                    "localEndpoint=" + localEndpoint +
                    ", localConnection=" + localConnection +
                    ", remoteEndpoint=" + remoteEndpoint +
                    '}';
        }
    }
}

<code block>


package com.hazelcast.test;

import com.hazelcast.config.Config;
import com.hazelcast.config.XmlConfigBuilder;
import com.hazelcast.core.Hazelcast;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastInstanceFactory;
import com.hazelcast.instance.NodeContext;
import com.hazelcast.nio.Address;

import java.net.UnknownHostException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.List;
import java.util.concurrent.atomic.AtomicInteger;

import static com.hazelcast.util.Preconditions.checkNotNull;

public class TestHazelcastInstanceFactory {

    private final AtomicInteger ports = new AtomicInteger(5000);
    private final boolean mockNetwork = TestEnvironment.isMockNetwork();
    private final AtomicInteger nodeIndex = new AtomicInteger();

    protected TestNodeRegistry registry;
    protected List<Address> addresses;
    private int count;

    public TestHazelcastInstanceFactory(int count) {
        init(count);
        if (mockNetwork) {
            this.addresses.addAll(createAddresses(ports, count));
        }
    }

    public TestHazelcastInstanceFactory(String... addresses) {
        init(addresses.length);
        if (mockNetwork) {
            this.addresses.addAll(createAddresses(ports, addresses));
        }
    }

    private void init(int initialNodeCount) {
        this.count = initialNodeCount;
        if (mockNetwork) {
            this.addresses = new ArrayList<Address>(initialNodeCount);
            this.registry = new TestNodeRegistry();
        } else {
            this.addresses = null;
            this.registry = null;
        }
    }

    public HazelcastInstance newHazelcastInstance() {
        return newHazelcastInstance(new Config());
    }

    public HazelcastInstance newHazelcastInstance(Config config) {
        if (mockNetwork) {
            init(config);
            NodeContext nodeContext = registry.createNodeContext(pickAddress());
            return HazelcastInstanceFactory.newHazelcastInstance(config, null, nodeContext);
        }
        return HazelcastInstanceFactory.newHazelcastInstance(config);
    }

    private Address pickAddress() {
        int id = nodeIndex.getAndIncrement();
        if (addresses.size() > id) {
            return addresses.get(id);
        }
        Address address = createAddress("127.0.0.1", ports.incrementAndGet());
        addresses.add(address);
        return address;
    }

    public HazelcastInstance[] newInstances() {
        return newInstances(new Config());
    }

    public HazelcastInstance[] newInstances(Config config, int nodeCount) {
        final HazelcastInstance[] instances = new HazelcastInstance[nodeCount];
        for (int i = 0; i < nodeCount; i++) {
            instances[i] = newHazelcastInstance(config);
        }
        return instances;
    }

    public HazelcastInstance[] newInstances(Config config) {
        return newInstances(config, count);
    }

    public Collection<HazelcastInstance> getAllHazelcastInstances() {
        if (mockNetwork) {
            return registry.getAllHazelcastInstances();
        }
        return Hazelcast.getAllHazelcastInstances();
    }

    public void shutdownAll() {
        if (mockNetwork) {
            registry.shutdown();
        } else {
            Hazelcast.shutdownAll();
        }
    }

    public void terminateAll() {
        if (mockNetwork) {
            registry.terminate();
        } else {
            HazelcastInstanceFactory.terminateAll();
        }
    }

    private static List<Address> createAddresses(AtomicInteger ports, int count) {
        List<Address> addresses = new ArrayList<Address>(count);
        for (int i = 0; i < count; i++) {
            addresses.add(createAddress("127.0.0.1", ports.incrementAndGet()));
        }
        return addresses;
    }

    private static List<Address> createAddresses(AtomicInteger ports, String... addressArray) {
        checkElementsNotNull(addressArray);

        final int count = addressArray.length;
        List<Address> addresses = new ArrayList<Address>(count);
        for (int i = 0; i < count; i++) {
            addresses.add(createAddress(addressArray[i], ports.incrementAndGet()));
        }
        return addresses;
    }

    protected static Address createAddress(String host, int port) {
        try {
            return new Address(host, port);
        } catch (UnknownHostException e) {
            e.printStackTrace();
        }
        return null;
    }

    private static <T> void checkElementsNotNull(T[] array) {
        checkNotNull(array, "Array should not be null");
        for (Object element : array) {
            checkNotNull(element, "Array element should not be null");
        }
    }

    private static Config init(Config config) {
        if (config == null) {
            config = new XmlConfigBuilder().build();
        }
        config.setProperty(GroupProperties.PROP_WAIT_SECONDS_BEFORE_JOIN, "0");
        config.setProperty(GroupProperties.PROP_GRACEFUL_SHUTDOWN_MAX_WAIT, "120");
        config.setProperty(GroupProperties.PROP_PARTITION_BACKUP_SYNC_INTERVAL, "1");
        config.getNetworkConfig().getJoin().getMulticastConfig().setEnabled(false);
        return config;
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder("TestHazelcastInstanceFactory{");
        sb.append("addresses=").append(addresses);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.client;

import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.config.XmlClientConfigBuilder;
import com.hazelcast.client.impl.ClientServiceFactory;
import com.hazelcast.client.impl.DefaultClientServiceFactory;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.impl.HazelcastClientProxy;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.OutOfMemoryHandler;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.util.EmptyStatement;

import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;


public final class HazelcastClient {

    static {
        OutOfMemoryErrorDispatcher.setClientHandler(new ClientOutOfMemoryHandler());
    }

    private static final ConcurrentMap<String, HazelcastClientProxy> CLIENTS
            = new ConcurrentHashMap<String, HazelcastClientProxy>(5);

    
    private HazelcastClient() {
    }

    public static HazelcastInstance newHazelcastClient() {
        return newHazelcastClient(new XmlClientConfigBuilder().build());
    }

    public static HazelcastInstance newHazelcastClient(ClientConfig config) {
        if (config == null) {
            config = new XmlClientConfigBuilder().build();
        }

        final ClassLoader tccl = Thread.currentThread().getContextClassLoader();
        HazelcastClientProxy proxy;
        try {
            Thread.currentThread().setContextClassLoader(HazelcastClient.class.getClassLoader());
            ClientServiceFactory clientServiceFactory = new DefaultClientServiceFactory();
            final HazelcastClientInstanceImpl client = new HazelcastClientInstanceImpl(config, clientServiceFactory);
            client.start();
            OutOfMemoryErrorDispatcher.registerClient(client);
            proxy = new HazelcastClientProxy(client);
            CLIENTS.put(client.getName(), proxy);
        } finally {
            Thread.currentThread().setContextClassLoader(tccl);
        }
        return proxy;
    }

    
    public static HazelcastInstance getHazelcastClientByName(String instanceName) {
        return CLIENTS.get(instanceName);
    }


    
    public static Collection<HazelcastInstance> getAllHazelcastClients() {
        Collection<HazelcastClientProxy> values = CLIENTS.values();
        return Collections.<HazelcastInstance>unmodifiableCollection(new HashSet<HazelcastInstance>(values));
    }

    
    public static void shutdownAll() {
        for (HazelcastClientProxy proxy : CLIENTS.values()) {
            HazelcastClientInstanceImpl client = proxy.client;
            if (client == null) {
                continue;
            }
            proxy.client = null;
            try {
                client.shutdown();
            } catch (Throwable ignored) {
                EmptyStatement.ignore(ignored);
            }
        }
        OutOfMemoryErrorDispatcher.clearClients();
        CLIENTS.clear();
    }

    
    public static void shutdown(HazelcastInstance instance) {
        if (instance instanceof HazelcastClientProxy) {
            final HazelcastClientProxy proxy = (HazelcastClientProxy) instance;
            HazelcastClientInstanceImpl client = proxy.client;
            if (client == null) {
                return;
            }
            proxy.client = null;
            CLIENTS.remove(client.getName());

            try {
                client.shutdown();
            } catch (Throwable ignored) {
                EmptyStatement.ignore(ignored);
            } finally {
                OutOfMemoryErrorDispatcher.deregisterClient(client);
            }
        }
    }

    
    public static void shutdown(String instanceName) {
        HazelcastClientProxy proxy = CLIENTS.remove(instanceName);
        if (proxy == null) {
            return;
        }
        HazelcastClientInstanceImpl client = proxy.client;
        if (client == null) {
            return;
        }
        proxy.client = null;
        try {
            client.shutdown();
        } catch (Throwable ignored) {
            EmptyStatement.ignore(ignored);
        } finally {
            OutOfMemoryErrorDispatcher.deregisterClient(client);
        }
    }

    
    public static void setOutOfMemoryHandler(OutOfMemoryHandler outOfMemoryHandler) {
        OutOfMemoryErrorDispatcher.setClientHandler(outOfMemoryHandler);
    }

}

<code block>
package com.hazelcast.client.impl;

import com.hazelcast.cache.impl.nearcache.NearCacheManager;
import com.hazelcast.client.ClientExtension;
import com.hazelcast.client.HazelcastClient;
import com.hazelcast.client.LoadBalancer;
import com.hazelcast.client.config.ClientAwsConfig;
import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.config.ClientNetworkConfig;
import com.hazelcast.client.config.ClientProperties;
import com.hazelcast.client.config.ClientSecurityConfig;
import com.hazelcast.client.connection.AddressTranslator;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.connection.nio.ClientConnectionManagerImpl;
import com.hazelcast.client.impl.client.DistributedObjectInfo;
import com.hazelcast.client.impl.client.GetDistributedObjectsRequest;
import com.hazelcast.client.proxy.ClientClusterProxy;
import com.hazelcast.client.proxy.PartitionServiceProxy;
import com.hazelcast.client.spi.ClientClusterService;
import com.hazelcast.client.spi.ClientExecutionService;
import com.hazelcast.client.spi.ClientInvocationService;
import com.hazelcast.client.spi.ClientListenerService;
import com.hazelcast.client.spi.ClientPartitionService;
import com.hazelcast.client.spi.ClientTransactionManagerService;
import com.hazelcast.client.spi.ProxyManager;
import com.hazelcast.client.spi.impl.AwsAddressTranslator;
import com.hazelcast.client.spi.impl.ClientClusterServiceImpl;
import com.hazelcast.client.spi.impl.ClientExecutionServiceImpl;
import com.hazelcast.client.spi.impl.ClientInvocation;
import com.hazelcast.client.spi.impl.ClientListenerServiceImpl;
import com.hazelcast.client.spi.impl.ClientNonSmartInvocationServiceImpl;
import com.hazelcast.client.spi.impl.ClientPartitionServiceImpl;
import com.hazelcast.client.spi.impl.ClientSmartInvocationServiceImpl;
import com.hazelcast.client.spi.impl.ClientTransactionManagerServiceImpl;
import com.hazelcast.client.spi.impl.DefaultAddressTranslator;
import com.hazelcast.client.util.RoundRobinLB;
import com.hazelcast.collection.impl.list.ListService;
import com.hazelcast.collection.impl.queue.QueueService;
import com.hazelcast.collection.impl.set.SetService;
import com.hazelcast.concurrent.atomiclong.AtomicLongService;
import com.hazelcast.concurrent.atomicreference.AtomicReferenceService;
import com.hazelcast.concurrent.countdownlatch.CountDownLatchService;
import com.hazelcast.concurrent.idgen.IdGeneratorService;
import com.hazelcast.concurrent.lock.LockServiceImpl;
import com.hazelcast.concurrent.semaphore.SemaphoreService;
import com.hazelcast.config.Config;
import com.hazelcast.config.GroupConfig;
import com.hazelcast.core.Client;
import com.hazelcast.core.ClientService;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.DistributedObjectListener;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.IAtomicLong;
import com.hazelcast.core.IAtomicReference;
import com.hazelcast.core.ICountDownLatch;
import com.hazelcast.core.IExecutorService;
import com.hazelcast.core.IList;
import com.hazelcast.core.ILock;
import com.hazelcast.core.IMap;
import com.hazelcast.core.IQueue;
import com.hazelcast.core.ISemaphore;
import com.hazelcast.core.ISet;
import com.hazelcast.core.ITopic;
import com.hazelcast.core.IdGenerator;
import com.hazelcast.core.LifecycleService;
import com.hazelcast.core.MultiMap;
import com.hazelcast.core.PartitionService;
import com.hazelcast.core.ReplicatedMap;
import com.hazelcast.executor.impl.DistributedExecutorService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.mapreduce.JobTracker;
import com.hazelcast.mapreduce.impl.MapReduceService;
import com.hazelcast.multimap.impl.MultiMapService;
import com.hazelcast.nio.ClassLoaderUtil;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.quorum.QuorumService;
import com.hazelcast.replicatedmap.impl.ReplicatedMapService;
import com.hazelcast.ringbuffer.Ringbuffer;
import com.hazelcast.ringbuffer.impl.RingbufferService;
import com.hazelcast.security.Credentials;
import com.hazelcast.security.UsernamePasswordCredentials;
import com.hazelcast.spi.impl.SerializableList;
import com.hazelcast.spi.impl.SerializationServiceSupport;
import com.hazelcast.topic.impl.TopicService;
import com.hazelcast.transaction.HazelcastXAResource;
import com.hazelcast.transaction.TransactionContext;
import com.hazelcast.transaction.TransactionException;
import com.hazelcast.transaction.TransactionOptions;
import com.hazelcast.transaction.TransactionalTask;
import com.hazelcast.transaction.impl.xa.XAService;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.ServiceLoader;

import java.util.Collection;
import java.util.Iterator;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.logging.Level;

public class HazelcastClientInstanceImpl implements HazelcastInstance, SerializationServiceSupport {

    private static final AtomicInteger CLIENT_ID = new AtomicInteger();
    private static final ILogger LOGGER = Logger.getLogger(HazelcastClient.class);

    private final ClientProperties clientProperties;
    private final int id = CLIENT_ID.getAndIncrement();
    private final String instanceName;
    private final ClientConfig config;
    private final ThreadGroup threadGroup;
    private final LifecycleServiceImpl lifecycleService;
    private final SerializationService serializationService;
    private final ClientConnectionManager connectionManager;
    private final ClientClusterServiceImpl clusterService;
    private final ClientPartitionServiceImpl partitionService;
    private final ClientInvocationService invocationService;
    private final ClientExecutionServiceImpl executionService;
    private final ClientListenerServiceImpl listenerService;
    private final NearCacheManager nearCacheManager;
    private final ClientTransactionManagerService transactionManager;
    private final ProxyManager proxyManager;
    private final ConcurrentMap<String, Object> userContext;
    private final LoadBalancer loadBalancer;
    private final ClientExtension clientExtension;
    private final Credentials credentials;

    public HazelcastClientInstanceImpl(ClientConfig config, ClientServiceFactory clientServiceFactory) {
        this.config = config;
        final GroupConfig groupConfig = config.getGroupConfig();
        instanceName = "hz.client_" + id + (groupConfig != null ? "_" + groupConfig.getName() : "");
        clientExtension = createClientInitializer(config.getClassLoader());
        clientExtension.beforeStart(this);

        credentials = initCredentials(config);
        threadGroup = new ThreadGroup(instanceName);
        lifecycleService = new LifecycleServiceImpl(this);
        clientProperties = new ClientProperties(config);
        serializationService = clientExtension.createSerializationService();
        proxyManager = new ProxyManager(this);
        executionService = initExecutionService();
        loadBalancer = initLoadBalancer(config);
        transactionManager = new ClientTransactionManagerServiceImpl(this, loadBalancer);
        partitionService = new ClientPartitionServiceImpl(this);
        connectionManager = clientServiceFactory.createConnectionManager(config, this);
        clusterService = new ClientClusterServiceImpl(this);
        invocationService = initInvocationService();
        listenerService = initListenerService();
        userContext = new ConcurrentHashMap<String, Object>();
        nearCacheManager = clientExtension.createNearCacheManager();

        proxyManager.init(config);
    }

    private LoadBalancer initLoadBalancer(ClientConfig config) {
        LoadBalancer lb = config.getLoadBalancer();
        if (lb == null) {
            lb = new RoundRobinLB();
        }
        return lb;
    }

    private Credentials initCredentials(ClientConfig config) {
        final GroupConfig groupConfig = config.getGroupConfig();
        final ClientSecurityConfig securityConfig = config.getSecurityConfig();
        Credentials c = securityConfig.getCredentials();
        if (c == null) {
            final String credentialsClassname = securityConfig.getCredentialsClassname();
            if (credentialsClassname != null) {
                try {
                    c = ClassLoaderUtil.newInstance(config.getClassLoader(), credentialsClassname);
                } catch (Exception e) {
                    throw ExceptionUtil.rethrow(e);
                }
            }
        }
        if (c == null) {
            c = new UsernamePasswordCredentials(groupConfig.getName(), groupConfig.getPassword());
        }
        return c;
    }

    private ClientInvocationService initInvocationService() {
        final ClientNetworkConfig networkConfig = config.getNetworkConfig();
        if (networkConfig.isSmartRouting()) {
            return new ClientSmartInvocationServiceImpl(this, loadBalancer);

        } else {
            return new ClientNonSmartInvocationServiceImpl(this);
        }
    }

    public int getId() {
        return id;
    }

    private ClientExtension createClientInitializer(ClassLoader classLoader) {
        try {
            String factoryId = ClientExtension.class.getName();
            Iterator<ClientExtension> iter = ServiceLoader.iterator(ClientExtension.class, factoryId, classLoader);
            while (iter.hasNext()) {
                ClientExtension initializer = iter.next();
                if (!(initializer.getClass().equals(DefaultClientExtension.class))) {
                    return initializer;
                }
            }
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }
        return new DefaultClientExtension();
    }

    private ClientListenerServiceImpl initListenerService() {
        int eventQueueCapacity = clientProperties.getEventQueueCapacity().getInteger();
        int eventThreadCount = clientProperties.getEventThreadCount().getInteger();
        return new ClientListenerServiceImpl(this, eventThreadCount, eventQueueCapacity);
    }

    private ClientExecutionServiceImpl initExecutionService() {
        return new ClientExecutionServiceImpl(instanceName, threadGroup,
                config.getClassLoader(), config.getExecutorPoolSize());
    }

    public void start() {
        lifecycleService.setStarted();
        connectionManager.start();
        try {
            clusterService.start();
        } catch (Exception e) {
            lifecycleService.shutdown();
            throw ExceptionUtil.rethrow(e);
        }
        loadBalancer.init(getCluster(), config);
        partitionService.start();
        clientExtension.afterStart(this);
    }

    ClientConnectionManager initClientConnectionManager() {
        final ClientAwsConfig awsConfig = config.getNetworkConfig().getAwsConfig();
        AddressTranslator addressTranslator;
        if (awsConfig != null && awsConfig.isEnabled()) {
            try {
                addressTranslator = new AwsAddressTranslator(awsConfig);
            } catch (NoClassDefFoundError e) {
                LOGGER.log(Level.WARNING, "hazelcast-cloud.jar might be missing!");
                throw e;
            }
        } else {
            addressTranslator = new DefaultAddressTranslator();
        }
        return new ClientConnectionManagerImpl(this, addressTranslator);
    }

    @Override
    public HazelcastXAResource getXAResource() {
        return getDistributedObject(XAService.SERVICE_NAME, XAService.SERVICE_NAME);
    }

    public Config getConfig() {
        throw new UnsupportedOperationException("Client cannot access cluster config!");
    }

    public ClientProperties getClientProperties() {
        return clientProperties;
    }

    @Override
    public String getName() {
        return instanceName;
    }

    @Override
    public <E> IQueue<E> getQueue(String name) {
        return getDistributedObject(QueueService.SERVICE_NAME, name);
    }

    @Override
    public <E> ITopic<E> getTopic(String name) {
        return getDistributedObject(TopicService.SERVICE_NAME, name);
    }

    @Override
    public <E> ITopic<E> getReliableTopic(String name) {
        throw new UnsupportedOperationException();
    }

    @Override
    public <E> ISet<E> getSet(String name) {
        return getDistributedObject(SetService.SERVICE_NAME, name);
    }

    @Override
    public <E> IList<E> getList(String name) {
        return getDistributedObject(ListService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> IMap<K, V> getMap(String name) {
        return getDistributedObject(MapService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> MultiMap<K, V> getMultiMap(String name) {
        return getDistributedObject(MultiMapService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> ReplicatedMap<K, V> getReplicatedMap(String name) {
        return getDistributedObject(ReplicatedMapService.SERVICE_NAME, name);
    }

    @Override
    public JobTracker getJobTracker(String name) {
        return getDistributedObject(MapReduceService.SERVICE_NAME, name);
    }

    @Override
    public ILock getLock(String key) {
        return getDistributedObject(LockServiceImpl.SERVICE_NAME, key);
    }

    @Override
    public <E> Ringbuffer<E> getRingbuffer(String name) {
        return getDistributedObject(RingbufferService.SERVICE_NAME, name);
    }

    @Override
    public Cluster getCluster() {
        return new ClientClusterProxy(clusterService);
    }

    @Override
    public Client getLocalEndpoint() {
        return clusterService.getLocalClient();
    }

    @Override
    public IExecutorService getExecutorService(String name) {
        return getDistributedObject(DistributedExecutorService.SERVICE_NAME, name);
    }

    public <T> T executeTransaction(TransactionalTask<T> task) throws TransactionException {
        return transactionManager.executeTransaction(task);
    }

    @Override
    public <T> T executeTransaction(TransactionOptions options, TransactionalTask<T> task) throws TransactionException {
        return transactionManager.executeTransaction(options, task);
    }

    @Override
    public TransactionContext newTransactionContext() {
        return transactionManager.newTransactionContext();
    }

    @Override
    public TransactionContext newTransactionContext(TransactionOptions options) {
        return transactionManager.newTransactionContext(options);
    }

    public ClientTransactionManagerService getTransactionManager() {
        return transactionManager;
    }

    @Override
    public IdGenerator getIdGenerator(String name) {
        return getDistributedObject(IdGeneratorService.SERVICE_NAME, name);
    }

    @Override
    public IAtomicLong getAtomicLong(String name) {
        return getDistributedObject(AtomicLongService.SERVICE_NAME, name);
    }

    @Override
    public <E> IAtomicReference<E> getAtomicReference(String name) {
        return getDistributedObject(AtomicReferenceService.SERVICE_NAME, name);
    }

    @Override
    public ICountDownLatch getCountDownLatch(String name) {
        return getDistributedObject(CountDownLatchService.SERVICE_NAME, name);
    }

    @Override
    public ISemaphore getSemaphore(String name) {
        return getDistributedObject(SemaphoreService.SERVICE_NAME, name);
    }

    @Override
    public Collection<DistributedObject> getDistributedObjects() {
        try {
            GetDistributedObjectsRequest request = new GetDistributedObjectsRequest();

            final Future<SerializableList> future = new ClientInvocation(this, request).invoke();
            final SerializableList serializableList = serializationService.toObject(future.get());
            for (Data data : serializableList) {
                final DistributedObjectInfo o = serializationService.toObject(data);
                getDistributedObject(o.getServiceName(), o.getName());
            }
            return (Collection<DistributedObject>) proxyManager.getDistributedObjects();
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }
    }

    @Override
    public String addDistributedObjectListener(DistributedObjectListener distributedObjectListener) {
        return proxyManager.addDistributedObjectListener(distributedObjectListener);
    }

    @Override
    public boolean removeDistributedObjectListener(String registrationId) {
        return proxyManager.removeDistributedObjectListener(registrationId);
    }

    @Override
    public PartitionService getPartitionService() {
        return new PartitionServiceProxy(partitionService, listenerService);
    }

    @Override
    public QuorumService getQuorumService() {
        throw new UnsupportedOperationException();
    }

    @Override
    public ClientService getClientService() {
        throw new UnsupportedOperationException();
    }

    @Override
    public LoggingService getLoggingService() {
        throw new UnsupportedOperationException();
    }

    @Override
    public LifecycleService getLifecycleService() {
        return lifecycleService;
    }

    @Override
    public <T extends DistributedObject> T getDistributedObject(String serviceName, String name) {
        return (T) proxyManager.getOrCreateProxy(serviceName, name);
    }

    @Override
    public ConcurrentMap<String, Object> getUserContext() {
        return userContext;
    }

    public ClientConfig getClientConfig() {
        return config;
    }

    public SerializationService getSerializationService() {
        return serializationService;
    }

    public ClientConnectionManager getConnectionManager() {
        return connectionManager;
    }

    public ClientClusterService getClientClusterService() {
        return clusterService;
    }

    public ClientExecutionService getClientExecutionService() {
        return executionService;
    }

    public ClientPartitionService getClientPartitionService() {
        return partitionService;
    }

    public ClientInvocationService getInvocationService() {
        return invocationService;
    }

    public ClientListenerService getListenerService() {
        return listenerService;
    }

    public NearCacheManager getNearCacheManager() {
        return nearCacheManager;
    }

    public ThreadGroup getThreadGroup() {
        return threadGroup;
    }

    public ClientExtension getClientExtension() {
        return clientExtension;
    }

    public Credentials getCredentials() {
        return credentials;
    }

    @Override
    public void shutdown() {
        getLifecycleService().shutdown();
    }

    public void doShutdown() {
        proxyManager.destroy();
        executionService.shutdown();
        partitionService.stop();
        transactionManager.shutdown();
        connectionManager.shutdown();
        invocationService.shutdown();
        listenerService.shutdown();
        serializationService.destroy();
        nearCacheManager.destroyAllNearCaches();
    }
}

<code block>


package com.hazelcast.client.impl;

import com.hazelcast.client.HazelcastClient;
import com.hazelcast.client.config.ClientAwsConfig;
import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.connection.AddressTranslator;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.connection.nio.ClientConnectionManagerImpl;
import com.hazelcast.client.spi.impl.AwsAddressTranslator;
import com.hazelcast.client.spi.impl.DefaultAddressTranslator;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;

import java.util.logging.Level;

public class DefaultClientServiceFactory implements ClientServiceFactory {

    private static final ILogger LOGGER = Logger.getLogger(HazelcastClient.class);

    public DefaultClientServiceFactory() {
    }

    @Override
    public ClientConnectionManager createConnectionManager(ClientConfig config, HazelcastClientInstanceImpl client) {
        final ClientAwsConfig awsConfig = config.getNetworkConfig().getAwsConfig();
        AddressTranslator addressTranslator;
        if (awsConfig != null && awsConfig.isEnabled()) {
            try {
                addressTranslator = new AwsAddressTranslator(awsConfig);
            } catch (NoClassDefFoundError e) {
                LOGGER.log(Level.WARNING, "hazelcast-cloud.jar might be missing!");
                throw e;
            }
        } else {
            addressTranslator = new DefaultAddressTranslator();
        }
        return new ClientConnectionManagerImpl(client, addressTranslator);
    }
}

<code block>


package com.hazelcast.client.impl;

import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.connection.ClientConnectionManager;

public interface ClientServiceFactory {

    ClientConnectionManager createConnectionManager(ClientConfig config, HazelcastClientInstanceImpl client);
}

<code block>


package com.hazelcast.client.connection.nio;

import com.hazelcast.client.ClientTypes;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.core.LifecycleService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.Protocols;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.IOSelector;
import com.hazelcast.nio.tcp.SocketChannelWrapper;

import java.io.Closeable;
import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.Socket;
import java.nio.ByteBuffer;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;

import static com.hazelcast.util.StringUtil.stringToBytes;

public class ClientConnection implements Connection, Closeable {

    protected final int connectionId;
    private final AtomicBoolean live = new AtomicBoolean(true);
    private final ILogger logger = Logger.getLogger(ClientConnection.class);

    private final AtomicInteger packetCount = new AtomicInteger(0);
    private final ClientWriteHandler writeHandler;
    private final ClientReadHandler readHandler;
    private final SocketChannelWrapper socketChannelWrapper;
    private final ClientConnectionManager connectionManager;
    private final SerializationService serializationService;
    private final LifecycleService lifecycleService;

    private volatile Address remoteEndpoint;
    private volatile boolean heartBeating = true;

    public ClientConnection(HazelcastClientInstanceImpl client, IOSelector in, IOSelector out,
                            int connectionId, SocketChannelWrapper socketChannelWrapper) throws IOException {
        final Socket socket = socketChannelWrapper.socket();
        this.connectionManager = client.getConnectionManager();
        this.serializationService = client.getSerializationService();
        this.lifecycleService = client.getLifecycleService();
        this.socketChannelWrapper = socketChannelWrapper;
        this.connectionId = connectionId;
        this.readHandler = new ClientReadHandler(this, in, socket.getReceiveBufferSize());
        this.writeHandler = new ClientWriteHandler(this, out, socket.getSendBufferSize());
    }

    public ClientConnection(HazelcastClientInstanceImpl client,
                            int connectionId) throws IOException {
        this.connectionManager = client.getConnectionManager();
        this.serializationService = client.getSerializationService();
        this.lifecycleService = client.getLifecycleService();
        this.connectionId = connectionId;
        writeHandler = null;
        readHandler = null;
        socketChannelWrapper = null;
    }

    public void incrementPacketCount() {
        packetCount.incrementAndGet();
    }

    public void decrementPacketCount() {
        packetCount.decrementAndGet();
    }

    public int getPacketCount() {
        return packetCount.get();
    }

    public SerializationService getSerializationService() {
        return serializationService;
    }

    @Override
    public boolean write(SocketWritable packet) {
        if (!live.get()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Connection is closed, won't write packet -> " + packet);
            }
            return false;
        }
        writeHandler.enqueueSocketWritable(packet);
        return true;
    }

    public void init() throws IOException {
        final ByteBuffer buffer = ByteBuffer.allocate(6);
        buffer.put(stringToBytes(Protocols.CLIENT_BINARY));
        buffer.put(stringToBytes(ClientTypes.JAVA));
        buffer.flip();
        socketChannelWrapper.write(buffer);
    }

    @Override
    public Address getEndPoint() {
        return remoteEndpoint;
    }

    @Override
    public boolean isAlive() {
        return live.get();
    }

    @Override
    public long lastReadTime() {
        return readHandler.getLastHandle();
    }

    @Override
    public long lastWriteTime() {
        return writeHandler.getLastHandle();
    }

    @Override
    public void close() {
        close(null);
    }

    @Override
    public ConnectionType getType() {
        return ConnectionType.JAVA_CLIENT;
    }

    @Override
    public boolean isClient() {
        return true;
    }

    @Override
    public InetAddress getInetAddress() {
        return socketChannelWrapper.socket().getInetAddress();
    }

    @Override
    public InetSocketAddress getRemoteSocketAddress() {
        return (InetSocketAddress) socketChannelWrapper.socket().getRemoteSocketAddress();
    }

    @Override
    public int getPort() {
        return socketChannelWrapper.socket().getPort();
    }

    public SocketChannelWrapper getSocketChannelWrapper() {
        return socketChannelWrapper;
    }

    public ClientConnectionManager getConnectionManager() {
        return connectionManager;
    }

    public ClientReadHandler getReadHandler() {
        return readHandler;
    }

    public void setRemoteEndpoint(Address remoteEndpoint) {
        this.remoteEndpoint = remoteEndpoint;
    }

    public Address getRemoteEndpoint() {
        return remoteEndpoint;
    }

    public InetSocketAddress getLocalSocketAddress() {
        return (InetSocketAddress) socketChannelWrapper.socket().getLocalSocketAddress();
    }

    protected void innerClose() throws IOException {
        if (socketChannelWrapper.isOpen()) {
            socketChannelWrapper.close();
        }
        readHandler.shutdown();
        writeHandler.shutdown();
    }

    public void close(Throwable t) {
        if (!live.compareAndSet(true, false)) {
            return;
        }
        String message = "Connection [" + getRemoteSocketAddress() + "] lost. Reason: ";
        if (t != null) {
            message += t.getClass().getName() + "[" + t.getMessage() + "]";
        } else {
            message += "Socket explicitly closed";
        }

        try {
            innerClose();
        } catch (Exception e) {
            logger.warning(e);
        }

        if (lifecycleService.isRunning()) {
            logger.warning(message);
        } else {
            logger.finest(message);
        }
    }

    
    @edu.umd.cs.findbugs.annotations.SuppressWarnings("VO_VOLATILE_INCREMENT")
    void heartBeatingFailed() {
        heartBeating = false;
    }

    void heartBeatingSucceed() {
        heartBeating = true;
    }

    public boolean isHeartBeating() {
        return live.get() && heartBeating;
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (!(o instanceof ClientConnection)) {
            return false;
        }

        ClientConnection that = (ClientConnection) o;

        if (connectionId != that.connectionId) {
            return false;
        }

        return true;
    }

    @Override
    public int hashCode() {
        return connectionId;
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder("ClientConnection{");
        sb.append("live=").append(live);
        sb.append(", writeHandler=").append(writeHandler);
        sb.append(", readHandler=").append(readHandler);
        sb.append(", connectionId=").append(connectionId);
        sb.append(", socketChannel=").append(socketChannelWrapper);
        sb.append(", remoteEndpoint=").append(remoteEndpoint);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.client.connection.nio;

import com.hazelcast.client.ClientExtension;
import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.config.ClientNetworkConfig;
import com.hazelcast.client.config.ClientProperties;
import com.hazelcast.client.config.SocketOptions;
import com.hazelcast.client.connection.AddressTranslator;
import com.hazelcast.client.connection.Authenticator;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.spi.ClientInvocationService;
import com.hazelcast.client.spi.impl.ClientExecutionServiceImpl;
import com.hazelcast.client.spi.impl.ClientInvocation;
import com.hazelcast.client.spi.impl.ClientListenerServiceImpl;
import com.hazelcast.client.spi.impl.ConnectionHeartbeatListener;
import com.hazelcast.cluster.client.ClientPingRequest;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketInterceptor;
import com.hazelcast.nio.tcp.IOSelector;
import com.hazelcast.nio.tcp.IOSelectorOutOfMemoryHandler;
import com.hazelcast.nio.tcp.InSelectorImpl;
import com.hazelcast.nio.tcp.SocketChannelWrapper;
import com.hazelcast.nio.tcp.SocketChannelWrapperFactory;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;

import java.io.IOException;
import java.net.Socket;
import java.nio.channels.SocketChannel;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.CopyOnWriteArraySet;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

import static com.hazelcast.client.config.ClientProperties.PROP_HEARTBEAT_INTERVAL_DEFAULT;
import static com.hazelcast.client.config.ClientProperties.PROP_HEARTBEAT_TIMEOUT_DEFAULT;
import static com.hazelcast.client.config.SocketOptions.DEFAULT_BUFFER_SIZE_BYTE;
import static com.hazelcast.client.config.SocketOptions.KILO_BYTE;

public class ClientConnectionManagerImpl implements ClientConnectionManager {

    private static final ILogger LOGGER = Logger.getLogger(ClientConnectionManagerImpl.class);

    private static final IOSelectorOutOfMemoryHandler OUT_OF_MEMORY_HANDLER = new IOSelectorOutOfMemoryHandler() {
        @Override
        public void handle(OutOfMemoryError error) {
            LOGGER.severe(error);
        }
    };

    private final int connectionTimeout;
    private final int heartBeatInterval;
    private final int heartBeatTimeout;

    private final ConcurrentMap<Address, Object> connectionLockMap = new ConcurrentHashMap<Address, Object>();

    protected final AtomicInteger connectionIdGen = new AtomicInteger();
    private final HazelcastClientInstanceImpl client;
    private final SocketInterceptor socketInterceptor;
    private final SocketOptions socketOptions;
    private IOSelector inSelector;
    private IOSelector outSelector;

    private final SocketChannelWrapperFactory socketChannelWrapperFactory;
    private final ClientExecutionServiceImpl executionService;
    private final AddressTranslator addressTranslator;
    private final ConcurrentMap<Address, ClientConnection> connections
            = new ConcurrentHashMap<Address, ClientConnection>();

    private final Set<ConnectionListener> connectionListeners = new CopyOnWriteArraySet<ConnectionListener>();
    private final Set<ConnectionHeartbeatListener> heartbeatListeners =
            new CopyOnWriteArraySet<ConnectionHeartbeatListener>();

    protected volatile boolean alive;

    public ClientConnectionManagerImpl(HazelcastClientInstanceImpl client,
                                       AddressTranslator addressTranslator) {
        this.client = client;
        this.addressTranslator = addressTranslator;
        final ClientConfig config = client.getClientConfig();
        final ClientNetworkConfig networkConfig = config.getNetworkConfig();

        final int connTimeout = networkConfig.getConnectionTimeout();
        connectionTimeout = connTimeout == 0 ? Integer.MAX_VALUE : connTimeout;

        final ClientProperties clientProperties = client.getClientProperties();
        int timeout = clientProperties.getHeartbeatTimeout().getInteger();
        this.heartBeatTimeout = timeout > 0 ? timeout : Integer.parseInt(PROP_HEARTBEAT_TIMEOUT_DEFAULT);

        int interval = clientProperties.getHeartbeatInterval().getInteger();
        heartBeatInterval = interval > 0 ? interval : Integer.parseInt(PROP_HEARTBEAT_INTERVAL_DEFAULT);

        executionService = (ClientExecutionServiceImpl) client.getClientExecutionService();

        initializeSelectors(client);

        socketOptions = networkConfig.getSocketOptions();
        ClientExtension clientExtension = client.getClientExtension();
        socketChannelWrapperFactory = clientExtension.createSocketChannelWrapperFactory();
        socketInterceptor = initSocketInterceptor(networkConfig.getSocketInterceptorConfig());
    }

    protected void initializeSelectors(HazelcastClientInstanceImpl client) {
        inSelector = new InSelectorImpl(
                client.getThreadGroup(),
                client.getName() + ".ClientInSelector",
                Logger.getLogger(InSelectorImpl.class),
                OUT_OF_MEMORY_HANDLER);
        outSelector = new ClientOutSelectorImpl(
                client.getThreadGroup(),
                client.getName() + ".ClientOutSelector",
                Logger.getLogger(ClientOutSelectorImpl.class),
                OUT_OF_MEMORY_HANDLER);
    }


    private SocketInterceptor initSocketInterceptor(SocketInterceptorConfig sic) {
        if (sic != null && sic.isEnabled()) {
            ClientExtension clientExtension = client.getClientExtension();
            return clientExtension.createSocketInterceptor();
        }
        return null;
    }

    @Override
    public boolean isAlive() {
        return alive;
    }

    @Override
    public synchronized void start() {
        if (alive) {
            return;
        }
        alive = true;
        startSelectors();
        HeartBeat heartBeat = new HeartBeat();
        executionService.scheduleWithFixedDelay(heartBeat, heartBeatInterval, heartBeatInterval, TimeUnit.MILLISECONDS);
    }

    protected void startSelectors() {
        inSelector.start();
        outSelector.start();
    }

    @Override
    public synchronized void shutdown() {
        if (!alive) {
            return;
        }
        alive = false;
        for (ClientConnection connection : connections.values()) {
            connection.close();
        }
        shutdownSelectors();
        connectionLockMap.clear();
        connectionListeners.clear();
        heartbeatListeners.clear();
    }

    protected void shutdownSelectors() {
        inSelector.shutdown();
        outSelector.shutdown();
    }

    public ClientConnection getConnection(Address target) {
        return connections.get(target);
    }

    public ClientConnection getOrConnect(Address target, Authenticator authenticator) throws IOException {
        Address address = addressTranslator.translate(target);

        if (address == null) {
            throw new IOException("Address is required!");
        }

        ClientConnection connection = connections.get(target);
        if (connection == null) {
            final Object lock = getLock(target);
            synchronized (lock) {
                connection = connections.get(target);
                if (connection == null) {
                    connection = createSocketConnection(address);
                    authenticate(authenticator, connection);
                    connections.put(connection.getRemoteEndpoint(), connection);
                    fireConnectionAddedEvent(connection);
                }
            }
        }
        return connection;
    }

    private void authenticate(Authenticator authenticator, ClientConnection connection) throws IOException {
        try {
            authenticator.authenticate(connection);
        } catch (Throwable throwable) {
            connection.close(throwable);
            throw ExceptionUtil.rethrow(throwable, IOException.class);
        }
    }

    private void fireConnectionAddedEvent(ClientConnection connection) {
        for (ConnectionListener connectionListener : connectionListeners) {
            connectionListener.connectionAdded(connection);
        }
    }

    protected ClientConnection createSocketConnection(final Address address) throws IOException {
        if (!alive) {
            throw new HazelcastException("ConnectionManager is not active!!!");
        }
        SocketChannel socketChannel = null;
        try {
            socketChannel = SocketChannel.open();
            Socket socket = socketChannel.socket();
            socket.setKeepAlive(socketOptions.isKeepAlive());
            socket.setTcpNoDelay(socketOptions.isTcpNoDelay());
            socket.setReuseAddress(socketOptions.isReuseAddress());
            if (socketOptions.getLingerSeconds() > 0) {
                socket.setSoLinger(true, socketOptions.getLingerSeconds());
            }
            int bufferSize = socketOptions.getBufferSize() * KILO_BYTE;
            if (bufferSize <= 0) {
                bufferSize = DEFAULT_BUFFER_SIZE_BYTE;
            }
            socket.setSendBufferSize(bufferSize);
            socket.setReceiveBufferSize(bufferSize);
            socketChannel.socket().connect(address.getInetSocketAddress(), connectionTimeout);
            SocketChannelWrapper socketChannelWrapper =
                    socketChannelWrapperFactory.wrapSocketChannel(socketChannel, true);
            final ClientConnection clientConnection = new ClientConnection(client, inSelector,
                    outSelector, connectionIdGen.incrementAndGet(), socketChannelWrapper);
            socketChannel.configureBlocking(true);
            if (socketInterceptor != null) {
                socketInterceptor.onConnect(socket);
            }
            socketChannel.configureBlocking(false);
            socket.setSoTimeout(0);
            clientConnection.getReadHandler().register();
            return clientConnection;
        } catch (Exception e) {
            if (socketChannel != null) {
                socketChannel.close();
            }
            throw ExceptionUtil.rethrow(e, IOException.class);
        }
    }

    @Override
    public void destroyConnection(final Connection connection) {
        Address endpoint = connection.getEndPoint();
        if (endpoint != null) {
            final ClientConnection conn = connections.remove(endpoint);
            if (conn == null) {
                return;
            }
            conn.close();
            for (ConnectionListener connectionListener : connectionListeners) {
                connectionListener.connectionRemoved(conn);
            }

        } else {
            ClientInvocationService invocationService = client.getInvocationService();
            invocationService.cleanConnectionResources((ClientConnection) connection);
        }
    }

    @Override
    public void handlePacket(Packet packet) {
        final ClientConnection conn = (ClientConnection) packet.getConn();
        conn.incrementPacketCount();
        if (packet.isHeaderSet(Packet.HEADER_EVENT)) {
            final ClientListenerServiceImpl listenerService = (ClientListenerServiceImpl) client.getListenerService();
            listenerService.handleEventPacket(packet);
        } else {
            ClientInvocationService invocationService = client.getInvocationService();
            invocationService.handlePacket(packet);
        }
    }

    private Object getLock(Address address) {
        Object lock = connectionLockMap.get(address);
        if (lock == null) {
            lock = new Object();
            Object current = connectionLockMap.putIfAbsent(address, lock);
            if (current != null) {
                lock = current;
            }
        }
        return lock;
    }

    class HeartBeat implements Runnable {

        @Override
        public void run() {
            if (!alive) {
                return;
            }
            final long now = Clock.currentTimeMillis();
            for (ClientConnection connection : connections.values()) {
                if (now - connection.lastReadTime() > heartBeatTimeout) {
                    if (connection.isHeartBeating()) {
                        connection.heartBeatingFailed();
                        fireHeartBeatStopped(connection);
                    }
                }
                if (now - connection.lastReadTime() > heartBeatInterval) {
                    final ClientPingRequest request = new ClientPingRequest();
                    new ClientInvocation(client, request, connection).invoke();
                } else {
                    if (!connection.isHeartBeating()) {
                        connection.heartBeatingSucceed();
                        fireHeartBeatStarted(connection);
                    }
                }
            }
        }

        private void fireHeartBeatStarted(ClientConnection connection) {
            for (ConnectionHeartbeatListener heartbeatListener : heartbeatListeners) {
                heartbeatListener.heartBeatStarted(connection);
            }
        }

        private void fireHeartBeatStopped(ClientConnection connection) {
            for (ConnectionHeartbeatListener heartbeatListener : heartbeatListeners) {
                heartbeatListener.heartBeatStopped(connection);
            }
        }

    }

    @Override
    public void addConnectionListener(ConnectionListener connectionListener) {
        connectionListeners.add(connectionListener);
    }

    @Override
    public void addConnectionHeartbeatListener(ConnectionHeartbeatListener connectionHeartbeatListener) {
        heartbeatListeners.add(connectionHeartbeatListener);
    }
}

<code block>


package com.hazelcast.client.test;

import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.test.TestHazelcastFactory;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertEquals;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class HazelcastFactoryTest extends HazelcastTestSupport {

    @Test
    public void testTestHazelcastInstanceFactory_smartClients() {
        TestHazelcastFactory instanceFactory = new TestHazelcastFactory();
        final HazelcastInstance instance1 = instanceFactory.newHazelcastInstance();
        final HazelcastInstance instance2 = instanceFactory.newHazelcastInstance();
        final HazelcastInstance instance3 = instanceFactory.newHazelcastInstance();

        final HazelcastInstance client1 = instanceFactory.newHazelcastClient();
        final HazelcastInstance client2 = instanceFactory.newHazelcastClient();


        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                touchRandomNode(client1);
                touchRandomNode(client2);

                assertEquals(3, instance1.getCluster().getMembers().size());
                assertEquals(3, instance2.getCluster().getMembers().size());
                assertEquals(3, instance3.getCluster().getMembers().size());

                assertEquals(2, instance1.getClientService().getConnectedClients().size());
                assertEquals(2, instance2.getClientService().getConnectedClients().size());
                assertEquals(2, instance3.getClientService().getConnectedClients().size());
            }
        });

        instanceFactory.terminateAll();

    }

    private void touchRandomNode(HazelcastInstance hazelcastInstance) {
        hazelcastInstance.getMap(randomString()).get(randomString());
    }

    @Test
    public void testTestHazelcastInstanceFactory_dummyClients() {
        TestHazelcastFactory instanceFactory = new TestHazelcastFactory();
        final HazelcastInstance instance1 = instanceFactory.newHazelcastInstance();
        final HazelcastInstance instance2 = instanceFactory.newHazelcastInstance();
        final HazelcastInstance instance3 = instanceFactory.newHazelcastInstance();

        ClientConfig clientConfig = new ClientConfig();
        clientConfig.getNetworkConfig().setSmartRouting(false);
        final HazelcastInstance client1 = instanceFactory.newHazelcastClient(clientConfig);
        final HazelcastInstance client2 = instanceFactory.newHazelcastClient(clientConfig);


        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(3, instance1.getCluster().getMembers().size());
                assertEquals(3, instance2.getCluster().getMembers().size());
                assertEquals(3, instance3.getCluster().getMembers().size());
            }
        });

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                touchRandomNode(client1);
                touchRandomNode(client2);

                int actual = instance1.getClientService().getConnectedClients().size() +
                        instance2.getClientService().getConnectedClients().size() +
                        instance3.getClientService().getConnectedClients().size();
                assertEquals(2, actual);
            }
        });

        assertTrueEventually(new AssertTask() {
            @Override
            public void run() throws Exception {
                assertEquals(3, client1.getCluster().getMembers().size());
                assertEquals(3, client1.getCluster().getMembers().size());
            }
        });

        instanceFactory.terminateAll();

    }
}

<code block>


package com.hazelcast.client.test;

import com.hazelcast.client.HazelcastClient;
import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.config.XmlClientConfigBuilder;
import com.hazelcast.client.impl.ClientServiceFactory;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.impl.HazelcastClientProxy;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.nio.Address;
import com.hazelcast.test.TestEnvironment;
import com.hazelcast.test.TestHazelcastInstanceFactory;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.atomic.AtomicInteger;

public class TestHazelcastFactory extends TestHazelcastInstanceFactory {

    private final boolean mockNetwork = TestEnvironment.isMockNetwork();
    private final List<HazelcastClientInstanceImpl> clients = new ArrayList<HazelcastClientInstanceImpl>(10);
    private final TestClientRegistry clientRegistry;
    private final AtomicInteger clientPorts = new AtomicInteger(6000);

    public TestHazelcastFactory() {
        super(0);
        this.clientRegistry = new TestClientRegistry(registry);
    }

    public HazelcastInstance newHazelcastClient() {
        return this.newHazelcastClient(null);
    }

    public HazelcastInstance newHazelcastClient(ClientConfig config) {
        if (!mockNetwork) {
            return HazelcastClient.newHazelcastClient(config);
        }

        if (config == null) {
            config = new XmlClientConfigBuilder().build();
        }
        for (Address address : addresses) {
            config.getNetworkConfig().addAddress(address.getHost() + ":" + address.getPort());
        }

        final ClassLoader tccl = Thread.currentThread().getContextClassLoader();
        HazelcastClientProxy proxy;
        try {
            Thread.currentThread().setContextClassLoader(HazelcastClient.class.getClassLoader());
            ClientServiceFactory clientServiceFactory =
                    clientRegistry.createClientServiceFactory(createAddress("127.0.0.1", clientPorts.incrementAndGet()));
            final HazelcastClientInstanceImpl client = new HazelcastClientInstanceImpl(config, clientServiceFactory);
            client.start();
            clients.add(client);
            OutOfMemoryErrorDispatcher.registerClient(client);
            proxy = new HazelcastClientProxy(client);
        } finally {
            Thread.currentThread().setContextClassLoader(tccl);
        }
        return proxy;
    }

    @Override
    public void shutdownAll() {
        if (!mockNetwork) {
            HazelcastClient.shutdownAll();
        } else {
            for (HazelcastClientInstanceImpl client : clients) {
                client.shutdown();
            }
        }
        super.shutdownAll();
    }

    @Override
    public void terminateAll() {
        if (!mockNetwork) {
            
            HazelcastClient.shutdownAll();
        } else {
            for (HazelcastClientInstanceImpl client : clients) {
                client.getLifecycleService().terminate();
            }
        }
        super.terminateAll();
    }
}

<code block>


package com.hazelcast.client.test;

import com.hazelcast.client.HazelcastClient;
import com.hazelcast.client.config.ClientAwsConfig;
import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.connection.AddressTranslator;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.connection.nio.ClientConnection;
import com.hazelcast.client.connection.nio.ClientConnectionManagerImpl;
import com.hazelcast.client.impl.ClientServiceFactory;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.spi.impl.AwsAddressTranslator;
import com.hazelcast.client.spi.impl.DefaultAddressTranslator;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.TestUtil;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.test.TestNodeRegistry;
import com.hazelcast.util.ExceptionUtil;

import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.util.logging.Level;

public class TestClientRegistry {

    private static final ILogger LOGGER = Logger.getLogger(HazelcastClient.class);
    private final TestNodeRegistry nodeRegistry;

    public TestClientRegistry(TestNodeRegistry nodeRegistry) {
        this.nodeRegistry = nodeRegistry;
    }


    ClientServiceFactory createClientServiceFactory(Address clientAddress) {
        return new MockClientServiceFactory(clientAddress);
    }

    private class MockClientServiceFactory implements ClientServiceFactory {

        private final Address clientAddress;

        public MockClientServiceFactory(Address clientAddress) {
            this.clientAddress = clientAddress;
        }

        @Override
        public ClientConnectionManager createConnectionManager(ClientConfig config, HazelcastClientInstanceImpl client) {
            final ClientAwsConfig awsConfig = config.getNetworkConfig().getAwsConfig();
            AddressTranslator addressTranslator;
            if (awsConfig != null && awsConfig.isEnabled()) {
                try {
                    addressTranslator = new AwsAddressTranslator(awsConfig);
                } catch (NoClassDefFoundError e) {
                    LOGGER.log(Level.WARNING, "hazelcast-cloud.jar might be missing!");
                    throw e;
                }
            } else {
                addressTranslator = new DefaultAddressTranslator();
            }
            return new MockClientConnectionManager(client, addressTranslator, clientAddress);
        }
    }


    private class MockClientConnectionManager extends ClientConnectionManagerImpl {

        private final Address clientAddress;
        private final HazelcastClientInstanceImpl client;

        public MockClientConnectionManager(HazelcastClientInstanceImpl client, AddressTranslator addressTranslator,
                                           Address clientAddress) {
            super(client, addressTranslator);
            this.client = client;
            this.clientAddress = clientAddress;
        }

        @Override
        protected void initializeSelectors(HazelcastClientInstanceImpl client) {

        }

        @Override
        protected void startSelectors() {

        }

        @Override
        protected void shutdownSelectors() {

        }

        @Override
        protected ClientConnection createSocketConnection(Address address) throws IOException {
            if (!alive) {
                throw new HazelcastException("ConnectionManager is not active!!!");
            }
            try {
                HazelcastInstance instance = nodeRegistry.getInstance(address);
                if (instance == null) {
                    throw new IOException("Can not connected to " + address + ": instance does not exist");
                }
                Node node = TestUtil.getNode(instance);
                return new MockedClientConnection(client, connectionIdGen.incrementAndGet(),
                        node.nodeEngine, address, clientAddress);
            } catch (Exception e) {
                throw ExceptionUtil.rethrow(e, IOException.class);
            }
        }


    }


    private class MockedClientConnection extends ClientConnection {
        private volatile long lastReadTime;
        private volatile long lastWriteTime;
        private final NodeEngineImpl serverNodeEngine;
        private final Address remoteAddress;
        private final Address localAddress;
        private final Connection serverSideConnection;

        public MockedClientConnection(HazelcastClientInstanceImpl client, int connectionId, NodeEngineImpl serverNodeEngine,
                                      Address address, Address localAddress) throws IOException {
            super(client, connectionId);
            this.serverNodeEngine = serverNodeEngine;
            this.remoteAddress = address;
            this.localAddress = localAddress;
            this.serverSideConnection = new MockedNodeConnection(connectionId, remoteAddress,
                    localAddress, serverNodeEngine, this);
        }

        void handlePacket(Packet packet) {
            lastReadTime = System.currentTimeMillis();
            getConnectionManager().handlePacket(packet);
        }

        @Override
        public boolean write(SocketWritable socketWritable) {
            Packet newPacket = readFromPacket((Packet) socketWritable);
            MemberImpl member = serverNodeEngine.getClusterService().getMember(remoteAddress);
            lastWriteTime = System.currentTimeMillis();
            if (member != null) {
                member.didRead();
            }
            serverNodeEngine.getNode().clientEngine.handlePacket(newPacket);
            return true;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }


            newPacket.setConn(serverSideConnection);
            return newPacket;
        }

        @Override
        public void init() throws IOException {

        }

        @Override
        public long lastReadTime() {
            return lastReadTime;
        }

        @Override
        public long lastWriteTime() {
            return lastWriteTime;
        }

        @Override
        public InetAddress getInetAddress() {
            try {
                return remoteAddress.getInetAddress();
            } catch (UnknownHostException e) {
                e.printStackTrace();
                return null;
            }
        }

        @Override
        public InetSocketAddress getRemoteSocketAddress() {
            try {
                return remoteAddress.getInetSocketAddress();
            } catch (UnknownHostException e) {
                e.printStackTrace();
                return null;
            }
        }

        @Override
        public int getPort() {
            return remoteAddress.getPort();
        }

        @Override
        public InetSocketAddress getLocalSocketAddress() {
            try {
                return localAddress.getInetSocketAddress();
            } catch (UnknownHostException e) {
                e.printStackTrace();
            }
            return null;
        }

        @Override
        protected void innerClose() throws IOException {
            serverSideConnection.close();
        }
    }

    private class MockedNodeConnection extends TestNodeRegistry.MockConnection {

        private final MockedClientConnection responseConnection;
        private final int connectionId;

        public MockedNodeConnection(int connectionId, Address localEndpoint, Address remoteEndpoint, NodeEngineImpl nodeEngine
                , MockedClientConnection responseConnection) {
            super(localEndpoint, remoteEndpoint, nodeEngine);
            this.responseConnection = responseConnection;
            this.connectionId = connectionId;
        }

        @Override
        public boolean write(SocketWritable socketWritable) {
            final Packet packet = (Packet) socketWritable;
            if (nodeEngine.getNode().isActive()) {
                Packet newPacket = readFromPacket(packet);
                MemberImpl member = nodeEngine.getClusterService().getMember(localEndpoint);
                if (member != null) {
                    member.didRead();
                }
                responseConnection.handlePacket(newPacket);
                return true;
            }
            return false;
        }

        @Override
        public boolean isClient() {
            return true;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }

            newPacket.setConn(responseConnection);
            return newPacket;
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (o == null || getClass() != o.getClass()) return false;

            MockedNodeConnection that = (MockedNodeConnection) o;

            if (connectionId != that.connectionId) return false;
            Address remoteEndpoint = getEndPoint();
            return !(remoteEndpoint != null ? !remoteEndpoint.equals(that.getEndPoint()) : that.getEndPoint() != null);

        }

        @Override
        public void close() {
            super.close();
            responseConnection.close();
        }

        @Override
        public int hashCode() {
            int result = connectionId;
            Address remoteEndpoint = getEndPoint();
            result = 31 * result + (remoteEndpoint != null ? remoteEndpoint.hashCode() : 0);
            return result;
        }

        @Override
        public ConnectionType getType() {
            return ConnectionType.JAVA_CLIENT;
        }

        @Override
        public String toString() {
            return "MockedNodeConnection{" +
                    " remoteEndpoint = " + getEndPoint() +
                    ", localEndpoint = " + localEndpoint +
                    ", connectionId = " + connectionId +
                    '}';
        }
    }
}

<code block>


package com.hazelcast.client.impl;

import com.hazelcast.client.AuthenticationException;
import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.ClientEndpointManager;
import com.hazelcast.client.ClientEngine;
import com.hazelcast.client.impl.client.AuthenticationRequest;
import com.hazelcast.client.impl.client.ClientRequest;
import com.hazelcast.client.impl.client.ClientResponse;
import com.hazelcast.client.impl.operations.ClientDisconnectionOperation;
import com.hazelcast.client.impl.operations.GetConnectedClientsOperation;
import com.hazelcast.client.impl.operations.PostJoinClientOperation;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.client.impl.protocol.MessageTaskFactory;
import com.hazelcast.client.impl.protocol.task.MessageTask;
import com.hazelcast.cluster.ClusterService;
import com.hazelcast.config.Config;
import com.hazelcast.core.Client;
import com.hazelcast.core.ClientListener;
import com.hazelcast.core.ClientType;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.PortableReader;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.TcpIpConnection;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.security.Credentials;
import com.hazelcast.security.SecurityContext;
import com.hazelcast.spi.CoreService;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.MemberAttributeServiceEvent;
import com.hazelcast.spi.MembershipAwareService;
import com.hazelcast.spi.MembershipServiceEvent;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PostJoinAwareService;
import com.hazelcast.spi.ProxyService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.PartitionSpecificRunnable;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;
import com.hazelcast.transaction.TransactionManagerService;
import com.hazelcast.util.executor.ExecutorType;

import javax.security.auth.login.LoginException;
import java.security.Permission;
import java.util.Collection;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Executor;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.Future;
import java.util.logging.Level;

import static com.hazelcast.spi.impl.OperationResponseHandlerFactory.createEmptyResponseHandler;


public class ClientEngineImpl implements ClientEngine, CoreService, PostJoinAwareService,
        ManagedService, MembershipAwareService, EventPublishingService<ClientEndpointImpl, ClientListener> {

    
    public static final String SERVICE_NAME = "hz:core:clientEngine";
    private static final int ENDPOINT_REMOVE_DELAY_SECONDS = 10;
    private static final int EXECUTOR_QUEUE_CAPACITY_PER_CORE = 100000;
    private static final int THREADS_PER_CORE = 20;

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final Executor executor;

    private final SerializationService serializationService;
    
    private final ConcurrentMap<String, String> ownershipMappings = new ConcurrentHashMap<String, String>();

    private final ClientEndpointManagerImpl endpointManager;
    private final ILogger logger;
    private final ConnectionListener connectionListener = new ConnectionListenerImpl();

    private final MessageTaskFactory messageTaskFactory;

    public ClientEngineImpl(Node node) {
        this.logger = node.getLogger(ClientEngine.class);
        this.node = node;
        this.serializationService = node.getSerializationService();
        this.nodeEngine = node.nodeEngine;
        this.endpointManager = new ClientEndpointManagerImpl(this, nodeEngine);
        this.executor = newExecutor();
        this.messageTaskFactory = node.getNodeExtension().createMessageTaskFactory(node);

        ClientHeartbeatMonitor heartBeatMonitor = new ClientHeartbeatMonitor(
                endpointManager, this, nodeEngine.getExecutionService(), node.groupProperties);
        heartBeatMonitor.start();
    }

    private Executor newExecutor() {
        final ExecutionService executionService = nodeEngine.getExecutionService();
        int coreSize = Runtime.getRuntime().availableProcessors();

        int threadCount = node.getGroupProperties().CLIENT_ENGINE_THREAD_COUNT.getInteger();
        if (threadCount <= 0) {
            threadCount = coreSize * THREADS_PER_CORE;
        }

        return executionService.register(ExecutionService.CLIENT_EXECUTOR,
                threadCount, coreSize * EXECUTOR_QUEUE_CAPACITY_PER_CORE,
                ExecutorType.CONCRETE);
    }

    
    public ConnectionListener getConnectionListener() {
        return connectionListener;
    }

    @Override
    public int getClientEndpointCount() {
        return endpointManager.size();
    }

    public void handlePacket(Packet packet) {
        int partitionId = packet.getPartitionId();
        if (partitionId < 0) {
            executor.execute(new ClientPacketProcessor(packet));
        } else {
            InternalOperationService operationService = nodeEngine.getOperationService();
            operationService.execute(new ClientPacketProcessor(packet));
        }
    }

    public void handleClientMessage(ClientMessage clientMessage, Connection connection) {

        
        int partitionId = clientMessage.getPartitionId();
        final MessageTask messageTask = messageTaskFactory.create(clientMessage, connection);
        if (partitionId < 0) {
            executor.execute(messageTask);
        } else {
            InternalOperationService operationService = nodeEngine.getOperationService();
            operationService.execute(messageTask);
        }
    }

    @Override
    public InternalPartitionService getPartitionService() {
        return nodeEngine.getPartitionService();
    }

    @Override
    public ClusterService getClusterService() {
        return nodeEngine.getClusterService();
    }

    @Override
    public EventService getEventService() {
        return nodeEngine.getEventService();
    }

    @Override
    public ProxyService getProxyService() {
        return nodeEngine.getProxyService();
    }

    public void sendResponse(ClientEndpoint endpoint, Object key, Object response, int callId, boolean isError, boolean isEvent) {
        Data data = serializationService.toData(response);
        ClientResponse clientResponse = new ClientResponse(data, callId, isError);
        Data responseData = serializationService.toData(clientResponse);
        int partitionId = key == null ? -1 : getPartitionService().getPartitionId(key);
        final Packet packet = new Packet(responseData, partitionId);
        if (isEvent) {
            packet.setHeader(Packet.HEADER_EVENT);
        }
        Connection conn = endpoint.getConnection();
        conn.write(packet);
    }

    @Override
    public Address getMasterAddress() {
        return node.getMasterAddress();
    }

    @Override
    public Address getThisAddress() {
        return node.getThisAddress();
    }

    @Override
    public MemberImpl getLocalMember() {
        return node.getLocalMember();
    }

    @Override
    public Config getConfig() {
        return node.getConfig();
    }

    @Override
    public ILogger getLogger(Class clazz) {
        return node.getLogger(clazz);
    }

    public ClientEndpointManager getEndpointManager() {
        return endpointManager;
    }

    @Override
    public SecurityContext getSecurityContext() {
        return node.securityContext;
    }

    public void bind(final ClientEndpoint endpoint) {
        final Connection conn = endpoint.getConnection();
        if (conn instanceof TcpIpConnection) {
            Address address = new Address(conn.getRemoteSocketAddress());
            ((TcpIpConnection) conn).setEndPoint(address);
        }
        sendClientEvent(endpoint);
    }

    void sendClientEvent(ClientEndpoint endpoint) {
        final EventService eventService = nodeEngine.getEventService();
        final Collection<EventRegistration> regs = eventService.getRegistrations(SERVICE_NAME, SERVICE_NAME);
        String uuid = endpoint.getUuid();
        eventService.publishEvent(SERVICE_NAME, regs, endpoint, uuid.hashCode());
    }

    @Override
    public void dispatchEvent(ClientEndpointImpl event, ClientListener listener) {
        if (event.isAuthenticated()) {
            listener.clientConnected(event);
        } else {
            listener.clientDisconnected(event);
        }
    }

    @Override
    public void memberAdded(MembershipServiceEvent event) {
    }

    @Override
    public void memberRemoved(MembershipServiceEvent event) {
        if (event.getMember().localMember()) {
            return;
        }

        final String deadMemberUuid = event.getMember().getUuid();
        try {
            nodeEngine.getExecutionService().schedule(new DestroyEndpointTask(deadMemberUuid),
                    ENDPOINT_REMOVE_DELAY_SECONDS, TimeUnit.SECONDS);

        } catch (RejectedExecutionException e) {
            if (logger.isFinestEnabled()) {
                logger.finest(e);
            }
        }
    }

    @Override
    public void memberAttributeChanged(MemberAttributeServiceEvent event) {
    }

    public Collection<Client> getClients() {
        final HashSet<Client> clients = new HashSet<Client>();
        for (ClientEndpoint endpoint : endpointManager.getEndpoints()) {
            clients.add((Client) endpoint);
        }
        return clients;
    }

    @Override
    public void init(NodeEngine nodeEngine, Properties properties) {
        node.getConnectionManager().addConnectionListener(connectionListener);
    }

    @Override
    public void reset() {
    }

    @Override
    public void shutdown(boolean terminate) {
        for (ClientEndpoint ce : endpointManager.getEndpoints()) {
            ClientEndpointImpl endpoint = (ClientEndpointImpl) ce;
            try {
                endpoint.destroy();
            } catch (LoginException e) {
                logger.finest(e.getMessage());
            }
            try {
                final Connection conn = endpoint.getConnection();
                if (conn.isAlive()) {
                    conn.close();
                }
            } catch (Exception e) {
                logger.finest(e);
            }
        }
        endpointManager.clear();
        ownershipMappings.clear();
    }

    public void addOwnershipMapping(String clientUuid, String ownerUuid) {
        ownershipMappings.put(clientUuid, ownerUuid);
    }

    public void removeOwnershipMapping(String clientUuid) {
        ownershipMappings.remove(clientUuid);
    }

    public TransactionManagerService getTransactionManagerService() {
        return node.nodeEngine.getTransactionManagerService();
    }

    private final class ClientPacketProcessor implements PartitionSpecificRunnable {
        final Packet packet;

        private ClientPacketProcessor(Packet packet) {
            this.packet = packet;
        }

        @Override
        public int getPartitionId() {
            return packet.getPartitionId();
        }

        @Override
        public void run() {
            Connection conn = packet.getConn();
            ClientEndpointImpl endpoint = (ClientEndpointImpl) endpointManager.getEndpoint(conn);
            ClientRequest request = null;
            try {
                request = loadRequest();
                if (request == null) {
                    handlePacketWithNullRequest();
                } else if (request instanceof AuthenticationRequest) {
                    if (conn.isAlive()) {
                        endpoint = new ClientEndpointImpl(ClientEngineImpl.this, conn);
                        processRequest(endpoint, request);
                    } else {
                        handleEndpointNotCreatedConnectionNotAlive();
                    }
                } else if (endpoint == null) {
                    handleMissingEndpoint(conn);
                } else if (endpoint.isAuthenticated()) {
                    processRequest(endpoint, request);
                } else {
                    handleAuthenticationFailure(endpoint, request);
                }
            } catch (Throwable e) {
                logProcessingFailure(request, e);
                handleProcessingFailure(endpoint, request, packet.getData(), e);
            }
        }

        private ClientRequest loadRequest() {
            Data data = packet.getData();
            return serializationService.toObject(data);
        }

        private void handleEndpointNotCreatedConnectionNotAlive() {
            logger.warning("Dropped: " + packet + " -> endpoint not created for AuthenticationRequest, "
                    + "connection not alive");
        }

        private void handlePacketWithNullRequest() {
            logger.warning("Dropped: " + packet + " -> null request");
        }

        private void handleMissingEndpoint(Connection conn) {
            if (conn.isAlive()) {
                logger.severe("Dropping: " + packet + " -> no endpoint found for live connection.");
            } else {
                if (logger.isFinestEnabled()) {
                    logger.finest("Dropping: " + packet + " -> no endpoint found for dead connection.");
                }
            }
        }

        private void logProcessingFailure(ClientRequest request, Throwable e) {
            Level level = nodeEngine.isActive() ? Level.SEVERE : Level.FINEST;
            if (logger.isLoggable(level)) {
                if (request == null) {
                    logger.log(level, e.getMessage(), e);
                } else {
                    logger.log(level, "While executing request: " + request + " -> " + e.getMessage(), e);
                }
            }
        }

        private void handleProcessingFailure(ClientEndpointImpl endpoint, ClientRequest request, Data data, Throwable e) {
            if (request != null && endpoint != null) {
                endpoint.sendResponse(e, request.getCallId());
            } else if (data != null && endpoint != null) {
                int callId = extractCallId(data);
                if (callId != -1) {
                    endpoint.sendResponse(e, callId);
                }
                
            }
        }

        private int extractCallId(Data data) {
            try {
                PortableReader portableReader = serializationService.createPortableReader(data);
                return portableReader.readInt("cId");

            } catch (Throwable e) {
                Level level = nodeEngine.isActive() ? Level.SEVERE : Level.FINEST;
                if (logger.isLoggable(level)) {
                    logger.log(level, e.getMessage(), e);
                }
            }
            return -1;
        }

        private void processRequest(ClientEndpointImpl endpoint, ClientRequest request) throws Exception {
            if (!node.joined()) {
                throw new HazelcastInstanceNotActiveException("Hazelcast instance is not ready yet!");
            }

            request.setEndpoint(endpoint);
            initService(request);
            request.setClientEngine(ClientEngineImpl.this);
            final Credentials credentials = endpoint.getCredentials();
            request.setSerializationService(serializationService);
            request.setOperationService(nodeEngine.getOperationService());
            interceptBefore(credentials, request);
            checkPermissions(endpoint, request);
            request.process();
            interceptAfter(credentials, request);
        }

        private void interceptBefore(Credentials credentials, ClientRequest request) {
            final SecurityContext securityContext = getSecurityContext();
            final String methodName = request.getMethodName();
            if (securityContext != null && methodName != null) {
                final String objectType = request.getDistributedObjectType();
                final String objectName = request.getDistributedObjectName();
                securityContext.interceptBefore(credentials, objectType, objectName, methodName, request.getParameters());
            }
        }

        private void interceptAfter(Credentials credentials, ClientRequest request) {
            final SecurityContext securityContext = getSecurityContext();
            final String methodName = request.getMethodName();
            if (securityContext != null && methodName != null) {
                final String objectType = request.getDistributedObjectType();
                final String objectName = request.getDistributedObjectName();
                securityContext.interceptAfter(credentials, objectType, objectName, methodName);
            }
        }

        private void checkPermissions(ClientEndpointImpl endpoint, ClientRequest request) {
            SecurityContext securityContext = getSecurityContext();
            if (securityContext != null) {
                Permission permission = request.getRequiredPermission();
                if (permission != null) {
                    securityContext.checkPermission(endpoint.getSubject(), permission);
                }
            }
        }

        private void initService(ClientRequest request) {
            String serviceName = request.getServiceName();
            if (serviceName == null) {
                return;
            }

            Object service = nodeEngine.getService(serviceName);
            if (service == null) {
                if (nodeEngine.isActive()) {
                    throw new IllegalArgumentException("No service registered with name: " + serviceName);
                }
                throw new HazelcastInstanceNotActiveException();
            }
            request.setService(service);
        }

        private void handleAuthenticationFailure(ClientEndpointImpl endpoint, ClientRequest request) {
            Exception exception;
            if (nodeEngine.isActive()) {
                String message = "Client " + endpoint + " must authenticate before any operation.";
                logger.severe(message);
                exception = new AuthenticationException(message);
            } else {
                exception = new HazelcastInstanceNotActiveException();
            }
            endpoint.sendResponse(exception, request.getCallId());
            endpointManager.removeEndpoint(endpoint);
        }
    }

    private final class ConnectionListenerImpl implements ConnectionListener {

        @Override
        public void connectionAdded(Connection conn) {
            
            
            
        }

        @Override
        public void connectionRemoved(Connection connection) {
            if (connection.isClient() && connection instanceof TcpIpConnection && nodeEngine.isActive()) {
                ClientEndpointImpl endpoint = (ClientEndpointImpl) endpointManager.getEndpoint(connection);
                if (endpoint == null) {
                    return;
                }

                if (!endpoint.isFirstConnection()) {
                    return;
                }

                String localMemberUuid = node.getLocalMember().getUuid();
                String ownerUuid = endpoint.getPrincipal().getOwnerUuid();
                if (localMemberUuid.equals(ownerUuid)) {
                    callDisconnectionOperation(endpoint);
                }
            }
        }

        private void callDisconnectionOperation(ClientEndpointImpl endpoint) {
            Collection<MemberImpl> memberList = nodeEngine.getClusterService().getMemberList();
            OperationService operationService = nodeEngine.getOperationService();
            ClientDisconnectionOperation op = createClientDisconnectionOperation(endpoint.getUuid());
            operationService.runOperationOnCallingThread(op);

            for (MemberImpl member : memberList) {
                if (!member.localMember()) {
                    op = createClientDisconnectionOperation(endpoint.getUuid());
                    operationService.send(op, member.getAddress());
                }
            }
        }
    }

    private ClientDisconnectionOperation createClientDisconnectionOperation(String clientUuid) {
        ClientDisconnectionOperation op = new ClientDisconnectionOperation(clientUuid);
        op.setNodeEngine(nodeEngine)
                .setServiceName(SERVICE_NAME)
                .setService(this)
                .setOperationResponseHandler(createEmptyResponseHandler());
        return op;
    }

    private class DestroyEndpointTask implements Runnable {
        private final String deadMemberUuid;

        public DestroyEndpointTask(String deadMemberUuid) {
            this.deadMemberUuid = deadMemberUuid;
        }

        @Override
        public void run() {
            endpointManager.removeEndpoints(deadMemberUuid);
            removeMappings();
        }

        void removeMappings() {
            Iterator<Map.Entry<String, String>> iterator = ownershipMappings.entrySet().iterator();
            while (iterator.hasNext()) {
                Map.Entry<String, String> entry = iterator.next();
                String clientUuid = entry.getKey();
                String memberUuid = entry.getValue();
                if (deadMemberUuid.equals(memberUuid)) {
                    iterator.remove();
                    ClientDisconnectionOperation op = createClientDisconnectionOperation(clientUuid);
                    nodeEngine.getOperationService().runOperationOnCallingThread(op);
                }
            }
        }
    }

    @Override
    public Operation getPostJoinOperation() {
        return ownershipMappings.isEmpty() ? null : new PostJoinClientOperation(ownershipMappings);
    }

    @Override
    public Map<ClientType, Integer> getConnectedClientStats() {

        int numberOfCppClients    = 0;
        int numberOfDotNetClients = 0;
        int numberOfJavaClients   = 0;
        int numberOfOtherClients  = 0;

        Operation clientInfoOperation = new GetConnectedClientsOperation();
        OperationService operationService = node.nodeEngine.getOperationService();
        Map<ClientType, Integer> resultMap = new HashMap<ClientType, Integer>();
        Map<String, ClientType> clientsMap = new HashMap<String, ClientType>();

        for (MemberImpl member : node.getClusterService().getMemberList()) {
            Address target = member.getAddress();
            Future<Map<String, ClientType>> future
                    = operationService.invokeOnTarget(SERVICE_NAME, clientInfoOperation, target);
            try {
                Map<String, ClientType> endpoints = future.get();
                if (endpoints == null) {
                    continue;
                }
                
                for (Map.Entry<String, ClientType> entry : endpoints.entrySet()) {
                    clientsMap.put(entry.getKey(), entry.getValue());
                }
            } catch (Exception e) {
                logger.warning("Cannot get client information from: " + target.toString(), e);
            }
        }

        
        for (ClientType clientType : clientsMap.values()) {
            switch (clientType) {
                case JAVA:
                    numberOfJavaClients++;
                    break;
                case CSHARP:
                    numberOfDotNetClients++;
                    break;
                case CPP:
                    numberOfCppClients++;
                    break;
                default:
                    numberOfOtherClients++;
            }
        }

        resultMap.put(ClientType.CPP, numberOfCppClients);
        resultMap.put(ClientType.CSHARP, numberOfDotNetClients);
        resultMap.put(ClientType.JAVA, numberOfJavaClients);
        resultMap.put(ClientType.OTHER, numberOfOtherClients);

        return resultMap;
    }
}

<code block>


package com.hazelcast.mapreduce;

import com.hazelcast.core.*;
import com.hazelcast.mapreduce.helpers.Employee;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.DataSerializable;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.test.AssertTask;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.TestHazelcastInstanceFactory;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.io.IOException;
import java.math.BigInteger;
import java.util.*;
import java.util.concurrent.CancellationException;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Semaphore;
import java.util.logging.Logger;

import static org.junit.Assert.*;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
@SuppressWarnings("unused")
public class MapReduceTest
        extends HazelcastTestSupport {
    final static Logger logger = Logger.getLogger("test");

    private static final String MAP_NAME = "default";

    private void tripshutdown(HazelcastInstance... instances) {
        for (HazelcastInstance instance : instances) {
            try {
                instance.shutdown();
            } catch (Throwable ex) {
                logger.log(java.util.logging.Level.INFO, ex.getMessage(), ex);
            }
        }
    }

    @Test(timeout = 60000)
    public void test_early_finalization_combiner_github_5283() throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            KeyValueSource<Integer, Integer> kvs = KeyValueSource.fromMap(m1);
            KeyValueSource<Integer, Integer> wrapper = new MapKeyValueSourceAdapter<Integer, Integer>(kvs);
            Job<Integer, Integer> job = tracker.newJob(wrapper);

            ICompletableFuture<Map<String, List<Integer>>> future =
                    job.mapper(new TestMapper())
                            .combiner(new FinalizingCombinerFactory())
                            .reducer(new ListBasedReducerFactory()).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(100, result.size());
            for (List<Integer> value : result.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testPartitionPostpone()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            KeyValueSource<Integer, Integer> kvs = KeyValueSource.fromMap(m1);
            KeyValueSource<Integer, Integer> wrapper = new MapKeyValueSourceAdapter<Integer, Integer>(kvs);
            Job<Integer, Integer> job = tracker.newJob(wrapper);
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new TestMapper()).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(100, result.size());
            for (List<Integer> value : result.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void test_collide_user_provided_combiner_list_result_github_3614() throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            KeyValueSource<Integer, Integer> kvs = KeyValueSource.fromMap(m1);
            KeyValueSource<Integer, Integer> wrapper = new MapKeyValueSourceAdapter<Integer, Integer>(kvs);
            Job<Integer, Integer> job = tracker.newJob(wrapper);
            ICompletableFuture<Map<String, List<Integer>>> future =
                    job.mapper(new TestMapper())
                            .combiner(new ListResultingCombinerFactory())
                            .reducer(new ListBasedReducerFactory()).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(100, result.size());
            for (List<Integer> value : result.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 30000, expected = ExecutionException.class)
    public void testExceptionDistributionWithCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new ExceptionThrowingMapper())
                    .submit(new Collator<Map.Entry<String, List<Integer>>, Map<String, List<Integer>>>() {
                        @Override
                        public Map<String, List<Integer>> collate(
                                Iterable<Map.Entry<String, List<Integer>>> values) {
                            return null;
                        }
                    });

            try {
                Map<String, List<Integer>> result = future.get();
                fail();

            } catch (Exception e) {
                e.printStackTrace();
                assertTrue(e.getCause() instanceof NullPointerException);
                throw e;
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 30000, expected = ExecutionException.class)
    public void testExceptionDistribution()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new ExceptionThrowingMapper()).submit();

            try {
                Map<String, List<Integer>> result = future.get();
                fail();

            } catch (Exception e) {
                e.printStackTrace();
                assertTrue(e.getCause() instanceof NullPointerException);
                throw e;
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 30000, expected = CancellationException.class)
    public void testInProcessCancellation()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new TimeConsumingMapper()).submit();

            future.cancel(true);

            try {
                Map<String, List<Integer>> result = future.get();
                fail();

            } catch (Exception e) {
                e.printStackTrace();
                throw e;
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapper()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new TestMapper()).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(100, result.size());
            for (List<Integer> value : result.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testKeyedMapperCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 10000; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.onKeys(50).mapper(new TestMapper()).submit(new GroupingTestCollator());

            int result = future.get();

            assertEquals(50, result);
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testKeyPredicateMapperCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 10000; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.keyPredicate(new TestKeyPredicate()).mapper(new TestMapper())
                    .submit(new GroupingTestCollator());

            int result = future.get();

            assertEquals(50, result);
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperComplexMapping()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new GroupingTestMapper(2)).submit();

            Map<String, List<Integer>> result = future.get();

            assertEquals(1, result.size());
            assertEquals(25, result.values().iterator().next().size());
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperReducer()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, Integer>> future = job.mapper(new GroupingTestMapper()).reducer(new TestReducerFactory())
                    .submit();

            Map<String, Integer> result = future.get();

            
            int[] expectedResults = new int[4];
            for (int i = 0; i < 100; i++) {
                int index = i % 4;
                expectedResults[index] += i;
            }

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResults[i], (int) result.get(String.valueOf(i)));
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperReducerChunked()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        final HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        final HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            final IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 10000; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            JobCompletableFuture<Map<String, Integer>> future = job.chunkSize(10).mapper(new GroupingTestMapper())
                    .reducer(new TestReducerFactory()).submit();

            final TrackableJob trackableJob = tracker.getTrackableJob(future.getJobId());
            final JobProcessInformation processInformation = trackableJob.getJobProcessInformation();
            Map<String, Integer> result = future.get();

            
            int[] expectedResults = new int[4];
            for (int i = 0; i < 10000; i++) {
                int index = i % 4;
                expectedResults[index] += i;
            }

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResults[i], (int) result.get(String.valueOf(i)));
            }

            assertTrueEventually(new AssertTask() {
                @Override
                public void run() {
                    if (processInformation.getProcessedRecords() < 10000) {
                        System.err.println(processInformation.getProcessedRecords());
                    }
                    assertEquals(10000, processInformation.getProcessedRecords());
                }
            });
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.mapper(new GroupingTestMapper()).submit(new GroupingTestCollator());

            int result = future.get();

            
            int expectedResult = 0;
            for (int i = 0; i < 100; i++) {
                expectedResult += i;
            }

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResult, result);
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testMapperReducerCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.mapper(new GroupingTestMapper()).reducer(new TestReducerFactory())
                    .submit(new TestCollator());

            int result = future.get();

            
            int expectedResult = 0;
            for (int i = 0; i < 100; i++) {
                expectedResult += i;
            }

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResult, result);
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testAsyncMapper()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final Map<String, List<Integer>> listenerResults = new HashMap<String, List<Integer>>();
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.mapper(new TestMapper()).submit();

            future.andThen(new ExecutionCallback<Map<String, List<Integer>>>() {
                @Override
                public void onResponse(Map<String, List<Integer>> response) {
                    try {
                        listenerResults.putAll(response);
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });


            semaphore.acquire();

            assertEquals(100, listenerResults.size());
            for (List<Integer> value : listenerResults.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testKeyedAsyncMapper()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);


        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final Map<String, List<Integer>> listenerResults = new HashMap<String, List<Integer>>();
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, List<Integer>>> future = job.onKeys(50).mapper(new TestMapper()).submit();

            future.andThen(new ExecutionCallback<Map<String, List<Integer>>>() {
                @Override
                public void onResponse(Map<String, List<Integer>> response) {
                    try {
                        listenerResults.putAll(response);
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });

            semaphore.acquire();

            assertEquals(1, listenerResults.size());
            for (List<Integer> value : listenerResults.values()) {
                assertEquals(1, value.size());
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testAsyncMapperReducer()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final Map<String, Integer> listenerResults = new HashMap<String, Integer>();
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Map<String, Integer>> future = job.mapper(new GroupingTestMapper()).reducer(new TestReducerFactory())
                    .submit();

            future.andThen(new ExecutionCallback<Map<String, Integer>>() {
                @Override
                public void onResponse(Map<String, Integer> response) {
                    try {
                        listenerResults.putAll(response);
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });

            
            int[] expectedResults = new int[4];
            for (int i = 0; i < 100; i++) {
                int index = i % 4;
                expectedResults[index] += i;
            }

            semaphore.acquire();

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResults[i], (int) listenerResults.get(String.valueOf(i)));
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testAsyncMapperCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final int[] result = new int[1];
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.mapper(new GroupingTestMapper()).submit(new GroupingTestCollator());

            future.andThen(new ExecutionCallback<Integer>() {
                @Override
                public void onResponse(Integer response) {
                    try {
                        result[0] = response.intValue();
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });

            
            int expectedResult = 0;
            for (int i = 0; i < 100; i++) {
                expectedResult += i;
            }

            semaphore.acquire();

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResult, result[0]);
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testAsyncMapperReducerCollator()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            final int[] result = new int[1];
            final Semaphore semaphore = new Semaphore(1);
            semaphore.acquire();

            JobTracker tracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = tracker.newJob(KeyValueSource.fromMap(m1));
            ICompletableFuture<Integer> future = job.mapper(new GroupingTestMapper()).reducer(new TestReducerFactory())
                    .submit(new TestCollator());

            future.andThen(new ExecutionCallback<Integer>() {
                @Override
                public void onResponse(Integer response) {
                    try {
                        result[0] = response.intValue();
                    } finally {
                        semaphore.release();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    semaphore.release();
                }
            });

            
            int expectedResult = 0;
            for (int i = 0; i < 100; i++) {
                expectedResult += i;
            }

            semaphore.acquire();

            for (int i = 0; i < 4; i++) {
                assertEquals(expectedResult, result[0]);
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testNullFromObjectCombiner()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        try {
            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker jobTracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = jobTracker.newJob(KeyValueSource.fromMap(m1));
            JobCompletableFuture<Map<String, BigInteger>> future = job.chunkSize(10).mapper(new GroupingTestMapper())
                    .combiner(new ObjectCombinerFactory())
                    .reducer(new ObjectReducerFactory()).submit();

            int[] expectedResults = new int[4];
            for (int i = 0; i < 100; i++) {
                int index = i % 4;
                expectedResults[index] += i;
            }

            Map<String, BigInteger> map = future.get();
            for (int i = 0; i < 4; i++) {
                assertEquals(BigInteger.valueOf(expectedResults[i]), map.get(String.valueOf(i)));
            }
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testNullFromObjectReducer()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        try {

            assertClusterSizeEventually(3, h1);
            assertClusterSizeEventually(3, h2);
            assertClusterSizeEventually(3, h3);

            IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
            for (int i = 0; i < 100; i++) {
                m1.put(i, i);
            }

            JobTracker jobTracker = h1.getJobTracker("default");
            Job<Integer, Integer> job = jobTracker.newJob(KeyValueSource.fromMap(m1));
            JobCompletableFuture<Map<String, BigInteger>> future = job.chunkSize(10).mapper(new GroupingTestMapper())
                    .combiner(new ObjectCombinerFactory())
                    .reducer(new NullReducerFactory()).submit();

            Map<String, BigInteger> map = future.get();
            assertEquals(0, map.size());
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }

    @Test(timeout = 60000)
    public void testDataSerializableIntermediateObject()
            throws Exception {
        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);

        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        assertClusterSizeEventually(3, h1);
        assertClusterSizeEventually(3, h2);
        assertClusterSizeEventually(3, h3);

        IMap<Integer, Integer> m1 = h1.getMap(MAP_NAME);
        for (int i = 0; i < 100; i++) {
            m1.put(i, i);
        }

        JobTracker jobTracker = h1.getJobTracker("default");
        Job<Integer, Integer> job = jobTracker.newJob(KeyValueSource.fromMap(m1));
        ICompletableFuture<Integer> future = job.mapper(new TestMapper())
                .combiner(new DataSerializableIntermediateCombinerFactory())
                .reducer(new DataSerializableIntermediateReducerFactory())
                .submit(new DataSerializableIntermediateCollator());

        
        int expectedResult = 0;
        for (int i = 0; i < 100; i++) {
            expectedResult += i;
        }
        expectedResult = (int) ((double) expectedResult / 100);

        assertEquals(expectedResult, (int) future.get());
    }

    @Test(timeout = 60000)
    public void employeeMapReduceTest() throws Exception {

        TestHazelcastInstanceFactory nodeFactory = createHazelcastInstanceFactory(3);
        HazelcastInstance h1 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h2 = nodeFactory.newHazelcastInstance();
        HazelcastInstance h3 = nodeFactory.newHazelcastInstance();

        try {
            final IMap map = h1.getMap(randomString());

            final int keyCount = 100;
            for (int id = 0; id < keyCount; id++) {
                map.put(id, new Employee(id));
            }

            JobTracker tracker = h1.getJobTracker(randomString());
            Job<Integer, Employee> job = tracker.newJob(KeyValueSource.fromMap(map));

            ICompletableFuture<Map<Integer, Set<Employee>>> future = job
                    .mapper(new ModIdMapper(2))
                    .combiner(new RangeIdCombinerFactory(10, 30))
                    .reducer(new IdReducerFactory(10, 20, 30))
                    .submit();

            Map<Integer, Set<Employee>> result = future.get();

            assertEquals("expected 8 Employees with id's ending 2, 4, 6, 8", 8, result.size());
        } finally {
            tripshutdown(h1, h2, h3);
        }
    }


    public static class ModIdMapper implements Mapper<Integer, Employee, Integer, Employee> {

        private int mod = 0;

        public ModIdMapper(int mod) {
            this.mod = mod;
        }

        public void map(Integer key, Employee e, Context<Integer, Employee> context) {
            if (e.getId() % mod == 0) {
                context.emit(key, e);
            }
        }
    }

    public static class RangeIdCombinerFactory implements CombinerFactory<Integer, Employee, Set<Employee>> {

        private int min = 0, max = 0;

        public RangeIdCombinerFactory(int min, int max) {
            this.min = min;
            this.max = max;
        }

        public Combiner<Employee, Set<Employee>> newCombiner(Integer key) {
            return new EmployeeCombiner();
        }

        private class EmployeeCombiner extends Combiner<Employee, Set<Employee>> {
            private Set<Employee> passed = new HashSet<Employee>();

            public void combine(Employee e) {
                if (e.getId() >= min && e.getId() <= max) {
                    passed.add(e);
                }
            }

            public Set<Employee> finalizeChunk() {
                if (passed.isEmpty()) {
                    return null;
                }
                return passed;
            }

            public void reset() {
                passed = new HashSet<Employee>();
            }
        }
    }


    public static class IdReducerFactory implements ReducerFactory<Integer, Set<Employee>, Set<Employee>> {

        private int[] removeIds = null;

        public IdReducerFactory(int... removeIds) {
            this.removeIds = removeIds;
        }

        public Reducer<Set<Employee>, Set<Employee>> newReducer(Integer key) {
            return new EmployeeReducer();
        }

        private class EmployeeReducer extends Reducer<Set<Employee>, Set<Employee>> {

            private volatile Set<Employee> passed = new HashSet<Employee>();

            public void reduce(Set<Employee> set) {
                for (Employee e : set) {
                    boolean add = true;
                    for (int id : removeIds) {
                        if (e.getId() == id) {
                            add = false;
                            break;
                        }
                    }
                    if (add) {
                        passed.add(e);
                    }
                }
            }

            public Set<Employee> finalizeReduce() {
                if (passed.isEmpty()) {
                    return null;
                }
                return passed;
            }
        }
    }


    public static class EmployeeCollator implements Collator<Map.Entry<Integer, Set<Employee>>, Map<Integer, Set<Employee>>> {

        public Map<Integer, Set<Employee>> collate(Iterable<Map.Entry<Integer, Set<Employee>>> values) {
            Map<Integer, Set<Employee>> result = new HashMap();
            for (Map.Entry<Integer, Set<Employee>> entry : values) {
                for (Employee e : entry.getValue()) {
                    result.put(e.getId(), entry.getValue());
                }
            }
            return result;
        }
    }


    public static class TupleIntInt
            implements DataSerializable {

        private int count;
        private int amount;

        public TupleIntInt() {
        }

        public TupleIntInt(int count, int amount) {
            this.count = count;
            this.amount = amount;
        }

        @Override
        public void writeData(ObjectDataOutput out)
                throws IOException {

            out.writeInt(count);
            out.writeInt(amount);
        }

        @Override
        public void readData(ObjectDataInput in)
                throws IOException {

            count = in.readInt();
            amount = in.readInt();
        }
    }

    public static class ObjectCombinerFactory
            implements CombinerFactory<String, Integer, BigInteger> {

        @Override
        public Combiner<Integer, BigInteger> newCombiner(String key) {
            return new ObjectCombiner();
        }
    }

    public static class ObjectCombiner
            extends Combiner<Integer, BigInteger> {

        private BigInteger count;

        @Override
        public void combine(Integer value) {
            count = count == null ? BigInteger.valueOf(value) : count.add(BigInteger.valueOf(value));
        }

        @Override
        public BigInteger finalizeChunk() {
            return count;
        }

        @Override
        public void reset() {
            count = null;
        }
    }

    public static class ObjectReducerFactory
            implements ReducerFactory<String, BigInteger, BigInteger> {

        @Override
        public Reducer<BigInteger, BigInteger> newReducer(String key) {
            return new ObjectReducer();
        }
    }

    public static class ObjectReducer
            extends Reducer<BigInteger, BigInteger> {

        private BigInteger count;

        @Override
        public void reduce(BigInteger value) {
            count = count == null ? value : value.add(count);
        }

        @Override
        public BigInteger finalizeReduce() {
            return count;
        }
    }

    public static class DataSerializableIntermediateCombinerFactory
            implements CombinerFactory<String, Integer, TupleIntInt> {

        @Override
        public Combiner<Integer, TupleIntInt> newCombiner(String key) {
            return new DataSerializableIntermediateCombiner();
        }
    }

    public static class DataSerializableIntermediateCombiner
            extends Combiner<Integer, TupleIntInt> {

        private int count;
        private int amount;

        @Override
        public void combine(Integer value) {
            count++;
            amount += value;
        }

        @Override
        public TupleIntInt finalizeChunk() {
            int count = this.count;
            int amount = this.amount;
            this.count = 0;
            this.amount = 0;
            return new TupleIntInt(count, amount);
        }
    }

    public static class DataSerializableIntermediateReducerFactory
            implements ReducerFactory<String, TupleIntInt, TupleIntInt> {

        @Override
        public Reducer<TupleIntInt, TupleIntInt> newReducer(String key) {
            return new DataSerializableIntermediateReducer();
        }
    }

    public static class DataSerializableIntermediateReducer
            extends Reducer<TupleIntInt, TupleIntInt> {

        private volatile int count;
        private volatile int amount;

        @Override
        public void reduce(TupleIntInt value) {
            count += value.count;
            amount += value.amount;
        }

        @Override
        public TupleIntInt finalizeReduce() {
            return new TupleIntInt(count, amount);
        }
    }

    public static class DataSerializableIntermediateCollator
            implements Collator<Map.Entry<String, TupleIntInt>, Integer> {

        @Override
        public Integer collate(Iterable<Map.Entry<String, TupleIntInt>> values) {
            int count = 0;
            int amount = 0;
            for (Map.Entry<String, TupleIntInt> value : values) {
                TupleIntInt tuple = value.getValue();
                count += tuple.count;
                amount += tuple.amount;
            }
            return (int) ((double) amount / count);
        }
    }

    public static class ExceptionThrowingMapper
            implements Mapper<Integer, Integer, String, Integer> {

        @Override
        public void map(Integer key, Integer value, Context<String, Integer> context) {
            throw new NullPointerException("BUMM!");
        }
    }

    public static class TimeConsumingMapper
            implements Mapper<Integer, Integer, String, Integer> {

        @Override
        public void map(Integer key, Integer value, Context<String, Integer> collector) {
            try {
                Thread.sleep(1000);
            } catch (Exception ignore) {
            }
            collector.emit(String.valueOf(key), value);
        }
    }

    public static class TestKeyPredicate
            implements KeyPredicate<Integer> {

        @Override
        public boolean evaluate(Integer key) {
            return key == 50;
        }
    }

    public static class TestMapper
            implements Mapper<Integer, Integer, String, Integer> {

        @Override
        public void map(Integer key, Integer value, Context<String, Integer> collector) {
            collector.emit(String.valueOf(key), value);
        }
    }

    public static class GroupingTestMapper
            implements Mapper<Integer, Integer, String, Integer> {

        private int moduleKey = -1;

        public GroupingTestMapper() {
        }

        public GroupingTestMapper(int moduleKey) {
            this.moduleKey = moduleKey;
        }

        @Override
        public void map(Integer key, Integer value, Context<String, Integer> collector) {
            if (moduleKey == -1 || (key % 4) == moduleKey) {
                collector.emit(String.valueOf(key % 4), value);
            }
        }
    }

    public static class TestReducer
            extends Reducer<Integer, Integer> {

        private volatile int sum = 0;

        @Override
        public void reduce(Integer value) {
            sum += value;
        }

        @Override
        public Integer finalizeReduce() {
            return sum;
        }
    }

    public static class TestReducerFactory
            implements ReducerFactory<String, Integer, Integer> {

        public TestReducerFactory() {
        }

        @Override
        public Reducer<Integer, Integer> newReducer(String key) {
            return new TestReducer();
        }
    }

    public static class GroupingTestCollator
            implements Collator<Map.Entry<String, List<Integer>>, Integer> {

        @Override
        public Integer collate(Iterable<Map.Entry<String, List<Integer>>> values) {
            int sum = 0;
            for (Map.Entry<String, List<Integer>> entry : values) {
                for (Integer value : entry.getValue()) {
                    sum += value;
                }
            }
            return sum;
        }
    }

    public static class TestCollator
            implements Collator<Map.Entry<String, Integer>, Integer> {

        @Override
        public Integer collate(Iterable<Map.Entry<String, Integer>> values) {
            int sum = 0;
            for (Map.Entry<String, Integer> entry : values) {
                sum += entry.getValue();
            }
            return sum;
        }
    }

    public static class NullReducerFactory
            implements ReducerFactory<String, BigInteger, BigInteger> {

        @Override
        public Reducer<BigInteger, BigInteger> newReducer(String key) {
            return new NullReducer();
        }
    }

    public static class NullReducer
            extends Reducer<BigInteger, BigInteger> {

        @Override
        public void reduce(BigInteger value) {
        }

        @Override
        public BigInteger finalizeReduce() {
            return null;
        }
    }

    public static class MapKeyValueSourceAdapter<K, V>
            extends KeyValueSource<K, V>
            implements DataSerializable, PartitionIdAware {

        private volatile KeyValueSource<K, V> keyValueSource;
        private int openCount = 0;

        public MapKeyValueSourceAdapter() {
        }

        public MapKeyValueSourceAdapter(KeyValueSource<K, V> keyValueSource) {
            this.keyValueSource = keyValueSource;
        }

        @Override
        public boolean open(NodeEngine nodeEngine) {
            if (openCount < 2) {
                openCount++;
                return false;
            }
            return keyValueSource.open(nodeEngine);
        }

        @Override
        public boolean hasNext() {
            return keyValueSource.hasNext();
        }

        @Override
        public K key() {
            return keyValueSource.key();
        }

        @Override
        public Map.Entry<K, V> element() {
            return keyValueSource.element();
        }

        @Override
        public boolean reset() {
            return keyValueSource.reset();
        }

        @Override
        public boolean isAllKeysSupported() {
            return keyValueSource.isAllKeysSupported();
        }

        @Override
        public Collection<K> getAllKeys0() {
            return keyValueSource.getAllKeys0();
        }

        public static <K1, V1> KeyValueSource<K1, V1> fromMap(IMap<K1, V1> map) {
            return KeyValueSource.fromMap(map);
        }

        public static <K1, V1> KeyValueSource<K1, V1> fromMultiMap(MultiMap<K1, V1> multiMap) {
            return KeyValueSource.fromMultiMap(multiMap);
        }

        public static <V1> KeyValueSource<String, V1> fromList(IList<V1> list) {
            return KeyValueSource.fromList(list);
        }

        public static <V1> KeyValueSource<String, V1> fromSet(ISet<V1> set) {
            return KeyValueSource.fromSet(set);
        }

        @Override
        public void close()
                throws IOException {
            keyValueSource.close();
        }

        @Override
        public void writeData(ObjectDataOutput out)
                throws IOException {
            out.writeObject(keyValueSource);
        }

        @Override
        public void readData(ObjectDataInput in)
                throws IOException {
            keyValueSource = in.readObject();
        }

        @Override
        public void setPartitionId(int partitionId) {
            if (keyValueSource instanceof PartitionIdAware) {
                ((PartitionIdAware) keyValueSource).setPartitionId(partitionId);
            }
        }
    }

    public static class ListResultingCombinerFactory implements CombinerFactory<String, Integer, List<Integer>> {

        @Override
        public Combiner<Integer, List<Integer>> newCombiner(String key) {
            return new ListResultingCombiner();
        }

        private class ListResultingCombiner extends Combiner<Integer, List<Integer>> {

            private final List<Integer> result = new ArrayList<Integer>();

            @Override
            public void combine(Integer value) {
                result.add(value);
            }

            @Override
            public List<Integer> finalizeChunk() {
                return new ArrayList<Integer>(result);
            }

            @Override
            public void reset() {
                result.clear();
            }
        }
    }

    public static class ListBasedReducerFactory implements ReducerFactory<String, List<Integer>, List<Integer>> {

        @Override
        public Reducer<List<Integer>, List<Integer>> newReducer(String key) {
            return new ListBasedReducer();
        }

        private class ListBasedReducer extends Reducer<List<Integer>, List<Integer>> {

            private final List<Integer> result = new ArrayList<Integer>();

            @Override
            public void reduce(List<Integer> value) {
                result.addAll(value);
            }

            @Override
            public List<Integer> finalizeReduce() {
                return result;
            }
        }
    }

    public static class FinalizingCombinerFactory implements CombinerFactory<String, Integer, List<Integer>> {

        @Override
        public Combiner<Integer, List<Integer>> newCombiner(String key) {
            return new FinalizingCombiner();
        }

        private class FinalizingCombiner extends Combiner<Integer, List<Integer>> {

            private List<Integer> result = new ArrayList<Integer>();

            @Override
            public void combine(Integer value) {
                result.add(value);
            }

            @Override
            public List<Integer> finalizeChunk() {
                return new ArrayList<Integer>(result);
            }

            @Override
            public void reset() {
                result.clear();
            }

            @Override
            public void finalizeCombine() {
                result = null;
            }
        }
    }
}

<code block>


package com.hazelcast.test;


public final class TestEnvironment {

    public static final String HAZELCAST_TEST_USE_NETWORK = "hazelcast.test.use.network";
    public static final String HAZELCAST_TEST_USE_CLIENT = "hazelcast.test.use.client";

    private TestEnvironment() {
    }

    public static boolean isMockNetwork() {
        return !Boolean.getBoolean(HAZELCAST_TEST_USE_NETWORK);
    }

    public static boolean isUseClient() {
        return Boolean.getBoolean(HAZELCAST_TEST_USE_CLIENT);
    }
}

<code block>


package com.hazelcast.test;

import com.hazelcast.cluster.Joiner;
import com.hazelcast.cluster.impl.AbstractJoiner;
import com.hazelcast.cluster.impl.ClusterServiceImpl;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.AddressPicker;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.NodeContext;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.ConnectionManager;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.util.ExceptionUtil;

import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.nio.channels.ServerSocketChannel;
import java.util.ArrayList;
import java.util.Collection;
import java.util.LinkedList;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

final class TestNodeRegistry {

    private final Address[] addresses;
    private final ConcurrentMap<Address, NodeEngineImpl> nodes = new ConcurrentHashMap<Address, NodeEngineImpl>(10);
    private final Object joinerLock = new Object();

    TestNodeRegistry(Address[] addresses) {
        this.addresses = addresses;
    }

    NodeContext createNodeContext(Address address) {
        return new MockNodeContext(addresses, nodes, address, joinerLock);
    }

    HazelcastInstance getInstance(Address address) {
        NodeEngineImpl nodeEngine = nodes.get(address);
        return nodeEngine != null && nodeEngine.isActive() ? nodeEngine.getHazelcastInstance() : null;
    }

    Collection<HazelcastInstance> getAllHazelcastInstances() {
        Collection<HazelcastInstance> all = new LinkedList<HazelcastInstance>();
        for (NodeEngineImpl nodeEngine : nodes.values()) {
            if (nodeEngine.isActive()) {
                all.add(nodeEngine.getHazelcastInstance());
            }
        }
        return all;
    }

    void shutdown() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            value.getHazelcastInstance().shutdown();
        }
    }

    void terminate() {
        final Collection<NodeEngineImpl> values = new ArrayList<NodeEngineImpl>(nodes.values());
        nodes.clear();
        for (NodeEngineImpl value : values) {
            HazelcastInstance hz = value.getHazelcastInstance();
            hz.getLifecycleService().terminate();
        }
    }

    private static class MockNodeContext implements NodeContext {

        final Address[] addresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Address thisAddress;
        final Object joinerLock;

        public MockNodeContext(Address[] addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Address thisAddress, Object joinerLock) {
            this.addresses = addresses;
            this.nodes = nodes;
            this.thisAddress = thisAddress;
            this.joinerLock = joinerLock;
        }

        public AddressPicker createAddressPicker(Node node) {
            return new StaticAddressPicker(thisAddress);
        }

        public Joiner createJoiner(Node node) {
            return new MockJoiner(node, addresses, nodes, joinerLock);
        }

        public ConnectionManager createConnectionManager(Node node, ServerSocketChannel serverSocketChannel) {
            return new MockConnectionManager(addresses, nodes, node, joinerLock);
        }
    }

    private static class StaticAddressPicker implements AddressPicker {
        final Address thisAddress;

        private StaticAddressPicker(Address thisAddress) {
            this.thisAddress = thisAddress;
        }

        public void pickAddress() throws Exception {
        }

        public Address getBindAddress() {
            return thisAddress;
        }

        public Address getPublicAddress() {
            return thisAddress;
        }

        public ServerSocketChannel getServerSocketChannel() {
            return null;
        }
    }

    private static class MockJoiner extends AbstractJoiner {

        final Address[] addresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Object joinerLock;

        MockJoiner(Node node, Address[] addresses, ConcurrentMap<Address, NodeEngineImpl> nodes, Object joinerLock) {
            super(node);
            this.addresses = addresses;
            this.nodes = nodes;
            this.joinerLock = joinerLock;
        }

        public void doJoin() {
            NodeEngineImpl nodeEngine = null;
            synchronized (joinerLock) {
                for (Address address : addresses) {
                    NodeEngineImpl ne = nodes.get(address);
                    if (ne != null && ne.getNode().isActive() && ne.getNode().joined()) {
                        nodeEngine = ne;
                        break;
                    }
                }
                Address master = null;
                if (nodeEngine != null) {
                    if (nodeEngine.getNode().isMaster()) {
                        master = nodeEngine.getThisAddress();
                    } else {
                        master = nodeEngine.getMasterAddress();
                    }
                }
                if (master == null) {
                    master = node.getThisAddress();
                }
                node.setMasterAddress(master);
                if (node.getMasterAddress().equals(node.getThisAddress())) {
                    node.setJoined();
                    node.setAsMaster();
                } else {
                    for (int i = 0; !node.joined() && i < 2000; i++) {
                        try {
                            node.clusterService.sendJoinRequest(node.getMasterAddress(), true);
                            Thread.sleep(50);
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    if (!node.joined()) {
                        throw new AssertionError("Node[" + node.getThisAddress()
                                + "] should have been joined to " + node.getMasterAddress());
                    }
                }
            }
        }

        public void searchForOtherClusters() {
        }

        @Override
        public String getType() {
            return "mock";
        }

        public String toString() {
            return "MockJoiner";
        }

        @Override
        public void blacklist(Address address, boolean permanent) {
        }

        @Override
        public boolean unblacklist(Address address) {
            return false;
        }

        @Override
        public boolean isBlacklisted(Address address) {
            return false;
        }
    }

    private static class MockConnectionManager implements ConnectionManager {
        final Address[] addresses;
        final ConcurrentMap<Address, NodeEngineImpl> nodes;
        final Map<Address, MockConnection> mapConnections = new ConcurrentHashMap<Address, MockConnection>(10);
        final Node node;
        final Object joinerLock;

        MockConnectionManager(Address[] addresses, ConcurrentMap<Address, NodeEngineImpl> nodes,
                              Node node, Object joinerLock) {
            this.addresses = addresses;
            this.nodes = nodes;
            this.node = node;
            this.joinerLock = joinerLock;
            synchronized (this.joinerLock) {
                this.nodes.put(node.getThisAddress(), node.nodeEngine);
            }
        }

        @Override
        public void dumpPerformanceMetrics(StringBuffer sb) {
        }

        public Connection getConnection(Address address) {
            MockConnection conn = mapConnections.get(address);
            if (conn == null) {
                NodeEngineImpl nodeEngine = nodes.get(address);
                MockConnection thisConnection = new MockConnection(address, node.getThisAddress(), node.nodeEngine);
                conn = new MockConnection(node.getThisAddress(), address, nodeEngine);
                conn.localConnection = thisConnection;
                thisConnection.localConnection = conn;
                mapConnections.put(address, conn);
            }
            return conn;
        }

        public Connection getOrConnect(Address address) {
            return getConnection(address);
        }

        public Connection getOrConnect(Address address, boolean silent) {
            return getConnection(address);
        }

        public void shutdown() {
            for (Address address : addresses) {
                if (address.equals(node.getThisAddress())) continue;

                final NodeEngineImpl nodeEngine = nodes.get(address);
                if (nodeEngine != null && nodeEngine.isActive()) {
                    nodeEngine.getExecutionService().execute(ExecutionService.SYSTEM_EXECUTOR, new Runnable() {
                        public void run() {
                            final ClusterServiceImpl clusterService = (ClusterServiceImpl) nodeEngine.getClusterService();
                            clusterService.removeAddress(node.getThisAddress());
                        }
                    });
                }
            }
        }

        @Override
        public boolean registerConnection(Address address, Connection connection) {
            mapConnections.put(address, (MockConnection) connection);
            return true;
        }

        public void start() {
        }

        public void addConnectionListener(ConnectionListener connectionListener) {
        }

        public void destroyConnection(Connection conn) {
        }


        public void restart() {
        }

        @Override
        public int getActiveConnectionCount() {
            return 0;
        }

        public int getCurrentClientConnections() {
            return 0;
        }

        @Override
        public int getConnectionCount() {
            return 0;
        }

        public int getAllTextConnections() {
            return 0;
        }
    }

    private static class MockConnection implements Connection {
        final Address localEndpoint;
        volatile Connection localConnection;
        final Address remoteEndpoint;
        final NodeEngineImpl nodeEngine;

        public MockConnection(Address localEndpoint, Address remoteEndpoint, NodeEngineImpl nodeEngine) {
            this.localEndpoint = localEndpoint;
            this.remoteEndpoint = remoteEndpoint;
            this.nodeEngine = nodeEngine;
        }

        public Address getEndPoint() {
            return remoteEndpoint;
        }

        public boolean live() {
            return true;
        }

        public int getId() {
            return 0;
        }

        public boolean write(SocketWritable socketWritable) {
            final Packet packet = (Packet) socketWritable;
            if (nodeEngine.getNode().isActive()) {
                Packet newPacket = readFromPacket(packet);
                MemberImpl member = nodeEngine.getClusterService().getMember(localEndpoint);
                if (member != null) {
                    member.didRead();
                }
                nodeEngine.getPacketTransceiver().receive(newPacket);
                return true;
            }
            return false;
        }

        private Packet readFromPacket(Packet packet) {
            Packet newPacket = new Packet();
            ByteBuffer buffer = ByteBuffer.allocate(4096);
            boolean writeDone;
            boolean readDone;
            do {
                writeDone = packet.writeTo(buffer);
                buffer.flip();
                readDone = newPacket.readFrom(buffer);
                if (buffer.hasRemaining()) {
                    throw new IllegalStateException("Buffer should be empty! " + buffer);
                }
                buffer.clear();
            } while (!writeDone);

            if (!readDone) {
                throw new IllegalStateException("Read should be completed!");
            }

            newPacket.setConn(localConnection);
            return newPacket;
        }

        public long lastReadTime() {
            return System.currentTimeMillis();
        }

        public long lastWriteTime() {
            return System.currentTimeMillis();
        }

        public void close() {
        }

        public boolean isClient() {
            return false;
        }

        @Override
        public ConnectionType getType() {
            return ConnectionType.MEMBER;
        }

        public InetAddress getInetAddress() {
            try {
                return localEndpoint.getInetAddress();
            } catch (UnknownHostException e) {
                throw ExceptionUtil.rethrow(e);
            }
        }

        public InetSocketAddress getRemoteSocketAddress() {
            return new InetSocketAddress(getInetAddress(), getPort());
        }

        public int getPort() {
            return localEndpoint.getPort();
        }

        @Override
        public boolean isAlive() {
            return true;
        }
    }
}

<code block>


package com.hazelcast.test;

import com.hazelcast.config.Config;
import com.hazelcast.config.XmlConfigBuilder;
import com.hazelcast.core.Hazelcast;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.instance.GroupProperties;
import com.hazelcast.instance.HazelcastInstanceFactory;
import com.hazelcast.instance.NodeContext;
import com.hazelcast.nio.Address;

import java.lang.reflect.Method;
import java.net.UnknownHostException;
import java.util.Arrays;
import java.util.Collection;
import java.util.concurrent.atomic.AtomicInteger;

import static com.hazelcast.util.Preconditions.checkNotNull;

public final class TestHazelcastInstanceFactory {

    private final static String HAZELCAST_CLIENT = "com.hazelcast.client.HazelcastClient";
    private final static String HAZELCAST_CLIENT_CONFIG = "com.hazelcast.client.config.ClientConfig";
    private final static AtomicInteger PORTS = new AtomicInteger(5000);

    public final boolean mockNetwork = TestEnvironment.isMockNetwork();
    public final boolean useClient = TestEnvironment.isUseClient();

    private final Address[] addresses;
    private final TestNodeRegistry registry;
    private final AtomicInteger nodeIndex = new AtomicInteger();
    private final int count;

    public TestHazelcastInstanceFactory(int count) {
        this(createAddresses(count));
    }

    public TestHazelcastInstanceFactory(String... addresses) {
        this(createAddresses(addresses));
    }

    private TestHazelcastInstanceFactory(Address[] addresses) {
        this.count = addresses.length;
        if (mockNetwork) {
            this.addresses = addresses;
            this.registry = new TestNodeRegistry(this.addresses);
        } else {
            this.addresses = null;
            this.registry = null;
        }
    }

    public HazelcastInstance newHazelcastInstance() {
        return newHazelcastInstance(new Config());
    }

    public HazelcastInstance newHazelcastInstance(Config config) {
        if (mockNetwork) {
            if (nodeIndex.get() >= addresses.length) {
                throw new IndexOutOfBoundsException("Max " + addresses.length + " instances can be created!");
            }
            init(config);
            NodeContext nodeContext = registry.createNodeContext(addresses[nodeIndex.getAndIncrement()]);
            return HazelcastInstanceFactory.newHazelcastInstance(config, null, nodeContext);
        }
        if (useClient) {
            return newHazelcastClient();
        } else {
            return HazelcastInstanceFactory.newHazelcastInstance(config);
        }
    }

    public HazelcastInstance[] newInstances() {
        return newInstances(new Config());
    }

    public HazelcastInstance[] newInstances(Config config, int nodeCount) {
        final HazelcastInstance[] instances = new HazelcastInstance[nodeCount];
        for (int i = 0; i < nodeCount; i++) {
            instances[i] = newHazelcastInstance(config);
        }
        return instances;
    }

    public HazelcastInstance[] newInstances(Config config) {
        return newInstances(config, count);
    }

    public Collection<HazelcastInstance> getAllHazelcastInstances() {
        if (mockNetwork) {
            return registry.getAllHazelcastInstances();
        }
        return Hazelcast.getAllHazelcastInstances();
    }

    public void shutdownAll() {
        if (mockNetwork) {
            nodeIndex.set(Integer.MAX_VALUE);
            registry.shutdown();
        } else {
            Hazelcast.shutdownAll();
        }
    }

    public void terminateAll() {
        if (mockNetwork) {
            nodeIndex.set(Integer.MAX_VALUE);
            registry.terminate();
        } else {
            HazelcastInstanceFactory.terminateAll();
        }
    }

    private static HazelcastInstance newHazelcastClient() {
        Class clazz = null;
        try {
            clazz = Class.forName(HAZELCAST_CLIENT);
            Class clientConfig = Class.forName(HAZELCAST_CLIENT_CONFIG);
            Method method = clazz.getMethod("newHazelcastClient", clientConfig);
            HazelcastInstance hazelcastInstance = (HazelcastInstance) method.invoke(null, clientConfig.newInstance());
            return hazelcastInstance;
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

    private static Address[] createAddresses(int count) {
        Address[] addresses = new Address[count];
        for (int i = 0; i < count; i++) {
            try {
                addresses[i] = new Address("127.0.0.1", PORTS.incrementAndGet());
            } catch (UnknownHostException e) {
                e.printStackTrace();
            }
        }
        return addresses;
    }

    private static Address[] createAddresses(String...addressArray) {
        checkElementsNotNull(addressArray);

        final int count = addressArray.length;
        Address[] addresses = new Address[count];
        for (int i = 0; i < count; i++) {
            try {
                addresses[i] = new Address(addressArray[i], PORTS.incrementAndGet());
            } catch (UnknownHostException e) {
                e.printStackTrace();
            }
        }
        return addresses;
    }

    private static <T> void checkElementsNotNull(T[] array) {
        checkNotNull(array, "Array should not be null");
        for (Object element : array) {
            checkNotNull(element, "Array element should not be null");
        }
    }

    private static Config init(Config config) {
        if (config == null) {
            config = new XmlConfigBuilder().build();
        }
        config.setProperty(GroupProperties.PROP_WAIT_SECONDS_BEFORE_JOIN, "0");
        config.setProperty(GroupProperties.PROP_GRACEFUL_SHUTDOWN_MAX_WAIT, "120");
        config.setProperty(GroupProperties.PROP_PARTITION_BACKUP_SYNC_INTERVAL, "1");
        config.getNetworkConfig().getJoin().getMulticastConfig().setEnabled(false);
        return config;
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder("TestHazelcastInstanceFactory{");
        sb.append("addresses=").append(Arrays.toString(addresses));
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.client;

import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.config.XmlClientConfigBuilder;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.impl.HazelcastClientProxy;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.OutOfMemoryHandler;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.util.EmptyStatement;

import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;


public final class HazelcastClient {

    static {
        OutOfMemoryErrorDispatcher.setClientHandler(new ClientOutOfMemoryHandler());
    }

    private static final ConcurrentMap<String, HazelcastClientProxy> CLIENTS
            = new ConcurrentHashMap<String, HazelcastClientProxy>(5);

    
    private HazelcastClient() {
    }

    public static HazelcastInstance newHazelcastClient() {
        return newHazelcastClient(new XmlClientConfigBuilder().build());
    }

    public static HazelcastInstance newHazelcastClient(ClientConfig config) {
        if (config == null) {
            config = new XmlClientConfigBuilder().build();
        }

        final ClassLoader tccl = Thread.currentThread().getContextClassLoader();
        HazelcastClientProxy proxy;
        try {
            Thread.currentThread().setContextClassLoader(HazelcastClient.class.getClassLoader());
            final HazelcastClientInstanceImpl client = new HazelcastClientInstanceImpl(config);
            client.start();
            OutOfMemoryErrorDispatcher.registerClient(client);
            proxy = new HazelcastClientProxy(client);
            CLIENTS.put(client.getName(), proxy);
        } finally {
            Thread.currentThread().setContextClassLoader(tccl);
        }
        return proxy;
    }

    
    public static HazelcastInstance getHazelcastClientByName(String instanceName) {
        return CLIENTS.get(instanceName);
    }


    
    public static Collection<HazelcastInstance> getAllHazelcastClients() {
        Collection<HazelcastClientProxy> values = CLIENTS.values();
        return Collections.<HazelcastInstance>unmodifiableCollection(new HashSet<HazelcastInstance>(values));
    }

    
    public static void shutdownAll() {
        for (HazelcastClientProxy proxy : CLIENTS.values()) {
            HazelcastClientInstanceImpl client = proxy.client;
            if (client == null) {
                continue;
            }
            proxy.client = null;
            try {
                client.shutdown();
            } catch (Throwable ignored) {
                EmptyStatement.ignore(ignored);
            }
        }
        OutOfMemoryErrorDispatcher.clearClients();
        CLIENTS.clear();
    }

    
    public static void shutdown(HazelcastInstance instance) {
        if (instance instanceof HazelcastClientProxy) {
            final HazelcastClientProxy proxy = (HazelcastClientProxy) instance;
            HazelcastClientInstanceImpl client = proxy.client;
            if (client == null) {
                return;
            }
            proxy.client = null;
            CLIENTS.remove(client.getName());

            try {
                client.shutdown();
            } catch (Throwable ignored) {
                EmptyStatement.ignore(ignored);
            } finally {
                OutOfMemoryErrorDispatcher.deregisterClient(client);
            }
        }
    }

    
    public static void shutdown(String instanceName) {
        HazelcastClientProxy proxy = CLIENTS.remove(instanceName);
        if (proxy == null) {
            return;
        }
        HazelcastClientInstanceImpl client = proxy.client;
        if (client == null) {
            return;
        }
        proxy.client = null;
        try {
            client.shutdown();
        } catch (Throwable ignored) {
            EmptyStatement.ignore(ignored);
        } finally {
            OutOfMemoryErrorDispatcher.deregisterClient(client);
        }
    }

    
    public static void setOutOfMemoryHandler(OutOfMemoryHandler outOfMemoryHandler) {
        OutOfMemoryErrorDispatcher.setClientHandler(outOfMemoryHandler);
    }

}

<code block>
package com.hazelcast.client.impl;

import com.hazelcast.cache.impl.nearcache.NearCacheManager;
import com.hazelcast.client.ClientExtension;
import com.hazelcast.client.HazelcastClient;
import com.hazelcast.client.LoadBalancer;
import com.hazelcast.client.config.ClientAwsConfig;
import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.config.ClientNetworkConfig;
import com.hazelcast.client.config.ClientProperties;
import com.hazelcast.client.config.ClientSecurityConfig;
import com.hazelcast.client.connection.AddressTranslator;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.connection.nio.ClientConnectionManagerImpl;
import com.hazelcast.client.impl.client.DistributedObjectInfo;
import com.hazelcast.client.impl.client.GetDistributedObjectsRequest;
import com.hazelcast.client.proxy.ClientClusterProxy;
import com.hazelcast.client.proxy.PartitionServiceProxy;
import com.hazelcast.client.spi.ClientClusterService;
import com.hazelcast.client.spi.ClientExecutionService;
import com.hazelcast.client.spi.ClientInvocationService;
import com.hazelcast.client.spi.ClientListenerService;
import com.hazelcast.client.spi.ClientPartitionService;
import com.hazelcast.client.spi.ClientTransactionManagerService;
import com.hazelcast.client.spi.ProxyManager;
import com.hazelcast.client.spi.impl.AwsAddressTranslator;
import com.hazelcast.client.spi.impl.ClientClusterServiceImpl;
import com.hazelcast.client.spi.impl.ClientExecutionServiceImpl;
import com.hazelcast.client.spi.impl.ClientInvocation;
import com.hazelcast.client.spi.impl.ClientListenerServiceImpl;
import com.hazelcast.client.spi.impl.ClientNonSmartInvocationServiceImpl;
import com.hazelcast.client.spi.impl.ClientPartitionServiceImpl;
import com.hazelcast.client.spi.impl.ClientSmartInvocationServiceImpl;
import com.hazelcast.client.spi.impl.DefaultAddressTranslator;
import com.hazelcast.client.spi.impl.ClientTransactionManagerServiceImpl;
import com.hazelcast.client.util.RoundRobinLB;
import com.hazelcast.collection.impl.list.ListService;
import com.hazelcast.collection.impl.set.SetService;
import com.hazelcast.concurrent.atomiclong.AtomicLongService;
import com.hazelcast.concurrent.atomicreference.AtomicReferenceService;
import com.hazelcast.concurrent.countdownlatch.CountDownLatchService;
import com.hazelcast.concurrent.idgen.IdGeneratorService;
import com.hazelcast.concurrent.lock.LockServiceImpl;
import com.hazelcast.concurrent.semaphore.SemaphoreService;
import com.hazelcast.config.Config;
import com.hazelcast.config.GroupConfig;
import com.hazelcast.core.Client;
import com.hazelcast.core.ClientService;
import com.hazelcast.core.Cluster;
import com.hazelcast.core.DistributedObject;
import com.hazelcast.core.DistributedObjectListener;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.IAtomicLong;
import com.hazelcast.core.IAtomicReference;
import com.hazelcast.core.ICountDownLatch;
import com.hazelcast.core.IExecutorService;
import com.hazelcast.core.IList;
import com.hazelcast.core.ILock;
import com.hazelcast.core.IMap;
import com.hazelcast.core.IQueue;
import com.hazelcast.core.ISemaphore;
import com.hazelcast.core.ISet;
import com.hazelcast.core.ITopic;
import com.hazelcast.core.IdGenerator;
import com.hazelcast.core.LifecycleService;
import com.hazelcast.core.MultiMap;
import com.hazelcast.core.PartitionService;
import com.hazelcast.core.ReplicatedMap;
import com.hazelcast.executor.impl.DistributedExecutorService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.logging.LoggingService;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.mapreduce.JobTracker;
import com.hazelcast.mapreduce.impl.MapReduceService;
import com.hazelcast.multimap.impl.MultiMapService;
import com.hazelcast.nio.ClassLoaderUtil;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.collection.impl.queue.QueueService;
import com.hazelcast.quorum.QuorumService;
import com.hazelcast.replicatedmap.impl.ReplicatedMapService;
import com.hazelcast.ringbuffer.Ringbuffer;
import com.hazelcast.ringbuffer.impl.RingbufferService;
import com.hazelcast.security.Credentials;
import com.hazelcast.security.UsernamePasswordCredentials;
import com.hazelcast.spi.impl.SerializableList;
import com.hazelcast.spi.impl.SerializationServiceSupport;
import com.hazelcast.topic.impl.TopicService;
import com.hazelcast.transaction.HazelcastXAResource;
import com.hazelcast.transaction.TransactionContext;
import com.hazelcast.transaction.TransactionException;
import com.hazelcast.transaction.TransactionOptions;
import com.hazelcast.transaction.TransactionalTask;
import com.hazelcast.transaction.impl.xa.XAService;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.ServiceLoader;

import java.util.Collection;
import java.util.Iterator;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.logging.Level;

public class HazelcastClientInstanceImpl implements HazelcastInstance, SerializationServiceSupport {

    private static final AtomicInteger CLIENT_ID = new AtomicInteger();
    private static final ILogger LOGGER = Logger.getLogger(HazelcastClient.class);

    private final ClientProperties clientProperties;
    private final int id = CLIENT_ID.getAndIncrement();
    private final String instanceName;
    private final ClientConfig config;
    private final ThreadGroup threadGroup;
    private final LifecycleServiceImpl lifecycleService;
    private final SerializationService serializationService;
    private final ClientConnectionManager connectionManager;
    private final ClientClusterServiceImpl clusterService;
    private final ClientPartitionServiceImpl partitionService;
    private final ClientInvocationService invocationService;
    private final ClientExecutionServiceImpl executionService;
    private final ClientListenerServiceImpl listenerService;
    private final NearCacheManager nearCacheManager;
    private final ClientTransactionManagerService transactionManager;
    private final ProxyManager proxyManager;
    private final ConcurrentMap<String, Object> userContext;
    private final LoadBalancer loadBalancer;
    private final ClientExtension clientExtension;
    private final Credentials credentials;

    public HazelcastClientInstanceImpl(ClientConfig config) {
        this.config = config;
        final GroupConfig groupConfig = config.getGroupConfig();
        instanceName = "hz.client_" + id + (groupConfig != null ? "_" + groupConfig.getName() : "");
        clientExtension = createClientInitializer(config.getClassLoader());
        clientExtension.beforeStart(this);

        credentials = initCredentials(config);
        threadGroup = new ThreadGroup(instanceName);
        lifecycleService = new LifecycleServiceImpl(this);
        clientProperties = new ClientProperties(config);
        serializationService = clientExtension.createSerializationService();
        proxyManager = new ProxyManager(this);
        executionService = initExecutionService();
        loadBalancer = initLoadBalancer(config);
        transactionManager = new ClientTransactionManagerServiceImpl(this, loadBalancer);
        partitionService = new ClientPartitionServiceImpl(this);
        connectionManager = initClientConnectionManager();
        clusterService = new ClientClusterServiceImpl(this);
        invocationService = initInvocationService();
        listenerService = initListenerService();
        userContext = new ConcurrentHashMap<String, Object>();
        nearCacheManager = clientExtension.createNearCacheManager();

        proxyManager.init(config);
    }

    private LoadBalancer initLoadBalancer(ClientConfig config) {
        LoadBalancer lb = config.getLoadBalancer();
        if (lb == null) {
            lb = new RoundRobinLB();
        }
        return lb;
    }

    private Credentials initCredentials(ClientConfig config) {
        final GroupConfig groupConfig = config.getGroupConfig();
        final ClientSecurityConfig securityConfig = config.getSecurityConfig();
        Credentials c = securityConfig.getCredentials();
        if (c == null) {
            final String credentialsClassname = securityConfig.getCredentialsClassname();
            if (credentialsClassname != null) {
                try {
                    c = ClassLoaderUtil.newInstance(config.getClassLoader(), credentialsClassname);
                } catch (Exception e) {
                    throw ExceptionUtil.rethrow(e);
                }
            }
        }
        if (c == null) {
            c = new UsernamePasswordCredentials(groupConfig.getName(), groupConfig.getPassword());
        }
        return c;
    }

    private ClientInvocationService initInvocationService() {
        final ClientNetworkConfig networkConfig = config.getNetworkConfig();
        if (networkConfig.isSmartRouting()) {
            return new ClientSmartInvocationServiceImpl(this, loadBalancer);

        } else {
            return new ClientNonSmartInvocationServiceImpl(this);
        }
    }

    public int getId() {
        return id;
    }

    private ClientExtension createClientInitializer(ClassLoader classLoader) {
        try {
            String factoryId = ClientExtension.class.getName();
            Iterator<ClientExtension> iter = ServiceLoader.iterator(ClientExtension.class, factoryId, classLoader);
            while (iter.hasNext()) {
                ClientExtension initializer = iter.next();
                if (!(initializer.getClass().equals(DefaultClientExtension.class))) {
                    return initializer;
                }
            }
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }
        return new DefaultClientExtension();
    }

    private ClientListenerServiceImpl initListenerService() {
        int eventQueueCapacity = clientProperties.getEventQueueCapacity().getInteger();
        int eventThreadCount = clientProperties.getEventThreadCount().getInteger();
        return new ClientListenerServiceImpl(this, eventThreadCount, eventQueueCapacity);
    }

    private ClientExecutionServiceImpl initExecutionService() {
        return new ClientExecutionServiceImpl(instanceName, threadGroup,
                config.getClassLoader(), config.getExecutorPoolSize());
    }

    public void start() {
        lifecycleService.setStarted();
        connectionManager.start();
        try {
            clusterService.start();
        } catch (Exception e) {
            lifecycleService.shutdown();
            throw ExceptionUtil.rethrow(e);
        }
        loadBalancer.init(getCluster(), config);
        partitionService.start();
        clientExtension.afterStart(this);
    }

    ClientConnectionManager initClientConnectionManager() {
        final ClientAwsConfig awsConfig = config.getNetworkConfig().getAwsConfig();
        AddressTranslator addressTranslator;
        if (awsConfig != null && awsConfig.isEnabled()) {
            try {
                addressTranslator = new AwsAddressTranslator(awsConfig);
            } catch (NoClassDefFoundError e) {
                LOGGER.log(Level.WARNING, "hazelcast-cloud.jar might be missing!");
                throw e;
            }
        } else {
            addressTranslator = new DefaultAddressTranslator();
        }
        return new ClientConnectionManagerImpl(this, addressTranslator);
    }

    @Override
    public HazelcastXAResource getXAResource() {
        return getDistributedObject(XAService.SERVICE_NAME, XAService.SERVICE_NAME);
    }

    public Config getConfig() {
        throw new UnsupportedOperationException("Client cannot access cluster config!");
    }

    public ClientProperties getClientProperties() {
        return clientProperties;
    }

    @Override
    public String getName() {
        return instanceName;
    }

    @Override
    public <E> IQueue<E> getQueue(String name) {
        return getDistributedObject(QueueService.SERVICE_NAME, name);
    }

    @Override
    public <E> ITopic<E> getTopic(String name) {
        return getDistributedObject(TopicService.SERVICE_NAME, name);
    }

    @Override
    public <E> ITopic<E> getReliableTopic(String name) {
        throw new UnsupportedOperationException();
    }

    @Override
    public <E> ISet<E> getSet(String name) {
        return getDistributedObject(SetService.SERVICE_NAME, name);
    }

    @Override
    public <E> IList<E> getList(String name) {
        return getDistributedObject(ListService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> IMap<K, V> getMap(String name) {
        return getDistributedObject(MapService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> MultiMap<K, V> getMultiMap(String name) {
        return getDistributedObject(MultiMapService.SERVICE_NAME, name);
    }

    @Override
    public <K, V> ReplicatedMap<K, V> getReplicatedMap(String name) {
        return getDistributedObject(ReplicatedMapService.SERVICE_NAME, name);
    }

    @Override
    public JobTracker getJobTracker(String name) {
        return getDistributedObject(MapReduceService.SERVICE_NAME, name);
    }

    @Override
    public ILock getLock(String key) {
        return getDistributedObject(LockServiceImpl.SERVICE_NAME, key);
    }

    @Override
    public <E> Ringbuffer<E> getRingbuffer(String name) {
        return getDistributedObject(RingbufferService.SERVICE_NAME, name);
    }

    @Override
    public Cluster getCluster() {
        return new ClientClusterProxy(clusterService);
    }

    @Override
    public Client getLocalEndpoint() {
        return clusterService.getLocalClient();
    }

    @Override
    public IExecutorService getExecutorService(String name) {
        return getDistributedObject(DistributedExecutorService.SERVICE_NAME, name);
    }

    public <T> T executeTransaction(TransactionalTask<T> task) throws TransactionException {
        return transactionManager.executeTransaction(task);
    }

    @Override
    public <T> T executeTransaction(TransactionOptions options, TransactionalTask<T> task) throws TransactionException {
        return transactionManager.executeTransaction(options, task);
    }

    @Override
    public TransactionContext newTransactionContext() {
        return transactionManager.newTransactionContext();
    }

    @Override
    public TransactionContext newTransactionContext(TransactionOptions options) {
        return transactionManager.newTransactionContext(options);
    }

    public ClientTransactionManagerService getTransactionManager() {
        return transactionManager;
    }

    @Override
    public IdGenerator getIdGenerator(String name) {
        return getDistributedObject(IdGeneratorService.SERVICE_NAME, name);
    }

    @Override
    public IAtomicLong getAtomicLong(String name) {
        return getDistributedObject(AtomicLongService.SERVICE_NAME, name);
    }

    @Override
    public <E> IAtomicReference<E> getAtomicReference(String name) {
        return getDistributedObject(AtomicReferenceService.SERVICE_NAME, name);
    }

    @Override
    public ICountDownLatch getCountDownLatch(String name) {
        return getDistributedObject(CountDownLatchService.SERVICE_NAME, name);
    }

    @Override
    public ISemaphore getSemaphore(String name) {
        return getDistributedObject(SemaphoreService.SERVICE_NAME, name);
    }

    @Override
    public Collection<DistributedObject> getDistributedObjects() {
        try {
            GetDistributedObjectsRequest request = new GetDistributedObjectsRequest();

            final Future<SerializableList> future = new ClientInvocation(this, request).invoke();
            final SerializableList serializableList = serializationService.toObject(future.get());
            for (Data data : serializableList) {
                final DistributedObjectInfo o = serializationService.toObject(data);
                getDistributedObject(o.getServiceName(), o.getName());
            }
            return (Collection<DistributedObject>) proxyManager.getDistributedObjects();
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }
    }

    @Override
    public String addDistributedObjectListener(DistributedObjectListener distributedObjectListener) {
        return proxyManager.addDistributedObjectListener(distributedObjectListener);
    }

    @Override
    public boolean removeDistributedObjectListener(String registrationId) {
        return proxyManager.removeDistributedObjectListener(registrationId);
    }

    @Override
    public PartitionService getPartitionService() {
        return new PartitionServiceProxy(partitionService, listenerService);
    }

    @Override
    public QuorumService getQuorumService() {
        throw new UnsupportedOperationException();
    }

    @Override
    public ClientService getClientService() {
        throw new UnsupportedOperationException();
    }

    @Override
    public LoggingService getLoggingService() {
        throw new UnsupportedOperationException();
    }

    @Override
    public LifecycleService getLifecycleService() {
        return lifecycleService;
    }

    @Override
    public <T extends DistributedObject> T getDistributedObject(String serviceName, String name) {
        return (T) proxyManager.getOrCreateProxy(serviceName, name);
    }

    @Override
    public ConcurrentMap<String, Object> getUserContext() {
        return userContext;
    }

    public ClientConfig getClientConfig() {
        return config;
    }

    public SerializationService getSerializationService() {
        return serializationService;
    }

    public ClientConnectionManager getConnectionManager() {
        return connectionManager;
    }

    public ClientClusterService getClientClusterService() {
        return clusterService;
    }

    public ClientExecutionService getClientExecutionService() {
        return executionService;
    }

    public ClientPartitionService getClientPartitionService() {
        return partitionService;
    }

    public ClientInvocationService getInvocationService() {
        return invocationService;
    }

    public ClientListenerService getListenerService() {
        return listenerService;
    }

    public NearCacheManager getNearCacheManager() {
        return nearCacheManager;
    }

    public ThreadGroup getThreadGroup() {
        return threadGroup;
    }

    public ClientExtension getClientExtension() {
        return clientExtension;
    }

    public Credentials getCredentials() {
        return credentials;
    }

    @Override
    public void shutdown() {
        getLifecycleService().shutdown();
    }

    public void doShutdown() {
        proxyManager.destroy();
        executionService.shutdown();
        partitionService.stop();
        transactionManager.shutdown();
        connectionManager.shutdown();
        invocationService.shutdown();
        listenerService.shutdown();
        serializationService.destroy();
        nearCacheManager.destroyAllNearCaches();
    }
}

<code block>


package com.hazelcast.client.connection.nio;

import com.hazelcast.client.ClientTypes;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.core.LifecycleService;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionType;
import com.hazelcast.nio.Protocols;
import com.hazelcast.nio.SocketWritable;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.nio.tcp.IOSelector;
import com.hazelcast.nio.tcp.SocketChannelWrapper;

import java.io.Closeable;
import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.Socket;
import java.nio.ByteBuffer;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;

import static com.hazelcast.util.StringUtil.stringToBytes;

public class ClientConnection implements Connection, Closeable {

    private final ILogger logger = Logger.getLogger(ClientConnection.class);
    private final AtomicBoolean live = new AtomicBoolean(true);
    private final AtomicInteger packetCount = new AtomicInteger(0);

    private final ClientWriteHandler writeHandler;
    private final ClientReadHandler readHandler;
    private final int connectionId;
    private final SocketChannelWrapper socketChannelWrapper;
    private final ClientConnectionManager connectionManager;
    private final SerializationService serializationService;
    private final LifecycleService lifecycleService;

    private volatile Address remoteEndpoint;
    private volatile boolean heartBeating = true;

    public ClientConnection(HazelcastClientInstanceImpl client, IOSelector in, IOSelector out,
                            int connectionId, SocketChannelWrapper socketChannelWrapper) throws IOException {
        final Socket socket = socketChannelWrapper.socket();
        this.connectionManager = client.getConnectionManager();
        this.serializationService = client.getSerializationService();
        this.lifecycleService = client.getLifecycleService();
        this.socketChannelWrapper = socketChannelWrapper;
        this.connectionId = connectionId;
        this.readHandler = new ClientReadHandler(this, in, socket.getReceiveBufferSize());
        this.writeHandler = new ClientWriteHandler(this, out, socket.getSendBufferSize());
    }

    public void incrementPacketCount() {
        packetCount.incrementAndGet();
    }

    public void decrementPacketCount() {
        packetCount.decrementAndGet();
    }

    public int getPacketCount() {
        return packetCount.get();
    }

    public SerializationService getSerializationService() {
        return serializationService;
    }

    @Override
    public boolean write(SocketWritable packet) {
        if (!live.get()) {
            if (logger.isFinestEnabled()) {
                logger.finest("Connection is closed, won't write packet -> " + packet);
            }
            return false;
        }
        writeHandler.enqueueSocketWritable(packet);
        return true;
    }

    public void init() throws IOException {
        final ByteBuffer buffer = ByteBuffer.allocate(6);
        buffer.put(stringToBytes(Protocols.CLIENT_BINARY));
        buffer.put(stringToBytes(ClientTypes.JAVA));
        buffer.flip();
        socketChannelWrapper.write(buffer);
    }

    @Override
    public Address getEndPoint() {
        return remoteEndpoint;
    }

    @Override
    public boolean isAlive() {
        return live.get();
    }

    @Override
    public long lastReadTime() {
        return readHandler.getLastHandle();
    }

    @Override
    public long lastWriteTime() {
        return writeHandler.getLastHandle();
    }

    @Override
    public void close() {
        close(null);
    }

    @Override
    public ConnectionType getType() {
        return ConnectionType.JAVA_CLIENT;
    }

    @Override
    public boolean isClient() {
        return true;
    }

    @Override
    public InetAddress getInetAddress() {
        return socketChannelWrapper.socket().getInetAddress();
    }

    @Override
    public InetSocketAddress getRemoteSocketAddress() {
        return (InetSocketAddress) socketChannelWrapper.socket().getRemoteSocketAddress();
    }

    @Override
    public int getPort() {
        return socketChannelWrapper.socket().getPort();
    }

    public SocketChannelWrapper getSocketChannelWrapper() {
        return socketChannelWrapper;
    }

    public ClientConnectionManager getConnectionManager() {
        return connectionManager;
    }

    public ClientReadHandler getReadHandler() {
        return readHandler;
    }

    public void setRemoteEndpoint(Address remoteEndpoint) {
        this.remoteEndpoint = remoteEndpoint;
    }

    public Address getRemoteEndpoint() {
        return remoteEndpoint;
    }

    public InetSocketAddress getLocalSocketAddress() {
        return (InetSocketAddress) socketChannelWrapper.socket().getLocalSocketAddress();
    }

    private void innerClose() throws IOException {
        if (socketChannelWrapper.isOpen()) {
            socketChannelWrapper.close();
        }
        readHandler.shutdown();
        writeHandler.shutdown();
    }

    public void close(Throwable t) {
        if (!live.compareAndSet(true, false)) {
            return;
        }
        String message = "Connection [" + socketChannelWrapper.socket().getRemoteSocketAddress() + "] lost. Reason: ";
        if (t != null) {
            message += t.getClass().getName() + "[" + t.getMessage() + "]";
        } else {
            message += "Socket explicitly closed";
        }

        try {
            innerClose();
        } catch (Exception e) {
            logger.warning(e);
        }

        if (lifecycleService.isRunning()) {
            logger.warning(message);
        } else {
            logger.finest(message);
        }
    }

    
    @edu.umd.cs.findbugs.annotations.SuppressWarnings("VO_VOLATILE_INCREMENT")
    void heartBeatingFailed() {
        heartBeating = false;
    }

    void heartBeatingSucceed() {
        heartBeating = true;
    }

    public boolean isHeartBeating() {
        return live.get() && heartBeating;
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (!(o instanceof ClientConnection)) {
            return false;
        }

        ClientConnection that = (ClientConnection) o;

        if (connectionId != that.connectionId) {
            return false;
        }

        return true;
    }

    @Override
    public int hashCode() {
        return connectionId;
    }

    @Override
    public String toString() {
        final StringBuilder sb = new StringBuilder("ClientConnection{");
        sb.append("live=").append(live);
        sb.append(", writeHandler=").append(writeHandler);
        sb.append(", readHandler=").append(readHandler);
        sb.append(", connectionId=").append(connectionId);
        sb.append(", socketChannel=").append(socketChannelWrapper);
        sb.append(", remoteEndpoint=").append(remoteEndpoint);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.client.connection.nio;

import com.hazelcast.client.ClientExtension;
import com.hazelcast.client.config.ClientConfig;
import com.hazelcast.client.config.ClientNetworkConfig;
import com.hazelcast.client.config.ClientProperties;
import com.hazelcast.client.config.SocketOptions;
import com.hazelcast.client.connection.AddressTranslator;
import com.hazelcast.client.connection.Authenticator;
import com.hazelcast.client.connection.ClientConnectionManager;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.spi.ClientInvocationService;
import com.hazelcast.client.spi.impl.ClientExecutionServiceImpl;
import com.hazelcast.client.spi.impl.ClientInvocation;
import com.hazelcast.client.spi.impl.ClientListenerServiceImpl;
import com.hazelcast.client.spi.impl.ConnectionHeartbeatListener;
import com.hazelcast.cluster.client.ClientPingRequest;
import com.hazelcast.config.SocketInterceptorConfig;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.nio.ConnectionListener;
import com.hazelcast.nio.Packet;
import com.hazelcast.nio.SocketInterceptor;
import com.hazelcast.nio.tcp.IOSelector;
import com.hazelcast.nio.tcp.IOSelectorOutOfMemoryHandler;
import com.hazelcast.nio.tcp.InSelectorImpl;
import com.hazelcast.nio.tcp.SocketChannelWrapper;
import com.hazelcast.nio.tcp.SocketChannelWrapperFactory;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;

import java.io.IOException;
import java.net.Socket;
import java.nio.channels.SocketChannel;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.CopyOnWriteArraySet;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

import static com.hazelcast.client.config.ClientProperties.PROP_HEARTBEAT_INTERVAL_DEFAULT;
import static com.hazelcast.client.config.ClientProperties.PROP_HEARTBEAT_TIMEOUT_DEFAULT;
import static com.hazelcast.client.config.SocketOptions.DEFAULT_BUFFER_SIZE_BYTE;
import static com.hazelcast.client.config.SocketOptions.KILO_BYTE;

public class ClientConnectionManagerImpl implements ClientConnectionManager {

    private static final ILogger LOGGER = Logger.getLogger(ClientConnectionManagerImpl.class);

    private static final IOSelectorOutOfMemoryHandler OUT_OF_MEMORY_HANDLER = new IOSelectorOutOfMemoryHandler() {
        @Override
        public void handle(OutOfMemoryError error) {
            LOGGER.severe(error);
        }
    };

    private final int connectionTimeout;
    private final int heartBeatInterval;
    private final int heartBeatTimeout;

    private final ConcurrentMap<Address, Object> connectionLockMap = new ConcurrentHashMap<Address, Object>();

    private final AtomicInteger connectionIdGen = new AtomicInteger();
    private final HazelcastClientInstanceImpl client;
    private final SocketInterceptor socketInterceptor;
    private final SocketOptions socketOptions;
    private final IOSelector inSelector;
    private final IOSelector outSelector;

    private final SocketChannelWrapperFactory socketChannelWrapperFactory;
    private final ClientExecutionServiceImpl executionService;
    private final AddressTranslator addressTranslator;
    private final ConcurrentMap<Address, ClientConnection> connections
            = new ConcurrentHashMap<Address, ClientConnection>();

    private final Set<ConnectionListener> connectionListeners = new CopyOnWriteArraySet<ConnectionListener>();
    private final Set<ConnectionHeartbeatListener> heartbeatListeners =
            new CopyOnWriteArraySet<ConnectionHeartbeatListener>();

    private volatile boolean alive;

    public ClientConnectionManagerImpl(HazelcastClientInstanceImpl client,
                                       AddressTranslator addressTranslator) {
        this.client = client;
        this.addressTranslator = addressTranslator;
        final ClientConfig config = client.getClientConfig();
        final ClientNetworkConfig networkConfig = config.getNetworkConfig();

        final int connTimeout = networkConfig.getConnectionTimeout();
        connectionTimeout = connTimeout == 0 ? Integer.MAX_VALUE : connTimeout;

        final ClientProperties clientProperties = client.getClientProperties();
        int timeout = clientProperties.getHeartbeatTimeout().getInteger();
        this.heartBeatTimeout = timeout > 0 ? timeout : Integer.parseInt(PROP_HEARTBEAT_TIMEOUT_DEFAULT);

        int interval = clientProperties.getHeartbeatInterval().getInteger();
        heartBeatInterval = interval > 0 ? interval : Integer.parseInt(PROP_HEARTBEAT_INTERVAL_DEFAULT);

        executionService = (ClientExecutionServiceImpl) client.getClientExecutionService();

        inSelector = new InSelectorImpl(
                client.getThreadGroup(),
                client.getName() + ".ClientInSelector",
                Logger.getLogger(InSelectorImpl.class),
                OUT_OF_MEMORY_HANDLER);
        outSelector = new ClientOutSelectorImpl(
                client.getThreadGroup(),
                client.getName() + ".ClientOutSelector",
                Logger.getLogger(ClientOutSelectorImpl.class),
                OUT_OF_MEMORY_HANDLER);

        socketOptions = networkConfig.getSocketOptions();
        ClientExtension clientExtension = client.getClientExtension();
        socketChannelWrapperFactory = clientExtension.createSocketChannelWrapperFactory();
        socketInterceptor = initSocketInterceptor(networkConfig.getSocketInterceptorConfig());
    }


    private SocketInterceptor initSocketInterceptor(SocketInterceptorConfig sic) {
        if (sic != null && sic.isEnabled()) {
            ClientExtension clientExtension = client.getClientExtension();
            return clientExtension.createSocketInterceptor();
        }
        return null;
    }

    @Override
    public boolean isAlive() {
        return alive;
    }

    @Override
    public synchronized void start() {
        if (alive) {
            return;
        }
        alive = true;
        inSelector.start();
        outSelector.start();
        HeartBeat heartBeat = new HeartBeat();
        executionService.scheduleWithFixedDelay(heartBeat, heartBeatInterval, heartBeatInterval, TimeUnit.MILLISECONDS);
    }

    @Override
    public synchronized void shutdown() {
        if (!alive) {
            return;
        }
        alive = false;
        for (ClientConnection connection : connections.values()) {
            connection.close();
        }
        inSelector.shutdown();
        outSelector.shutdown();
        connectionLockMap.clear();
        connectionListeners.clear();
        heartbeatListeners.clear();
    }

    public ClientConnection getConnection(Address target) {
        return connections.get(target);
    }

    public ClientConnection getOrConnect(Address target, Authenticator authenticator) throws IOException {
        Address address = addressTranslator.translate(target);

        if (address == null) {
            throw new IOException("Address is required!");
        }

        ClientConnection connection = connections.get(target);
        if (connection == null) {
            final Object lock = getLock(target);
            synchronized (lock) {
                connection = connections.get(target);
                if (connection == null) {
                    connection = createSocketConnection(address);
                    authenticate(authenticator, connection);
                    connections.put(connection.getRemoteEndpoint(), connection);
                    fireConnectionAddedEvent(connection);
                }
            }
        }
        return connection;
    }

    private void authenticate(Authenticator authenticator, ClientConnection connection) throws IOException {
        try {
            authenticator.authenticate(connection);
        } catch (Throwable throwable) {
            connection.close(throwable);
            throw ExceptionUtil.rethrow(throwable, IOException.class);
        }
    }

    private void fireConnectionAddedEvent(ClientConnection connection) {
        for (ConnectionListener connectionListener : connectionListeners) {
            connectionListener.connectionAdded(connection);
        }
    }

    private ClientConnection createSocketConnection(final Address address) throws IOException {
        if (!alive) {
            throw new HazelcastException("ConnectionManager is not active!!!");
        }
        SocketChannel socketChannel = null;
        try {
            socketChannel = SocketChannel.open();
            Socket socket = socketChannel.socket();
            socket.setKeepAlive(socketOptions.isKeepAlive());
            socket.setTcpNoDelay(socketOptions.isTcpNoDelay());
            socket.setReuseAddress(socketOptions.isReuseAddress());
            if (socketOptions.getLingerSeconds() > 0) {
                socket.setSoLinger(true, socketOptions.getLingerSeconds());
            }
            int bufferSize = socketOptions.getBufferSize() * KILO_BYTE;
            if (bufferSize <= 0) {
                bufferSize = DEFAULT_BUFFER_SIZE_BYTE;
            }
            socket.setSendBufferSize(bufferSize);
            socket.setReceiveBufferSize(bufferSize);
            socketChannel.socket().connect(address.getInetSocketAddress(), connectionTimeout);
            SocketChannelWrapper socketChannelWrapper =
                    socketChannelWrapperFactory.wrapSocketChannel(socketChannel, true);
            final ClientConnection clientConnection = new ClientConnection(client, inSelector,
                    outSelector, connectionIdGen.incrementAndGet(), socketChannelWrapper);
            socketChannel.configureBlocking(true);
            if (socketInterceptor != null) {
                socketInterceptor.onConnect(socket);
            }
            socketChannel.configureBlocking(false);
            socket.setSoTimeout(0);
            clientConnection.getReadHandler().register();
            return clientConnection;
        } catch (Exception e) {
            if (socketChannel != null) {
                socketChannel.close();
            }
            throw ExceptionUtil.rethrow(e, IOException.class);
        }
    }

    @Override
    public void destroyConnection(final Connection connection) {
        Address endpoint = connection.getEndPoint();
        if (endpoint != null) {
            final ClientConnection conn = connections.remove(endpoint);
            if (conn == null) {
                return;
            }
            conn.close();
            for (ConnectionListener connectionListener : connectionListeners) {
                connectionListener.connectionRemoved(conn);
            }

        } else {
            ClientInvocationService invocationService = client.getInvocationService();
            invocationService.cleanConnectionResources((ClientConnection) connection);
        }
    }

    @Override
    public void handlePacket(Packet packet) {
        final ClientConnection conn = (ClientConnection) packet.getConn();
        conn.incrementPacketCount();
        if (packet.isHeaderSet(Packet.HEADER_EVENT)) {
            final ClientListenerServiceImpl listenerService = (ClientListenerServiceImpl) client.getListenerService();
            listenerService.handleEventPacket(packet);
        } else {
            ClientInvocationService invocationService = client.getInvocationService();
            invocationService.handlePacket(packet);
        }
    }

    private Object getLock(Address address) {
        Object lock = connectionLockMap.get(address);
        if (lock == null) {
            lock = new Object();
            Object current = connectionLockMap.putIfAbsent(address, lock);
            if (current != null) {
                lock = current;
            }
        }
        return lock;
    }

    class HeartBeat implements Runnable {

        @Override
        public void run() {
            if (!alive) {
                return;
            }
            final long now = Clock.currentTimeMillis();
            for (ClientConnection connection : connections.values()) {
                if (now - connection.lastReadTime() > heartBeatTimeout) {
                    if (connection.isHeartBeating()) {
                        connection.heartBeatingFailed();
                        fireHeartBeatStopped(connection);
                    }
                }
                if (now - connection.lastReadTime() > heartBeatInterval) {
                    final ClientPingRequest request = new ClientPingRequest();
                    new ClientInvocation(client, request, connection).invoke();
                } else {
                    if (!connection.isHeartBeating()) {
                        connection.heartBeatingSucceed();
                        fireHeartBeatStarted(connection);
                    }
                }
            }
        }

        private void fireHeartBeatStarted(ClientConnection connection) {
            for (ConnectionHeartbeatListener heartbeatListener : heartbeatListeners) {
                heartbeatListener.heartBeatStarted(connection);
            }
        }

        private void fireHeartBeatStopped(ClientConnection connection) {
            for (ConnectionHeartbeatListener heartbeatListener : heartbeatListeners) {
                heartbeatListener.heartBeatStopped(connection);
            }
        }

    }

    @Override
    public void addConnectionListener(ConnectionListener connectionListener) {
        connectionListeners.add(connectionListener);
    }

    @Override
    public void addConnectionHeartbeatListener(ConnectionHeartbeatListener connectionHeartbeatListener) {
        heartbeatListeners.add(connectionHeartbeatListener);
    }
}

<code block>


package com.hazelcast.client;

import com.hazelcast.test.TestEnvironment;
import com.hazelcast.test.annotation.ClientCompatibleTest;
import org.junit.BeforeClass;
import org.junit.Ignore;
import org.junit.experimental.categories.Categories;
import org.junit.runner.RunWith;
import org.junit.runners.Suite;



@Ignore
@RunWith(Categories.class)
@Categories.IncludeCategory(ClientCompatibleTest.class)
@Suite.SuiteClasses({})
public class ClientCompatibleTestsSuit {

    @BeforeClass
    public static void setUp() {
        System.setProperty(TestEnvironment.HAZELCAST_TEST_USE_NETWORK, "true");
        System.setProperty(TestEnvironment.HAZELCAST_TEST_USE_CLIENT, "true");

        System.setProperty("hazelcast.version.check.enabled", "false");
        System.setProperty("hazelcast.mancenter.enabled", "false");
        System.setProperty("hazelcast.wait.seconds.before.join", "1");
        System.setProperty("hazelcast.local.localAddress", "127.0.0.1");
        System.setProperty("java.net.preferIPv4Stack", "true");
    }
}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.impl.DefaultData;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashSet;
import java.util.List;
import java.util.Set;


public class MessageFlyweight {
    
    private static final long LONG_MASK = 0x00000000FFFFFFFFL;
    
    private static final int INT_MASK = 0x0000FFFF;
    
    private static final short SHORT_MASK = 0x00FF;

    protected ClientProtocolBuffer buffer;
    
    private int offset;
    
    private int index;


    public MessageFlyweight() {
        offset = 0;
    }

    public MessageFlyweight wrap(ClientProtocolBuffer buffer, int offset) {
        this.buffer = buffer;
        this.offset = offset;
        this.index = 0;
        return this;
    }

    public int index() {
        return index;
    }

    public MessageFlyweight index(int index) {
        this.index = index;
        return this;
    }

    public ClientProtocolBuffer buffer() {
        return buffer;
    }

    
    public MessageFlyweight set(boolean value) {
        buffer.putByte(index + offset, (byte) (value ? 1 : 0));
        index += Bits.BYTE_SIZE_IN_BYTES;
        return this;
    }

    public MessageFlyweight set(int value) {
        buffer.putInt(index + offset, value);
        index += Bits.INT_SIZE_IN_BYTES;
        return this;
    }

    public MessageFlyweight set(long value) {
        buffer.putLong(index + offset, value);
        index += Bits.LONG_SIZE_IN_BYTES;
        return this;
    }

    public MessageFlyweight set(String value) {
        index += buffer.putStringUtf8(index + offset, value);
        return this;
    }

    public MessageFlyweight set(Data data) {
        final byte[] bytes = data.toByteArray();
        set(bytes);
        return this;
    }

    public MessageFlyweight set(final byte[] value) {
        final int length = value.length;
        set(length);
        buffer.putBytes(index + offset, value);
        index += length;
        return this;
    }

    public MessageFlyweight set(final Collection<Data> value) {
        final int length = value.size();
        set(length);
        for (Data v : value) {
            set(v);
        }
        return this;
    }

    

    
    public boolean getBoolean() {
        byte result = buffer.getByte(index + offset);
        index += Bits.BYTE_SIZE_IN_BYTES;
        return result != 0;
    }

    public int getInt() {
        int result = buffer.getInt(index + offset);
        index += Bits.INT_SIZE_IN_BYTES;
        return result;
    }

    public long getLong() {
        long result = buffer.getLong(index + offset);
        index += Bits.LONG_SIZE_IN_BYTES;
        return result;
    }

    public String getStringUtf8() {
        final int length = buffer.getInt(index + offset);
        String result = buffer.getStringUtf8(index + offset, length);
        index += length + Bits.INT_SIZE_IN_BYTES;
        return result;
    }

    public byte[] getByteArray() {
        final int length = buffer.getInt(index + offset);
        index += Bits.INT_SIZE_IN_BYTES;
        byte[] result = new byte[length];
        buffer.getBytes(index + offset, result);
        index += length;
        return result;
    }

    public Data getData() {
        return new DefaultData(getByteArray());
    }

    public List<Data> getDataList() {
        final int length = buffer.getInt(index + offset);
        index += Bits.INT_SIZE_IN_BYTES;
        final List<Data> result = new ArrayList<Data>();
        for (int i = 0; i < length; i++) {
            result.add(getData());
        }
        return result;
    }

    public Set<Data> getDataSet() {
        final int length = buffer.getInt(index + offset);
        index += Bits.INT_SIZE_IN_BYTES;
        final Set<Data> result = new HashSet<Data>();
        for (int i = 0; i < length; i++) {
            result.add(getData());
        }
        return result;
    }

    

    protected int int32Get(int index) {
        return buffer.getInt(index + offset);
    }

    protected void int32Set(int index, int length) {
        buffer.putInt(index + offset, length);
    }

    protected short uint8Get(int index) {
        return (short) (buffer.getByte(index + offset) & SHORT_MASK);
    }

    protected void uint8Put(int index, short value) {
        buffer.putByte(index + offset, (byte) value);
    }

    protected int uint16Get(int index) {
        return buffer.getShort(index + offset) & INT_MASK;
    }

    protected void uint16Put(int index, int value) {
        buffer.putShort(index + offset, (short) value);
    }

    protected long uint32Get(int index) {
        return buffer.getInt(index + offset) & LONG_MASK;
    }

    protected void uint32Put(int index, long value) {
        buffer.putInt(index + offset, (int) value);
    }

}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;

public final class ParameterUtil {

    private static final int UTF8_MAX_BYTES_PER_CHAR = 4;

    private ParameterUtil() { }

    public static int calculateStringDataSize(String string) {
        return Bits.INT_SIZE_IN_BYTES + string.length() * UTF8_MAX_BYTES_PER_CHAR;
    }

    public static int calculateByteArrayDataSize(byte[] bytes) {
        return Bits.INT_SIZE_IN_BYTES + bytes.length;
    }

    public static int calculateDataSize(Data key) {
        return calculateByteArrayDataSize(key.toByteArray());
    }
}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;

import java.nio.ByteBuffer;
import java.nio.ByteOrder;


public class SafeBuffer implements ClientProtocolBuffer {

    private ByteBuffer byteBuffer;

    public SafeBuffer(byte[] buffer) {
        wrap(buffer);
    }

    @Override
    public void putLong(int index, long value) {
        byteBuffer.putLong(index, value);
    }

    @Override
    public void putInt(int index, int value) {
        byteBuffer.putInt(index, value);
    }

    @Override
    public void putShort(int index, short value) {
        byteBuffer.putShort(index, value);
    }

    @Override
    public void putByte(int index, byte value) {
        byteBuffer.put(index, value);
    }

    @Override
    public void putBytes(int index, byte[] src) {
        putBytes(index, src, 0, src.length);
    }

    @Override
    public void putBytes(int index, byte[] src, int offset, int length) {
        byteBuffer.position(index);
        byteBuffer.put(src, offset, length);
    }

    @Override
    public int putStringUtf8(int index, String value) {
        return putStringUtf8(index, value, Integer.MAX_VALUE);
    }

    @Override
    public int putStringUtf8(int index, String value, int maxEncodedSize) {
        final byte[] bytes = value.getBytes(Bits.UTF_8);
        if (bytes.length > maxEncodedSize) {
            throw new IllegalArgumentException("Encoded string larger than maximum size: " + maxEncodedSize);
        }

        putInt(index, bytes.length);
        putBytes(index + Bits.INT_SIZE_IN_BYTES, bytes);

        return Bits.INT_SIZE_IN_BYTES + bytes.length;
    }

    @Override
    public void wrap(byte[] buffer) {
        byteBuffer = ByteBuffer.wrap(buffer);
        byteBuffer.order(ByteOrder.LITTLE_ENDIAN);
    }

    @Override
    public byte[] byteArray() {
        return byteBuffer.array();
    }

    @Override
    public int capacity() {
        return byteBuffer.capacity();
    }

    @Override
    public long getLong(int index) {

        return byteBuffer.getLong(index);
    }

    @Override
    public int getInt(int index) {
        return byteBuffer.getInt(index);
    }

    @Override
    public short getShort(int index) {
        return byteBuffer.getShort(index);
    }

    @Override
    public byte getByte(int index) {
        return byteBuffer.get(index);
    }

    @Override
    public void getBytes(int index, byte[] dst) {
        getBytes(index, dst, 0, dst.length);
    }

    @Override
    public void getBytes(int index, byte[] dst, int offset, int length) {
        byteBuffer.position(index);
        byteBuffer.get(dst, offset, length);
    }

    @Override
    public String getStringUtf8(int offset, int length) {
        final byte[] stringInBytes = new byte[length];
        getBytes(offset + Bits.INT_SIZE_IN_BYTES, stringInBytes);

        return new String(stringInBytes, Bits.UTF_8);
    }

}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.util.QuickMath;

import java.util.Arrays;


public class BufferBuilder {
    
    public static final int INITIAL_CAPACITY = 4096;

    private static final String PROP_HAZELCAST_PROTOCOL_UNSAFE = "hazelcast.protocol.unsafe.enabled";
    private static final boolean USE_UNSAFE = Boolean.getBoolean(PROP_HAZELCAST_PROTOCOL_UNSAFE);

    private final ClientProtocolBuffer protocolBuffer;

    private int position;
    private int capacity;

    
    public BufferBuilder() {
        this(INITIAL_CAPACITY);
    }

    
    private BufferBuilder(int initialCapacity) {
        capacity = QuickMath.nextPowerOfTwo(initialCapacity);
        if (USE_UNSAFE) {
            protocolBuffer = new UnsafeBuffer(new byte[capacity]);
        } else {
            protocolBuffer = new SafeBuffer(new byte[capacity]);

        }
    }

    
    public int capacity() {
        return capacity;
    }

    
    public int position() {
        return position;
    }

    
    public ClientProtocolBuffer buffer() {
        return protocolBuffer;
    }

    
    public BufferBuilder append(ClientProtocolBuffer srcBuffer, int srcOffset, int length) {
        ensureCapacity(length);

        srcBuffer.getBytes(srcOffset, protocolBuffer.byteArray(), position, length);
        position += length;

        return this;
    }

    private void ensureCapacity(int additionalCapacity) {
        int requiredCapacity = position + additionalCapacity;

        if (requiredCapacity < 0) {
            String s = String.format("Insufficient capacity: position=%d additional=%d", position, additionalCapacity);
            throw new IllegalStateException(s);
        }

        if (requiredCapacity > capacity) {
            int newCapacity = QuickMath.nextPowerOfTwo(requiredCapacity);
            byte[] newBuffer = Arrays.copyOf(protocolBuffer.byteArray(), newCapacity);

            capacity = newCapacity;
            protocolBuffer.wrap(newBuffer);
        }
    }
}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.util.collection.Int2ObjectHashMap;
import com.hazelcast.client.impl.protocol.ClientMessage;

import java.nio.ByteBuffer;

import static com.hazelcast.client.impl.protocol.ClientMessage.BEGIN_AND_END_FLAGS;
import static com.hazelcast.client.impl.protocol.ClientMessage.BEGIN_FLAG;
import static com.hazelcast.client.impl.protocol.ClientMessage.END_FLAG;


public class ClientMessageBuilder {

    private final Int2ObjectHashMap<BufferBuilder> builderBySessionIdMap = new Int2ObjectHashMap<BufferBuilder>();

    private final MessageHandler delegate;
    private ClientMessage message = ClientMessage.create();

    public ClientMessageBuilder(MessageHandler delegate) {
        this.delegate = delegate;
    }

    public void onData(final ByteBuffer buffer) {
        while (buffer.hasRemaining()) {
            final boolean complete = message.readFrom(buffer);
            if (!complete) {
                return;
            }

            
            if (message.isFlagSet(BEGIN_AND_END_FLAGS)) {
                
                handleMessage(message);
                message = ClientMessage.create();
                continue;
            }

            
            if (message.isFlagSet(BEGIN_FLAG)) {
                final BufferBuilder builder = new BufferBuilder();
                builderBySessionIdMap.put(message.getCorrelationId(), builder);
                builder.append(message.buffer(), 0, message.getFrameLength());
            } else {
                final BufferBuilder builder = builderBySessionIdMap.get(message.getCorrelationId());
                if (builder.position() == 0) {
                    throw new IllegalStateException();
                }

                builder.append(message.buffer(), message.getDataOffset(), message.getFrameLength() - message.getDataOffset());

                if (message.isFlagSet(END_FLAG)) {
                    final int msgLength = builder.position();
                    ClientMessage cm = ClientMessage.createForDecode(builder.buffer(), 0);
                    cm.setFrameLength(msgLength);
                    
                    handleMessage(cm);
                    builderBySessionIdMap.remove(message.getCorrelationId());

                }
            }

            message = ClientMessage.create();
        }
    }

    private void handleMessage(ClientMessage message) {
        message.index(message.getDataOffset());
        delegate.handleMessage(message);
    }

    
    public interface MessageHandler {

        
        void handleMessage(ClientMessage message);
    }


}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;
import com.hazelcast.nio.UnsafeHelper;
import sun.misc.Unsafe;

import java.nio.ByteOrder;


@edu.umd.cs.findbugs.annotations.SuppressWarnings({ "EI_EXPOSE_REP", "EI_EXPOSE_REP2" })
public class UnsafeBuffer implements ClientProtocolBuffer {
    private static final String DISABLE_BOUNDS_CHECKS_PROP_NAME = "hazelcast.disable.bounds.checks";
    private static final boolean SHOULD_BOUNDS_CHECK = !Boolean.getBoolean(DISABLE_BOUNDS_CHECKS_PROP_NAME);

    private static final ByteOrder NATIVE_BYTE_ORDER = ByteOrder.nativeOrder();
    private static final ByteOrder PROTOCOL_BYTE_ORDER = ByteOrder.LITTLE_ENDIAN;
    private static final Unsafe UNSAFE = UnsafeHelper.UNSAFE;
    private static final long ARRAY_BASE_OFFSET = UNSAFE.arrayBaseOffset(byte[].class);

    private byte[] byteArray;
    private long addressOffset;

    private int capacity;

    
    public UnsafeBuffer(final byte[] buffer) {
        wrap(buffer);
    }

    @Override
    public void wrap(final byte[] buffer) {
        addressOffset = ARRAY_BASE_OFFSET;
        capacity = buffer.length;
        byteArray = buffer;
    }

    @Override
    public byte[] byteArray() {
        return byteArray;
    }

    @Override
    public int capacity() {
        return capacity;
    }

    

    @Override
    public long getLong(final int index) {
        boundsCheck(index, Bits.LONG_SIZE_IN_BYTES);

        long bits = UNSAFE.getLong(byteArray, addressOffset + index);
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Long.reverseBytes(bits);
        }

        return bits;
    }

    @Override
    public void putLong(final int index, final long value) {
        boundsCheck(index, Bits.LONG_SIZE_IN_BYTES);

        long bits = value;
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Long.reverseBytes(bits);
        }

        UNSAFE.putLong(byteArray, addressOffset + index, bits);
    }

    

    @Override
    public int getInt(final int index) {
        boundsCheck(index, Bits.INT_SIZE_IN_BYTES);

        int bits = UNSAFE.getInt(byteArray, addressOffset + index);
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Integer.reverseBytes(bits);
        }

        return bits;
    }

    @Override
    public void putInt(final int index, final int value) {
        boundsCheck(index, Bits.INT_SIZE_IN_BYTES);

        int bits = value;
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Integer.reverseBytes(bits);
        }

        UNSAFE.putInt(byteArray, addressOffset + index, bits);
    }


    

    @Override
    public short getShort(final int index) {
        boundsCheck(index, Bits.SHORT_SIZE_IN_BYTES);

        short bits = UNSAFE.getShort(byteArray, addressOffset + index);
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Short.reverseBytes(bits);
        }

        return bits;
    }

    @Override
    public void putShort(final int index, final short value) {
        boundsCheck(index, Bits.SHORT_SIZE_IN_BYTES);

        short bits = value;
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Short.reverseBytes(bits);
        }

        UNSAFE.putShort(byteArray, addressOffset + index, bits);
    }

    @Override
    public byte getByte(final int index) {
        boundsCheck(index, Bits.BYTE_SIZE_IN_BYTES);

        return UNSAFE.getByte(byteArray, addressOffset + index);
    }

    @Override
    public void putByte(final int index, final byte value) {
        boundsCheck(index, Bits.BYTE_SIZE_IN_BYTES);

        UNSAFE.putByte(byteArray, addressOffset + index, value);
    }

    @Override
    public void getBytes(final int index, final byte[] dst) {
        getBytes(index, dst, 0, dst.length);
    }

    @Override
    public void getBytes(final int index, final byte[] dst, final int offset, final int length) {
        boundsCheck(index, length);
        boundsCheck(dst, offset, length);

        UNSAFE.copyMemory(byteArray, addressOffset + index, dst, ARRAY_BASE_OFFSET + offset, length);
    }

    @Override
    public void putBytes(final int index, final byte[] src) {
        putBytes(index, src, 0, src.length);
    }

    @Override
    public void putBytes(final int index, final byte[] src, final int offset, final int length) {
        boundsCheck(index, length);
        boundsCheck(src, offset, length);

        UNSAFE.copyMemory(src, ARRAY_BASE_OFFSET + offset, byteArray, addressOffset + index, length);
    }

    @Override
    public String getStringUtf8(final int offset, final int length) {
        final byte[] stringInBytes = new byte[length];
        getBytes(offset + Bits.INT_SIZE_IN_BYTES, stringInBytes);

        return new String(stringInBytes, Bits.UTF_8);
    }

    @Override
    public int putStringUtf8(final int index, final String value) {
        return putStringUtf8(index, value, Integer.MAX_VALUE);
    }

    @Override
    public int putStringUtf8(final int index, final String value, final int maxEncodedSize) {
        final byte[] bytes = value.getBytes(Bits.UTF_8);
        if (bytes.length > maxEncodedSize) {
            throw new IllegalArgumentException("Encoded string larger than maximum size: " + maxEncodedSize);
        }

        putInt(index, bytes.length);
        putBytes(index + Bits.INT_SIZE_IN_BYTES, bytes);

        return Bits.INT_SIZE_IN_BYTES + bytes.length;
    }

    

    private void boundsCheck(final int index, final int length) {
        if (SHOULD_BOUNDS_CHECK) {
            if (index < 0 || length < 0 || (index + length) > capacity) {
                throw new IndexOutOfBoundsException(String.format("index=%d, length=%d, capacity=%d", index, length, capacity));
            }
        }
    }

    private static void boundsCheck(final byte[] buffer, final int index, final int length) {
        if (SHOULD_BOUNDS_CHECK) {
            final int capacity = buffer.length;
            if (index < 0 || length < 0 || (index + length) > capacity) {
                throw new IndexOutOfBoundsException(String.format("index=%d, length=%d, capacity=%d", index, length, capacity));
            }
        }
    }
}

<code block>


package com.hazelcast.util;


public final class QuickMath {

    private QuickMath() {
    }

    
    public static boolean isPowerOfTwo(long x) {
        return (x & (x - 1)) == 0;
    }

    
    public static int modPowerOfTwo(int a, int b) {
        return a & (b - 1);
    }

    
    public static long modPowerOfTwo(long a, int b) {
        return a & (b - 1);
    }

    
    public static int nextPowerOfTwo(final int value) {
        return 1 << (32 - Integer.numberOfLeadingZeros(value - 1));
    }

    
    public static long nextPowerOfTwo(final long value) {
        return 1L << (64 - Long.numberOfLeadingZeros(value - 1));
    }

    
    public static int log2(int value) {
        return 31 - Integer.numberOfLeadingZeros(value);
    }

    
    public static int log2(long value) {
        return 63 - Long.numberOfLeadingZeros(value);
    }

    
    public static int divideByAndCeilToInt(double d, int k) {
        return (int) Math.ceil(d / k);
    }

    
    public static long divideByAndCeilToLong(double d, int k) {
        return (long) Math.ceil(d / k);
    }

    
    public static int divideByAndRoundToInt(double d, int k) {
        return (int) Math.rint(d / k);
    }

    
    public static long divideByAndRoundToLong(double d, int k) {
        return (long) Math.rint(d / k);
    }

    
    public static int normalize(int value, int factor) {
        return divideByAndCeilToInt(value, factor) * factor;
    }

    
    public static long normalize(long value, int factor) {
        return divideByAndCeilToLong(value, factor) * factor;
    }

    public static String bytesToHex(byte[] in) {
        final char[] hexArray = "0123456789abcdef".toCharArray();

        char[] hexChars = new char[in.length * 2];
        for (int j = 0; j < in.length; j++) {
            int v = in[j] & 0xff;
            hexChars[j * 2] = hexArray[v >>> 4];
            hexChars[j * 2 + 1] = hexArray[v & 0xf];
        }
        return new String(hexChars);
    }

    
    public static int compareIntegers(int i1, int i2) {
        if (i1 > i2) {
            return +1;
        } else if (i2 > i1) {
            return -1;
        } else {
            return 0;
        }
    }

    
    public static int compareLongs(long l1, long l2) {
        if (l1 > l2) {
            return +1;
        } else if (l2 > l1) {
            return -1;
        } else {
            return 0;
        }
    }
}

<code block>


package com.hazelcast.util;

import static com.hazelcast.partition.InternalPartition.MAX_BACKUP_COUNT;
import static java.lang.String.format;


public final class Preconditions {

    private Preconditions() {
    }


    
    public static String checkHasText(String argument, String errorMessage) {
        if (argument == null || argument.isEmpty()) {
            throw new IllegalArgumentException(errorMessage);
        }

        return argument;
    }

    
    public static <T> T checkNotNull(T argument, String errorMessage) {
        if (argument == null) {
            throw new NullPointerException(errorMessage);
        }
        return argument;
    }

    
    public static <T> T checkNotNull(T argument) {
        if (argument == null) {
            throw new NullPointerException();
        }
        return argument;
    }

    
    public static <E> E isNotNull(E argument, String argName) {
        if (argument == null) {
            throw new IllegalArgumentException(format("argument '%s' can't be null", argName));
        }

        return argument;
    }

    
    public static long checkNotNegative(long value, String errorMessage) {
        if (value < 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static int checkNotNegative(int value, String errorMessage) {
        if (value < 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static long checkNegative(long value, String errorMessage) {
        if (value >= 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static long checkPositive(long value, String errorMessage) {
        if (value <= 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static int checkPositive(int value, String errorMessage) {
        if (value <= 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static int checkBackupCount(int newBackupCount, int currentAsyncBackupCount) {
        if (newBackupCount < 0) {
            throw new IllegalArgumentException("backup-count can't be smaller than 0");
        }

        if (currentAsyncBackupCount < 0) {
            throw new IllegalArgumentException("async-backup-count can't be smaller than 0");
        }

        if (newBackupCount > MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("backup-count can't be larger than than " + MAX_BACKUP_COUNT);
        }

        if (newBackupCount + currentAsyncBackupCount > MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("the sum of backup-count and async-backup-count can't be larger than than "
                    + MAX_BACKUP_COUNT);
        }

        return newBackupCount;
    }

    
    public static int checkAsyncBackupCount(int currentBackupCount, int newAsyncBackupCount) {
        if (currentBackupCount < 0) {
            throw new IllegalArgumentException("backup-count can't be smaller than 0");
        }

        if (newAsyncBackupCount < 0) {
            throw new IllegalArgumentException("async-backup-count can't be smaller than 0");
        }

        if (newAsyncBackupCount > MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("async-backup-count can't be larger than than " + MAX_BACKUP_COUNT);
        }

        if (currentBackupCount + newAsyncBackupCount > MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("the sum of backup-count and async-backup-count can't be larger than than "
                    + MAX_BACKUP_COUNT);
        }

        return newAsyncBackupCount;
    }

    
    public static <E> E checkInstanceOf(Class type, E object, String errorMessage) {
        isNotNull(type, "type");
        if (!type.isInstance(object)) {
            throw new IllegalArgumentException(errorMessage);
        }
        return object;
    }

    
    public static <E> E checkNotInstanceOf(Class type, E object, String errorMessage) {
        isNotNull(type, "type");
        if (type.isInstance(object)) {
            throw new IllegalArgumentException(errorMessage);
        }
        return object;
    }

    
    public static void checkFalse(boolean expression, String errorMessage) {
        if (expression) {
            throw new IllegalArgumentException(errorMessage);
        }
    }

    
    public static void checkTrue(boolean expression, String errorMessage) {
        if (!expression) {
            throw new IllegalArgumentException(errorMessage);
        }
    }
}


<code block>


package com.hazelcast.util.collection;

import com.hazelcast.util.QuickMath;
import com.hazelcast.util.function.BiConsumer;
import com.hazelcast.util.function.LongLongConsumer;
import com.hazelcast.util.function.Predicate;
import com.hazelcast.util.function.Supplier;

import java.util.Arrays;
import java.util.Collection;
import java.util.Iterator;
import java.util.Map;
import java.util.Set;


public class Long2LongHashMap implements Map<Long, Long> {
    private final Set<Long> keySet;
    private final LongIterator valueIterator = new LongIterator(1);
    private final Collection<Long> values;
    private final Set<Entry<Long, Long>> entrySet;

    private final double loadFactor;
    private final long missingValue;

    private long[] entries;
    private int capacity;
    private int mask;
    private int resizeThreshold;
    private int size;

    public Long2LongHashMap(final long missingValue) {
        this(16, 0.6, missingValue);
    }

    @SuppressWarnings("unchecked")
    public Long2LongHashMap(final int initialCapacity, final double loadFactor, final long missingValue) {
        this.loadFactor = loadFactor;
        this.missingValue = missingValue;
        capacity(QuickMath.nextPowerOfTwo(initialCapacity));
        final LongIterator keyIterator = new LongIterator(0);
        keySet = new MapDelegatingSet<Long>(this, new IteratorSupplier(keyIterator), new Predicate() {
            @Override public boolean test(Object value) {
                return containsValue(value);
            }
        });
        values = new MapDelegatingSet<Long>(this, new Supplier<Iterator<Long>>() {
            @Override public Iterator<Long> get() {
                return valueIterator.reset();
            }
        }, new Predicate() {
            @Override
            public boolean test(Object key) {
                return containsKey(key);
            }
        });
        final EntryIterator entryIterator = new EntryIterator();
        entrySet = new MapDelegatingSet<Entry<Long, Long>>(this, new EntryIteratorSupplier(entryIterator), new
                Predicate() {
            @Override
            public boolean test(Object e) {
                return Long2LongHashMap.this.containsKey(((Entry<Long, Long>) e).getKey());
            }
        });
    }

    
    public int size() {
        return size;
    }

    
    public boolean isEmpty() {
        return size() == 0;
    }

    public long get(final long key) {
        final long[] entries = this.entries;
        int index = hash(key);
        long candidateKey;
        while ((candidateKey = entries[index]) != missingValue) {
            if (candidateKey == key) {
                return entries[index + 1];
            }
            index = next(index);
        }
        return missingValue;
    }

    public long put(final long key, final long value) {
        long oldValue = missingValue;
        int index = hash(key);
        long candidateKey;
        while ((candidateKey = entries[index]) != missingValue) {
            if (candidateKey == key) {
                oldValue = entries[index + 1];
                break;
            }
            index = next(index);
        }
        if (oldValue == missingValue) {
            ++size;
            entries[index] = key;
        }
        entries[index + 1] = value;
        checkResize();
        return oldValue;
    }

    private void checkResize() {
        if (size > resizeThreshold) {
            final int newCapacity = capacity << 1;
            if (newCapacity < 0) {
                throw new IllegalStateException("Max capacity reached at size=" + size);
            }
            rehash(newCapacity);
        }
    }

    private void rehash(final int newCapacity) {
        final long[] oldEntries = entries;
        capacity(newCapacity);
        for (int i = 0; i < oldEntries.length; i += 2) {
            final long key = oldEntries[i];
            if (key != missingValue) {
                put(key, oldEntries[i + 1]);
            }
        }
    }

    private int hash(final long key) {
        int hash = (int) key ^ (int) (key >>> 32);
        hash = (hash << 1) - (hash << 8);
        return hash & mask;
    }

    
    public void longForEach(final LongLongConsumer consumer) {
        final long[] entries = this.entries;
        for (int i = 0; i < entries.length; i += 2) {
            final long key = entries[i];
            if (key != missingValue) {
                consumer.accept(entries[i], entries[i + 1]);
            }
        }
    }

    
    public boolean containsKey(final long key) {
        return get(key) != missingValue;
    }

    public boolean containsValue(final long value) {
        final long[] entries = this.entries;
        for (int i = 1; i < entries.length; i += 2) {
            final long entryValue = entries[i];
            if (entryValue == value) {
                return true;
            }
        }
        return false;
    }

    
    public void clear() {
        Arrays.fill(entries, missingValue);
        size = 0;
    }

    

    
    public Long get(final Object key) {
        return get((long) (Long) key);
    }

    
    public Long put(final Long key, final Long value) {
        return put(key.longValue(), value.longValue());
    }

    
    public void forEach(final BiConsumer<? super Long, ? super Long> action) {
        longForEach(new UnboxingBiConsumer(action));
    }

    
    public boolean containsKey(final Object key) {
        return containsKey((long) (Long) key);
    }

    
    public boolean containsValue(final Object value) {
        return containsValue((long) (Long) value);
    }

    
    public void putAll(final Map<? extends Long, ? extends Long> map) {
        for (final Entry<? extends Long, ? extends Long> entry : map.entrySet()) {
            put(entry.getKey(), entry.getValue());
        }
    }

    
    public Set<Long> keySet() {
        return keySet;
    }

    
    public Collection<Long> values() {
        return values;
    }

    
    public Set<Entry<Long, Long>> entrySet() {
        return entrySet;
    }

    
    public Long remove(final Object key) {
        return remove((long) (Long) key);
    }

    public long remove(final long key) {
        final long[] entries = this.entries;
        int index = hash(key);
        long candidateKey;
        while ((candidateKey = entries[index]) != missingValue) {
            if (candidateKey == key) {
                final int valueIndex = index + 1;
                final long oldValue = entries[valueIndex];
                entries[index] = missingValue;
                entries[valueIndex] = missingValue;
                size--;
                compactChain(index);
                return oldValue;
            }
            index = next(index);
        }
        return missingValue;
    }

    private void compactChain(int deleteIndex) {
        final long[] entries = this.entries;
        int index = deleteIndex;
        while (true) {
            index = next(index);
            if (entries[index] == missingValue) {
                return;
            }
            final int hash = hash(entries[index]);
            if ((index < hash && (hash <= deleteIndex || deleteIndex <= index))
                    || (hash <= deleteIndex && deleteIndex <= index)) {
                entries[deleteIndex] = entries[index];
                entries[deleteIndex + 1] = entries[index + 1];
                entries[index] = missingValue;
                entries[index + 1] = missingValue;
                deleteIndex = index;
            }
        }
    }

    public long minValue() {
        long min = Long.MAX_VALUE;
        final LongIterator iterator = valueIterator.reset();
        while (iterator.hasNext()) {
            min = Math.min(min, iterator.nextValue());
        }
        return min;
    }

    private static class IteratorSupplier implements Supplier<Iterator<Long>> {
        private final LongIterator keyIterator;

        public IteratorSupplier(LongIterator keyIterator) {
            this.keyIterator = keyIterator;
        }

        @Override
        public Iterator<Long> get() {
            return keyIterator.reset();
        }
    }

    private static class EntryIteratorSupplier implements Supplier<Iterator<Entry<Long, Long>>> {
        private final EntryIterator entryIterator;

        public EntryIteratorSupplier(EntryIterator entryIterator) {
            this.entryIterator = entryIterator;
        }

        @Override
        public Iterator<Entry<Long, Long>> get() {
            return entryIterator.reset();
        }
    }

    private static class UnboxingBiConsumer implements LongLongConsumer {
        private final BiConsumer<? super Long, ? super Long> action;

        public UnboxingBiConsumer(BiConsumer<? super Long, ? super Long> action) {
            this.action = action;
        }

        @Override
        public void accept(long t, long u) {
            action.accept(t, u);
        }
    }

    

    private abstract class AbstractIterator {
        protected final int startIndex;

        protected int index;

        protected AbstractIterator(final int startIndex) {
            this.startIndex = startIndex;
            index = startIndex;
        }

        public boolean hasNext() {
            while (entries[index] == missingValue) {
                nextIndex();
                if (index == startIndex) {
                    return false;
                }
            }
            return true;
        }

        public void remove() {
            throw new UnsupportedOperationException("remove");
        }

        protected void nextIndex() {
            index = next(index);
        }
    }

    private final class LongIterator extends AbstractIterator implements Iterator<Long> {
        private LongIterator(final int startIndex) {
            super(startIndex);
        }

        private LongIterator reset() {
            index = startIndex;
            return this;
        }

        public Long next() {
            return nextValue();
        }

        public long nextValue() {
            final long entry = entries[index];
            nextIndex();
            return entry;
        }
    }

    private final class EntryIterator extends AbstractIterator implements Iterator<Entry<Long, Long>>, Entry<Long,
            Long> {
        private long key;
        private long value;

        private EntryIterator() {
            super(0);
        }

        private EntryIterator reset() {
            index = startIndex;
            return this;
        }

        public Long getKey() {
            return key;
        }

        public Long getValue() {
            return value;
        }

        public Long setValue(final Long value) {
            throw new UnsupportedOperationException();
        }

        public Entry<Long, Long> next() {
            key = entries[index];
            value = entries[index + 1];
            nextIndex();
            return this;
        }
    }

    private int next(final int index) {
        return (index + 2) & mask;
    }

    private void capacity(final int newCapacity) {
        capacity = newCapacity;
        resizeThreshold = (int) (newCapacity * loadFactor);
        mask = (newCapacity * 2) - 1;
        entries = new long[newCapacity * 2];
        Arrays.fill(entries, missingValue);
    }
}

<code block>



package com.hazelcast.util.collection;

<code block>


package com.hazelcast.util.collection;


public final class Hashing {
    private Hashing() { }

    public static int intHash(final int value, final int mask) {
        final int hash = (value << 1) - (value << 8);
        return hash & mask;
    }

    public static int longHash(final long value, final int mask) {
        int hash = (int) value ^ (int) (value >>> 32);
        hash = (hash << 1) - (hash << 8);
        return hash & mask;
    }

}

<code block>


package com.hazelcast.util.collection;

import com.hazelcast.util.function.Predicate;
import com.hazelcast.util.function.Supplier;

import java.util.AbstractSet;
import java.util.Iterator;
import java.util.Map;


public final class MapDelegatingSet<V> extends AbstractSet<V> {
    private final Map<?, ?> delegate;
    private final Supplier<Iterator<V>> iterator;
    private final Predicate contains;

    public MapDelegatingSet(final Map<?, ?> delegate, final Supplier<Iterator<V>> iterator, final Predicate contains) {
        this.delegate = delegate;
        this.iterator = iterator;
        this.contains = contains;
    }

    
    public int size() {
        return delegate.size();
    }

    
    public boolean isEmpty() {
        return delegate.isEmpty();
    }

    
    @SuppressWarnings("unchecked")
    public boolean contains(final Object o) {
        return contains.test(o);
    }

    
    public Iterator<V> iterator() {
        return iterator.get();
    }

    
    public void clear() {
        delegate.clear();
    }
}

<code block>


package com.hazelcast.util.collection;

import java.util.Iterator;


public class IntIterator implements Iterator<Integer> {
    private final int missingValue;
    private final int[] values;

    private int position;

    
    public IntIterator(final int missingValue, final int[] values) {
        this.missingValue = missingValue;
        this.values = values;
    }

    public boolean hasNext() {
        final int[] values = this.values;
        while (position < values.length) {
            if (values[position] != missingValue) {
                return true;
            }

            position++;
        }

        return false;
    }

    public Integer next() {
        return nextValue();
    }

    public void remove() {
        throw new UnsupportedOperationException("remove");
    }

    
    public int nextValue() {
        final int value = values[position];
        position++;
        return value;
    }

    void reset() {
        position = 0;
    }
}

<code block>


package com.hazelcast.util.collection;

import com.hazelcast.util.QuickMath;
import com.hazelcast.util.function.LongFunction;

import java.util.AbstractCollection;
import java.util.AbstractSet;
import java.util.Arrays;
import java.util.Collection;
import java.util.Iterator;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Set;

import static com.hazelcast.util.Preconditions.checkNotNull;


public class Long2ObjectHashMap<V> implements Map<Long, V> {
    private final double loadFactor;
    private int resizeThreshold;
    private int capacity;
    private int mask;
    private int size;

    private long[] keys;
    private Object[] values;

    
    private final ValueCollection<V> valueCollection = new ValueCollection<V>();
    private final KeySet keySet = new KeySet();
    private final EntrySet<V> entrySet = new EntrySet<V>();

    public Long2ObjectHashMap() {
        this(8, 0.6);
    }

    
    public Long2ObjectHashMap(final int initialCapacity, final double loadFactor) {
        this.loadFactor = loadFactor;
        capacity = QuickMath.nextPowerOfTwo(initialCapacity);
        mask = capacity - 1;
        resizeThreshold = (int) (capacity * loadFactor);

        keys = new long[capacity];
        values = new Object[capacity];
    }

    
    public double loadFactor() {
        return loadFactor;
    }

    
    public int capacity() {
        return capacity;
    }

    
    public int resizeThreshold() {
        return resizeThreshold;
    }

    
    public int size() {
        return size;
    }

    
    public boolean isEmpty() {
        return 0 == size;
    }

    
    public boolean containsKey(final Object key) {
        checkNotNull(key, "Null keys are not permitted");
        return containsKey(((Long) key).longValue());
    }

    
    public boolean containsKey(final long key) {
        int index = hash(key);
        while (null != values[index]) {
            if (key == keys[index]) {
                return true;
            }
            index = ++index & mask;
        }
        return false;
    }

    
    public boolean containsValue(final Object value) {
        checkNotNull(value, "Null values are not permitted");
        for (final Object v : values) {
            if (null != v && value.equals(v)) {
                return true;
            }
        }
        return false;
    }

    
    public V get(final Object key) {
        return get(((Long) key).longValue());
    }

    
    @SuppressWarnings("unchecked")
    public V get(final long key) {
        int index = hash(key);
        Object value;
        while (null != (value = values[index])) {
            if (key == keys[index]) {
                return (V) value;
            }
            index = ++index & mask;
        }
        return null;
    }

    
    public V computeIfAbsent(final long key, final LongFunction<? extends V> mappingFunction) {
        checkNotNull(mappingFunction, "mappingFunction cannot be null");
        V value = get(key);
        if (value == null) {
            value = mappingFunction.apply(key);
            if (value != null) {
                put(key, value);
            }
        }
        return value;
    }

    
    public V put(final Long key, final V value) {
        return put(key.longValue(), value);
    }

    
    @SuppressWarnings("unchecked")
    public V put(final long key, final V value) {
        checkNotNull(value, "Value cannot be null");
        V oldValue = null;
        int index = hash(key);
        while (null != values[index]) {
            if (key == keys[index]) {
                oldValue = (V) values[index];
                break;
            }
            index = ++index & mask;
        }
        if (null == oldValue) {
            ++size;
            keys[index] = key;
        }
        values[index] = value;
        if (size > resizeThreshold) {
            increaseCapacity();
        }
        return oldValue;
    }

    
    public V remove(final Object key) {
        return remove(((Long) key).longValue());
    }

    
    @SuppressWarnings("unchecked")
    public V remove(final long key) {
        int index = hash(key);
        Object value;
        while (null != (value = values[index])) {
            if (key == keys[index]) {
                values[index] = null;
                --size;
                compactChain(index);
                return (V) value;
            }
            index = ++index & mask;
        }
        return null;
    }

    
    public void clear() {
        size = 0;
        Arrays.fill(values, null);
    }

    
    public void compact() {
        final int idealCapacity = (int) Math.round(size() * (1.0d / loadFactor));
        rehash(QuickMath.nextPowerOfTwo(idealCapacity));
    }

    
    public void putAll(final Map<? extends Long, ? extends V> map) {
        for (final Entry<? extends Long, ? extends V> entry : map.entrySet()) {
            put(entry.getKey(), entry.getValue());
        }
    }

    
    public KeySet keySet() {
        return keySet;
    }

    
    public Collection<V> values() {
        return valueCollection;
    }

    
    public Set<Entry<Long, V>> entrySet() {
        return entrySet;
    }

    
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append('{');
        for (final Map.Entry<Long, V> entry : entrySet()) {
            sb.append(entry.getKey().longValue());
            sb.append('=');
            sb.append(entry.getValue());
            sb.append(", ");
        }
        if (sb.length() > 1) {
            sb.setLength(sb.length() - 2);
        }
        sb.append('}');
        return sb.toString();
    }

    private void increaseCapacity() {
        final int newCapacity = capacity << 1;
        if (newCapacity < 0) {
            throw new IllegalStateException("Max capacity reached at size=" + size);
        }
        rehash(newCapacity);
    }

    private void rehash(final int newCapacity) {
        if (1 != Integer.bitCount(newCapacity)) {
            throw new IllegalStateException("New capacity must be a power of two");
        }
        capacity = newCapacity;
        mask = newCapacity - 1;
        resizeThreshold = (int) (newCapacity * loadFactor);
        final long[] tempKeys = new long[capacity];
        final Object[] tempValues = new Object[capacity];
        for (int i = 0, size = values.length; i < size; i++) {
            final Object value = values[i];
            if (null != value) {
                final long key = keys[i];
                int newHash = hash(key);
                while (null != tempValues[newHash]) {
                    newHash = ++newHash & mask;
                }
                tempKeys[newHash] = key;
                tempValues[newHash] = value;
            }
        }
        keys = tempKeys;
        values = tempValues;
    }

    private void compactChain(int deleteIndex) {
        int index = deleteIndex;
        while (true) {
            index = ++index & mask;
            if (null == values[index]) {
                return;
            }
            final int hash = hash(keys[index]);
            if ((index < hash && (hash <= deleteIndex || deleteIndex <= index))
                    || (hash <= deleteIndex && deleteIndex <= index)) {
                keys[deleteIndex] = keys[index];
                values[deleteIndex] = values[index];
                values[index] = null;
                deleteIndex = index;
            }
        }
    }

    private int hash(final long key) {
        int hash = (int) key ^ (int) (key >>> 32);
        hash = (hash << 1) - (hash << 8);
        return hash & mask;
    }

    
    
    

    public class KeySet extends AbstractSet<Long> {
        public int size() {
            return Long2ObjectHashMap.this.size();
        }

        public boolean isEmpty() {
            return Long2ObjectHashMap.this.isEmpty();
        }

        public boolean contains(final Object o) {
            return Long2ObjectHashMap.this.containsKey(o);
        }

        public boolean contains(final long key) {
            return Long2ObjectHashMap.this.containsKey(key);
        }

        public KeyIterator iterator() {
            return new KeyIterator();
        }

        public boolean remove(final Object o) {
            return null != Long2ObjectHashMap.this.remove(o);
        }

        public boolean remove(final long key) {
            return null != Long2ObjectHashMap.this.remove(key);
        }

        public void clear() {
            Long2ObjectHashMap.this.clear();
        }
    }

    private class ValueCollection<V> extends AbstractCollection<V> {
        public int size() {
            return Long2ObjectHashMap.this.size();
        }

        public boolean isEmpty() {
            return Long2ObjectHashMap.this.isEmpty();
        }

        public boolean contains(final Object o) {
            return Long2ObjectHashMap.this.containsValue(o);
        }

        public ValueIterator<V> iterator() {
            return new ValueIterator<V>();
        }

        public void clear() {
            Long2ObjectHashMap.this.clear();
        }
    }

    private class EntrySet<V> extends AbstractSet<Map.Entry<Long, V>> {
        public int size() {
            return Long2ObjectHashMap.this.size();
        }

        public boolean isEmpty() {
            return Long2ObjectHashMap.this.isEmpty();
        }

        public Iterator<Map.Entry<Long, V>> iterator() {
            return new EntryIterator<V>();
        }

        public void clear() {
            Long2ObjectHashMap.this.clear();
        }
    }

    
    
    

    private abstract class AbstractIterator<T> implements Iterator<T> {
        protected final long[] keys = Long2ObjectHashMap.this.keys;
        protected final Object[] values = Long2ObjectHashMap.this.values;
        private int posCounter;
        private int stopCounter;
        private boolean isPositionValid;

        protected AbstractIterator() {
            int i = capacity;
            if (null != values[capacity - 1]) {
                i = 0;
                for (int size = capacity; i < size; i++) {
                    if (null == values[i]) {
                        break;
                    }
                }
            }
            stopCounter = i;
            posCounter = i + capacity;
        }

        protected int getPosition() {
            return posCounter & mask;
        }

        public boolean hasNext() {
            for (int i = posCounter - 1; i >= stopCounter; i--) {
                final int index = i & mask;
                if (null != values[index]) {
                    return true;
                }
            }
            return false;
        }

        protected void findNext() {
            isPositionValid = false;
            for (int i = posCounter - 1; i >= stopCounter; i--) {
                final int index = i & mask;
                if (null != values[index]) {
                    posCounter = i;
                    isPositionValid = true;
                    return;
                }
            }
            throw new NoSuchElementException();
        }

        public abstract T next();

        public void remove() {
            if (isPositionValid) {
                final int position = getPosition();
                values[position] = null;
                --size;
                compactChain(position);
                isPositionValid = false;
            } else {
                throw new IllegalStateException();
            }
        }
    }

    public class ValueIterator<T> extends AbstractIterator<T> {
        @SuppressWarnings("unchecked")
        public T next() {
            findNext();
            return (T) values[getPosition()];
        }
    }

    public class KeyIterator extends AbstractIterator<Long> {
        public Long next() {
            return nextLong();
        }

        public long nextLong() {
            findNext();

            return keys[getPosition()];
        }
    }

    @SuppressWarnings("unchecked")
    public class EntryIterator<V> extends AbstractIterator<Entry<Long, V>> implements Entry<Long, V> {
        public Entry<Long, V> next() {
            findNext();
            return this;
        }

        public Long getKey() {
            return keys[getPosition()];
        }

        public V getValue() {
            return (V) values[getPosition()];
        }

        public V setValue(final V value) {
            checkNotNull(value);
            final int pos = getPosition();
            final Object oldValue = values[pos];
            values[pos] = value;
            return (V) oldValue;
        }
    }
}

<code block>


package com.hazelcast.util.collection;


import com.hazelcast.util.QuickMath;
import com.hazelcast.util.function.IntFunction;

import java.util.AbstractCollection;
import java.util.AbstractSet;
import java.util.Arrays;
import java.util.Collection;
import java.util.Iterator;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Set;

import static com.hazelcast.util.Preconditions.checkNotNull;


@edu.umd.cs.findbugs.annotations.SuppressWarnings("PZ_DONT_REUSE_ENTRY_OBJECTS_IN_ITERATORS")
public class Int2ObjectHashMap<V> implements Map<Integer, V> {
    private final double loadFactor;
    private int resizeThreshold;
    private int capacity;
    private int mask;
    private int size;

    private int[] keys;
    private Object[] values;

    
    private final ValueCollection valueCollection = new ValueCollection();
    private final KeySet keySet = new KeySet();
    private final EntrySet entrySet = new EntrySet();

    public Int2ObjectHashMap() {
        this(8, 0.6);
    }

    
    public Int2ObjectHashMap(final int initialCapacity, final double loadFactor) {
        this.loadFactor = loadFactor;
        capacity = QuickMath.nextPowerOfTwo(initialCapacity);
        mask = capacity - 1;
        resizeThreshold = (int) (capacity * loadFactor);

        keys = new int[capacity];
        values = new Object[capacity];
    }

    
    public double loadFactor() {
        return loadFactor;
    }

    
    public int capacity() {
        return capacity;
    }

    
    public int resizeThreshold() {
        return resizeThreshold;
    }

    
    public int size() {
        return size;
    }

    
    public boolean isEmpty() {
        return 0 == size;
    }

    
    public boolean containsKey(final Object key) {
        checkNotNull(key, "Null keys are not permitted");

        return containsKey(((Integer) key).intValue());
    }

    
    public boolean containsKey(final int key) {
        int index = hash(key);

        while (null != values[index]) {
            if (key == keys[index]) {
                return true;
            }

            index = ++index & mask;
        }

        return false;
    }

    
    public boolean containsValue(final Object value) {
        checkNotNull(value, "Null values are not permitted");

        for (final Object v : values) {
            if (null != v && value.equals(v)) {
                return true;
            }
        }

        return false;
    }

    
    public V get(final Object key) {
        return get(((Integer) key).intValue());
    }

    
    @SuppressWarnings("unchecked")
    public V get(final int key) {
        int index = hash(key);

        Object value;
        while (null != (value = values[index])) {
            if (key == keys[index]) {
                return (V) value;
            }

            index = ++index & mask;
        }

        return null;
    }


    
    public V computeIfAbsent(final int key, final IntFunction<? extends V> mappingFunction) {
        checkNotNull(mappingFunction, "mappingFunction cannot be null");
        V value = get(key);
        if (value == null) {
            value = mappingFunction.apply(key);
            if (value != null) {
                put(key, value);
            }
        }

        return value;
    }

    
    public V put(final Integer key, final V value) {
        return put(key.intValue(), value);
    }

    
    @SuppressWarnings("unchecked")
    public V put(final int key, final V value) {
        checkNotNull(value, "Value cannot be null");

        V oldValue = null;
        int index = hash(key);

        while (null != values[index]) {
            if (key == keys[index]) {
                oldValue = (V) values[index];
                break;
            }

            index = ++index & mask;
        }

        if (null == oldValue) {
            ++size;
            keys[index] = key;
        }

        values[index] = value;

        if (size > resizeThreshold) {
            increaseCapacity();
        }

        return oldValue;
    }

    
    public V remove(final Object key) {
        return remove(((Integer) key).intValue());
    }

    
    @SuppressWarnings("unchecked")
    public V remove(final int key) {
        int index = hash(key);

        Object value;
        while (null != (value = values[index])) {
            if (key == keys[index]) {
                values[index] = null;
                --size;

                compactChain(index);

                return (V) value;
            }

            index = ++index & mask;
        }

        return null;
    }

    
    public void clear() {
        size = 0;
        Arrays.fill(values, null);
    }

    
    public void compact() {
        final int idealCapacity = (int) Math.round(size() * (1.0d / loadFactor));
        rehash(QuickMath.nextPowerOfTwo(idealCapacity));
    }

    
    public void putAll(final Map<? extends Integer, ? extends V> map) {
        for (final Entry<? extends Integer, ? extends V> entry : map.entrySet()) {
            put(entry.getKey(), entry.getValue());
        }
    }

    
    public KeySet keySet() {
        return keySet;
    }

    
    public Collection<V> values() {
        return valueCollection;
    }

    
    public Set<Entry<Integer, V>> entrySet() {
        return entrySet;
    }

    
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append('{');

        for (final Entry<Integer, V> entry : entrySet()) {
            sb.append(entry.getKey().intValue());
            sb.append('=');
            sb.append(entry.getValue());
            sb.append(", ");
        }

        if (sb.length() > 1) {
            sb.setLength(sb.length() - 2);
        }

        sb.append('}');

        return sb.toString();
    }

    private void increaseCapacity() {
        final int newCapacity = capacity << 1;
        if (newCapacity < 0) {
            throw new IllegalStateException("Max capacity reached at size=" + size);
        }

        rehash(newCapacity);
    }

    private void rehash(final int newCapacity) {
        if (1 != Integer.bitCount(newCapacity)) {
            throw new IllegalStateException("New capacity must be a power of two");
        }

        capacity = newCapacity;
        mask = newCapacity - 1;
        resizeThreshold = (int) (newCapacity * loadFactor);

        final int[] tempKeys = new int[capacity];
        final Object[] tempValues = new Object[capacity];

        for (int i = 0, size = values.length; i < size; i++) {
            final Object value = values[i];
            if (null != value) {
                final int key = keys[i];
                int newHash = hash(key);
                while (null != tempValues[newHash]) {
                    newHash = ++newHash & mask;
                }

                tempKeys[newHash] = key;
                tempValues[newHash] = value;
            }
        }

        keys = tempKeys;
        values = tempValues;
    }

    private void compactChain(int deleteIndex) {
        int index = deleteIndex;
        while (true) {
            index = ++index & mask;
            if (null == values[index]) {
                return;
            }

            final int hash = hash(keys[index]);

            if ((index < hash && (hash <= deleteIndex || deleteIndex <= index))
                    || (hash <= deleteIndex && deleteIndex <= index)) {
                keys[deleteIndex] = keys[index];
                values[deleteIndex] = values[index];

                values[index] = null;
                deleteIndex = index;
            }
        }
    }

    private int hash(final int key) {
        final int hash = (key << 1) - (key << 8);
        return hash & mask;
    }

    
    
    

    public class KeySet extends AbstractSet<Integer> {
        public int size() {
            return Int2ObjectHashMap.this.size();
        }

        public boolean isEmpty() {
            return Int2ObjectHashMap.this.isEmpty();
        }

        public boolean contains(final Object o) {
            return Int2ObjectHashMap.this.containsKey(o);
        }

        public boolean contains(final int key) {
            return Int2ObjectHashMap.this.containsKey(key);
        }

        public KeyIterator iterator() {
            return new KeyIterator();
        }

        public boolean remove(final Object o) {
            return null != Int2ObjectHashMap.this.remove(o);
        }

        public boolean remove(final int key) {
            return null != Int2ObjectHashMap.this.remove(key);
        }

        public void clear() {
            Int2ObjectHashMap.this.clear();
        }
    }

    private class ValueCollection extends AbstractCollection<V> {
        public int size() {
            return Int2ObjectHashMap.this.size();
        }

        public boolean isEmpty() {
            return Int2ObjectHashMap.this.isEmpty();
        }

        public boolean contains(final Object o) {
            return Int2ObjectHashMap.this.containsValue(o);
        }

        public ValueIterator<V> iterator() {
            return new ValueIterator<V>();
        }

        public void clear() {
            Int2ObjectHashMap.this.clear();
        }
    }

    private class EntrySet extends AbstractSet<Entry<Integer, V>> {
        public int size() {
            return Int2ObjectHashMap.this.size();
        }

        public boolean isEmpty() {
            return Int2ObjectHashMap.this.isEmpty();
        }

        public Iterator<Entry<Integer, V>> iterator() {
            return new EntryIterator<V>();
        }

        public void clear() {
            Int2ObjectHashMap.this.clear();
        }
    }

    
    
    

    private abstract class AbstractIterator<T> implements Iterator<T> {
        protected final int[] keys = Int2ObjectHashMap.this.keys;
        protected final Object[] values = Int2ObjectHashMap.this.values;
        private int posCounter;
        private int stopCounter;
        private boolean isPositionValid;

        protected AbstractIterator() {
            int i = capacity;
            if (null != values[capacity - 1]) {
                i = 0;
                for (int size = capacity; i < size; i++) {
                    if (null == values[i]) {
                        break;
                    }
                }
            }

            stopCounter = i;
            posCounter = i + capacity;
        }

        protected int getPosition() {
            return posCounter & mask;
        }

        public boolean hasNext() {
            for (int i = posCounter - 1; i >= stopCounter; i--) {
                final int index = i & mask;
                if (null != values[index]) {
                    return true;
                }
            }

            return false;
        }

        protected void findNext() {
            isPositionValid = false;

            for (int i = posCounter - 1; i >= stopCounter; i--) {
                final int index = i & mask;
                if (null != values[index]) {
                    posCounter = i;
                    isPositionValid = true;
                    return;
                }
            }

            throw new NoSuchElementException();
        }

        public abstract T next();

        public void remove() {
            if (isPositionValid) {
                final int position = getPosition();
                values[position] = null;
                --size;

                compactChain(position);

                isPositionValid = false;
            } else {
                throw new IllegalStateException();
            }
        }
    }

    public class ValueIterator<T> extends AbstractIterator<T> {
        @SuppressWarnings("unchecked")
        public T next() {
            findNext();

            return (T) values[getPosition()];
        }
    }

    public class KeyIterator extends AbstractIterator<Integer> {
        public Integer next() {
            return nextInt();
        }

        public int nextInt() {
            findNext();

            return keys[getPosition()];
        }
    }

    @SuppressWarnings("unchecked")
    public class EntryIterator<V> extends AbstractIterator<Entry<Integer, V>> implements Entry<Integer, V> {
        public Entry<Integer, V> next() {
            findNext();

            return this;
        }

        public Integer getKey() {
            return keys[getPosition()];
        }

        public V getValue() {
            return (V) values[getPosition()];
        }

        public V setValue(final V value) {
            checkNotNull(value, "Value must not be null");

            final int pos = getPosition();
            final Object oldValue = values[pos];
            values[pos] = value;

            return (V) oldValue;
        }
    }
}

<code block>


package com.hazelcast.util.collection;

import com.hazelcast.util.QuickMath;
import com.hazelcast.util.function.Predicate;

import java.util.Arrays;
import java.util.Collection;
import java.util.Set;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class IntHashSet implements Set<Integer> {
    private final int[] values;
    private final IntIterator iterator;
    private final int mask;
    private final int missingValue;

    private int size;

    public IntHashSet(final int proposedCapacity, final int missingValue) {
        size = 0;
        this.missingValue = missingValue;
        final int capacity = QuickMath.nextPowerOfTwo(proposedCapacity);
        mask = capacity - 1;
        values = new int[capacity];
        Arrays.fill(values, missingValue);

        
        iterator = new IntIterator(missingValue, values);
    }

    
    public boolean add(final Integer value) {
        return add(value.intValue());
    }

    
    public boolean add(final int value) {
        int index = Hashing.intHash(value, mask);

        while (values[index] != missingValue) {
            if (values[index] == value) {
                return false;
            }

            index = next(index);
        }

        values[index] = value;
        size++;

        return true;
    }

    
    public boolean remove(final Object value) {
        return value instanceof Integer && remove(((Integer) value).intValue());
    }

    
    public boolean remove(final int value) {
        int index = Hashing.intHash(value, mask);

        while (values[index] != missingValue) {
            if (values[index] == value) {
                values[index] = missingValue;
                compactChain(index);
                return true;
            }

            index = next(index);
        }

        return false;
    }

    private int next(int index) {
        index = ++index & mask;
        return index;
    }

    private void compactChain(final int deleteIndex) {
        final int[] values = this.values;

        int index = deleteIndex;
        while (true) {
            final int previousIndex = index;
            index = next(index);
            if (values[index] == missingValue) {
                return;
            }

            values[previousIndex] = values[index];
            values[index] = missingValue;
        }
    }

    
    public boolean contains(final Object value) {
        return value instanceof Integer && contains(((Integer) value).intValue());
    }

    
    public boolean contains(final int value) {
        int index = Hashing.intHash(value, mask);

        while (values[index] != missingValue) {
            if (values[index] == value) {
                return true;
            }

            index = next(index);
        }

        return false;
    }

    
    public int size() {
        return size;
    }

    
    public boolean isEmpty() {
        return size() == 0;
    }

    
    public void clear() {
        final int[] values = this.values;
        final int length = values.length;
        for (int i = 0; i < length; i++) {
            values[i] = missingValue;
        }
        size = 0;
    }

    
    @SuppressWarnings("unchecked")
    public <T> T[] toArray(final T[] ignore) {
        return (T[]) (Object) Arrays.copyOf(values, values.length);
    }

    
    public boolean addAll(final Collection<? extends Integer> coll) {
        return addAllCapture(coll);
    }

    private <E extends Integer> boolean addAllCapture(final Collection<E> coll) {
        final Predicate<E> p = new Predicate<E>() {
            @Override
            public boolean test(E x) {
                return add(x);
            }
        };
        return conjunction(coll, p);
    }

    
    public boolean containsAll(final Collection<?> coll) {
        return containsAllCapture(coll);
    }

    private <E> boolean containsAllCapture(Collection<E> coll) {
        return conjunction(coll, new Predicate<E>() {
            @Override
            public boolean test(E value) {
                return contains(value);
            }
        });
    }

    
    public boolean containsAll(final IntHashSet other) {
        final IntIterator iterator = other.iterator();
        while (iterator.hasNext()) {
            if (!contains(iterator.nextValue())) {
                return false;
            }
        }
        return true;
    }

    
    public IntHashSet difference(final IntHashSet collection) {
        checkNotNull(collection, "Collection must not be null");

        IntHashSet difference = null;

        final IntIterator it = iterator();

        while (it.hasNext()) {
            final int value = it.nextValue();
            if (!collection.contains(value)) {
                if (difference == null) {
                    difference = new IntHashSet(size, missingValue);
                }

                difference.add(value);
            }
        }

        return difference;
    }

    
    public boolean removeAll(final Collection<?> coll) {
        return removeAllCapture(coll);
    }

    private <E> boolean removeAllCapture(final Collection<E> coll) {
        return conjunction(coll, new Predicate<E>() {
            @Override
            public boolean test(E value) {
                return remove(value);
            }
        });
    }

    private static <E> boolean conjunction(final Collection<E> collection, final Predicate<E> predicate) {
        checkNotNull(collection);

        boolean acc = false;
        for (final E e : collection) {
            
            acc |= predicate.test(e);
        }

        return acc;
    }

    
    public IntIterator iterator() {
        iterator.reset();
        return iterator;
    }

    
    public void copy(final IntHashSet obj) {
        
        if (this.mask != obj.mask) {
            throw new IllegalArgumentException("Cannot copy object: masks not equal");
        }

        if (this.missingValue != obj.missingValue) {
            throw new IllegalArgumentException("Cannot copy object: missingValues not equal");
        }

        System.arraycopy(obj.values, 0, this.values, 0, this.values.length);
        this.size = obj.size;
    }

    
    public String toString() {
        final StringBuilder b = new StringBuilder(size() * 3 + 2);
        b.append('{');
        String separator = "";
        for (int i : values) {
            b.append(i).append(separator);
            separator = ",";
        }
        return b.append('}').toString();
    }

    
    public Object[] toArray() {
        final int[] values = this.values;
        final Object[] array = new Object[values.length];
        for (int i = 0; i < values.length; i++) {
            array[i] = values[i];
        }
        return array;
    }

    
    public boolean equals(final Object other) {
        if (other == this) {
            return true;
        }

        if (other instanceof IntHashSet) {
            final IntHashSet otherSet = (IntHashSet) other;
            return otherSet.missingValue == missingValue && otherSet.size() == size() && containsAll(otherSet);
        }

        return false;
    }

    
    public int hashCode() {
        final IntIterator iterator = iterator();
        int total = 0;
        while (iterator.hasNext()) {
            
            total += (int) iterator.nextValue();
        }
        return total;
    }

    

    public boolean retainAll(final Collection<?> coll) {
        throw new UnsupportedOperationException("Not implemented");
    }
}

<code block>


package com.hazelcast.util.collection;

import java.util.Iterator;


public class LongIterator implements Iterator<Long> {
    private final long missingValue;
    private final long[] values;

    private int position;

    
    public LongIterator(final long missingValue, final long[] values) {
        this.missingValue = missingValue;
        this.values = values;
    }

    public boolean hasNext() {
        final long[] values = this.values;
        while (position < values.length) {
            if (values[position] != missingValue) {
                return true;
            }

            position++;
        }

        return false;
    }

    public Long next() {
        return nextValue();
    }

    public void remove() {
        throw new UnsupportedOperationException("remove");
    }

    
    public long nextValue() {
        final long value = values[position];
        position++;
        return value;
    }

    void reset() {
        position = 0;
    }
}

<code block>


package com.hazelcast.util.collection;


import com.hazelcast.util.function.Consumer;

import java.util.Map;


public class BiInt2ObjectMap<V> {
    
    public interface EntryConsumer<V> {
        
        void accept(int keyPartA, int keyPartB, V value);
    }

    private final Long2ObjectHashMap<V> map;

    
    public BiInt2ObjectMap() {
        map = new Long2ObjectHashMap<V>();
    }

    
    public BiInt2ObjectMap(final int initialCapacity, final double loadFactor) {
        map = new Long2ObjectHashMap<V>(initialCapacity, loadFactor);
    }

    
    public int capacity() {
        return map.capacity();
    }

    
    public double loadFactor() {
        return map.loadFactor();
    }

    
    public V put(final int keyPartA, final int keyPartB, final V value) {
        final long key = compoundKey(keyPartA, keyPartB);

        return map.put(key, value);
    }

    
    public V get(final int keyPartA, final int keyPartB) {
        final long key = compoundKey(keyPartA, keyPartB);

        return map.get(key);
    }

    
    public V remove(final int keyPartA, final int keyPartB) {
        final long key = compoundKey(keyPartA, keyPartB);

        return map.remove(key);
    }

    
    public void forEach(final EntryConsumer<V> consumer) {
        for (Map.Entry<Long, V> entry : map.entrySet()) {
            Long compoundKey = entry.getKey();
            final int keyPartA = (int) (compoundKey >>> 32);
            final int keyPartB = (int) (compoundKey & 0xFFFFFFFFL);
            consumer.accept(keyPartA, keyPartB, entry.getValue());
        }
    }

    
    public void forEach(final Consumer<V> consumer) {
        for (Map.Entry<Long, V> entry : map.entrySet()) {
            consumer.accept(entry.getValue());
        }
    }

    
    public int size() {
        return map.size();
    }

    
    public boolean isEmpty() {
        return map.isEmpty();
    }

    private static long compoundKey(final int keyPartA, final int keyPartB) {
        return ((long) keyPartA << 32) | keyPartB;
    }
}

<code block>


package com.hazelcast.util.collection;

import com.hazelcast.util.QuickMath;
import com.hazelcast.util.function.Predicate;

import java.util.Arrays;
import java.util.Collection;
import java.util.Set;

import static com.hazelcast.util.Preconditions.checkNotNull;


public final class LongHashSet implements Set<Long> {
    private final long[] values;
    private final LongIterator iterator;
    private final int mask;
    private final long missingValue;

    private int size;

    public LongHashSet(final int proposedCapacity, final long missingValue) {
        size = 0;
        this.missingValue = missingValue;
        final int capacity = QuickMath.nextPowerOfTwo(proposedCapacity);
        mask = capacity - 1;
        values = new long[capacity];
        Arrays.fill(values, missingValue);

        
        iterator = new LongIterator(missingValue, values);
    }

    
    public boolean add(final Long value) {
        return add(value.longValue());
    }

    
    public boolean add(final long value) {
        int index = Hashing.longHash(value, mask);

        while (values[index] != missingValue) {
            if (values[index] == value) {
                return false;
            }

            index = next(index);
        }

        values[index] = value;
        size++;

        return true;
    }

    
    public boolean remove(final Object value) {
        return value instanceof Long && remove(((Long) value).longValue());
    }

    
    public boolean remove(final long value) {
        int index = Hashing.longHash(value, mask);

        while (values[index] != missingValue) {
            if (values[index] == value) {
                values[index] = missingValue;
                compactChain(index);
                return true;
            }

            index = next(index);
        }

        return false;
    }

    private int next(int index) {
        index = ++index & mask;
        return index;
    }

    private void compactChain(final int deleteIndex) {
        final long[] values = this.values;

        int index = deleteIndex;
        while (true) {
            final int previousIndex = index;
            index = next(index);
            if (values[index] == missingValue) {
                return;
            }

            values[previousIndex] = values[index];
            values[index] = missingValue;
        }
    }

    
    public boolean contains(final Object value) {
        return value instanceof Long && contains(((Long) value).longValue());
    }

    
    public boolean contains(final long value) {
        int index = Hashing.longHash(value, mask);

        while (values[index] != missingValue) {
            if (values[index] == value) {
                return true;
            }

            index = next(index);
        }

        return false;
    }

    
    public int size() {
        return size;
    }

    
    public boolean isEmpty() {
        return size() == 0;
    }

    
    public void clear() {
        final long[] values = this.values;
        final int length = values.length;
        for (int i = 0; i < length; i++) {
            values[i] = missingValue;
        }
        size = 0;
    }

    
    @SuppressWarnings("unchecked")
    public <T> T[] toArray(final T[] ignore) {
        return (T[]) (Object) Arrays.copyOf(values, values.length);
    }

    
    public boolean addAll(final Collection<? extends Long> coll) {
        return addAllCapture(coll);
    }

    private <E extends Long> boolean addAllCapture(final Collection<E> coll) {
        final Predicate<E> p = new Predicate<E>() {
            @Override
            public boolean test(E x) {
                return add(x);
            }
        };
        return conjunction(coll, p);
    }

    
    public boolean containsAll(final Collection<?> coll) {
        return containsAllCapture(coll);
    }

    private <E> boolean containsAllCapture(Collection<E> coll) {
        return conjunction(coll, new Predicate<E>() {
            @Override
            public boolean test(E value) {
                return contains(value);
            }
        });
    }

    
    public boolean containsAll(final LongHashSet other) {
        final LongIterator iterator = other.iterator();
        while (iterator.hasNext()) {
            if (!contains(iterator.nextValue())) {
                return false;
            }
        }
        return true;
    }

    
    public LongHashSet difference(final LongHashSet collection) {
        checkNotNull(collection);

        LongHashSet difference = null;

        final LongIterator it = iterator();

        while (it.hasNext()) {
            final long value = it.nextValue();
            if (!collection.contains(value)) {
                if (difference == null) {
                    difference = new LongHashSet(size, missingValue);
                }

                difference.add(value);
            }
        }

        return difference;
    }

    
    public boolean removeAll(final Collection<?> coll) {
        return removeAllCapture(coll);
    }

    private <E> boolean removeAllCapture(final Collection<E> coll) {
        return conjunction(coll, new Predicate<E>() {
            @Override
            public boolean test(E value) {
                return remove(value);
            }
        });
    }

    private static <T> boolean conjunction(final Collection<T> collection, final Predicate<T> predicate) {
        checkNotNull(collection);

        boolean acc = false;
        for (final T t : collection) {
            
            acc |= predicate.test(t);
        }

        return acc;
    }

    
    public LongIterator iterator() {
        iterator.reset();
        return iterator;
    }

    
    public void copy(final LongHashSet obj) {
        
        if (this.mask != obj.mask) {
            throw new IllegalArgumentException("Cannot copy object: masks not equal");
        }

        if (this.missingValue != obj.missingValue) {
            throw new IllegalArgumentException("Cannot copy object: missingValues not equal");
        }

        System.arraycopy(obj.values, 0, this.values, 0, this.values.length);
        this.size = obj.size;
    }

    
    public String toString() {
        final StringBuilder b = new StringBuilder(size() * 3 + 2);
        b.append('{');
        String separator = "";
        for (long i : values) {
            b.append(i).append(separator);
            separator = ",";
        }
        return b.append('}').toString();
    }

    
    public Object[] toArray() {
        final long[] values = this.values;
        final Object[] array = new Object[values.length];
        for (int i = 0; i < values.length; i++) {
            array[i] = values[i];
        }
        return array;
    }

    
    public boolean equals(final Object other) {
        if (other == this) {
            return true;
        }

        if (other instanceof LongHashSet) {
            final LongHashSet otherSet = (LongHashSet) other;
            return otherSet.missingValue == missingValue && otherSet.size() == size() && containsAll(otherSet);
        }

        return false;
    }

    
    public int hashCode() {
        final LongIterator iterator = iterator();
        int total = 0;
        while (iterator.hasNext()) {
            
            total += (long) iterator.nextValue();
        }
        return total;
    }

    

    public boolean retainAll(final Collection<?> coll) {
        throw new UnsupportedOperationException("Not implemented");
    }
}

<code block>



package com.hazelcast.util.function;

<code block>


package com.hazelcast.util.function;


public interface Consumer<T> {

    
    void accept(T t);

}

<code block>


package com.hazelcast.util.function;


public interface IntFunction<R> {

    
    R apply(int value);
}

<code block>


package com.hazelcast.util.function;


public interface LongFunction<R> {

    
    R apply(long value);
}

<code block>


package com.hazelcast.util.function;


public interface LongLongConsumer {
    
    void accept(long key, long value);
}

<code block>


package com.hazelcast.util.function;


public interface BiConsumer<T, U> {

    
    void accept(T t, U u);
}

<code block>


package com.hazelcast.util.function;


public interface Supplier<T> {
    T get();
}

<code block>


package com.hazelcast.util.function;


public interface Predicate<T> {

    
    boolean test(T t);
}

<code block>


package com.hazelcast.nio;

import java.nio.charset.Charset;


public final class Bits {

    
    public static final int BYTE_SIZE_IN_BYTES = 1;
    
    public static final int BOOLEAN_SIZE_IN_BYTES = 1;
    
    public static final int SHORT_SIZE_IN_BYTES = 2;
    
    public static final int CHAR_SIZE_IN_BYTES = 2;
    
    public static final int INT_SIZE_IN_BYTES = 4;
    
    public static final int FLOAT_SIZE_IN_BYTES = 4;
    
    public static final int LONG_SIZE_IN_BYTES = 8;
    
    public static final int DOUBLE_SIZE_IN_BYTES = 8;
    
    public static final int CACHE_LINE_LENGTH = 64;

    
    public static final Charset UTF_8 = Charset.forName("UTF-8");
    
    public static final Charset ISO_8859_1 = Charset.forName("ISO-8859-1");

    private Bits() {
    }

    public static char readChar(byte[] buffer, int pos, boolean bigEndian) {
        return bigEndian ? readCharB(buffer, pos) : readCharL(buffer, pos);
    }

    public static char readCharB(byte[] buffer, int pos) {
        int byte1 = buffer[pos] & 0xFF;
        int byte0 = buffer[pos + 1] & 0xFF;
        return (char) ((byte1 << 8) + byte0);
    }

    public static char readCharL(byte[] buffer, int pos) {
        int byte1 = buffer[pos] & 0xFF;
        int byte0 = buffer[pos + 1] & 0xFF;
        return (char) ((byte0 << 8) + byte1);
    }

    public static void writeChar(byte[] buffer, int pos, char v, boolean bigEndian) {
        if (bigEndian) {
            writeCharB(buffer, pos, v);
        } else {
            writeCharL(buffer, pos, v);
        }
    }

    public static void writeCharB(byte[] buffer, int pos, char v) {
        buffer[pos] = (byte) ((v >>> 8) & 0xFF);
        buffer[pos + 1] = (byte) ((v) & 0xFF);
    }

    public static void writeCharL(byte[] buffer, int pos, char v) {
        buffer[pos] = (byte) ((v) & 0xFF);
        buffer[pos + 1] = (byte) ((v >>> 8) & 0xFF);
    }

    public static short readShort(byte[] buffer, int pos, boolean bigEndian) {
        return bigEndian ? readShortB(buffer, pos) : readShortL(buffer, pos);
    }

    public static short readShortB(byte[] buffer, int pos) {
        int byte1 = buffer[pos] & 0xFF;
        int byte0 = buffer[pos + 1] & 0xFF;
        return (short) ((byte1 << 8) + byte0);
    }

    public static short readShortL(byte[] buffer, int pos) {
        int byte1 = buffer[pos] & 0xFF;
        int byte0 = buffer[pos + 1] & 0xFF;
        return (short) ((byte0 << 8) + byte1);
    }

    public static void writeShort(byte[] buffer, int pos, short v, boolean bigEndian) {
        if (bigEndian) {
            writeShortB(buffer, pos, v);
        } else {
            writeShortL(buffer, pos, v);
        }
    }

    public static void writeShortB(byte[] buffer, int pos, short v) {
        buffer[pos] = (byte) ((v >>> 8) & 0xFF);
        buffer[pos + 1] = (byte) ((v) & 0xFF);
    }

    public static void writeShortL(byte[] buffer, int pos, short v) {
        buffer[pos] = (byte) ((v) & 0xFF);
        buffer[pos + 1] = (byte) ((v >>> 8) & 0xFF);
    }

    public static int readInt(byte[] buffer, int pos, boolean bigEndian) {
        if (bigEndian) {
            return readIntB(buffer, pos);
        } else {
            return readIntL(buffer, pos);
        }
    }

    public static int readIntB(byte[] buffer, int pos) {
        int byte3 = (buffer[pos] & 0xFF) << 24;
        int byte2 = (buffer[pos + 1] & 0xFF) << 16;
        int byte1 = (buffer[pos + 2] & 0xFF) << 8;
        int byte0 = buffer[pos + 3] & 0xFF;
        return byte3 + byte2 + byte1 + byte0;
    }

    public static int readIntL(byte[] buffer, int pos) {
        int byte3 = buffer[pos] & 0xFF;
        int byte2 = (buffer[pos + 1] & 0xFF) << 8;
        int byte1 = (buffer[pos + 2] & 0xFF) << 16;
        int byte0 = (buffer[pos + 3] & 0xFF) << 24;
        return byte3 + byte2 + byte1 + byte0;
    }

    public static void writeInt(byte[] buffer, int pos, int v, boolean bigEndian) {
        if (bigEndian) {
            writeIntB(buffer, pos, v);
        } else {
            writeIntL(buffer, pos, v);
        }
    }

    public static void writeIntB(byte[] buffer, int pos, int v) {
        buffer[pos] = (byte) ((v >>> 24) & 0xFF);
        buffer[pos + 1] = (byte) ((v >>> 16) & 0xFF);
        buffer[pos + 2] = (byte) ((v >>> 8) & 0xFF);
        buffer[pos + 3] = (byte) ((v) & 0xFF);
    }

    public static void writeIntL(byte[] buffer, int pos, int v) {
        buffer[pos] = (byte) ((v) & 0xFF);
        buffer[pos + 1] = (byte) ((v >>> 8) & 0xFF);
        buffer[pos + 2] = (byte) ((v >>> 16) & 0xFF);
        buffer[pos + 3] = (byte) ((v >>> 24) & 0xFF);
    }

    public static long readLong(byte[] buffer, int pos, boolean bigEndian) {
        if (bigEndian) {
            return readLongB(buffer, pos);
        } else {
            return readLongL(buffer, pos);
        }
    }

    public static long readLongB(byte[] buffer, int pos) {
        long byte7 = (long) buffer[pos] << 56;
        long byte6 = (long) (buffer[pos + 1] & 0xFF) << 48;
        long byte5 = (long) (buffer[pos + 2] & 0xFF) << 40;
        long byte4 = (long) (buffer[pos + 3] & 0xFF) << 32;
        long byte3 = (long) (buffer[pos + 4] & 0xFF) << 24;
        long byte2 = (long) (buffer[pos + 5] & 0xFF) << 16;
        long byte1 = (long) (buffer[pos + 6] & 0xFF) << 8;
        long byte0 = (long) (buffer[pos + 7] & 0xFF);
        return byte7 + byte6 + byte5 + byte4 + byte3 + byte2 + byte1 + byte0;
    }

    public static long readLongL(byte[] buffer, int pos) {
        long byte7 = (long) (buffer[pos] & 0xFF);
        long byte6 = (long) (buffer[pos + 1] & 0xFF) << 8;
        long byte5 = (long) (buffer[pos + 2] & 0xFF) << 16;
        long byte4 = (long) (buffer[pos + 3] & 0xFF) << 24;
        long byte3 = (long) (buffer[pos + 4] & 0xFF) << 32;
        long byte2 = (long) (buffer[pos + 5] & 0xFF) << 40;
        long byte1 = (long) (buffer[pos + 6] & 0xFF) << 48;
        long byte0 = (long) (buffer[pos + 7] & 0xFF) << 56;
        return byte7 + byte6 + byte5 + byte4 + byte3 + byte2 + byte1 + byte0;
    }

    public static void writeLong(byte[] buffer, int pos, long v, boolean bigEndian) {
        if (bigEndian) {
            writeLongB(buffer, pos, v);
        } else {
            writeLongL(buffer, pos, v);
        }
    }

    public static void writeLongB(byte[] buffer, int pos, long v) {
        buffer[pos] = (byte) (v >>> 56);
        buffer[pos + 1] = (byte) (v >>> 48);
        buffer[pos + 2] = (byte) (v >>> 40);
        buffer[pos + 3] = (byte) (v >>> 32);
        buffer[pos + 4] = (byte) (v >>> 24);
        buffer[pos + 5] = (byte) (v >>> 16);
        buffer[pos + 6] = (byte) (v >>> 8);
        buffer[pos + 7] = (byte) (v);
    }

    public static void writeLongL(byte[] buffer, int pos, long v) {
        buffer[pos] = (byte) (v);
        buffer[pos + 1] = (byte) (v >>> 8);
        buffer[pos + 2] = (byte) (v >>> 16);
        buffer[pos + 3] = (byte) (v >>> 24);
        buffer[pos + 4] = (byte) (v >>> 32);
        buffer[pos + 5] = (byte) (v >>> 40);
        buffer[pos + 6] = (byte) (v >>> 48);
        buffer[pos + 7] = (byte) (v >>> 56);
    }

    
    public static byte setBit(byte value, int bit) {
        value |= 1 << bit;
        return value;
    }

    
    public static byte clearBit(byte value, int bit) {
        value &= ~(1 << bit);
        return value;
    }

    
    public static byte invertBit(byte value, int bit) {
        value ^= 1 << bit;
        return value;
    }

    
    public static int setBit(int value, int bit) {
        value |= 1 << bit;
        return value;
    }

    
    public static int clearBit(int value, int bit) {
        value &= ~(1 << bit);
        return value;
    }

    
    public static int invertBit(int value, int bit) {
        value ^= 1 << bit;
        return value;
    }

    
    public static boolean isBitSet(int value, int bit) {
        return (value & 1 << bit) != 0;
    }

    
    public static int combineToInt(short x, short y) {
        return ((int) x << 16) | ((int) y & 0xFFFF);
    }

    public static short extractShort(int value, boolean lowerBits) {
        return (short) ((lowerBits) ? value : (value >> 16));
    }

    
    public static long combineToLong(int x, int y) {
        return ((long) x << 32) | ((long) y & 0xFFFFFFFFL);
    }

    public static int extractInt(long value, boolean lowerBits) {
        return (int) ((lowerBits) ? value : (value >> 32));
    }
}

<code block>


package com.hazelcast.util;

import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.math.BigInteger;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;


@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class QuickMathTest {

    @Test
    public void testIsPowerOfTwo() {
        assertTrue(QuickMath.isPowerOfTwo(1));
        assertTrue(QuickMath.isPowerOfTwo(2));
        assertFalse(QuickMath.isPowerOfTwo(3));
        assertTrue(QuickMath.isPowerOfTwo(1024));
        assertFalse(QuickMath.isPowerOfTwo(1023));
        assertFalse(QuickMath.isPowerOfTwo(Integer.MAX_VALUE));
    }

    @Test
    public void testNextPowerOfTwo() {
        assertEquals(1, QuickMath.nextPowerOfTwo(-9999999));
        assertEquals(1, QuickMath.nextPowerOfTwo(-1));
        assertEquals(1, QuickMath.nextPowerOfTwo(0));
        assertEquals(1, QuickMath.nextPowerOfTwo(1));
        assertEquals(2, QuickMath.nextPowerOfTwo(2));
        assertEquals(1024, QuickMath.nextPowerOfTwo(999));
        assertEquals(1 << 23, QuickMath.nextPowerOfTwo((1 << 23) - 1));
        assertEquals(1 << 23, QuickMath.nextPowerOfTwo(1 << 23));

        assertEquals(2048L, QuickMath.nextPowerOfTwo(2000L));
        assertEquals(1L << 33, QuickMath.nextPowerOfTwo((1L << 33) - 3));
        assertEquals(1L << 43, QuickMath.nextPowerOfTwo((1L << 43)));
    }

    @Test
    public void testNextLongPowerOfTwo() {
        assertEquals(1L, QuickMath.nextPowerOfTwo(-9999999L));
        assertEquals(1L, QuickMath.nextPowerOfTwo(-1L));
        assertEquals(1L, QuickMath.nextPowerOfTwo(0L));
        assertEquals(1L, QuickMath.nextPowerOfTwo(1L));
        assertEquals(2L, QuickMath.nextPowerOfTwo(2L));
        assertEquals(4L, QuickMath.nextPowerOfTwo(3L));
        assertEquals(1L << 62, QuickMath.nextPowerOfTwo((1L << 61) + 1));
    }

    @Test
    public void testModPowerOfTwo() {
        int[] aParams = new int[]{
                0, 1, Integer.MAX_VALUE / 2, Integer.MAX_VALUE
        };
        int[] bParams = new int[]{
                1, 2, 1024, powerOfTwo(10), powerOfTwo(20)
        };

        for (int a : aParams) {
            for (int b : bParams) {
                assertEquals(a % b, QuickMath.modPowerOfTwo(a, b));
            }
        }
    }

    private int powerOfTwo(int x) {
        return BigInteger.valueOf(2).pow(x).intValue();
    }
}

<code block>


package com.hazelcast.util.collection;

import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Assert;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.Collection;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;

import static java.lang.Integer.valueOf;
import static org.hamcrest.core.Is.is;
import static org.hamcrest.core.IsEqual.equalTo;
import static org.hamcrest.number.IsCloseTo.closeTo;
import static org.hamcrest.number.OrderingComparison.lessThan;
import static org.junit.Assert.assertThat;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class Int2ObjectHashMapTest {
    private final Int2ObjectHashMap<String> intToObjectMap = new Int2ObjectHashMap<String>();

    @Test public void shouldDoPutAndThenGet() {
        final String value = "Seven";
        intToObjectMap.put(7, value);

        assertThat(intToObjectMap.get(7), is(value));
    }

    @Test public void shouldReplaceExistingValueForTheSameKey() {
        final int key = 7;
        final String value = "Seven";
        intToObjectMap.put(key, value);

        final String newValue = "New Seven";
        final String oldValue = intToObjectMap.put(key, newValue);

        assertThat(intToObjectMap.get(key), is(newValue));
        assertThat(oldValue, is(value));
        assertThat(valueOf(intToObjectMap.size()), is(valueOf(1)));
    }

    @Test public void shouldGrowWhenThresholdExceeded() {
        final double loadFactor = 0.5d;
        final Int2ObjectHashMap<String> map = new Int2ObjectHashMap<String>(32, loadFactor);
        for (int i = 0; i < 16; i++) {
            map.put(i, Integer.toString(i));
        }

        assertThat(valueOf(map.resizeThreshold()), is(valueOf(16)));
        assertThat(valueOf(map.capacity()), is(valueOf(32)));
        assertThat(valueOf(map.size()), is(valueOf(16)));

        map.put(16, "16");

        assertThat(valueOf(map.resizeThreshold()), is(valueOf(32)));
        assertThat(valueOf(map.capacity()), is(valueOf(64)));
        assertThat(valueOf(map.size()), is(valueOf(17)));

        assertThat(map.get(16), equalTo("16"));
        assertThat(loadFactor, closeTo(map.loadFactor(), 0.0));
    }

    @Test public void shouldHandleCollisionAndThenLinearProbe() {
        final double loadFactor = 0.5d;
        final Int2ObjectHashMap<String> map = new Int2ObjectHashMap<String>(32, loadFactor);
        final int key = 7;
        final String value = "Seven";
        map.put(key, value);

        final int collisionKey = key + map.capacity();
        final String collisionValue = Integer.toString(collisionKey);
        map.put(collisionKey, collisionValue);

        assertThat(map.get(key), is(value));
        assertThat(map.get(collisionKey), is(collisionValue));
        assertThat(loadFactor, closeTo(map.loadFactor(), 0.0));
    }

    @Test public void shouldClearCollection() {
        for (int i = 0; i < 15; i++) {
            intToObjectMap.put(i, Integer.toString(i));
        }

        assertThat(valueOf(intToObjectMap.size()), is(valueOf(15)));
        assertThat(intToObjectMap.get(1), is("1"));

        intToObjectMap.clear();

        assertThat(valueOf(intToObjectMap.size()), is(valueOf(0)));
        Assert.assertNull(intToObjectMap.get(1));
    }

    @Test public void shouldCompactCollection() {
        final int totalItems = 50;
        for (int i = 0; i < totalItems; i++) {
            intToObjectMap.put(i, Integer.toString(i));
        }

        for (int i = 0, limit = totalItems - 4; i < limit; i++) {
            intToObjectMap.remove(i);
        }

        final int capacityBeforeCompaction = intToObjectMap.capacity();
        intToObjectMap.compact();

        assertThat(valueOf(intToObjectMap.capacity()), lessThan(valueOf(capacityBeforeCompaction)));
    }

    @Test public void shouldContainValue() {
        final int key = 7;
        final String value = "Seven";

        intToObjectMap.put(key, value);

        Assert.assertTrue(intToObjectMap.containsValue(value));
        Assert.assertFalse(intToObjectMap.containsValue("NoKey"));
    }

    @Test public void shouldContainKey() {
        final int key = 7;
        final String value = "Seven";

        intToObjectMap.put(key, value);

        Assert.assertTrue(intToObjectMap.containsKey(key));
        Assert.assertFalse(intToObjectMap.containsKey(0));
    }

    @Test public void shouldRemoveEntry() {
        final int key = 7;
        final String value = "Seven";

        intToObjectMap.put(key, value);

        Assert.assertTrue(intToObjectMap.containsKey(key));

        intToObjectMap.remove(key);

        Assert.assertFalse(intToObjectMap.containsKey(key));
    }

    @Test public void shouldRemoveEntryAndCompactCollisionChain() {
        final int key = 12;
        final String value = "12";

        intToObjectMap.put(key, value);
        intToObjectMap.put(13, "13");

        final int collisionKey = key + intToObjectMap.capacity();
        final String collisionValue = Integer.toString(collisionKey);

        intToObjectMap.put(collisionKey, collisionValue);
        intToObjectMap.put(14, "14");

        assertThat(intToObjectMap.remove(key), is(value));
    }

    @Test public void shouldIterateValues() {
        final Collection<String> initialSet = new HashSet<String>();

        for (int i = 0; i < 11; i++) {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
            initialSet.add(value);
        }

        final Collection<String> copyToSet = new HashSet<String>();

        for (final String s : intToObjectMap.values()) {
            copyToSet.add(s);
        }

        assertThat(copyToSet, is(initialSet));
    }

    @Test public void shouldIterateKeysGettingIntAsPrimitive() {
        final Collection<Integer> initialSet = new HashSet<Integer>();

        for (int i = 0; i < 11; i++) {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
            initialSet.add(valueOf(i));
        }

        final Collection<Integer> copyToSet = new HashSet<Integer>();

        for (final Int2ObjectHashMap.KeyIterator iter = intToObjectMap.keySet().iterator(); iter.hasNext(); ) {
            copyToSet.add(valueOf(iter.nextInt()));
        }

        assertThat(copyToSet, is(initialSet));
    }

    @Test public void shouldIterateKeys() {
        final Collection<Integer> initialSet = new HashSet<Integer>();

        for (int i = 0; i < 11; i++) {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
            initialSet.add(valueOf(i));
        }

        final Collection<Integer> copyToSet = new HashSet<Integer>();

        for (final Integer aInteger : intToObjectMap.keySet()) {
            copyToSet.add(aInteger);
        }

        assertThat(copyToSet, is(initialSet));
    }

    @Test public void shouldIterateAndHandleRemove() {
        final Collection<Integer> initialSet = new HashSet<Integer>();

        final int count = 11;
        for (int i = 0; i < count; i++) {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
            initialSet.add(valueOf(i));
        }

        final Collection<Integer> copyOfSet = new HashSet<Integer>();

        int i = 0;
        for (final Iterator<Integer> iter = intToObjectMap.keySet().iterator(); iter.hasNext(); ) {
            final Integer item = iter.next();
            if (i++ == 7) {
                iter.remove();
            } else {
                copyOfSet.add(item);
            }
        }

        final int reducedSetSize = count - 1;
        assertThat(valueOf(initialSet.size()), is(valueOf(count)));
        assertThat(valueOf(intToObjectMap.size()), is(valueOf(reducedSetSize)));
        assertThat(valueOf(copyOfSet.size()), is(valueOf(reducedSetSize)));
    }

    @Test public void shouldIterateEntries() {
        final int count = 11;
        for (int i = 0; i < count; i++) {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
        }

        final String testValue = "Wibble";
        for (final Map.Entry<Integer, String> entry : intToObjectMap.entrySet()) {
            assertThat(entry.getKey(), equalTo(valueOf(entry.getValue())));

            if (entry.getKey() == 7) {
                entry.setValue(testValue);
            }
        }

        assertThat(intToObjectMap.get(7), equalTo(testValue));
    }

    @Test public void shouldGenerateStringRepresentation() {
        final int[] testEntries = {3, 1, 19, 7, 11, 12, 7};

        for (final int testEntry : testEntries) {
            intToObjectMap.put(testEntry, String.valueOf(testEntry));
        }

        final String mapAsAString = "{7=7, 12=12, 19=19, 3=3, 11=11, 1=1}";
        assertThat(intToObjectMap.toString(), equalTo(mapAsAString));
    }
}


<code block>


package com.hazelcast.util.collection;

import com.hazelcast.util.function.LongLongConsumer;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;
import org.mockito.InOrder;

import java.util.Collection;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

import static java.lang.Long.MAX_VALUE;
import static org.hamcrest.Matchers.hasItems;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertThat;
import static org.junit.Assert.assertTrue;
import static org.mockito.Mockito.inOrder;
import static org.mockito.Mockito.mock;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class Long2LongHashMapTest {
    public static final long MISSING_VALUE = -1L;

    private Long2LongHashMap map = new Long2LongHashMap(MISSING_VALUE);

    @Test public void shouldInitiallyBeEmpty() {
        assertEquals(0, map.size());
        assertTrue(map.isEmpty());
    }

    @Test public void getShouldReturnMissingValueWhenEmpty() {
        assertEquals(MISSING_VALUE, map.get(1L));
    }

    @Test public void getShouldReturnMissingValueWhenThereIsNoElement() {
        map.put(1L, 1L);

        assertEquals(MISSING_VALUE, map.get(2L));
    }

    @Test public void getShouldReturnPutValues() {
        map.put(1L, 1L);

        assertEquals(1L, map.get(1L));
    }

    @Test public void putShouldReturnOldValue() {
        map.put(1L, 1L);

        assertEquals(1L, map.put(1L, 2L));
    }

    @Test public void clearShouldResetSize() {
        map.put(1L, 1L);
        map.put(100L, 100L);

        map.clear();

        assertEquals(0, map.size());
        assertTrue(map.isEmpty());
    }

    @Test public void clearShouldRemoveValues() {
        map.put(1L, 1L);
        map.put(100L, 100L);

        map.clear();

        assertEquals(MISSING_VALUE, map.get(1L));
        assertEquals(MISSING_VALUE, map.get(100L));
    }

    @Test public void forEachShouldLoopOverEveryElement() {
        map.put(1L, 1L);
        map.put(100L, 100L);

        final LongLongConsumer mockConsumer = mock(LongLongConsumer.class);
        map.longForEach(mockConsumer);

        final InOrder inOrder = inOrder(mockConsumer);
        inOrder.verify(mockConsumer).accept(1L, 1L);
        inOrder.verify(mockConsumer).accept(100L, 100L);
        inOrder.verifyNoMoreInteractions();
    }

    @Test public void shouldNotContainKeyOfAMissingKey() {
        assertFalse(map.containsKey(1L));
    }

    @Test public void shouldContainKeyOfAPresentKey() {
        map.put(1L, 1L);

        assertTrue(map.containsKey(1L));
    }

    @Test public void shouldNotContainValueForAMissingEntry() {
        assertFalse(map.containsValue(1L));
    }

    @Test public void shouldContainValueForAPresentEntry() {
        map.put(1L, 1L);

        assertTrue(map.containsValue(1L));
    }

    @Test public void shouldExposeValidKeySet() {
        map.put(1L, 1L);
        map.put(2L, 2L);

        assertCollectionContainsElements(map.keySet());
    }

    @Test public void shouldExposeValidValueSet() {
        map.put(1L, 1L);
        map.put(2L, 2L);

        assertCollectionContainsElements(map.values());
    }

    @Test public void shouldPutAllMembersOfAnotherHashMap() {
        map.put(1L, 1L);
        map.put(2L, 3L);

        final Map<Long, Long> other = new HashMap<Long, Long>();
        other.put(1L, 2L);
        other.put(3L, 4L);

        map.putAll(other);

        assertEquals(3, map.size());

        assertEquals(2, map.get(1L));
        assertEquals(3, map.get(2L));
        assertEquals(4, map.get(3L));
    }

    @Test public void entrySetShouldContainEntries() {
        map.put(1L, 1L);
        map.put(2L, 3L);

        final Set<Entry<Long, Long>> entrySet = map.entrySet();
        assertEquals(2, entrySet.size());
        assertFalse(entrySet.isEmpty());

        final Iterator<Entry<Long, Long>> it = entrySet.iterator();
        assertTrue(it.hasNext());
        assertEntryIs(it.next(), 1L, 1L);
        assertTrue(it.hasNext());
        assertEntryIs(it.next(), 2L, 3L);
        assertFalse(it.hasNext());
    }

    @Test public void removeShouldReturnMissing() {
        assertEquals(MISSING_VALUE, map.remove(1L));
    }

    @Test public void removeShouldReturnValueRemoved() {
        map.put(1L, 2L);

        assertEquals(2L, map.remove(1L));
    }

    @Test public void removeShouldRemoveEntry() {
        map.put(1L, 2L);

        map.remove(1L);

        assertTrue(map.isEmpty());
        assertFalse(map.containsKey(1L));
        assertFalse(map.containsValue(2L));
    }

    @Test public void shouldOnlyRemoveTheSpecifiedEntry() {
        for (int i = 0; i < 8; i++) {
            map.put(i, i * 2);
        }

        map.remove(5L);

        for (int i = 0; i < 8; i++) {
            if (i != 5) {
                assertTrue(map.containsKey(i));
                assertTrue(map.containsValue(2 * i));
            }
        }
    }

    @Test public void shouldResizeWhenMoreElementsAreAdded() {
        for (int key = 0; key < 100; key++) {
            final int value = key * 2;
            assertEquals(MISSING_VALUE, map.put(key, value));
            assertEquals(value, map.get(key));
        }
    }

    @Test public void shouldHaveNoMinValueForEmptyCollection() {
        assertEquals(MAX_VALUE, map.minValue());
    }

    @Test public void shouldFindMinValue() {
        map.put(1, 2);
        map.put(2, 10);
        map.put(3, -5);

        assertEquals(-5, map.minValue());
    }

    private static void assertEntryIs(final Entry<Long, Long> entry, final long expectedKey, final long expectedValue) {
        assertEquals(expectedKey, entry.getKey().longValue());
        assertEquals(expectedValue, entry.getValue().longValue());
    }

    private static void assertCollectionContainsElements(final Collection<Long> keys) {
        assertEquals(2, keys.size());
        assertFalse(keys.isEmpty());
        assertTrue(keys.contains(1L));
        assertTrue(keys.contains(2L));
        assertFalse(keys.contains(3L));
        assertThat(keys, hasItems(1L, 2L));

        assertThat("iterator has failed to be reset", keys, hasItems(1L, 2L));
    }

}

<code block>


package com.hazelcast.util.collection;

import com.hazelcast.util.collection.BiInt2ObjectMap.EntryConsumer;
import com.hazelcast.util.function.Consumer;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.HashSet;
import java.util.Set;

import static org.hamcrest.CoreMatchers.either;
import static org.hamcrest.CoreMatchers.is;
import static org.hamcrest.Matchers.greaterThan;
import static org.hamcrest.core.IsEqual.equalTo;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertThat;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class BiInt2ObjectMapTest {
    private final BiInt2ObjectMap<String> map = new BiInt2ObjectMap<String>();

    @Test public void shouldInitialiseUnderlyingImplementation() {
        final int initialCapacity = 10;
        final double loadFactor = 0.6;
        final BiInt2ObjectMap<String> map = new BiInt2ObjectMap<String>(initialCapacity, loadFactor);

        assertThat(map.capacity(), either(is(initialCapacity)).or(greaterThan(initialCapacity)));
        assertThat(map.loadFactor(), is(loadFactor));
    }

    @Test public void shouldReportEmpty() {
        assertThat(map.isEmpty(), is(true));
    }

    @Test public void shouldPutItem() {
        final String testValue = "Test";
        final int keyPartA = 3;
        final int keyPartB = 7;

        assertNull(map.put(keyPartA, keyPartB, testValue));
        assertThat(map.size(), is(1));
    }

    @Test public void shouldPutAndGetItem() {
        final String testValue = "Test";
        final int keyPartA = 3;
        final int keyPartB = 7;

        assertNull(map.put(keyPartA, keyPartB, testValue));
        assertThat(map.get(keyPartA, keyPartB), is(testValue));
    }

    @Test public void shouldReturnNullWhenNotFoundItem() {
        final int keyPartA = 3;
        final int keyPartB = 7;

        assertNull(map.get(keyPartA, keyPartB));
    }

    @Test public void shouldRemoveItem() {
        final String testValue = "Test";
        final int keyPartA = 3;
        final int keyPartB = 7;

        map.put(keyPartA, keyPartB, testValue);
        assertThat(map.remove(keyPartA, keyPartB), is(testValue));
        assertNull(map.get(keyPartA, keyPartB));
    }

    @Test public void shouldIterateValues() {
        final Set<String> expectedSet = new HashSet<String>();
        final int count = 7;

        for (int i = 0; i < count; i++) {
            final String value = String.valueOf(i);
            expectedSet.add(value);
            map.put(i, i + 97, value);
        }

        final Set<String> actualSet = new HashSet<String>();

        map.forEach(new Consumer<String>() {
            @Override public void accept(String s) {
                actualSet.add(s);
            }
        });

        assertThat(actualSet, equalTo(expectedSet));
    }

    @Test public void shouldIterateEntries() {
        final Set<EntryCapture<String>> expectedSet = new HashSet<EntryCapture<String>>();
        final int count = 7;

        for (int i = 0; i < count; i++) {
            final String value = String.valueOf(i);
            expectedSet.add(new EntryCapture<String>(i, i + 97, value));
            map.put(i, i + 97, value);
        }

        final Set<EntryCapture<String>> actualSet = new HashSet<EntryCapture<String>>();

        map.forEach(new EntryConsumer<String>() {
            @Override public void accept(int keyPartA, int keyPartB, String value) {
                actualSet.add(new EntryCapture<String>(keyPartA, keyPartB, value));
            }
        });

        assertThat(actualSet, equalTo(expectedSet));
    }

    public static class EntryCapture<V> {
        public final int keyPartA;
        public final int keyPartB;
        public final V value;

        public EntryCapture(final int keyPartA, final int keyPartB, final V value) {
            this.keyPartA = keyPartA;
            this.keyPartB = keyPartB;
            this.value = value;
        }

        public boolean equals(final Object o) {
            if (this == o) {
                return true;
            }

            if (o == null || getClass() != o.getClass()) {
                return false;
            }

            final EntryCapture that = (EntryCapture) o;

            return keyPartA == that.keyPartA && keyPartB == that.keyPartB && value.equals(that.value);

        }

        public int hashCode() {
            int result = keyPartA;
            result = 31 * result + keyPartB;
            result = 31 * result + value.hashCode();

            return result;
        }
    }
}

<code block>


package com.hazelcast.util.collection;


import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Assert;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.Collection;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;

import static java.lang.Long.valueOf;
import static org.hamcrest.core.Is.is;
import static org.hamcrest.core.IsEqual.equalTo;
import static org.hamcrest.number.IsCloseTo.closeTo;
import static org.hamcrest.number.OrderingComparison.lessThan;
import static org.junit.Assert.assertThat;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class Long2ObjectHashMapTest {
    private final Long2ObjectHashMap<String> longToObjectMap = new Long2ObjectHashMap<String>();

    @Test public void shouldDoPutAndThenGet() {
        final String value = "Seven";
        longToObjectMap.put(7, value);

        assertThat(longToObjectMap.get(7), is(value));
    }

    @Test public void shouldReplaceExistingValueForTheSameKey() {
        final long key = 7;
        final String value = "Seven";
        longToObjectMap.put(key, value);

        final String newValue = "New Seven";
        final String oldValue = longToObjectMap.put(key, newValue);

        assertThat(longToObjectMap.get(key), is(newValue));
        assertThat(oldValue, is(value));
        assertThat(valueOf(longToObjectMap.size()), is(valueOf(1)));
    }

    @Test public void shouldGrowWhenThresholdExceeded() {
        final double loadFactor = 0.5d;
        final Long2ObjectHashMap<String> map = new Long2ObjectHashMap<String>(32, loadFactor);
        for (int i = 0; i < 16; i++) {
            map.put(i, Long.toString(i));
        }

        assertThat(valueOf(map.resizeThreshold()), is(valueOf(16)));
        assertThat(valueOf(map.capacity()), is(valueOf(32)));
        assertThat(valueOf(map.size()), is(valueOf(16)));

        map.put(16, "16");

        assertThat(valueOf(map.resizeThreshold()), is(valueOf(32)));
        assertThat(valueOf(map.capacity()), is(valueOf(64)));
        assertThat(valueOf(map.size()), is(valueOf(17)));

        assertThat(map.get(16), equalTo("16"));
        assertThat(loadFactor, closeTo(map.loadFactor(), 0.0));

    }

    @Test public void shouldHandleCollisionAndThenLinearProbe() {
        final double loadFactor = 0.5d;
        final Long2ObjectHashMap<String> map = new Long2ObjectHashMap<String>(32, loadFactor);
        final long key = 7;
        final String value = "Seven";
        map.put(key, value);

        final long collisionKey = key + map.capacity();
        final String collisionValue = Long.toString(collisionKey);
        map.put(collisionKey, collisionValue);

        assertThat(map.get(key), is(value));
        assertThat(map.get(collisionKey), is(collisionValue));
        assertThat(loadFactor, closeTo(map.loadFactor(), 0.0));
    }

    @Test public void shouldClearCollection() {
        for (int i = 0; i < 15; i++) {
            longToObjectMap.put(i, Long.toString(i));
        }

        assertThat(valueOf(longToObjectMap.size()), is(valueOf(15)));
        assertThat(longToObjectMap.get(1), is("1"));

        longToObjectMap.clear();

        assertThat(valueOf(longToObjectMap.size()), is(valueOf(0)));
        Assert.assertNull(longToObjectMap.get(1));
    }

    @Test public void shouldCompactCollection() {
        final int totalItems = 50;
        for (int i = 0; i < totalItems; i++) {
            longToObjectMap.put(i, Long.toString(i));
        }

        for (int i = 0, limit = totalItems - 4; i < limit; i++) {
            longToObjectMap.remove(i);
        }

        final int capacityBeforeCompaction = longToObjectMap.capacity();
        longToObjectMap.compact();

        assertThat(valueOf(longToObjectMap.capacity()), lessThan(valueOf(capacityBeforeCompaction)));
    }

    @Test public void shouldContainValue() {
        final long key = 7;
        final String value = "Seven";

        longToObjectMap.put(key, value);

        Assert.assertTrue(longToObjectMap.containsValue(value));
        Assert.assertFalse(longToObjectMap.containsValue("NoKey"));
    }

    @Test public void shouldContainKey() {
        final long key = 7;
        final String value = "Seven";

        longToObjectMap.put(key, value);

        Assert.assertTrue(longToObjectMap.containsKey(key));
        Assert.assertFalse(longToObjectMap.containsKey(0));
    }

    @Test public void shouldRemoveEntry() {
        final long key = 7;
        final String value = "Seven";

        longToObjectMap.put(key, value);

        Assert.assertTrue(longToObjectMap.containsKey(key));

        longToObjectMap.remove(key);

        Assert.assertFalse(longToObjectMap.containsKey(key));
    }

    @Test public void shouldRemoveEntryAndCompactCollisionChain() {
        final long key = 12;
        final String value = "12";

        longToObjectMap.put(key, value);
        longToObjectMap.put(13, "13");

        final long collisionKey = key + longToObjectMap.capacity();
        final String collisionValue = Long.toString(collisionKey);

        longToObjectMap.put(collisionKey, collisionValue);
        longToObjectMap.put(14, "14");

        assertThat(longToObjectMap.remove(key), is(value));
    }

    @Test public void shouldIterateValues() {
        final Collection<String> initialSet = new HashSet<String>();

        for (int i = 0; i < 11; i++) {
            final String value = Long.toString(i);
            longToObjectMap.put(i, value);
            initialSet.add(value);
        }

        final Collection<String> copyToSet = new HashSet<String>(longToObjectMap.values());

        assertThat(copyToSet, is(initialSet));
    }

    @Test public void shouldIterateKeysGettingLongAsPrimitive() {
        final Collection<Long> initialSet = new HashSet<Long>();

        for (int i = 0; i < 11; i++) {
            final String value = Long.toString(i);
            longToObjectMap.put(i, value);
            initialSet.add(valueOf(i));
        }

        final Collection<Long> copyToSet = new HashSet<Long>();

        for (final Long2ObjectHashMap.KeyIterator iter = longToObjectMap.keySet().iterator(); iter.hasNext(); ) {
            copyToSet.add(valueOf(iter.nextLong()));
        }

        assertThat(copyToSet, is(initialSet));
    }

    @Test public void shouldIterateKeys() {
        final Collection<Long> initialSet = new HashSet<Long>();

        for (int i = 0; i < 11; i++) {
            final String value = Long.toString(i);
            longToObjectMap.put(i, value);
            initialSet.add(valueOf(i));
        }

        final Collection<Long> copyToSet = new HashSet<Long>(longToObjectMap.keySet());

        assertThat(copyToSet, is(initialSet));
    }

    @Test public void shouldIterateAndHandleRemove() {
        final Collection<Long> initialSet = new HashSet<Long>();

        final int count = 11;
        for (int i = 0; i < count; i++) {
            final String value = Long.toString(i);
            longToObjectMap.put(i, value);
            initialSet.add(valueOf(i));
        }

        final Collection<Long> copyOfSet = new HashSet<Long>();

        int i = 0;
        for (final Iterator<Long> iter = longToObjectMap.keySet().iterator(); iter.hasNext(); ) {
            final Long item = iter.next();
            if (i++ == 7) {
                iter.remove();
            } else {
                copyOfSet.add(item);
            }
        }

        assertThat(valueOf(initialSet.size()), is(valueOf(count)));
        final int reducedSetSize = count - 1;
        assertThat(valueOf(longToObjectMap.size()), is(valueOf(reducedSetSize)));
        assertThat(valueOf(copyOfSet.size()), is(valueOf(reducedSetSize)));
    }

    @Test public void shouldIterateEntries() {
        final int count = 11;
        for (int i = 0; i < count; i++) {
            final String value = Long.toString(i);
            longToObjectMap.put(i, value);
        }

        final String testValue = "Wibble";
        for (final Map.Entry<Long, String> entry : longToObjectMap.entrySet()) {
            assertThat(entry.getKey(), equalTo(valueOf(entry.getValue())));

            if (entry.getKey().intValue() == 7) {
                entry.setValue(testValue);
            }
        }

        assertThat(longToObjectMap.get(7), equalTo(testValue));
    }

    @Test public void shouldGenerateStringRepresentation() {
        final int[] testEntries = {3, 1, 19, 7, 11, 12, 7};

        for (final int testEntry : testEntries) {
            longToObjectMap.put(testEntry, String.valueOf(testEntry));
        }

        final String mapAsAString = "{7=7, 12=12, 19=19, 3=3, 11=11, 1=1}";
        assertThat(longToObjectMap.toString(), equalTo(mapAsAString));
    }
}


<code block>


package com.hazelcast.util.collection;

import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.Iterator;

import static org.hamcrest.Matchers.contains;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotEquals;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertThat;
import static org.junit.Assert.assertTrue;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class IntHashSetTest {
    private final IntHashSet obj = new IntHashSet(100, -1);

    @Test public void initiallyContainsNoElements() throws Exception {
        for (int i = 0; i < 10000; i++) {
            assertFalse(obj.contains(i));
        }
    }

    @Test public void initiallyContainsNoBoxedElements() {
        for (int i = 0; i < 10000; i++) {
            assertFalse(obj.contains(Integer.valueOf(i)));
        }
    }

    @Test public void containsAddedBoxedElement() {
        assertTrue(obj.add(1));

        assertTrue(obj.contains(1));
    }

    @Test public void addingAnElementTwiceDoesNothing() {
        assertTrue(obj.add(1));

        assertFalse(obj.add(1));
    }

    @Test public void containsAddedBoxedElements() {
        assertTrue(obj.add(1));
        assertTrue(obj.add(Integer.valueOf(2)));

        assertTrue(obj.contains(Integer.valueOf(1)));
        assertTrue(obj.contains(2));
    }

    @Test public void removingAnElementFromAnEmptyListDoesNothing() {
        assertFalse(obj.remove(0));
    }

    @Test public void removingAPresentElementRemovesIt() {
        assertTrue(obj.add(1));

        assertTrue(obj.remove(1));

        assertFalse(obj.contains(1));
    }

    @Test public void sizeIsInitiallyZero() {
        assertEquals(0, obj.size());
    }

    @Test public void sizeIncrementsWithNumberOfAddedElements() {
        obj.add(1);
        obj.add(2);

        assertEquals(2, obj.size());
    }

    @Test public void sizeContainsNumberOfNewElements() {
        obj.add(1);
        obj.add(1);

        assertEquals(1, obj.size());
    }

    @Test public void iteratorsListElements() {
        obj.add(1);
        obj.add(2);

        assertIteratorHasElements();
    }

    @Test public void iteratorsStartFromTheBeginningEveryTime() {
        iteratorsListElements();

        assertIteratorHasElements();
    }

    @Test public void clearRemovesAllElementsOfTheSet() {
        obj.add(1);
        obj.add(2);

        obj.clear();

        assertEquals(0, obj.size());
        assertFalse(obj.contains(1));
        assertFalse(obj.contains(2));
    }

    @Test public void differenceReturnsNullIfBothSetsEqual() {
        obj.add(1);
        obj.add(2);

        final IntHashSet other = new IntHashSet(100, -1);
        other.add(1);
        other.add(2);

        assertNull(obj.difference(other));
    }

    @Test public void differenceReturnsSetDifference() {
        obj.add(1);
        obj.add(2);

        final IntHashSet other = new IntHashSet(100, -1);
        other.add(1);

        final IntHashSet diff = obj.difference(other);
        assertEquals(1, diff.size());
        assertTrue(diff.contains(2));
    }

    @Test public void copiesOtherIntHashSet() {
        obj.add(1);
        obj.add(2);

        final IntHashSet other = new IntHashSet(100, -1);
        other.copy(obj);

        assertThat(other, contains(1, 2));
    }

    @Test public void twoEmptySetsAreEqual() {
        final IntHashSet other = new IntHashSet(100, -1);
        assertEquals(obj, other);
    }

    @Test public void equalityRequiresTheSameMissingValue() {
        final IntHashSet other = new IntHashSet(100, 1);
        assertNotEquals(obj, other);
    }

    @Test public void setsWithTheSameValuesAreEqual() {
        final IntHashSet other = new IntHashSet(100, -1);

        obj.add(1);
        obj.add(1001);

        other.add(1);
        other.add(1001);

        assertEquals(obj, other);
    }

    @Test public void setsWithTheDifferentSizesAreNotEqual() {
        final IntHashSet other = new IntHashSet(100, -1);

        obj.add(1);
        obj.add(1001);

        other.add(1001);

        assertNotEquals(obj, other);
    }

    @Test public void setsWithTheDifferentValuesAreNotEqual() {
        final IntHashSet other = new IntHashSet(100, -1);

        obj.add(1);
        obj.add(1001);

        other.add(2);
        other.add(1001);

        assertNotEquals(obj, other);
    }

    @Test public void twoEmptySetsHaveTheSameHashcode() {
        final IntHashSet other = new IntHashSet(100, -1);
        assertEquals(obj.hashCode(), other.hashCode());
    }

    @Test public void setsWithTheSameValuesHaveTheSameHashcode() {
        final IntHashSet other = new IntHashSet(100, -1);

        obj.add(1);
        obj.add(1001);

        other.add(1);
        other.add(1001);

        assertEquals(obj.hashCode(), other.hashCode());
    }

    private void assertIteratorHasElements() {
        final Iterator<Integer> iter = obj.iterator();

        assertTrue(iter.hasNext());
        assertEquals(Integer.valueOf(1), iter.next());
        assertTrue(iter.hasNext());
        assertEquals(Integer.valueOf(2), iter.next());
        assertFalse(iter.hasNext());
    }
}

<code block>



package com.hazelcast.collection;

<code block>
package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.impl.DefaultData;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashSet;
import java.util.List;
import java.util.Set;


public class MessageFlyweight {
    
    private static final long LONG_MASK = 0x00000000FFFFFFFFL;
    
    private static final int INT_MASK = 0x0000FFFF;
    
    private static final short SHORT_MASK = 0x00FF;

    private int offset; 
    private int index; 
    protected ClientProtocolBuffer buffer;


    public MessageFlyweight() {
        offset = 0;
    }

    public MessageFlyweight wrap(ClientProtocolBuffer buffer, int offset) {
        this.buffer = buffer;
        this.offset = offset;
        this.index = 0;
        return this;
    }

    public int index() {
        return index;
    }

    public MessageFlyweight index(int index) {
        this.index = index;
        return this;
    }

    public ClientProtocolBuffer buffer() {
        return buffer;
    }

    
    public MessageFlyweight set(boolean value) {
        buffer.putByte(index + offset, (byte) (value ? 1 : 0));
        index += Bits.BYTE_SIZE_IN_BYTES;
        return this;
    }

    public MessageFlyweight set(int value) {
        buffer.putInt(index + offset, value);
        index += Bits.INT_SIZE_IN_BYTES;
        return this;
    }

    public MessageFlyweight set(long value) {
        buffer.putLong(index + offset, value);
        index += Bits.LONG_SIZE_IN_BYTES;
        return this;
    }

    public MessageFlyweight set(String value) {
        index += buffer.putStringUtf8(index + offset, value);
        return this;
    }

    public MessageFlyweight set(Data data) {
        final byte[] bytes = data.toByteArray();
        set(bytes);
        return this;
    }

    public MessageFlyweight set(final byte[] value) {
        final int length = value.length;
        set(length);
        buffer.putBytes(index + offset, value);
        index += length;
        return this;
    }

    public MessageFlyweight set(final Collection<Data> value) {
        final int length = value.size();
        set(length);
        for (Data v : value) {
            set(v);
        }
        return this;
    }

    

    
    public boolean getBoolean() {
        byte result = buffer.getByte(index + offset);
        index += Bits.BYTE_SIZE_IN_BYTES;
        return result != 0;
    }

    public int getInt() {
        int result = buffer.getInt(index + offset);
        index += Bits.INT_SIZE_IN_BYTES;
        return result;
    }

    public long getLong() {
        long result = buffer.getLong(index + offset);
        index += Bits.LONG_SIZE_IN_BYTES;
        return result;
    }

    public String getStringUtf8() {
        final int length = buffer.getInt(index + offset);
        String result = buffer.getStringUtf8(index + offset, length);
        index += length + Bits.INT_SIZE_IN_BYTES;
        return result;
    }

    public byte[] getByteArray() {
        final int length = buffer.getInt(index + offset);
        index += Bits.INT_SIZE_IN_BYTES;
        byte[] result = new byte[length];
        buffer.getBytes(index + offset, result);
        index += length;
        return result;
    }

    public Data getData() {
        return new DefaultData(getByteArray());
    }

    public List<Data> getDataList() {
        final int length = buffer.getInt(index + offset);
        index += Bits.INT_SIZE_IN_BYTES;
        final List<Data> result = new ArrayList<Data>();
        for (int i = 0; i < length; i++) {
            result.add(getData());
        }
        return result;
    }

    public Set<Data> getDataSet() {
        final int length = buffer.getInt(index + offset);
        index += Bits.INT_SIZE_IN_BYTES;
        final Set<Data> result = new HashSet<Data>();
        for (int i = 0; i < length; i++) {
            result.add(getData());
        }
        return result;
    }

    

    protected int int32Get(int index) {
        return buffer.getInt(index + offset);
    }

    protected void int32Set(int index, int length) {
        buffer.putInt(index + offset, length);
    }

    protected short uint8Get(int index) {
        return (short) (buffer.getByte(index + offset) & SHORT_MASK);
    }

    protected void uint8Put(int index, short value) {
        buffer.putByte(index + offset, (byte) value);
    }

    protected int uint16Get(int index) {
        return buffer.getShort(index + offset) & INT_MASK;
    }

    protected void uint16Put(int index, int value) {
        buffer.putShort(index + offset, (short) value);
    }

    protected long uint32Get(int index) {
        return buffer.getInt(index + offset) & LONG_MASK;
    }

    protected void uint32Put(int index, long value) {
        buffer.putInt(index + offset, (int) value);
    }

}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;
import com.hazelcast.nio.serialization.Data;

public class ParameterUtil {

    public static int calculateStringDataSize(String string) {
        return Bits.INT_SIZE_IN_BYTES + string.length() * 4;
    }

    public static int calculateByteArrayDataSize(byte[] bytes) {
        return Bits.INT_SIZE_IN_BYTES + bytes.length;
    }

    public static int calculateDataSize(Data key) {
        return calculateByteArrayDataSize(key.toByteArray());
    }
}

<code block>


package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;

import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.charset.Charset;


public class SafeBuffer implements ClientProtocolBuffer {

    public static final Charset UTF_8 = Charset.forName("utf-8");
    private ByteBuffer byteBuffer;

    public SafeBuffer(byte[] buffer) {
        wrap(buffer);
    }

    @Override
    public void putLong(int index, long value) {
        byteBuffer.putLong(index, value);
    }

    @Override
    public void putInt(int index, int value) {
        byteBuffer.putInt(index, value);
    }

    @Override
    public void putShort(int index, short value) {
        byteBuffer.putShort(index, value);
    }

    @Override
    public void putByte(int index, byte value) {
        byteBuffer.put(index, value);
    }

    @Override
    public void putBytes(int index, byte[] src) {
        putBytes(index, src, 0, src.length);
    }

    @Override
    public void putBytes(int index, byte[] src, int offset, int length) {
        byteBuffer.position(index);
        byteBuffer.put(src, offset, length);
    }

    @Override
    public int putStringUtf8(int index, String value) {
        return putStringUtf8(index, value, Integer.MAX_VALUE);
    }

    @Override
    public int putStringUtf8(int index, String value, int maxEncodedSize) {
        final byte[] bytes = value.getBytes(UTF_8);
        if (bytes.length > maxEncodedSize) {
            throw new IllegalArgumentException("Encoded string larger than maximum size: " + maxEncodedSize);
        }

        putInt(index, bytes.length);
        putBytes(index + Bits.INT_SIZE_IN_BYTES, bytes);

        return Bits.INT_SIZE_IN_BYTES + bytes.length;
    }

    @Override
    public void wrap(byte[] buffer) {
        byteBuffer = ByteBuffer.wrap(buffer);
        byteBuffer.order(ByteOrder.LITTLE_ENDIAN);
    }

    @Override
    public byte[] byteArray() {
        return byteBuffer.array();
    }

    @Override
    public int capacity() {
        return byteBuffer.capacity();
    }

    @Override
    public long getLong(int index) {

        return byteBuffer.getLong(index);
    }

    @Override
    public int getInt(int index) {
        return byteBuffer.getInt(index);
    }

    @Override
    public short getShort(int index) {
        return byteBuffer.getShort(index);
    }

    @Override
    public byte getByte(int index) {
        return byteBuffer.get(index);
    }

    @Override
    public void getBytes(int index, byte[] dst) {
        getBytes(index, dst, 0, dst.length);
    }

    @Override
    public void getBytes(int index, byte[] dst, int offset, int length) {
        byteBuffer.position(index);
        byteBuffer.get(dst, offset, length);
    }

    @Override
    public String getStringUtf8(int offset, int length) {
        final byte[] stringInBytes = new byte[length];
        getBytes(offset + Bits.INT_SIZE_IN_BYTES, stringInBytes);

        return new String(stringInBytes, UTF_8);
    }

}

<code block>

package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.util.QuickMath;

import java.util.Arrays;


public class BufferBuilder {
    public static final int INITIAL_CAPACITY = 4096;

    private static final String PROP_HAZELCAST_PROTOCOL_UNSAFE = "hazelcast.protocol.unsafe.enabled";
    private static final boolean USE_UNSAFE = Boolean.getBoolean(PROP_HAZELCAST_PROTOCOL_UNSAFE);

    private final ClientProtocolBuffer protocolBuffer;

    private int position;
    private int capacity;

    
    public BufferBuilder() {
        this(INITIAL_CAPACITY);
    }

    
    private BufferBuilder(int initialCapacity) {
        capacity = QuickMath.nextPowerOfTwo(initialCapacity);
        if (USE_UNSAFE) {
            protocolBuffer = new UnsafeBuffer(new byte[capacity]);
        } else {
            protocolBuffer = new SafeBuffer(new byte[capacity]);

        }
    }

    
    public int capacity() {
        return capacity;
    }

    
    public int position() {
        return position;
    }

    
    public ClientProtocolBuffer buffer() {
        return protocolBuffer;
    }

    
    public BufferBuilder append(ClientProtocolBuffer srcBuffer, int srcOffset, int length) {
        ensureCapacity(length);

        srcBuffer.getBytes(srcOffset, protocolBuffer.byteArray(), position, length);
        position += length;

        return this;
    }

    private void ensureCapacity(int additionalCapacity) {
        int requiredCapacity = position + additionalCapacity;

        if (requiredCapacity < 0) {
            String s = String.format("Insufficient capacity: position=%d additional=%d", position, additionalCapacity);
            throw new IllegalStateException(s);
        }

        if (requiredCapacity > capacity) {
            int newCapacity = QuickMath.nextPowerOfTwo(requiredCapacity);
            byte[] newBuffer = Arrays.copyOf(protocolBuffer.byteArray(), newCapacity);

            capacity = newCapacity;
            protocolBuffer.wrap(newBuffer);
        }
    }
}

<code block>
package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.client.impl.protocol.ClientMessage;

import java.nio.ByteBuffer;

import static com.hazelcast.client.impl.protocol.ClientMessage.BEGIN_AND_END_FLAGS;
import static com.hazelcast.client.impl.protocol.ClientMessage.BEGIN_FLAG;
import static com.hazelcast.client.impl.protocol.ClientMessage.END_FLAG;


public class ClientMessageBuilder {

    private final Int2ObjectHashMap<BufferBuilder> builderBySessionIdMap = new Int2ObjectHashMap<BufferBuilder>();

    private final MessageHandler delegate;
    private ClientMessage message = ClientMessage.create();

    public ClientMessageBuilder(MessageHandler delegate) {
        this.delegate = delegate;
    }

    public void onData(final ByteBuffer buffer) {
        while (buffer.hasRemaining()) {
            final boolean complete = message.readFrom(buffer);
            if (!complete) {
                return;
            }

            
            if (message.isFlagSet(BEGIN_AND_END_FLAGS)) {
                
                handleMessage(message);
                message = ClientMessage.create();
                continue;
            }

            if (message.isFlagSet(BEGIN_FLAG)) {     
                final BufferBuilder builder = new BufferBuilder();
                builderBySessionIdMap.put(message.getCorrelationId(), builder);
                builder.append(message.buffer(), 0, message.getFrameLength());
            } else {
                final BufferBuilder builder = builderBySessionIdMap.get(message.getCorrelationId());
                if (builder.position() == 0) {
                    throw new IllegalStateException();
                }

                builder.append(message.buffer(), message.getDataOffset(), message.getFrameLength() - message.getDataOffset());

                if (message.isFlagSet(END_FLAG)) {
                    final int msgLength = builder.position();
                    ClientMessage cm = ClientMessage.createForDecode(builder.buffer(), 0);
                    cm.setFrameLength(msgLength);
                    
                    handleMessage(cm);
                    builderBySessionIdMap.remove(message.getCorrelationId());

                }
            }

            message = ClientMessage.create();
        }
    }

    private void handleMessage(ClientMessage message) {
        message.index(message.getDataOffset());
        delegate.handleMessage(message);
    }

    
    public interface MessageHandler {

        
        void handleMessage(ClientMessage message);
    }


}

<code block>

package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.util.QuickMath;

import java.util.AbstractCollection;
import java.util.AbstractSet;
import java.util.Arrays;
import java.util.Collection;
import java.util.Iterator;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Set;

import static com.hazelcast.util.Preconditions.checkNotNull;


@edu.umd.cs.findbugs.annotations.SuppressWarnings({"PZ_DONT_REUSE_ENTRY_OBJECTS_IN_ITERATORS"})
public class Int2ObjectHashMap<V>
        implements Map<Integer, V> {
    private final double loadFactor;
    private int resizeThreshold;
    private int capacity;
    private int mask;
    private int size;

    private int[] keys;
    private Object[] values;

    
    private final ValueCollection<V> valueCollection = new ValueCollection<V>();
    private final KeySet keySet = new KeySet();
    private final EntrySet<V> entrySet = new EntrySet<V>();

    public Int2ObjectHashMap() {
        this(8, 0.6);
    }

    
    public Int2ObjectHashMap(final int initialCapacity, final double loadFactor) {
        this.loadFactor = loadFactor;
        capacity = QuickMath.nextPowerOfTwo(initialCapacity);
        mask = capacity - 1;
        resizeThreshold = (int) (capacity * loadFactor);

        keys = new int[capacity];
        values = new Object[capacity];
    }

    
    public double loadFactor() {
        return loadFactor;
    }

    
    public int capacity() {
        return capacity;
    }

    
    public int resizeThreshold() {
        return resizeThreshold;
    }

    
    public int size() {
        return size;
    }

    
    public boolean isEmpty() {
        return 0 == size;
    }

    
    public boolean containsKey(final Object key) {
        checkNotNull(key, "Null keys are not permitted");

        return containsKey(((Integer) key).intValue());
    }

    
    public boolean containsKey(final int key) {
        int index = hash(key);

        while (null != values[index]) {
            if (key == keys[index]) {
                return true;
            }

            index = ++index & mask;
        }

        return false;
    }

    
    public boolean containsValue(final Object value) {
        checkNotNull(value, "Null values are not permitted");

        for (final Object v : values) {
            if (null != v && value.equals(v)) {
                return true;
            }
        }

        return false;
    }

    
    public V get(final Object key) {
        return get(((Integer) key).intValue());
    }

    
    @SuppressWarnings("unchecked")
    public V get(final int key) {
        int index = hash(key);

        Object value;
        while (null != (value = values[index])) {
            if (key == keys[index]) {
                return (V) value;
            }

            index = ++index & mask;
        }

        return null;
    }

    
    public V getOrDefault(final int key, final Supplier<V> supplier) {
        V value = get(key);
        if (value == null) {
            value = supplier.get();
            put(key, value);
        }

        return value;
    }


    
    public V put(final Integer key, final V value) {
        return put(key.intValue(), value);
    }

    
    @SuppressWarnings("unchecked")
    public V put(final int key, final V value) {
        checkNotNull(value, "Value cannot be null");

        V oldValue = null;
        int index = hash(key);

        while (null != values[index]) {
            if (key == keys[index]) {
                oldValue = (V) values[index];
                break;
            }

            index = ++index & mask;
        }

        if (null == oldValue) {
            ++size;
            keys[index] = key;
        }

        values[index] = value;

        if (size > resizeThreshold) {
            increaseCapacity();
        }

        return oldValue;
    }

    
    public V remove(final Object key) {
        return remove(((Integer) key).intValue());
    }

    
    @SuppressWarnings("unchecked")
    public V remove(final int key) {
        int index = hash(key);

        Object value;
        while (null != (value = values[index])) {
            if (key == keys[index]) {
                values[index] = null;
                --size;

                compactChain(index);

                return (V) value;
            }

            index = ++index & mask;
        }

        return null;
    }

    
    public void clear() {
        size = 0;
        Arrays.fill(values, null);
    }

    
    public void compact() {
        final int idealCapacity = (int) Math.round(size() * (1.0d / loadFactor));
        rehash(QuickMath.nextPowerOfTwo(idealCapacity));
    }

    
    public void putAll(final Map<? extends Integer, ? extends V> map) {
        for (final Entry<? extends Integer, ? extends V> entry : map.entrySet()) {
            put(entry.getKey(), entry.getValue());
        }
    }

    
    public KeySet keySet() {
        return keySet;
    }

    
    public Collection<V> values() {
        return valueCollection;
    }

    
    public Set<Entry<Integer, V>> entrySet() {
        return entrySet;
    }

    
    public String toString() {
        final StringBuilder sb = new StringBuilder();
        sb.append('{');

        for (final Entry<Integer, V> entry : entrySet()) {
            sb.append(entry.getKey().intValue());
            sb.append('=');
            sb.append(entry.getValue());
            sb.append(", ");
        }

        if (sb.length() > 1) {
            sb.setLength(sb.length() - 2);
        }

        sb.append('}');

        return sb.toString();
    }

    private void increaseCapacity() {
        final int newCapacity = capacity << 1;
        if (newCapacity < 0) {
            throw new IllegalStateException("Max capacity reached at size=" + size);
        }

        rehash(newCapacity);
    }

    private void rehash(final int newCapacity) {
        if (1 != Integer.bitCount(newCapacity)) {
            throw new IllegalStateException("New capacity must be a power of two");
        }

        capacity = newCapacity;
        mask = newCapacity - 1;
        resizeThreshold = (int) (newCapacity * loadFactor);

        final int[] tempKeys = new int[capacity];
        final Object[] tempValues = new Object[capacity];

        for (int i = 0, size = values.length; i < size; i++) {
            final Object value = values[i];
            if (null != value) {
                final int key = keys[i];
                int newHash = hash(key);
                while (null != tempValues[newHash]) {
                    newHash = ++newHash & mask;
                }

                tempKeys[newHash] = key;
                tempValues[newHash] = value;
            }
        }

        keys = tempKeys;
        values = tempValues;
    }

    private void compactChain(int deleteIndex) {
        int index = deleteIndex;
        while (true) {
            index = ++index & mask;
            if (null == values[index]) {
                return;
            }

            final int hash = hash(keys[index]);

            if ((index < hash && (hash <= deleteIndex || deleteIndex <= index)) || (hash <= deleteIndex
                    && deleteIndex <= index)) {
                keys[deleteIndex] = keys[index];
                values[deleteIndex] = values[index];

                values[index] = null;
                deleteIndex = index;
            }
        }
    }

    private int hash(final int key) {
        final int hash = (key << 1) - (key << 8);
        return hash & mask;
    }

    
    
    

    public class KeySet
            extends AbstractSet<Integer> {
        public int size() {
            return Int2ObjectHashMap.this.size();
        }

        public boolean isEmpty() {
            return Int2ObjectHashMap.this.isEmpty();
        }

        public boolean contains(final Object o) {
            return Int2ObjectHashMap.this.containsKey(o);
        }

        public boolean contains(final int key) {
            return Int2ObjectHashMap.this.containsKey(key);
        }

        public KeyIterator iterator() {
            return new KeyIterator();
        }

        public boolean remove(final Object o) {
            return null != Int2ObjectHashMap.this.remove(o);
        }

        public boolean remove(final int key) {
            return null != Int2ObjectHashMap.this.remove(key);
        }

        public void clear() {
            Int2ObjectHashMap.this.clear();
        }
    }

    private class ValueCollection<V>
            extends AbstractCollection<V> {
        public int size() {
            return Int2ObjectHashMap.this.size();
        }

        public boolean isEmpty() {
            return Int2ObjectHashMap.this.isEmpty();
        }

        public boolean contains(final Object o) {
            return Int2ObjectHashMap.this.containsValue(o);
        }

        public ValueIterator<V> iterator() {
            return new ValueIterator<V>();
        }

        public void clear() {
            Int2ObjectHashMap.this.clear();
        }
    }

    private class EntrySet<V>
            extends AbstractSet<Entry<Integer, V>> {
        public int size() {
            return Int2ObjectHashMap.this.size();
        }

        public boolean isEmpty() {
            return Int2ObjectHashMap.this.isEmpty();
        }

        public Iterator<Entry<Integer, V>> iterator() {
            return new EntryIterator<V>();
        }

        public void clear() {
            Int2ObjectHashMap.this.clear();
        }
    }

    
    
    

    private abstract class AbstractIterator<T>
            implements Iterator<T> {
        private int posCounter;
        private int stopCounter;
        private boolean isPositionValid = false;
        protected final int[] keys = Int2ObjectHashMap.this.keys;
        protected final Object[] values = Int2ObjectHashMap.this.values;

        protected AbstractIterator() {
            int i = capacity;
            if (null != values[capacity - 1]) {
                i = 0;
                for (int size = capacity; i < size; i++) {
                    if (null == values[i]) {
                        break;
                    }
                }
            }

            stopCounter = i;
            posCounter = i + capacity;
        }

        protected int getPosition() {
            return posCounter & mask;
        }

        public boolean hasNext() {
            for (int i = posCounter - 1; i >= stopCounter; i--) {
                final int index = i & mask;
                if (null != values[index]) {
                    return true;
                }
            }

            return false;
        }

        protected void findNext() {
            isPositionValid = false;

            for (int i = posCounter - 1; i >= stopCounter; i--) {
                final int index = i & mask;
                if (null != values[index]) {
                    posCounter = i;
                    isPositionValid = true;
                    return;
                }
            }

            throw new NoSuchElementException();
        }

        public abstract T next();

        public void remove() {
            if (isPositionValid) {
                final int position = getPosition();
                values[position] = null;
                --size;

                compactChain(position);

                isPositionValid = false;
            } else {
                throw new IllegalStateException();
            }
        }
    }

    public class ValueIterator<T>
            extends AbstractIterator<T> {
        @SuppressWarnings("unchecked")
        public T next() {
            findNext();

            return (T) values[getPosition()];
        }
    }

    public class KeyIterator
            extends AbstractIterator<Integer> {
        public Integer next() {
            return nextInt();
        }

        public int nextInt() {
            findNext();

            return keys[getPosition()];
        }
    }

    @SuppressWarnings("unchecked")
    public class EntryIterator<V>
            extends AbstractIterator<Entry<Integer, V>>
            implements Entry<Integer, V> {
        public Entry<Integer, V> next() {
            findNext();

            return this;
        }

        public Integer getKey() {
            return keys[getPosition()];
        }

        public V getValue() {
            return (V) values[getPosition()];
        }

        public V setValue(final V value) {
            checkNotNull(value, "value cannot be null");

            final int pos = getPosition();
            final Object oldValue = values[pos];
            values[pos] = value;

            return (V) oldValue;
        }
    }

    public interface Supplier<T> {

        
        T get();
    }

}

<code block>

package com.hazelcast.client.impl.protocol.util;

import com.hazelcast.nio.Bits;
import com.hazelcast.nio.UnsafeHelper;
import sun.misc.Unsafe;

import java.nio.ByteOrder;
import java.nio.charset.Charset;

;


@edu.umd.cs.findbugs.annotations.SuppressWarnings({"EI_EXPOSE_REP", "EI_EXPOSE_REP2"})
public class UnsafeBuffer implements ClientProtocolBuffer {
    
    public static final Charset UTF_8 = Charset.forName("utf-8");

    private static final String DISABLE_BOUNDS_CHECKS_PROP_NAME = "hazelcast.disable.bounds.checks";
    private static final boolean SHOULD_BOUNDS_CHECK = !Boolean.getBoolean(DISABLE_BOUNDS_CHECKS_PROP_NAME);

    private static final ByteOrder NATIVE_BYTE_ORDER = ByteOrder.nativeOrder();
    private static final ByteOrder PROTOCOL_BYTE_ORDER = ByteOrder.LITTLE_ENDIAN;
    private static final Unsafe UNSAFE = UnsafeHelper.UNSAFE;
    private static final long ARRAY_BASE_OFFSET = UNSAFE.arrayBaseOffset(byte[].class);

    private byte[] byteArray;
    private long addressOffset;

    private int capacity;

    
    public UnsafeBuffer(final byte[] buffer) {
        wrap(buffer);
    }

    @Override
    public void wrap(final byte[] buffer) {
        addressOffset = ARRAY_BASE_OFFSET;
        capacity = buffer.length;
        byteArray = buffer;
    }

    @Override
    public byte[] byteArray() {
        return byteArray;
    }

    @Override
    public int capacity() {
        return capacity;
    }

    

    @Override
    public long getLong(final int index) {
        boundsCheck(index, Bits.LONG_SIZE_IN_BYTES);

        long bits = UNSAFE.getLong(byteArray, addressOffset + index);
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Long.reverseBytes(bits);
        }

        return bits;
    }

    @Override
    public void putLong(final int index, final long value) {
        boundsCheck(index, Bits.LONG_SIZE_IN_BYTES);

        long bits = value;
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Long.reverseBytes(bits);
        }

        UNSAFE.putLong(byteArray, addressOffset + index, bits);
    }

    

    @Override
    public int getInt(final int index) {
        boundsCheck(index, Bits.INT_SIZE_IN_BYTES);

        int bits = UNSAFE.getInt(byteArray, addressOffset + index);
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Integer.reverseBytes(bits);
        }

        return bits;
    }

    @Override
    public void putInt(final int index, final int value) {
        boundsCheck(index, Bits.INT_SIZE_IN_BYTES);

        int bits = value;
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Integer.reverseBytes(bits);
        }

        UNSAFE.putInt(byteArray, addressOffset + index, bits);
    }


    

    @Override
    public short getShort(final int index) {
        boundsCheck(index, Bits.SHORT_SIZE_IN_BYTES);

        short bits = UNSAFE.getShort(byteArray, addressOffset + index);
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Short.reverseBytes(bits);
        }

        return bits;
    }

    @Override
    public void putShort(final int index, final short value) {
        boundsCheck(index, Bits.SHORT_SIZE_IN_BYTES);

        short bits = value;
        if (NATIVE_BYTE_ORDER != PROTOCOL_BYTE_ORDER) {
            bits = Short.reverseBytes(bits);
        }

        UNSAFE.putShort(byteArray, addressOffset + index, bits);
    }

    @Override
    public byte getByte(final int index) {
        boundsCheck(index, Bits.BYTE_SIZE_IN_BYTES);

        return UNSAFE.getByte(byteArray, addressOffset + index);
    }

    @Override
    public void putByte(final int index, final byte value) {
        boundsCheck(index, Bits.BYTE_SIZE_IN_BYTES);

        UNSAFE.putByte(byteArray, addressOffset + index, value);
    }

    @Override
    public void getBytes(final int index, final byte[] dst) {
        getBytes(index, dst, 0, dst.length);
    }

    @Override
    public void getBytes(final int index, final byte[] dst, final int offset, final int length) {
        boundsCheck(index, length);
        boundsCheck(dst, offset, length);

        UNSAFE.copyMemory(byteArray, addressOffset + index, dst, ARRAY_BASE_OFFSET + offset, length);
    }

    @Override
    public void putBytes(final int index, final byte[] src) {
        putBytes(index, src, 0, src.length);
    }

    @Override
    public void putBytes(final int index, final byte[] src, final int offset, final int length) {
        boundsCheck(index, length);
        boundsCheck(src, offset, length);

        UNSAFE.copyMemory(src, ARRAY_BASE_OFFSET + offset, byteArray, addressOffset + index, length);
    }

    @Override
    public String getStringUtf8(final int offset, final int length) {
        final byte[] stringInBytes = new byte[length];
        getBytes(offset + Bits.INT_SIZE_IN_BYTES, stringInBytes);

        return new String(stringInBytes, UTF_8);
    }

    @Override
    public int putStringUtf8(final int index, final String value) {
        return putStringUtf8(index, value, Integer.MAX_VALUE);
    }

    @Override
    public int putStringUtf8(final int index, final String value, final int maxEncodedSize) {
        final byte[] bytes = value.getBytes(UTF_8);
        if (bytes.length > maxEncodedSize) {
            throw new IllegalArgumentException("Encoded string larger than maximum size: " + maxEncodedSize);
        }

        putInt(index, bytes.length);
        putBytes(index + Bits.INT_SIZE_IN_BYTES, bytes);

        return Bits.INT_SIZE_IN_BYTES + bytes.length;
    }

    

    private void boundsCheck(final int index, final int length) {
        if (SHOULD_BOUNDS_CHECK) {
            if (index < 0 || length < 0 || (index + length) > capacity) {
                throw new IndexOutOfBoundsException(String.format("index=%d, length=%d, capacity=%d", index, length, capacity));
            }
        }
    }

    private static void boundsCheck(final byte[] buffer, final int index, final int length) {
        if (SHOULD_BOUNDS_CHECK) {
            final int capacity = buffer.length;
            if (index < 0 || length < 0 || (index + length) > capacity) {
                throw new IndexOutOfBoundsException(String.format("index=%d, length=%d, capacity=%d", index, length, capacity));
            }
        }
    }
}

<code block>


package com.hazelcast.util;


public final class QuickMath {

    private QuickMath() {
    }

    
    public static boolean isPowerOfTwo(long x) {
        return (x & (x - 1)) == 0;
    }

    
    public static int modPowerOfTwo(int a, int b) {
        return a & (b - 1);
    }

    
    public static long modPowerOfTwo(long a, int b) {
        return a & (b - 1);
    }

    
    public static int nextPowerOfTwo(int value) {
        if (!isPowerOfTwo(value)) {
            value--;
            value |= value >> 1;
            value |= value >> 2;
            value |= value >> 4;
            value |= value >> 8;
            value |= value >> 16;
            value++;
        }
        return value;
    }

    
    public static long nextPowerOfTwo(long value) {
        if (!isPowerOfTwo(value)) {
            value--;
            value |= value >> 1;
            value |= value >> 2;
            value |= value >> 4;
            value |= value >> 8;
            value |= value >> 16;
            value |= value >> 32;
            value++;
        }
        return value;
    }

    
    public static int log2(int value) {
        return 31 - Integer.numberOfLeadingZeros(value);
    }

    
    public static int log2(long value) {
        return 63 - Long.numberOfLeadingZeros(value);
    }

    
    public static int divideByAndCeilToInt(double d, int k) {
        return (int) Math.ceil(d / k);
    }

    
    public static long divideByAndCeilToLong(double d, int k) {
        return (long) Math.ceil(d / k);
    }

    
    public static int divideByAndRoundToInt(double d, int k) {
        return (int) Math.rint(d / k);
    }

    
    public static long divideByAndRoundToLong(double d, int k) {
        return (long) Math.rint(d / k);
    }

    
    public static int normalize(int value, int factor) {
        return divideByAndCeilToInt(value, factor) * factor;
    }

    
    public static long normalize(long value, int factor) {
        return divideByAndCeilToLong(value, factor) * factor;
    }

    public static String bytesToHex(byte[] in) {
        final char[] hexArray = "0123456789abcdef".toCharArray();

        char[] hexChars = new char[in.length * 2];
        for (int j = 0; j < in.length; j++) {
            int v = in[j] & 0xff;
            hexChars[j * 2] = hexArray[v >>> 4];
            hexChars[j * 2 + 1] = hexArray[v & 0xf];
        }
        return new String(hexChars);
    }

    
    public static int compareIntegers(int i1, int i2) {
        if (i1 > i2) {
            return +1;
        } else if (i2 > i1) {
            return -1;
        } else {
            return 0;
        }
    }

    
    public static int compareLongs(long l1, long l2) {
        if (l1 > l2) {
            return +1;
        } else if (l2 > l1) {
            return -1;
        } else {
            return 0;
        }
    }

}

<code block>


package com.hazelcast.util;

import static com.hazelcast.partition.InternalPartition.MAX_BACKUP_COUNT;
import static java.lang.String.format;


public final class Preconditions {

    private Preconditions() {
    }


    
    public static <T> T checkNotNull(T argument, String errorMessage) {
        if (argument == null) {
            throw new NullPointerException(errorMessage);
        }
        return argument;
    }

    
    public static String checkHasText(String argument, String errorMessage) {
        if (argument == null || argument.isEmpty()) {
            throw new IllegalArgumentException(errorMessage);
        }

        return argument;
    }

    
    public static <E> E isNotNull(E argument, String argName) {
        if (argument == null) {
            throw new IllegalArgumentException(format("argument '%s' can't be null", argName));
        }

        return argument;
    }

    
    public static long checkNotNegative(long value, String errorMessage) {
        if (value < 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static int checkNotNegative(int value, String errorMessage) {
        if (value < 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static long checkNegative(long value, String errorMessage) {
        if (value >= 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static long checkPositive(long value, String errorMessage) {
        if (value <= 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static int checkPositive(int value, String errorMessage) {
        if (value <= 0) {
            throw new IllegalArgumentException(errorMessage);
        }
        return value;
    }

    
    public static int checkBackupCount(int newBackupCount, int currentAsyncBackupCount) {
        if (newBackupCount < 0) {
            throw new IllegalArgumentException("backup-count can't be smaller than 0");
        }

        if (currentAsyncBackupCount < 0) {
            throw new IllegalArgumentException("async-backup-count can't be smaller than 0");
        }

        if (newBackupCount > MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("backup-count can't be larger than than " + MAX_BACKUP_COUNT);
        }

        if (newBackupCount + currentAsyncBackupCount > MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("the sum of backup-count and async-backup-count can't be larger than than "
                    + MAX_BACKUP_COUNT);
        }

        return newBackupCount;
    }

    
    public static int checkAsyncBackupCount(int currentBackupCount, int newAsyncBackupCount) {
        if (currentBackupCount < 0) {
            throw new IllegalArgumentException("backup-count can't be smaller than 0");
        }

        if (newAsyncBackupCount < 0) {
            throw new IllegalArgumentException("async-backup-count can't be smaller than 0");
        }

        if (newAsyncBackupCount > MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("async-backup-count can't be larger than than " + MAX_BACKUP_COUNT);
        }

        if (currentBackupCount + newAsyncBackupCount > MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("the sum of backup-count and async-backup-count can't be larger than than "
                    + MAX_BACKUP_COUNT);
        }

        return newAsyncBackupCount;
    }

    
    public static <E> E checkInstanceOf(Class type, E object, String errorMessage) {
        isNotNull(type, "type");
        if (!type.isInstance(object)) {
            throw new IllegalArgumentException(errorMessage);
        }
        return object;
    }

    
    public static <E> E checkNotInstanceOf(Class type, E object, String errorMessage) {
        isNotNull(type, "type");
        if (type.isInstance(object)) {
            throw new IllegalArgumentException(errorMessage);
        }
        return object;
    }

    
    public static void checkFalse(boolean expression, String errorMessage) {
        if (expression) {
            throw new IllegalArgumentException(errorMessage);
        }
    }

    
    public static void checkTrue(boolean expression, String errorMessage) {
        if (!expression) {
            throw new IllegalArgumentException(errorMessage);
        }
    }
}


<code block>


package com.hazelcast.nio;


public final class Bits {

    
    public static final int BYTE_SIZE_IN_BYTES = 1;
    
    public static final int BOOLEAN_SIZE_IN_BYTES = 1;
    
    public static final int SHORT_SIZE_IN_BYTES = 2;
    
    public static final int CHAR_SIZE_IN_BYTES = 2;
    
    public static final int INT_SIZE_IN_BYTES = 4;
    
    public static final int FLOAT_SIZE_IN_BYTES = 4;
    
    public static final int LONG_SIZE_IN_BYTES = 8;
    
    public static final int DOUBLE_SIZE_IN_BYTES = 8;
    
    public static final int CACHE_LINE_LENGTH = 64;

    private Bits() {
    }

    public static char readChar(byte[] buffer, int pos, boolean bigEndian) {
        return bigEndian ? readCharB(buffer, pos) : readCharL(buffer, pos);
    }

    public static char readCharB(byte[] buffer, int pos) {
        int byte1 = buffer[pos] & 0xFF;
        int byte0 = buffer[pos + 1] & 0xFF;
        return (char) ((byte1 << 8) + byte0);
    }

    public static char readCharL(byte[] buffer, int pos) {
        int byte1 = buffer[pos] & 0xFF;
        int byte0 = buffer[pos + 1] & 0xFF;
        return (char) ((byte0 << 8) + byte1);
    }

    public static void writeChar(byte[] buffer, int pos, char v, boolean bigEndian) {
        if (bigEndian) {
            writeCharB(buffer, pos, v);
        } else {
            writeCharL(buffer, pos, v);
        }
    }

    public static void writeCharB(byte[] buffer, int pos, char v) {
        buffer[pos] = (byte) ((v >>> 8) & 0xFF);
        buffer[pos + 1] = (byte) ((v) & 0xFF);
    }

    public static void writeCharL(byte[] buffer, int pos, char v) {
        buffer[pos] = (byte) ((v) & 0xFF);
        buffer[pos + 1] = (byte) ((v >>> 8) & 0xFF);
    }

    public static short readShort(byte[] buffer, int pos, boolean bigEndian) {
        return bigEndian ? readShortB(buffer, pos) : readShortL(buffer, pos);
    }

    public static short readShortB(byte[] buffer, int pos) {
        int byte1 = buffer[pos] & 0xFF;
        int byte0 = buffer[pos + 1] & 0xFF;
        return (short) ((byte1 << 8) + byte0);
    }

    public static short readShortL(byte[] buffer, int pos) {
        int byte1 = buffer[pos] & 0xFF;
        int byte0 = buffer[pos + 1] & 0xFF;
        return (short) ((byte0 << 8) + byte1);
    }

    public static void writeShort(byte[] buffer, int pos, short v, boolean bigEndian) {
        if (bigEndian) {
            writeShortB(buffer, pos, v);
        } else {
            writeShortL(buffer, pos, v);
        }
    }

    public static void writeShortB(byte[] buffer, int pos, short v) {
        buffer[pos] = (byte) ((v >>> 8) & 0xFF);
        buffer[pos + 1] = (byte) ((v) & 0xFF);
    }

    public static void writeShortL(byte[] buffer, int pos, short v) {
        buffer[pos] = (byte) ((v) & 0xFF);
        buffer[pos + 1] = (byte) ((v >>> 8) & 0xFF);
    }

    public static int readInt(byte[] buffer, int pos, boolean bigEndian) {
        if (bigEndian) {
            return readIntB(buffer, pos);
        } else {
            return readIntL(buffer, pos);
        }
    }

    public static int readIntB(byte[] buffer, int pos) {
        int byte3 = (buffer[pos] & 0xFF) << 24;
        int byte2 = (buffer[pos + 1] & 0xFF) << 16;
        int byte1 = (buffer[pos + 2] & 0xFF) << 8;
        int byte0 = buffer[pos + 3] & 0xFF;
        return byte3 + byte2 + byte1 + byte0;
    }

    public static int readIntL(byte[] buffer, int pos) {
        int byte3 = buffer[pos] & 0xFF;
        int byte2 = (buffer[pos + 1] & 0xFF) << 8;
        int byte1 = (buffer[pos + 2] & 0xFF) << 16;
        int byte0 = (buffer[pos + 3] & 0xFF) << 24;
        return byte3 + byte2 + byte1 + byte0;
    }

    public static void writeInt(byte[] buffer, int pos, int v, boolean bigEndian) {
        if (bigEndian) {
            writeIntB(buffer, pos, v);
        } else {
            writeIntL(buffer, pos, v);
        }
    }

    public static void writeIntB(byte[] buffer, int pos, int v) {
        buffer[pos] = (byte) ((v >>> 24) & 0xFF);
        buffer[pos + 1] = (byte) ((v >>> 16) & 0xFF);
        buffer[pos + 2] = (byte) ((v >>> 8) & 0xFF);
        buffer[pos + 3] = (byte) ((v) & 0xFF);
    }

    public static void writeIntL(byte[] buffer, int pos, int v) {
        buffer[pos] = (byte) ((v) & 0xFF);
        buffer[pos + 1] = (byte) ((v >>> 8) & 0xFF);
        buffer[pos + 2] = (byte) ((v >>> 16) & 0xFF);
        buffer[pos + 3] = (byte) ((v >>> 24) & 0xFF);
    }

    public static long readLong(byte[] buffer, int pos, boolean bigEndian) {
        if (bigEndian) {
            return readLongB(buffer, pos);
        } else {
            return readLongL(buffer, pos);
        }
    }

    public static long readLongB(byte[] buffer, int pos) {
        long byte7 = (long) buffer[pos] << 56;
        long byte6 = (long) (buffer[pos + 1] & 0xFF) << 48;
        long byte5 = (long) (buffer[pos + 2] & 0xFF) << 40;
        long byte4 = (long) (buffer[pos + 3] & 0xFF) << 32;
        long byte3 = (long) (buffer[pos + 4] & 0xFF) << 24;
        long byte2 = (long) (buffer[pos + 5] & 0xFF) << 16;
        long byte1 = (long) (buffer[pos + 6] & 0xFF) << 8;
        long byte0 = (long) (buffer[pos + 7] & 0xFF);
        return byte7 + byte6 + byte5 + byte4 + byte3 + byte2 + byte1 + byte0;
    }

    public static long readLongL(byte[] buffer, int pos) {
        long byte7 = (long) (buffer[pos] & 0xFF);
        long byte6 = (long) (buffer[pos + 1] & 0xFF) << 8;
        long byte5 = (long) (buffer[pos + 2] & 0xFF) << 16;
        long byte4 = (long) (buffer[pos + 3] & 0xFF) << 24;
        long byte3 = (long) (buffer[pos + 4] & 0xFF) << 32;
        long byte2 = (long) (buffer[pos + 5] & 0xFF) << 40;
        long byte1 = (long) (buffer[pos + 6] & 0xFF) << 48;
        long byte0 = (long) (buffer[pos + 7] & 0xFF) << 56;
        return byte7 + byte6 + byte5 + byte4 + byte3 + byte2 + byte1 + byte0;
    }

    public static void writeLong(byte[] buffer, int pos, long v, boolean bigEndian) {
        if (bigEndian) {
            writeLongB(buffer, pos, v);
        } else {
            writeLongL(buffer, pos, v);
        }
    }

    public static void writeLongB(byte[] buffer, int pos, long v) {
        buffer[pos] = (byte) (v >>> 56);
        buffer[pos + 1] = (byte) (v >>> 48);
        buffer[pos + 2] = (byte) (v >>> 40);
        buffer[pos + 3] = (byte) (v >>> 32);
        buffer[pos + 4] = (byte) (v >>> 24);
        buffer[pos + 5] = (byte) (v >>> 16);
        buffer[pos + 6] = (byte) (v >>> 8);
        buffer[pos + 7] = (byte) (v);
    }

    public static void writeLongL(byte[] buffer, int pos, long v) {
        buffer[pos] = (byte) (v);
        buffer[pos + 1] = (byte) (v >>> 8);
        buffer[pos + 2] = (byte) (v >>> 16);
        buffer[pos + 3] = (byte) (v >>> 24);
        buffer[pos + 4] = (byte) (v >>> 32);
        buffer[pos + 5] = (byte) (v >>> 40);
        buffer[pos + 6] = (byte) (v >>> 48);
        buffer[pos + 7] = (byte) (v >>> 56);
    }

    
    public static byte setBit(byte value, int bit) {
        value |= 1 << bit;
        return value;
    }

    
    public static byte clearBit(byte value, int bit) {
        value &= ~(1 << bit);
        return value;
    }

    
    public static byte invertBit(byte value, int bit) {
        value ^= 1 << bit;
        return value;
    }

    
    public static int setBit(int value, int bit) {
        value |= 1 << bit;
        return value;
    }

    
    public static int clearBit(int value, int bit) {
        value &= ~(1 << bit);
        return value;
    }

    
    public static int invertBit(int value, int bit) {
        value ^= 1 << bit;
        return value;
    }

    
    public static boolean isBitSet(int value, int bit) {
        return (value & 1 << bit) != 0;
    }

    
    public static int combineToInt(short x, short y) {
        return ((int) x << 16) | ((int) y & 0xFFFF);
    }

    public static short extractShort(int value, boolean lowerBits) {
        return (short) ((lowerBits) ? value : (value >> 16));
    }

    
    public static long combineToLong(int x, int y) {
        return ((long) x << 32) | ((long) y & 0xFFFFFFFFL);
    }

    public static int extractInt(long value, boolean lowerBits) {
        return (int) ((lowerBits) ? value : (value >> 32));
    }
}

<code block>

package com.hazelcast.client.protocol;

import com.hazelcast.client.impl.protocol.util.Int2ObjectHashMap;
import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Assert;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.util.Collection;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;

import static java.lang.Integer.valueOf;
import static org.hamcrest.core.Is.is;
import static org.hamcrest.core.IsEqual.equalTo;
import static org.hamcrest.number.IsCloseTo.closeTo;
import static org.hamcrest.number.OrderingComparison.lessThan;
import static org.junit.Assert.assertThat;

@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class Int2ObjectHashMapTest
{
    private final Int2ObjectHashMap<String> intToObjectMap = new Int2ObjectHashMap<String>();

    @Test
    public void shouldDoPutAndThenGet()
    {
        final String value = "Seven";
        intToObjectMap.put(7, value);

        assertThat(intToObjectMap.get(7), is(value));
    }

    @Test
    public void shouldReplaceExistingValueForTheSameKey()
    {
        final int key = 7;
        final String value = "Seven";
        intToObjectMap.put(key, value);

        final String newValue = "New Seven";
        final String oldValue = intToObjectMap.put(key, newValue);

        assertThat(intToObjectMap.get(key), is(newValue));
        assertThat(oldValue, is(value));
        assertThat(valueOf(intToObjectMap.size()), is(valueOf(1)));
    }

    @Test
    public void shouldGrowWhenThresholdExceeded()
    {
        final double loadFactor = 0.5d;
        final Int2ObjectHashMap<String> map = new Int2ObjectHashMap<String>(32, loadFactor);
        for (int i = 0; i < 16; i++)
        {
            map.put(i, Integer.toString(i));
        }

        assertThat(valueOf(map.resizeThreshold()), is(valueOf(16)));
        assertThat(valueOf(map.capacity()), is(valueOf(32)));
        assertThat(valueOf(map.size()), is(valueOf(16)));

        map.put(16, "16");

        assertThat(valueOf(map.resizeThreshold()), is(valueOf(32)));
        assertThat(valueOf(map.capacity()), is(valueOf(64)));
        assertThat(valueOf(map.size()), is(valueOf(17)));

        assertThat(map.get(16), equalTo("16"));
        assertThat(loadFactor, closeTo(map.loadFactor(), 0.0));
    }

    @Test
    public void shouldHandleCollisionAndThenLinearProbe()
    {
        final double loadFactor = 0.5d;
        final Int2ObjectHashMap<String> map = new Int2ObjectHashMap<String>(32, loadFactor);
        final int key = 7;
        final String value = "Seven";
        map.put(key, value);

        final int collisionKey = key + map.capacity();
        final String collisionValue = Integer.toString(collisionKey);
        map.put(collisionKey, collisionValue);

        assertThat(map.get(key), is(value));
        assertThat(map.get(collisionKey), is(collisionValue));
        assertThat(loadFactor, closeTo(map.loadFactor(), 0.0));
    }

    @Test
    public void shouldClearCollection()
    {
        for (int i = 0; i < 15; i++)
        {
            intToObjectMap.put(i, Integer.toString(i));
        }

        assertThat(valueOf(intToObjectMap.size()), is(valueOf(15)));
        assertThat(intToObjectMap.get(1), is("1"));

        intToObjectMap.clear();

        assertThat(valueOf(intToObjectMap.size()), is(valueOf(0)));
        Assert.assertNull(intToObjectMap.get(1));
    }

    @Test
    public void shouldCompactCollection()
    {
        final int totalItems = 50;
        for (int i = 0; i < totalItems; i++)
        {
            intToObjectMap.put(i, Integer.toString(i));
        }

        for (int i = 0, limit = totalItems - 4; i < limit; i++)
        {
            intToObjectMap.remove(i);
        }

        final int capacityBeforeCompaction = intToObjectMap.capacity();
        intToObjectMap.compact();

        assertThat(valueOf(intToObjectMap.capacity()), lessThan(valueOf(capacityBeforeCompaction)));
    }

    @Test
    public void shouldContainValue()
    {
        final int key = 7;
        final String value = "Seven";

        intToObjectMap.put(key, value);

        Assert.assertTrue(intToObjectMap.containsValue(value));
        Assert.assertFalse(intToObjectMap.containsValue("NoKey"));
    }

    @Test
    public void shouldContainKey()
    {
        final int key = 7;
        final String value = "Seven";

        intToObjectMap.put(key, value);

        Assert.assertTrue(intToObjectMap.containsKey(key));
        Assert.assertFalse(intToObjectMap.containsKey(0));
    }

    @Test
    public void shouldRemoveEntry()
    {
        final int key = 7;
        final String value = "Seven";

        intToObjectMap.put(key, value);

        Assert.assertTrue(intToObjectMap.containsKey(key));

        intToObjectMap.remove(key);

        Assert.assertFalse(intToObjectMap.containsKey(key));
    }

    @Test
    public void shouldRemoveEntryAndCompactCollisionChain()
    {
        final int key = 12;
        final String value = "12";

        intToObjectMap.put(key, value);
        intToObjectMap.put(13, "13");

        final int collisionKey = key + intToObjectMap.capacity();
        final String collisionValue = Integer.toString(collisionKey);

        intToObjectMap.put(collisionKey, collisionValue);
        intToObjectMap.put(14, "14");

        assertThat(intToObjectMap.remove(key), is(value));
    }

    @Test
    public void shouldIterateValues()
    {
        final Collection<String> initialSet = new HashSet<String>();

        for (int i = 0; i < 11; i++)
        {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
            initialSet.add(value);
        }

        final Collection<String> copyToSet = new HashSet<String>();

        for (final String s : intToObjectMap.values())
        {
            copyToSet.add(s);
        }

        assertThat(copyToSet, is(initialSet));
    }

    @Test
    public void shouldIterateKeysGettingIntAsPrimitive()
    {
        final Collection<Integer> initialSet = new HashSet<Integer>();

        for (int i = 0; i < 11; i++)
        {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
            initialSet.add(valueOf(i));
        }

        final Collection<Integer> copyToSet = new HashSet<Integer>();

        for (final Int2ObjectHashMap.KeyIterator iter = intToObjectMap.keySet().iterator(); iter.hasNext();)
        {
            copyToSet.add(valueOf(iter.nextInt()));
        }

        assertThat(copyToSet, is(initialSet));
    }

    @Test
    public void shouldIterateKeys()
    {
        final Collection<Integer> initialSet = new HashSet<Integer>();

        for (int i = 0; i < 11; i++)
        {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
            initialSet.add(valueOf(i));
        }

        final Collection<Integer> copyToSet = new HashSet<Integer>();

        for (final Integer aInteger : intToObjectMap.keySet())
        {
            copyToSet.add(aInteger);
        }

        assertThat(copyToSet, is(initialSet));
    }

    @Test
    public void shouldIterateAndHandleRemove()
    {
        final Collection<Integer> initialSet = new HashSet<Integer>();

        final int count = 11;
        for (int i = 0; i < count; i++)
        {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
            initialSet.add(valueOf(i));
        }

        final Collection<Integer> copyOfSet = new HashSet<Integer>();

        int i = 0;
        for (final Iterator<Integer> iter = intToObjectMap.keySet().iterator(); iter.hasNext();)
        {
            final Integer item = iter.next();
            if (i++ == 7)
            {
                iter.remove();
            }
            else
            {
                copyOfSet.add(item);
            }
        }

        final int reducedSetSize = count - 1;
        assertThat(valueOf(initialSet.size()), is(valueOf(count)));
        assertThat(valueOf(intToObjectMap.size()), is(valueOf(reducedSetSize)));
        assertThat(valueOf(copyOfSet.size()), is(valueOf(reducedSetSize)));
    }

    @Test
    public void shouldIterateEntries()
    {
        final int count = 11;
        for (int i = 0; i < count; i++)
        {
            final String value = Integer.toString(i);
            intToObjectMap.put(i, value);
        }

        final String testValue = "Wibble";
        for (final Map.Entry<Integer, String> entry : intToObjectMap.entrySet())
        {
            assertThat(entry.getKey(), equalTo(valueOf(entry.getValue())));

            if (entry.getKey() == 7)
            {
                entry.setValue(testValue);
            }
        }

        assertThat(intToObjectMap.get(7), equalTo(testValue));
    }

    @Test
    public void shouldGenerateStringRepresentation()
    {
        final int[] testEntries = {3, 1, 19, 7, 11, 12, 7};

        for (final int testEntry : testEntries)
        {
            intToObjectMap.put(testEntry, String.valueOf(testEntry));
        }

        final String mapAsAString = "{7=7, 12=12, 19=19, 3=3, 11=11, 1=1}";
        assertThat(intToObjectMap.toString(), equalTo(mapAsAString));
    }
}


<code block>


package com.hazelcast.util;

import com.hazelcast.test.HazelcastSerialClassRunner;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import java.math.BigInteger;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;


@RunWith(HazelcastSerialClassRunner.class)
@Category(QuickTest.class)
public class QuickMathTest {

    @Test
    public void testIsPowerOfTwo() {
        assertTrue(QuickMath.isPowerOfTwo(1));
        assertTrue(QuickMath.isPowerOfTwo(2));
        assertFalse(QuickMath.isPowerOfTwo(3));
        assertTrue(QuickMath.isPowerOfTwo(1024));
        assertFalse(QuickMath.isPowerOfTwo(1023));
        assertFalse(QuickMath.isPowerOfTwo(Integer.MAX_VALUE));
    }

    @Test
    public void testNextPowerOfTwo() {
        assertEquals(2, QuickMath.nextPowerOfTwo(2));
        assertEquals(1024, QuickMath.nextPowerOfTwo(999));
        assertEquals(1 << 23, QuickMath.nextPowerOfTwo((1 << 23) - 1));
        assertEquals(1 << 23, QuickMath.nextPowerOfTwo(1 << 23));

        assertEquals(2048L, QuickMath.nextPowerOfTwo(2000L));
        assertEquals(1L << 33, QuickMath.nextPowerOfTwo((1L << 33) - 3));
        assertEquals(1L << 43, QuickMath.nextPowerOfTwo((1L << 43)));
    }

    @Test
    public void testModPowerOfTwo() {
        int[] aParams = new int[]{
                0, 1, Integer.MAX_VALUE / 2, Integer.MAX_VALUE
        };
        int[] bParams = new int[]{
                1, 2, 1024, powerOfTwo(10), powerOfTwo(20)
        };

        for (int a : aParams) {
            for (int b : bParams) {
                assertEquals(a % b, QuickMath.modPowerOfTwo(a, b));
            }
        }
    }

    private int powerOfTwo(int x) {
        return BigInteger.valueOf(2).pow(x).intValue();
    }
}

<code block>


package com.hazelcast.cache.impl.nearcache.impl.store;

import com.hazelcast.cache.impl.eviction.EvictionChecker;
import com.hazelcast.cache.impl.eviction.EvictionListener;
import com.hazelcast.cache.impl.eviction.EvictionPolicyEvaluator;
import com.hazelcast.cache.impl.eviction.EvictionPolicyEvaluatorProvider;
import com.hazelcast.cache.impl.eviction.EvictionPolicyType;
import com.hazelcast.cache.impl.eviction.EvictionStrategy;
import com.hazelcast.cache.impl.eviction.EvictionStrategyProvider;
import com.hazelcast.cache.impl.maxsize.MaxSizeChecker;
import com.hazelcast.cache.impl.nearcache.NearCacheContext;
import com.hazelcast.cache.impl.nearcache.NearCacheRecord;
import com.hazelcast.cache.impl.nearcache.NearCacheRecordStore;
import com.hazelcast.cache.impl.nearcache.impl.NearCacheRecordMap;
import com.hazelcast.config.EvictionConfig;
import com.hazelcast.config.NearCacheConfig;
import com.hazelcast.monitor.NearCacheStats;
import com.hazelcast.monitor.impl.NearCacheStatsImpl;
import com.hazelcast.nio.UnsafeHelper;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;

public abstract class AbstractNearCacheRecordStore<
        K, V, KS, R extends NearCacheRecord, NCRM extends NearCacheRecordMap<KS, R>>
        implements NearCacheRecordStore<K, V>, EvictionListener<KS, R> {

    
    protected static final int REFERENCE_SIZE =
            UnsafeHelper.UNSAFE_AVAILABLE
                    ? UnsafeHelper.UNSAFE.arrayIndexScale(Object[].class)
                    : (Integer.SIZE / Byte.SIZE);

    private static final int MILLI_SECONDS_IN_A_SECOND = 1000;

    protected final long timeToLiveMillis;
    protected final long maxIdleMillis;

    protected final NearCacheConfig nearCacheConfig;
    protected final SerializationService serializationService;
    protected final NearCacheStatsImpl nearCacheStats;
    protected NCRM records;

    protected final MaxSizeChecker maxSizeChecker;
    protected final EvictionPolicyEvaluator<KS, R> evictionPolicyEvaluator;
    protected final EvictionChecker evictionChecker;
    protected final EvictionStrategy<KS, R, NCRM> evictionStrategy;

    public AbstractNearCacheRecordStore(NearCacheConfig nearCacheConfig, NearCacheContext nearCacheContext) {
        this(nearCacheConfig, nearCacheContext, new NearCacheStatsImpl());
    }

    public AbstractNearCacheRecordStore(NearCacheConfig nearCacheConfig, NearCacheContext nearCacheContext,
                                        NearCacheStatsImpl nearCacheStats) {
        this.nearCacheConfig = nearCacheConfig;
        this.timeToLiveMillis = nearCacheConfig.getTimeToLiveSeconds() * MILLI_SECONDS_IN_A_SECOND;
        this.maxIdleMillis = nearCacheConfig.getMaxIdleSeconds() * MILLI_SECONDS_IN_A_SECOND;
        this.serializationService = nearCacheContext.getSerializationService();
        this.nearCacheStats = nearCacheStats;
        this.records = createNearCacheRecordMap(nearCacheConfig, nearCacheContext);

        final EvictionConfig evictionConfig = nearCacheConfig.getEvictionConfig();
        if (evictionConfig != null) {
            this.maxSizeChecker = createNearCacheMaxSizeChecker(evictionConfig, nearCacheConfig, nearCacheContext);
            this.evictionPolicyEvaluator = createEvictionPolicyEvaluator(evictionConfig);
            this.evictionChecker = createEvictionChecker(nearCacheConfig);
            this.evictionStrategy = createEvictionStrategy(evictionConfig);
        } else {
            this.maxSizeChecker = null;
            this.evictionPolicyEvaluator = null;
            this.evictionChecker = null;
            this.evictionStrategy = null;
        }
    }

    protected abstract MaxSizeChecker createNearCacheMaxSizeChecker(EvictionConfig evictionConfig,
                                                                    NearCacheConfig nearCacheConfig,
                                                                    NearCacheContext nearCacheContext);

    protected abstract NCRM createNearCacheRecordMap(NearCacheConfig nearCacheConfig,
                                                     NearCacheContext nearCacheContext);

    protected abstract long getKeyStorageMemoryCost(K key);
    protected abstract long getRecordStorageMemoryCost(R record);

    protected abstract R valueToRecord(V value);
    protected abstract V recordToValue(R record);

    protected abstract R getRecord(K key);
    protected abstract R putRecord(K key, R record);
    protected abstract void putToRecord(R record, V value);
    protected abstract R removeRecord(K key);

    protected void checkAvailable() {
        if (!isAvailable()) {
            throw new IllegalStateException(nearCacheConfig.getName()
                    + " named near cache record store is not available");
        }
    }

    protected EvictionPolicyEvaluator<KS, R> createEvictionPolicyEvaluator(EvictionConfig evictionConfig) {
        final EvictionPolicyType evictionPolicyType = evictionConfig.getEvictionPolicyType();
        if (evictionPolicyType == null) {
            throw new IllegalArgumentException("Eviction policy cannot be null");
        }
        return EvictionPolicyEvaluatorProvider.getEvictionPolicyEvaluator(evictionConfig);
    }

    protected EvictionChecker createEvictionChecker(NearCacheConfig nearCacheConfig) {
        return new MaxSizeEvictionChecker();
    }

    protected EvictionStrategy<KS, R, NCRM> createEvictionStrategy(EvictionConfig evictionConfig) {
        return EvictionStrategyProvider.getEvictionStrategy(evictionConfig);
    }

    protected boolean isAvailable() {
        return records != null;
    }

    protected Data valueToData(V value) {
        if (value instanceof Data) {
            return (Data) value;
        } else if (value != null) {
            return serializationService.toData(value);
        } else {
            return null;
        }
    }

    protected V dataToValue(Data data) {
        if (data != null) {
            return serializationService.toObject(data);
        } else {
            return null;
        }
    }

    protected Data toData(Object obj) {
        if (obj == null) {
            return null;
        } else if (obj instanceof Data) {
            return (Data) obj;
        } else {
            return valueToData((V) obj);
        }
    }

    protected V toValue(Object obj) {
        if (obj == null) {
            return null;
        } else if (obj instanceof Data) {
            return dataToValue((Data) obj);
        } else {
            return (V) obj;
        }
    }

    protected long getTotalStorageMemoryCost(K key, R record) {
        return getKeyStorageMemoryCost(key) + getRecordStorageMemoryCost(record);
    }

    protected boolean isRecordExpired(R record) {
        long now = Clock.currentTimeMillis();
        if (record.isExpiredAt(now)) {
            return true;
        } else {
            return record.isIdleAt(maxIdleMillis, now);
        }
    }

    protected void onRecordCreate(R record) {
        record.setCreationTime(Clock.currentTimeMillis());
    }

    protected void onRecordAccess(R record) {
        record.setAccessTime(Clock.currentTimeMillis());
        record.incrementAccessHit();
    }

    protected void onGet(K key, V value, R record) {

    }

    protected void onGetError(K key, V value, R record, Throwable error) {

    }

    protected void onPut(K key, V value, R record, R oldRecord) {

    }

    protected void onPutError(K key, V value, R record, R oldRecord, Throwable error) {

    }

    protected void onRemove(K key, R record, boolean removed) {

    }

    protected void onRemoveError(K key, R record, boolean removed, Throwable error) {

    }

    protected boolean isEvictionEnabled() {
        return evictionStrategy != null && evictionPolicyEvaluator != null;
    }

    @Override
    public void onEvict(KS key, R record) {
        nearCacheStats.decrementOwnedEntryCount();
    }

    @Override
    public V get(K key) {
        checkAvailable();

        R record = null;
        V value = null;
        try {
            record = getRecord(key);
            if (record != null) {
                if (isRecordExpired(record)) {
                    remove(key);
                    return null;
                }
                onRecordAccess(record);
                nearCacheStats.incrementHits();
                value = recordToValue(record);
                onGet(key, value, record);
                return value;
            } else {
                nearCacheStats.incrementMisses();
                return null;
            }
        } catch (Throwable error) {
            onGetError(key, value, record, error);
            throw ExceptionUtil.rethrow(error);
        }
    }

    @Override
    public void put(K key, V value) {
        checkAvailable();

        R record = null;
        R oldRecord = null;
        try {
            record = valueToRecord(value);
            onRecordCreate(record);
            oldRecord = putRecord(key, record);
            if (oldRecord == null) {
                nearCacheStats.incrementOwnedEntryCount();
            } else {
                long oldRecordMemoryCost = getRecordStorageMemoryCost(oldRecord);
                nearCacheStats.decrementOwnedEntryMemoryCost(oldRecordMemoryCost);
            }
            onPut(key, value, record, oldRecord);
        } catch (Throwable error) {
            onPutError(key, value, record, oldRecord, error);
            throw ExceptionUtil.rethrow(error);
        }
    }

    @Override
    public boolean remove(K key) {
        checkAvailable();

        R record = null;
        boolean removed = false;
        try {
            record = removeRecord(key);
            if (record != null) {
                removed = true;
                nearCacheStats.decrementOwnedEntryCount();
            }
            onRemove(key, record, removed);
            return record != null;
        } catch (Throwable error) {
            onRemoveError(key, record, removed, error);
            throw ExceptionUtil.rethrow(error);
        }
    }

    protected void clearRecords() {
        records.clear();
    }

    @Override
    public void clear() {
        checkAvailable();

        clearRecords();
        nearCacheStats.setOwnedEntryCount(0);
        nearCacheStats.setOwnedEntryMemoryCost(0L);
    }

    protected void destroyStore() {
        clearRecords();
        
        records = null;
    }

    @Override
    public void destroy() {
        checkAvailable();

        destroyStore();
        nearCacheStats.setOwnedEntryCount(0);
        nearCacheStats.setOwnedEntryMemoryCost(0L);
    }

    @Override
    public int size() {
        checkAvailable();

        return records.size();
    }

    @Override
    public NearCacheStats getNearCacheStats() {
        checkAvailable();

        return nearCacheStats;
    }

    protected class MaxSizeEvictionChecker implements EvictionChecker {

        @Override
        public boolean isEvictionRequired() {
            if (maxSizeChecker != null) {
                return maxSizeChecker.isReachedToMaxSize();
            } else {
                return false;
            }
        }

    }

    @Override
    public void doEvictionIfRequired() {
        checkAvailable();

        if (isEvictionEnabled()) {
            evictionStrategy.evict(records, evictionPolicyEvaluator, evictionChecker, this);
        }
    }

    @Override
    public void doEviction() {
        checkAvailable();

        if (isEvictionEnabled()) {
            evictionStrategy.evict(records, evictionPolicyEvaluator, null, this);
        }
    }

}

<code block>


package com.hazelcast.client.cache.impl;

import com.hazelcast.cache.CacheStatistics;
import com.hazelcast.cache.impl.ICacheInternal;
import com.hazelcast.cache.impl.client.CacheGetAllRequest;
import com.hazelcast.cache.impl.client.CacheGetRequest;
import com.hazelcast.cache.impl.client.CacheSizeRequest;
import com.hazelcast.cache.impl.nearcache.NearCache;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.spi.ClientContext;
import com.hazelcast.client.spi.impl.ClientInvocation;
import com.hazelcast.client.spi.impl.ClientInvocationFuture;
import com.hazelcast.config.CacheConfig;
import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.ICompletableFuture;
import com.hazelcast.map.impl.MapEntrySet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.executor.DelegatingFuture;

import javax.cache.CacheException;
import javax.cache.expiry.ExpiryPolicy;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.Future;

import static com.hazelcast.cache.impl.CacheProxyUtil.validateNotNull;


abstract class AbstractClientCacheProxy<K, V>
        extends AbstractClientInternalCacheProxy<K, V>
        implements ICacheInternal<K, V> {

    protected AbstractClientCacheProxy(CacheConfig cacheConfig, ClientContext clientContext,
                                       HazelcastClientCacheManager cacheManager) {
        super(cacheConfig, clientContext, cacheManager);
    }

    protected Object getFromNearCache(Data keyData, boolean async) {
        Object cached = nearCache != null ? nearCache.get(keyData) : null;
        if (cached != null && NearCache.NULL_OBJECT != cached) {
            return !async ? cached : createCompletedFuture(cached);
        }
        return null;
    }

    protected Object getInternal(K key, ExpiryPolicy expiryPolicy, boolean async) {
        ensureOpen();
        validateNotNull(key);
        final Data keyData = toData(key);
        Object cached = getFromNearCache(keyData, async);
        if (cached != null) {
            return cached;
        }
        CacheGetRequest request = new CacheGetRequest(nameWithPrefix, keyData, expiryPolicy, cacheConfig.getInMemoryFormat());
        ClientInvocationFuture future;
        try {
            final int partitionId = clientContext.getPartitionService().getPartitionId(key);
            final HazelcastClientInstanceImpl client = (HazelcastClientInstanceImpl) clientContext.getHazelcastInstance();
            final ClientInvocation clientInvocation = new ClientInvocation(client, request, partitionId);
            future = clientInvocation.invoke();
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }
        if (async) {
            if (nearCache != null) {
                future.andThenInternal(new ExecutionCallback<Data>() {
                    public void onResponse(Data valueData) {
                        storeInNearCache(keyData, valueData, null);
                    }

                    public void onFailure(Throwable t) {
                    }
                });
            }
            return new DelegatingFuture<V>(future, clientContext.getSerializationService());
        } else {
            try {
                Object value = future.get();
                if (nearCache != null) {
                    storeInNearCache(keyData, toData(value), null);
                }
                return toObject(value);
            } catch (Throwable e) {
                throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
            }
        }
    }

    @Override
    public ICompletableFuture<V> getAsync(K key) {
        return getAsync(key, null);
    }

    @Override
    public ICompletableFuture<V> getAsync(K key, ExpiryPolicy expiryPolicy) {
        return (ICompletableFuture<V>) getInternal(key, expiryPolicy, true);
    }

    @Override
    public ICompletableFuture<Void> putAsync(K key, V value) {
        return putAsync(key, value, null);
    }

    @Override
    public ICompletableFuture<Void> putAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return putAsyncInternal(key, value, expiryPolicy, false, true);
    }

    @Override
    public ICompletableFuture<Boolean> putIfAbsentAsync(K key, V value) {
        return putIfAbsentAsyncInternal(key, value, null, false);
    }

    @Override
    public ICompletableFuture<Boolean> putIfAbsentAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return putIfAbsentAsyncInternal(key, value, expiryPolicy, false);
    }

    @Override
    public ICompletableFuture<V> getAndPutAsync(K key, V value) {
        return getAndPutAsync(key, value, null);
    }

    @Override
    public ICompletableFuture<V> getAndPutAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return putAsyncInternal(key, value, expiryPolicy, true, false);
    }

    @Override
    public ICompletableFuture<Boolean> removeAsync(K key) {
        return removeAsyncInternal(key, null, false, false, false);
    }

    @Override
    public ICompletableFuture<Boolean> removeAsync(K key, V oldValue) {
        return removeAsyncInternal(key, oldValue, true, false, false);
    }

    @Override
    public ICompletableFuture<V> getAndRemoveAsync(K key) {
        return removeAsyncInternal(key, null, false, true, false);
    }

    @Override
    public ICompletableFuture<Boolean> replaceAsync(K key, V value) {
        return replaceAsyncInternal(key, null, value, null, false, false, false);
    }

    @Override
    public ICompletableFuture<Boolean> replaceAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return replaceAsyncInternal(key, null, value, expiryPolicy, false, false, false);
    }

    @Override
    public ICompletableFuture<Boolean> replaceAsync(K key, V oldValue, V newValue) {
        return replaceAsyncInternal(key, oldValue, newValue, null, true, false, false);
    }

    @Override
    public ICompletableFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, ExpiryPolicy expiryPolicy) {
        return replaceAsyncInternal(key, oldValue, newValue, expiryPolicy, true, false, false);
    }

    @Override
    public ICompletableFuture<V> getAndReplaceAsync(K key, V value) {
        return replaceAsyncInternal(key, null, value, null, false, true, false);
    }

    @Override
    public ICompletableFuture<V> getAndReplaceAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return replaceAsyncInternal(key, null, value, expiryPolicy, false, true, false);
    }

    @Override
    public V get(K key, ExpiryPolicy expiryPolicy) {
        return (V) getInternal(key, expiryPolicy, false);
    }

    @Override
    public Map<K, V> getAll(Set<? extends K> keys, ExpiryPolicy expiryPolicy) {
        ensureOpen();
        validateNotNull(keys);
        if (keys.isEmpty()) {
            return Collections.EMPTY_MAP;
        }
        final Set<Data> keySet = new HashSet(keys.size());
        for (K key : keys) {
            final Data k = toData(key);
            keySet.add(k);
        }
        Map<K, V> result = getAllFromNearCache(keySet);
        if (keySet.isEmpty()) {
            return result;
        }
        final CacheGetAllRequest request = new CacheGetAllRequest(nameWithPrefix, keySet, expiryPolicy);
        final MapEntrySet mapEntrySet = toObject(invoke(request));
        final Set<Map.Entry<Data, Data>> entrySet = mapEntrySet.getEntrySet();
        for (Map.Entry<Data, Data> dataEntry : entrySet) {
            final Data keyData = dataEntry.getKey();
            final Data valueData = dataEntry.getValue();
            final K key = toObject(keyData);
            final V value = toObject(valueData);
            result.put(key, value);
            storeInNearCache(keyData, valueData, value);
        }
        return result;
    }

    private Map<K, V> getAllFromNearCache(Set<Data> keySet) {
        Map<K, V> result = new HashMap<K, V>();
        if (nearCache != null) {
            final Iterator<Data> iterator = keySet.iterator();
            while (iterator.hasNext()) {
                Data key = iterator.next();
                Object cached = nearCache.get(key);
                if (cached != null && !NearCache.NULL_OBJECT.equals(cached)) {
                    result.put((K) toObject(key), (V) cached);
                    iterator.remove();
                }
            }
        }
        return result;
    }

    @Override
    public void put(K key, V value, ExpiryPolicy expiryPolicy) {
        final ICompletableFuture<Object> f = putAsyncInternal(key, value, expiryPolicy, false, true);
        try {
            f.get();
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public V getAndPut(K key, V value, ExpiryPolicy expiryPolicy) {
        final ICompletableFuture<V> f = putAsyncInternal(key, value, expiryPolicy, true, true);
        try {
            return toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public void putAll(Map<? extends K, ? extends V> map, ExpiryPolicy expiryPolicy) {
        ensureOpen();
        validateNotNull(map);
        
        for (Map.Entry<? extends K, ? extends V> entry : map.entrySet()) {
            put(entry.getKey(), entry.getValue(), expiryPolicy);
        }
    }

    @Override
    public boolean putIfAbsent(K key, V value, ExpiryPolicy expiryPolicy) {
        final Future<Boolean> f = putIfAbsentAsyncInternal(key, value, expiryPolicy, true);
        try {
            return (Boolean) toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public boolean replace(K key, V oldValue, V newValue, ExpiryPolicy expiryPolicy) {
        final Future<Boolean> f = replaceAsyncInternal(key, oldValue, newValue, expiryPolicy, true, false, true);
        try {
            return (Boolean) toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public boolean replace(K key, V value, ExpiryPolicy expiryPolicy) {
        final Future<Boolean> f = replaceAsyncInternal(key, null, value, expiryPolicy, false, false, true);
        try {
            return (Boolean) toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public V getAndReplace(K key, V value, ExpiryPolicy expiryPolicy) {
        final Future<V> f = replaceAsyncInternal(key, null, value, expiryPolicy, false, true, true);
        try {
            return toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public int size() {
        ensureOpen();
        try {
            CacheSizeRequest request = new CacheSizeRequest(nameWithPrefix);
            Integer result = invoke(request);
            if (result == null) {
                return 0;
            }
            return result;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(t, CacheException.class);
        }
    }

    @Override
    public CacheStatistics getLocalCacheStatistics() {
        throw new UnsupportedOperationException("local cache Statistics are not implemented yet");
    }

}

<code block>


package com.hazelcast.cache.impl.nearcache.impl.store;

import com.hazelcast.cache.impl.eviction.EvictionChecker;
import com.hazelcast.cache.impl.eviction.EvictionListener;
import com.hazelcast.cache.impl.eviction.EvictionPolicyEvaluator;
import com.hazelcast.cache.impl.eviction.EvictionPolicyEvaluatorProvider;
import com.hazelcast.cache.impl.eviction.EvictionPolicyType;
import com.hazelcast.cache.impl.eviction.EvictionStrategy;
import com.hazelcast.cache.impl.eviction.EvictionStrategyProvider;
import com.hazelcast.cache.impl.maxsize.MaxSizeChecker;
import com.hazelcast.cache.impl.nearcache.NearCacheContext;
import com.hazelcast.cache.impl.nearcache.NearCacheRecord;
import com.hazelcast.cache.impl.nearcache.NearCacheRecordStore;
import com.hazelcast.cache.impl.nearcache.impl.NearCacheRecordMap;
import com.hazelcast.config.EvictionConfig;
import com.hazelcast.config.NearCacheConfig;
import com.hazelcast.monitor.NearCacheStats;
import com.hazelcast.monitor.impl.NearCacheStatsImpl;
import com.hazelcast.nio.UnsafeHelper;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.nio.serialization.SerializationService;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;

public abstract class AbstractNearCacheRecordStore<
        K, V, KS, R extends NearCacheRecord, NCRM extends NearCacheRecordMap<KS, R>>
        implements NearCacheRecordStore<K, V>, EvictionListener<KS, R> {

    
    protected static final int REFERENCE_SIZE =
            UnsafeHelper.UNSAFE_AVAILABLE
                    ? UnsafeHelper.UNSAFE.arrayIndexScale(Object[].class)
                    : (Integer.SIZE / Byte.SIZE);

    private static final int MILLI_SECONDS_IN_A_SECOND = 1000;

    protected final long timeToLiveMillis;
    protected final long maxIdleMillis;

    protected final NearCacheConfig nearCacheConfig;
    protected final SerializationService serializationService;
    protected final NearCacheStatsImpl nearCacheStats;
    protected NCRM records;

    protected final MaxSizeChecker maxSizeChecker;
    protected final EvictionPolicyEvaluator<KS, R> evictionPolicyEvaluator;
    protected final EvictionChecker evictionChecker;
    protected final EvictionStrategy<KS, R, NCRM> evictionStrategy;

    public AbstractNearCacheRecordStore(NearCacheConfig nearCacheConfig, NearCacheContext nearCacheContext) {
        this(nearCacheConfig, nearCacheContext, new NearCacheStatsImpl());
    }

    public AbstractNearCacheRecordStore(NearCacheConfig nearCacheConfig, NearCacheContext nearCacheContext,
                                        NearCacheStatsImpl nearCacheStats) {
        this.nearCacheConfig = nearCacheConfig;
        this.timeToLiveMillis = nearCacheConfig.getTimeToLiveSeconds() * MILLI_SECONDS_IN_A_SECOND;
        this.maxIdleMillis = nearCacheConfig.getMaxIdleSeconds() * MILLI_SECONDS_IN_A_SECOND;
        this.serializationService = nearCacheContext.getSerializationService();
        this.nearCacheStats = nearCacheStats;
        this.records = createNearCacheRecordMap(nearCacheConfig, nearCacheContext);

        final EvictionConfig evictionConfig = nearCacheConfig.getEvictionConfig();
        if (evictionConfig != null) {
            this.maxSizeChecker = createNearCacheMaxSizeChecker(evictionConfig, nearCacheConfig, nearCacheContext);
            this.evictionPolicyEvaluator = createEvictionPolicyEvaluator(evictionConfig);
            this.evictionChecker = createEvictionChecker(nearCacheConfig);
            this.evictionStrategy = createEvictionStrategy(evictionConfig);
        } else {
            this.maxSizeChecker = null;
            this.evictionPolicyEvaluator = null;
            this.evictionChecker = null;
            this.evictionStrategy = null;
        }
    }

    protected abstract MaxSizeChecker createNearCacheMaxSizeChecker(EvictionConfig evictionConfig,
                                                                    NearCacheConfig nearCacheConfig,
                                                                    NearCacheContext nearCacheContext);

    protected abstract NCRM createNearCacheRecordMap(NearCacheConfig nearCacheConfig,
                                                     NearCacheContext nearCacheContext);

    protected abstract long getKeyStorageMemoryCost(K key);
    protected abstract long getRecordStorageMemoryCost(R record);

    protected abstract R valueToRecord(V value);
    protected abstract V recordToValue(R record);

    protected abstract R getRecord(K key);
    protected abstract R putRecord(K key, R record);
    protected abstract void putToRecord(R record, V value);
    protected abstract R removeRecord(K key);

    protected void checkAvailable() {
        if (!isAvailable()) {
            throw new IllegalStateException(nearCacheConfig.getName()
                    + " named near cache record store is not available");
        }
    }

    protected EvictionPolicyEvaluator<KS, R> createEvictionPolicyEvaluator(EvictionConfig evictionConfig) {
        final EvictionPolicyType evictionPolicyType = evictionConfig.getEvictionPolicyType();
        if (evictionPolicyType == null) {
            throw new IllegalArgumentException("Eviction policy cannot be null");
        }
        return EvictionPolicyEvaluatorProvider.getEvictionPolicyEvaluator(evictionConfig);
    }

    protected EvictionChecker createEvictionChecker(NearCacheConfig nearCacheConfig) {
        return new MaxSizeEvictionChecker();
    }

    protected EvictionStrategy<KS, R, NCRM> createEvictionStrategy(EvictionConfig evictionConfig) {
        return EvictionStrategyProvider.getEvictionStrategy(evictionConfig);
    }

    protected boolean isAvailable() {
        return records != null;
    }

    protected Data valueToData(V value) {
        if (value instanceof Data) {
            return (Data) value;
        } else if (value != null) {
            return serializationService.toData(value);
        } else {
            return null;
        }
    }

    protected V dataToValue(Data data) {
        if (data != null) {
            return serializationService.toObject(data);
        } else {
            return null;
        }
    }

    protected Data toData(Object obj) {
        if (obj == null) {
            return null;
        } else if (obj instanceof Data) {
            return (Data) obj;
        } else {
            return valueToData((V) obj);
        }
    }

    protected V toValue(Object obj) {
        if (obj == null) {
            return null;
        } else if (obj instanceof Data) {
            return dataToValue((Data) obj);
        } else {
            return (V) obj;
        }
    }

    protected long getTotalStorageMemoryCost(K key, R record) {
        return getKeyStorageMemoryCost(key) + getRecordStorageMemoryCost(record);
    }

    protected boolean isRecordExpired(R record) {
        long now = Clock.currentTimeMillis();
        if (record.isExpiredAt(now)) {
            return true;
        } else {
            return record.isIdleAt(maxIdleMillis, now);
        }
    }

    protected void onRecordCreate(R record) {
        record.setCreationTime(Clock.currentTimeMillis());
    }

    protected void onRecordAccess(R record) {
        record.setAccessTime(Clock.currentTimeMillis());
        record.incrementAccessHit();
    }

    protected void onGet(K key, V value, R record) {

    }

    protected void onGetError(K key, V value, R record, Throwable error) {

    }

    protected void onPut(K key, V value, R record, boolean newPut) {

    }

    protected void onPutError(K key, V value, R record, boolean newPut, Throwable error) {

    }

    protected void onRemove(K key, R record, boolean removed) {

    }

    protected void onRemoveError(K key, R record, boolean removed, Throwable error) {

    }

    protected boolean isEvictionEnabled() {
        return evictionStrategy != null && evictionPolicyEvaluator != null;
    }

    @Override
    public void onEvict(KS key, R record) {
        nearCacheStats.decrementOwnedEntryCount();
    }

    @Override
    public V get(K key) {
        checkAvailable();

        R record = null;
        V value = null;
        try {
            record = getRecord(key);
            if (record != null) {
                if (isRecordExpired(record)) {
                    remove(key);
                    return null;
                }
                onRecordAccess(record);
                nearCacheStats.incrementHits();
                value = recordToValue(record);
                onGet(key, value, record);
                return value;
            } else {
                nearCacheStats.incrementMisses();
                return null;
            }
        } catch (Throwable error) {
            onGetError(key, value, record, error);
            throw ExceptionUtil.rethrow(error);
        }
    }

    @Override
    public void put(K key, V value) {
        checkAvailable();

        R record = null;
        boolean newPut = false;
        try {
            record = getRecord(key);
            if (record == null) {
                newPut = true;
                record = valueToRecord(value);
                onRecordCreate(record);
                putRecord(key, record);
                nearCacheStats.incrementOwnedEntryCount();
            } else {
                long oldRecordMemoryCost = getRecordStorageMemoryCost(record);
                putToRecord(record, value);
                long newRecordMemoryCost = getRecordStorageMemoryCost(record);
                nearCacheStats.incrementOwnedEntryMemoryCost(newRecordMemoryCost - oldRecordMemoryCost);
            }
            onPut(key, value, record, newPut);
        } catch (Throwable error) {
            onPutError(key, value, record, newPut, error);
            throw ExceptionUtil.rethrow(error);
        }
    }

    @Override
    public boolean remove(K key) {
        checkAvailable();

        R record = null;
        boolean removed = false;
        try {
            record = removeRecord(key);
            if (record != null) {
                removed = true;
                nearCacheStats.decrementOwnedEntryCount();
            }
            onRemove(key, record, removed);
            return record != null;
        } catch (Throwable error) {
            onRemoveError(key, record, removed, error);
            throw ExceptionUtil.rethrow(error);
        }
    }

    protected void clearRecords() {
        records.clear();
    }

    @Override
    public void clear() {
        checkAvailable();

        clearRecords();
        nearCacheStats.setOwnedEntryCount(0);
        nearCacheStats.setOwnedEntryMemoryCost(0L);
    }

    protected void destroyStore() {
        clearRecords();
        
        records = null;
    }

    @Override
    public void destroy() {
        checkAvailable();

        destroyStore();
        nearCacheStats.setOwnedEntryCount(0);
        nearCacheStats.setOwnedEntryMemoryCost(0L);
    }

    @Override
    public int size() {
        checkAvailable();

        return records.size();
    }

    @Override
    public NearCacheStats getNearCacheStats() {
        checkAvailable();

        return nearCacheStats;
    }

    protected class MaxSizeEvictionChecker implements EvictionChecker {

        @Override
        public boolean isEvictionRequired() {
            if (maxSizeChecker != null) {
                return maxSizeChecker.isReachedToMaxSize();
            } else {
                return false;
            }
        }

    }

    @Override
    public void doEvictionIfRequired() {
        checkAvailable();

        if (isEvictionEnabled()) {
            evictionStrategy.evict(records, evictionPolicyEvaluator, evictionChecker, this);
        }
    }

    @Override
    public void doEviction() {
        checkAvailable();

        if (isEvictionEnabled()) {
            evictionStrategy.evict(records, evictionPolicyEvaluator, null, this);
        }
    }

}

<code block>


package com.hazelcast.client.cache.impl;

import com.hazelcast.cache.CacheStatistics;
import com.hazelcast.cache.impl.ICacheInternal;
import com.hazelcast.cache.impl.client.CacheGetAllRequest;
import com.hazelcast.cache.impl.client.CacheGetRequest;
import com.hazelcast.cache.impl.client.CacheSizeRequest;
import com.hazelcast.cache.impl.nearcache.NearCache;
import com.hazelcast.client.impl.HazelcastClientInstanceImpl;
import com.hazelcast.client.spi.ClientContext;
import com.hazelcast.client.spi.impl.ClientInvocation;
import com.hazelcast.client.spi.impl.ClientInvocationFuture;
import com.hazelcast.config.CacheConfig;
import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.ICompletableFuture;
import com.hazelcast.map.impl.MapEntrySet;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.executor.DelegatingFuture;

import javax.cache.CacheException;
import javax.cache.expiry.ExpiryPolicy;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.Future;

import static com.hazelcast.cache.impl.CacheProxyUtil.validateNotNull;


abstract class AbstractClientCacheProxy<K, V>
        extends AbstractClientInternalCacheProxy<K, V>
        implements ICacheInternal<K, V> {

    protected AbstractClientCacheProxy(CacheConfig cacheConfig, ClientContext clientContext,
                                       HazelcastClientCacheManager cacheManager) {
        super(cacheConfig, clientContext, cacheManager);
    }

    protected Object getInternal(K key, ExpiryPolicy expiryPolicy, boolean async) {
        ensureOpen();
        validateNotNull(key);
        final Data keyData = toData(key);
        Object cached = nearCache != null ? nearCache.get(keyData) : null;
        if (cached != null && !NearCache.NULL_OBJECT.equals(cached)) {
            return createCompletedFuture(cached);
        }
        CacheGetRequest request = new CacheGetRequest(nameWithPrefix, keyData, expiryPolicy, cacheConfig.getInMemoryFormat());
        ClientInvocationFuture future;
        try {
            final int partitionId = clientContext.getPartitionService().getPartitionId(key);
            final HazelcastClientInstanceImpl client = (HazelcastClientInstanceImpl) clientContext.getHazelcastInstance();
            final ClientInvocation clientInvocation = new ClientInvocation(client, request, partitionId);
            future = clientInvocation.invoke();
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }
        if (async) {
            if (nearCache != null) {
                future.andThenInternal(new ExecutionCallback<Data>() {
                    public void onResponse(Data valueData) {
                        storeInNearCache(keyData, valueData, null);
                    }

                    public void onFailure(Throwable t) {
                    }
                });
            }
            return new DelegatingFuture<V>(future, clientContext.getSerializationService());
        } else {
            try {
                Object value = future.get();
                if (nearCache != null) {
                    storeInNearCache(keyData, toData(value), null);
                }
                return toObject(value);
            } catch (Throwable e) {
                throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
            }
        }
    }

    @Override
    public ICompletableFuture<V> getAsync(K key) {
        return getAsync(key, null);
    }

    @Override
    public ICompletableFuture<V> getAsync(K key, ExpiryPolicy expiryPolicy) {
        return (ICompletableFuture<V>) getInternal(key, expiryPolicy, true);
    }

    @Override
    public ICompletableFuture<Void> putAsync(K key, V value) {
        return putAsync(key, value, null);
    }

    @Override
    public ICompletableFuture<Void> putAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return putAsyncInternal(key, value, expiryPolicy, false, true);
    }

    @Override
    public ICompletableFuture<Boolean> putIfAbsentAsync(K key, V value) {
        return putIfAbsentAsyncInternal(key, value, null, false);
    }

    @Override
    public ICompletableFuture<Boolean> putIfAbsentAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return putIfAbsentAsyncInternal(key, value, expiryPolicy, false);
    }

    @Override
    public ICompletableFuture<V> getAndPutAsync(K key, V value) {
        return getAndPutAsync(key, value, null);
    }

    @Override
    public ICompletableFuture<V> getAndPutAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return putAsyncInternal(key, value, expiryPolicy, true, false);
    }

    @Override
    public ICompletableFuture<Boolean> removeAsync(K key) {
        return removeAsyncInternal(key, null, false, false, false);
    }

    @Override
    public ICompletableFuture<Boolean> removeAsync(K key, V oldValue) {
        return removeAsyncInternal(key, oldValue, true, false, false);
    }

    @Override
    public ICompletableFuture<V> getAndRemoveAsync(K key) {
        return removeAsyncInternal(key, null, false, true, false);
    }

    @Override
    public ICompletableFuture<Boolean> replaceAsync(K key, V value) {
        return replaceAsyncInternal(key, null, value, null, false, false, false);
    }

    @Override
    public ICompletableFuture<Boolean> replaceAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return replaceAsyncInternal(key, null, value, expiryPolicy, false, false, false);
    }

    @Override
    public ICompletableFuture<Boolean> replaceAsync(K key, V oldValue, V newValue) {
        return replaceAsyncInternal(key, oldValue, newValue, null, true, false, false);
    }

    @Override
    public ICompletableFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, ExpiryPolicy expiryPolicy) {
        return replaceAsyncInternal(key, oldValue, newValue, expiryPolicy, true, false, false);
    }

    @Override
    public ICompletableFuture<V> getAndReplaceAsync(K key, V value) {
        return replaceAsyncInternal(key, null, value, null, false, true, false);
    }

    @Override
    public ICompletableFuture<V> getAndReplaceAsync(K key, V value, ExpiryPolicy expiryPolicy) {
        return replaceAsyncInternal(key, null, value, expiryPolicy, false, true, false);
    }

    @Override
    public V get(K key, ExpiryPolicy expiryPolicy) {
        return (V) getInternal(key, expiryPolicy, false);
    }

    @Override
    public Map<K, V> getAll(Set<? extends K> keys, ExpiryPolicy expiryPolicy) {
        ensureOpen();
        validateNotNull(keys);
        if (keys.isEmpty()) {
            return Collections.EMPTY_MAP;
        }
        final Set<Data> keySet = new HashSet(keys.size());
        for (K key : keys) {
            final Data k = toData(key);
            keySet.add(k);
        }
        Map<K, V> result = getAllFromNearCache(keySet);
        if (keySet.isEmpty()) {
            return result;
        }
        final CacheGetAllRequest request = new CacheGetAllRequest(nameWithPrefix, keySet, expiryPolicy);
        final MapEntrySet mapEntrySet = toObject(invoke(request));
        final Set<Map.Entry<Data, Data>> entrySet = mapEntrySet.getEntrySet();
        for (Map.Entry<Data, Data> dataEntry : entrySet) {
            final Data keyData = dataEntry.getKey();
            final Data valueData = dataEntry.getValue();
            final K key = toObject(keyData);
            final V value = toObject(valueData);
            result.put(key, value);
            storeInNearCache(keyData, valueData, value);
        }
        return result;
    }

    private Map<K, V> getAllFromNearCache(Set<Data> keySet) {
        Map<K, V> result = new HashMap<K, V>();
        if (nearCache != null) {
            final Iterator<Data> iterator = keySet.iterator();
            while (iterator.hasNext()) {
                Data key = iterator.next();
                Object cached = nearCache.get(key);
                if (cached != null && !NearCache.NULL_OBJECT.equals(cached)) {
                    result.put((K) toObject(key), (V) cached);
                    iterator.remove();
                }
            }
        }
        return result;
    }

    @Override
    public void put(K key, V value, ExpiryPolicy expiryPolicy) {
        final ICompletableFuture<Object> f = putAsyncInternal(key, value, expiryPolicy, false, true);
        try {
            f.get();
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public V getAndPut(K key, V value, ExpiryPolicy expiryPolicy) {
        final ICompletableFuture<V> f = putAsyncInternal(key, value, expiryPolicy, true, true);
        try {
            return toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public void putAll(Map<? extends K, ? extends V> map, ExpiryPolicy expiryPolicy) {
        ensureOpen();
        validateNotNull(map);
        
        for (Map.Entry<? extends K, ? extends V> entry : map.entrySet()) {
            put(entry.getKey(), entry.getValue(), expiryPolicy);
        }
    }

    @Override
    public boolean putIfAbsent(K key, V value, ExpiryPolicy expiryPolicy) {
        final Future<Boolean> f = putIfAbsentAsyncInternal(key, value, expiryPolicy, true);
        try {
            return (Boolean) toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public boolean replace(K key, V oldValue, V newValue, ExpiryPolicy expiryPolicy) {
        final Future<Boolean> f = replaceAsyncInternal(key, oldValue, newValue, expiryPolicy, true, false, true);
        try {
            return (Boolean) toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public boolean replace(K key, V value, ExpiryPolicy expiryPolicy) {
        final Future<Boolean> f = replaceAsyncInternal(key, null, value, expiryPolicy, false, false, true);
        try {
            return (Boolean) toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public V getAndReplace(K key, V value, ExpiryPolicy expiryPolicy) {
        final Future<V> f = replaceAsyncInternal(key, null, value, expiryPolicy, false, true, true);
        try {
            return toObject(f.get());
        } catch (Throwable e) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(e, CacheException.class);
        }
    }

    @Override
    public int size() {
        ensureOpen();
        try {
            CacheSizeRequest request = new CacheSizeRequest(nameWithPrefix);
            Integer result = invoke(request);
            if (result == null) {
                return 0;
            }
            return result;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrowAllowedTypeFirst(t, CacheException.class);
        }
    }

    @Override
    public CacheStatistics getLocalCacheStatistics() {
        throw new UnsupportedOperationException("local cache Statistics are not implemented yet");
    }

}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.ReplicaErrorLogger;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PartitionAwareOperation;
import com.hazelcast.spi.UrgentSystemOperation;

import java.io.IOException;


final class SyncReplicaVersion extends Operation implements PartitionAwareOperation, UrgentSystemOperation {

    public static final int OPERATION_TRY_COUNT = 10;
    public static final int OPERATION_TRY_PAUSE_MILLIS = 250;

    private final int syncReplicaIndex;
    private final ExecutionCallback callback;
    private final boolean sync;

    public SyncReplicaVersion(int syncReplicaIndex, ExecutionCallback callback) {
        if (syncReplicaIndex < 1 || syncReplicaIndex > InternalPartition.MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("Replica index should be in range [1-"
                    + InternalPartition.MAX_BACKUP_COUNT + "]");
        }
        this.syncReplicaIndex = syncReplicaIndex;
        this.callback = callback;
        this.sync = callback != null;
    }

    @Override
    public void beforeRun() throws Exception {
    }

    @Override
    public void run() throws Exception {
        InternalPartitionServiceImpl partitionService = getService();
        int partitionId = getPartitionId();
        int replicaIndex = syncReplicaIndex;
        InternalPartition partition = partitionService.getPartition(partitionId);
        Address target = partition.getReplicaAddress(replicaIndex);
        if (target == null) {
            notifyCallback(false);
            return;
        }

        invokeCheckReplicaVersion(partitionId, replicaIndex, target);
    }

    private void invokeCheckReplicaVersion(int partitionId, int replicaIndex, Address target) {
        InternalPartitionServiceImpl partitionService = getService();
        long[] currentVersions = partitionService.getPartitionReplicaVersions(partitionId);
        long currentReplicaVersion = currentVersions[replicaIndex - 1];

        if (currentReplicaVersion > 0) {
            CheckReplicaVersion op = createCheckReplicaVersion(partitionId, replicaIndex, currentReplicaVersion);
            NodeEngine nodeEngine = getNodeEngine();
            OperationService operationService = nodeEngine.getOperationService();
            if (sync) {
                operationService.createInvocationBuilder(InternalPartitionService.SERVICE_NAME, op, target)
                        .setExecutionCallback(callback)
                        .setTryCount(OPERATION_TRY_COUNT)
                        .setTryPauseMillis(OPERATION_TRY_PAUSE_MILLIS)
                        .invoke();
            } else {
                operationService.send(op, target);
            }
        } else {
            notifyCallback(true);
        }
    }

    private void notifyCallback(boolean result) {
        if (callback != null) {
            callback.onResponse(result);
        }
    }

    private CheckReplicaVersion createCheckReplicaVersion(int partitionId, int replicaIndex, long currentVersion) {
        CheckReplicaVersion op = new CheckReplicaVersion(currentVersion, sync);
        op.setPartitionId(partitionId).setReplicaIndex(replicaIndex).setServiceName(InternalPartitionService.SERVICE_NAME);
        return op;
    }

    @Override
    public void afterRun() throws Exception {
    }

    @Override
    public boolean returnsResponse() {
        return false;
    }

    @Override
    public Object getResponse() {
        return null;
    }

    @Override
    public boolean validatesTarget() {
        return false;
    }

    @Override
    public String getServiceName() {
        return InternalPartitionService.SERVICE_NAME;
    }

    @Override
    public void logError(Throwable e) {
        ReplicaErrorLogger.log(e, getLogger());
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        throw new UnsupportedOperationException();
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        throw new UnsupportedOperationException();
    }

    @Override
    public String toString() {
        return getClass().getSimpleName() + "{" + "partitionId=" + getPartitionId() + ", replicaIndex=" + syncReplicaIndex + '}';
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.cluster.MemberInfo;
import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.Member;
import com.hazelcast.core.MigrationEvent;
import com.hazelcast.core.MigrationEvent.MigrationStatus;
import com.hazelcast.core.MigrationListener;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionLostEvent;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationEndpoint;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.partition.PartitionEvent;
import com.hazelcast.partition.PartitionEventListener;
import com.hazelcast.partition.PartitionInfo;
import com.hazelcast.partition.PartitionLostEvent;
import com.hazelcast.partition.PartitionLostListener;
import com.hazelcast.partition.PartitionRuntimeState;
import com.hazelcast.partition.PartitionServiceProxy;
import com.hazelcast.partition.membergroup.MemberGroup;
import com.hazelcast.partition.membergroup.MemberGroupFactory;
import com.hazelcast.partition.membergroup.MemberGroupFactoryFactory;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PartitionAwareService;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.ResponseHandlerFactory;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.FutureUtil.ExceptionHandler;
import com.hazelcast.util.scheduler.CoalescingDelayedTrigger;
import com.hazelcast.util.scheduler.EntryTaskScheduler;
import com.hazelcast.util.scheduler.EntryTaskSchedulerFactory;
import com.hazelcast.util.scheduler.ScheduleType;
import com.hazelcast.util.scheduler.ScheduledEntry;
import com.hazelcast.util.scheduler.ScheduledEntryProcessor;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReferenceArray;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;

import static com.hazelcast.partition.impl.InternalPartitionServiceState.MIGRATION_LOCAL;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.MIGRATION_ON_MASTER;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.SAFE;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.REPLICA_NOT_SYNC;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;



public class InternalPartitionServiceImpl implements InternalPartitionService, ManagedService,
        EventPublishingService<PartitionEvent, PartitionEventListener<PartitionEvent>>, PartitionAwareService {

    private static final String EXCEPTION_MSG_PARTITION_STATE_SYNC_TIMEOUT = "Partition state sync invocation timed out";

    private static final int DEFAULT_PAUSE_MILLIS = 1000;
    private static final int PARTITION_OWNERSHIP_WAIT_MILLIS = 10;
    private static final int REPLICA_SYNC_CHECK_TIMEOUT_SECONDS = 10;

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final ILogger logger;
    private final int partitionCount;
    private final InternalPartitionImpl[] partitions;
    private final PartitionReplicaVersions[] replicaVersions;
    private final AtomicReferenceArray<ReplicaSyncInfo> replicaSyncRequests;
    private final EntryTaskScheduler<Integer, ReplicaSyncInfo> replicaSyncScheduler;
    private final Semaphore replicaSyncProcessLock;
    private final MigrationThread migrationThread;
    private final long partitionMigrationInterval;
    private final long partitionMigrationTimeout;
    private final long backupSyncCheckInterval;
    private final int maxParallelReplications;
    private final PartitionStateGenerator partitionStateGenerator;
    private final MemberGroupFactory memberGroupFactory;
    private final PartitionServiceProxy proxy;
    private final Lock lock = new ReentrantLock();
    private final AtomicInteger stateVersion = new AtomicInteger();
    private final BlockingQueue<Runnable> migrationQueue = new LinkedBlockingQueue<Runnable>();
    private final AtomicBoolean migrationActive = new AtomicBoolean(true);
    private final AtomicLong lastRepartitionTime = new AtomicLong();
    private final CoalescingDelayedTrigger delayedResumeMigrationTrigger;

    private final ExceptionHandler partitionStateSyncTimeoutHandler;

    
    private volatile int memberGroupsSize;

    
    private volatile boolean initialized;

    
    private final ConcurrentMap<Integer, MigrationInfo> activeMigrations
            = new ConcurrentHashMap<Integer, MigrationInfo>(3, 0.75f, 1);

    
    private final LinkedList<MigrationInfo> completedMigrations = new LinkedList<MigrationInfo>();

    public InternalPartitionServiceImpl(Node node) {
        this.partitionCount = node.groupProperties.PARTITION_COUNT.getInteger();
        this.node = node;
        this.nodeEngine = node.nodeEngine;
        this.logger = node.getLogger(InternalPartitionService.class);
        partitionStateSyncTimeoutHandler =
                logAllExceptions(logger, EXCEPTION_MSG_PARTITION_STATE_SYNC_TIMEOUT, Level.FINEST);
        this.partitions = new InternalPartitionImpl[partitionCount];
        PartitionListener partitionListener = new LocalPartitionListener(this, node.getThisAddress());
        for (int i = 0; i < partitionCount; i++) {
            this.partitions[i] = new InternalPartitionImpl(i, partitionListener, node.getThisAddress());
        }
        replicaVersions = new PartitionReplicaVersions[partitionCount];
        for (int i = 0; i < replicaVersions.length; i++) {
            replicaVersions[i] = new PartitionReplicaVersions(i);
        }

        memberGroupFactory = MemberGroupFactoryFactory.newMemberGroupFactory(node.getConfig().getPartitionGroupConfig());
        partitionStateGenerator = new PartitionStateGeneratorImpl();

        long interval = node.groupProperties.PARTITION_MIGRATION_INTERVAL.getLong();
        partitionMigrationInterval = interval > 0 ? TimeUnit.SECONDS.toMillis(interval) : 0;

        partitionMigrationTimeout = TimeUnit.SECONDS.toMillis(
                node.groupProperties.PARTITION_MIGRATION_TIMEOUT.getLong());

        migrationThread = new MigrationThread(node);
        proxy = new PartitionServiceProxy(this);

        ExecutionService executionService = nodeEngine.getExecutionService();
        ScheduledExecutorService scheduledExecutor = executionService.getDefaultScheduledExecutor();

        
        
        
        
        
        
        
        replicaSyncScheduler = EntryTaskSchedulerFactory.newScheduler(scheduledExecutor,
                new ReplicaSyncEntryProcessor(this), ScheduleType.POSTPONE);

        replicaSyncRequests = new AtomicReferenceArray<ReplicaSyncInfo>(partitionCount);

        long maxMigrationDelayMs = calculateMaxMigrationDelayOnMemberRemoved();
        long minMigrationDelayMs = calculateMigrationDelayOnMemberRemoved(maxMigrationDelayMs);
        this.delayedResumeMigrationTrigger = new CoalescingDelayedTrigger(
                executionService, minMigrationDelayMs, maxMigrationDelayMs, new Runnable() {
            @Override
            public void run() {
                resumeMigration();
            }
        });

        long definedBackupSyncCheckInterval = node.groupProperties.PARTITION_BACKUP_SYNC_INTERVAL.getInteger();
        backupSyncCheckInterval = definedBackupSyncCheckInterval > 0 ? definedBackupSyncCheckInterval : 1;

        maxParallelReplications = node.groupProperties.PARTITION_MAX_PARALLEL_REPLICATIONS.getInteger();
        replicaSyncProcessLock = new Semaphore(maxParallelReplications);
    }

    private long calculateMaxMigrationDelayOnMemberRemoved() {
        
        return node.groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong() / 2;
    }

    private long calculateMigrationDelayOnMemberRemoved(long maxDelayMs) {
        long migrationDelayMs = node.groupProperties.MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS.getLong() * 1000;

        long connectionErrorDetectionIntervalMs = node.groupProperties.CONNECTION_MONITOR_INTERVAL.getLong()
                * node.groupProperties.CONNECTION_MONITOR_MAX_FAULTS.getInteger() * 5;
        migrationDelayMs = Math.max(migrationDelayMs, connectionErrorDetectionIntervalMs);

        long heartbeatIntervalMs = node.groupProperties.HEARTBEAT_INTERVAL_SECONDS.getLong() * 1000;
        migrationDelayMs = Math.max(migrationDelayMs, heartbeatIntervalMs * 3);

        migrationDelayMs = Math.min(migrationDelayMs, maxDelayMs);
        return migrationDelayMs;
    }

    @Override
    public void init(NodeEngine nodeEngine, Properties properties) {
        migrationThread.start();

        int partitionTableSendInterval = node.groupProperties.PARTITION_TABLE_SEND_INTERVAL.getInteger();
        if (partitionTableSendInterval <= 0) {
            partitionTableSendInterval = 1;
        }
        ExecutionService executionService = nodeEngine.getExecutionService();
        executionService.scheduleAtFixedRate(new SendClusterStateTask(),
                partitionTableSendInterval, partitionTableSendInterval, TimeUnit.SECONDS);

        executionService.scheduleWithFixedDelay(new SyncReplicaVersionTask(),
                backupSyncCheckInterval, backupSyncCheckInterval, TimeUnit.SECONDS);
    }

    @Override
    public Address getPartitionOwner(int partitionId) {
        if (!initialized) {
            firstArrangement();
        }
        if (partitions[partitionId].getOwnerOrNull() == null && !node.isMaster() && node.joined()) {
            notifyMasterToAssignPartitions();
        }
        return partitions[partitionId].getOwnerOrNull();
    }

    @Override
    public Address getPartitionOwnerOrWait(int partition) {
        Address owner = getPartitionOwner(partition);
        while (owner == null) {
            try {
                Thread.sleep(PARTITION_OWNERSHIP_WAIT_MILLIS);
            } catch (InterruptedException e) {
                ExceptionUtil.rethrow(e);
            }
            owner = getPartitionOwner(partition);
        }
        return owner;
    }

    private void notifyMasterToAssignPartitions() {
        if (initialized) {
            return;
        }
        if (lock.tryLock()) {
            try {
                if (!initialized && !node.isMaster() && node.getMasterAddress() != null && node.joined()) {
                    Future f = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, new AssignPartitions(),
                            node.getMasterAddress()).setTryCount(1).invoke();
                    f.get(1, TimeUnit.SECONDS);
                }
            } catch (Exception e) {
                logger.finest(e);
            } finally {
                lock.unlock();
            }
        }
    }

    @Override
    public void firstArrangement() {
        if (!node.isMaster() || !node.isActive()) {
            notifyMasterToAssignPartitions();
            return;
        }
        if (!initialized) {
            lock.lock();
            try {
                if (initialized) {
                    return;
                }
                PartitionStateGenerator psg = partitionStateGenerator;
                final Set<Member> members = node.getClusterService().getMembers();
                Collection<MemberGroup> memberGroups = memberGroupFactory.createMemberGroups(members);
                if (memberGroups.isEmpty()) {
                    logger.warning("No member group is available to assign partition ownership...");
                    return;
                }

                logger.info("Initializing cluster partition table first arrangement...");
                Address[][] newState = psg.initialize(memberGroups, partitionCount);
                if (newState.length != partitionCount) {
                    throw new HazelcastException("Invalid partition count! "
                            + "Expected: " + partitionCount + ", Actual: " + newState.length);
                }

                for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
                    InternalPartitionImpl partition = partitions[partitionId];
                    Address[] replicas = newState[partitionId];
                    partition.setReplicaAddresses(replicas);
                }
                initialized = true;
                publishPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
        }
    }

    private void updateMemberGroupsSize() {
        Set<Member> members = node.getClusterService().getMembers();
        final Collection<MemberGroup> groups = memberGroupFactory.createMemberGroups(members);
        int size = 0;
        for (MemberGroup group : groups) {
            if (group.size() > 0) {
                size++;
            }
        }
        memberGroupsSize = size;
    }

    @Override
    public int getMemberGroupsSize() {
        int size = memberGroupsSize;
        
        
        return size > 0 ? size : 1;
    }

    @Override
    public int getMaxBackupCount() {
        return Math.min(getMemberGroupsSize() - 1, InternalPartition.MAX_BACKUP_COUNT);
    }

    public void memberAdded(MemberImpl member) {
        if (!member.localMember()) {
            updateMemberGroupsSize();
        }
        if (node.isMaster() && node.isActive()) {
            lock.lock();
            try {
                migrationQueue.clear();
                if (initialized) {
                    migrationQueue.add(new RepartitioningTask());

                    
                    Collection<MemberImpl> members = node.clusterService.getMemberList();
                    PartitionStateOperation op = new PartitionStateOperation(createPartitionState(members));
                    nodeEngine.getOperationService().send(op, member.getAddress());
                }
            } finally {
                lock.unlock();
            }
        }
    }

    public void memberRemoved(final MemberImpl member) {
        updateMemberGroupsSize();
        final Address deadAddress = member.getAddress();
        final Address thisAddress = node.getThisAddress();
        if (deadAddress == null || deadAddress.equals(thisAddress)) {
            return;
        }
        lock.lock();
        try {
            migrationQueue.clear();
            if (!activeMigrations.isEmpty()) {
                if (node.isMaster()) {
                    rollbackActiveMigrationsFromPreviousMaster(node.getLocalMember().getUuid());
                }
                for (MigrationInfo migrationInfo : activeMigrations.values()) {
                    if (deadAddress.equals(migrationInfo.getSource()) || deadAddress.equals(migrationInfo.getDestination())) {
                        migrationInfo.invalidate();
                    }
                }
            }
            
            
            
            
            pauseMigration();
            cancelReplicaSyncRequestsTo(deadAddress);
            removeDeadAddress(deadAddress, thisAddress);

            if (node.isMaster() && initialized) {
                migrationQueue.add(new RepartitioningTask());
            }

            resumeMigrationEventually();
        } finally {
            lock.unlock();
        }
    }

    private void cancelReplicaSyncRequestsTo(Address deadAddress) {
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            ReplicaSyncInfo syncInfo = replicaSyncRequests.get(partitionId);
            if (syncInfo != null && deadAddress.equals(syncInfo.target)) {
                cancelReplicaSync(partitionId);
            }
        }
    }

    void cancelReplicaSync(int partitionId) {
        ReplicaSyncInfo syncInfo = replicaSyncRequests.get(partitionId);
        if (syncInfo != null && replicaSyncRequests.compareAndSet(partitionId, syncInfo, null)) {
            replicaSyncScheduler.cancel(partitionId);
            releaseReplicaSyncPermit();
        }
    }

    private void resumeMigrationEventually() {
        delayedResumeMigrationTrigger.executeWithDelay();
    }

    private void removeDeadAddress(Address deadAddress, Address thisAddress) {
        for (InternalPartitionImpl partition : partitions) {
            if (deadAddress.equals(partition.getOwnerOrNull()) && thisAddress.equals(partition.getReplicaAddress(1))) {
                partition.setMigrating(true);
            }
            
            partition.onDeadAddress(deadAddress);
            
            if (partition.onDeadAddress(deadAddress)) {
                throw new IllegalStateException("Duplicate address found in partition replicas!");
            }

        }
    }

    private void rollbackActiveMigrationsFromPreviousMaster(final String currentMasterUuid) {
        lock.lock();
        try {
            if (!activeMigrations.isEmpty()) {
                for (MigrationInfo migrationInfo : activeMigrations.values()) {
                    if (!currentMasterUuid.equals(migrationInfo.getMasterUuid())) {
                        
                        
                        logger.info("Rolling-back migration initiated by the old master -> " + migrationInfo);
                        finalizeActiveMigration(migrationInfo);
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private PartitionRuntimeState createPartitionState(Collection<MemberImpl> members) {
        lock.lock();
        try {
            List<MemberInfo> memberInfos = new ArrayList<MemberInfo>(members.size());
            for (MemberImpl member : members) {
                MemberInfo memberInfo = new MemberInfo(member.getAddress(), member.getUuid(), member.getAttributes());
                memberInfos.add(memberInfo);
            }
            ArrayList<MigrationInfo> migrationInfos = new ArrayList<MigrationInfo>(completedMigrations);
            ILogger logger = node.getLogger(PartitionRuntimeState.class);
            return new PartitionRuntimeState(logger, memberInfos, partitions, migrationInfos, stateVersion.get());
        } finally {
            lock.unlock();
        }
    }

    private void publishPartitionRuntimeState() {
        if (!initialized) {
            
            return;
        }

        if (!node.isMaster() || !node.isActive() || !node.joined()) {
            return;
        }

        if (!isMigrationActive()) {
            
            return;
        }

        lock.lock();
        try {
            Collection<MemberImpl> members = node.clusterService.getMemberList();
            PartitionRuntimeState partitionState = createPartitionState(members);
            PartitionStateOperation op = new PartitionStateOperation(partitionState);

            OperationService operationService = nodeEngine.getOperationService();
            for (MemberImpl member : members) {
                if (!member.localMember()) {
                    try {
                        operationService.send(op, member.getAddress());
                    } catch (Exception e) {
                        logger.finest(e);
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void syncPartitionRuntimeState() {
        syncPartitionRuntimeState(node.clusterService.getMemberList());
    }

    private void syncPartitionRuntimeState(Collection<MemberImpl> members) {
        if (!initialized) {
            
            return;
        }

        if (!node.isMaster() || !node.isActive() || !node.joined()) {
            return;
        }

        lock.lock();
        try {
            PartitionRuntimeState partitionState = createPartitionState(members);
            OperationService operationService = nodeEngine.getOperationService();

            List<Future> calls = firePartitionStateOperation(members, partitionState, operationService);
            waitWithDeadline(calls, 3, TimeUnit.SECONDS, partitionStateSyncTimeoutHandler);
        } finally {
            lock.unlock();
        }
    }

    private List<Future> firePartitionStateOperation(Collection<MemberImpl> members,
                                                     PartitionRuntimeState partitionState,
                                                     OperationService operationService) {
        List<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    Address address = member.getAddress();
                    PartitionStateOperation operation = new PartitionStateOperation(partitionState, true);
                    Future<Object> f = operationService.invokeOnTarget(SERVICE_NAME, operation, address);
                    calls.add(f);
                } catch (Exception e) {
                    logger.finest(e);
                }
            }
        }
        return calls;
    }

    void processPartitionRuntimeState(PartitionRuntimeState partitionState) {
        lock.lock();
        try {
            if (!node.isActive() || !node.joined()) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Node should be active(" + node.isActive() + ") and joined(" + node.joined()
                            + ") to be able to process partition table!");
                }
                return;
            }
            final Address sender = partitionState.getEndpoint();
            final Address master = node.getMasterAddress();
            if (node.isMaster()) {
                logger.warning("This is the master node and received a PartitionRuntimeState from "
                        + sender + ". Ignoring incoming state! ");
                return;
            } else {
                if (sender == null || !sender.equals(master)) {
                    if (node.clusterService.getMember(sender) == null) {
                        logger.severe("Received a ClusterRuntimeState from an unknown member!"
                                + " => Sender: " + sender + ", Master: " + master + "! ");
                        return;
                    } else {
                        logger.warning("Received a ClusterRuntimeState, but its sender doesn't seem to be master!"
                                + " => Sender: " + sender + ", Master: " + master + "! "
                                + "(Ignore if master node has changed recently.)");
                    }
                }
            }

            stateVersion.set(partitionState.getVersion());
            initialized = true;

            PartitionInfo[] state = partitionState.getPartitions();
            filterAndLogUnknownAddressesInPartitionTable(sender, state);
            finalizeOrRollbackMigration(partitionState, state);
        } finally {
            lock.unlock();
        }
    }

    private void finalizeOrRollbackMigration(PartitionRuntimeState partitionState, PartitionInfo[] state) {
        Collection<MigrationInfo> completedMigrations = partitionState.getCompletedMigrations();
        for (MigrationInfo completedMigration : completedMigrations) {
            addCompletedMigration(completedMigration);
            int partitionId = completedMigration.getPartitionId();
            PartitionInfo partitionInfo = state[partitionId];
            
            
            
            
            
            
            updatePartition(partitionInfo);
            finalizeActiveMigration(completedMigration);
        }
        if (!activeMigrations.isEmpty()) {
            final MemberImpl masterMember = getMasterMember();
            rollbackActiveMigrationsFromPreviousMaster(masterMember.getUuid());
        }

        updateAllPartitions(state);
    }

    private void updatePartition(PartitionInfo partitionInfo) {
        InternalPartitionImpl partition = partitions[partitionInfo.getPartitionId()];
        Address[] replicas = partitionInfo.getReplicaAddresses();
        partition.setReplicaAddresses(replicas);
    }

    private void updateAllPartitions(PartitionInfo[] state) {
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            updatePartition(state[partitionId]);
        }
    }

    private void filterAndLogUnknownAddressesInPartitionTable(Address sender, PartitionInfo[] state) {
        final Set<Address> unknownAddresses = new HashSet<Address>();
        for (int partitionId = 0; partitionId < state.length; partitionId++) {
            PartitionInfo partitionInfo = state[partitionId];
            searchUnknownAddressesInPartitionTable(sender, unknownAddresses, partitionId, partitionInfo);
        }
        logUnknownAddressesInPartitionTable(sender, unknownAddresses);
    }

    private void logUnknownAddressesInPartitionTable(Address sender, Set<Address> unknownAddresses) {
        if (!unknownAddresses.isEmpty() && logger.isLoggable(Level.WARNING)) {
            StringBuilder s = new StringBuilder("Following unknown addresses are found in partition table")
                    .append(" sent from master[").append(sender).append("].")
                    .append(" (Probably they have recently joined or left the cluster.)")
                    .append(" {");
            for (Address address : unknownAddresses) {
                s.append("\n\t").append(address);
            }
            s.append("\n}");
            logger.warning(s.toString());
        }
    }

    private void searchUnknownAddressesInPartitionTable(Address sender, Set<Address> unknownAddresses, int partitionId,
                                                        PartitionInfo partitionInfo) {
        for (int index = 0; index < InternalPartition.MAX_REPLICA_COUNT; index++) {
            Address address = partitionInfo.getReplicaAddress(index);
            if (address != null && getMember(address) == null) {
                if (logger.isFinestEnabled()) {
                    logger.finest(
                            "Unknown " + address + " found in partition table sent from master "
                                    + sender + ". It has probably already left the cluster. partitionId="
                                    + partitionId);
                }
                unknownAddresses.add(address);
            }
        }
    }

    private void finalizeActiveMigration(final MigrationInfo migrationInfo) {
        if (activeMigrations.containsKey(migrationInfo.getPartitionId())) {
            lock.lock();
            try {
                if (activeMigrations.containsValue(migrationInfo)) {
                    if (migrationInfo.startProcessing()) {
                        processMigrationInfo(migrationInfo);
                    } else {
                        logger.info("Scheduling finalization of " + migrationInfo
                                + ", because migration process is currently running.");
                        nodeEngine.getExecutionService().schedule(new Runnable() {
                            @Override
                            public void run() {
                                finalizeActiveMigration(migrationInfo);
                            }
                        }, 3, TimeUnit.SECONDS);
                    }
                }
            } finally {
                lock.unlock();
            }
        }
    }

    private void processMigrationInfo(MigrationInfo migrationInfo) {
        try {
            Address thisAddress = node.getThisAddress();
            boolean source = thisAddress.equals(migrationInfo.getSource());
            boolean destination = thisAddress.equals(migrationInfo.getDestination());
            if (source || destination) {
                int partitionId = migrationInfo.getPartitionId();
                InternalPartitionImpl migratingPartition = getPartitionImpl(partitionId);
                Address ownerAddress = migratingPartition.getOwnerOrNull();
                boolean success = migrationInfo.getDestination().equals(ownerAddress);
                MigrationEndpoint endpoint = source ? MigrationEndpoint.SOURCE : MigrationEndpoint.DESTINATION;
                FinalizeMigrationOperation op = new FinalizeMigrationOperation(endpoint, success);
                op.setPartitionId(partitionId)
                        .setNodeEngine(nodeEngine)
                        .setValidateTarget(false)
                        .setService(this);
                nodeEngine.getOperationService().executeOperation(op);
            }
        } catch (Exception e) {
            logger.warning(e);
        } finally {
            migrationInfo.doneProcessing();
        }
    }

    void addActiveMigration(MigrationInfo migrationInfo) {
        lock.lock();
        try {
            int partitionId = migrationInfo.getPartitionId();
            partitions[partitionId].setMigrating(true);
            MigrationInfo currentMigrationInfo = activeMigrations.putIfAbsent(partitionId, migrationInfo);
            if (currentMigrationInfo != null) {
                boolean oldMaster = false;
                MigrationInfo oldMigration;
                MigrationInfo newMigration;
                MemberImpl masterMember = getMasterMember();
                String master = masterMember.getUuid();
                if (!master.equals(currentMigrationInfo.getMasterUuid())) {
                    
                    oldMigration = currentMigrationInfo;
                    newMigration = migrationInfo;
                    oldMaster = true;
                } else if (!master.equals(migrationInfo.getMasterUuid())) {
                    
                    oldMigration = migrationInfo;
                    newMigration = currentMigrationInfo;
                    oldMaster = true;
                } else if (!currentMigrationInfo.isProcessing() && migrationInfo.isProcessing()) {
                    
                    oldMigration = currentMigrationInfo;
                    newMigration = migrationInfo;
                } else {
                    String message = "Something is seriously wrong! There are two migration requests for the "
                            + "same partition! First -> " + currentMigrationInfo + ", Second -> " + migrationInfo;
                    IllegalStateException error = new IllegalStateException(message);
                    logger.severe(message, error);
                    throw error;
                }

                if (oldMaster) {
                    logger.info("Finalizing migration instantiated by the old master -> " + oldMigration);
                } else {
                    if (logger.isFinestEnabled()) {
                        logger.finest("Finalizing previous migration -> " + oldMigration);
                    }
                }
                finalizeActiveMigration(oldMigration);
                activeMigrations.put(partitionId, newMigration);
            }
        } finally {
            lock.unlock();
        }
    }

    private MemberImpl getMasterMember() {
        return node.clusterService.getMember(node.getMasterAddress());
    }

    MigrationInfo getActiveMigration(int partitionId) {
        return activeMigrations.get(partitionId);
    }

    MigrationInfo removeActiveMigration(int partitionId) {
        partitions[partitionId].setMigrating(false);
        return activeMigrations.remove(partitionId);
    }

    public Collection<MigrationInfo> getActiveMigrations() {
        return Collections.unmodifiableCollection(activeMigrations.values());
    }

    private void addCompletedMigration(MigrationInfo migrationInfo) {
        lock.lock();
        try {
            if (completedMigrations.size() > 25) {
                completedMigrations.removeFirst();
            }
            completedMigrations.add(migrationInfo);
        } finally {
            lock.unlock();
        }
    }

    private void evictCompletedMigrations() {
        lock.lock();
        try {
            if (!completedMigrations.isEmpty()) {
                completedMigrations.removeFirst();
            }
        } finally {
            lock.unlock();
        }
    }

    
    
    
    void triggerPartitionReplicaSync(int partitionId, int replicaIndex, long delayMillis) {
        if (replicaIndex < 0 || replicaIndex > InternalPartition.MAX_REPLICA_COUNT) {
            throw new IllegalArgumentException("Invalid replica index! replicaIndex=" + replicaIndex
                    + " for partitionId=" + partitionId);
        }

        if (!checkSyncPartitionTarget(partitionId, replicaIndex)) {
            return;
        }

        InternalPartitionImpl partition = getPartitionImpl(partitionId);
        Address target = partition.getOwnerOrNull();
        ReplicaSyncInfo syncInfo = new ReplicaSyncInfo(partitionId, replicaIndex, target);

        if (delayMillis > 0) {
            schedulePartitionReplicaSync(syncInfo, target, delayMillis);
            return;
        }

        
        
        
        if (!isMigrationActive() || partition.isMigrating()) {
            schedulePartitionReplicaSync(syncInfo, target, REPLICA_SYNC_RETRY_DELAY);
            return;
        }

        if (replicaSyncRequests.compareAndSet(partitionId, null, syncInfo)) {
            if (fireSyncReplicaRequest(syncInfo, target)) {
                return;
            }

            replicaSyncRequests.compareAndSet(partitionId, syncInfo, null);
            schedulePartitionReplicaSync(syncInfo, target, REPLICA_SYNC_RETRY_DELAY);
            return;
        }

        long scheduleDelay = getReplicaSyncScheduleDelay(partitionId);
        schedulePartitionReplicaSync(syncInfo, target, scheduleDelay);
    }

    private long getReplicaSyncScheduleDelay(int partitionId) {
        long scheduleDelay = DEFAULT_REPLICA_SYNC_DELAY;
        Address thisAddress = node.getThisAddress();
        InternalPartitionImpl partition = getPartitionImpl(partitionId);
        ReplicaSyncInfo currentSyncInfo = replicaSyncRequests.get(partitionId);
        if (currentSyncInfo != null
                && !thisAddress.equals(partition.getReplicaAddress(currentSyncInfo.replicaIndex))) {
            clearReplicaSyncRequest(partitionId, currentSyncInfo.replicaIndex);
            scheduleDelay = REPLICA_SYNC_RETRY_DELAY;
        }
        return scheduleDelay;
    }

    private boolean fireSyncReplicaRequest(ReplicaSyncInfo syncInfo, Address target) {
        if (tryToAcquireReplicaSyncPermit()) {
            int partitionId = syncInfo.partitionId;
            int replicaIndex = syncInfo.replicaIndex;
            replicaSyncScheduler.cancel(partitionId);

            if (logger.isFinestEnabled()) {
                logger.finest("Sending sync replica request to -> " + target + "; for partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex);
            }
            replicaSyncScheduler.schedule(partitionMigrationTimeout, partitionId, syncInfo);
            ReplicaSyncRequest syncRequest = new ReplicaSyncRequest(partitionId, replicaIndex);
            nodeEngine.getOperationService().send(syncRequest, target);
            return true;
        }
        return false;
    }

    private void schedulePartitionReplicaSync(ReplicaSyncInfo syncInfo, Address target, long delayMillis) {
        int partitionId = syncInfo.partitionId;
        int replicaIndex = syncInfo.replicaIndex;

        if (logger.isFinestEnabled()) {
            logger.finest("Scheduling [" + delayMillis + "ms] sync replica request to -> " + target
                    + "; for partitionId=" + partitionId + ", replicaIndex=" + replicaIndex);
        }
        replicaSyncScheduler.schedule(delayMillis, partitionId, syncInfo);
    }

    private boolean checkSyncPartitionTarget(int partitionId, int replicaIndex) {
        final InternalPartitionImpl partition = getPartitionImpl(partitionId);
        final Address target = partition.getOwnerOrNull();
        if (target == null) {
            logger.info("Sync replica target is null, no need to sync -> partitionId=" + partitionId + ", replicaIndex="
                    + replicaIndex);
            return false;
        }

        Address thisAddress = nodeEngine.getThisAddress();
        if (target.equals(thisAddress)) {
            if (logger.isFinestEnabled()) {
                logger.finest("This node is now owner of partition, cannot sync replica -> partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex + ", partition-info="
                        + getPartitionImpl(partitionId));
            }
            return false;
        }

        if (!partition.isOwnerOrBackup(thisAddress)) {
            if (logger.isFinestEnabled()) {
                logger.finest("This node is not backup replica of partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex + " anymore.");
            }
            return false;
        }
        return true;
    }

    @Override
    public InternalPartition[] getPartitions() {
        
        InternalPartition[] result = new InternalPartition[partitions.length];
        System.arraycopy(partitions, 0, result, 0, partitions.length);
        return result;
    }

    @Override
    public MemberImpl getMember(Address address) {
        return node.clusterService.getMember(address);
    }

    InternalPartitionImpl getPartitionImpl(int partitionId) {
        return partitions[partitionId];
    }

    @Override
    public InternalPartitionImpl getPartition(int partitionId) {
        return getPartition(partitionId, true);
    }

    @Override
    public InternalPartitionImpl getPartition(int partitionId, boolean triggerOwnerAssignment) {
        InternalPartitionImpl p = getPartitionImpl(partitionId);
        if (triggerOwnerAssignment && p.getOwnerOrNull() == null) {
            
            
            getPartitionOwner(partitionId);
        }
        return p;
    }

    @Override
    public boolean prepareToSafeShutdown(long timeout, TimeUnit unit) {
        long timeoutInMillis = unit.toMillis(timeout);
        long sleep = DEFAULT_PAUSE_MILLIS;
        while (timeoutInMillis > 0) {
            while (timeoutInMillis > 0 && shouldWaitMigrationOrBackups(Level.INFO)) {
                timeoutInMillis = sleepWithBusyWait(timeoutInMillis, sleep);
            }
            if (timeoutInMillis <= 0) {
                break;
            }

            if (node.isMaster()) {
                syncPartitionRuntimeState();
            } else {
                timeoutInMillis = waitForOngoingMigrations(timeoutInMillis, sleep);
                if (timeoutInMillis <= 0) {
                    break;
                }
            }

            long start = Clock.currentTimeMillis();
            boolean ok = checkReplicaSyncState();
            timeoutInMillis -= (Clock.currentTimeMillis() - start);
            if (ok) {
                logger.finest("Replica sync state before shutdown is OK");
                return true;
            } else {
                if (timeoutInMillis <= 0) {
                    break;
                }
                logger.info("Some backup replicas are inconsistent with primary, waiting for synchronization. Timeout: "
                        + timeoutInMillis + "ms");
                timeoutInMillis = sleepWithBusyWait(timeoutInMillis, sleep);
            }
        }
        return false;
    }

    private long waitForOngoingMigrations(long timeoutInMillis, long sleep) {
        long timeout = timeoutInMillis;
        while (timeout > 0 && hasOnGoingMigrationMaster(Level.WARNING)) {
            
            logger.info("Waiting for the master node to complete remaining migrations!");
            timeout = sleepWithBusyWait(timeout, sleep);
        }
        return timeout;
    }

    private long sleepWithBusyWait(long timeoutInMillis, long sleep) {
        try {
            
            Thread.sleep(sleep);
        } catch (InterruptedException ie) {
            logger.finest("Busy wait interrupted", ie);
        }
        return timeoutInMillis - sleep;
    }

    @Override
    public boolean isMemberStateSafe() {
        return getMemberState() == SAFE;
    }

    public InternalPartitionServiceState getMemberState() {
        if (hasOnGoingMigrationLocal()) {
            return MIGRATION_LOCAL;
        }

        if (!node.isMaster()) {
            if (hasOnGoingMigrationMaster(Level.OFF)) {
                return MIGRATION_ON_MASTER;
            }
        }

        return isReplicaInSyncState() ? SAFE : REPLICA_NOT_SYNC;
    }

    @Override
    public boolean hasOnGoingMigration() {
        return hasOnGoingMigrationLocal() || (!node.isMaster() && hasOnGoingMigrationMaster(Level.FINEST));
    }

    private boolean hasOnGoingMigrationMaster(Level level) {
        Address masterAddress = node.getMasterAddress();
        if (masterAddress == null) {
            return true;
        }
        Operation operation = new HasOngoingMigration();
        OperationService operationService = nodeEngine.getOperationService();
        InvocationBuilder invocationBuilder = operationService.createInvocationBuilder(SERVICE_NAME, operation,
                masterAddress);
        Future future = invocationBuilder.setTryCount(100).setTryPauseMillis(100).invoke();
        try {
            return (Boolean) future.get(1, TimeUnit.MINUTES);
        } catch (InterruptedException ie) {
            Logger.getLogger(InternalPartitionServiceImpl.class).finest("Future wait interrupted", ie);
        } catch (Exception e) {
            logger.log(level, "Could not get a response from master about migrations! -> " + e.toString());
        }
        return false;
    }

    @Override
    public boolean hasOnGoingMigrationLocal() {
        return !activeMigrations.isEmpty() || !migrationQueue.isEmpty()
                || !isMigrationActive()
                || migrationThread.isMigrating()
                || shouldWaitMigrationOrBackups(Level.OFF);
    }

    private boolean isReplicaInSyncState() {
        if (!initialized || getMemberGroupsSize() < 2) {
            return true;
        }
        final int replicaIndex = 1;
        final List<Future> futures = new ArrayList<Future>();
        final Address thisAddress = node.getThisAddress();
        for (InternalPartitionImpl partition : partitions) {
            final Address owner = partition.getOwnerOrNull();
            if (thisAddress.equals(owner)) {
                if (partition.getReplicaAddress(replicaIndex) != null) {
                    final int partitionId = partition.getPartitionId();
                    final long replicaVersion = getCurrentReplicaVersion(replicaIndex, partitionId);
                    final Operation operation = createReplicaSyncStateOperation(replicaVersion, partitionId);
                    final Future future = invoke(operation, replicaIndex, partitionId);
                    futures.add(future);
                }
            }
        }
        if (futures.isEmpty()) {
            return true;
        }
        for (Future future : futures) {
            boolean isSync = getFutureResult(future, REPLICA_SYNC_CHECK_TIMEOUT_SECONDS, TimeUnit.SECONDS);
            if (!isSync) {
                return false;
            }
        }
        return true;
    }

    private long getCurrentReplicaVersion(int replicaIndex, int partitionId) {
        final long[] versions = getPartitionReplicaVersions(partitionId);
        return versions[replicaIndex - 1];
    }

    private boolean getFutureResult(Future future, long seconds, TimeUnit unit) {
        boolean sync;
        try {
            sync = (Boolean) future.get(seconds, unit);
        } catch (Throwable t) {
            sync = false;
            logger.warning("Exception while getting future", t);
        }
        return sync;
    }

    private Future invoke(Operation operation, int replicaIndex, int partitionId) {
        final OperationService operationService = nodeEngine.getOperationService();
        return operationService.createInvocationBuilder(InternalPartitionService.SERVICE_NAME, operation, partitionId)
                .setTryCount(3)
                .setTryPauseMillis(250)
                .setReplicaIndex(replicaIndex)
                .invoke();
    }

    private Operation createReplicaSyncStateOperation(long replicaVersion, int partitionId) {
        final Operation op = new IsReplicaVersionSync(replicaVersion);
        op.setService(this);
        op.setNodeEngine(nodeEngine);
        op.setResponseHandler(ResponseHandlerFactory
                .createErrorLoggingResponseHandler(node.getLogger(IsReplicaVersionSync.class)));
        op.setPartitionId(partitionId);

        return op;
    }

    private boolean checkReplicaSyncState() {
        if (!initialized) {
            return true;
        }

        if (getMemberGroupsSize() < 2) {
            return true;
        }

        final Address thisAddress = node.getThisAddress();
        final Semaphore s = new Semaphore(0);
        final AtomicBoolean ok = new AtomicBoolean(true);
        final ExecutionCallback<Object> callback = new ExecutionCallback<Object>() {
            @Override
            public void onResponse(Object response) {
                if (Boolean.FALSE.equals(response)) {
                    ok.compareAndSet(true, false);
                }
                s.release();
            }

            @Override
            public void onFailure(Throwable t) {
                ok.compareAndSet(true, false);
            }
        };
        int ownedCount = submitSyncReplicaOperations(thisAddress, s, ok, callback);
        try {
            if (ok.get()) {
                int permits = ownedCount * getMaxBackupCount();
                return s.tryAcquire(permits, REPLICA_SYNC_CHECK_TIMEOUT_SECONDS, TimeUnit.SECONDS) && ok.get();
            } else {
                return false;
            }
        } catch (InterruptedException ignored) {
            return false;
        }
    }

    private int submitSyncReplicaOperations(Address thisAddress, Semaphore s, AtomicBoolean ok,
                                            ExecutionCallback callback) {

        int ownedCount = 0;
        ILogger responseLogger = node.getLogger(SyncReplicaVersion.class);
        ResponseHandler responseHandler = ResponseHandlerFactory
                .createErrorLoggingResponseHandler(responseLogger);

        for (InternalPartitionImpl partition : partitions) {
            Address owner = partition.getOwnerOrNull();
            if (thisAddress.equals(owner)) {
                for (int i = 1; i <= getMaxBackupCount(); i++) {
                    if (partition.getReplicaAddress(i) != null) {
                        SyncReplicaVersion op = new SyncReplicaVersion(i, callback);
                        op.setService(this);
                        op.setNodeEngine(nodeEngine);
                        op.setResponseHandler(responseHandler);
                        op.setPartitionId(partition.getPartitionId());
                        nodeEngine.getOperationService().executeOperation(op);
                    } else {
                        ok.set(false);
                        s.release();
                    }
                }
                ownedCount++;
            } else if (owner == null) {
                ok.set(false);
            }
        }
        return ownedCount;
    }

    private boolean shouldWaitMigrationOrBackups(Level level) {
        if (!preCheckShouldWaitMigrationOrBackups()) {
            return false;
        }

        if (checkForActiveMigrations(level)) {
            return true;
        }

        for (InternalPartitionImpl partition : partitions) {
            if (partition.getReplicaAddress(1) == null) {
                if (logger.isLoggable(level)) {
                    logger.log(level, "Should take backup of partitionId=" + partition.getPartitionId());
                }
                return true;
            }
        }
        int replicaSyncProcesses = maxParallelReplications - replicaSyncProcessLock.availablePermits();
        if (replicaSyncProcesses > 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Processing replica sync requests: " + replicaSyncProcesses);
            }
            return true;
        }
        return false;
    }

    private boolean preCheckShouldWaitMigrationOrBackups() {
        if (!initialized) {
            return false;
        }

        if (getMemberGroupsSize() < 2) {
            return false;
        }

        return true;
    }

    private boolean checkForActiveMigrations(Level level) {
        final int activeSize = activeMigrations.size();
        if (activeSize != 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Waiting for active migration tasks: " + activeSize);
            }
            return true;
        }

        int queueSize = migrationQueue.size();
        if (queueSize != 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Waiting for cluster migration tasks: " + queueSize);
            }
            return true;
        }
        return false;
    }

    @Override
    public final int getPartitionId(Data key) {
        int hash = key.getPartitionHash();
        if (hash == Integer.MIN_VALUE) {
            return 0;
        } else {
            return Math.abs(hash) % partitionCount;
        }
    }

    @Override
    public final int getPartitionId(Object key) {
        return getPartitionId(nodeEngine.toData(key));
    }

    @Override
    public final int getPartitionCount() {
        return partitionCount;
    }

    public long getPartitionMigrationTimeout() {
        return partitionMigrationTimeout;
    }

    
    
    @Override
    public long[] incrementPartitionReplicaVersions(int partitionId, int backupCount) {
        PartitionReplicaVersions replicaVersion = replicaVersions[partitionId];
        return replicaVersion.incrementAndGet(backupCount);
    }

    
    @Override
    public void updatePartitionReplicaVersions(int partitionId, long[] versions, int replicaIndex) {
        PartitionReplicaVersions partitionVersion = replicaVersions[partitionId];
        if (!partitionVersion.update(versions, replicaIndex)) {
            
            triggerPartitionReplicaSync(partitionId, replicaIndex, 0L);
        }
    }

    
    
    @Override
    public long[] getPartitionReplicaVersions(int partitionId) {
        return replicaVersions[partitionId].get();
    }

    
    @Override
    public void setPartitionReplicaVersions(int partitionId, long[] versions, int replicaOffset) {
        replicaVersions[partitionId].set(versions, replicaOffset);
    }

    @Override
    public void clearPartitionReplicaVersions(int partitionId) {
        replicaVersions[partitionId].clear();
    }

    
    void finalizeReplicaSync(int partitionId, int replicaIndex, long[] versions) {
        PartitionReplicaVersions replicaVersion = replicaVersions[partitionId];
        replicaVersion.clear();
        replicaVersion.set(versions, replicaIndex);
        clearReplicaSyncRequest(partitionId, replicaIndex);
    }

    
    void clearReplicaSyncRequest(int partitionId, int replicaIndex) {
        ReplicaSyncInfo syncInfo = new ReplicaSyncInfo(partitionId, replicaIndex, null);
        ReplicaSyncInfo currentSyncInfo = replicaSyncRequests.get(partitionId);

        replicaSyncScheduler.cancelIfExists(partitionId, syncInfo);

        if (syncInfo.equals(currentSyncInfo)
                && replicaSyncRequests.compareAndSet(partitionId, currentSyncInfo, null)) {

            releaseReplicaSyncPermit();
        } else if (currentSyncInfo != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("Not able to cancel sync! " + syncInfo + " VS Current " + currentSyncInfo);
            }
        }
    }

    boolean tryToAcquireReplicaSyncPermit() {
        return replicaSyncProcessLock.tryAcquire();
    }

    void releaseReplicaSyncPermit() {
        replicaSyncProcessLock.release();
    }

    @Override
    public Map<Address, List<Integer>> getMemberPartitionsMap() {
        final int members = node.getClusterService().getSize();
        Map<Address, List<Integer>> memberPartitions = new HashMap<Address, List<Integer>>(members);
        for (int i = 0; i < partitionCount; i++) {
            Address owner;
            while ((owner = getPartitionOwner(i)) == null) {
                try {
                    Thread.sleep(PARTITION_OWNERSHIP_WAIT_MILLIS);
                } catch (InterruptedException e) {
                    throw new HazelcastException(e);
                }
            }
            List<Integer> ownedPartitions = memberPartitions.get(owner);
            if (ownedPartitions == null) {
                ownedPartitions = new ArrayList<Integer>();
                memberPartitions.put(owner, ownedPartitions);
            }
            ownedPartitions.add(i);
        }
        return memberPartitions;
    }

    @Override
    public List<Integer> getMemberPartitions(Address target) {
        List<Integer> ownedPartitions = new LinkedList<Integer>();
        for (int i = 0; i < partitionCount; i++) {
            final Address owner = getPartitionOwner(i);
            if (target.equals(owner)) {
                ownedPartitions.add(i);
            }
        }
        return ownedPartitions;
    }

    @Override
    public void reset() {
        migrationQueue.clear();
        for (int k = 0; k < replicaSyncRequests.length(); k++) {
            replicaSyncRequests.set(k, null);
        }
        replicaSyncScheduler.cancelAll();
        
        
        replicaSyncProcessLock.drainPermits();
        replicaSyncProcessLock.release(maxParallelReplications);

        lock.lock();
        try {
            initialized = false;
            for (InternalPartitionImpl partition : partitions) {
                partition.reset();
            }
            activeMigrations.clear();
            completedMigrations.clear();
            stateVersion.set(0);
        } finally {
            lock.unlock();
        }
    }

    public void pauseMigration() {
        migrationActive.set(false);
    }

    public void resumeMigration() {
        migrationActive.set(true);
    }

    public boolean isMigrationActive() {
        return migrationActive.get();
    }

    @Override
    public void shutdown(boolean terminate) {
        logger.finest("Shutting down the partition service");
        migrationThread.stopNow();
        reset();
    }

    public long getMigrationQueueSize() {
        return migrationQueue.size();
    }

    public PartitionServiceProxy getPartitionServiceProxy() {
        return proxy;
    }

    private void sendMigrationEvent(final MigrationInfo migrationInfo, final MigrationStatus status) {
        MemberImpl current = getMember(migrationInfo.getSource());
        MemberImpl newOwner = getMember(migrationInfo.getDestination());
        MigrationEvent event = new MigrationEvent(migrationInfo.getPartitionId(), current, newOwner, status);
        EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, MIGRATION_EVENT_TOPIC);
        eventService.publishEvent(SERVICE_NAME, registrations, event, event.getPartitionId());
    }

    @Override
    public String addMigrationListener(MigrationListener listener) {
        if (listener == null) {
            throw new NullPointerException("listener can't be null");
        }

        final MigrationListenerAdapter adapter = new MigrationListenerAdapter(listener);

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration = eventService.registerListener(SERVICE_NAME, MIGRATION_EVENT_TOPIC, adapter);
        return registration.getId();
    }

    @Override
    public boolean removeMigrationListener(String registrationId) {
        if (registrationId == null) {
            throw new NullPointerException("registrationId can't be null");
        }

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, MIGRATION_EVENT_TOPIC, registrationId);
    }

    @Override
    public String addPartitionLostListener(PartitionLostListener listener) {
        if (listener == null) {
            throw new NullPointerException("listener can't be null");
        }

        final PartitionLostListenerAdapter adapter = new PartitionLostListenerAdapter(listener);

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration = eventService.registerListener(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC, adapter);
        return registration.getId();
    }

    @Override
    public boolean removePartitionLostListener(String registrationId) {
        if (registrationId == null) {
            throw new NullPointerException("registrationId can't be null");
        }

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC, registrationId);
    }

    @Override
    public void dispatchEvent(PartitionEvent partitionEvent, PartitionEventListener partitionEventListener) {
        partitionEventListener.onEvent(partitionEvent);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder("PartitionManager[" + stateVersion + "] {\n");
        sb.append("\n");
        sb.append("migrationQ: ").append(migrationQueue.size());
        sb.append("\n}");
        return sb.toString();
    }

    public Node getNode() {
        return node;
    }

    @Override
    public boolean isPartitionOwner(int partitionId) {
        InternalPartitionImpl partition = getPartition(partitionId);
        return node.getThisAddress().equals(partition.getOwnerOrNull());
    }

    @Override
    public int getPartitionStateVersion() {
        return stateVersion.get();
    }

    @Override
    public void onPartitionLost(InternalPartitionLostEvent event) {
        final PartitionLostEvent partitionLostEvent = new PartitionLostEvent(event.getPartitionId(), event.getLostReplicaIndex(),
                event.getEventSource());
        final EventService eventService = nodeEngine.getEventService();
        final Collection<EventRegistration> registrations = eventService
                .getRegistrations(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC);
        eventService.publishEvent(SERVICE_NAME, registrations, partitionLostEvent, event.getPartitionId());
    }

    
    public List<ReplicaSyncInfo> getOngoingReplicaSyncRequests() {
        final int length = replicaSyncRequests.length();
        final List<ReplicaSyncInfo> replicaSyncRequestsList = new ArrayList<ReplicaSyncInfo>(length);
        for (int i = 0; i < length; i++) {
            final ReplicaSyncInfo replicaSyncInfo = replicaSyncRequests.get(i);
            if (replicaSyncInfo != null) {
                replicaSyncRequestsList.add(replicaSyncInfo);
            }
        }

        return replicaSyncRequestsList;
    }

    
    public List<ScheduledEntry<Integer, ReplicaSyncInfo>> getScheduledReplicaSyncRequests() {
        final List<ScheduledEntry<Integer, ReplicaSyncInfo>> entries = new ArrayList<ScheduledEntry<Integer, ReplicaSyncInfo>>();
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            final ScheduledEntry<Integer, ReplicaSyncInfo> entry = replicaSyncScheduler.get(partitionId);
            if (entry != null) {
               entries.add(entry);
            }
        }

        return entries;
    }

    private class SendClusterStateTask implements Runnable {
        @Override
        public void run() {
            if (node.isMaster() && node.isActive()) {
                if (!migrationQueue.isEmpty() && isMigrationActive()) {
                    logger.info("Remaining migration tasks in queue => " + migrationQueue.size());
                }
                publishPartitionRuntimeState();
            }
        }
    }

    private class SyncReplicaVersionTask implements Runnable {
        @Override
        public void run() {
            if (node.isActive() && migrationActive.get()) {
                for (InternalPartitionImpl partition : partitions) {
                    if (partition.isLocal()) {
                        for (int index = 1; index < InternalPartition.MAX_REPLICA_COUNT; index++) {
                            if (partition.getReplicaAddress(index) != null) {
                                SyncReplicaVersion op = new SyncReplicaVersion(index, null);
                                op.setService(InternalPartitionServiceImpl.this);
                                op.setNodeEngine(nodeEngine);
                                op.setResponseHandler(ResponseHandlerFactory
                                        .createErrorLoggingResponseHandler(node.getLogger(SyncReplicaVersion.class)));
                                op.setPartitionId(partition.getPartitionId());
                                nodeEngine.getOperationService().executeOperation(op);
                            }
                        }
                    }
                }
            }
        }
    }

    private class RepartitioningTask implements Runnable {
        @Override
        public void run() {
            if (node.isMaster() && node.isActive()) {
                lock.lock();
                try {
                    if (!initialized) {
                        return;
                    }
                    if (!isMigrationAllowed()) {
                        return;
                    }

                    migrationQueue.clear();
                    PartitionStateGenerator psg = partitionStateGenerator;
                    Collection<MemberImpl> members = node.getClusterService().getMemberList();
                    Collection<MemberGroup> memberGroups = memberGroupFactory.createMemberGroups(members);
                    Address[][] newState = psg.reArrange(memberGroups, partitions);

                    if (!isMigrationAllowed()) {
                        return;
                    }

                    int migrationCount = 0;
                    int lostCount = 0;
                    lastRepartitionTime.set(Clock.currentTimeMillis());
                    for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
                        Address[] replicas = newState[partitionId];
                        InternalPartitionImpl currentPartition = partitions[partitionId];
                        Address currentOwner = currentPartition.getOwnerOrNull();
                        Address newOwner = replicas[0];

                        if (currentOwner == null) {
                            
                            lostCount++;
                            assignNewPartitionOwner(partitionId, replicas, currentPartition, newOwner);
                        } else if (newOwner != null && !currentOwner.equals(newOwner)) {
                            if (logger.isFinestEnabled()) {
                                logger.finest("PartitionToMigrate partitionId=" + partitionId
                                        + " replicas=" + Arrays.toString(replicas) + " currentOwner="
                                        + currentOwner + " newOwner=" + newOwner);
                            }

                            migrationCount++;
                            migratePartitionToNewOwner(partitionId, replicas, currentOwner, newOwner);
                        } else {
                            currentPartition.setReplicaAddresses(replicas);
                        }
                    }
                    syncPartitionRuntimeState(members);
                    logMigrationStatistics(migrationCount, lostCount);
                } finally {
                    lock.unlock();
                }
            }
        }

        private void logMigrationStatistics(int migrationCount, int lostCount) {
            if (lostCount > 0) {
                logger.warning("Assigning new owners for " + lostCount + " LOST partitions!");
            }

            if (migrationCount > 0) {
                logger.info("Re-partitioning cluster data... Migration queue size: " + migrationCount);
            } else {
                logger.info("Partition balance is ok, no need to re-partition cluster data... ");
            }
        }

        private void migratePartitionToNewOwner(int partitionId, Address[] replicas, Address currentOwner, Address newOwner) {
            MigrationInfo info = new MigrationInfo(partitionId, currentOwner, newOwner);
            MigrateTask migrateTask = new MigrateTask(info, replicas);
            boolean offered = migrationQueue.offer(migrateTask);
            if (!offered) {
                logger.severe("Failed to offer: " + migrateTask);
            }
        }

        private void assignNewPartitionOwner(int partitionId, Address[] replicas, InternalPartitionImpl currentPartition,
                                             Address newOwner) {
            currentPartition.setReplicaAddresses(replicas);
            MigrationInfo migrationInfo = new MigrationInfo(partitionId, null, newOwner);
            sendMigrationEvent(migrationInfo, MigrationStatus.STARTED);
            sendMigrationEvent(migrationInfo, MigrationStatus.COMPLETED);
        }

        private boolean isMigrationAllowed() {
            if (isMigrationActive()) {
                return true;
            }
            migrationQueue.add(this);
            return false;
        }
    }

    private class MigrateTask implements Runnable {
        final MigrationInfo migrationInfo;
        final Address[] addresses;

        public MigrateTask(MigrationInfo migrationInfo, Address[] addresses) {
            this.migrationInfo = migrationInfo;
            this.addresses = addresses;
            final MemberImpl masterMember = getMasterMember();
            if (masterMember != null) {
                migrationInfo.setMasterUuid(masterMember.getUuid());
                migrationInfo.setMaster(masterMember.getAddress());
            }
        }

        @Override
        public void run() {
            if (!node.isActive() || !node.isMaster()) {
                return;
            }
            final MigrationRequestOperation migrationRequestOp = new MigrationRequestOperation(migrationInfo);
            try {
                MigrationInfo info = migrationInfo;
                InternalPartitionImpl partition = partitions[info.getPartitionId()];
                Address owner = partition.getOwnerOrNull();
                if (owner == null) {
                    logger.severe("ERROR: partition owner is not set! -> partitionId=" + info.getPartitionId()
                            + " , " + partition + " -VS- " + info);
                    return;
                }
                if (!owner.equals(info.getSource())) {
                    logger.severe("ERROR: partition owner is not the source of migration! -> partitionId="
                            + info.getPartitionId() + " , " + partition + " -VS- " + info + " found owner=" + owner);
                    return;
                }
                sendMigrationEvent(migrationInfo, MigrationStatus.STARTED);
                Boolean result;
                MemberImpl fromMember = getMember(migrationInfo.getSource());
                if (logger.isFinestEnabled()) {
                    logger.finest("Starting Migration: " + migrationInfo);
                }
                if (fromMember == null) {
                    
                    logger.warning("Partition is lost! Assign new owner and exit... partitionId=" + info.getPartitionId());
                    result = Boolean.TRUE;
                } else {
                    result = executeMigrateOperation(migrationRequestOp, fromMember);
                }
                processMigrationResult(result);
            } catch (Throwable t) {
                final Level level = migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Error [" + t.getClass() + ": " + t.getMessage() + "] while executing " + migrationRequestOp);
                logger.finest(t);
                migrationOperationFailed();
            }
        }

        private void processMigrationResult(Boolean result) {
            if (Boolean.TRUE.equals(result)) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Finished Migration: " + migrationInfo);
                }
                migrationOperationSucceeded();
            } else {
                final Level level = migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Migration failed: " + migrationInfo);
                migrationOperationFailed();
            }
        }

        private Boolean executeMigrateOperation(MigrationRequestOperation migrationRequestOp, MemberImpl fromMember) {
            Future future = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, migrationRequestOp,
                    migrationInfo.getSource())
                    .setCallTimeout(partitionMigrationTimeout)
                    .setTryPauseMillis(DEFAULT_PAUSE_MILLIS).invoke();

            try {
                Object response = future.get();
                return (Boolean) nodeEngine.toObject(response);
            } catch (Throwable e) {
                final Level level = node.isActive() && migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Failed migration from " + fromMember + " for " + migrationRequestOp.getMigrationInfo(), e);
            }
            return Boolean.FALSE;
        }

        private void migrationOperationFailed() {
            lock.lock();
            try {
                addCompletedMigration(migrationInfo);
                finalizeActiveMigration(migrationInfo);
                publishPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
            sendMigrationEvent(migrationInfo, MigrationStatus.FAILED);

            
            migrationQueue.add(new RepartitioningTask());
        }

        private void migrationOperationSucceeded() {
            lock.lock();
            try {
                final int partitionId = migrationInfo.getPartitionId();
                InternalPartitionImpl partition = partitions[partitionId];
                partition.setReplicaAddresses(addresses);
                addCompletedMigration(migrationInfo);
                finalizeActiveMigration(migrationInfo);
                syncPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
            sendMigrationEvent(migrationInfo, MigrationStatus.COMPLETED);
        }

        @Override
        public String toString() {
            return getClass().getSimpleName() + "{" + "migrationInfo=" + migrationInfo + '}';
        }
    }

    private class MigrationThread extends Thread implements Runnable {
        private final long sleepTime = Math.max(250L, partitionMigrationInterval);
        private volatile boolean migrating;

        MigrationThread(Node node) {
            super(node.getHazelcastThreadGroup().getInternalThreadGroup(),
                    node.getHazelcastThreadGroup().getThreadNamePrefix("migration"));
        }

        @Override
        public void run() {
            try {
                while (!isInterrupted()) {
                    doRun();
                }
            } catch (InterruptedException e) {
                if (logger.isFinestEnabled()) {
                    logger.finest("MigrationThread is interrupted: " + e.getMessage());
                }
            } catch (OutOfMemoryError e) {
                OutOfMemoryErrorDispatcher.onOutOfMemory(e);
            } finally {
                migrationQueue.clear();
            }
        }

        private void doRun() throws InterruptedException {
            for (; ; ) {
                if (!isMigrationActive()) {
                    break;
                }
                Runnable r = migrationQueue.poll(1, TimeUnit.SECONDS);
                if (r == null) {
                    break;
                }

                processTask(r);
                if (partitionMigrationInterval > 0) {
                    Thread.sleep(partitionMigrationInterval);
                }
            }
            boolean hasNoTasks = migrationQueue.isEmpty();
            if (hasNoTasks) {
                if (migrating) {
                    migrating = false;
                    logger.info("All migration tasks have been completed, queues are empty.");
                }
                evictCompletedMigrations();
                Thread.sleep(sleepTime);
            } else if (!isMigrationActive()) {
                Thread.sleep(sleepTime);
            }
        }

        boolean processTask(Runnable r) {
            if (r == null || isInterrupted()) {
                return false;
            }
            migrating = (r instanceof MigrateTask);
            try {
                r.run();
            } catch (Throwable t) {
                logger.warning(t);
            }
            return true;
        }

        void stopNow() {
            migrationQueue.clear();
            interrupt();
        }

        boolean isMigrating() {
            return migrating;
        }
    }

    private static final class LocalPartitionListener implements PartitionListener {
        final Address thisAddress;
        final InternalPartitionServiceImpl partitionService;

        private LocalPartitionListener(InternalPartitionServiceImpl partitionService, Address thisAddress) {
            this.thisAddress = thisAddress;
            this.partitionService = partitionService;
        }

        @Override
        public void replicaChanged(PartitionReplicaChangeEvent event) {
            final int partitionId = event.getPartitionId();
            final int replicaIndex = event.getReplicaIndex();
            final Address newAddress = event.getNewAddress();
            final Address oldAddress = event.getOldAddress();
            final PartitionReplicaChangeReason reason = event.getReason();

            final boolean initialAssignment = event.getOldAddress() == null;

            if (replicaIndex > 0) {
                
                if (thisAddress.equals(oldAddress)) {
                    clearPartition(partitionId, replicaIndex);
                } else if (thisAddress.equals(newAddress)) {
                    synchronizePartition(partitionId, replicaIndex, reason, initialAssignment);
                }
            } else {
                if (!initialAssignment && thisAddress.equals(newAddress)) {
                    
                    
                    
                    promoteFromBackups(partitionId, reason, oldAddress);
                }
                partitionService.cancelReplicaSync(partitionId);
            }

            Node node = partitionService.node;
            if (replicaIndex == 0 && newAddress == null && node.isActive() && node.joined()) {
                logOwnerOfPartitionIsRemoved(event);
            }
            if (node.isMaster()) {
                partitionService.stateVersion.incrementAndGet();
            }
        }

        private void clearPartition(final int partitionId, final int oldReplicaIndex) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            ClearReplicaOperation op = new ClearReplicaOperation(oldReplicaIndex);
            op.setPartitionId(partitionId).setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void synchronizePartition(int partitionId, int replicaIndex,
                                          PartitionReplicaChangeReason reason, boolean initialAssignment) {
            
            if (partitionService.initialized) {
                long delayMillis = 0L;
                if (replicaIndex > 1) {
                    
                    
                    
                    delayMillis = (long) (REPLICA_SYNC_RETRY_DELAY + (Math.random() * DEFAULT_REPLICA_SYNC_DELAY));
                }

                resetReplicaVersion(partitionId, replicaIndex, reason, initialAssignment);
                partitionService.triggerPartitionReplicaSync(partitionId, replicaIndex, delayMillis);
            }
        }

        private void resetReplicaVersion(int partitionId, int replicaIndex,
                                         PartitionReplicaChangeReason reason, boolean initialAssignment) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            ResetReplicaVersionOperation op = new ResetReplicaVersionOperation(reason, initialAssignment);
            op.setPartitionId(partitionId).setReplicaIndex(replicaIndex)
              .setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void promoteFromBackups(int partitionId, PartitionReplicaChangeReason reason, Address oldAddress) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            PromoteFromBackupOperation op = new PromoteFromBackupOperation(reason, oldAddress);
            op.setPartitionId(partitionId).setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void logOwnerOfPartitionIsRemoved(PartitionReplicaChangeEvent event) {
            String warning = "Owner of partition is being removed! "
                    + "Possible data loss for partitionId=" + event.getPartitionId() + " , " + event;
            partitionService.logger.warning(warning);
        }
    }

    private static class ReplicaSyncEntryProcessor implements ScheduledEntryProcessor<Integer, ReplicaSyncInfo> {

        final InternalPartitionServiceImpl partitionService;

        ReplicaSyncEntryProcessor(InternalPartitionServiceImpl partitionService) {
            this.partitionService = partitionService;
        }

        @Override
        public void process(EntryTaskScheduler<Integer, ReplicaSyncInfo> scheduler,
                            Collection<ScheduledEntry<Integer, ReplicaSyncInfo>> entries) {

            for (ScheduledEntry<Integer, ReplicaSyncInfo> entry : entries) {
                ReplicaSyncInfo syncInfo = entry.getValue();
                int partitionId = syncInfo.partitionId;
                if (partitionService.replicaSyncRequests.compareAndSet(partitionId, syncInfo, null)) {
                    partitionService.releaseReplicaSyncPermit();
                }

                InternalPartitionImpl partition = partitionService.getPartitionImpl(partitionId);
                int currentReplicaIndex = partition.getReplicaIndex(partitionService.node.getThisAddress());
                if (currentReplicaIndex > 0) {
                    partitionService.triggerPartitionReplicaSync(partitionId, currentReplicaIndex, 0L);
                }
            }
        }
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberLeftException;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationEndpoint;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.MigrationAwareService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.PartitionMigrationEvent;
import com.hazelcast.spi.PartitionReplicationEvent;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.impl.SimpleExecutionCallback;
import com.hazelcast.spi.impl.servicemanager.ServiceInfo;
import com.hazelcast.spi.exception.RetryableHazelcastException;
import com.hazelcast.spi.exception.TargetNotMemberException;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;
import java.util.Collection;
import java.util.LinkedList;
import java.util.concurrent.ExecutionException;
import java.util.logging.Level;

public final class MigrationRequestOperation extends BaseMigrationOperation {

    private static final int TRY_PAUSE_MILLIS = 1000;

    private boolean returnResponse = true;

    public MigrationRequestOperation() {
    }

    public MigrationRequestOperation(MigrationInfo migrationInfo) {
        super(migrationInfo);
    }

    public void run() {
        NodeEngine nodeEngine = getNodeEngine();
        verifyGoodMaster(nodeEngine);

        Address source = migrationInfo.getSource();
        Address destination = migrationInfo.getDestination();
        verifyExistingTarget(nodeEngine, destination);

        if (destination.equals(source)) {
            getLogger().warning("Source and destination addresses are the same! => " + toString());
            success = false;
            return;
        }

        verifyNotThisNode(nodeEngine, source);

        InternalPartitionServiceImpl partitionService = getService();
        InternalPartition partition = partitionService.getPartition(migrationInfo.getPartitionId());
        Address owner = partition.getOwnerOrNull();
        verifyOwnerExists(owner);

        if (!migrationInfo.startProcessing()) {
            getLogger().warning("Migration is cancelled -> " + migrationInfo);
            success = false;
            return;
        }

        try {
            verifyOwner(source, partition, owner);
            partitionService.addActiveMigration(migrationInfo);
            Collection<Operation> tasks = prepareMigrationTasks();
            if (tasks.size() > 0) {
                long[] replicaVersions = partitionService.getPartitionReplicaVersions(migrationInfo.getPartitionId());
                invokeMigrationOperation(destination, replicaVersions, tasks);
                returnResponse = false;
            } else {
                success = true;
            }
        } catch (Throwable e) {
            logThrowable(e);
            success = false;
        } finally {
            migrationInfo.doneProcessing();
        }
    }

    private void logThrowable(Throwable t) {
        Throwable throwableToLog = t;
        if (throwableToLog instanceof ExecutionException) {
            throwableToLog = throwableToLog.getCause() != null ? throwableToLog.getCause() : throwableToLog;
        }
        Level level = getLogLevel(throwableToLog);
        getLogger().log(level, throwableToLog.getMessage(), throwableToLog);
    }

    private Level getLogLevel(Throwable e) {
        return (e instanceof MemberLeftException || e instanceof InterruptedException)
                || !getNodeEngine().isActive() ? Level.INFO : Level.WARNING;
    }

    private void verifyNotThisNode(NodeEngine nodeEngine, Address source) {
        if (source == null || !source.equals(nodeEngine.getThisAddress())) {
            throw new RetryableHazelcastException("Source of migration is not this node! => " + toString());
        }
    }

    private void verifyOwnerExists(Address owner) {
        if (owner == null) {
            throw new RetryableHazelcastException("Cannot migrate at the moment! Owner of the partition is null => "
                    + migrationInfo);
        }
    }

    private void verifyOwner(Address source, InternalPartition partition, Address owner) {
        if (!source.equals(owner)) {
            throw new HazelcastException("Cannot migrate! This node is not owner of the partition => "
                    + migrationInfo + " -> partitionId=" + partition.getPartitionId() + " , " + partition);
        }
    }

    private void invokeMigrationOperation(Address destination, long[] replicaVersions, Collection<Operation> tasks)
            throws IOException {

        MigrationOperation operation = new MigrationOperation(migrationInfo, replicaVersions, tasks);

        NodeEngine nodeEngine = getNodeEngine();
        InternalPartitionServiceImpl partitionService = getService();

        nodeEngine.getOperationService()
                .createInvocationBuilder(InternalPartitionService.SERVICE_NAME, operation, destination)
                .setExecutionCallback(new MigrationCallback(migrationInfo, getResponseHandler()))
                .setResultDeserialized(true)
                .setCallTimeout(partitionService.getPartitionMigrationTimeout())
                .setTryPauseMillis(TRY_PAUSE_MILLIS)
                .setReplicaIndex(getReplicaIndex())
                .invoke();
    }

    private void verifyGoodMaster(NodeEngine nodeEngine) {
        Address masterAddress = nodeEngine.getMasterAddress();
        if (!masterAddress.equals(migrationInfo.getMaster())) {
            throw new RetryableHazelcastException("Migration initiator is not master node! => " + toString());
        }
        if (!masterAddress.equals(getCallerAddress())) {
            throw new RetryableHazelcastException("Caller is not master node! => " + toString());
        }
    }

    private void verifyExistingTarget(NodeEngine nodeEngine, Address destination) {
        Member target = nodeEngine.getClusterService().getMember(destination);
        if (target == null) {
            throw new TargetNotMemberException("Destination of migration could not be found! => " + toString());
        }
    }

    @Override
    public ExceptionAction onException(Throwable throwable) {
        if (throwable instanceof TargetNotMemberException) {
            return ExceptionAction.THROW_EXCEPTION;
        }
        return super.onException(throwable);
    }

    @Override
    public Object getResponse() {
        return success;
    }

    @Override
    public boolean returnsResponse() {
        return returnResponse;
    }

    private Collection<Operation> prepareMigrationTasks() {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        PartitionReplicationEvent replicationEvent = new PartitionReplicationEvent(migrationInfo.getPartitionId(), 0);
        PartitionMigrationEvent migrationEvent
                = new PartitionMigrationEvent(MigrationEndpoint.SOURCE, migrationInfo.getPartitionId());

        Collection<Operation> tasks = new LinkedList<Operation>();
        for (ServiceInfo serviceInfo : nodeEngine.getServiceInfos(MigrationAwareService.class)) {
            MigrationAwareService service = (MigrationAwareService) serviceInfo.getService();
            service.beforeMigration(migrationEvent);
            Operation op = service.prepareReplicationOperation(replicationEvent);
            if (op != null) {
                op.setServiceName(serviceInfo.getName());
                tasks.add(op);
            }
        }
        return tasks;
    }

    private static final class MigrationCallback extends SimpleExecutionCallback<Object> {

        final MigrationInfo migrationInfo;
        final ResponseHandler responseHandler;

        private MigrationCallback(MigrationInfo migrationInfo, ResponseHandler responseHandler) {
            this.migrationInfo = migrationInfo;
            this.responseHandler = responseHandler;
        }

        @Override
        public void notify(Object result) {
            migrationInfo.doneProcessing();
            responseHandler.sendResponse(result);
        }
    }
}

<code block>


package com.hazelcast.cache.impl.client;

import com.hazelcast.cache.impl.CachePortableHook;
import com.hazelcast.cache.impl.CacheService;
import com.hazelcast.cache.impl.operation.CacheCreateConfigOperation;
import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.impl.client.ClientRequest;
import com.hazelcast.config.CacheConfig;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.PortableReader;
import com.hazelcast.nio.serialization.PortableWriter;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.SimpleExecutionCallback;

import java.io.IOException;
import java.security.Permission;


public class CacheCreateConfigRequest
        extends ClientRequest {

    private static final int TRY_COUNT = 100;

    private CacheConfig cacheConfig;
    private boolean createAlsoOnOthers = true;
    private boolean ignoreLocal;
    private int partitionId;

    public CacheCreateConfigRequest() {
    }

    public CacheCreateConfigRequest(CacheConfig cacheConfig, boolean createAlsoOnOthers, boolean ignoreLocal,
                                    int partitionId) {
        this.cacheConfig = cacheConfig;
        this.createAlsoOnOthers = createAlsoOnOthers;
        this.ignoreLocal = ignoreLocal;
        this.partitionId = partitionId;
    }

    @Override
    public final void process()
            throws Exception {
        final ClientEndpoint endpoint = getEndpoint();
        final Operation op = prepareOperation();
        op.setCallerUuid(endpoint.getUuid());
        final InvocationBuilder builder = operationService.createInvocationBuilder(getServiceName(), op, partitionId);
        builder.setTryCount(TRY_COUNT)
                .setResultDeserialized(false)
                .setExecutionCallback(new SimpleExecutionCallback<Object>() {
                    public void notify(Object object) {
                        endpoint.sendResponse(object, getCallId());
                    }
                });
        builder.invoke();
    }

    protected Operation prepareOperation() {
        return new CacheCreateConfigOperation(cacheConfig, createAlsoOnOthers, ignoreLocal);
    }

    @Override
    public final int getFactoryId() {
        return CachePortableHook.F_ID;
    }

    @Override
    public int getClassId() {
        return CachePortableHook.CREATE_CONFIG;
    }

    @Override
    public String getServiceName() {
        return CacheService.SERVICE_NAME;
    }

    @Override
    public void write(PortableWriter writer)
            throws IOException {
        writer.writeBoolean("o", createAlsoOnOthers);
        writer.writeBoolean("l", ignoreLocal);
        writer.writeInt("p", partitionId);
        final ObjectDataOutput out = writer.getRawDataOutput();
        out.writeObject(cacheConfig);
    }

    @Override
    public void read(PortableReader reader)
            throws IOException {
        createAlsoOnOthers = reader.readBoolean("o");
        ignoreLocal = reader.readBoolean("l");
        partitionId = reader.readInt("p");
        final ObjectDataInput in = reader.getRawDataInput();
        cacheConfig = in.readObject();
    }

    @Override
    public Permission getRequiredPermission() {
        return null;
    }

}

<code block>


package com.hazelcast.cache.impl.client;

import com.hazelcast.cache.impl.CachePortableHook;
import com.hazelcast.cache.impl.CacheService;
import com.hazelcast.cache.impl.operation.CacheDestroyOperation;
import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.impl.client.ClientRequest;
import com.hazelcast.nio.serialization.PortableReader;
import com.hazelcast.nio.serialization.PortableWriter;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.SimpleExecutionCallback;

import java.io.IOException;
import java.security.Permission;


public class CacheDestroyRequest
        extends ClientRequest {

    private static final int TRY_COUNT = 100;

    private String name;
    private int partitionId;

    public CacheDestroyRequest() {
    }

    public CacheDestroyRequest(String name, int partitionId) {
        this.name = name;
        this.partitionId = partitionId;
    }

    @Override
    public final void process()
            throws Exception {
        final ClientEndpoint endpoint = getEndpoint();
        final Operation op = prepareOperation();
        op.setCallerUuid(endpoint.getUuid());
        final InvocationBuilder builder = operationService.createInvocationBuilder(getServiceName(), op, partitionId);
        builder.setTryCount(TRY_COUNT)
                .setResultDeserialized(false)
                .setExecutionCallback(new SimpleExecutionCallback<Object>() {
                    public void notify(Object object) {
                        endpoint.sendResponse(object, getCallId());
                    }
                });
        builder.invoke();
    }

    protected Operation prepareOperation() {
        return new CacheDestroyOperation(name);
    }

    @Override
    public final int getFactoryId() {
        return CachePortableHook.F_ID;
    }

    @Override
    public int getClassId() {
        return CachePortableHook.DESTROY_CACHE;
    }

    @Override
    public String getServiceName() {
        return CacheService.SERVICE_NAME;
    }

    @Override
    public void write(PortableWriter writer)
            throws IOException {
        writer.writeUTF("n", name);
        writer.writeInt("p", partitionId);
    }

    @Override
    public void read(PortableReader reader)
            throws IOException {
        name = reader.readUTF("n");
        partitionId = reader.readInt("p");
    }

    @Override
    public Permission getRequiredPermission() {
        return null;
    }

}

<code block>


package com.hazelcast.cache.impl.operation;

import com.hazelcast.cache.impl.AbstractCacheService;
import com.hazelcast.cache.impl.CacheDataSerializerHook;
import com.hazelcast.cache.impl.CacheService;
import com.hazelcast.config.CacheConfig;
import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.impl.AbstractNamedOperation;
import com.hazelcast.spi.impl.SimpleExecutionCallback;

import java.io.IOException;
import java.util.Collection;
import java.util.concurrent.atomic.AtomicInteger;


public class CacheCreateConfigOperation
        extends AbstractNamedOperation
        implements IdentifiedDataSerializable {

    private CacheConfig config;
    private boolean createAlsoOnOthers = true;
    private boolean ignoreLocal;

    private boolean returnsResponse = true;
    private transient Object response;

    public CacheCreateConfigOperation() {
    }

    public CacheCreateConfigOperation(CacheConfig config) {
        this(config, true);
    }

    public CacheCreateConfigOperation(CacheConfig config, boolean createAlsoOnOthers) {
        this(config, createAlsoOnOthers, false);
    }

    public CacheCreateConfigOperation(CacheConfig config, boolean createAlsoOnOthers, boolean ignoreLocal) {
        super(config.getNameWithPrefix());
        this.config = config;
        this.createAlsoOnOthers = createAlsoOnOthers;
        this.ignoreLocal = ignoreLocal;
    }

    @Override
    public String getServiceName() {
        return CacheService.SERVICE_NAME;
    }

    @Override
    public void run() throws Exception {
        AbstractCacheService service = getService();
        if (!ignoreLocal) {
            response = service.createCacheConfigIfAbsent(config);
        }
        if (createAlsoOnOthers) {
            NodeEngine nodeEngine = getNodeEngine();
            Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
            int remoteNodeCount = members.size() - 1;

            if (remoteNodeCount > 0) {
                postponeReturnResponse();

                ExecutionCallback<Object> callback = new CacheConfigCreateCallback(getResponseHandler(), remoteNodeCount);
                OperationService operationService = nodeEngine.getOperationService();
                for (MemberImpl member : members) {
                    if (!member.localMember()) {
                        CacheCreateConfigOperation op = new CacheCreateConfigOperation(config, false);
                        operationService
                                .createInvocationBuilder(AbstractCacheService.SERVICE_NAME, op, member.getAddress())
                                .setExecutionCallback(callback)
                                .invoke();
                    }
                }
            }
        }
    }

    private void postponeReturnResponse() {
        
        
        returnsResponse = false;
    }

    private static class CacheConfigCreateCallback extends SimpleExecutionCallback<Object> {

        final ResponseHandler responseHandler;
        final AtomicInteger counter;

        public CacheConfigCreateCallback(ResponseHandler responseHandler, int count) {
            this.responseHandler = responseHandler;
            counter = new AtomicInteger(count);
        }

        @Override
        public void notify(Object object) {
            if (counter.decrementAndGet() == 0) {
                responseHandler.sendResponse(null);
            }
        }
    }

    @Override
    public Object getResponse() {
        return response;
    }

    @Override
    public boolean returnsResponse() {
        return returnsResponse;
    }

    @Override
    protected void writeInternal(ObjectDataOutput out)
            throws IOException {
        super.writeInternal(out);
        out.writeObject(config);
        out.writeBoolean(createAlsoOnOthers);
        out.writeBoolean(ignoreLocal);
    }

    @Override
    protected void readInternal(ObjectDataInput in)
            throws IOException {
        super.readInternal(in);
        config = in.readObject();
        createAlsoOnOthers = in.readBoolean();
        ignoreLocal = in.readBoolean();
    }

    @Override
    public int getId() {
        return CacheDataSerializerHook.CREATE_CONFIG;
    }

    @Override
    public int getFactoryId() {
        return CacheDataSerializerHook.F_ID;
    }

}

<code block>


package com.hazelcast.spi;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.spi.impl.NodeEngineImpl;


public abstract class InvocationBuilder {

    
    public static final long DEFAULT_CALL_TIMEOUT = -1L;

    
    public static final int DEFAULT_REPLICA_INDEX = 0;

    
    public static final int DEFAULT_TRY_COUNT = 250;

    
    public static final long DEFAULT_TRY_PAUSE_MILLIS = 500;

    
    public static final boolean DEFAULT_DESERIALIZE_RESULT = true;

    protected final NodeEngineImpl nodeEngine;
    protected final String serviceName;
    protected final Operation op;
    protected final int partitionId;
    protected final Address target;
    protected Callback<Object> callback;
    protected ExecutionCallback<Object> executionCallback;

    protected long callTimeout = DEFAULT_CALL_TIMEOUT;
    protected int replicaIndex;
    protected int tryCount = DEFAULT_TRY_COUNT;
    protected long tryPauseMillis = DEFAULT_TRY_PAUSE_MILLIS;
    protected boolean resultDeserialized = DEFAULT_DESERIALIZE_RESULT;

    
    public InvocationBuilder(NodeEngineImpl nodeEngine, String serviceName, Operation op,
                             int partitionId, Address target) {
        this.nodeEngine = nodeEngine;
        this.serviceName = serviceName;
        this.op = op;
        this.partitionId = partitionId;
        this.target = target;
    }

     
    public InvocationBuilder setReplicaIndex(int replicaIndex) {
        if (replicaIndex < 0 || replicaIndex >= InternalPartition.MAX_REPLICA_COUNT) {
            throw new IllegalArgumentException("Replica index is out of range [0-"
                    + (InternalPartition.MAX_REPLICA_COUNT - 1) + "]");
        }
        this.replicaIndex = replicaIndex;
        return this;
    }

    
    public boolean isResultDeserialized() {
        return resultDeserialized;
    }

    
    public InvocationBuilder setResultDeserialized(boolean resultDeserialized) {
        this.resultDeserialized = resultDeserialized;
        return this;
    }

    
    public InvocationBuilder setTryCount(int tryCount) {
        this.tryCount = tryCount;
        return this;
    }

    
    public InvocationBuilder setTryPauseMillis(long tryPauseMillis) {
        this.tryPauseMillis = tryPauseMillis;
        return this;
    }

    public InvocationBuilder setCallTimeout(long callTimeout) {
        this.callTimeout = callTimeout;
        return this;
    }

    
    public String getServiceName() {
        return serviceName;
    }

    
    public Operation getOp() {
        return op;
    }

    

    public int getReplicaIndex() {
        return replicaIndex;
    }

    
    public int getTryCount() {
        return tryCount;
    }

    
    public long getTryPauseMillis() {
        return tryPauseMillis;
    }

    
    public Address getTarget() {
        return target;
    }

    
    public int getPartitionId() {
        return partitionId;
    }

    public long getCallTimeout() {
        return callTimeout;
    }

    
    @Deprecated
    public Callback getCallback() {
        return callback;
    }

    
    @Deprecated
    public InvocationBuilder setCallback(Callback<Object> callback) {
        if (executionCallback != null) {
            throw new IllegalStateException("Can't set the callback if executionCallback already is set");
        }
        this.callback = callback;
        return this;
    }

    
    public ExecutionCallback<Object> getExecutionCallback() {
        return executionCallback;
    }

    
    public InvocationBuilder setExecutionCallback(ExecutionCallback<Object> executionCallback) {
        if (callback != null) {
            throw new IllegalStateException("Can't set the executionCallback if callback already is set");
        }
        this.executionCallback = executionCallback;
        return this;
    }

    protected ExecutionCallback getTargetExecutionCallback() {
        ExecutionCallback targetCallback = executionCallback;
        if (callback != null) {
            targetCallback = new ExecutorCallbackAdapter(callback);
        }
        return targetCallback;
    }

    static final class ExecutorCallbackAdapter<E> implements ExecutionCallback<E> {
        private final Callback callback;

        private ExecutorCallbackAdapter(Callback callback) {
            this.callback = callback;
        }

        @Override
        public void onResponse(E response) {
            callback.notify(response);
        }

        @Override
        public void onFailure(Throwable t) {
            callback.notify(t);
        }
    }

    public abstract <E> InternalCompletableFuture<E> invoke();
}

<code block>


package com.hazelcast.spi.impl;

import com.hazelcast.core.ExecutionCallback;


public abstract class SimpleExecutionCallback<E> implements ExecutionCallback<E> {

    public abstract void notify(Object response);

    @Override
    public final void onResponse(E response) {
        notify(response);
    }

    @Override
    public final void onFailure(Throwable t) {
        notify(t);
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.MemberLeftException;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.NodeEngineImpl;


public final class TargetInvocation extends Invocation {

    private final Address target;

    public TargetInvocation(NodeEngineImpl nodeEngine, String serviceName, Operation op,
                            Address target, int tryCount, long tryPauseMillis, long callTimeout,
                            ExecutionCallback callback, boolean resultDeserialized) {
        super(nodeEngine, serviceName, op, op.getPartitionId(), op.getReplicaIndex(),
                tryCount, tryPauseMillis, callTimeout, callback, resultDeserialized);
        this.target = target;
    }

    @Override
    public Address getTarget() {
        return target;
    }

    @Override
    ExceptionAction onException(Throwable t) {
        return t instanceof MemberLeftException ? ExceptionAction.THROW_EXCEPTION : op.onException(t);
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.impl.operationservice.impl.responses.Response;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;

import java.util.concurrent.ExecutionException;
import java.util.concurrent.Executor;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;

import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.INTERRUPTED_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.NULL_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.TIMEOUT_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.WAIT_RESPONSE;
import static com.hazelcast.util.ExceptionUtil.fixRemoteStackTrace;
import static com.hazelcast.util.Preconditions.isNotNull;
import static java.lang.Math.min;


final class InvocationFuture<E> implements InternalCompletableFuture<E> {

    private static final int MAX_CALL_TIMEOUT_EXTENSION = 60 * 1000;

    private static final AtomicReferenceFieldUpdater<InvocationFuture, Object> RESPONSE
            = AtomicReferenceFieldUpdater.newUpdater(InvocationFuture.class, Object.class, "response");
    private static final AtomicIntegerFieldUpdater<InvocationFuture> WAITER_COUNT
            = AtomicIntegerFieldUpdater.newUpdater(InvocationFuture.class, "waiterCount");

    volatile boolean interrupted;
    volatile Object response;

    
    
    private volatile int waiterCount;
    private final OperationServiceImpl operationService;
    private final Invocation invocation;
    private volatile ExecutionCallbackNode<E> callbackHead;

    InvocationFuture(OperationServiceImpl operationService, Invocation invocation, ExecutionCallback callback) {
        this.invocation = invocation;
        this.operationService = operationService;

        if (callback != null) {
            callbackHead = new ExecutionCallbackNode<E>(callback, operationService.asyncExecutor, null);
        }
    }

    static long decrementTimeout(long timeout, long diff) {
        if (timeout == Long.MAX_VALUE) {
            return timeout;
        }

        return timeout - diff;
    }

    @Override
    public void andThen(ExecutionCallback<E> callback, Executor executor) {
        isNotNull(callback, "callback");
        isNotNull(executor, "executor");

        synchronized (this) {
            if (responseAvailable(response)) {
                runAsynchronous(callback, executor);
                return;
            }

            this.callbackHead = new ExecutionCallbackNode<E>(callback, executor, callbackHead);
        }
    }

    private boolean responseAvailable(Object response) {
        if (response == null) {
            return false;
        }

        if (response == InternalResponse.WAIT_RESPONSE) {
            return false;
        }

        return true;
    }

    @Override
    public void andThen(ExecutionCallback<E> callback) {
        andThen(callback, operationService.asyncExecutor);
    }

    private void runAsynchronous(final ExecutionCallback<E> callback, Executor executor) {
        try {
            executor.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        Object resp = resolveApplicationResponse(response);

                        if (resp == null || !(resp instanceof Throwable)) {
                            callback.onResponse((E) resp);
                        } else {
                            callback.onFailure((Throwable) resp);
                        }
                    } catch (Throwable cause) {
                        invocation.logger.severe("Failed asynchronous execution of execution callback: " + callback
                                + "for call " + invocation, cause);
                    }
                }
            });
        } catch (RejectedExecutionException e) {
            invocation.logger.warning("Execution of callback: " + callback + " is rejected!", e);
        }
    }

    
    public void set(Object offeredResponse) {
        assert !(offeredResponse instanceof Response) : "unexpected response found: " + offeredResponse;

        if (offeredResponse == null) {
            offeredResponse = NULL_RESPONSE;
        }

        ExecutionCallbackNode<E> callbackChain;
        synchronized (this) {
            if (response != null && !(response instanceof InternalResponse)) {
                
                
                

                
                ILogger logger = invocation.logger;
                if (logger.isFinestEnabled()) {
                    logger.finest("Future response is already set! Current response: "
                            + response + ", Offered response: " + offeredResponse + ", Invocation: " + invocation);
                }
                return;
            }

            response = offeredResponse;
            if (offeredResponse == WAIT_RESPONSE) {
                return;
            }
            callbackChain = callbackHead;
            callbackHead = null;
            notifyAll();

            operationService.invocationsRegistry.deregister(invocation);
        }


        notifyCallbacks(callbackChain);
    }

    private void notifyCallbacks(ExecutionCallbackNode<E> callbackChain) {
        while (callbackChain != null) {
            runAsynchronous(callbackChain.callback, callbackChain.executor);
            callbackChain = callbackChain.next;
        }
    }

    @Override
    public E get() throws InterruptedException, ExecutionException {
        try {
            return get(Long.MAX_VALUE, TimeUnit.MILLISECONDS);
        } catch (TimeoutException e) {
            invocation.logger.severe("Unexpected timeout while processing " + this, e);
            return null;
        }
    }

    @Override
    public E getSafely() {
        try {
            
            
            return get();
        } catch (Throwable throwable) {
            throw ExceptionUtil.rethrow(throwable);
        }
    }

    @Override
    public E get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {
        Object unresolvedResponse = waitForResponse(timeout, unit);
        return (E) resolveApplicationResponseOrThrowException(unresolvedResponse);
    }

    private Object waitForResponse(long time, TimeUnit unit) {
        if (responseAvailable(response)) {
            return response;
        }

        WAITER_COUNT.incrementAndGet(this);
        try {
            long timeoutMs = toTimeoutMs(time, unit);
            long maxCallTimeoutMs = getMaxCallTimeout();
            boolean longPolling = timeoutMs > maxCallTimeoutMs;

            int pollCount = 0;
            while (timeoutMs >= 0) {
                long pollTimeoutMs = min(maxCallTimeoutMs, timeoutMs);
                long startMs = Clock.currentTimeMillis();
                long lastPollTime = 0;
                pollCount++;

                try {
                    pollResponse(pollTimeoutMs);
                    lastPollTime = Clock.currentTimeMillis() - startMs;
                    timeoutMs = decrementTimeout(timeoutMs, lastPollTime);

                    if (response == WAIT_RESPONSE) {
                        RESPONSE.compareAndSet(this, WAIT_RESPONSE, null);
                        continue;
                    } else if (response != null) {
                        
                        
                        if (response != INTERRUPTED_RESPONSE && interrupted) {
                            Thread.currentThread().interrupt();
                        }
                        return response;
                    }
                } catch (InterruptedException e) {
                    interrupted = true;
                }

                if (!interrupted && longPolling) {
                    
                    Address target = invocation.getTarget();
                    if (invocation.remote && invocation.nodeEngine.getThisAddress().equals(target)) {
                        
                        continue;
                    }

                    invocation.logger.warning("No response for " + lastPollTime + " ms. " + toString());
                    boolean executing = operationService.getIsStillRunningService().isOperationExecuting(invocation);
                    if (!executing) {
                        Object operationTimeoutException = invocation.newOperationTimeoutException(pollCount * pollTimeoutMs);
                        
                        set(operationTimeoutException);
                    }
                }
            }
            return TIMEOUT_RESPONSE;
        } finally {
            WAITER_COUNT.decrementAndGet(this);
        }
    }

    private void pollResponse(long pollTimeoutMs) throws InterruptedException {
        
        if (pollTimeoutMs <= 0 || response != null) {
            return;
        }

        long currentTimeoutMs = pollTimeoutMs;
        long waitStart = Clock.currentTimeMillis();
        synchronized (this) {
            while (currentTimeoutMs > 0 && response == null) {
                wait(currentTimeoutMs);
                currentTimeoutMs = pollTimeoutMs - (Clock.currentTimeMillis() - waitStart);
            }
        }
    }

    long getMaxCallTimeout() {
        long callTimeout = invocation.callTimeout;
        long maxCallTimeout = callTimeout + getCallTimeoutExtension(callTimeout);
        return maxCallTimeout > 0 ? maxCallTimeout : Long.MAX_VALUE;
    }

    private static long getCallTimeoutExtension(long callTimeout) {
        if (callTimeout <= 0) {
            return 0L;
        }

        return Math.min(callTimeout, MAX_CALL_TIMEOUT_EXTENSION);
    }

    int getWaitingThreadsCount() {
        return waiterCount;
    }

    private static long toTimeoutMs(long time, TimeUnit unit) {
        long timeoutMs = unit.toMillis(time);
        if (timeoutMs < 0) {
            timeoutMs = 0;
        }
        return timeoutMs;
    }

    private Object resolveApplicationResponseOrThrowException(Object unresolvedResponse)
            throws ExecutionException, InterruptedException, TimeoutException {

        Object response = resolveApplicationResponse(unresolvedResponse);

        if (response == null || !(response instanceof Throwable)) {
            return response;
        }

        if (response instanceof ExecutionException) {
            throw (ExecutionException) response;
        }

        if (response instanceof TimeoutException) {
            throw (TimeoutException) response;
        }

        if (response instanceof InterruptedException) {
            throw (InterruptedException) response;
        }

        if (response instanceof Error) {
            throw (Error) response;
        }

        
        throw new ExecutionException((Throwable) response);
    }

    private Object resolveApplicationResponse(Object unresolvedResponse) {
        if (unresolvedResponse == NULL_RESPONSE) {
            return null;
        }

        if (unresolvedResponse == TIMEOUT_RESPONSE) {
            return new TimeoutException("Call " + invocation + " encountered a timeout");
        }

        if (unresolvedResponse == INTERRUPTED_RESPONSE) {
            return new InterruptedException("Call " + invocation + " was interrupted");
        }

        Object response = unresolvedResponse;
        if (invocation.resultDeserialized && response instanceof Data) {
            response = invocation.nodeEngine.toObject(response);
            if (response == null) {
                return null;
            }
        }

        if (response instanceof Throwable) {
            Throwable throwable = ((Throwable) response);
            if (invocation.remote) {
                fixRemoteStackTrace((Throwable) response, Thread.currentThread().getStackTrace());
            }
            return throwable;
        }

        return response;
    }

    @Override
    public boolean cancel(boolean mayInterruptIfRunning) {
        return false;
    }

    @Override
    public boolean isCancelled() {
        return false;
    }

    @Override
    public boolean isDone() {
         return responseAvailable(response);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder("InvocationFuture{");
        sb.append("invocation=").append(invocation.toString());
        sb.append(", response=").append(response);
        sb.append(", done=").append(isDone());
        sb.append('}');
        return sb.toString();
    }

    private static final class ExecutionCallbackNode<E> {
        private final ExecutionCallback<E> callback;
        private final Executor executor;
        private final ExecutionCallbackNode<E> next;

        private ExecutionCallbackNode(ExecutionCallback<E> callback, Executor executor, ExecutionCallbackNode<E> next) {
            this.callback = callback;
            this.executor = executor;
            this.next = next;
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.NodeEngineImpl;


public final class PartitionInvocation extends Invocation {

    public PartitionInvocation(NodeEngineImpl nodeEngine, String serviceName, Operation op, int partitionId,
                               int replicaIndex, int tryCount, long tryPauseMillis, long callTimeout,
                               ExecutionCallback callback, boolean resultDeserialized) {
        super(nodeEngine, serviceName, op, partitionId, replicaIndex, tryCount, tryPauseMillis,
                callTimeout, callback, resultDeserialized);
    }

    @Override
    public Address getTarget() {
        return getPartition().getReplicaAddress(replicaIndex);
    }

    @Override
    ExceptionAction onException(Throwable t) {
        final ExceptionAction action = op.onException(t);
        return action != null ? action : ExceptionAction.THROW_EXCEPTION;
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.nio.Address;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.NodeEngineImpl;


public class InvocationBuilderImpl extends InvocationBuilder {

    public InvocationBuilderImpl(NodeEngineImpl nodeEngine, String serviceName, Operation op, int partitionId) {
        this(nodeEngine, serviceName, op, partitionId, null);
    }

    public InvocationBuilderImpl(NodeEngineImpl nodeEngine, String serviceName, Operation op, Address target) {
        this(nodeEngine, serviceName, op, Operation.GENERIC_PARTITION_ID, target);
    }

    private InvocationBuilderImpl(NodeEngineImpl nodeEngine, String serviceName, Operation op,
                                  int partitionId, Address target) {
        super(nodeEngine, serviceName, op, partitionId, target);
    }

    @Override
    public InternalCompletableFuture invoke() {
        if (target == null) {
            return new PartitionInvocation(nodeEngine, serviceName, op, partitionId, replicaIndex,
                    tryCount, tryPauseMillis, callTimeout, getTargetExecutionCallback(), resultDeserialized).invoke();
        } else {
            return new TargetInvocation(nodeEngine, serviceName, op, target, tryCount, tryPauseMillis,
                    callTimeout, getTargetExecutionCallback(), resultDeserialized).invoke();
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.OperationTimeoutException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.exception.ResponseAlreadySentException;
import com.hazelcast.spi.exception.RetryableException;
import com.hazelcast.spi.exception.RetryableIOException;
import com.hazelcast.spi.exception.TargetNotMemberException;
import com.hazelcast.spi.exception.WrongTargetException;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.ErrorResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.NormalResponse;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;

import static com.hazelcast.spi.ExecutionService.ASYNC_EXECUTOR;
import static com.hazelcast.spi.OperationAccessor.setCallTimeout;
import static com.hazelcast.spi.OperationAccessor.setCallerAddress;
import static com.hazelcast.spi.OperationAccessor.setInvocationTime;
import static com.hazelcast.spi.impl.operationutil.Operations.isJoinOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isMigrationOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isWanReplicationOperation;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.INTERRUPTED_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.NULL_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.WAIT_RESPONSE;
import static java.lang.Boolean.FALSE;
import static java.lang.Boolean.TRUE;
import static java.util.logging.Level.WARNING;


abstract class Invocation implements ResponseHandler, Runnable {

    private static final AtomicReferenceFieldUpdater<Invocation, Boolean> RESPONSE_RECEIVED =
            AtomicReferenceFieldUpdater.newUpdater(Invocation.class, Boolean.class, "responseReceived");

    private static final AtomicIntegerFieldUpdater<Invocation> BACKUPS_COMPLETED =
            AtomicIntegerFieldUpdater.newUpdater(Invocation.class, "backupsCompleted");

    private static final long MIN_TIMEOUT = 10000;
    private static final int MAX_FAST_INVOCATION_COUNT = 5;
    
    private static final int LOG_MAX_INVOCATION_COUNT = 99;
    private static final int LOG_INVOCATION_COUNT_MOD = 10;

    
    volatile long pendingResponseReceivedMillis = -1;
    
    volatile Object pendingResponse;
    
    volatile int backupsExpected;
    
    volatile int backupsCompleted;
    
    volatile Boolean responseReceived = FALSE;

    final long callTimeout;
    final NodeEngineImpl nodeEngine;
    final String serviceName;
    final Operation op;
    final int partitionId;
    final int replicaIndex;
    final int tryCount;
    final long tryPauseMillis;
    final ILogger logger;
    final boolean resultDeserialized;
    boolean remote;
    Address invTarget;
    MemberImpl targetMember;
    final InvocationFuture invocationFuture;
    final OperationServiceImpl operationService;

    
    volatile int invokeCount;

    Invocation(NodeEngineImpl nodeEngine, String serviceName, Operation op, int partitionId,
               int replicaIndex, int tryCount, long tryPauseMillis, long callTimeout, ExecutionCallback callback,
               boolean resultDeserialized) {
        this.operationService = (OperationServiceImpl) nodeEngine.getOperationService();
        this.logger = operationService.invocationLogger;
        this.nodeEngine = nodeEngine;
        this.serviceName = serviceName;
        this.op = op;
        this.partitionId = partitionId;
        this.replicaIndex = replicaIndex;
        this.tryCount = tryCount;
        this.tryPauseMillis = tryPauseMillis;
        this.callTimeout = getCallTimeout(callTimeout);
        this.invocationFuture = new InvocationFuture(operationService, this, callback);
        this.resultDeserialized = resultDeserialized;
    }

    abstract ExceptionAction onException(Throwable t);

    protected abstract Address getTarget();

    InternalPartition getPartition() {
        return nodeEngine.getPartitionService().getPartition(partitionId);
    }

    @Override
    public boolean isLocal() {
        return true;
    }

    private long getCallTimeout(long callTimeout) {
        if (callTimeout > 0) {
            return callTimeout;
        }

        long defaultCallTimeout = operationService.defaultCallTimeoutMillis;
        if (!(op instanceof WaitSupport)) {
            return defaultCallTimeout;
        }

        long waitTimeoutMillis = op.getWaitTimeout();
        if (waitTimeoutMillis > 0 && waitTimeoutMillis < Long.MAX_VALUE) {
            
            long max = Math.max(waitTimeoutMillis, MIN_TIMEOUT);
            return Math.min(max, defaultCallTimeout);
        }
        return defaultCallTimeout;
    }

    public final InvocationFuture invoke() {
        invokeInternal(false);
        return invocationFuture;
    }

    public final void invokeAsync() {
        invokeInternal(true);
    }

    private void invokeInternal(boolean isAsync) {
        if (invokeCount > 0) {
            
            throw new IllegalStateException("An invocation can not be invoked more than once!");
        }

        if (op.getCallId() != 0) {
            throw new IllegalStateException("An operation[" + op + "] can not be used for multiple invocations!");
        }

        try {
            setCallTimeout(op, callTimeout);
            setCallerAddress(op, nodeEngine.getThisAddress());
            op.setNodeEngine(nodeEngine)
                    .setServiceName(serviceName)
                    .setPartitionId(partitionId)
                    .setReplicaIndex(replicaIndex);

            boolean isAllowed = operationService.operationExecutor.isInvocationAllowedFromCurrentThread(op, isAsync);
            if (!isAllowed && !isMigrationOperation(op)) {
                throw new IllegalThreadStateException(Thread.currentThread() + " cannot make remote call: " + op);
            }
            doInvoke(isAsync);
        } catch (Exception e) {
            handleInvocationException(e);
        }
    }

    private void handleInvocationException(Exception e) {
        if (e instanceof RetryableException) {
            notify(e);
        } else {
            throw ExceptionUtil.rethrow(e);
        }
    }

    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "We have the guarantee that only a single thread at any given time can change the volatile field")
    private void doInvoke(boolean isAsync) {
        if (!engineActive()) {
            return;
        }

        invokeCount++;

        
        if (!initInvocationTarget()) {
            return;
        }

        setInvocationTime(op, nodeEngine.getClusterService().getClusterClock().getClusterTime());
        operationService.invocationsRegistry.register(this);
        if (remote) {
            doInvokeRemote();
        } else {
            doInvokeLocal(isAsync);
        }
    }

    private void doInvokeLocal(boolean isAsync) {
        if (op.getCallerUuid() == null) {
            op.setCallerUuid(nodeEngine.getLocalMember().getUuid());
        }

        responseReceived = FALSE;
        op.setResponseHandler(this);

        OperationExecutor executor = operationService.operationExecutor;
        if (isAsync) {
            executor.execute(op);
        } else {
            executor.runOnCallingThreadIfPossible(op);
        }

    }

    private void doInvokeRemote() {
        boolean sent = operationService.send(op, invTarget);
        if (!sent) {
            operationService.invocationsRegistry.deregister(this);
            notify(new RetryableIOException("Packet not send to -> " + invTarget));
        }
    }

    @Override
    public void run() {
        doInvoke(false);
    }

    private boolean engineActive() {
        if (nodeEngine.isActive()) {
            return true;
        }

        remote = false;
        notify(new HazelcastInstanceNotActiveException());
        return false;
    }

    
    boolean initInvocationTarget() {
        Address thisAddress = nodeEngine.getThisAddress();

        invTarget = getTarget();

        if (invTarget == null) {
            remote = false;
            if (nodeEngine.isActive()) {
                notify(new WrongTargetException(thisAddress, null, partitionId
                        , replicaIndex, op.getClass().getName(), serviceName));
            } else {
                notify(new HazelcastInstanceNotActiveException());
            }
            return false;
        }

        targetMember = nodeEngine.getClusterService().getMember(invTarget);
        if (targetMember == null && !(isJoinOperation(op) || isWanReplicationOperation(op))) {
            notify(new TargetNotMemberException(invTarget, partitionId, op.getClass().getName(), serviceName));
            return false;
        }

        if (op.getPartitionId() != partitionId) {
            notify(new IllegalStateException("Partition id of operation: " + op.getPartitionId()
                    + " is not equal to the partition id of invocation: " + partitionId));
            return false;
        }

        if (op.getReplicaIndex() != replicaIndex) {
            notify(new IllegalStateException("Replica index of operation: " + op.getReplicaIndex()
                    + " is not equal to the replica index of invocation: " + replicaIndex));
            return false;
        }

        remote = !thisAddress.equals(invTarget);
        return true;
    }

    @Override
    public void sendResponse(Object obj) {
        if (!RESPONSE_RECEIVED.compareAndSet(this, FALSE, TRUE)) {
            throw new ResponseAlreadySentException("NormalResponse already responseReceived for callback: " + this
                    + ", current-response: : " + obj);
        }
        notify(obj);
    }

    
    
    void notify(Object response) {
        if (response == null) {
            response = NULL_RESPONSE;
        }

        if (response instanceof CallTimeoutResponse) {
            notifyCallTimeout();
            return;
        }

        if (response instanceof ErrorResponse || response instanceof Throwable) {
            notifyError(response);
            return;
        }

        if (response instanceof NormalResponse) {
            NormalResponse normalResponse = (NormalResponse) response;
            notifyNormalResponse(normalResponse.getValue(), normalResponse.getBackupCount());
            return;
        }

        
        invocationFuture.set(response);
    }

    void notifyError(Object error) {
        assert error != null;

        Throwable cause;
        if (error instanceof Throwable) {
            cause = (Throwable) error;
        } else {
            cause = ((ErrorResponse) error).getCause();
        }

        switch (onException(cause)) {
            case CONTINUE_WAIT:
                handleContinueWait();
                break;
            case THROW_EXCEPTION:
                notifyNormalResponse(cause, 0);
                break;
            case RETRY_INVOCATION:
                if (invokeCount < tryCount) {
                    
                    handleRetry(cause);
                } else {
                    
                    notifyNormalResponse(cause, 0);
                }
                break;
            default:
                throw new IllegalStateException("Unhandled ExceptionAction");
        }
    }

    void notifyNormalResponse(Object value, int expectedBackups) {
        if (value == null) {
            value = NULL_RESPONSE;
        }

        
        

        if (expectedBackups > backupsCompleted) {
            
            

            this.pendingResponseReceivedMillis = Clock.currentTimeMillis();

            this.backupsExpected = expectedBackups;

            
            
            this.pendingResponse = value;

            if (backupsCompleted != expectedBackups) {
                
                return;
            }
        }

        
        
        
        invocationFuture.set(value);
    }

    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "We have the guarantee that only a single thread at any given time can change the volatile field")
    void notifyCallTimeout() {
        if (logger.isFinestEnabled()) {
            logger.finest("Call timed-out during wait-notify phase, retrying call: " + toString());
        }

        if (op instanceof WaitSupport) {
            
            long waitTimeout = op.getWaitTimeout();
            waitTimeout -= callTimeout;
            op.setWaitTimeout(waitTimeout);
        }

        invokeCount--;
        handleRetry("invocation timeout");
    }

    void notifySingleBackupComplete() {
        int newBackupsCompleted = BACKUPS_COMPLETED.incrementAndGet(this);

        Object pendingResponse = this.pendingResponse;
        if (pendingResponse == null) {
            
            return;
        }

        
        int backupsExpected = this.backupsExpected;
        if (backupsExpected < newBackupsCompleted) {
            
            return;
        }

        if (backupsExpected != newBackupsCompleted) {
            
            return;
        }

        
        
        invocationFuture.set(pendingResponse);
    }

    boolean checkInvocationTimeout() {
        long maxCallTimeout = invocationFuture.getMaxCallTimeout();
        long expirationTime = op.getInvocationTime() + maxCallTimeout;

        boolean hasResponse = pendingResponse != null;
        boolean hasWaitingThreads = invocationFuture.getWaitingThreadsCount() > 0;
        boolean notExpired = maxCallTimeout == Long.MAX_VALUE
                || expirationTime < 0
                || expirationTime >= Clock.currentTimeMillis();

        if (hasResponse || hasWaitingThreads || notExpired) {
            return false;
        }

        operationService.getIsStillRunningService().timeoutInvocationIfNotExecuting(this);
        return true;
    }

    Object newOperationTimeoutException(long totalTimeoutMs) {
        boolean hasResponse = this.pendingResponse != null;
        int backupsExpected = this.backupsExpected;
        int backupsCompleted = this.backupsCompleted;

        if (hasResponse) {
            return new OperationTimeoutException("No response for " + totalTimeoutMs + " ms."
                    + " Aborting invocation! " + toString()
                    + " Not all backups have completed! "
                    + " backups-expected:" + backupsExpected
                    + " backups-completed: " + backupsCompleted);
        } else {
            return new OperationTimeoutException("No response for " + totalTimeoutMs + " ms."
                    + " Aborting invocation! " + toString()
                    + " No response has been received! "
                    + " backups-expected:" + backupsExpected
                    + " backups-completed: " + backupsCompleted);
        }
    }

    private void handleContinueWait() {
        invocationFuture.set(WAIT_RESPONSE);
    }

    private void handleRetry(Object cause) {
        if (invokeCount > LOG_MAX_INVOCATION_COUNT && invokeCount % LOG_INVOCATION_COUNT_MOD == 0) {
            if (logger.isLoggable(WARNING)) {
                logger.warning("Retrying invocation: " + toString() + ", Reason: " + cause);
            }
        }

        operationService.invocationsRegistry.deregister(this);

        if (invocationFuture.interrupted) {
            invocationFuture.set(INTERRUPTED_RESPONSE);
            return;
        }

        invocationFuture.set(WAIT_RESPONSE);
        ExecutionService ex = nodeEngine.getExecutionService();
        
        if (invokeCount < MAX_FAST_INVOCATION_COUNT) {
            operationService.asyncExecutor.execute(this);
        } else {
            ex.schedule(ASYNC_EXECUTOR, this, tryPauseMillis, TimeUnit.MILLISECONDS);
        }
    }

    boolean checkBackupTimeout(long timeoutMillis) {
        
        
        
        boolean allBackupsComplete = backupsExpected == backupsCompleted;
        long responseReceivedMillis = pendingResponseReceivedMillis;

        
        long expirationTime = responseReceivedMillis + timeoutMillis;
        boolean timeout = expirationTime > 0 && expirationTime < Clock.currentTimeMillis();

        
        
        boolean responseReceived = pendingResponse != null;

        if (allBackupsComplete || !responseReceived || !timeout) {
            return false;
        }

        boolean targetDead = nodeEngine.getClusterService().getMember(invTarget) == null;
        if (targetDead) {
            
            
            
            
            
            
            resetAndReInvoke();
            return false;
        }

         
        invocationFuture.set(pendingResponse);
        return true;
    }

    private void resetAndReInvoke() {
        operationService.invocationsRegistry.deregister(this);
        invokeCount = 0;
        pendingResponse = null;
        pendingResponseReceivedMillis = -1;
        backupsExpected = 0;
        backupsCompleted = 0;
        doInvoke(false);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder();
        sb.append("Invocation");
        sb.append("{ serviceName='").append(serviceName).append('\'');
        sb.append(", op=").append(op);
        sb.append(", partitionId=").append(partitionId);
        sb.append(", replicaIndex=").append(replicaIndex);
        sb.append(", tryCount=").append(tryCount);
        sb.append(", tryPauseMillis=").append(tryPauseMillis);
        sb.append(", invokeCount=").append(invokeCount);
        sb.append(", callTimeout=").append(callTimeout);
        sb.append(", target=").append(invTarget);
        sb.append(", backupsExpected=").append(backupsExpected);
        sb.append(", backupsCompleted=").append(backupsCompleted);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.map.impl.proxy;

import com.hazelcast.concurrent.lock.LockProxySupport;
import com.hazelcast.config.EntryListenerConfig;
import com.hazelcast.config.ListenerConfig;
import com.hazelcast.config.MapConfig;
import com.hazelcast.config.MapIndexConfig;
import com.hazelcast.config.MapPartitionLostListenerConfig;
import com.hazelcast.config.MapStoreConfig;
import com.hazelcast.core.EntryEventType;
import com.hazelcast.core.EntryView;
import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastInstanceAware;
import com.hazelcast.core.ICompletableFuture;
import com.hazelcast.core.IFunction;
import com.hazelcast.core.IMap;
import com.hazelcast.core.MapStore;
import com.hazelcast.core.Member;
import com.hazelcast.core.PartitioningStrategy;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.map.EntryProcessor;
import com.hazelcast.map.MapInterceptor;
import com.hazelcast.map.impl.EntryEventFilter;
import com.hazelcast.map.impl.MapContainer;
import com.hazelcast.map.impl.MapContextQuerySupport;
import com.hazelcast.map.impl.MapEntrySet;
import com.hazelcast.map.impl.MapEventPublisher;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.map.impl.MapServiceContext;
import com.hazelcast.map.impl.NearCache;
import com.hazelcast.map.impl.NearCacheProvider;
import com.hazelcast.map.impl.PartitionContainer;
import com.hazelcast.map.impl.QueryEventFilter;
import com.hazelcast.map.impl.RecordStore;
import com.hazelcast.map.impl.operation.AddIndexOperation;
import com.hazelcast.map.impl.operation.AddInterceptorOperation;
import com.hazelcast.map.impl.operation.BasePutOperation;
import com.hazelcast.map.impl.operation.BaseRemoveOperation;
import com.hazelcast.map.impl.operation.ClearOperation;
import com.hazelcast.map.impl.operation.ContainsKeyOperation;
import com.hazelcast.map.impl.operation.ContainsValueOperationFactory;
import com.hazelcast.map.impl.operation.DeleteOperation;
import com.hazelcast.map.impl.operation.EntryOperation;
import com.hazelcast.map.impl.operation.EvictAllOperation;
import com.hazelcast.map.impl.operation.EvictOperation;
import com.hazelcast.map.impl.operation.GetEntryViewOperation;
import com.hazelcast.map.impl.operation.GetOperation;
import com.hazelcast.map.impl.operation.IsEmptyOperationFactory;
import com.hazelcast.map.impl.operation.KeyBasedMapOperation;
import com.hazelcast.map.impl.operation.LoadAllOperation;
import com.hazelcast.map.impl.operation.LoadMapOperation;
import com.hazelcast.map.impl.operation.MapFlushOperation;
import com.hazelcast.map.impl.operation.MapGetAllOperationFactory;
import com.hazelcast.map.impl.operation.MultipleEntryOperationFactory;
import com.hazelcast.map.impl.operation.PartitionCheckIfLoadedOperationFactory;
import com.hazelcast.map.impl.operation.PartitionWideEntryWithPredicateOperationFactory;
import com.hazelcast.map.impl.operation.PutAllOperation;
import com.hazelcast.map.impl.operation.PutIfAbsentOperation;
import com.hazelcast.map.impl.operation.PutOperation;
import com.hazelcast.map.impl.operation.PutTransientOperation;
import com.hazelcast.map.impl.operation.RemoveIfSameOperation;
import com.hazelcast.map.impl.operation.RemoveInterceptorOperation;
import com.hazelcast.map.impl.operation.RemoveOperation;
import com.hazelcast.map.impl.operation.ReplaceIfSameOperation;
import com.hazelcast.map.impl.operation.ReplaceOperation;
import com.hazelcast.map.impl.operation.SetOperation;
import com.hazelcast.map.impl.operation.SizeOperationFactory;
import com.hazelcast.map.impl.operation.TryPutOperation;
import com.hazelcast.map.impl.operation.TryRemoveOperation;
import com.hazelcast.map.listener.MapListener;
import com.hazelcast.map.listener.MapPartitionLostListener;
import com.hazelcast.monitor.LocalMapStats;
import com.hazelcast.monitor.impl.LocalMapStatsImpl;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ClassLoaderUtil;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.query.PagingPredicate;
import com.hazelcast.query.Predicate;
import com.hazelcast.query.TruePredicate;
import com.hazelcast.spi.AbstractDistributedObject;
import com.hazelcast.spi.DefaultObjectNamespace;
import com.hazelcast.spi.EventFilter;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InitializingObject;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationFactory;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.BinaryOperationFactory;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.IterableUtil;
import com.hazelcast.util.IterationType;
import com.hazelcast.util.ThreadUtil;
import com.hazelcast.util.executor.CompletedFuture;

import java.util.AbstractMap;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.EventListener;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.map.impl.MapService.SERVICE_NAME;
import static com.hazelcast.util.IterableUtil.nullToEmpty;
import static com.hazelcast.util.Preconditions.checkNotNull;
import static java.util.Collections.singleton;

abstract class MapProxySupport extends AbstractDistributedObject<MapService> implements InitializingObject {

    protected static final String NULL_KEY_IS_NOT_ALLOWED = "Null key is not allowed!";
    protected static final String NULL_VALUE_IS_NOT_ALLOWED = "Null value is not allowed!";
    protected static final String NULL_PREDICATE_IS_NOT_ALLOWED = "Predicate should not be null!";
    protected static final String NULL_LISTENER_IS_NOT_ALLOWED = "Null listener is not allowed!";

    protected final String name;
    protected final LocalMapStatsImpl localMapStats;
    protected final LockProxySupport lockSupport;
    protected final PartitioningStrategy partitionStrategy;
    private MapServiceContext mapServiceContext;
    private InternalPartitionService partitionService;

    protected MapProxySupport(final String name, final MapService service, NodeEngine nodeEngine) {
        super(nodeEngine, service);
        this.name = name;
        this.mapServiceContext = service.getMapServiceContext();
        partitionStrategy = mapServiceContext.getMapContainer(name).getPartitioningStrategy();
        localMapStats = mapServiceContext.getLocalMapStatsProvider().getLocalMapStatsImpl(name);
        this.partitionService = getNodeEngine().getPartitionService();
        lockSupport = new LockProxySupport(new DefaultObjectNamespace(MapService.SERVICE_NAME, name));
    }

    @Override
    public void initialize() {
        initializeListeners();
        initializeIndexes();
        initializeMapStoreLoad();
    }

    private void initializeMapStoreLoad() {
        MapStoreConfig mapStoreConfig = getMapConfig().getMapStoreConfig();
        if (mapStoreConfig != null && mapStoreConfig.isEnabled()) {
            MapStoreConfig.InitialLoadMode initialLoadMode = mapStoreConfig.getInitialLoadMode();
            if (MapStoreConfig.InitialLoadMode.EAGER.equals(initialLoadMode)) {
                waitUntilLoaded();
            }
        }
    }

    private void initializeIndexes() {
        for (MapIndexConfig index : getMapConfig().getMapIndexConfigs()) {
            if (index.getAttribute() != null) {
                addIndex(index.getAttribute(), index.isOrdered());
            }
        }
    }

    private void initializeListeners() {
        final MapConfig mapConfig = getMapConfig();

        for (EntryListenerConfig listenerConfig : mapConfig.getEntryListenerConfigs()) {
            final MapListener listener = initializeListener(listenerConfig);
            if (listener != null) {
                if (listenerConfig.isLocal()) {
                    addLocalEntryListenerInternal(listener);
                } else {
                    addEntryListenerInternal(listener, null, listenerConfig.isIncludeValue());
                }
            }
        }

        for (MapPartitionLostListenerConfig listenerConfig : mapConfig.getPartitionLostListenerConfigs()) {
            final MapPartitionLostListener listener = initializeListener(listenerConfig);
            if (listener != null) {
                addPartitionLostListenerInternal(listener);
            }
        }
    }

    private <T extends EventListener> T initializeListener(ListenerConfig listenerConfig) {
        T listener = null;
        if (listenerConfig.getImplementation() != null) {
            listener = (T) listenerConfig.getImplementation();
        } else if (listenerConfig.getClassName() != null) {
            try {
                return ClassLoaderUtil
                        .newInstance(getNodeEngine().getConfigClassLoader(), listenerConfig.getClassName());
            } catch (Exception e) {
                throw ExceptionUtil.rethrow(e);
            }
        }

        if (listener instanceof HazelcastInstanceAware) {
            ((HazelcastInstanceAware) listener).setHazelcastInstance(getNodeEngine().getHazelcastInstance());
        }

        return listener;
    }

    
    
    protected Object getInternal(Data key) {
        
        
        final MapConfig mapConfig = getMapConfig();
        final boolean nearCacheEnabled = mapConfig.isNearCacheEnabled();
        if (nearCacheEnabled) {
            final Object fromNearCache = getFromNearCache(key);
            if (fromNearCache != null) {
                if (isCachedAsNullInNearCache(fromNearCache)) {
                    return null;
                }
                return fromNearCache;
            }
        }
        
        if (mapConfig.isReadBackupData()) {
            final Object fromBackup = readBackupDataOrNull(key);
            if (fromBackup != null) {
                return fromBackup;
            }
        }
        final GetOperation operation = new GetOperation(name, key);
        operation.setThreadId(ThreadUtil.getThreadId());
        final Data value = (Data) invokeOperation(key, operation);

        if (nearCacheEnabled) {
            if (notOwnerPartitionForKey(key) || cacheKeyAnyway()) {
                return putNearCache(key, value);
            }
        }
        return value;
    }

    private boolean notOwnerPartitionForKey(Data key) {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final NodeEngine nodeEngine = mapServiceContext.getNodeEngine();
        final int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        return !nodeEngine.getPartitionService().getPartitionOwner(partitionId)
                .equals(nodeEngine.getClusterService().getThisAddress());
    }

    private boolean cacheKeyAnyway() {
        return getMapConfig().getNearCacheConfig().isCacheLocalEntries();
    }

    private Object putNearCache(Data key, Data value) {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final NearCacheProvider nearCacheProvider = mapServiceContext.getNearCacheProvider();
        return nearCacheProvider.putNearCache(name, key, value);
    }


    private Object getFromNearCache(Data key) {
        if (!getMapConfig().isNearCacheEnabled()) {
            return null;
        }
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final NearCacheProvider nearCacheProvider = mapServiceContext.getNearCacheProvider();
        final Object cached = nearCacheProvider.getFromNearCache(name, key);
        if (cached == null) {
            return null;
        }
        mapServiceContext.interceptAfterGet(name, cached);
        return cached;
    }

    private void getFromNearCache(Map<Object, Object> resultMap, Collection<Data> keys) {
        if (!getMapConfig().isNearCacheEnabled()) {
            return;
        }
        final MapService mapService = getService();
        final Iterator<Data> iterator = keys.iterator();
        while (iterator.hasNext()) {
            Data key = iterator.next();
            final Object fromNearCache = getFromNearCache(key);
            if (fromNearCache == null) {
                continue;
            }
            if (!isCachedAsNullInNearCache(fromNearCache)) {
                resultMap.put(mapService.getMapServiceContext().toObject(key),
                        mapService.getMapServiceContext().toObject(fromNearCache));
            }
            iterator.remove();
        }
    }

    private boolean isCachedAsNullInNearCache(Object cached) {
        if (cached == null) {
            return false;
        }
        return NearCache.NULL_OBJECT.equals(cached);
    }

    private Data readBackupDataOrNull(Data key) {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final NodeEngine nodeEngine = mapServiceContext.getNodeEngine();
        final InternalPartitionService partitionService = nodeEngine.getPartitionService();
        final Address thisAddress = nodeEngine.getThisAddress();
        final int partitionId = partitionService.getPartitionId(key);
        final InternalPartition partition = partitionService.getPartition(partitionId, false);
        if (!partition.isOwnerOrBackup(thisAddress)) {
            return null;
        }
        final PartitionContainer partitionContainer = mapServiceContext.getPartitionContainer(partitionId);
        final RecordStore recordStore = partitionContainer.getExistingRecordStore(name);
        if (recordStore == null) {
            return null;
        }
        return recordStore.readBackupData(key);
    }

    protected ICompletableFuture<Data> getAsyncInternal(final Data key) {
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        final boolean nearCacheEnabled = getMapConfig().isNearCacheEnabled();
        if (nearCacheEnabled) {
            Object cached = mapService.getMapServiceContext().getNearCacheProvider().getFromNearCache(name, key);
            if (cached != null) {
                if (NearCache.NULL_OBJECT.equals(cached)) {
                    cached = null;
                }
                return new CompletedFuture<Data>(
                        nodeEngine.getSerializationService(),
                        cached,
                        nodeEngine.getExecutionService().getExecutor(ExecutionService.ASYNC_EXECUTOR));
            }
        }

        GetOperation operation = new GetOperation(name, key);
        try {
            final OperationService operationService = nodeEngine.getOperationService();
            final InvocationBuilder invocationBuilder
                    = operationService.createInvocationBuilder(SERVICE_NAME,
                    operation, partitionId).setResultDeserialized(false);
            final InternalCompletableFuture<Data> future = invocationBuilder.invoke();
            future.andThen(new ExecutionCallback<Data>() {
                @Override
                public void onResponse(Data response) {
                    if (nearCacheEnabled) {
                        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
                        if (!nodeEngine.getPartitionService().getPartitionOwner(partitionId)
                                .equals(nodeEngine.getClusterService().getThisAddress())
                                || getMapConfig().getNearCacheConfig().isCacheLocalEntries()) {
                            mapService.getMapServiceContext().getNearCacheProvider().putNearCache(name, key, response);
                        }
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                }
            });
            return future;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected Data putInternal(final Data key, final Data value, final long ttl, final TimeUnit timeunit) {
        PutOperation operation = new PutOperation(name, key, value, getTimeInMillis(ttl, timeunit));
        Data previousValue = (Data) invokeOperation(key, operation);
        invalidateNearCache(key);
        return previousValue;
    }

    protected boolean tryPutInternal(final Data key, final Data value, final long timeout, final TimeUnit timeunit) {
        TryPutOperation operation = new TryPutOperation(name, key, value, getTimeInMillis(timeout, timeunit));
        boolean putSuccessful = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return putSuccessful;
    }

    protected Data putIfAbsentInternal(final Data key, final Data value, final long ttl, final TimeUnit timeunit) {
        PutIfAbsentOperation operation = new PutIfAbsentOperation(name, key, value, getTimeInMillis(ttl, timeunit));
        Data previousValue = (Data) invokeOperation(key, operation);
        invalidateNearCache(key);
        return previousValue;
    }

    protected void putTransientInternal(final Data key, final Data value, final long ttl, final TimeUnit timeunit) {
        PutTransientOperation operation = new PutTransientOperation(name, key, value, getTimeInMillis(ttl, timeunit));
        invokeOperation(key, operation);
        invalidateNearCache(key);
    }

    private Object invokeOperation(Data key, KeyBasedMapOperation operation) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            Future f;
            Object o;
            OperationService operationService = nodeEngine.getOperationService();
            if (getMapConfig().isStatisticsEnabled()) {
                long time = System.currentTimeMillis();
                f = operationService
                        .createInvocationBuilder(SERVICE_NAME, operation, partitionId)
                        .setResultDeserialized(false)
                        .invoke();
                o = f.get();
                if (operation instanceof BasePutOperation) {
                    localMapStats.incrementPuts(System.currentTimeMillis() - time);
                } else if (operation instanceof BaseRemoveOperation) {
                    localMapStats.incrementRemoves(System.currentTimeMillis() - time);
                } else if (operation instanceof GetOperation) {
                    localMapStats.incrementGets(System.currentTimeMillis() - time);
                }

            } else {
                f = operationService.createInvocationBuilder(SERVICE_NAME, operation, partitionId)
                        .setResultDeserialized(false).invoke();
                o = f.get();
            }
            return o;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected ICompletableFuture<Data> putAsyncInternal(final Data key, final Data value,
                                                        final long ttl, final TimeUnit timeunit) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        PutOperation operation = new PutOperation(name, key, value, getTimeInMillis(ttl, timeunit));
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            ICompletableFuture<Data> future
                    = nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
            invalidateNearCache(key);
            return future;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected boolean replaceInternal(final Data key, final Data expect, final Data update) {
        ReplaceIfSameOperation operation = new ReplaceIfSameOperation(name, key, expect, update);
        boolean replaceSuccessful = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return replaceSuccessful;
    }

    protected Data replaceInternal(final Data key, final Data value) {
        ReplaceOperation operation = new ReplaceOperation(name, key, value);
        final Data result = (Data) invokeOperation(key, operation);
        invalidateNearCache(key);
        return result;
    }

    protected void setInternal(final Data key, final Data value, final long ttl, final TimeUnit timeunit) {
        SetOperation operation = new SetOperation(name, key, value, timeunit.toMillis(ttl));
        invokeOperation(key, operation);
        invalidateNearCache(key);
    }

    protected boolean evictInternal(final Data key) {
        EvictOperation operation = new EvictOperation(name, key, false);
        final boolean evictSuccess = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return evictSuccess;
    }

    protected void evictAllInternal() {
        try {
            clearNearCache();
            final Operation operation = new EvictAllOperation(name);
            final NodeEngine nodeEngine = getNodeEngine();
            final Map<Integer, Object> resultMap
                    = nodeEngine.getOperationService().invokeOnAllPartitions(SERVICE_NAME,
                    new BinaryOperationFactory(operation, nodeEngine));

            int numberOfAffectedEntries = 0;
            for (Object o : resultMap.values()) {
                numberOfAffectedEntries += (Integer) o;
            }
            if (numberOfAffectedEntries > 0) {
                publishMapEvent(numberOfAffectedEntries, EntryEventType.EVICT_ALL);
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected void loadAllInternal(boolean replaceExistingValues) {
        NodeEngine nodeEngine = getNodeEngine();
        OperationService operationService = nodeEngine.getOperationService();
        InternalPartitionService partitionService = nodeEngine.getPartitionService();
        int mapNamePartition = partitionService.getPartitionId(name);

        Operation operation = new LoadMapOperation(name, replaceExistingValues);
        Future loadMapFuture = operationService.invokeOnPartition(MapService.SERVICE_NAME, operation, mapNamePartition);

        try {
            loadMapFuture.get();
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }

        waitUntilLoaded();
    }

    
    protected void loadInternal(Iterable keys, boolean replaceExistingValues) {

        Iterable<Data> dataKeys = convertToData(keys);
        NodeEngine nodeEngine = getNodeEngine();
        Map<Integer, List<Data>> partitionIdToKeys = getPartitionIdToKeysMap(dataKeys);
        Iterable<Entry<Integer, List<Data>>> entries = partitionIdToKeys.entrySet();

        for (final Entry<Integer, List<Data>> entry : entries) {
            final Integer partitionId = entry.getKey();
            final List<Data> correspondingKeys = entry.getValue();
            final Operation operation = createLoadAllOperation(correspondingKeys, replaceExistingValues);
            nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
        }

        waitUntilLoaded();
    }

    private <K> Iterable<Data> convertToData(Iterable<K> keys) {
        return IterableUtil.map(nullToEmpty(keys), new IFunction<K, Data>() {
            public Data apply(K key) {
                return toData(key);
            }
        });
    }

    private Operation createLoadAllOperation(final List<Data> keys, boolean replaceExistingValues) {
        return new LoadAllOperation(name, keys, replaceExistingValues);
    }

    protected Data removeInternal(Data key) {
        RemoveOperation operation = new RemoveOperation(name, key);
        Data previousValue = (Data) invokeOperation(key, operation);
        invalidateNearCache(key);
        return previousValue;
    }

    protected void deleteInternal(Data key) {
        DeleteOperation operation = new DeleteOperation(name, key);
        invokeOperation(key, operation);
        invalidateNearCache(key);
    }

    protected boolean removeInternal(final Data key, final Data value) {
        RemoveIfSameOperation operation = new RemoveIfSameOperation(name, key, value);
        boolean removed = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return removed;
    }

    protected boolean tryRemoveInternal(final Data key, final long timeout, final TimeUnit timeunit) {
        TryRemoveOperation operation = new TryRemoveOperation(name, key, getTimeInMillis(timeout, timeunit));
        boolean removed = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return removed;
    }

    protected ICompletableFuture<Data> removeAsyncInternal(final Data key) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        RemoveOperation operation = new RemoveOperation(name, key);
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            ICompletableFuture<Data> future
                    = nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
            invalidateNearCache(key);
            return future;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected boolean containsKeyInternal(Data key) {
        if (isKeyInNearCache(key)) {
            return true;
        }
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        ContainsKeyOperation containsKeyOperation = new ContainsKeyOperation(name, key);
        containsKeyOperation.setThreadId(ThreadUtil.getThreadId());
        containsKeyOperation.setServiceName(SERVICE_NAME);
        try {
            Future f = nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, containsKeyOperation,
                    partitionId);
            return (Boolean) getService().getMapServiceContext().toObject(f.get());
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public void waitUntilLoaded() {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            OperationService operationService = nodeEngine.getOperationService();
            OperationFactory opFactory = new PartitionCheckIfLoadedOperationFactory(name);

            Map<Integer, Object> results;
            Collection<Integer> mapNamePartition = getPartitionsForKeys(singleton(toData(name)));

            results = operationService.invokeOnPartitions(SERVICE_NAME, opFactory, mapNamePartition);
            waitAllTrue(results);

            results = operationService.invokeOnAllPartitions(SERVICE_NAME, opFactory);
            waitAllTrue(results);

        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    private void waitAllTrue(Map<Integer, Object> results)
            throws InterruptedException {
        Iterator<Entry<Integer, Object>> iterator = results.entrySet().iterator();
        boolean isFinished = false;
        final Set<Integer> retrySet = new HashSet<Integer>();
        while (!isFinished) {
            while (iterator.hasNext()) {
                final Entry<Integer, Object> entry = iterator.next();
                if (Boolean.TRUE.equals(entry.getValue())) {
                    iterator.remove();
                } else {
                    retrySet.add(entry.getKey());
                }
            }
            if (retrySet.size() > 0) {
                results = retryPartitions(retrySet);
                iterator = results.entrySet().iterator();
                final int oneSecond = 1000;
                Thread.sleep(oneSecond);
                retrySet.clear();
            } else {
                isFinished = true;
            }
        }
    }

    private Map<Integer, Object> retryPartitions(Collection partitions) {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            final Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnPartitions(SERVICE_NAME, new PartitionCheckIfLoadedOperationFactory(name), partitions);
            return results;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public int size() {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME, new SizeOperationFactory(name));
            int total = 0;
            for (Object result : results.values()) {
                Integer size = (Integer) getService().getMapServiceContext().toObject(result);
                total += size;
            }
            return total;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public boolean containsValueInternal(Data dataValue) {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME, new ContainsValueOperationFactory(name, dataValue));
            for (Object result : results.values()) {
                Boolean contains = (Boolean) getService().getMapServiceContext().toObject(result);
                if (contains) {
                    return true;
                }
            }
            return false;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public boolean isEmpty() {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            
            
            
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME,
                            new IsEmptyOperationFactory(name));
            for (Object result : results.values()) {
                if (!(Boolean) getService().getMapServiceContext().toObject(result)) {
                    return false;
                }
            }
            return true;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected Map<Object, Object> getAllObjectInternal(final Set<Data> keys) {
        if (keys == null || keys.isEmpty()) {
            return Collections.emptyMap();
        }
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        Map<Object, Object> result = new HashMap<Object, Object>();
        final boolean nearCacheEnabled = getMapConfig().isNearCacheEnabled();
        if (nearCacheEnabled) {
            getFromNearCache(result, keys);
        }
        if (keys.isEmpty()) {
            return result;
        }
        Collection<Integer> partitions = getPartitionsForKeys(keys);
        Map<Integer, Object> responses;
        try {
            responses = nodeEngine.getOperationService()
                    .invokeOnPartitions(SERVICE_NAME, new MapGetAllOperationFactory(name, keys), partitions);
            for (Object response : responses.values()) {
                Set<Map.Entry<Data, Data>> entries
                        = ((MapEntrySet) mapService.getMapServiceContext().toObject(response)).getEntrySet();
                for (Entry<Data, Data> entry : entries) {
                    result.put(mapService.getMapServiceContext().toObject(entry.getKey()),
                            mapService.getMapServiceContext().toObject(entry.getValue()));
                    if (nearCacheEnabled) {
                        if (notOwnerPartitionForKey(entry.getKey())
                                || cacheKeyAnyway()) {
                            putNearCache(entry.getKey(), entry.getValue());
                        }
                    }
                }
            }
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }

        return result;
    }

    private Collection<Integer> getPartitionsForKeys(Set<Data> keys) {

        int partitions = partitionService.getPartitionCount();
        
        int capacity = Math.min(partitions, keys.size());
        Set<Integer> partitionIds = new HashSet<Integer>(capacity);

        Iterator<Data> iterator = keys.iterator();
        while (iterator.hasNext() && partitionIds.size() < partitions) {
            Data key = iterator.next();
            partitionIds.add(partitionService.getPartitionId(key));
        }
        return partitionIds;
    }

    private Map<Integer, List<Data>> getPartitionIdToKeysMap(Iterable<Data> keys) {
        if (keys == null) {
            return Collections.emptyMap();
        }
        final InternalPartitionService partitionService = getNodeEngine().getPartitionService();
        final Map<Integer, List<Data>> idToKeys = new HashMap<Integer, List<Data>>();

        final Iterator<Data> iterator = keys.iterator();
        while (iterator.hasNext()) {
            final Data key = iterator.next();
            final int partitionId = partitionService.getPartitionId(key);
            List<Data> keyList = idToKeys.get(partitionId);
            if (keyList == null) {
                keyList = new ArrayList<Data>();
                idToKeys.put(partitionId, keyList);
            }
            keyList.add(key);
        }
        return idToKeys;
    }

    protected void putAllInternal(final Map<? extends Object, ? extends Object> entries) {
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        int factor = 3;
        InternalPartitionService partitionService = nodeEngine.getPartitionService();
        OperationService operationService = nodeEngine.getOperationService();
        int partitionCount = partitionService.getPartitionCount();
        boolean tooManyEntries = entries.size() > (partitionCount * factor);
        try {
            if (tooManyEntries) {
                List<Future> futures = new LinkedList<Future>();
                Map<Integer, MapEntrySet> entryMap
                        = new HashMap<Integer, MapEntrySet>(nodeEngine.getPartitionService().getPartitionCount());
                for (Entry entry : entries.entrySet()) {
                    checkNotNull(entry.getKey(), NULL_KEY_IS_NOT_ALLOWED);
                    checkNotNull(entry.getValue(), NULL_VALUE_IS_NOT_ALLOWED);

                    int partitionId = partitionService.getPartitionId(entry.getKey());
                    if (!entryMap.containsKey(partitionId)) {
                        entryMap.put(partitionId, new MapEntrySet());
                    }
                    entryMap.get(partitionId).add(
                            new AbstractMap.SimpleImmutableEntry<Data, Data>(mapService.getMapServiceContext().toData(
                                    entry.getKey(),
                                    partitionStrategy),
                                    mapService.getMapServiceContext()
                                            .toData(entry.getValue())
                            ));
                }

                for (final Map.Entry<Integer, MapEntrySet> entry : entryMap.entrySet()) {
                    final Integer partitionId = entry.getKey();
                    final PutAllOperation op = new PutAllOperation(name, entry.getValue());
                    op.setPartitionId(partitionId);
                    futures.add(operationService.invokeOnPartition(SERVICE_NAME, op, partitionId));
                }

                for (Future future : futures) {
                    future.get();
                }

            } else {
                for (Entry entry : entries.entrySet()) {
                    checkNotNull(entry.getKey(), NULL_KEY_IS_NOT_ALLOWED);
                    checkNotNull(entry.getValue(), NULL_VALUE_IS_NOT_ALLOWED);

                    putInternal(mapService.getMapServiceContext().toData(entry.getKey(), partitionStrategy),
                            mapService.getMapServiceContext().toData(entry.getValue()),
                            -1,
                            TimeUnit.MILLISECONDS);
                }
            }
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }
    }

    public void flush() {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            
            nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME,
                            new BinaryOperationFactory(new MapFlushOperation(name), nodeEngine));
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public void clearInternal() {
        final String mapName = name;
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            ClearOperation clearOperation = new ClearOperation(mapName);
            clearOperation.setServiceName(SERVICE_NAME);
            final Map<Integer, Object> resultMap = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME, new BinaryOperationFactory(clearOperation, nodeEngine));

            int numberOfAffectedEntries = 0;
            for (Object o : resultMap.values()) {
                numberOfAffectedEntries += (Integer) o;
            }
            if (numberOfAffectedEntries > 0) {
                publishMapEvent(numberOfAffectedEntries, EntryEventType.CLEAR_ALL);
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public String addMapInterceptorInternal(MapInterceptor interceptor) {
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        if (interceptor instanceof HazelcastInstanceAware) {
            ((HazelcastInstanceAware) interceptor).setHazelcastInstance(nodeEngine.getHazelcastInstance());
        }
        String id = mapServiceContext.generateInterceptorId(name, interceptor);
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        for (MemberImpl member : members) {
            try {
                Future f = nodeEngine.getOperationService()
                        .invokeOnTarget(SERVICE_NAME, new AddInterceptorOperation(id, interceptor, name),
                                member.getAddress());
                f.get();
            } catch (Throwable t) {
                throw ExceptionUtil.rethrow(t);
            }
        }
        return id;
    }

    public void removeMapInterceptorInternal(String id) {
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        mapService.getMapServiceContext().removeInterceptor(name, id);
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        for (Member member : members) {
            try {
                if (member.localMember()) {
                    continue;
                }
                MemberImpl memberImpl = (MemberImpl) member;
                Future f = nodeEngine.getOperationService()
                        .invokeOnTarget(SERVICE_NAME, new RemoveInterceptorOperation(name, id), memberImpl.getAddress());
                f.get();
            } catch (Throwable t) {
                throw ExceptionUtil.rethrow(t);
            }
        }
    }

    public String addLocalEntryListenerInternal(final Object listener) {
        final MapService mapService = getService();
        return mapService.getMapServiceContext().addLocalEventListener(listener, name);
    }

    public String addLocalEntryListenerInternal(Object listener, Predicate predicate,
                                                final Data key, boolean includeValue) {

        final MapService mapService = getService();
        EventFilter eventFilter = new QueryEventFilter(includeValue, key, predicate);
        return mapService.getMapServiceContext().addLocalEventListener(listener, eventFilter, name);
    }

    protected String addEntryListenerInternal(
            final Object listener, final Data key, final boolean includeValue) {
        EventFilter eventFilter = new EntryEventFilter(includeValue, key);
        final MapService mapService = getService();
        return mapService.getMapServiceContext().addEventListener(listener, eventFilter, name);
    }

    protected String addEntryListenerInternal(
            Object listener, Predicate predicate, final Data key, final boolean includeValue) {
        EventFilter eventFilter = new QueryEventFilter(includeValue, key, predicate);
        final MapService mapService = getService();
        return mapService.getMapServiceContext().addEventListener(listener, eventFilter, name);
    }

    protected boolean removeEntryListenerInternal(String id) {
        final MapService mapService = getService();
        return mapService.getMapServiceContext().removeEventListener(name, id);
    }

    protected String addPartitionLostListenerInternal(MapPartitionLostListener listener) {
        final MapService mapService = getService();
        return mapService.getMapServiceContext().addPartitionLostListener(listener, name);
    }

    protected boolean removePartitionLostListenerInternal(String id) {
        final MapService mapService = getService();
        return mapService.getMapServiceContext().removePartitionLostListener(name, id);
    }

    protected EntryView getEntryViewInternal(final Data key) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        GetEntryViewOperation operation = new GetEntryViewOperation(name, key);
        operation.setThreadId(ThreadUtil.getThreadId());
        operation.setServiceName(SERVICE_NAME);
        try {
            Future f = nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
            Object o = getService().getMapServiceContext().toObject(f.get());
            return (EntryView) o;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public Data executeOnKeyInternal(Data key, EntryProcessor entryProcessor) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        EntryOperation operation = new EntryOperation(name, key, entryProcessor);
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            Future future = nodeEngine.getOperationService()
                    .createInvocationBuilder(SERVICE_NAME, operation, partitionId)
                    .setResultDeserialized(false)
                    .invoke();
            final Data data = (Data) future.get();
            invalidateNearCache(key);
            return data;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public Map executeOnKeysInternal(Set<Data> keys, EntryProcessor entryProcessor) {
        
        
        Map result = new HashMap();
        final NodeEngine nodeEngine = getNodeEngine();
        final Collection<Integer> partitionsForKeys = getPartitionsForKeys(keys);
        try {
            MultipleEntryOperationFactory operationFactory = new MultipleEntryOperationFactory(name, keys, entryProcessor);
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnPartitions(SERVICE_NAME, operationFactory, partitionsForKeys);
            for (Object o : results.values()) {
                if (o != null) {
                    final MapService service = getService();
                    final MapEntrySet mapEntrySet = (MapEntrySet) o;
                    for (Entry<Data, Data> entry : mapEntrySet.getEntrySet()) {
                        result.put(service.getMapServiceContext().toObject(entry.getKey()),
                                service.getMapServiceContext().toObject(entry.getValue()));
                    }
                }
            }
            invalidateNearCache(keys);
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
        return result;
    }

    public ICompletableFuture executeOnKeyInternal(Data key, EntryProcessor entryProcessor, ExecutionCallback callback) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        EntryOperation operation = new EntryOperation(name, key, entryProcessor);
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            if (callback == null) {
                return nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
            } else {
                ICompletableFuture future = nodeEngine.getOperationService()
                        .createInvocationBuilder(SERVICE_NAME, operation, partitionId)
                        .setExecutionCallback(new MapExecutionCallbackAdapter(callback))
                        .invoke();
                invalidateNearCache(key);
                return future;
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    
    
    public Map executeOnEntries(EntryProcessor entryProcessor) {
        return executeOnEntries(entryProcessor, TruePredicate.INSTANCE);
    }

    
    
    public Map executeOnEntries(EntryProcessor entryProcessor, Predicate predicate) {
        Map result = new HashMap();
        try {
            NodeEngine nodeEngine = getNodeEngine();
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME,
                            new PartitionWideEntryWithPredicateOperationFactory(name,
                                    entryProcessor,
                                    predicate)
                    );
            for (Object o : results.values()) {
                if (o != null) {
                    final MapService service = getService();
                    final MapEntrySet mapEntrySet = (MapEntrySet) o;
                    for (Entry<Data, Data> entry : mapEntrySet.getEntrySet()) {
                        final Data key = entry.getKey();
                        result.put(service.getMapServiceContext().toObject(key),
                                service.getMapServiceContext().toObject(entry.getValue()));
                        invalidateNearCache(key);
                    }
                }
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
        return result;
    }

    protected Object toObject(Object obj) {
        return getService().getMapServiceContext().toObject(obj);
    }

    protected Data toData(Object obj) {
        return getService().getMapServiceContext().toData(obj);
    }

    protected Data toData(Object o, PartitioningStrategy partitioningStrategy) {
        return getService().getMapServiceContext().toData(o, partitioningStrategy);
    }

    protected Set queryLocal(final Predicate predicate, final IterationType iterationType, final boolean dataResult) {
        if (predicate instanceof PagingPredicate) {
            return getMapQuerySupport().queryLocalMemberWithPagingPredicate(name, (PagingPredicate) predicate, iterationType);
        }
        return getMapQuerySupport().queryLocalMember(name, predicate, iterationType, dataResult);
    }

    protected Set query(final Predicate predicate, final IterationType iterationType, final boolean dataResult) {
        if (predicate instanceof PagingPredicate) {
            return getMapQuerySupport().queryWithPagingPredicate(name, (PagingPredicate) predicate, iterationType);
        }
        return getMapQuerySupport().query(name, predicate, iterationType, dataResult);
    }

    public void addIndex(final String attribute, final boolean ordered) {
        final NodeEngine nodeEngine = getNodeEngine();
        if (attribute == null) {
            throw new IllegalArgumentException("Attribute name cannot be null");
        }
        try {
            AddIndexOperation addIndexOperation = new AddIndexOperation(name, attribute, ordered);
            nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME, new BinaryOperationFactory(addIndexOperation, nodeEngine));
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public LocalMapStats getLocalMapStats() {
        return getService().getMapServiceContext().getLocalMapStatsProvider().createLocalMapStats(name);
    }

    private boolean isKeyInNearCache(Data key) {
        final MapService mapService = getService();
        final boolean nearCacheEnabled = getMapConfig().isNearCacheEnabled();
        if (nearCacheEnabled) {
            Object cached = mapService.getMapServiceContext().getNearCacheProvider().getFromNearCache(name, key);
            if (cached != null && !cached.equals(NearCache.NULL_OBJECT)) {
                return true;
            }
        }
        return false;
    }

    private void invalidateNearCache(Data key) {
        if (key == null) {
            return;
        }
        getService().getMapServiceContext().getNearCacheProvider().invalidateNearCache(name, key);
    }

    private void invalidateNearCache(Collection<Data> keys) {
        if (keys == null || keys.isEmpty()) {
            return;
        }
        getService().getMapServiceContext().getNearCacheProvider().invalidateNearCache(name, keys);
    }

    private void clearNearCache() {
        getService().getMapServiceContext().getNearCacheProvider().clearNearCache(name);
    }

    private void publishMapEvent(int numberOfAffectedEntries, EntryEventType eventType) {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final MapEventPublisher mapEventPublisher = mapServiceContext.getMapEventPublisher();
        mapEventPublisher.publishMapEvent(getNodeEngine().getThisAddress(), name, eventType, numberOfAffectedEntries);
    }

    protected long getTimeInMillis(final long time, final TimeUnit timeunit) {
        long timeInMillis = timeunit.toMillis(time);
        if (time > 0 && timeInMillis == 0) {
            timeInMillis = 1;
        }
        return timeInMillis;
    }

    private MapContextQuerySupport getMapQuerySupport() {
        return getService().getMapServiceContext().getMapContextQuerySupport();
    }

    protected MapStore getMapStore() {
        final MapService service = getService();
        final MapServiceContext mapServiceContext = service.getMapServiceContext();
        final MapContainer mapContainer = mapServiceContext.getMapContainer(name);
        return mapContainer.getMapStoreContext().getMapStoreWrapper();

    }

    private MapConfig getMapConfig() {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final MapContainer mapContainer = mapServiceContext.getMapContainer(name);
        return mapContainer.getMapConfig();
    }

    @Override
    public final String getName() {
        return name;
    }

    @Override
    public final String getServiceName() {
        return SERVICE_NAME;
    }

    private class MapExecutionCallbackAdapter implements ExecutionCallback {

        private final ExecutionCallback executionCallback;

        public MapExecutionCallbackAdapter(ExecutionCallback executionCallback) {
            this.executionCallback = executionCallback;
        }

        @Override
        public void onResponse(Object response) {
            MapServiceContext mapServiceContext = getService().getMapServiceContext();
            executionCallback.onResponse(mapServiceContext.toObject(response));
        }

        @Override
        public void onFailure(Throwable t) {
            executionCallback.onFailure(t);
        }
    }

    public PartitioningStrategy getPartitionStrategy() {
        return partitionStrategy;
    }
}


<code block>


package com.hazelcast.client.impl.protocol.task;

import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.instance.Node;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationFactory;
import com.hazelcast.spi.impl.SimpleExecutionCallback;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;

import java.util.Collection;
import java.util.HashSet;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

import static java.util.Collections.EMPTY_MAP;
import static java.util.Collections.synchronizedSet;

public abstract class AbstractMultiTargetMessageTask<P> extends AbstractMessageTask<P> {

    private static final int TRY_COUNT = 100;

    protected AbstractMultiTargetMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
        super(clientMessage, node, connection);
    }

    @Override
    protected void processMessage() {
        ClientEndpoint endpoint = getEndpoint();
        OperationFactory operationFactory = createOperationFactory();
        Collection<Address> targets = getTargets();

        if (returnResponseIfNoTargetLeft(targets, EMPTY_MAP)) {
            return;
        }

        final InternalOperationService operationService = nodeEngine.getOperationService();

        MultiTargetCallback callback = new MultiTargetCallback(targets);
        for (Address target : targets) {
            Operation op = operationFactory.createOperation();
            op.setCallerUuid(endpoint.getUuid());
            InvocationBuilder builder = operationService.createInvocationBuilder(getServiceName(), op, target)
                    .setTryCount(TRY_COUNT)
                    .setResultDeserialized(false)
                    .setExecutionCallback(new SingleTargetCallback(target, callback));
            builder.invoke();
        }
    }

    private boolean returnResponseIfNoTargetLeft(Collection<Address> targets, Map<Address, Object> results) {
        if (targets.isEmpty()) {
            try {
                sendResponse(reduce(results));
            } catch (Throwable throwable) {
                sendClientMessage(throwable);
            }
            return true;
        }
        return false;
    }

    protected abstract OperationFactory createOperationFactory();

    protected abstract Object reduce(Map<Address, Object> map) throws Throwable;

    public abstract Collection<Address> getTargets();

    private final class MultiTargetCallback {

        final Collection<Address> targets;
        final Map<Address, Object> results;

        private MultiTargetCallback(Collection<Address> targets) {
            this.targets = synchronizedSet(new HashSet<Address>(targets));
            this.results = new ConcurrentHashMap<Address, Object>(targets.size());
        }

        public void notify(Address target, Object result) {
            if (targets.remove(target)) {
                results.put(target, result);
            } else {
                if (results.containsKey(target)) {
                    throw new IllegalArgumentException("Duplicate response from -> " + target);
                }
                throw new IllegalArgumentException("Unknown target! -> " + target);
            }
            returnResponseIfNoTargetLeft(targets, results);
        }
    }

    private final class SingleTargetCallback extends SimpleExecutionCallback<Object> {

        final Address target;
        final MultiTargetCallback parent;

        private SingleTargetCallback(Address target, MultiTargetCallback parent) {
            this.target = target;
            this.parent = parent;
        }

        @Override
        public void notify(Object object) {
            parent.notify(target, object);
        }
    }
}

<code block>


package com.hazelcast.client.impl.client;

import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationFactory;
import com.hazelcast.spi.impl.SimpleExecutionCallback;

import java.util.Collection;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import static java.util.Collections.synchronizedSet;


public abstract class MultiTargetClientRequest extends ClientRequest {

    @Override
    public final void process() throws Exception {
        ClientEndpoint endpoint = getEndpoint();
        OperationFactory operationFactory = createOperationFactory();
        Collection<Address> targets = getTargets();
        if (targets.isEmpty()) {
            endpoint.sendResponse(reduce(new HashMap<Address, Object>()), getCallId());
            return;
        }

        MultiTargetCallback callback = new MultiTargetCallback(targets);
        for (Address target : targets) {
            Operation op = operationFactory.createOperation();
            op.setCallerUuid(endpoint.getUuid());
            InvocationBuilder builder = operationService.createInvocationBuilder(getServiceName(), op, target)
                    .setResultDeserialized(false)
                    .setExecutionCallback(new SingleTargetCallback(target, callback));
            builder.invoke();
        }
    }

    protected abstract OperationFactory createOperationFactory();

    protected abstract Object reduce(Map<Address, Object> map);

    public abstract Collection<Address> getTargets();

    private final class MultiTargetCallback {

        final Collection<Address> targets;
        final ConcurrentMap<Address, Object> results;

        private MultiTargetCallback(Collection<Address> targets) {
            this.targets = synchronizedSet(new HashSet<Address>(targets));
            this.results = new ConcurrentHashMap<Address, Object>(targets.size());
        }

        public void notify(Address target, Object result) {
            if (targets.remove(target)) {
                results.put(target, result);
            } else {
                if (results.containsKey(target)) {
                    throw new IllegalArgumentException("Duplicate response from -> " + target);
                }
                throw new IllegalArgumentException("Unknown target! -> " + target);
            }
            if (targets.isEmpty()) {
                Object response = reduce(results);
                endpoint.sendResponse(response, getCallId());
            }
        }
    }

    private static final class SingleTargetCallback extends SimpleExecutionCallback<Object> {

        final Address target;
        final MultiTargetCallback parent;

        private SingleTargetCallback(Address target, MultiTargetCallback parent) {
            this.target = target;
            this.parent = parent;
        }

        @Override
        public void notify(Object object) {
            parent.notify(target, object);
        }
    }
}

<code block>


package com.hazelcast.executor.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.ICompletableFuture;
import com.hazelcast.core.IExecutorService;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberSelector;
import com.hazelcast.core.MultiExecutionCallback;
import com.hazelcast.core.PartitionAware;
import com.hazelcast.executor.impl.operations.CallableTaskOperation;
import com.hazelcast.executor.impl.operations.MemberCallableTaskOperation;
import com.hazelcast.executor.impl.operations.ShutdownOperation;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.monitor.LocalExecutorStats;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.spi.AbstractDistributedObject;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.OperationService;
import com.hazelcast.util.Clock;
import com.hazelcast.util.executor.CompletedFuture;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
import java.util.logging.Level;

import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;
import static com.hazelcast.util.Preconditions.checkNotNull;
import static com.hazelcast.util.UuidUtil.buildRandomUuidString;

public class ExecutorServiceProxy
        extends AbstractDistributedObject<DistributedExecutorService>
        implements IExecutorService {

    public static final int SYNC_FREQUENCY = 100;
    public static final int SYNC_DELAY_MS = 10;

    private static final AtomicIntegerFieldUpdater<ExecutorServiceProxy> CONSECUTIVE_SUBMITS_UPDATER = AtomicIntegerFieldUpdater
            .newUpdater(ExecutorServiceProxy.class, "consecutiveSubmits");

    private static final ExceptionHandler WHILE_SHUTDOWN_EXCEPTION_HANDLER =
            logAllExceptions("Exception while ExecutorService shutdown", Level.FINEST);

    private final String name;
    private final Random random = new Random(-System.currentTimeMillis());
    private final int partitionCount;
    private final ILogger logger;

    
    private volatile int consecutiveSubmits;

    private volatile long lastSubmitTime;

    public ExecutorServiceProxy(String name, NodeEngine nodeEngine, DistributedExecutorService service) {
        super(nodeEngine, service);
        this.name = name;
        this.partitionCount = nodeEngine.getPartitionService().getPartitionCount();
        this.logger = nodeEngine.getLogger(ExecutorServiceProxy.class);
        getLocalExecutorStats();
    }

    @Override
    public void execute(Runnable command, MemberSelector memberSelector) {
        List<Member> members = selectMembers(memberSelector);
        int selectedMember = random.nextInt(members.size());
        executeOnMember(command, members.get(selectedMember));
    }

    @Override
    public void executeOnMembers(Runnable command, MemberSelector memberSelector) {
        List<Member> members = selectMembers(memberSelector);
        executeOnMembers(command, members);
    }

    @Override
    public <T> Future<T> submit(Callable<T> task, MemberSelector memberSelector) {
        List<Member> members = selectMembers(memberSelector);
        int selectedMember = random.nextInt(members.size());
        return submitToMember(task, members.get(selectedMember));
    }

    @Override
    public <T> Map<Member, Future<T>> submitToMembers(Callable<T> task, MemberSelector memberSelector) {
        List<Member> members = selectMembers(memberSelector);
        return submitToMembers(task, members);
    }

    @Override
    public void submit(Runnable task, MemberSelector memberSelector, ExecutionCallback callback) {
        List<Member> members = selectMembers(memberSelector);
        int selectedMember = random.nextInt(members.size());
        submitToMember(task, members.get(selectedMember), callback);
    }

    @Override
    public void submitToMembers(Runnable task, MemberSelector memberSelector, MultiExecutionCallback callback) {
        List<Member> members = selectMembers(memberSelector);
        submitToMembers(task, members, callback);
    }

    @Override
    public <T> void submit(Callable<T> task, MemberSelector memberSelector, ExecutionCallback<T> callback) {
        List<Member> members = selectMembers(memberSelector);
        int selectedMember = random.nextInt(members.size());
        submitToMember(task, members.get(selectedMember), callback);
    }

    @Override
    public <T> void submitToMembers(Callable<T> task, MemberSelector memberSelector, MultiExecutionCallback callback) {
        List<Member> members = selectMembers(memberSelector);
        submitToMembers(task, members, callback);
    }

    @Override
    public void execute(Runnable command) {
        Callable<?> callable = createRunnableAdapter(command);
        submit(callable);
    }

    private <T> RunnableAdapter<T> createRunnableAdapter(Runnable command) {
        checkNotNull(command, "Command can't be null");

        return new RunnableAdapter<T>(command);
    }

    @Override
    public void executeOnKeyOwner(Runnable command, Object key) {
        Callable<?> callable = createRunnableAdapter(command);
        submitToKeyOwner(callable, key);
    }

    @Override
    public void executeOnMember(Runnable command, Member member) {
        Callable<?> callable = createRunnableAdapter(command);
        submitToMember(callable, member);
    }

    @Override
    public void executeOnMembers(Runnable command, Collection<Member> members) {
        Callable<?> callable = createRunnableAdapter(command);
        submitToMembers(callable, members);
    }

    @Override
    public void executeOnAllMembers(Runnable command) {
        Callable<?> callable = createRunnableAdapter(command);
        submitToAllMembers(callable);
    }

    @Override
    public Future<?> submit(Runnable task) {
        Callable<?> callable = createRunnableAdapter(task);
        return submit(callable);
    }

    @Override
    public <T> Future<T> submit(Runnable task, T result) {
        checkNotNull(task, "task can't be null");
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Callable<T> callable = createRunnableAdapter(task);
        Data callableData = nodeEngine.toData(callable);
        String uuid = buildRandomUuidString();
        int partitionId = getTaskPartitionId(callable);

        CallableTaskOperation op = new CallableTaskOperation(name, uuid, callableData);
        ICompletableFuture future = invoke(partitionId, op);
        boolean sync = checkSync();
        if (sync) {
            try {
                future.get();
            } catch (Exception exception) {
                logger.warning(exception);
            }
            return new CompletedFuture<T>(nodeEngine.getSerializationService(), result, getAsyncExecutor());
        }
        return new CancellableDelegatingFuture<T>(future, result, nodeEngine, uuid, partitionId);
    }

    private void checkNotShutdown() {
        if (isShutdown()) {
            throw new RejectedExecutionException(getRejectionMessage());
        }
    }

    private InternalCompletableFuture invoke(int partitionId, CallableTaskOperation op) {
        NodeEngine nodeEngine = getNodeEngine();
        OperationService operationService = nodeEngine.getOperationService();
        return operationService.invokeOnPartition(DistributedExecutorService.SERVICE_NAME, op, partitionId);
    }

    @Override
    public <T> Future<T> submit(Callable<T> task) {
        final int partitionId = getTaskPartitionId(task);
        return submitToPartitionOwner(task, partitionId, false);
    }

    private <T> Future<T> submitToPartitionOwner(Callable<T> task, int partitionId, boolean preventSync) {
        checkNotNull(task, "task can't be null");
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Data taskData = nodeEngine.toData(task);
        String uuid = buildRandomUuidString();

        boolean sync = !preventSync && checkSync();
        CallableTaskOperation op = new CallableTaskOperation(name, uuid, taskData);
        ICompletableFuture future = invoke(partitionId, op);
        if (sync) {
            Object response;
            try {
                response = future.get();
            } catch (Exception e) {
                response = e;
            }
            return new CompletedFuture<T>(nodeEngine.getSerializationService(), response, getAsyncExecutor());
        }
        return new CancellableDelegatingFuture<T>(future, nodeEngine, uuid, partitionId);
    }

    
    private boolean checkSync() {
        boolean sync = false;
        long last = lastSubmitTime;
        long now = Clock.currentTimeMillis();
        if (last + SYNC_DELAY_MS < now) {
            CONSECUTIVE_SUBMITS_UPDATER.set(this, 0);
        } else if (CONSECUTIVE_SUBMITS_UPDATER.incrementAndGet(this) % SYNC_FREQUENCY == 0) {
            sync = true;
        }
        lastSubmitTime = now;
        return sync;
    }

    private <T> int getTaskPartitionId(Callable<T> task) {
        if (task instanceof PartitionAware) {
            Object partitionKey = ((PartitionAware) task).getPartitionKey();
            if (partitionKey != null) {
                return getNodeEngine().getPartitionService().getPartitionId(partitionKey);
            }
        }
        return random.nextInt(partitionCount);
    }

    @Override
    public <T> Future<T> submitToKeyOwner(Callable<T> task, Object key) {
        NodeEngine nodeEngine = getNodeEngine();
        return submitToPartitionOwner(task, nodeEngine.getPartitionService().getPartitionId(key), false);
    }

    @Override
    public <T> Future<T> submitToMember(Callable<T> task, Member member) {
        checkNotNull(task, "task can't be null");
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Data taskData = nodeEngine.toData(task);
        String uuid = buildRandomUuidString();
        Address target = ((MemberImpl) member).getAddress();

        boolean sync = checkSync();
        MemberCallableTaskOperation op = new MemberCallableTaskOperation(name, uuid, taskData);
        InternalCompletableFuture future = nodeEngine.getOperationService()
                .invokeOnTarget(DistributedExecutorService.SERVICE_NAME, op, target);
        if (sync) {
            Object response;
            try {
                response = future.get();
            } catch (Exception e) {
                response = e;
            }
            return new CompletedFuture<T>(nodeEngine.getSerializationService(), response, getAsyncExecutor());
        }
        return new CancellableDelegatingFuture<T>(future, nodeEngine, uuid, target);
    }

    @Override
    public <T> Map<Member, Future<T>> submitToMembers(Callable<T> task, Collection<Member> members) {
        Map<Member, Future<T>> futures = new HashMap<Member, Future<T>>(members.size());
        for (Member member : members) {
            futures.put(member, submitToMember(task, member));
        }
        return futures;
    }

    @Override
    public <T> Map<Member, Future<T>> submitToAllMembers(Callable<T> task) {
        NodeEngine nodeEngine = getNodeEngine();
        return submitToMembers(task, nodeEngine.getClusterService().getMembers());
    }

    @Override
    public void submit(Runnable task, ExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submit(callable, callback);
    }

    @Override
    public void submitToKeyOwner(Runnable task, Object key, ExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submitToKeyOwner(callable, key, callback);
    }

    @Override
    public void submitToMember(Runnable task, Member member, ExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submitToMember(callable, member, callback);
    }

    @Override
    public void submitToMembers(Runnable task, Collection<Member> members, MultiExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submitToMembers(callable, members, callback);
    }

    @Override
    public void submitToAllMembers(Runnable task, MultiExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submitToAllMembers(callable, callback);
    }

    private <T> void submitToPartitionOwner(Callable<T> task, ExecutionCallback<T> callback, int partitionId) {
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Data taskData = nodeEngine.toData(task);
        CallableTaskOperation op = new CallableTaskOperation(name, null, taskData);
        OperationService operationService = nodeEngine.getOperationService();
        operationService.createInvocationBuilder(DistributedExecutorService.SERVICE_NAME, op, partitionId)
                .setExecutionCallback((ExecutionCallback) callback).invoke();
    }

    @Override
    public <T> void submit(Callable<T> task, ExecutionCallback<T> callback) {
        int partitionId = getTaskPartitionId(task);
        submitToPartitionOwner(task, callback, partitionId);
    }

    @Override
    public <T> void submitToKeyOwner(Callable<T> task, Object key, ExecutionCallback<T> callback) {
        NodeEngine nodeEngine = getNodeEngine();
        submitToPartitionOwner(task, callback, nodeEngine.getPartitionService().getPartitionId(key));
    }

    @Override
    public <T> void submitToMember(Callable<T> task, Member member, ExecutionCallback<T> callback) {
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Data taskData = nodeEngine.toData(task);
        MemberCallableTaskOperation op = new MemberCallableTaskOperation(name, null, taskData);
        OperationService operationService = nodeEngine.getOperationService();
        Address address = ((MemberImpl) member).getAddress();
        operationService
                .createInvocationBuilder(DistributedExecutorService.SERVICE_NAME, op, address)
                .setExecutionCallback((ExecutionCallback) callback).invoke();
    }

    private String getRejectionMessage() {
        return "ExecutorService[" + name + "] is shutdown! In order to create a new ExecutorService with name '" + name
                + "', you need to destroy current ExecutorService first!";
    }

    @Override
    public <T> void submitToMembers(Callable<T> task, Collection<Member> members, MultiExecutionCallback callback) {
        NodeEngine nodeEngine = getNodeEngine();
        ExecutionCallbackAdapterFactory executionCallbackFactory = new ExecutionCallbackAdapterFactory(
                nodeEngine.getLogger(ExecutionCallbackAdapterFactory.class), members, callback);

        for (Member member : members) {
            submitToMember(task, member, executionCallbackFactory.<T>callbackFor(member));
        }
    }

    @Override
    public <T> void submitToAllMembers(Callable<T> task, MultiExecutionCallback callback) {
        NodeEngine nodeEngine = getNodeEngine();
        submitToMembers(task, nodeEngine.getClusterService().getMembers(), callback);
    }

    @Override
    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)
            throws InterruptedException {
        List<Future<T>> futures = new ArrayList<Future<T>>(tasks.size());
        List<Future<T>> result = new ArrayList<Future<T>>(tasks.size());
        for (Callable<T> task : tasks) {
            futures.add(submit(task));
        }
        for (Future<T> future : futures) {
            Object value;
            try {
                value = future.get();
            } catch (ExecutionException e) {
                value = e;
            }
            result.add(new CompletedFuture<T>(getNodeEngine().getSerializationService(), value, getAsyncExecutor()));
        }
        return result;
    }

    @Override
    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit)
            throws InterruptedException {
        checkNotNull(unit, "unit must not be null");
        checkNotNull(tasks, "tasks must not be null");

        long timeoutNanos = unit.toNanos(timeout);
        List<Future<T>> futures = new ArrayList<Future<T>>(tasks.size());
        boolean done = false;
        try {
            for (Callable<T> task : tasks) {
                long start = System.nanoTime();
                int partitionId = getTaskPartitionId(task);
                futures.add(submitToPartitionOwner(task, partitionId, true));
                timeoutNanos -= System.nanoTime() - start;
            }
            if (timeoutNanos <= 0L) {
                return futures;
            }

            done = wait(timeoutNanos, futures);
            return futures;
        } catch (Throwable t) {
            logger.severe(t);
            
            return futures;
        } finally {
            if (!done) {
                cancelAll(futures);
            }
        }
    }

    private <T> boolean wait(long timeoutNanos, List<Future<T>> futures) throws InterruptedException {
        boolean done = true;
        for (int i = 0, size = futures.size(); i < size; i++) {
            long start = System.nanoTime();
            Object value;
            try {
                Future<T> future = futures.get(i);
                value = future.get(timeoutNanos, TimeUnit.NANOSECONDS);
            } catch (ExecutionException e) {
                value = e;
            } catch (TimeoutException e) {
                done = false;
                for (int l = i; l < size; l++) {
                    Future<T> f = futures.get(i);
                    if (f.isDone()) {
                        Object v;
                        try {
                            v = f.get();
                        } catch (ExecutionException ex) {
                            v = ex;
                        }
                        futures.set(l, new CompletedFuture<T>(getNodeEngine().getSerializationService(), v, getAsyncExecutor()));
                    }
                }
                break;
            }

            futures.set(i, new CompletedFuture<T>(getNodeEngine().getSerializationService(), value, getAsyncExecutor()));
            timeoutNanos -= System.nanoTime() - start;
        }
        return done;
    }

    private static <T> void cancelAll(List<Future<T>> result) {
        for (Future<T> aResult : result) {
            aResult.cancel(true);
        }
    }

    @Override
    public <T> T invokeAny(Collection<? extends Callable<T>> tasks)
            throws InterruptedException, ExecutionException {
        throw new UnsupportedOperationException();
    }

    @Override
    public <T> T invokeAny(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit)
            throws InterruptedException, ExecutionException, TimeoutException {
        throw new UnsupportedOperationException();
    }

    @Override
    protected void throwNotActiveException() {
        throw new RejectedExecutionException();
    }

    @Override
    public boolean isShutdown() {
        try {
            return getService().isShutdown(name);
        } catch (HazelcastInstanceNotActiveException e) {
            return true;
        }
    }

    @Override
    public boolean isTerminated() {
        return isShutdown();
    }

    @Override
    public boolean awaitTermination(long timeout, TimeUnit unit)
            throws InterruptedException {
        return false;
    }

    @Override
    public void shutdown() {
        NodeEngine nodeEngine = getNodeEngine();
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        OperationService operationService = nodeEngine.getOperationService();
        Collection<Future> calls = new LinkedList<Future>();

        for (MemberImpl member : members) {
            if (member.localMember()) {
                getService().shutdownExecutor(name);
            } else {
                Future f = submitShutdownOperation(operationService, member);
                calls.add(f);
            }
        }

        waitWithDeadline(calls, 1, TimeUnit.SECONDS, WHILE_SHUTDOWN_EXCEPTION_HANDLER);
    }

    private InternalCompletableFuture submitShutdownOperation(OperationService operationService, MemberImpl member) {
        ShutdownOperation op = new ShutdownOperation(name);
        return operationService.invokeOnTarget(getServiceName(), op, member.getAddress());
    }

    @Override
    public List<Runnable> shutdownNow() {
        shutdown();
        return Collections.emptyList();
    }

    @Override
    public LocalExecutorStats getLocalExecutorStats() {
        return getService().getLocalExecutorStats(name);
    }

    @Override
    public String getServiceName() {
        return DistributedExecutorService.SERVICE_NAME;
    }

    @Override
    public String getName() {
        return name;
    }

    private ExecutorService getAsyncExecutor() {
        return getNodeEngine().getExecutionService().getExecutor(ExecutionService.ASYNC_EXECUTOR);
    }

    private List<Member> selectMembers(MemberSelector memberSelector) {
        if (memberSelector == null) {
            throw new IllegalArgumentException("memberSelector must not be null");
        }
        List<Member> selected = new ArrayList<Member>();
        Collection<MemberImpl> members = getNodeEngine().getClusterService().getMemberList();
        for (MemberImpl member : members) {
            if (memberSelector.select(member)) {
                selected.add(member);
            }
        }
        if (selected.isEmpty()) {
            throw new RejectedExecutionException("No member selected with memberSelector[" + memberSelector + "]");
        }
        return selected;
    }

    @Override
    public String toString() {
        return "IExecutorService{" + "name='" + name + '\'' + '}';
    }
}

<code block>
package com.hazelcast.spi;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.test.HazelcastParallelClassRunner;
import com.hazelcast.test.HazelcastTestSupport;
import com.hazelcast.test.annotation.QuickTest;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;

import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertSame;
import static org.mockito.Mockito.mock;

@RunWith(HazelcastParallelClassRunner.class)
@Category(QuickTest.class)
public class InvocationBuilderTest extends HazelcastTestSupport {

    @Test
    public void getTargetExecutionCallback_whenNull() {
        InvocationBuilder builder = new MockInvocationBuilder(null, null, null, 0, null);

        assertNull(builder.getTargetExecutionCallback());
    }

    @Test
    public void getTargetExecutionCallback_whenCallbackInstance() {
        InvocationBuilder invocationBuilder = new MockInvocationBuilder(null, null, null, 0, null);

        assertNull(invocationBuilder.getTargetExecutionCallback());

        Callback callback = mock(Callback.class);
        invocationBuilder.setCallback(callback);

        assertInstanceOf(InvocationBuilder.ExecutorCallbackAdapter.class, invocationBuilder.getTargetExecutionCallback());
    }

    @Test
    public void getTargetExecutionCallback_whenExecutionCallbackInstance() {
        InvocationBuilder invocationBuilder = new MockInvocationBuilder(null, null, null, 0, null);

        ExecutionCallback executionCallback = mock(ExecutionCallback.class);
        invocationBuilder.setExecutionCallback(executionCallback);

        assertSame(executionCallback, invocationBuilder.getTargetExecutionCallback());
    }

    class MockInvocationBuilder extends InvocationBuilder {
        public MockInvocationBuilder(NodeEngineImpl nodeEngine, String serviceName, Operation op, int partitionId, Address target) {
            super(nodeEngine, serviceName, op, partitionId, target);
        }

        @Override
        public <E> InternalCompletableFuture<E> invoke() {
            return null;
        }
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.ReplicaErrorLogger;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PartitionAwareOperation;
import com.hazelcast.spi.UrgentSystemOperation;

import java.io.IOException;


final class SyncReplicaVersion extends Operation implements PartitionAwareOperation, UrgentSystemOperation {

    public static final int OPERATION_TRY_COUNT = 10;
    public static final int OPERATION_TRY_PAUSE_MILLIS = 250;

    private final int syncReplicaIndex;
    private final Callback<Object> callback;
    private final boolean sync;

    public SyncReplicaVersion(int syncReplicaIndex, Callback<Object> callback) {
        if (syncReplicaIndex < 1 || syncReplicaIndex > InternalPartition.MAX_BACKUP_COUNT) {
            throw new IllegalArgumentException("Replica index should be in range [1-"
                    + InternalPartition.MAX_BACKUP_COUNT + "]");
        }
        this.syncReplicaIndex = syncReplicaIndex;
        this.callback = callback;
        this.sync = callback != null;
    }

    @Override
    public void beforeRun() throws Exception {
    }

    @Override
    public void run() throws Exception {
        InternalPartitionServiceImpl partitionService = getService();
        int partitionId = getPartitionId();
        int replicaIndex = syncReplicaIndex;
        InternalPartition partition = partitionService.getPartition(partitionId);
        Address target = partition.getReplicaAddress(replicaIndex);
        if (target == null) {
            notifyCallback(false);
            return;
        }

        invokeCheckReplicaVersion(partitionId, replicaIndex, target);
    }

    private void invokeCheckReplicaVersion(int partitionId, int replicaIndex, Address target) {
        InternalPartitionServiceImpl partitionService = getService();
        long[] currentVersions = partitionService.getPartitionReplicaVersions(partitionId);
        long currentReplicaVersion = currentVersions[replicaIndex - 1];

        if (currentReplicaVersion > 0) {
            CheckReplicaVersion op = createCheckReplicaVersion(partitionId, replicaIndex, currentReplicaVersion);
            NodeEngine nodeEngine = getNodeEngine();
            OperationService operationService = nodeEngine.getOperationService();
            if (sync) {
                operationService.createInvocationBuilder(InternalPartitionService.SERVICE_NAME, op, target)
                        .setCallback(callback)
                        .setTryCount(OPERATION_TRY_COUNT)
                        .setTryPauseMillis(OPERATION_TRY_PAUSE_MILLIS)
                        .invoke();
            } else {
                operationService.send(op, target);
            }
        } else {
            notifyCallback(true);
        }
    }

    private void notifyCallback(boolean result) {
        if (callback != null) {
            callback.notify(result);
        }
    }

    private CheckReplicaVersion createCheckReplicaVersion(int partitionId, int replicaIndex, long currentVersion) {
        CheckReplicaVersion op = new CheckReplicaVersion(currentVersion, sync);
        op.setPartitionId(partitionId).setReplicaIndex(replicaIndex).setServiceName(InternalPartitionService.SERVICE_NAME);
        return op;
    }

    @Override
    public void afterRun() throws Exception {
    }

    @Override
    public boolean returnsResponse() {
        return false;
    }

    @Override
    public Object getResponse() {
        return null;
    }

    @Override
    public boolean validatesTarget() {
        return false;
    }

    @Override
    public String getServiceName() {
        return InternalPartitionService.SERVICE_NAME;
    }

    @Override
    public void logError(Throwable e) {
        ReplicaErrorLogger.log(e, getLogger());
    }

    @Override
    protected void writeInternal(ObjectDataOutput out) throws IOException {
        throw new UnsupportedOperationException();
    }

    @Override
    protected void readInternal(ObjectDataInput in) throws IOException {
        throw new UnsupportedOperationException();
    }

    @Override
    public String toString() {
        return getClass().getSimpleName() + "{" + "partitionId=" + getPartitionId() + ", replicaIndex=" + syncReplicaIndex + '}';
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.cluster.MemberInfo;
import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.Member;
import com.hazelcast.core.MigrationEvent;
import com.hazelcast.core.MigrationEvent.MigrationStatus;
import com.hazelcast.core.MigrationListener;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.instance.Node;
import com.hazelcast.instance.OutOfMemoryErrorDispatcher;
import com.hazelcast.logging.ILogger;
import com.hazelcast.logging.Logger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionLostEvent;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationEndpoint;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.partition.PartitionEvent;
import com.hazelcast.partition.PartitionEventListener;
import com.hazelcast.partition.PartitionInfo;
import com.hazelcast.partition.PartitionLostEvent;
import com.hazelcast.partition.PartitionLostListener;
import com.hazelcast.partition.PartitionRuntimeState;
import com.hazelcast.partition.PartitionServiceProxy;
import com.hazelcast.partition.membergroup.MemberGroup;
import com.hazelcast.partition.membergroup.MemberGroupFactory;
import com.hazelcast.partition.membergroup.MemberGroupFactoryFactory;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.EventPublishingService;
import com.hazelcast.spi.EventRegistration;
import com.hazelcast.spi.EventService;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.ManagedService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.PartitionAwareService;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.ResponseHandlerFactory;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.FutureUtil.ExceptionHandler;
import com.hazelcast.util.scheduler.CoalescingDelayedTrigger;
import com.hazelcast.util.scheduler.EntryTaskScheduler;
import com.hazelcast.util.scheduler.EntryTaskSchedulerFactory;
import com.hazelcast.util.scheduler.ScheduleType;
import com.hazelcast.util.scheduler.ScheduledEntry;
import com.hazelcast.util.scheduler.ScheduledEntryProcessor;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReferenceArray;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;

import static com.hazelcast.partition.impl.InternalPartitionServiceState.MIGRATION_LOCAL;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.MIGRATION_ON_MASTER;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.SAFE;
import static com.hazelcast.partition.impl.InternalPartitionServiceState.REPLICA_NOT_SYNC;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;



public class InternalPartitionServiceImpl implements InternalPartitionService, ManagedService,
        EventPublishingService<PartitionEvent, PartitionEventListener<PartitionEvent>>, PartitionAwareService {

    private static final String EXCEPTION_MSG_PARTITION_STATE_SYNC_TIMEOUT = "Partition state sync invocation timed out";

    private static final int DEFAULT_PAUSE_MILLIS = 1000;
    private static final int PARTITION_OWNERSHIP_WAIT_MILLIS = 10;
    private static final int REPLICA_SYNC_CHECK_TIMEOUT_SECONDS = 10;

    private final Node node;
    private final NodeEngineImpl nodeEngine;
    private final ILogger logger;
    private final int partitionCount;
    private final InternalPartitionImpl[] partitions;
    private final PartitionReplicaVersions[] replicaVersions;
    private final AtomicReferenceArray<ReplicaSyncInfo> replicaSyncRequests;
    private final EntryTaskScheduler<Integer, ReplicaSyncInfo> replicaSyncScheduler;
    private final Semaphore replicaSyncProcessLock;
    private final MigrationThread migrationThread;
    private final long partitionMigrationInterval;
    private final long partitionMigrationTimeout;
    private final long backupSyncCheckInterval;
    private final int maxParallelReplications;
    private final PartitionStateGenerator partitionStateGenerator;
    private final MemberGroupFactory memberGroupFactory;
    private final PartitionServiceProxy proxy;
    private final Lock lock = new ReentrantLock();
    private final AtomicInteger stateVersion = new AtomicInteger();
    private final BlockingQueue<Runnable> migrationQueue = new LinkedBlockingQueue<Runnable>();
    private final AtomicBoolean migrationActive = new AtomicBoolean(true);
    private final AtomicLong lastRepartitionTime = new AtomicLong();
    private final CoalescingDelayedTrigger delayedResumeMigrationTrigger;

    private final ExceptionHandler partitionStateSyncTimeoutHandler;

    
    private volatile int memberGroupsSize;

    
    private volatile boolean initialized;

    
    private final ConcurrentMap<Integer, MigrationInfo> activeMigrations
            = new ConcurrentHashMap<Integer, MigrationInfo>(3, 0.75f, 1);

    
    private final LinkedList<MigrationInfo> completedMigrations = new LinkedList<MigrationInfo>();

    public InternalPartitionServiceImpl(Node node) {
        this.partitionCount = node.groupProperties.PARTITION_COUNT.getInteger();
        this.node = node;
        this.nodeEngine = node.nodeEngine;
        this.logger = node.getLogger(InternalPartitionService.class);
        partitionStateSyncTimeoutHandler =
                logAllExceptions(logger, EXCEPTION_MSG_PARTITION_STATE_SYNC_TIMEOUT, Level.FINEST);
        this.partitions = new InternalPartitionImpl[partitionCount];
        PartitionListener partitionListener = new LocalPartitionListener(this, node.getThisAddress());
        for (int i = 0; i < partitionCount; i++) {
            this.partitions[i] = new InternalPartitionImpl(i, partitionListener, node.getThisAddress());
        }
        replicaVersions = new PartitionReplicaVersions[partitionCount];
        for (int i = 0; i < replicaVersions.length; i++) {
            replicaVersions[i] = new PartitionReplicaVersions(i);
        }

        memberGroupFactory = MemberGroupFactoryFactory.newMemberGroupFactory(node.getConfig().getPartitionGroupConfig());
        partitionStateGenerator = new PartitionStateGeneratorImpl();

        long interval = node.groupProperties.PARTITION_MIGRATION_INTERVAL.getLong();
        partitionMigrationInterval = interval > 0 ? TimeUnit.SECONDS.toMillis(interval) : 0;

        partitionMigrationTimeout = TimeUnit.SECONDS.toMillis(
                node.groupProperties.PARTITION_MIGRATION_TIMEOUT.getLong());

        migrationThread = new MigrationThread(node);
        proxy = new PartitionServiceProxy(this);

        ExecutionService executionService = nodeEngine.getExecutionService();
        ScheduledExecutorService scheduledExecutor = executionService.getDefaultScheduledExecutor();

        
        
        
        
        
        
        
        replicaSyncScheduler = EntryTaskSchedulerFactory.newScheduler(scheduledExecutor,
                new ReplicaSyncEntryProcessor(this), ScheduleType.POSTPONE);

        replicaSyncRequests = new AtomicReferenceArray<ReplicaSyncInfo>(partitionCount);

        long maxMigrationDelayMs = calculateMaxMigrationDelayOnMemberRemoved();
        long minMigrationDelayMs = calculateMigrationDelayOnMemberRemoved(maxMigrationDelayMs);
        this.delayedResumeMigrationTrigger = new CoalescingDelayedTrigger(
                executionService, minMigrationDelayMs, maxMigrationDelayMs, new Runnable() {
            @Override
            public void run() {
                resumeMigration();
            }
        });

        long definedBackupSyncCheckInterval = node.groupProperties.PARTITION_BACKUP_SYNC_INTERVAL.getInteger();
        backupSyncCheckInterval = definedBackupSyncCheckInterval > 0 ? definedBackupSyncCheckInterval : 1;

        maxParallelReplications = node.groupProperties.PARTITION_MAX_PARALLEL_REPLICATIONS.getInteger();
        replicaSyncProcessLock = new Semaphore(maxParallelReplications);
    }

    private long calculateMaxMigrationDelayOnMemberRemoved() {
        
        return node.groupProperties.OPERATION_CALL_TIMEOUT_MILLIS.getLong() / 2;
    }

    private long calculateMigrationDelayOnMemberRemoved(long maxDelayMs) {
        long migrationDelayMs = node.groupProperties.MIGRATION_MIN_DELAY_ON_MEMBER_REMOVED_SECONDS.getLong() * 1000;

        long connectionErrorDetectionIntervalMs = node.groupProperties.CONNECTION_MONITOR_INTERVAL.getLong()
                * node.groupProperties.CONNECTION_MONITOR_MAX_FAULTS.getInteger() * 5;
        migrationDelayMs = Math.max(migrationDelayMs, connectionErrorDetectionIntervalMs);

        long heartbeatIntervalMs = node.groupProperties.HEARTBEAT_INTERVAL_SECONDS.getLong() * 1000;
        migrationDelayMs = Math.max(migrationDelayMs, heartbeatIntervalMs * 3);

        migrationDelayMs = Math.min(migrationDelayMs, maxDelayMs);
        return migrationDelayMs;
    }

    @Override
    public void init(NodeEngine nodeEngine, Properties properties) {
        migrationThread.start();

        int partitionTableSendInterval = node.groupProperties.PARTITION_TABLE_SEND_INTERVAL.getInteger();
        if (partitionTableSendInterval <= 0) {
            partitionTableSendInterval = 1;
        }
        ExecutionService executionService = nodeEngine.getExecutionService();
        executionService.scheduleAtFixedRate(new SendClusterStateTask(),
                partitionTableSendInterval, partitionTableSendInterval, TimeUnit.SECONDS);

        executionService.scheduleWithFixedDelay(new SyncReplicaVersionTask(),
                backupSyncCheckInterval, backupSyncCheckInterval, TimeUnit.SECONDS);
    }

    @Override
    public Address getPartitionOwner(int partitionId) {
        if (!initialized) {
            firstArrangement();
        }
        if (partitions[partitionId].getOwnerOrNull() == null && !node.isMaster() && node.joined()) {
            notifyMasterToAssignPartitions();
        }
        return partitions[partitionId].getOwnerOrNull();
    }

    @Override
    public Address getPartitionOwnerOrWait(int partition) {
        Address owner = getPartitionOwner(partition);
        while (owner == null) {
            try {
                Thread.sleep(PARTITION_OWNERSHIP_WAIT_MILLIS);
            } catch (InterruptedException e) {
                ExceptionUtil.rethrow(e);
            }
            owner = getPartitionOwner(partition);
        }
        return owner;
    }

    private void notifyMasterToAssignPartitions() {
        if (initialized) {
            return;
        }
        if (lock.tryLock()) {
            try {
                if (!initialized && !node.isMaster() && node.getMasterAddress() != null && node.joined()) {
                    Future f = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, new AssignPartitions(),
                            node.getMasterAddress()).setTryCount(1).invoke();
                    f.get(1, TimeUnit.SECONDS);
                }
            } catch (Exception e) {
                logger.finest(e);
            } finally {
                lock.unlock();
            }
        }
    }

    @Override
    public void firstArrangement() {
        if (!node.isMaster() || !node.isActive()) {
            notifyMasterToAssignPartitions();
            return;
        }
        if (!initialized) {
            lock.lock();
            try {
                if (initialized) {
                    return;
                }
                PartitionStateGenerator psg = partitionStateGenerator;
                final Set<Member> members = node.getClusterService().getMembers();
                Collection<MemberGroup> memberGroups = memberGroupFactory.createMemberGroups(members);
                if (memberGroups.isEmpty()) {
                    logger.warning("No member group is available to assign partition ownership...");
                    return;
                }

                logger.info("Initializing cluster partition table first arrangement...");
                Address[][] newState = psg.initialize(memberGroups, partitionCount);
                if (newState.length != partitionCount) {
                    throw new HazelcastException("Invalid partition count! "
                            + "Expected: " + partitionCount + ", Actual: " + newState.length);
                }

                for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
                    InternalPartitionImpl partition = partitions[partitionId];
                    Address[] replicas = newState[partitionId];
                    partition.setReplicaAddresses(replicas);
                }
                initialized = true;
                publishPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
        }
    }

    private void updateMemberGroupsSize() {
        Set<Member> members = node.getClusterService().getMembers();
        final Collection<MemberGroup> groups = memberGroupFactory.createMemberGroups(members);
        int size = 0;
        for (MemberGroup group : groups) {
            if (group.size() > 0) {
                size++;
            }
        }
        memberGroupsSize = size;
    }

    @Override
    public int getMemberGroupsSize() {
        int size = memberGroupsSize;
        
        
        return size > 0 ? size : 1;
    }

    @Override
    public int getMaxBackupCount() {
        return Math.min(getMemberGroupsSize() - 1, InternalPartition.MAX_BACKUP_COUNT);
    }

    public void memberAdded(MemberImpl member) {
        if (!member.localMember()) {
            updateMemberGroupsSize();
        }
        if (node.isMaster() && node.isActive()) {
            lock.lock();
            try {
                migrationQueue.clear();
                if (initialized) {
                    migrationQueue.add(new RepartitioningTask());

                    
                    Collection<MemberImpl> members = node.clusterService.getMemberList();
                    PartitionStateOperation op = new PartitionStateOperation(createPartitionState(members));
                    nodeEngine.getOperationService().send(op, member.getAddress());
                }
            } finally {
                lock.unlock();
            }
        }
    }

    public void memberRemoved(final MemberImpl member) {
        updateMemberGroupsSize();
        final Address deadAddress = member.getAddress();
        final Address thisAddress = node.getThisAddress();
        if (deadAddress == null || deadAddress.equals(thisAddress)) {
            return;
        }
        lock.lock();
        try {
            migrationQueue.clear();
            if (!activeMigrations.isEmpty()) {
                if (node.isMaster()) {
                    rollbackActiveMigrationsFromPreviousMaster(node.getLocalMember().getUuid());
                }
                for (MigrationInfo migrationInfo : activeMigrations.values()) {
                    if (deadAddress.equals(migrationInfo.getSource()) || deadAddress.equals(migrationInfo.getDestination())) {
                        migrationInfo.invalidate();
                    }
                }
            }
            
            
            
            
            pauseMigration();
            cancelReplicaSyncRequestsTo(deadAddress);
            removeDeadAddress(deadAddress, thisAddress);

            if (node.isMaster() && initialized) {
                migrationQueue.add(new RepartitioningTask());
            }

            resumeMigrationEventually();
        } finally {
            lock.unlock();
        }
    }

    private void cancelReplicaSyncRequestsTo(Address deadAddress) {
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            ReplicaSyncInfo syncInfo = replicaSyncRequests.get(partitionId);
            if (syncInfo != null && deadAddress.equals(syncInfo.target)) {
                cancelReplicaSync(partitionId);
            }
        }
    }

    void cancelReplicaSync(int partitionId) {
        ReplicaSyncInfo syncInfo = replicaSyncRequests.get(partitionId);
        if (syncInfo != null && replicaSyncRequests.compareAndSet(partitionId, syncInfo, null)) {
            replicaSyncScheduler.cancel(partitionId);
            releaseReplicaSyncPermit();
        }
    }

    private void resumeMigrationEventually() {
        delayedResumeMigrationTrigger.executeWithDelay();
    }

    private void removeDeadAddress(Address deadAddress, Address thisAddress) {
        for (InternalPartitionImpl partition : partitions) {
            if (deadAddress.equals(partition.getOwnerOrNull()) && thisAddress.equals(partition.getReplicaAddress(1))) {
                partition.setMigrating(true);
            }
            
            partition.onDeadAddress(deadAddress);
            
            if (partition.onDeadAddress(deadAddress)) {
                throw new IllegalStateException("Duplicate address found in partition replicas!");
            }

        }
    }

    private void rollbackActiveMigrationsFromPreviousMaster(final String currentMasterUuid) {
        lock.lock();
        try {
            if (!activeMigrations.isEmpty()) {
                for (MigrationInfo migrationInfo : activeMigrations.values()) {
                    if (!currentMasterUuid.equals(migrationInfo.getMasterUuid())) {
                        
                        
                        logger.info("Rolling-back migration initiated by the old master -> " + migrationInfo);
                        finalizeActiveMigration(migrationInfo);
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private PartitionRuntimeState createPartitionState(Collection<MemberImpl> members) {
        lock.lock();
        try {
            List<MemberInfo> memberInfos = new ArrayList<MemberInfo>(members.size());
            for (MemberImpl member : members) {
                MemberInfo memberInfo = new MemberInfo(member.getAddress(), member.getUuid(), member.getAttributes());
                memberInfos.add(memberInfo);
            }
            ArrayList<MigrationInfo> migrationInfos = new ArrayList<MigrationInfo>(completedMigrations);
            ILogger logger = node.getLogger(PartitionRuntimeState.class);
            return new PartitionRuntimeState(logger, memberInfos, partitions, migrationInfos, stateVersion.get());
        } finally {
            lock.unlock();
        }
    }

    private void publishPartitionRuntimeState() {
        if (!initialized) {
            
            return;
        }

        if (!node.isMaster() || !node.isActive() || !node.joined()) {
            return;
        }

        if (!isMigrationActive()) {
            
            return;
        }

        lock.lock();
        try {
            Collection<MemberImpl> members = node.clusterService.getMemberList();
            PartitionRuntimeState partitionState = createPartitionState(members);
            PartitionStateOperation op = new PartitionStateOperation(partitionState);

            OperationService operationService = nodeEngine.getOperationService();
            for (MemberImpl member : members) {
                if (!member.localMember()) {
                    try {
                        operationService.send(op, member.getAddress());
                    } catch (Exception e) {
                        logger.finest(e);
                    }
                }
            }
        } finally {
            lock.unlock();
        }
    }

    private void syncPartitionRuntimeState() {
        syncPartitionRuntimeState(node.clusterService.getMemberList());
    }

    private void syncPartitionRuntimeState(Collection<MemberImpl> members) {
        if (!initialized) {
            
            return;
        }

        if (!node.isMaster() || !node.isActive() || !node.joined()) {
            return;
        }

        lock.lock();
        try {
            PartitionRuntimeState partitionState = createPartitionState(members);
            OperationService operationService = nodeEngine.getOperationService();

            List<Future> calls = firePartitionStateOperation(members, partitionState, operationService);
            waitWithDeadline(calls, 3, TimeUnit.SECONDS, partitionStateSyncTimeoutHandler);
        } finally {
            lock.unlock();
        }
    }

    private List<Future> firePartitionStateOperation(Collection<MemberImpl> members,
                                                     PartitionRuntimeState partitionState,
                                                     OperationService operationService) {
        List<Future> calls = new ArrayList<Future>(members.size());
        for (MemberImpl member : members) {
            if (!member.localMember()) {
                try {
                    Address address = member.getAddress();
                    PartitionStateOperation operation = new PartitionStateOperation(partitionState, true);
                    Future<Object> f = operationService.invokeOnTarget(SERVICE_NAME, operation, address);
                    calls.add(f);
                } catch (Exception e) {
                    logger.finest(e);
                }
            }
        }
        return calls;
    }

    void processPartitionRuntimeState(PartitionRuntimeState partitionState) {
        lock.lock();
        try {
            if (!node.isActive() || !node.joined()) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Node should be active(" + node.isActive() + ") and joined(" + node.joined()
                            + ") to be able to process partition table!");
                }
                return;
            }
            final Address sender = partitionState.getEndpoint();
            final Address master = node.getMasterAddress();
            if (node.isMaster()) {
                logger.warning("This is the master node and received a PartitionRuntimeState from "
                        + sender + ". Ignoring incoming state! ");
                return;
            } else {
                if (sender == null || !sender.equals(master)) {
                    if (node.clusterService.getMember(sender) == null) {
                        logger.severe("Received a ClusterRuntimeState from an unknown member!"
                                + " => Sender: " + sender + ", Master: " + master + "! ");
                        return;
                    } else {
                        logger.warning("Received a ClusterRuntimeState, but its sender doesn't seem to be master!"
                                + " => Sender: " + sender + ", Master: " + master + "! "
                                + "(Ignore if master node has changed recently.)");
                    }
                }
            }

            stateVersion.set(partitionState.getVersion());
            initialized = true;

            PartitionInfo[] state = partitionState.getPartitions();
            filterAndLogUnknownAddressesInPartitionTable(sender, state);
            finalizeOrRollbackMigration(partitionState, state);
        } finally {
            lock.unlock();
        }
    }

    private void finalizeOrRollbackMigration(PartitionRuntimeState partitionState, PartitionInfo[] state) {
        Collection<MigrationInfo> completedMigrations = partitionState.getCompletedMigrations();
        for (MigrationInfo completedMigration : completedMigrations) {
            addCompletedMigration(completedMigration);
            int partitionId = completedMigration.getPartitionId();
            PartitionInfo partitionInfo = state[partitionId];
            
            
            
            
            
            
            updatePartition(partitionInfo);
            finalizeActiveMigration(completedMigration);
        }
        if (!activeMigrations.isEmpty()) {
            final MemberImpl masterMember = getMasterMember();
            rollbackActiveMigrationsFromPreviousMaster(masterMember.getUuid());
        }

        updateAllPartitions(state);
    }

    private void updatePartition(PartitionInfo partitionInfo) {
        InternalPartitionImpl partition = partitions[partitionInfo.getPartitionId()];
        Address[] replicas = partitionInfo.getReplicaAddresses();
        partition.setReplicaAddresses(replicas);
    }

    private void updateAllPartitions(PartitionInfo[] state) {
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            updatePartition(state[partitionId]);
        }
    }

    private void filterAndLogUnknownAddressesInPartitionTable(Address sender, PartitionInfo[] state) {
        final Set<Address> unknownAddresses = new HashSet<Address>();
        for (int partitionId = 0; partitionId < state.length; partitionId++) {
            PartitionInfo partitionInfo = state[partitionId];
            searchUnknownAddressesInPartitionTable(sender, unknownAddresses, partitionId, partitionInfo);
        }
        logUnknownAddressesInPartitionTable(sender, unknownAddresses);
    }

    private void logUnknownAddressesInPartitionTable(Address sender, Set<Address> unknownAddresses) {
        if (!unknownAddresses.isEmpty() && logger.isLoggable(Level.WARNING)) {
            StringBuilder s = new StringBuilder("Following unknown addresses are found in partition table")
                    .append(" sent from master[").append(sender).append("].")
                    .append(" (Probably they have recently joined or left the cluster.)")
                    .append(" {");
            for (Address address : unknownAddresses) {
                s.append("\n\t").append(address);
            }
            s.append("\n}");
            logger.warning(s.toString());
        }
    }

    private void searchUnknownAddressesInPartitionTable(Address sender, Set<Address> unknownAddresses, int partitionId,
                                                        PartitionInfo partitionInfo) {
        for (int index = 0; index < InternalPartition.MAX_REPLICA_COUNT; index++) {
            Address address = partitionInfo.getReplicaAddress(index);
            if (address != null && getMember(address) == null) {
                if (logger.isFinestEnabled()) {
                    logger.finest(
                            "Unknown " + address + " found in partition table sent from master "
                                    + sender + ". It has probably already left the cluster. partitionId="
                                    + partitionId);
                }
                unknownAddresses.add(address);
            }
        }
    }

    private void finalizeActiveMigration(final MigrationInfo migrationInfo) {
        if (activeMigrations.containsKey(migrationInfo.getPartitionId())) {
            lock.lock();
            try {
                if (activeMigrations.containsValue(migrationInfo)) {
                    if (migrationInfo.startProcessing()) {
                        processMigrationInfo(migrationInfo);
                    } else {
                        logger.info("Scheduling finalization of " + migrationInfo
                                + ", because migration process is currently running.");
                        nodeEngine.getExecutionService().schedule(new Runnable() {
                            @Override
                            public void run() {
                                finalizeActiveMigration(migrationInfo);
                            }
                        }, 3, TimeUnit.SECONDS);
                    }
                }
            } finally {
                lock.unlock();
            }
        }
    }

    private void processMigrationInfo(MigrationInfo migrationInfo) {
        try {
            Address thisAddress = node.getThisAddress();
            boolean source = thisAddress.equals(migrationInfo.getSource());
            boolean destination = thisAddress.equals(migrationInfo.getDestination());
            if (source || destination) {
                int partitionId = migrationInfo.getPartitionId();
                InternalPartitionImpl migratingPartition = getPartitionImpl(partitionId);
                Address ownerAddress = migratingPartition.getOwnerOrNull();
                boolean success = migrationInfo.getDestination().equals(ownerAddress);
                MigrationEndpoint endpoint = source ? MigrationEndpoint.SOURCE : MigrationEndpoint.DESTINATION;
                FinalizeMigrationOperation op = new FinalizeMigrationOperation(endpoint, success);
                op.setPartitionId(partitionId)
                        .setNodeEngine(nodeEngine)
                        .setValidateTarget(false)
                        .setService(this);
                nodeEngine.getOperationService().executeOperation(op);
            }
        } catch (Exception e) {
            logger.warning(e);
        } finally {
            migrationInfo.doneProcessing();
        }
    }

    void addActiveMigration(MigrationInfo migrationInfo) {
        lock.lock();
        try {
            int partitionId = migrationInfo.getPartitionId();
            partitions[partitionId].setMigrating(true);
            MigrationInfo currentMigrationInfo = activeMigrations.putIfAbsent(partitionId, migrationInfo);
            if (currentMigrationInfo != null) {
                boolean oldMaster = false;
                MigrationInfo oldMigration;
                MigrationInfo newMigration;
                MemberImpl masterMember = getMasterMember();
                String master = masterMember.getUuid();
                if (!master.equals(currentMigrationInfo.getMasterUuid())) {
                    
                    oldMigration = currentMigrationInfo;
                    newMigration = migrationInfo;
                    oldMaster = true;
                } else if (!master.equals(migrationInfo.getMasterUuid())) {
                    
                    oldMigration = migrationInfo;
                    newMigration = currentMigrationInfo;
                    oldMaster = true;
                } else if (!currentMigrationInfo.isProcessing() && migrationInfo.isProcessing()) {
                    
                    oldMigration = currentMigrationInfo;
                    newMigration = migrationInfo;
                } else {
                    String message = "Something is seriously wrong! There are two migration requests for the "
                            + "same partition! First -> " + currentMigrationInfo + ", Second -> " + migrationInfo;
                    IllegalStateException error = new IllegalStateException(message);
                    logger.severe(message, error);
                    throw error;
                }

                if (oldMaster) {
                    logger.info("Finalizing migration instantiated by the old master -> " + oldMigration);
                } else {
                    if (logger.isFinestEnabled()) {
                        logger.finest("Finalizing previous migration -> " + oldMigration);
                    }
                }
                finalizeActiveMigration(oldMigration);
                activeMigrations.put(partitionId, newMigration);
            }
        } finally {
            lock.unlock();
        }
    }

    private MemberImpl getMasterMember() {
        return node.clusterService.getMember(node.getMasterAddress());
    }

    MigrationInfo getActiveMigration(int partitionId) {
        return activeMigrations.get(partitionId);
    }

    MigrationInfo removeActiveMigration(int partitionId) {
        partitions[partitionId].setMigrating(false);
        return activeMigrations.remove(partitionId);
    }

    public Collection<MigrationInfo> getActiveMigrations() {
        return Collections.unmodifiableCollection(activeMigrations.values());
    }

    private void addCompletedMigration(MigrationInfo migrationInfo) {
        lock.lock();
        try {
            if (completedMigrations.size() > 25) {
                completedMigrations.removeFirst();
            }
            completedMigrations.add(migrationInfo);
        } finally {
            lock.unlock();
        }
    }

    private void evictCompletedMigrations() {
        lock.lock();
        try {
            if (!completedMigrations.isEmpty()) {
                completedMigrations.removeFirst();
            }
        } finally {
            lock.unlock();
        }
    }

    
    
    
    void triggerPartitionReplicaSync(int partitionId, int replicaIndex, long delayMillis) {
        if (replicaIndex < 0 || replicaIndex > InternalPartition.MAX_REPLICA_COUNT) {
            throw new IllegalArgumentException("Invalid replica index! replicaIndex=" + replicaIndex
                    + " for partitionId=" + partitionId);
        }

        if (!checkSyncPartitionTarget(partitionId, replicaIndex)) {
            return;
        }

        InternalPartitionImpl partition = getPartitionImpl(partitionId);
        Address target = partition.getOwnerOrNull();
        ReplicaSyncInfo syncInfo = new ReplicaSyncInfo(partitionId, replicaIndex, target);

        if (delayMillis > 0) {
            schedulePartitionReplicaSync(syncInfo, target, delayMillis);
            return;
        }

        
        
        
        if (!isMigrationActive() || partition.isMigrating()) {
            schedulePartitionReplicaSync(syncInfo, target, REPLICA_SYNC_RETRY_DELAY);
            return;
        }

        if (replicaSyncRequests.compareAndSet(partitionId, null, syncInfo)) {
            if (fireSyncReplicaRequest(syncInfo, target)) {
                return;
            }

            replicaSyncRequests.compareAndSet(partitionId, syncInfo, null);
            schedulePartitionReplicaSync(syncInfo, target, REPLICA_SYNC_RETRY_DELAY);
            return;
        }

        long scheduleDelay = getReplicaSyncScheduleDelay(partitionId);
        schedulePartitionReplicaSync(syncInfo, target, scheduleDelay);
    }

    private long getReplicaSyncScheduleDelay(int partitionId) {
        long scheduleDelay = DEFAULT_REPLICA_SYNC_DELAY;
        Address thisAddress = node.getThisAddress();
        InternalPartitionImpl partition = getPartitionImpl(partitionId);
        ReplicaSyncInfo currentSyncInfo = replicaSyncRequests.get(partitionId);
        if (currentSyncInfo != null
                && !thisAddress.equals(partition.getReplicaAddress(currentSyncInfo.replicaIndex))) {
            clearReplicaSyncRequest(partitionId, currentSyncInfo.replicaIndex);
            scheduleDelay = REPLICA_SYNC_RETRY_DELAY;
        }
        return scheduleDelay;
    }

    private boolean fireSyncReplicaRequest(ReplicaSyncInfo syncInfo, Address target) {
        if (tryToAcquireReplicaSyncPermit()) {
            int partitionId = syncInfo.partitionId;
            int replicaIndex = syncInfo.replicaIndex;
            replicaSyncScheduler.cancel(partitionId);

            if (logger.isFinestEnabled()) {
                logger.finest("Sending sync replica request to -> " + target + "; for partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex);
            }
            replicaSyncScheduler.schedule(partitionMigrationTimeout, partitionId, syncInfo);
            ReplicaSyncRequest syncRequest = new ReplicaSyncRequest(partitionId, replicaIndex);
            nodeEngine.getOperationService().send(syncRequest, target);
            return true;
        }
        return false;
    }

    private void schedulePartitionReplicaSync(ReplicaSyncInfo syncInfo, Address target, long delayMillis) {
        int partitionId = syncInfo.partitionId;
        int replicaIndex = syncInfo.replicaIndex;

        if (logger.isFinestEnabled()) {
            logger.finest("Scheduling [" + delayMillis + "ms] sync replica request to -> " + target
                    + "; for partitionId=" + partitionId + ", replicaIndex=" + replicaIndex);
        }
        replicaSyncScheduler.schedule(delayMillis, partitionId, syncInfo);
    }

    private boolean checkSyncPartitionTarget(int partitionId, int replicaIndex) {
        final InternalPartitionImpl partition = getPartitionImpl(partitionId);
        final Address target = partition.getOwnerOrNull();
        if (target == null) {
            logger.info("Sync replica target is null, no need to sync -> partitionId=" + partitionId + ", replicaIndex="
                    + replicaIndex);
            return false;
        }

        Address thisAddress = nodeEngine.getThisAddress();
        if (target.equals(thisAddress)) {
            if (logger.isFinestEnabled()) {
                logger.finest("This node is now owner of partition, cannot sync replica -> partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex + ", partition-info="
                        + getPartitionImpl(partitionId));
            }
            return false;
        }

        if (!partition.isOwnerOrBackup(thisAddress)) {
            if (logger.isFinestEnabled()) {
                logger.finest("This node is not backup replica of partitionId=" + partitionId
                        + ", replicaIndex=" + replicaIndex + " anymore.");
            }
            return false;
        }
        return true;
    }

    @Override
    public InternalPartition[] getPartitions() {
        
        InternalPartition[] result = new InternalPartition[partitions.length];
        System.arraycopy(partitions, 0, result, 0, partitions.length);
        return result;
    }

    @Override
    public MemberImpl getMember(Address address) {
        return node.clusterService.getMember(address);
    }

    InternalPartitionImpl getPartitionImpl(int partitionId) {
        return partitions[partitionId];
    }

    @Override
    public InternalPartitionImpl getPartition(int partitionId) {
        return getPartition(partitionId, true);
    }

    @Override
    public InternalPartitionImpl getPartition(int partitionId, boolean triggerOwnerAssignment) {
        InternalPartitionImpl p = getPartitionImpl(partitionId);
        if (triggerOwnerAssignment && p.getOwnerOrNull() == null) {
            
            
            getPartitionOwner(partitionId);
        }
        return p;
    }

    @Override
    public boolean prepareToSafeShutdown(long timeout, TimeUnit unit) {
        long timeoutInMillis = unit.toMillis(timeout);
        long sleep = DEFAULT_PAUSE_MILLIS;
        while (timeoutInMillis > 0) {
            while (timeoutInMillis > 0 && shouldWaitMigrationOrBackups(Level.INFO)) {
                timeoutInMillis = sleepWithBusyWait(timeoutInMillis, sleep);
            }
            if (timeoutInMillis <= 0) {
                break;
            }

            if (node.isMaster()) {
                syncPartitionRuntimeState();
            } else {
                timeoutInMillis = waitForOngoingMigrations(timeoutInMillis, sleep);
                if (timeoutInMillis <= 0) {
                    break;
                }
            }

            long start = Clock.currentTimeMillis();
            boolean ok = checkReplicaSyncState();
            timeoutInMillis -= (Clock.currentTimeMillis() - start);
            if (ok) {
                logger.finest("Replica sync state before shutdown is OK");
                return true;
            } else {
                if (timeoutInMillis <= 0) {
                    break;
                }
                logger.info("Some backup replicas are inconsistent with primary, waiting for synchronization. Timeout: "
                        + timeoutInMillis + "ms");
                timeoutInMillis = sleepWithBusyWait(timeoutInMillis, sleep);
            }
        }
        return false;
    }

    private long waitForOngoingMigrations(long timeoutInMillis, long sleep) {
        long timeout = timeoutInMillis;
        while (timeout > 0 && hasOnGoingMigrationMaster(Level.WARNING)) {
            
            logger.info("Waiting for the master node to complete remaining migrations!");
            timeout = sleepWithBusyWait(timeout, sleep);
        }
        return timeout;
    }

    private long sleepWithBusyWait(long timeoutInMillis, long sleep) {
        try {
            
            Thread.sleep(sleep);
        } catch (InterruptedException ie) {
            logger.finest("Busy wait interrupted", ie);
        }
        return timeoutInMillis - sleep;
    }

    @Override
    public boolean isMemberStateSafe() {
        return getMemberState() == SAFE;
    }

    public InternalPartitionServiceState getMemberState() {
        if (hasOnGoingMigrationLocal()) {
            return MIGRATION_LOCAL;
        }

        if (!node.isMaster()) {
            if (hasOnGoingMigrationMaster(Level.OFF)) {
                return MIGRATION_ON_MASTER;
            }
        }

        return isReplicaInSyncState() ? SAFE : REPLICA_NOT_SYNC;
    }

    @Override
    public boolean hasOnGoingMigration() {
        return hasOnGoingMigrationLocal() || (!node.isMaster() && hasOnGoingMigrationMaster(Level.FINEST));
    }

    private boolean hasOnGoingMigrationMaster(Level level) {
        Address masterAddress = node.getMasterAddress();
        if (masterAddress == null) {
            return true;
        }
        Operation operation = new HasOngoingMigration();
        OperationService operationService = nodeEngine.getOperationService();
        InvocationBuilder invocationBuilder = operationService.createInvocationBuilder(SERVICE_NAME, operation,
                masterAddress);
        Future future = invocationBuilder.setTryCount(100).setTryPauseMillis(100).invoke();
        try {
            return (Boolean) future.get(1, TimeUnit.MINUTES);
        } catch (InterruptedException ie) {
            Logger.getLogger(InternalPartitionServiceImpl.class).finest("Future wait interrupted", ie);
        } catch (Exception e) {
            logger.log(level, "Could not get a response from master about migrations! -> " + e.toString());
        }
        return false;
    }

    @Override
    public boolean hasOnGoingMigrationLocal() {
        return !activeMigrations.isEmpty() || !migrationQueue.isEmpty()
                || !isMigrationActive()
                || migrationThread.isMigrating()
                || shouldWaitMigrationOrBackups(Level.OFF);
    }

    private boolean isReplicaInSyncState() {
        if (!initialized || getMemberGroupsSize() < 2) {
            return true;
        }
        final int replicaIndex = 1;
        final List<Future> futures = new ArrayList<Future>();
        final Address thisAddress = node.getThisAddress();
        for (InternalPartitionImpl partition : partitions) {
            final Address owner = partition.getOwnerOrNull();
            if (thisAddress.equals(owner)) {
                if (partition.getReplicaAddress(replicaIndex) != null) {
                    final int partitionId = partition.getPartitionId();
                    final long replicaVersion = getCurrentReplicaVersion(replicaIndex, partitionId);
                    final Operation operation = createReplicaSyncStateOperation(replicaVersion, partitionId);
                    final Future future = invoke(operation, replicaIndex, partitionId);
                    futures.add(future);
                }
            }
        }
        if (futures.isEmpty()) {
            return true;
        }
        for (Future future : futures) {
            boolean isSync = getFutureResult(future, REPLICA_SYNC_CHECK_TIMEOUT_SECONDS, TimeUnit.SECONDS);
            if (!isSync) {
                return false;
            }
        }
        return true;
    }

    private long getCurrentReplicaVersion(int replicaIndex, int partitionId) {
        final long[] versions = getPartitionReplicaVersions(partitionId);
        return versions[replicaIndex - 1];
    }

    private boolean getFutureResult(Future future, long seconds, TimeUnit unit) {
        boolean sync;
        try {
            sync = (Boolean) future.get(seconds, unit);
        } catch (Throwable t) {
            sync = false;
            logger.warning("Exception while getting future", t);
        }
        return sync;
    }

    private Future invoke(Operation operation, int replicaIndex, int partitionId) {
        final OperationService operationService = nodeEngine.getOperationService();
        return operationService.createInvocationBuilder(InternalPartitionService.SERVICE_NAME, operation, partitionId)
                .setTryCount(3)
                .setTryPauseMillis(250)
                .setReplicaIndex(replicaIndex)
                .invoke();
    }

    private Operation createReplicaSyncStateOperation(long replicaVersion, int partitionId) {
        final Operation op = new IsReplicaVersionSync(replicaVersion);
        op.setService(this);
        op.setNodeEngine(nodeEngine);
        op.setResponseHandler(ResponseHandlerFactory
                .createErrorLoggingResponseHandler(node.getLogger(IsReplicaVersionSync.class)));
        op.setPartitionId(partitionId);

        return op;
    }

    private boolean checkReplicaSyncState() {
        if (!initialized) {
            return true;
        }

        if (getMemberGroupsSize() < 2) {
            return true;
        }

        final Address thisAddress = node.getThisAddress();
        final Semaphore s = new Semaphore(0);
        final AtomicBoolean ok = new AtomicBoolean(true);
        final Callback<Object> callback = new Callback<Object>() {
            @Override
            public void notify(Object object) {
                if (Boolean.FALSE.equals(object)) {
                    ok.compareAndSet(true, false);
                } else if (object instanceof Throwable) {
                    ok.compareAndSet(true, false);
                }
                s.release();
            }
        };
        int ownedCount = submitSyncReplicaOperations(thisAddress, s, ok, callback);
        try {
            if (ok.get()) {
                int permits = ownedCount * getMaxBackupCount();
                return s.tryAcquire(permits, REPLICA_SYNC_CHECK_TIMEOUT_SECONDS, TimeUnit.SECONDS) && ok.get();
            } else {
                return false;
            }
        } catch (InterruptedException ignored) {
            return false;
        }
    }

    private int submitSyncReplicaOperations(Address thisAddress, Semaphore s, AtomicBoolean ok,
                                            Callback<Object> callback) {

        int ownedCount = 0;
        ILogger responseLogger = node.getLogger(SyncReplicaVersion.class);
        ResponseHandler responseHandler = ResponseHandlerFactory
                .createErrorLoggingResponseHandler(responseLogger);

        for (InternalPartitionImpl partition : partitions) {
            Address owner = partition.getOwnerOrNull();
            if (thisAddress.equals(owner)) {
                for (int i = 1; i <= getMaxBackupCount(); i++) {
                    if (partition.getReplicaAddress(i) != null) {
                        SyncReplicaVersion op = new SyncReplicaVersion(i, callback);
                        op.setService(this);
                        op.setNodeEngine(nodeEngine);
                        op.setResponseHandler(responseHandler);
                        op.setPartitionId(partition.getPartitionId());
                        nodeEngine.getOperationService().executeOperation(op);
                    } else {
                        ok.set(false);
                        s.release();
                    }
                }
                ownedCount++;
            } else if (owner == null) {
                ok.set(false);
            }
        }
        return ownedCount;
    }

    private boolean shouldWaitMigrationOrBackups(Level level) {
        if (!preCheckShouldWaitMigrationOrBackups()) {
            return false;
        }

        if (checkForActiveMigrations(level)) {
            return true;
        }

        for (InternalPartitionImpl partition : partitions) {
            if (partition.getReplicaAddress(1) == null) {
                if (logger.isLoggable(level)) {
                    logger.log(level, "Should take backup of partitionId=" + partition.getPartitionId());
                }
                return true;
            }
        }
        int replicaSyncProcesses = maxParallelReplications - replicaSyncProcessLock.availablePermits();
        if (replicaSyncProcesses > 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Processing replica sync requests: " + replicaSyncProcesses);
            }
            return true;
        }
        return false;
    }

    private boolean preCheckShouldWaitMigrationOrBackups() {
        if (!initialized) {
            return false;
        }

        if (getMemberGroupsSize() < 2) {
            return false;
        }

        return true;
    }

    private boolean checkForActiveMigrations(Level level) {
        final int activeSize = activeMigrations.size();
        if (activeSize != 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Waiting for active migration tasks: " + activeSize);
            }
            return true;
        }

        int queueSize = migrationQueue.size();
        if (queueSize != 0) {
            if (logger.isLoggable(level)) {
                logger.log(level, "Waiting for cluster migration tasks: " + queueSize);
            }
            return true;
        }
        return false;
    }

    @Override
    public final int getPartitionId(Data key) {
        int hash = key.getPartitionHash();
        if (hash == Integer.MIN_VALUE) {
            return 0;
        } else {
            return Math.abs(hash) % partitionCount;
        }
    }

    @Override
    public final int getPartitionId(Object key) {
        return getPartitionId(nodeEngine.toData(key));
    }

    @Override
    public final int getPartitionCount() {
        return partitionCount;
    }

    public long getPartitionMigrationTimeout() {
        return partitionMigrationTimeout;
    }

    
    
    @Override
    public long[] incrementPartitionReplicaVersions(int partitionId, int backupCount) {
        PartitionReplicaVersions replicaVersion = replicaVersions[partitionId];
        return replicaVersion.incrementAndGet(backupCount);
    }

    
    @Override
    public void updatePartitionReplicaVersions(int partitionId, long[] versions, int replicaIndex) {
        PartitionReplicaVersions partitionVersion = replicaVersions[partitionId];
        if (!partitionVersion.update(versions, replicaIndex)) {
            
            triggerPartitionReplicaSync(partitionId, replicaIndex, 0L);
        }
    }

    
    
    @Override
    public long[] getPartitionReplicaVersions(int partitionId) {
        return replicaVersions[partitionId].get();
    }

    
    @Override
    public void setPartitionReplicaVersions(int partitionId, long[] versions, int replicaOffset) {
        replicaVersions[partitionId].set(versions, replicaOffset);
    }

    @Override
    public void clearPartitionReplicaVersions(int partitionId) {
        replicaVersions[partitionId].clear();
    }

    
    void finalizeReplicaSync(int partitionId, int replicaIndex, long[] versions) {
        PartitionReplicaVersions replicaVersion = replicaVersions[partitionId];
        replicaVersion.clear();
        replicaVersion.set(versions, replicaIndex);
        clearReplicaSyncRequest(partitionId, replicaIndex);
    }

    
    void clearReplicaSyncRequest(int partitionId, int replicaIndex) {
        ReplicaSyncInfo syncInfo = new ReplicaSyncInfo(partitionId, replicaIndex, null);
        ReplicaSyncInfo currentSyncInfo = replicaSyncRequests.get(partitionId);

        replicaSyncScheduler.cancelIfExists(partitionId, syncInfo);

        if (syncInfo.equals(currentSyncInfo)
                && replicaSyncRequests.compareAndSet(partitionId, currentSyncInfo, null)) {

            releaseReplicaSyncPermit();
        } else if (currentSyncInfo != null) {
            if (logger.isFinestEnabled()) {
                logger.finest("Not able to cancel sync! " + syncInfo + " VS Current " + currentSyncInfo);
            }
        }
    }

    boolean tryToAcquireReplicaSyncPermit() {
        return replicaSyncProcessLock.tryAcquire();
    }

    void releaseReplicaSyncPermit() {
        replicaSyncProcessLock.release();
    }

    @Override
    public Map<Address, List<Integer>> getMemberPartitionsMap() {
        final int members = node.getClusterService().getSize();
        Map<Address, List<Integer>> memberPartitions = new HashMap<Address, List<Integer>>(members);
        for (int i = 0; i < partitionCount; i++) {
            Address owner;
            while ((owner = getPartitionOwner(i)) == null) {
                try {
                    Thread.sleep(PARTITION_OWNERSHIP_WAIT_MILLIS);
                } catch (InterruptedException e) {
                    throw new HazelcastException(e);
                }
            }
            List<Integer> ownedPartitions = memberPartitions.get(owner);
            if (ownedPartitions == null) {
                ownedPartitions = new ArrayList<Integer>();
                memberPartitions.put(owner, ownedPartitions);
            }
            ownedPartitions.add(i);
        }
        return memberPartitions;
    }

    @Override
    public List<Integer> getMemberPartitions(Address target) {
        List<Integer> ownedPartitions = new LinkedList<Integer>();
        for (int i = 0; i < partitionCount; i++) {
            final Address owner = getPartitionOwner(i);
            if (target.equals(owner)) {
                ownedPartitions.add(i);
            }
        }
        return ownedPartitions;
    }

    @Override
    public void reset() {
        migrationQueue.clear();
        for (int k = 0; k < replicaSyncRequests.length(); k++) {
            replicaSyncRequests.set(k, null);
        }
        replicaSyncScheduler.cancelAll();
        
        
        replicaSyncProcessLock.drainPermits();
        replicaSyncProcessLock.release(maxParallelReplications);

        lock.lock();
        try {
            initialized = false;
            for (InternalPartitionImpl partition : partitions) {
                partition.reset();
            }
            activeMigrations.clear();
            completedMigrations.clear();
            stateVersion.set(0);
        } finally {
            lock.unlock();
        }
    }

    public void pauseMigration() {
        migrationActive.set(false);
    }

    public void resumeMigration() {
        migrationActive.set(true);
    }

    public boolean isMigrationActive() {
        return migrationActive.get();
    }

    @Override
    public void shutdown(boolean terminate) {
        logger.finest("Shutting down the partition service");
        migrationThread.stopNow();
        reset();
    }

    public long getMigrationQueueSize() {
        return migrationQueue.size();
    }

    public PartitionServiceProxy getPartitionServiceProxy() {
        return proxy;
    }

    private void sendMigrationEvent(final MigrationInfo migrationInfo, final MigrationStatus status) {
        MemberImpl current = getMember(migrationInfo.getSource());
        MemberImpl newOwner = getMember(migrationInfo.getDestination());
        MigrationEvent event = new MigrationEvent(migrationInfo.getPartitionId(), current, newOwner, status);
        EventService eventService = nodeEngine.getEventService();
        Collection<EventRegistration> registrations = eventService.getRegistrations(SERVICE_NAME, MIGRATION_EVENT_TOPIC);
        eventService.publishEvent(SERVICE_NAME, registrations, event, event.getPartitionId());
    }

    @Override
    public String addMigrationListener(MigrationListener listener) {
        if (listener == null) {
            throw new NullPointerException("listener can't be null");
        }

        final MigrationListenerAdapter adapter = new MigrationListenerAdapter(listener);

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration = eventService.registerListener(SERVICE_NAME, MIGRATION_EVENT_TOPIC, adapter);
        return registration.getId();
    }

    @Override
    public boolean removeMigrationListener(String registrationId) {
        if (registrationId == null) {
            throw new NullPointerException("registrationId can't be null");
        }

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, MIGRATION_EVENT_TOPIC, registrationId);
    }

    @Override
    public String addPartitionLostListener(PartitionLostListener listener) {
        if (listener == null) {
            throw new NullPointerException("listener can't be null");
        }

        final PartitionLostListenerAdapter adapter = new PartitionLostListenerAdapter(listener);

        EventService eventService = nodeEngine.getEventService();
        EventRegistration registration = eventService.registerListener(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC, adapter);
        return registration.getId();
    }

    @Override
    public boolean removePartitionLostListener(String registrationId) {
        if (registrationId == null) {
            throw new NullPointerException("registrationId can't be null");
        }

        EventService eventService = nodeEngine.getEventService();
        return eventService.deregisterListener(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC, registrationId);
    }

    @Override
    public void dispatchEvent(PartitionEvent partitionEvent, PartitionEventListener partitionEventListener) {
        partitionEventListener.onEvent(partitionEvent);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder("PartitionManager[" + stateVersion + "] {\n");
        sb.append("\n");
        sb.append("migrationQ: ").append(migrationQueue.size());
        sb.append("\n}");
        return sb.toString();
    }

    public Node getNode() {
        return node;
    }

    @Override
    public boolean isPartitionOwner(int partitionId) {
        InternalPartitionImpl partition = getPartition(partitionId);
        return node.getThisAddress().equals(partition.getOwnerOrNull());
    }

    @Override
    public int getPartitionStateVersion() {
        return stateVersion.get();
    }

    @Override
    public void onPartitionLost(InternalPartitionLostEvent event) {
        final PartitionLostEvent partitionLostEvent = new PartitionLostEvent(event.getPartitionId(), event.getLostReplicaIndex(),
                event.getEventSource());
        final EventService eventService = nodeEngine.getEventService();
        final Collection<EventRegistration> registrations = eventService
                .getRegistrations(SERVICE_NAME, PARTITION_LOST_EVENT_TOPIC);
        eventService.publishEvent(SERVICE_NAME, registrations, partitionLostEvent, event.getPartitionId());
    }

    
    public List<ReplicaSyncInfo> getOngoingReplicaSyncRequests() {
        final int length = replicaSyncRequests.length();
        final List<ReplicaSyncInfo> replicaSyncRequestsList = new ArrayList<ReplicaSyncInfo>(length);
        for (int i = 0; i < length; i++) {
            final ReplicaSyncInfo replicaSyncInfo = replicaSyncRequests.get(i);
            if (replicaSyncInfo != null) {
                replicaSyncRequestsList.add(replicaSyncInfo);
            }
        }

        return replicaSyncRequestsList;
    }

    
    public List<ScheduledEntry<Integer, ReplicaSyncInfo>> getScheduledReplicaSyncRequests() {
        final List<ScheduledEntry<Integer, ReplicaSyncInfo>> entries = new ArrayList<ScheduledEntry<Integer, ReplicaSyncInfo>>();
        for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
            final ScheduledEntry<Integer, ReplicaSyncInfo> entry = replicaSyncScheduler.get(partitionId);
            if (entry != null) {
               entries.add(entry);
            }
        }

        return entries;
    }

    private class SendClusterStateTask implements Runnable {
        @Override
        public void run() {
            if (node.isMaster() && node.isActive()) {
                if (!migrationQueue.isEmpty() && isMigrationActive()) {
                    logger.info("Remaining migration tasks in queue => " + migrationQueue.size());
                }
                publishPartitionRuntimeState();
            }
        }
    }

    private class SyncReplicaVersionTask implements Runnable {
        @Override
        public void run() {
            if (node.isActive() && migrationActive.get()) {
                for (InternalPartitionImpl partition : partitions) {
                    if (partition.isLocal()) {
                        for (int index = 1; index < InternalPartition.MAX_REPLICA_COUNT; index++) {
                            if (partition.getReplicaAddress(index) != null) {
                                SyncReplicaVersion op = new SyncReplicaVersion(index, null);
                                op.setService(InternalPartitionServiceImpl.this);
                                op.setNodeEngine(nodeEngine);
                                op.setResponseHandler(ResponseHandlerFactory
                                        .createErrorLoggingResponseHandler(node.getLogger(SyncReplicaVersion.class)));
                                op.setPartitionId(partition.getPartitionId());
                                nodeEngine.getOperationService().executeOperation(op);
                            }
                        }
                    }
                }
            }
        }
    }

    private class RepartitioningTask implements Runnable {
        @Override
        public void run() {
            if (node.isMaster() && node.isActive()) {
                lock.lock();
                try {
                    if (!initialized) {
                        return;
                    }
                    if (!isMigrationAllowed()) {
                        return;
                    }

                    migrationQueue.clear();
                    PartitionStateGenerator psg = partitionStateGenerator;
                    Collection<MemberImpl> members = node.getClusterService().getMemberList();
                    Collection<MemberGroup> memberGroups = memberGroupFactory.createMemberGroups(members);
                    Address[][] newState = psg.reArrange(memberGroups, partitions);

                    if (!isMigrationAllowed()) {
                        return;
                    }

                    int migrationCount = 0;
                    int lostCount = 0;
                    lastRepartitionTime.set(Clock.currentTimeMillis());
                    for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
                        Address[] replicas = newState[partitionId];
                        InternalPartitionImpl currentPartition = partitions[partitionId];
                        Address currentOwner = currentPartition.getOwnerOrNull();
                        Address newOwner = replicas[0];

                        if (currentOwner == null) {
                            
                            lostCount++;
                            assignNewPartitionOwner(partitionId, replicas, currentPartition, newOwner);
                        } else if (newOwner != null && !currentOwner.equals(newOwner)) {
                            if (logger.isFinestEnabled()) {
                                logger.finest("PartitionToMigrate partitionId=" + partitionId
                                        + " replicas=" + Arrays.toString(replicas) + " currentOwner="
                                        + currentOwner + " newOwner=" + newOwner);
                            }

                            migrationCount++;
                            migratePartitionToNewOwner(partitionId, replicas, currentOwner, newOwner);
                        } else {
                            currentPartition.setReplicaAddresses(replicas);
                        }
                    }
                    syncPartitionRuntimeState(members);
                    logMigrationStatistics(migrationCount, lostCount);
                } finally {
                    lock.unlock();
                }
            }
        }

        private void logMigrationStatistics(int migrationCount, int lostCount) {
            if (lostCount > 0) {
                logger.warning("Assigning new owners for " + lostCount + " LOST partitions!");
            }

            if (migrationCount > 0) {
                logger.info("Re-partitioning cluster data... Migration queue size: " + migrationCount);
            } else {
                logger.info("Partition balance is ok, no need to re-partition cluster data... ");
            }
        }

        private void migratePartitionToNewOwner(int partitionId, Address[] replicas, Address currentOwner, Address newOwner) {
            MigrationInfo info = new MigrationInfo(partitionId, currentOwner, newOwner);
            MigrateTask migrateTask = new MigrateTask(info, replicas);
            boolean offered = migrationQueue.offer(migrateTask);
            if (!offered) {
                logger.severe("Failed to offer: " + migrateTask);
            }
        }

        private void assignNewPartitionOwner(int partitionId, Address[] replicas, InternalPartitionImpl currentPartition,
                                             Address newOwner) {
            currentPartition.setReplicaAddresses(replicas);
            MigrationInfo migrationInfo = new MigrationInfo(partitionId, null, newOwner);
            sendMigrationEvent(migrationInfo, MigrationStatus.STARTED);
            sendMigrationEvent(migrationInfo, MigrationStatus.COMPLETED);
        }

        private boolean isMigrationAllowed() {
            if (isMigrationActive()) {
                return true;
            }
            migrationQueue.add(this);
            return false;
        }
    }

    private class MigrateTask implements Runnable {
        final MigrationInfo migrationInfo;
        final Address[] addresses;

        public MigrateTask(MigrationInfo migrationInfo, Address[] addresses) {
            this.migrationInfo = migrationInfo;
            this.addresses = addresses;
            final MemberImpl masterMember = getMasterMember();
            if (masterMember != null) {
                migrationInfo.setMasterUuid(masterMember.getUuid());
                migrationInfo.setMaster(masterMember.getAddress());
            }
        }

        @Override
        public void run() {
            if (!node.isActive() || !node.isMaster()) {
                return;
            }
            final MigrationRequestOperation migrationRequestOp = new MigrationRequestOperation(migrationInfo);
            try {
                MigrationInfo info = migrationInfo;
                InternalPartitionImpl partition = partitions[info.getPartitionId()];
                Address owner = partition.getOwnerOrNull();
                if (owner == null) {
                    logger.severe("ERROR: partition owner is not set! -> partitionId=" + info.getPartitionId()
                            + " , " + partition + " -VS- " + info);
                    return;
                }
                if (!owner.equals(info.getSource())) {
                    logger.severe("ERROR: partition owner is not the source of migration! -> partitionId="
                            + info.getPartitionId() + " , " + partition + " -VS- " + info + " found owner=" + owner);
                    return;
                }
                sendMigrationEvent(migrationInfo, MigrationStatus.STARTED);
                Boolean result;
                MemberImpl fromMember = getMember(migrationInfo.getSource());
                if (logger.isFinestEnabled()) {
                    logger.finest("Starting Migration: " + migrationInfo);
                }
                if (fromMember == null) {
                    
                    logger.warning("Partition is lost! Assign new owner and exit... partitionId=" + info.getPartitionId());
                    result = Boolean.TRUE;
                } else {
                    result = executeMigrateOperation(migrationRequestOp, fromMember);
                }
                processMigrationResult(result);
            } catch (Throwable t) {
                final Level level = migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Error [" + t.getClass() + ": " + t.getMessage() + "] while executing " + migrationRequestOp);
                logger.finest(t);
                migrationOperationFailed();
            }
        }

        private void processMigrationResult(Boolean result) {
            if (Boolean.TRUE.equals(result)) {
                if (logger.isFinestEnabled()) {
                    logger.finest("Finished Migration: " + migrationInfo);
                }
                migrationOperationSucceeded();
            } else {
                final Level level = migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Migration failed: " + migrationInfo);
                migrationOperationFailed();
            }
        }

        private Boolean executeMigrateOperation(MigrationRequestOperation migrationRequestOp, MemberImpl fromMember) {
            Future future = nodeEngine.getOperationService().createInvocationBuilder(SERVICE_NAME, migrationRequestOp,
                    migrationInfo.getSource())
                    .setCallTimeout(partitionMigrationTimeout)
                    .setTryPauseMillis(DEFAULT_PAUSE_MILLIS).invoke();

            try {
                Object response = future.get();
                return (Boolean) nodeEngine.toObject(response);
            } catch (Throwable e) {
                final Level level = node.isActive() && migrationInfo.isValid() ? Level.WARNING : Level.FINEST;
                logger.log(level, "Failed migration from " + fromMember + " for " + migrationRequestOp.getMigrationInfo(), e);
            }
            return Boolean.FALSE;
        }

        private void migrationOperationFailed() {
            lock.lock();
            try {
                addCompletedMigration(migrationInfo);
                finalizeActiveMigration(migrationInfo);
                publishPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
            sendMigrationEvent(migrationInfo, MigrationStatus.FAILED);

            
            migrationQueue.add(new RepartitioningTask());
        }

        private void migrationOperationSucceeded() {
            lock.lock();
            try {
                final int partitionId = migrationInfo.getPartitionId();
                InternalPartitionImpl partition = partitions[partitionId];
                partition.setReplicaAddresses(addresses);
                addCompletedMigration(migrationInfo);
                finalizeActiveMigration(migrationInfo);
                syncPartitionRuntimeState();
            } finally {
                lock.unlock();
            }
            sendMigrationEvent(migrationInfo, MigrationStatus.COMPLETED);
        }

        @Override
        public String toString() {
            return getClass().getSimpleName() + "{" + "migrationInfo=" + migrationInfo + '}';
        }
    }

    private class MigrationThread extends Thread implements Runnable {
        private final long sleepTime = Math.max(250L, partitionMigrationInterval);
        private volatile boolean migrating;

        MigrationThread(Node node) {
            super(node.getHazelcastThreadGroup().getInternalThreadGroup(),
                    node.getHazelcastThreadGroup().getThreadNamePrefix("migration"));
        }

        @Override
        public void run() {
            try {
                while (!isInterrupted()) {
                    doRun();
                }
            } catch (InterruptedException e) {
                if (logger.isFinestEnabled()) {
                    logger.finest("MigrationThread is interrupted: " + e.getMessage());
                }
            } catch (OutOfMemoryError e) {
                OutOfMemoryErrorDispatcher.onOutOfMemory(e);
            } finally {
                migrationQueue.clear();
            }
        }

        private void doRun() throws InterruptedException {
            for (; ; ) {
                if (!isMigrationActive()) {
                    break;
                }
                Runnable r = migrationQueue.poll(1, TimeUnit.SECONDS);
                if (r == null) {
                    break;
                }

                processTask(r);
                if (partitionMigrationInterval > 0) {
                    Thread.sleep(partitionMigrationInterval);
                }
            }
            boolean hasNoTasks = migrationQueue.isEmpty();
            if (hasNoTasks) {
                if (migrating) {
                    migrating = false;
                    logger.info("All migration tasks have been completed, queues are empty.");
                }
                evictCompletedMigrations();
                Thread.sleep(sleepTime);
            } else if (!isMigrationActive()) {
                Thread.sleep(sleepTime);
            }
        }

        boolean processTask(Runnable r) {
            if (r == null || isInterrupted()) {
                return false;
            }
            migrating = (r instanceof MigrateTask);
            try {
                r.run();
            } catch (Throwable t) {
                logger.warning(t);
            }
            return true;
        }

        void stopNow() {
            migrationQueue.clear();
            interrupt();
        }

        boolean isMigrating() {
            return migrating;
        }
    }

    private static final class LocalPartitionListener implements PartitionListener {
        final Address thisAddress;
        final InternalPartitionServiceImpl partitionService;

        private LocalPartitionListener(InternalPartitionServiceImpl partitionService, Address thisAddress) {
            this.thisAddress = thisAddress;
            this.partitionService = partitionService;
        }

        @Override
        public void replicaChanged(PartitionReplicaChangeEvent event) {
            final int partitionId = event.getPartitionId();
            final int replicaIndex = event.getReplicaIndex();
            final Address newAddress = event.getNewAddress();
            final Address oldAddress = event.getOldAddress();
            final PartitionReplicaChangeReason reason = event.getReason();

            final boolean initialAssignment = event.getOldAddress() == null;

            if (replicaIndex > 0) {
                
                if (thisAddress.equals(oldAddress)) {
                    clearPartition(partitionId, replicaIndex);
                } else if (thisAddress.equals(newAddress)) {
                    synchronizePartition(partitionId, replicaIndex, reason, initialAssignment);
                }
            } else {
                if (!initialAssignment && thisAddress.equals(newAddress)) {
                    
                    
                    
                    promoteFromBackups(partitionId, reason, oldAddress);
                }
                partitionService.cancelReplicaSync(partitionId);
            }

            Node node = partitionService.node;
            if (replicaIndex == 0 && newAddress == null && node.isActive() && node.joined()) {
                logOwnerOfPartitionIsRemoved(event);
            }
            if (node.isMaster()) {
                partitionService.stateVersion.incrementAndGet();
            }
        }

        private void clearPartition(final int partitionId, final int oldReplicaIndex) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            ClearReplicaOperation op = new ClearReplicaOperation(oldReplicaIndex);
            op.setPartitionId(partitionId).setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void synchronizePartition(int partitionId, int replicaIndex,
                                          PartitionReplicaChangeReason reason, boolean initialAssignment) {
            
            if (partitionService.initialized) {
                long delayMillis = 0L;
                if (replicaIndex > 1) {
                    
                    
                    
                    delayMillis = (long) (REPLICA_SYNC_RETRY_DELAY + (Math.random() * DEFAULT_REPLICA_SYNC_DELAY));
                }

                resetReplicaVersion(partitionId, replicaIndex, reason, initialAssignment);
                partitionService.triggerPartitionReplicaSync(partitionId, replicaIndex, delayMillis);
            }
        }

        private void resetReplicaVersion(int partitionId, int replicaIndex,
                                         PartitionReplicaChangeReason reason, boolean initialAssignment) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            ResetReplicaVersionOperation op = new ResetReplicaVersionOperation(reason, initialAssignment);
            op.setPartitionId(partitionId).setReplicaIndex(replicaIndex)
              .setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void promoteFromBackups(int partitionId, PartitionReplicaChangeReason reason, Address oldAddress) {
            NodeEngine nodeEngine = partitionService.nodeEngine;
            PromoteFromBackupOperation op = new PromoteFromBackupOperation(reason, oldAddress);
            op.setPartitionId(partitionId).setNodeEngine(nodeEngine).setService(partitionService);
            nodeEngine.getOperationService().executeOperation(op);
        }

        private void logOwnerOfPartitionIsRemoved(PartitionReplicaChangeEvent event) {
            String warning = "Owner of partition is being removed! "
                    + "Possible data loss for partitionId=" + event.getPartitionId() + " , " + event;
            partitionService.logger.warning(warning);
        }
    }

    private static class ReplicaSyncEntryProcessor implements ScheduledEntryProcessor<Integer, ReplicaSyncInfo> {

        final InternalPartitionServiceImpl partitionService;

        ReplicaSyncEntryProcessor(InternalPartitionServiceImpl partitionService) {
            this.partitionService = partitionService;
        }

        @Override
        public void process(EntryTaskScheduler<Integer, ReplicaSyncInfo> scheduler,
                            Collection<ScheduledEntry<Integer, ReplicaSyncInfo>> entries) {

            for (ScheduledEntry<Integer, ReplicaSyncInfo> entry : entries) {
                ReplicaSyncInfo syncInfo = entry.getValue();
                int partitionId = syncInfo.partitionId;
                if (partitionService.replicaSyncRequests.compareAndSet(partitionId, syncInfo, null)) {
                    partitionService.releaseReplicaSyncPermit();
                }

                InternalPartitionImpl partition = partitionService.getPartitionImpl(partitionId);
                int currentReplicaIndex = partition.getReplicaIndex(partitionService.node.getThisAddress());
                if (currentReplicaIndex > 0) {
                    partitionService.triggerPartitionReplicaSync(partitionId, currentReplicaIndex, 0L);
                }
            }
        }
    }
}

<code block>


package com.hazelcast.partition.impl;

import com.hazelcast.core.HazelcastException;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberLeftException;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.partition.MigrationEndpoint;
import com.hazelcast.partition.MigrationInfo;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.MigrationAwareService;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.PartitionMigrationEvent;
import com.hazelcast.spi.PartitionReplicationEvent;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.impl.servicemanager.ServiceInfo;
import com.hazelcast.spi.exception.RetryableHazelcastException;
import com.hazelcast.spi.exception.TargetNotMemberException;
import com.hazelcast.spi.impl.NodeEngineImpl;

import java.io.IOException;
import java.util.Collection;
import java.util.LinkedList;
import java.util.concurrent.ExecutionException;
import java.util.logging.Level;

public final class MigrationRequestOperation extends BaseMigrationOperation {

    private static final int TRY_PAUSE_MILLIS = 1000;

    private boolean returnResponse = true;

    public MigrationRequestOperation() {
    }

    public MigrationRequestOperation(MigrationInfo migrationInfo) {
        super(migrationInfo);
    }

    public void run() {
        NodeEngine nodeEngine = getNodeEngine();
        verifyGoodMaster(nodeEngine);

        Address source = migrationInfo.getSource();
        Address destination = migrationInfo.getDestination();
        verifyExistingTarget(nodeEngine, destination);

        if (destination.equals(source)) {
            getLogger().warning("Source and destination addresses are the same! => " + toString());
            success = false;
            return;
        }

        verifyNotThisNode(nodeEngine, source);

        InternalPartitionServiceImpl partitionService = getService();
        InternalPartition partition = partitionService.getPartition(migrationInfo.getPartitionId());
        Address owner = partition.getOwnerOrNull();
        verifyOwnerExists(owner);

        if (!migrationInfo.startProcessing()) {
            getLogger().warning("Migration is cancelled -> " + migrationInfo);
            success = false;
            return;
        }

        try {
            verifyOwner(source, partition, owner);
            partitionService.addActiveMigration(migrationInfo);
            Collection<Operation> tasks = prepareMigrationTasks();
            if (tasks.size() > 0) {
                long[] replicaVersions = partitionService.getPartitionReplicaVersions(migrationInfo.getPartitionId());
                invokeMigrationOperation(destination, replicaVersions, tasks);
                returnResponse = false;
            } else {
                success = true;
            }
        } catch (Throwable e) {
            logThrowable(e);
            success = false;
        } finally {
            migrationInfo.doneProcessing();
        }
    }

    private void logThrowable(Throwable t) {
        Throwable throwableToLog = t;
        if (throwableToLog instanceof ExecutionException) {
            throwableToLog = throwableToLog.getCause() != null ? throwableToLog.getCause() : throwableToLog;
        }
        Level level = getLogLevel(throwableToLog);
        getLogger().log(level, throwableToLog.getMessage(), throwableToLog);
    }

    private Level getLogLevel(Throwable e) {
        return (e instanceof MemberLeftException || e instanceof InterruptedException)
                || !getNodeEngine().isActive() ? Level.INFO : Level.WARNING;
    }

    private void verifyNotThisNode(NodeEngine nodeEngine, Address source) {
        if (source == null || !source.equals(nodeEngine.getThisAddress())) {
            throw new RetryableHazelcastException("Source of migration is not this node! => " + toString());
        }
    }

    private void verifyOwnerExists(Address owner) {
        if (owner == null) {
            throw new RetryableHazelcastException("Cannot migrate at the moment! Owner of the partition is null => "
                    + migrationInfo);
        }
    }

    private void verifyOwner(Address source, InternalPartition partition, Address owner) {
        if (!source.equals(owner)) {
            throw new HazelcastException("Cannot migrate! This node is not owner of the partition => "
                    + migrationInfo + " -> partitionId=" + partition.getPartitionId() + " , " + partition);
        }
    }

    private void invokeMigrationOperation(Address destination, long[] replicaVersions, Collection<Operation> tasks)
            throws IOException {

        MigrationOperation operation = new MigrationOperation(migrationInfo, replicaVersions, tasks);

        NodeEngine nodeEngine = getNodeEngine();
        InternalPartitionServiceImpl partitionService = getService();

        nodeEngine.getOperationService()
                .createInvocationBuilder(InternalPartitionService.SERVICE_NAME, operation, destination)
                .setCallback(new MigrationCallback(migrationInfo, getResponseHandler()))
                .setResultDeserialized(true)
                .setCallTimeout(partitionService.getPartitionMigrationTimeout())
                .setTryPauseMillis(TRY_PAUSE_MILLIS)
                .setReplicaIndex(getReplicaIndex())
                .invoke();
    }

    private void verifyGoodMaster(NodeEngine nodeEngine) {
        Address masterAddress = nodeEngine.getMasterAddress();
        if (!masterAddress.equals(migrationInfo.getMaster())) {
            throw new RetryableHazelcastException("Migration initiator is not master node! => " + toString());
        }
        if (!masterAddress.equals(getCallerAddress())) {
            throw new RetryableHazelcastException("Caller is not master node! => " + toString());
        }
    }

    private void verifyExistingTarget(NodeEngine nodeEngine, Address destination) {
        Member target = nodeEngine.getClusterService().getMember(destination);
        if (target == null) {
            throw new TargetNotMemberException("Destination of migration could not be found! => " + toString());
        }
    }

    @Override
    public ExceptionAction onException(Throwable throwable) {
        if (throwable instanceof TargetNotMemberException) {
            return ExceptionAction.THROW_EXCEPTION;
        }
        return super.onException(throwable);
    }

    @Override
    public Object getResponse() {
        return success;
    }

    @Override
    public boolean returnsResponse() {
        return returnResponse;
    }

    private Collection<Operation> prepareMigrationTasks() {
        NodeEngineImpl nodeEngine = (NodeEngineImpl) getNodeEngine();
        PartitionReplicationEvent replicationEvent = new PartitionReplicationEvent(migrationInfo.getPartitionId(), 0);
        PartitionMigrationEvent migrationEvent
                = new PartitionMigrationEvent(MigrationEndpoint.SOURCE, migrationInfo.getPartitionId());

        Collection<Operation> tasks = new LinkedList<Operation>();
        for (ServiceInfo serviceInfo : nodeEngine.getServiceInfos(MigrationAwareService.class)) {
            MigrationAwareService service = (MigrationAwareService) serviceInfo.getService();
            service.beforeMigration(migrationEvent);
            Operation op = service.prepareReplicationOperation(replicationEvent);
            if (op != null) {
                op.setServiceName(serviceInfo.getName());
                tasks.add(op);
            }
        }
        return tasks;
    }

    private static final class MigrationCallback implements Callback<Object> {

        final MigrationInfo migrationInfo;
        final ResponseHandler responseHandler;

        private MigrationCallback(MigrationInfo migrationInfo, ResponseHandler responseHandler) {
            this.migrationInfo = migrationInfo;
            this.responseHandler = responseHandler;
        }

        @Override
        public void notify(Object result) {
            migrationInfo.doneProcessing();
            responseHandler.sendResponse(result);
        }
    }
}

<code block>


package com.hazelcast.cache.impl.client;

import com.hazelcast.cache.impl.CachePortableHook;
import com.hazelcast.cache.impl.CacheService;
import com.hazelcast.cache.impl.operation.CacheCreateConfigOperation;
import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.impl.client.ClientRequest;
import com.hazelcast.config.CacheConfig;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.PortableReader;
import com.hazelcast.nio.serialization.PortableWriter;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;

import java.io.IOException;
import java.security.Permission;


public class CacheCreateConfigRequest
        extends ClientRequest {

    private static final int TRY_COUNT = 100;

    private CacheConfig cacheConfig;
    private boolean createAlsoOnOthers = true;
    private boolean ignoreLocal;
    private int partitionId;

    public CacheCreateConfigRequest() {
    }

    public CacheCreateConfigRequest(CacheConfig cacheConfig, boolean createAlsoOnOthers, boolean ignoreLocal,
                                    int partitionId) {
        this.cacheConfig = cacheConfig;
        this.createAlsoOnOthers = createAlsoOnOthers;
        this.ignoreLocal = ignoreLocal;
        this.partitionId = partitionId;
    }

    @Override
    public final void process()
            throws Exception {
        final ClientEndpoint endpoint = getEndpoint();
        final Operation op = prepareOperation();
        op.setCallerUuid(endpoint.getUuid());
        final InvocationBuilder builder = operationService.createInvocationBuilder(getServiceName(), op, partitionId);
        builder.setTryCount(TRY_COUNT).setResultDeserialized(false).setCallback(new Callback<Object>() {
            public void notify(Object object) {
                endpoint.sendResponse(object, getCallId());
            }
        });
        builder.invoke();
    }

    protected Operation prepareOperation() {
        return new CacheCreateConfigOperation(cacheConfig, createAlsoOnOthers, ignoreLocal);
    }

    @Override
    public final int getFactoryId() {
        return CachePortableHook.F_ID;
    }

    @Override
    public int getClassId() {
        return CachePortableHook.CREATE_CONFIG;
    }

    @Override
    public String getServiceName() {
        return CacheService.SERVICE_NAME;
    }

    @Override
    public void write(PortableWriter writer)
            throws IOException {
        writer.writeBoolean("o", createAlsoOnOthers);
        writer.writeBoolean("l", ignoreLocal);
        writer.writeInt("p", partitionId);
        final ObjectDataOutput out = writer.getRawDataOutput();
        out.writeObject(cacheConfig);
    }

    @Override
    public void read(PortableReader reader)
            throws IOException {
        createAlsoOnOthers = reader.readBoolean("o");
        ignoreLocal = reader.readBoolean("l");
        partitionId = reader.readInt("p");
        final ObjectDataInput in = reader.getRawDataInput();
        cacheConfig = in.readObject();
    }

    @Override
    public Permission getRequiredPermission() {
        return null;
    }

}

<code block>


package com.hazelcast.cache.impl.client;

import com.hazelcast.cache.impl.CachePortableHook;
import com.hazelcast.cache.impl.CacheService;
import com.hazelcast.cache.impl.operation.CacheDestroyOperation;
import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.impl.client.ClientRequest;
import com.hazelcast.nio.serialization.PortableReader;
import com.hazelcast.nio.serialization.PortableWriter;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;

import java.io.IOException;
import java.security.Permission;


public class CacheDestroyRequest
        extends ClientRequest {

    private static final int TRY_COUNT = 100;

    private String name;
    private int partitionId;

    public CacheDestroyRequest() {
    }

    public CacheDestroyRequest(String name, int partitionId) {
        this.name = name;
        this.partitionId = partitionId;
    }

    @Override
    public final void process()
            throws Exception {
        final ClientEndpoint endpoint = getEndpoint();
        final Operation op = prepareOperation();
        op.setCallerUuid(endpoint.getUuid());
        final InvocationBuilder builder = operationService.createInvocationBuilder(getServiceName(), op, partitionId);
        builder.setTryCount(TRY_COUNT).setResultDeserialized(false).setCallback(new Callback<Object>() {
            public void notify(Object object) {
                endpoint.sendResponse(object, getCallId());
            }
        });
        builder.invoke();
    }

    protected Operation prepareOperation() {
        return new CacheDestroyOperation(name);
    }

    @Override
    public final int getFactoryId() {
        return CachePortableHook.F_ID;
    }

    @Override
    public int getClassId() {
        return CachePortableHook.DESTROY_CACHE;
    }

    @Override
    public String getServiceName() {
        return CacheService.SERVICE_NAME;
    }

    @Override
    public void write(PortableWriter writer)
            throws IOException {
        writer.writeUTF("n", name);
        writer.writeInt("p", partitionId);
    }

    @Override
    public void read(PortableReader reader)
            throws IOException {
        name = reader.readUTF("n");
        partitionId = reader.readInt("p");
    }

    @Override
    public Permission getRequiredPermission() {
        return null;
    }

}

<code block>


package com.hazelcast.cache.impl.operation;

import com.hazelcast.cache.impl.AbstractCacheService;
import com.hazelcast.cache.impl.CacheDataSerializerHook;
import com.hazelcast.cache.impl.CacheService;
import com.hazelcast.config.CacheConfig;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.impl.AbstractNamedOperation;

import java.io.IOException;
import java.util.Collection;
import java.util.concurrent.atomic.AtomicInteger;


public class CacheCreateConfigOperation
        extends AbstractNamedOperation
        implements IdentifiedDataSerializable {

    private CacheConfig config;
    private boolean createAlsoOnOthers = true;
    private boolean ignoreLocal;

    private boolean returnsResponse = true;
    private transient Object response;

    public CacheCreateConfigOperation() {
    }

    public CacheCreateConfigOperation(CacheConfig config) {
        this(config, true);
    }

    public CacheCreateConfigOperation(CacheConfig config, boolean createAlsoOnOthers) {
        this(config, createAlsoOnOthers, false);
    }

    public CacheCreateConfigOperation(CacheConfig config, boolean createAlsoOnOthers, boolean ignoreLocal) {
        super(config.getNameWithPrefix());
        this.config = config;
        this.createAlsoOnOthers = createAlsoOnOthers;
        this.ignoreLocal = ignoreLocal;
    }

    @Override
    public String getServiceName() {
        return CacheService.SERVICE_NAME;
    }

    @Override
    public void run() throws Exception {
        AbstractCacheService service = getService();
        if (!ignoreLocal) {
            response = service.createCacheConfigIfAbsent(config);
        }
        if (createAlsoOnOthers) {
            NodeEngine nodeEngine = getNodeEngine();
            Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
            int remoteNodeCount = members.size() - 1;

            if (remoteNodeCount > 0) {
                postponeReturnResponse();

                Callback<Object> callback = new CacheConfigCreateCallback(getResponseHandler(), remoteNodeCount);
                OperationService operationService = nodeEngine.getOperationService();
                for (MemberImpl member : members) {
                    if (!member.localMember()) {
                        CacheCreateConfigOperation op = new CacheCreateConfigOperation(config, false);
                        operationService
                                .createInvocationBuilder(AbstractCacheService.SERVICE_NAME, op, member.getAddress())
                                .setCallback(callback)
                                .invoke();
                    }
                }
            }
        }
    }

    private void postponeReturnResponse() {
        
        
        returnsResponse = false;
    }

    private static class CacheConfigCreateCallback implements Callback<Object> {

        final ResponseHandler responseHandler;
        final AtomicInteger counter;

        public CacheConfigCreateCallback(ResponseHandler responseHandler, int count) {
            this.responseHandler = responseHandler;
            counter = new AtomicInteger(count);
        }

        @Override
        public void notify(Object object) {
            if (counter.decrementAndGet() == 0) {
                responseHandler.sendResponse(null);
            }
        }
    }

    @Override
    public Object getResponse() {
        return response;
    }

    @Override
    public boolean returnsResponse() {
        return returnsResponse;
    }

    @Override
    protected void writeInternal(ObjectDataOutput out)
            throws IOException {
        super.writeInternal(out);
        out.writeObject(config);
        out.writeBoolean(createAlsoOnOthers);
        out.writeBoolean(ignoreLocal);
    }

    @Override
    protected void readInternal(ObjectDataInput in)
            throws IOException {
        super.readInternal(in);
        config = in.readObject();
        createAlsoOnOthers = in.readBoolean();
        ignoreLocal = in.readBoolean();
    }

    @Override
    public int getId() {
        return CacheDataSerializerHook.CREATE_CONFIG;
    }

    @Override
    public int getFactoryId() {
        return CacheDataSerializerHook.F_ID;
    }

}

<code block>


package com.hazelcast.spi;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.spi.impl.NodeEngineImpl;


public abstract class InvocationBuilder {

    
    public static final long DEFAULT_CALL_TIMEOUT = -1L;

    
    public static final int DEFAULT_REPLICA_INDEX = 0;

    
    public static final int DEFAULT_TRY_COUNT = 250;

    
    public static final long DEFAULT_TRY_PAUSE_MILLIS = 500;

    
    public static final boolean DEFAULT_DESERIALIZE_RESULT = true;

    protected final NodeEngineImpl nodeEngine;
    protected final String serviceName;
    protected final Operation op;
    protected final int partitionId;
    protected final Address target;
    protected Callback<Object> callback;
    protected ExecutionCallback<Object> executionCallback;

    protected long callTimeout = DEFAULT_CALL_TIMEOUT;
    protected int replicaIndex;
    protected int tryCount = DEFAULT_TRY_COUNT;
    protected long tryPauseMillis = DEFAULT_TRY_PAUSE_MILLIS;
    protected boolean resultDeserialized = DEFAULT_DESERIALIZE_RESULT;

    
    public InvocationBuilder(NodeEngineImpl nodeEngine, String serviceName, Operation op,
                             int partitionId, Address target) {
        this.nodeEngine = nodeEngine;
        this.serviceName = serviceName;
        this.op = op;
        this.partitionId = partitionId;
        this.target = target;
    }

     
    public InvocationBuilder setReplicaIndex(int replicaIndex) {
        if (replicaIndex < 0 || replicaIndex >= InternalPartition.MAX_REPLICA_COUNT) {
            throw new IllegalArgumentException("Replica index is out of range [0-"
                    + (InternalPartition.MAX_REPLICA_COUNT - 1) + "]");
        }
        this.replicaIndex = replicaIndex;
        return this;
    }

    
    public boolean isResultDeserialized() {
        return resultDeserialized;
    }

    
    public InvocationBuilder setResultDeserialized(boolean resultDeserialized) {
        this.resultDeserialized = resultDeserialized;
        return this;
    }

    
    public InvocationBuilder setTryCount(int tryCount) {
        this.tryCount = tryCount;
        return this;
    }

    
    public InvocationBuilder setTryPauseMillis(long tryPauseMillis) {
        this.tryPauseMillis = tryPauseMillis;
        return this;
    }

    public InvocationBuilder setCallTimeout(long callTimeout) {
        this.callTimeout = callTimeout;
        return this;
    }

    
    public String getServiceName() {
        return serviceName;
    }

    
    public Operation getOp() {
        return op;
    }

    

    public int getReplicaIndex() {
        return replicaIndex;
    }

    
    public int getTryCount() {
        return tryCount;
    }

    
    public long getTryPauseMillis() {
        return tryPauseMillis;
    }

    
    public Address getTarget() {
        return target;
    }

    
    public int getPartitionId() {
        return partitionId;
    }

    public long getCallTimeout() {
        return callTimeout;
    }

    
    @Deprecated
    public Callback getCallback() {
        return callback;
    }

    
    @Deprecated
    public InvocationBuilder setCallback(Callback<Object> callback) {
        if (executionCallback != null) {
            throw new IllegalStateException("Can't set the callback if executionCallback already is set");
        }
        this.callback = callback;
        return this;
    }

    
    public ExecutionCallback<Object> getExecutionCallback() {
        return executionCallback;
    }

    
    public InvocationBuilder setExecutionCallback(ExecutionCallback<Object> executionCallback) {
        if (callback != null) {
            throw new IllegalStateException("Can't set the executionCallback if callback already is set");
        }
        this.executionCallback = executionCallback;
        return this;
    }

    public abstract <E> InternalCompletableFuture<E> invoke();
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.MemberLeftException;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.NodeEngineImpl;


public final class TargetInvocation extends Invocation {

    private final Address target;

    public TargetInvocation(NodeEngineImpl nodeEngine, String serviceName, Operation op,
                            Address target, int tryCount, long tryPauseMillis, long callTimeout,
                            Object callback, boolean resultDeserialized) {
        super(nodeEngine, serviceName, op, op.getPartitionId(), op.getReplicaIndex(),
                tryCount, tryPauseMillis, callTimeout, callback, resultDeserialized);
        this.target = target;
    }

    @Override
    public Address getTarget() {
        return target;
    }

    @Override
    ExceptionAction onException(Throwable t) {
        return t instanceof MemberLeftException ? ExceptionAction.THROW_EXCEPTION : op.onException(t);
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.impl.operationservice.impl.responses.Response;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;

import java.util.concurrent.ExecutionException;
import java.util.concurrent.Executor;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;

import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.INTERRUPTED_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.NULL_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.TIMEOUT_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.WAIT_RESPONSE;
import static com.hazelcast.util.ExceptionUtil.fixRemoteStackTrace;
import static com.hazelcast.util.Preconditions.isNotNull;
import static java.lang.Math.min;


final class InvocationFuture<E> implements InternalCompletableFuture<E> {

    private static final int MAX_CALL_TIMEOUT_EXTENSION = 60 * 1000;

    private static final AtomicReferenceFieldUpdater<InvocationFuture, Object> RESPONSE
            = AtomicReferenceFieldUpdater.newUpdater(InvocationFuture.class, Object.class, "response");
    private static final AtomicIntegerFieldUpdater<InvocationFuture> WAITER_COUNT
            = AtomicIntegerFieldUpdater.newUpdater(InvocationFuture.class, "waiterCount");

    volatile boolean interrupted;
    volatile Object response;

    
    
    private volatile int waiterCount;
    private final OperationServiceImpl operationService;
    private final Invocation invocation;
    private volatile ExecutionCallbackNode<E> callbackHead;

    InvocationFuture(OperationServiceImpl operationService, Invocation invocation, Object callback) {
        this.invocation = invocation;
        this.operationService = operationService;

        if (callback != null) {
            ExecutionCallback executionCallback;
            if (callback instanceof ExecutionCallback) {
                executionCallback = (ExecutionCallback) callback;
            } else {
                executionCallback = new ExecutorCallbackAdapter<E>((Callback) callback);
            }

            callbackHead = new ExecutionCallbackNode<E>(executionCallback, operationService.asyncExecutor, null);
        }
    }

    static long decrementTimeout(long timeout, long diff) {
        if (timeout == Long.MAX_VALUE) {
            return timeout;
        }

        return timeout - diff;
    }

    @Override
    public void andThen(ExecutionCallback<E> callback, Executor executor) {
        isNotNull(callback, "callback");
        isNotNull(executor, "executor");

        synchronized (this) {
            if (responseAvailable(response)) {
                runAsynchronous(callback, executor);
                return;
            }

            this.callbackHead = new ExecutionCallbackNode<E>(callback, executor, callbackHead);
        }
    }

    private boolean responseAvailable(Object response) {
        if (response == null) {
            return false;
        }

        if (response == InternalResponse.WAIT_RESPONSE) {
            return false;
        }

        return true;
    }

    @Override
    public void andThen(ExecutionCallback<E> callback) {
        andThen(callback, operationService.asyncExecutor);
    }

    private void runAsynchronous(final ExecutionCallback<E> callback, Executor executor) {
        try {
            executor.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        Object resp = resolveApplicationResponse(response);

                        if (resp == null || !(resp instanceof Throwable)) {
                            callback.onResponse((E) resp);
                        } else {
                            callback.onFailure((Throwable) resp);
                        }
                    } catch (Throwable cause) {
                        invocation.logger.severe("Failed asynchronous execution of execution callback: " + callback
                                + "for call " + invocation, cause);
                    }
                }
            });
        } catch (RejectedExecutionException e) {
            invocation.logger.warning("Execution of callback: " + callback + " is rejected!", e);
        }
    }

    
    public void set(Object offeredResponse) {
        assert !(offeredResponse instanceof Response) : "unexpected response found: " + offeredResponse;

        if (offeredResponse == null) {
            offeredResponse = NULL_RESPONSE;
        }

        ExecutionCallbackNode<E> callbackChain;
        synchronized (this) {
            if (response != null && !(response instanceof InternalResponse)) {
                
                
                

                
                ILogger logger = invocation.logger;
                if (logger.isFinestEnabled()) {
                    logger.finest("Future response is already set! Current response: "
                            + response + ", Offered response: " + offeredResponse + ", Invocation: " + invocation);
                }
                return;
            }

            response = offeredResponse;
            if (offeredResponse == WAIT_RESPONSE) {
                return;
            }
            callbackChain = callbackHead;
            callbackHead = null;
            notifyAll();

            operationService.invocationsRegistry.deregister(invocation);
        }


        notifyCallbacks(callbackChain);
    }

    private void notifyCallbacks(ExecutionCallbackNode<E> callbackChain) {
        while (callbackChain != null) {
            runAsynchronous(callbackChain.callback, callbackChain.executor);
            callbackChain = callbackChain.next;
        }
    }

    @Override
    public E get() throws InterruptedException, ExecutionException {
        try {
            return get(Long.MAX_VALUE, TimeUnit.MILLISECONDS);
        } catch (TimeoutException e) {
            invocation.logger.severe("Unexpected timeout while processing " + this, e);
            return null;
        }
    }

    @Override
    public E getSafely() {
        try {
            
            
            return get();
        } catch (Throwable throwable) {
            throw ExceptionUtil.rethrow(throwable);
        }
    }

    @Override
    public E get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {
        Object unresolvedResponse = waitForResponse(timeout, unit);
        return (E) resolveApplicationResponseOrThrowException(unresolvedResponse);
    }

    private Object waitForResponse(long time, TimeUnit unit) {
        if (responseAvailable(response)) {
            return response;
        }

        WAITER_COUNT.incrementAndGet(this);
        try {
            long timeoutMs = toTimeoutMs(time, unit);
            long maxCallTimeoutMs = getMaxCallTimeout();
            boolean longPolling = timeoutMs > maxCallTimeoutMs;

            int pollCount = 0;
            while (timeoutMs >= 0) {
                long pollTimeoutMs = min(maxCallTimeoutMs, timeoutMs);
                long startMs = Clock.currentTimeMillis();
                long lastPollTime = 0;
                pollCount++;

                try {
                    pollResponse(pollTimeoutMs);
                    lastPollTime = Clock.currentTimeMillis() - startMs;
                    timeoutMs = decrementTimeout(timeoutMs, lastPollTime);

                    if (response == WAIT_RESPONSE) {
                        RESPONSE.compareAndSet(this, WAIT_RESPONSE, null);
                        continue;
                    } else if (response != null) {
                        
                        
                        if (response != INTERRUPTED_RESPONSE && interrupted) {
                            Thread.currentThread().interrupt();
                        }
                        return response;
                    }
                } catch (InterruptedException e) {
                    interrupted = true;
                }

                if (!interrupted && longPolling) {
                    
                    Address target = invocation.getTarget();
                    if (invocation.remote && invocation.nodeEngine.getThisAddress().equals(target)) {
                        
                        continue;
                    }

                    invocation.logger.warning("No response for " + lastPollTime + " ms. " + toString());
                    boolean executing = operationService.getIsStillRunningService().isOperationExecuting(invocation);
                    if (!executing) {
                        Object operationTimeoutException = invocation.newOperationTimeoutException(pollCount * pollTimeoutMs);
                        
                        set(operationTimeoutException);
                    }
                }
            }
            return TIMEOUT_RESPONSE;
        } finally {
            WAITER_COUNT.decrementAndGet(this);
        }
    }

    private void pollResponse(long pollTimeoutMs) throws InterruptedException {
        
        if (pollTimeoutMs <= 0 || response != null) {
            return;
        }

        long currentTimeoutMs = pollTimeoutMs;
        long waitStart = Clock.currentTimeMillis();
        synchronized (this) {
            while (currentTimeoutMs > 0 && response == null) {
                wait(currentTimeoutMs);
                currentTimeoutMs = pollTimeoutMs - (Clock.currentTimeMillis() - waitStart);
            }
        }
    }

    long getMaxCallTimeout() {
        long callTimeout = invocation.callTimeout;
        long maxCallTimeout = callTimeout + getCallTimeoutExtension(callTimeout);
        return maxCallTimeout > 0 ? maxCallTimeout : Long.MAX_VALUE;
    }

    private static long getCallTimeoutExtension(long callTimeout) {
        if (callTimeout <= 0) {
            return 0L;
        }

        return Math.min(callTimeout, MAX_CALL_TIMEOUT_EXTENSION);
    }

    int getWaitingThreadsCount() {
        return waiterCount;
    }

    private static long toTimeoutMs(long time, TimeUnit unit) {
        long timeoutMs = unit.toMillis(time);
        if (timeoutMs < 0) {
            timeoutMs = 0;
        }
        return timeoutMs;
    }

    private Object resolveApplicationResponseOrThrowException(Object unresolvedResponse)
            throws ExecutionException, InterruptedException, TimeoutException {

        Object response = resolveApplicationResponse(unresolvedResponse);

        if (response == null || !(response instanceof Throwable)) {
            return response;
        }

        if (response instanceof ExecutionException) {
            throw (ExecutionException) response;
        }

        if (response instanceof TimeoutException) {
            throw (TimeoutException) response;
        }

        if (response instanceof InterruptedException) {
            throw (InterruptedException) response;
        }

        if (response instanceof Error) {
            throw (Error) response;
        }

        
        throw new ExecutionException((Throwable) response);
    }

    private Object resolveApplicationResponse(Object unresolvedResponse) {
        if (unresolvedResponse == NULL_RESPONSE) {
            return null;
        }

        if (unresolvedResponse == TIMEOUT_RESPONSE) {
            return new TimeoutException("Call " + invocation + " encountered a timeout");
        }

        if (unresolvedResponse == INTERRUPTED_RESPONSE) {
            return new InterruptedException("Call " + invocation + " was interrupted");
        }

        Object response = unresolvedResponse;
        if (invocation.resultDeserialized && response instanceof Data) {
            response = invocation.nodeEngine.toObject(response);
            if (response == null) {
                return null;
            }
        }

        if (response instanceof Throwable) {
            Throwable throwable = ((Throwable) response);
            if (invocation.remote) {
                fixRemoteStackTrace((Throwable) response, Thread.currentThread().getStackTrace());
            }
            return throwable;
        }

        return response;
    }

    @Override
    public boolean cancel(boolean mayInterruptIfRunning) {
        return false;
    }

    @Override
    public boolean isCancelled() {
        return false;
    }

    @Override
    public boolean isDone() {
         return responseAvailable(response);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder("InvocationFuture{");
        sb.append("invocation=").append(invocation.toString());
        sb.append(", response=").append(response);
        sb.append(", done=").append(isDone());
        sb.append('}');
        return sb.toString();
    }

    private static final class ExecutionCallbackNode<E> {
        private final ExecutionCallback<E> callback;
        private final Executor executor;
        private final ExecutionCallbackNode<E> next;

        private ExecutionCallbackNode(ExecutionCallback<E> callback, Executor executor, ExecutionCallbackNode<E> next) {
            this.callback = callback;
            this.executor = executor;
            this.next = next;
        }
    }

    private static final class ExecutorCallbackAdapter<E> implements ExecutionCallback<E> {
        private final Callback callback;

        private ExecutorCallbackAdapter(Callback callback) {
            this.callback = callback;
        }

        @Override
        public void onResponse(E response) {
            callback.notify(response);
        }

        @Override
        public void onFailure(Throwable t) {
            callback.notify(t);
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.nio.Address;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.NodeEngineImpl;


public final class PartitionInvocation extends Invocation {

    public PartitionInvocation(NodeEngineImpl nodeEngine, String serviceName, Operation op, int partitionId,
                               int replicaIndex, int tryCount, long tryPauseMillis, long callTimeout,
                               Object callback, boolean resultDeserialized) {
        super(nodeEngine, serviceName, op, partitionId, replicaIndex, tryCount, tryPauseMillis,
                callTimeout, callback, resultDeserialized);
    }

    @Override
    public Address getTarget() {
        return getPartition().getReplicaAddress(replicaIndex);
    }

    @Override
    ExceptionAction onException(Throwable t) {
        final ExceptionAction action = op.onException(t);
        return action != null ? action : ExceptionAction.THROW_EXCEPTION;
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.nio.Address;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.NodeEngineImpl;


public class InvocationBuilderImpl extends InvocationBuilder {

    public InvocationBuilderImpl(NodeEngineImpl nodeEngine, String serviceName, Operation op, int partitionId) {
        this(nodeEngine, serviceName, op, partitionId, null);
    }

    public InvocationBuilderImpl(NodeEngineImpl nodeEngine, String serviceName, Operation op, Address target) {
        this(nodeEngine, serviceName, op, Operation.GENERIC_PARTITION_ID, target);
    }

    private InvocationBuilderImpl(NodeEngineImpl nodeEngine, String serviceName, Operation op,
                                  int partitionId, Address target) {
        super(nodeEngine, serviceName, op, partitionId, target);
    }

    @Override
    public InternalCompletableFuture invoke() {
        Object callback = this.callback;
        if (callback == null) {
            callback = this.executionCallback;
        }

        if (target == null) {
            return new PartitionInvocation(nodeEngine, serviceName, op, partitionId, replicaIndex,
                    tryCount, tryPauseMillis, callTimeout, callback, resultDeserialized).invoke();
        } else {
            return new TargetInvocation(nodeEngine, serviceName, op, target, tryCount, tryPauseMillis,
                    callTimeout, callback, resultDeserialized).invoke();
        }
    }
}

<code block>


package com.hazelcast.spi.impl.operationservice.impl;

import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.OperationTimeoutException;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.nio.Address;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.spi.ExceptionAction;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.ResponseHandler;
import com.hazelcast.spi.WaitSupport;
import com.hazelcast.spi.exception.ResponseAlreadySentException;
import com.hazelcast.spi.exception.RetryableException;
import com.hazelcast.spi.exception.RetryableIOException;
import com.hazelcast.spi.exception.TargetNotMemberException;
import com.hazelcast.spi.exception.WrongTargetException;
import com.hazelcast.spi.impl.NodeEngineImpl;
import com.hazelcast.spi.impl.operationexecutor.OperationExecutor;
import com.hazelcast.spi.impl.operationservice.impl.responses.CallTimeoutResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.ErrorResponse;
import com.hazelcast.spi.impl.operationservice.impl.responses.NormalResponse;
import com.hazelcast.util.Clock;
import com.hazelcast.util.ExceptionUtil;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;

import static com.hazelcast.spi.ExecutionService.ASYNC_EXECUTOR;
import static com.hazelcast.spi.OperationAccessor.setCallTimeout;
import static com.hazelcast.spi.OperationAccessor.setCallerAddress;
import static com.hazelcast.spi.OperationAccessor.setInvocationTime;
import static com.hazelcast.spi.impl.operationutil.Operations.isJoinOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isMigrationOperation;
import static com.hazelcast.spi.impl.operationutil.Operations.isWanReplicationOperation;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.INTERRUPTED_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.NULL_RESPONSE;
import static com.hazelcast.spi.impl.operationservice.impl.InternalResponse.WAIT_RESPONSE;
import static java.lang.Boolean.FALSE;
import static java.lang.Boolean.TRUE;
import static java.util.logging.Level.WARNING;


abstract class Invocation implements ResponseHandler, Runnable {

    private static final AtomicReferenceFieldUpdater<Invocation, Boolean> RESPONSE_RECEIVED =
            AtomicReferenceFieldUpdater.newUpdater(Invocation.class, Boolean.class, "responseReceived");

    private static final AtomicIntegerFieldUpdater<Invocation> BACKUPS_COMPLETED =
            AtomicIntegerFieldUpdater.newUpdater(Invocation.class, "backupsCompleted");

    private static final long MIN_TIMEOUT = 10000;
    private static final int MAX_FAST_INVOCATION_COUNT = 5;
    
    private static final int LOG_MAX_INVOCATION_COUNT = 99;
    private static final int LOG_INVOCATION_COUNT_MOD = 10;

    
    volatile long pendingResponseReceivedMillis = -1;
    
    volatile Object pendingResponse;
    
    volatile int backupsExpected;
    
    volatile int backupsCompleted;
    
    volatile Boolean responseReceived = FALSE;

    final long callTimeout;
    final NodeEngineImpl nodeEngine;
    final String serviceName;
    final Operation op;
    final int partitionId;
    final int replicaIndex;
    final int tryCount;
    final long tryPauseMillis;
    final ILogger logger;
    final boolean resultDeserialized;
    boolean remote;
    Address invTarget;
    MemberImpl targetMember;
    final InvocationFuture invocationFuture;
    final OperationServiceImpl operationService;

    
    volatile int invokeCount;

    Invocation(NodeEngineImpl nodeEngine, String serviceName, Operation op, int partitionId,
               int replicaIndex, int tryCount, long tryPauseMillis, long callTimeout, Object callback,
               boolean resultDeserialized) {
        this.operationService = (OperationServiceImpl) nodeEngine.getOperationService();
        this.logger = operationService.invocationLogger;
        this.nodeEngine = nodeEngine;
        this.serviceName = serviceName;
        this.op = op;
        this.partitionId = partitionId;
        this.replicaIndex = replicaIndex;
        this.tryCount = tryCount;
        this.tryPauseMillis = tryPauseMillis;
        this.callTimeout = getCallTimeout(callTimeout);
        this.invocationFuture = new InvocationFuture(operationService, this, callback);
        this.resultDeserialized = resultDeserialized;
    }

    abstract ExceptionAction onException(Throwable t);

    protected abstract Address getTarget();

    InternalPartition getPartition() {
        return nodeEngine.getPartitionService().getPartition(partitionId);
    }

    @Override
    public boolean isLocal() {
        return true;
    }

    private long getCallTimeout(long callTimeout) {
        if (callTimeout > 0) {
            return callTimeout;
        }

        long defaultCallTimeout = operationService.defaultCallTimeoutMillis;
        if (!(op instanceof WaitSupport)) {
            return defaultCallTimeout;
        }

        long waitTimeoutMillis = op.getWaitTimeout();
        if (waitTimeoutMillis > 0 && waitTimeoutMillis < Long.MAX_VALUE) {
            
            long max = Math.max(waitTimeoutMillis, MIN_TIMEOUT);
            return Math.min(max, defaultCallTimeout);
        }
        return defaultCallTimeout;
    }

    public final InvocationFuture invoke() {
        invokeInternal(false);
        return invocationFuture;
    }

    public final void invokeAsync() {
        invokeInternal(true);
    }

    private void invokeInternal(boolean isAsync) {
        if (invokeCount > 0) {
            
            throw new IllegalStateException("An invocation can not be invoked more than once!");
        }

        if (op.getCallId() != 0) {
            throw new IllegalStateException("An operation[" + op + "] can not be used for multiple invocations!");
        }

        try {
            setCallTimeout(op, callTimeout);
            setCallerAddress(op, nodeEngine.getThisAddress());
            op.setNodeEngine(nodeEngine)
                    .setServiceName(serviceName)
                    .setPartitionId(partitionId)
                    .setReplicaIndex(replicaIndex);

            boolean isAllowed = operationService.operationExecutor.isInvocationAllowedFromCurrentThread(op, isAsync);
            if (!isAllowed && !isMigrationOperation(op)) {
                throw new IllegalThreadStateException(Thread.currentThread() + " cannot make remote call: " + op);
            }
            doInvoke(isAsync);
        } catch (Exception e) {
            handleInvocationException(e);
        }
    }

    private void handleInvocationException(Exception e) {
        if (e instanceof RetryableException) {
            notify(e);
        } else {
            throw ExceptionUtil.rethrow(e);
        }
    }

    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "We have the guarantee that only a single thread at any given time can change the volatile field")
    private void doInvoke(boolean isAsync) {
        if (!engineActive()) {
            return;
        }

        invokeCount++;

        
        if (!initInvocationTarget()) {
            return;
        }

        setInvocationTime(op, nodeEngine.getClusterService().getClusterClock().getClusterTime());
        operationService.invocationsRegistry.register(this);
        if (remote) {
            doInvokeRemote();
        } else {
            doInvokeLocal(isAsync);
        }
    }

    private void doInvokeLocal(boolean isAsync) {
        if (op.getCallerUuid() == null) {
            op.setCallerUuid(nodeEngine.getLocalMember().getUuid());
        }

        responseReceived = FALSE;
        op.setResponseHandler(this);

        OperationExecutor executor = operationService.operationExecutor;
        if (isAsync) {
            executor.execute(op);
        } else {
            executor.runOnCallingThreadIfPossible(op);
        }

    }

    private void doInvokeRemote() {
        boolean sent = operationService.send(op, invTarget);
        if (!sent) {
            operationService.invocationsRegistry.deregister(this);
            notify(new RetryableIOException("Packet not send to -> " + invTarget));
        }
    }

    @Override
    public void run() {
        doInvoke(false);
    }

    private boolean engineActive() {
        if (nodeEngine.isActive()) {
            return true;
        }

        remote = false;
        notify(new HazelcastInstanceNotActiveException());
        return false;
    }

    
    boolean initInvocationTarget() {
        Address thisAddress = nodeEngine.getThisAddress();

        invTarget = getTarget();

        if (invTarget == null) {
            remote = false;
            if (nodeEngine.isActive()) {
                notify(new WrongTargetException(thisAddress, null, partitionId
                        , replicaIndex, op.getClass().getName(), serviceName));
            } else {
                notify(new HazelcastInstanceNotActiveException());
            }
            return false;
        }

        targetMember = nodeEngine.getClusterService().getMember(invTarget);
        if (targetMember == null && !(isJoinOperation(op) || isWanReplicationOperation(op))) {
            notify(new TargetNotMemberException(invTarget, partitionId, op.getClass().getName(), serviceName));
            return false;
        }

        if (op.getPartitionId() != partitionId) {
            notify(new IllegalStateException("Partition id of operation: " + op.getPartitionId()
                    + " is not equal to the partition id of invocation: " + partitionId));
            return false;
        }

        if (op.getReplicaIndex() != replicaIndex) {
            notify(new IllegalStateException("Replica index of operation: " + op.getReplicaIndex()
                    + " is not equal to the replica index of invocation: " + replicaIndex));
            return false;
        }

        remote = !thisAddress.equals(invTarget);
        return true;
    }

    @Override
    public void sendResponse(Object obj) {
        if (!RESPONSE_RECEIVED.compareAndSet(this, FALSE, TRUE)) {
            throw new ResponseAlreadySentException("NormalResponse already responseReceived for callback: " + this
                    + ", current-response: : " + obj);
        }
        notify(obj);
    }

    
    
    void notify(Object response) {
        if (response == null) {
            response = NULL_RESPONSE;
        }

        if (response instanceof CallTimeoutResponse) {
            notifyCallTimeout();
            return;
        }

        if (response instanceof ErrorResponse || response instanceof Throwable) {
            notifyError(response);
            return;
        }

        if (response instanceof NormalResponse) {
            NormalResponse normalResponse = (NormalResponse) response;
            notifyNormalResponse(normalResponse.getValue(), normalResponse.getBackupCount());
            return;
        }

        
        invocationFuture.set(response);
    }

    void notifyError(Object error) {
        assert error != null;

        Throwable cause;
        if (error instanceof Throwable) {
            cause = (Throwable) error;
        } else {
            cause = ((ErrorResponse) error).getCause();
        }

        switch (onException(cause)) {
            case CONTINUE_WAIT:
                handleContinueWait();
                break;
            case THROW_EXCEPTION:
                notifyNormalResponse(cause, 0);
                break;
            case RETRY_INVOCATION:
                if (invokeCount < tryCount) {
                    
                    handleRetry(cause);
                } else {
                    
                    notifyNormalResponse(cause, 0);
                }
                break;
            default:
                throw new IllegalStateException("Unhandled ExceptionAction");
        }
    }

    void notifyNormalResponse(Object value, int expectedBackups) {
        if (value == null) {
            value = NULL_RESPONSE;
        }

        
        

        if (expectedBackups > backupsCompleted) {
            
            

            this.pendingResponseReceivedMillis = Clock.currentTimeMillis();

            this.backupsExpected = expectedBackups;

            
            
            this.pendingResponse = value;

            if (backupsCompleted != expectedBackups) {
                
                return;
            }
        }

        
        
        
        invocationFuture.set(value);
    }

    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = "VO_VOLATILE_INCREMENT",
            justification = "We have the guarantee that only a single thread at any given time can change the volatile field")
    void notifyCallTimeout() {
        if (logger.isFinestEnabled()) {
            logger.finest("Call timed-out during wait-notify phase, retrying call: " + toString());
        }

        if (op instanceof WaitSupport) {
            
            long waitTimeout = op.getWaitTimeout();
            waitTimeout -= callTimeout;
            op.setWaitTimeout(waitTimeout);
        }

        invokeCount--;
        handleRetry("invocation timeout");
    }

    void notifySingleBackupComplete() {
        int newBackupsCompleted = BACKUPS_COMPLETED.incrementAndGet(this);

        Object pendingResponse = this.pendingResponse;
        if (pendingResponse == null) {
            
            return;
        }

        
        int backupsExpected = this.backupsExpected;
        if (backupsExpected < newBackupsCompleted) {
            
            return;
        }

        if (backupsExpected != newBackupsCompleted) {
            
            return;
        }

        
        
        invocationFuture.set(pendingResponse);
    }

    boolean checkInvocationTimeout() {
        long maxCallTimeout = invocationFuture.getMaxCallTimeout();
        long expirationTime = op.getInvocationTime() + maxCallTimeout;

        boolean hasResponse = pendingResponse != null;
        boolean hasWaitingThreads = invocationFuture.getWaitingThreadsCount() > 0;
        boolean notExpired = maxCallTimeout == Long.MAX_VALUE
                || expirationTime < 0
                || expirationTime >= Clock.currentTimeMillis();

        if (hasResponse || hasWaitingThreads || notExpired) {
            return false;
        }

        operationService.getIsStillRunningService().timeoutInvocationIfNotExecuting(this);
        return true;
    }

    Object newOperationTimeoutException(long totalTimeoutMs) {
        boolean hasResponse = this.pendingResponse != null;
        int backupsExpected = this.backupsExpected;
        int backupsCompleted = this.backupsCompleted;

        if (hasResponse) {
            return new OperationTimeoutException("No response for " + totalTimeoutMs + " ms."
                    + " Aborting invocation! " + toString()
                    + " Not all backups have completed! "
                    + " backups-expected:" + backupsExpected
                    + " backups-completed: " + backupsCompleted);
        } else {
            return new OperationTimeoutException("No response for " + totalTimeoutMs + " ms."
                    + " Aborting invocation! " + toString()
                    + " No response has been received! "
                    + " backups-expected:" + backupsExpected
                    + " backups-completed: " + backupsCompleted);
        }
    }

    private void handleContinueWait() {
        invocationFuture.set(WAIT_RESPONSE);
    }

    private void handleRetry(Object cause) {
        if (invokeCount > LOG_MAX_INVOCATION_COUNT && invokeCount % LOG_INVOCATION_COUNT_MOD == 0) {
            if (logger.isLoggable(WARNING)) {
                logger.warning("Retrying invocation: " + toString() + ", Reason: " + cause);
            }
        }

        operationService.invocationsRegistry.deregister(this);

        if (invocationFuture.interrupted) {
            invocationFuture.set(INTERRUPTED_RESPONSE);
            return;
        }

        invocationFuture.set(WAIT_RESPONSE);
        ExecutionService ex = nodeEngine.getExecutionService();
        
        if (invokeCount < MAX_FAST_INVOCATION_COUNT) {
            operationService.asyncExecutor.execute(this);
        } else {
            ex.schedule(ASYNC_EXECUTOR, this, tryPauseMillis, TimeUnit.MILLISECONDS);
        }
    }

    boolean checkBackupTimeout(long timeoutMillis) {
        
        
        
        boolean allBackupsComplete = backupsExpected == backupsCompleted;
        long responseReceivedMillis = pendingResponseReceivedMillis;

        
        long expirationTime = responseReceivedMillis + timeoutMillis;
        boolean timeout = expirationTime > 0 && expirationTime < Clock.currentTimeMillis();

        
        
        boolean responseReceived = pendingResponse != null;

        if (allBackupsComplete || !responseReceived || !timeout) {
            return false;
        }

        boolean targetDead = nodeEngine.getClusterService().getMember(invTarget) == null;
        if (targetDead) {
            
            
            
            
            
            
            resetAndReInvoke();
            return false;
        }

         
        invocationFuture.set(pendingResponse);
        return true;
    }

    private void resetAndReInvoke() {
        operationService.invocationsRegistry.deregister(this);
        invokeCount = 0;
        pendingResponse = null;
        pendingResponseReceivedMillis = -1;
        backupsExpected = 0;
        backupsCompleted = 0;
        doInvoke(false);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder();
        sb.append("Invocation");
        sb.append("{ serviceName='").append(serviceName).append('\'');
        sb.append(", op=").append(op);
        sb.append(", partitionId=").append(partitionId);
        sb.append(", replicaIndex=").append(replicaIndex);
        sb.append(", tryCount=").append(tryCount);
        sb.append(", tryPauseMillis=").append(tryPauseMillis);
        sb.append(", invokeCount=").append(invokeCount);
        sb.append(", callTimeout=").append(callTimeout);
        sb.append(", target=").append(invTarget);
        sb.append(", backupsExpected=").append(backupsExpected);
        sb.append(", backupsCompleted=").append(backupsCompleted);
        sb.append('}');
        return sb.toString();
    }
}

<code block>


package com.hazelcast.map.impl.proxy;

import com.hazelcast.concurrent.lock.LockProxySupport;
import com.hazelcast.config.EntryListenerConfig;
import com.hazelcast.config.ListenerConfig;
import com.hazelcast.config.MapConfig;
import com.hazelcast.config.MapIndexConfig;
import com.hazelcast.config.MapPartitionLostListenerConfig;
import com.hazelcast.config.MapStoreConfig;
import com.hazelcast.core.EntryEventType;
import com.hazelcast.core.EntryView;
import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastInstanceAware;
import com.hazelcast.core.ICompletableFuture;
import com.hazelcast.core.IFunction;
import com.hazelcast.core.IMap;
import com.hazelcast.core.MapStore;
import com.hazelcast.core.Member;
import com.hazelcast.core.PartitioningStrategy;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.map.EntryProcessor;
import com.hazelcast.map.MapInterceptor;
import com.hazelcast.map.impl.EntryEventFilter;
import com.hazelcast.map.impl.MapContainer;
import com.hazelcast.map.impl.MapContextQuerySupport;
import com.hazelcast.map.impl.MapEntrySet;
import com.hazelcast.map.impl.MapEventPublisher;
import com.hazelcast.map.impl.MapService;
import com.hazelcast.map.impl.MapServiceContext;
import com.hazelcast.map.impl.NearCache;
import com.hazelcast.map.impl.NearCacheProvider;
import com.hazelcast.map.impl.PartitionContainer;
import com.hazelcast.map.impl.QueryEventFilter;
import com.hazelcast.map.impl.RecordStore;
import com.hazelcast.map.impl.operation.AddIndexOperation;
import com.hazelcast.map.impl.operation.AddInterceptorOperation;
import com.hazelcast.map.impl.operation.BasePutOperation;
import com.hazelcast.map.impl.operation.BaseRemoveOperation;
import com.hazelcast.map.impl.operation.ClearOperation;
import com.hazelcast.map.impl.operation.ContainsKeyOperation;
import com.hazelcast.map.impl.operation.ContainsValueOperationFactory;
import com.hazelcast.map.impl.operation.DeleteOperation;
import com.hazelcast.map.impl.operation.EntryOperation;
import com.hazelcast.map.impl.operation.EvictAllOperation;
import com.hazelcast.map.impl.operation.EvictOperation;
import com.hazelcast.map.impl.operation.GetEntryViewOperation;
import com.hazelcast.map.impl.operation.GetOperation;
import com.hazelcast.map.impl.operation.IsEmptyOperationFactory;
import com.hazelcast.map.impl.operation.KeyBasedMapOperation;
import com.hazelcast.map.impl.operation.LoadAllOperation;
import com.hazelcast.map.impl.operation.LoadMapOperation;
import com.hazelcast.map.impl.operation.MapFlushOperation;
import com.hazelcast.map.impl.operation.MapGetAllOperationFactory;
import com.hazelcast.map.impl.operation.MultipleEntryOperationFactory;
import com.hazelcast.map.impl.operation.PartitionCheckIfLoadedOperationFactory;
import com.hazelcast.map.impl.operation.PartitionWideEntryWithPredicateOperationFactory;
import com.hazelcast.map.impl.operation.PutAllOperation;
import com.hazelcast.map.impl.operation.PutIfAbsentOperation;
import com.hazelcast.map.impl.operation.PutOperation;
import com.hazelcast.map.impl.operation.PutTransientOperation;
import com.hazelcast.map.impl.operation.RemoveIfSameOperation;
import com.hazelcast.map.impl.operation.RemoveInterceptorOperation;
import com.hazelcast.map.impl.operation.RemoveOperation;
import com.hazelcast.map.impl.operation.ReplaceIfSameOperation;
import com.hazelcast.map.impl.operation.ReplaceOperation;
import com.hazelcast.map.impl.operation.SetOperation;
import com.hazelcast.map.impl.operation.SizeOperationFactory;
import com.hazelcast.map.impl.operation.TryPutOperation;
import com.hazelcast.map.impl.operation.TryRemoveOperation;
import com.hazelcast.map.listener.MapListener;
import com.hazelcast.map.listener.MapPartitionLostListener;
import com.hazelcast.monitor.LocalMapStats;
import com.hazelcast.monitor.impl.LocalMapStatsImpl;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ClassLoaderUtil;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.partition.InternalPartition;
import com.hazelcast.partition.InternalPartitionService;
import com.hazelcast.query.PagingPredicate;
import com.hazelcast.query.Predicate;
import com.hazelcast.query.TruePredicate;
import com.hazelcast.spi.AbstractDistributedObject;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.DefaultObjectNamespace;
import com.hazelcast.spi.EventFilter;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InitializingObject;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationFactory;
import com.hazelcast.spi.OperationService;
import com.hazelcast.spi.impl.BinaryOperationFactory;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.IterableUtil;
import com.hazelcast.util.IterationType;
import com.hazelcast.util.ThreadUtil;
import com.hazelcast.util.executor.CompletedFuture;

import java.util.AbstractMap;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.EventListener;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;

import static com.hazelcast.map.impl.MapService.SERVICE_NAME;
import static com.hazelcast.util.IterableUtil.nullToEmpty;
import static com.hazelcast.util.Preconditions.checkNotNull;
import static java.util.Collections.singleton;

abstract class MapProxySupport extends AbstractDistributedObject<MapService> implements InitializingObject {

    protected static final String NULL_KEY_IS_NOT_ALLOWED = "Null key is not allowed!";
    protected static final String NULL_VALUE_IS_NOT_ALLOWED = "Null value is not allowed!";
    protected static final String NULL_PREDICATE_IS_NOT_ALLOWED = "Predicate should not be null!";
    protected static final String NULL_LISTENER_IS_NOT_ALLOWED = "Null listener is not allowed!";

    protected final String name;
    protected final LocalMapStatsImpl localMapStats;
    protected final LockProxySupport lockSupport;
    protected final PartitioningStrategy partitionStrategy;
    private MapServiceContext mapServiceContext;
    private InternalPartitionService partitionService;

    protected MapProxySupport(final String name, final MapService service, NodeEngine nodeEngine) {
        super(nodeEngine, service);
        this.name = name;
        this.mapServiceContext = service.getMapServiceContext();
        partitionStrategy = mapServiceContext.getMapContainer(name).getPartitioningStrategy();
        localMapStats = mapServiceContext.getLocalMapStatsProvider().getLocalMapStatsImpl(name);
        this.partitionService = getNodeEngine().getPartitionService();
        lockSupport = new LockProxySupport(new DefaultObjectNamespace(MapService.SERVICE_NAME, name));
    }

    @Override
    public void initialize() {
        initializeListeners();
        initializeIndexes();
        initializeMapStoreLoad();
    }

    private void initializeMapStoreLoad() {
        MapStoreConfig mapStoreConfig = getMapConfig().getMapStoreConfig();
        if (mapStoreConfig != null && mapStoreConfig.isEnabled()) {
            MapStoreConfig.InitialLoadMode initialLoadMode = mapStoreConfig.getInitialLoadMode();
            if (MapStoreConfig.InitialLoadMode.EAGER.equals(initialLoadMode)) {
                waitUntilLoaded();
            }
        }
    }

    private void initializeIndexes() {
        for (MapIndexConfig index : getMapConfig().getMapIndexConfigs()) {
            if (index.getAttribute() != null) {
                addIndex(index.getAttribute(), index.isOrdered());
            }
        }
    }

    private void initializeListeners() {
        final MapConfig mapConfig = getMapConfig();

        for (EntryListenerConfig listenerConfig : mapConfig.getEntryListenerConfigs()) {
            final MapListener listener = initializeListener(listenerConfig);
            if (listener != null) {
                if (listenerConfig.isLocal()) {
                    addLocalEntryListenerInternal(listener);
                } else {
                    addEntryListenerInternal(listener, null, listenerConfig.isIncludeValue());
                }
            }
        }

        for (MapPartitionLostListenerConfig listenerConfig : mapConfig.getPartitionLostListenerConfigs()) {
            final MapPartitionLostListener listener = initializeListener(listenerConfig);
            if (listener != null) {
                addPartitionLostListenerInternal(listener);
            }
        }
    }

    private <T extends EventListener> T initializeListener(ListenerConfig listenerConfig) {
        T listener = null;
        if (listenerConfig.getImplementation() != null) {
            listener = (T) listenerConfig.getImplementation();
        } else if (listenerConfig.getClassName() != null) {
            try {
                return ClassLoaderUtil
                        .newInstance(getNodeEngine().getConfigClassLoader(), listenerConfig.getClassName());
            } catch (Exception e) {
                throw ExceptionUtil.rethrow(e);
            }
        }

        if (listener instanceof HazelcastInstanceAware) {
            ((HazelcastInstanceAware) listener).setHazelcastInstance(getNodeEngine().getHazelcastInstance());
        }

        return listener;
    }

    
    
    protected Object getInternal(Data key) {
        
        
        final MapConfig mapConfig = getMapConfig();
        final boolean nearCacheEnabled = mapConfig.isNearCacheEnabled();
        if (nearCacheEnabled) {
            final Object fromNearCache = getFromNearCache(key);
            if (fromNearCache != null) {
                if (isCachedAsNullInNearCache(fromNearCache)) {
                    return null;
                }
                return fromNearCache;
            }
        }
        
        if (mapConfig.isReadBackupData()) {
            final Object fromBackup = readBackupDataOrNull(key);
            if (fromBackup != null) {
                return fromBackup;
            }
        }
        final GetOperation operation = new GetOperation(name, key);
        operation.setThreadId(ThreadUtil.getThreadId());
        final Data value = (Data) invokeOperation(key, operation);

        if (nearCacheEnabled) {
            if (notOwnerPartitionForKey(key) || cacheKeyAnyway()) {
                return putNearCache(key, value);
            }
        }
        return value;
    }

    private boolean notOwnerPartitionForKey(Data key) {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final NodeEngine nodeEngine = mapServiceContext.getNodeEngine();
        final int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        return !nodeEngine.getPartitionService().getPartitionOwner(partitionId)
                .equals(nodeEngine.getClusterService().getThisAddress());
    }

    private boolean cacheKeyAnyway() {
        return getMapConfig().getNearCacheConfig().isCacheLocalEntries();
    }

    private Object putNearCache(Data key, Data value) {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final NearCacheProvider nearCacheProvider = mapServiceContext.getNearCacheProvider();
        return nearCacheProvider.putNearCache(name, key, value);
    }


    private Object getFromNearCache(Data key) {
        if (!getMapConfig().isNearCacheEnabled()) {
            return null;
        }
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final NearCacheProvider nearCacheProvider = mapServiceContext.getNearCacheProvider();
        final Object cached = nearCacheProvider.getFromNearCache(name, key);
        if (cached == null) {
            return null;
        }
        mapServiceContext.interceptAfterGet(name, cached);
        return cached;
    }

    private void getFromNearCache(Map<Object, Object> resultMap, Collection<Data> keys) {
        if (!getMapConfig().isNearCacheEnabled()) {
            return;
        }
        final MapService mapService = getService();
        final Iterator<Data> iterator = keys.iterator();
        while (iterator.hasNext()) {
            Data key = iterator.next();
            final Object fromNearCache = getFromNearCache(key);
            if (fromNearCache == null) {
                continue;
            }
            if (!isCachedAsNullInNearCache(fromNearCache)) {
                resultMap.put(mapService.getMapServiceContext().toObject(key),
                        mapService.getMapServiceContext().toObject(fromNearCache));
            }
            iterator.remove();
        }
    }

    private boolean isCachedAsNullInNearCache(Object cached) {
        if (cached == null) {
            return false;
        }
        return NearCache.NULL_OBJECT.equals(cached);
    }

    private Data readBackupDataOrNull(Data key) {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final NodeEngine nodeEngine = mapServiceContext.getNodeEngine();
        final InternalPartitionService partitionService = nodeEngine.getPartitionService();
        final Address thisAddress = nodeEngine.getThisAddress();
        final int partitionId = partitionService.getPartitionId(key);
        final InternalPartition partition = partitionService.getPartition(partitionId, false);
        if (!partition.isOwnerOrBackup(thisAddress)) {
            return null;
        }
        final PartitionContainer partitionContainer = mapServiceContext.getPartitionContainer(partitionId);
        final RecordStore recordStore = partitionContainer.getExistingRecordStore(name);
        if (recordStore == null) {
            return null;
        }
        return recordStore.readBackupData(key);
    }

    protected ICompletableFuture<Data> getAsyncInternal(final Data key) {
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        final boolean nearCacheEnabled = getMapConfig().isNearCacheEnabled();
        if (nearCacheEnabled) {
            Object cached = mapService.getMapServiceContext().getNearCacheProvider().getFromNearCache(name, key);
            if (cached != null) {
                if (NearCache.NULL_OBJECT.equals(cached)) {
                    cached = null;
                }
                return new CompletedFuture<Data>(
                        nodeEngine.getSerializationService(),
                        cached,
                        nodeEngine.getExecutionService().getExecutor(ExecutionService.ASYNC_EXECUTOR));
            }
        }

        GetOperation operation = new GetOperation(name, key);
        try {
            final OperationService operationService = nodeEngine.getOperationService();
            final InvocationBuilder invocationBuilder
                    = operationService.createInvocationBuilder(SERVICE_NAME,
                    operation, partitionId).setResultDeserialized(false);
            final InternalCompletableFuture<Data> future = invocationBuilder.invoke();
            future.andThen(new ExecutionCallback<Data>() {
                @Override
                public void onResponse(Data response) {
                    if (nearCacheEnabled) {
                        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
                        if (!nodeEngine.getPartitionService().getPartitionOwner(partitionId)
                                .equals(nodeEngine.getClusterService().getThisAddress())
                                || getMapConfig().getNearCacheConfig().isCacheLocalEntries()) {
                            mapService.getMapServiceContext().getNearCacheProvider().putNearCache(name, key, response);
                        }
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                }
            });
            return future;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected Data putInternal(final Data key, final Data value, final long ttl, final TimeUnit timeunit) {
        PutOperation operation = new PutOperation(name, key, value, getTimeInMillis(ttl, timeunit));
        Data previousValue = (Data) invokeOperation(key, operation);
        invalidateNearCache(key);
        return previousValue;
    }

    protected boolean tryPutInternal(final Data key, final Data value, final long timeout, final TimeUnit timeunit) {
        TryPutOperation operation = new TryPutOperation(name, key, value, getTimeInMillis(timeout, timeunit));
        boolean putSuccessful = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return putSuccessful;
    }

    protected Data putIfAbsentInternal(final Data key, final Data value, final long ttl, final TimeUnit timeunit) {
        PutIfAbsentOperation operation = new PutIfAbsentOperation(name, key, value, getTimeInMillis(ttl, timeunit));
        Data previousValue = (Data) invokeOperation(key, operation);
        invalidateNearCache(key);
        return previousValue;
    }

    protected void putTransientInternal(final Data key, final Data value, final long ttl, final TimeUnit timeunit) {
        PutTransientOperation operation = new PutTransientOperation(name, key, value, getTimeInMillis(ttl, timeunit));
        invokeOperation(key, operation);
        invalidateNearCache(key);
    }

    private Object invokeOperation(Data key, KeyBasedMapOperation operation) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            Future f;
            Object o;
            OperationService operationService = nodeEngine.getOperationService();
            if (getMapConfig().isStatisticsEnabled()) {
                long time = System.currentTimeMillis();
                f = operationService
                        .createInvocationBuilder(SERVICE_NAME, operation, partitionId)
                        .setResultDeserialized(false)
                        .invoke();
                o = f.get();
                if (operation instanceof BasePutOperation) {
                    localMapStats.incrementPuts(System.currentTimeMillis() - time);
                } else if (operation instanceof BaseRemoveOperation) {
                    localMapStats.incrementRemoves(System.currentTimeMillis() - time);
                } else if (operation instanceof GetOperation) {
                    localMapStats.incrementGets(System.currentTimeMillis() - time);
                }

            } else {
                f = operationService.createInvocationBuilder(SERVICE_NAME, operation, partitionId)
                        .setResultDeserialized(false).invoke();
                o = f.get();
            }
            return o;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected ICompletableFuture<Data> putAsyncInternal(final Data key, final Data value,
                                                        final long ttl, final TimeUnit timeunit) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        PutOperation operation = new PutOperation(name, key, value, getTimeInMillis(ttl, timeunit));
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            ICompletableFuture<Data> future
                    = nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
            invalidateNearCache(key);
            return future;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected boolean replaceInternal(final Data key, final Data expect, final Data update) {
        ReplaceIfSameOperation operation = new ReplaceIfSameOperation(name, key, expect, update);
        boolean replaceSuccessful = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return replaceSuccessful;
    }

    protected Data replaceInternal(final Data key, final Data value) {
        ReplaceOperation operation = new ReplaceOperation(name, key, value);
        final Data result = (Data) invokeOperation(key, operation);
        invalidateNearCache(key);
        return result;
    }

    protected void setInternal(final Data key, final Data value, final long ttl, final TimeUnit timeunit) {
        SetOperation operation = new SetOperation(name, key, value, timeunit.toMillis(ttl));
        invokeOperation(key, operation);
        invalidateNearCache(key);
    }

    protected boolean evictInternal(final Data key) {
        EvictOperation operation = new EvictOperation(name, key, false);
        final boolean evictSuccess = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return evictSuccess;
    }

    protected void evictAllInternal() {
        try {
            clearNearCache();
            final Operation operation = new EvictAllOperation(name);
            final NodeEngine nodeEngine = getNodeEngine();
            final Map<Integer, Object> resultMap
                    = nodeEngine.getOperationService().invokeOnAllPartitions(SERVICE_NAME,
                    new BinaryOperationFactory(operation, nodeEngine));

            int numberOfAffectedEntries = 0;
            for (Object o : resultMap.values()) {
                numberOfAffectedEntries += (Integer) o;
            }
            if (numberOfAffectedEntries > 0) {
                publishMapEvent(numberOfAffectedEntries, EntryEventType.EVICT_ALL);
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected void loadAllInternal(boolean replaceExistingValues) {
        NodeEngine nodeEngine = getNodeEngine();
        OperationService operationService = nodeEngine.getOperationService();
        InternalPartitionService partitionService = nodeEngine.getPartitionService();
        int mapNamePartition = partitionService.getPartitionId(name);

        Operation operation = new LoadMapOperation(name, replaceExistingValues);
        Future loadMapFuture = operationService.invokeOnPartition(MapService.SERVICE_NAME, operation, mapNamePartition);

        try {
            loadMapFuture.get();
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }

        waitUntilLoaded();
    }

    
    protected void loadInternal(Iterable keys, boolean replaceExistingValues) {

        Iterable<Data> dataKeys = convertToData(keys);
        NodeEngine nodeEngine = getNodeEngine();
        Map<Integer, List<Data>> partitionIdToKeys = getPartitionIdToKeysMap(dataKeys);
        Iterable<Entry<Integer, List<Data>>> entries = partitionIdToKeys.entrySet();

        for (final Entry<Integer, List<Data>> entry : entries) {
            final Integer partitionId = entry.getKey();
            final List<Data> correspondingKeys = entry.getValue();
            final Operation operation = createLoadAllOperation(correspondingKeys, replaceExistingValues);
            nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
        }

        waitUntilLoaded();
    }

    private <K> Iterable<Data> convertToData(Iterable<K> keys) {
        return IterableUtil.map(nullToEmpty(keys), new IFunction<K, Data>() {
            public Data apply(K key) {
                return toData(key);
            }
        });
    }

    private Operation createLoadAllOperation(final List<Data> keys, boolean replaceExistingValues) {
        return new LoadAllOperation(name, keys, replaceExistingValues);
    }

    protected Data removeInternal(Data key) {
        RemoveOperation operation = new RemoveOperation(name, key);
        Data previousValue = (Data) invokeOperation(key, operation);
        invalidateNearCache(key);
        return previousValue;
    }

    protected void deleteInternal(Data key) {
        DeleteOperation operation = new DeleteOperation(name, key);
        invokeOperation(key, operation);
        invalidateNearCache(key);
    }

    protected boolean removeInternal(final Data key, final Data value) {
        RemoveIfSameOperation operation = new RemoveIfSameOperation(name, key, value);
        boolean removed = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return removed;
    }

    protected boolean tryRemoveInternal(final Data key, final long timeout, final TimeUnit timeunit) {
        TryRemoveOperation operation = new TryRemoveOperation(name, key, getTimeInMillis(timeout, timeunit));
        boolean removed = (Boolean) invokeOperation(key, operation);
        invalidateNearCache(key);
        return removed;
    }

    protected ICompletableFuture<Data> removeAsyncInternal(final Data key) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        RemoveOperation operation = new RemoveOperation(name, key);
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            ICompletableFuture<Data> future
                    = nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
            invalidateNearCache(key);
            return future;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected boolean containsKeyInternal(Data key) {
        if (isKeyInNearCache(key)) {
            return true;
        }
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        ContainsKeyOperation containsKeyOperation = new ContainsKeyOperation(name, key);
        containsKeyOperation.setThreadId(ThreadUtil.getThreadId());
        containsKeyOperation.setServiceName(SERVICE_NAME);
        try {
            Future f = nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, containsKeyOperation,
                    partitionId);
            return (Boolean) getService().getMapServiceContext().toObject(f.get());
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public void waitUntilLoaded() {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            OperationService operationService = nodeEngine.getOperationService();
            OperationFactory opFactory = new PartitionCheckIfLoadedOperationFactory(name);

            Map<Integer, Object> results;
            Collection<Integer> mapNamePartition = getPartitionsForKeys(singleton(toData(name)));

            results = operationService.invokeOnPartitions(SERVICE_NAME, opFactory, mapNamePartition);
            waitAllTrue(results);

            results = operationService.invokeOnAllPartitions(SERVICE_NAME, opFactory);
            waitAllTrue(results);

        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    private void waitAllTrue(Map<Integer, Object> results)
            throws InterruptedException {
        Iterator<Entry<Integer, Object>> iterator = results.entrySet().iterator();
        boolean isFinished = false;
        final Set<Integer> retrySet = new HashSet<Integer>();
        while (!isFinished) {
            while (iterator.hasNext()) {
                final Entry<Integer, Object> entry = iterator.next();
                if (Boolean.TRUE.equals(entry.getValue())) {
                    iterator.remove();
                } else {
                    retrySet.add(entry.getKey());
                }
            }
            if (retrySet.size() > 0) {
                results = retryPartitions(retrySet);
                iterator = results.entrySet().iterator();
                final int oneSecond = 1000;
                Thread.sleep(oneSecond);
                retrySet.clear();
            } else {
                isFinished = true;
            }
        }
    }

    private Map<Integer, Object> retryPartitions(Collection partitions) {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            final Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnPartitions(SERVICE_NAME, new PartitionCheckIfLoadedOperationFactory(name), partitions);
            return results;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public int size() {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME, new SizeOperationFactory(name));
            int total = 0;
            for (Object result : results.values()) {
                Integer size = (Integer) getService().getMapServiceContext().toObject(result);
                total += size;
            }
            return total;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public boolean containsValueInternal(Data dataValue) {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME, new ContainsValueOperationFactory(name, dataValue));
            for (Object result : results.values()) {
                Boolean contains = (Boolean) getService().getMapServiceContext().toObject(result);
                if (contains) {
                    return true;
                }
            }
            return false;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public boolean isEmpty() {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            
            
            
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME,
                            new IsEmptyOperationFactory(name));
            for (Object result : results.values()) {
                if (!(Boolean) getService().getMapServiceContext().toObject(result)) {
                    return false;
                }
            }
            return true;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    protected Map<Object, Object> getAllObjectInternal(final Set<Data> keys) {
        if (keys == null || keys.isEmpty()) {
            return Collections.emptyMap();
        }
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        Map<Object, Object> result = new HashMap<Object, Object>();
        final boolean nearCacheEnabled = getMapConfig().isNearCacheEnabled();
        if (nearCacheEnabled) {
            getFromNearCache(result, keys);
        }
        if (keys.isEmpty()) {
            return result;
        }
        Collection<Integer> partitions = getPartitionsForKeys(keys);
        Map<Integer, Object> responses;
        try {
            responses = nodeEngine.getOperationService()
                    .invokeOnPartitions(SERVICE_NAME, new MapGetAllOperationFactory(name, keys), partitions);
            for (Object response : responses.values()) {
                Set<Map.Entry<Data, Data>> entries
                        = ((MapEntrySet) mapService.getMapServiceContext().toObject(response)).getEntrySet();
                for (Entry<Data, Data> entry : entries) {
                    result.put(mapService.getMapServiceContext().toObject(entry.getKey()),
                            mapService.getMapServiceContext().toObject(entry.getValue()));
                    if (nearCacheEnabled) {
                        if (notOwnerPartitionForKey(entry.getKey())
                                || cacheKeyAnyway()) {
                            putNearCache(entry.getKey(), entry.getValue());
                        }
                    }
                }
            }
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }

        return result;
    }

    private Collection<Integer> getPartitionsForKeys(Set<Data> keys) {

        int partitions = partitionService.getPartitionCount();
        
        int capacity = Math.min(partitions, keys.size());
        Set<Integer> partitionIds = new HashSet<Integer>(capacity);

        Iterator<Data> iterator = keys.iterator();
        while (iterator.hasNext() && partitionIds.size() < partitions) {
            Data key = iterator.next();
            partitionIds.add(partitionService.getPartitionId(key));
        }
        return partitionIds;
    }

    private Map<Integer, List<Data>> getPartitionIdToKeysMap(Iterable<Data> keys) {
        if (keys == null) {
            return Collections.emptyMap();
        }
        final InternalPartitionService partitionService = getNodeEngine().getPartitionService();
        final Map<Integer, List<Data>> idToKeys = new HashMap<Integer, List<Data>>();

        final Iterator<Data> iterator = keys.iterator();
        while (iterator.hasNext()) {
            final Data key = iterator.next();
            final int partitionId = partitionService.getPartitionId(key);
            List<Data> keyList = idToKeys.get(partitionId);
            if (keyList == null) {
                keyList = new ArrayList<Data>();
                idToKeys.put(partitionId, keyList);
            }
            keyList.add(key);
        }
        return idToKeys;
    }

    protected void putAllInternal(final Map<? extends Object, ? extends Object> entries) {
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        int factor = 3;
        InternalPartitionService partitionService = nodeEngine.getPartitionService();
        OperationService operationService = nodeEngine.getOperationService();
        int partitionCount = partitionService.getPartitionCount();
        boolean tooManyEntries = entries.size() > (partitionCount * factor);
        try {
            if (tooManyEntries) {
                List<Future> futures = new LinkedList<Future>();
                Map<Integer, MapEntrySet> entryMap
                        = new HashMap<Integer, MapEntrySet>(nodeEngine.getPartitionService().getPartitionCount());
                for (Entry entry : entries.entrySet()) {
                    checkNotNull(entry.getKey(), NULL_KEY_IS_NOT_ALLOWED);
                    checkNotNull(entry.getValue(), NULL_VALUE_IS_NOT_ALLOWED);

                    int partitionId = partitionService.getPartitionId(entry.getKey());
                    if (!entryMap.containsKey(partitionId)) {
                        entryMap.put(partitionId, new MapEntrySet());
                    }
                    entryMap.get(partitionId).add(
                            new AbstractMap.SimpleImmutableEntry<Data, Data>(mapService.getMapServiceContext().toData(
                                    entry.getKey(),
                                    partitionStrategy),
                                    mapService.getMapServiceContext()
                                            .toData(entry.getValue())
                            ));
                }

                for (final Map.Entry<Integer, MapEntrySet> entry : entryMap.entrySet()) {
                    final Integer partitionId = entry.getKey();
                    final PutAllOperation op = new PutAllOperation(name, entry.getValue());
                    op.setPartitionId(partitionId);
                    futures.add(operationService.invokeOnPartition(SERVICE_NAME, op, partitionId));
                }

                for (Future future : futures) {
                    future.get();
                }

            } else {
                for (Entry entry : entries.entrySet()) {
                    checkNotNull(entry.getKey(), NULL_KEY_IS_NOT_ALLOWED);
                    checkNotNull(entry.getValue(), NULL_VALUE_IS_NOT_ALLOWED);

                    putInternal(mapService.getMapServiceContext().toData(entry.getKey(), partitionStrategy),
                            mapService.getMapServiceContext().toData(entry.getValue()),
                            -1,
                            TimeUnit.MILLISECONDS);
                }
            }
        } catch (Exception e) {
            throw ExceptionUtil.rethrow(e);
        }
    }

    public void flush() {
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            
            nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME,
                            new BinaryOperationFactory(new MapFlushOperation(name), nodeEngine));
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public void clearInternal() {
        final String mapName = name;
        final NodeEngine nodeEngine = getNodeEngine();
        try {
            ClearOperation clearOperation = new ClearOperation(mapName);
            clearOperation.setServiceName(SERVICE_NAME);
            final Map<Integer, Object> resultMap = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME, new BinaryOperationFactory(clearOperation, nodeEngine));

            int numberOfAffectedEntries = 0;
            for (Object o : resultMap.values()) {
                numberOfAffectedEntries += (Integer) o;
            }
            if (numberOfAffectedEntries > 0) {
                publishMapEvent(numberOfAffectedEntries, EntryEventType.CLEAR_ALL);
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public String addMapInterceptorInternal(MapInterceptor interceptor) {
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        if (interceptor instanceof HazelcastInstanceAware) {
            ((HazelcastInstanceAware) interceptor).setHazelcastInstance(nodeEngine.getHazelcastInstance());
        }
        String id = mapServiceContext.generateInterceptorId(name, interceptor);
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        for (MemberImpl member : members) {
            try {
                Future f = nodeEngine.getOperationService()
                        .invokeOnTarget(SERVICE_NAME, new AddInterceptorOperation(id, interceptor, name),
                                member.getAddress());
                f.get();
            } catch (Throwable t) {
                throw ExceptionUtil.rethrow(t);
            }
        }
        return id;
    }

    public void removeMapInterceptorInternal(String id) {
        final NodeEngine nodeEngine = getNodeEngine();
        final MapService mapService = getService();
        mapService.getMapServiceContext().removeInterceptor(name, id);
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        for (Member member : members) {
            try {
                if (member.localMember()) {
                    continue;
                }
                MemberImpl memberImpl = (MemberImpl) member;
                Future f = nodeEngine.getOperationService()
                        .invokeOnTarget(SERVICE_NAME, new RemoveInterceptorOperation(name, id), memberImpl.getAddress());
                f.get();
            } catch (Throwable t) {
                throw ExceptionUtil.rethrow(t);
            }
        }
    }

    public String addLocalEntryListenerInternal(final Object listener) {
        final MapService mapService = getService();
        return mapService.getMapServiceContext().addLocalEventListener(listener, name);
    }

    public String addLocalEntryListenerInternal(Object listener, Predicate predicate,
                                                final Data key, boolean includeValue) {

        final MapService mapService = getService();
        EventFilter eventFilter = new QueryEventFilter(includeValue, key, predicate);
        return mapService.getMapServiceContext().addLocalEventListener(listener, eventFilter, name);
    }

    protected String addEntryListenerInternal(
            final Object listener, final Data key, final boolean includeValue) {
        EventFilter eventFilter = new EntryEventFilter(includeValue, key);
        final MapService mapService = getService();
        return mapService.getMapServiceContext().addEventListener(listener, eventFilter, name);
    }

    protected String addEntryListenerInternal(
            Object listener, Predicate predicate, final Data key, final boolean includeValue) {
        EventFilter eventFilter = new QueryEventFilter(includeValue, key, predicate);
        final MapService mapService = getService();
        return mapService.getMapServiceContext().addEventListener(listener, eventFilter, name);
    }

    protected boolean removeEntryListenerInternal(String id) {
        final MapService mapService = getService();
        return mapService.getMapServiceContext().removeEventListener(name, id);
    }

    protected String addPartitionLostListenerInternal(MapPartitionLostListener listener) {
        final MapService mapService = getService();
        return mapService.getMapServiceContext().addPartitionLostListener(listener, name);
    }

    protected boolean removePartitionLostListenerInternal(String id) {
        final MapService mapService = getService();
        return mapService.getMapServiceContext().removePartitionLostListener(name, id);
    }

    protected EntryView getEntryViewInternal(final Data key) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        GetEntryViewOperation operation = new GetEntryViewOperation(name, key);
        operation.setThreadId(ThreadUtil.getThreadId());
        operation.setServiceName(SERVICE_NAME);
        try {
            Future f = nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
            Object o = getService().getMapServiceContext().toObject(f.get());
            return (EntryView) o;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public Data executeOnKeyInternal(Data key, EntryProcessor entryProcessor) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        EntryOperation operation = new EntryOperation(name, key, entryProcessor);
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            Future future = nodeEngine.getOperationService()
                    .createInvocationBuilder(SERVICE_NAME, operation, partitionId)
                    .setResultDeserialized(false)
                    .invoke();
            final Data data = (Data) future.get();
            invalidateNearCache(key);
            return data;
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public Map executeOnKeysInternal(Set<Data> keys, EntryProcessor entryProcessor) {
        
        
        Map result = new HashMap();
        final NodeEngine nodeEngine = getNodeEngine();
        final Collection<Integer> partitionsForKeys = getPartitionsForKeys(keys);
        try {
            MultipleEntryOperationFactory operationFactory = new MultipleEntryOperationFactory(name, keys, entryProcessor);
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnPartitions(SERVICE_NAME, operationFactory, partitionsForKeys);
            for (Object o : results.values()) {
                if (o != null) {
                    final MapService service = getService();
                    final MapEntrySet mapEntrySet = (MapEntrySet) o;
                    for (Entry<Data, Data> entry : mapEntrySet.getEntrySet()) {
                        result.put(service.getMapServiceContext().toObject(entry.getKey()),
                                service.getMapServiceContext().toObject(entry.getValue()));
                    }
                }
            }
            invalidateNearCache(keys);
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
        return result;
    }

    public ICompletableFuture executeOnKeyInternal(Data key, EntryProcessor entryProcessor, ExecutionCallback callback) {
        final NodeEngine nodeEngine = getNodeEngine();
        int partitionId = nodeEngine.getPartitionService().getPartitionId(key);
        EntryOperation operation = new EntryOperation(name, key, entryProcessor);
        operation.setThreadId(ThreadUtil.getThreadId());
        try {
            if (callback == null) {
                return nodeEngine.getOperationService().invokeOnPartition(SERVICE_NAME, operation, partitionId);
            } else {
                ICompletableFuture future = nodeEngine.getOperationService()
                        .createInvocationBuilder(SERVICE_NAME, operation, partitionId)
                        .setCallback(new MapExecutionCallbackAdapter(callback))
                        .invoke();
                invalidateNearCache(key);
                return future;
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    
    
    public Map executeOnEntries(EntryProcessor entryProcessor) {
        return executeOnEntries(entryProcessor, TruePredicate.INSTANCE);
    }

    
    
    public Map executeOnEntries(EntryProcessor entryProcessor, Predicate predicate) {
        Map result = new HashMap();
        try {
            NodeEngine nodeEngine = getNodeEngine();
            Map<Integer, Object> results = nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME,
                            new PartitionWideEntryWithPredicateOperationFactory(name,
                                    entryProcessor,
                                    predicate)
                    );
            for (Object o : results.values()) {
                if (o != null) {
                    final MapService service = getService();
                    final MapEntrySet mapEntrySet = (MapEntrySet) o;
                    for (Entry<Data, Data> entry : mapEntrySet.getEntrySet()) {
                        final Data key = entry.getKey();
                        result.put(service.getMapServiceContext().toObject(key),
                                service.getMapServiceContext().toObject(entry.getValue()));
                        invalidateNearCache(key);
                    }
                }
            }
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
        return result;
    }

    protected Object toObject(Object obj) {
        return getService().getMapServiceContext().toObject(obj);
    }

    protected Data toData(Object obj) {
        return getService().getMapServiceContext().toData(obj);
    }

    protected Data toData(Object o, PartitioningStrategy partitioningStrategy) {
        return getService().getMapServiceContext().toData(o, partitioningStrategy);
    }

    protected Set queryLocal(final Predicate predicate, final IterationType iterationType, final boolean dataResult) {
        if (predicate instanceof PagingPredicate) {
            return getMapQuerySupport().queryLocalMemberWithPagingPredicate(name, (PagingPredicate) predicate, iterationType);
        }
        return getMapQuerySupport().queryLocalMember(name, predicate, iterationType, dataResult);
    }

    protected Set query(final Predicate predicate, final IterationType iterationType, final boolean dataResult) {
        if (predicate instanceof PagingPredicate) {
            return getMapQuerySupport().queryWithPagingPredicate(name, (PagingPredicate) predicate, iterationType);
        }
        return getMapQuerySupport().query(name, predicate, iterationType, dataResult);
    }

    public void addIndex(final String attribute, final boolean ordered) {
        final NodeEngine nodeEngine = getNodeEngine();
        if (attribute == null) {
            throw new IllegalArgumentException("Attribute name cannot be null");
        }
        try {
            AddIndexOperation addIndexOperation = new AddIndexOperation(name, attribute, ordered);
            nodeEngine.getOperationService()
                    .invokeOnAllPartitions(SERVICE_NAME, new BinaryOperationFactory(addIndexOperation, nodeEngine));
        } catch (Throwable t) {
            throw ExceptionUtil.rethrow(t);
        }
    }

    public LocalMapStats getLocalMapStats() {
        return getService().getMapServiceContext().getLocalMapStatsProvider().createLocalMapStats(name);
    }

    private boolean isKeyInNearCache(Data key) {
        final MapService mapService = getService();
        final boolean nearCacheEnabled = getMapConfig().isNearCacheEnabled();
        if (nearCacheEnabled) {
            Object cached = mapService.getMapServiceContext().getNearCacheProvider().getFromNearCache(name, key);
            if (cached != null && !cached.equals(NearCache.NULL_OBJECT)) {
                return true;
            }
        }
        return false;
    }

    private void invalidateNearCache(Data key) {
        if (key == null) {
            return;
        }
        getService().getMapServiceContext().getNearCacheProvider().invalidateNearCache(name, key);
    }

    private void invalidateNearCache(Collection<Data> keys) {
        if (keys == null || keys.isEmpty()) {
            return;
        }
        getService().getMapServiceContext().getNearCacheProvider().invalidateNearCache(name, keys);
    }

    private void clearNearCache() {
        getService().getMapServiceContext().getNearCacheProvider().clearNearCache(name);
    }

    private void publishMapEvent(int numberOfAffectedEntries, EntryEventType eventType) {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final MapEventPublisher mapEventPublisher = mapServiceContext.getMapEventPublisher();
        mapEventPublisher.publishMapEvent(getNodeEngine().getThisAddress(), name, eventType, numberOfAffectedEntries);
    }

    protected long getTimeInMillis(final long time, final TimeUnit timeunit) {
        long timeInMillis = timeunit.toMillis(time);
        if (time > 0 && timeInMillis == 0) {
            timeInMillis = 1;
        }
        return timeInMillis;
    }

    private MapContextQuerySupport getMapQuerySupport() {
        return getService().getMapServiceContext().getMapContextQuerySupport();
    }

    protected MapStore getMapStore() {
        final MapService service = getService();
        final MapServiceContext mapServiceContext = service.getMapServiceContext();
        final MapContainer mapContainer = mapServiceContext.getMapContainer(name);
        return mapContainer.getMapStoreContext().getMapStoreWrapper();

    }

    private MapConfig getMapConfig() {
        final MapService mapService = getService();
        final MapServiceContext mapServiceContext = mapService.getMapServiceContext();
        final MapContainer mapContainer = mapServiceContext.getMapContainer(name);
        return mapContainer.getMapConfig();
    }

    @Override
    public final String getName() {
        return name;
    }

    @Override
    public final String getServiceName() {
        return SERVICE_NAME;
    }

    private class MapExecutionCallbackAdapter implements Callback {

        private final ExecutionCallback executionCallback;

        public MapExecutionCallbackAdapter(ExecutionCallback executionCallback) {
            this.executionCallback = executionCallback;
        }

        @Override
        public void notify(Object response) {
            if (response instanceof Throwable) {
                executionCallback.onFailure((Throwable) response);
            } else {
                executionCallback.onResponse(getService().getMapServiceContext().toObject(response));
            }
        }
    }

    public PartitioningStrategy getPartitionStrategy() {
        return partitionStrategy;
    }
}


<code block>


package com.hazelcast.client.impl.protocol.task;

import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.client.impl.protocol.ClientMessage;
import com.hazelcast.instance.Node;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.Connection;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationFactory;
import com.hazelcast.spi.impl.operationservice.InternalOperationService;

import java.util.Collection;
import java.util.HashSet;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

import static java.util.Collections.EMPTY_MAP;
import static java.util.Collections.synchronizedSet;

public abstract class AbstractMultiTargetMessageTask<P> extends AbstractMessageTask<P> {

    private static final int TRY_COUNT = 100;

    protected AbstractMultiTargetMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
        super(clientMessage, node, connection);
    }

    @Override
    protected void processMessage() {
        ClientEndpoint endpoint = getEndpoint();
        OperationFactory operationFactory = createOperationFactory();
        Collection<Address> targets = getTargets();

        if (returnResponseIfNoTargetLeft(targets, EMPTY_MAP)) {
            return;
        }

        final InternalOperationService operationService = nodeEngine.getOperationService();

        MultiTargetCallback callback = new MultiTargetCallback(targets);
        for (Address target : targets) {
            Operation op = operationFactory.createOperation();
            op.setCallerUuid(endpoint.getUuid());
            InvocationBuilder builder = operationService.createInvocationBuilder(getServiceName(), op, target)
                    .setTryCount(TRY_COUNT)
                    .setResultDeserialized(false)
                    .setCallback(new SingleTargetCallback(target, callback));
            builder.invoke();
        }
    }

    private boolean returnResponseIfNoTargetLeft(Collection<Address> targets, Map<Address, Object> results) {
        if (targets.isEmpty()) {
            try {
                sendResponse(reduce(results));
            } catch (Throwable throwable) {
                sendClientMessage(throwable);
            }
            return true;
        }
        return false;
    }

    protected abstract OperationFactory createOperationFactory();

    protected abstract Object reduce(Map<Address, Object> map) throws Throwable;

    public abstract Collection<Address> getTargets();

    private final class MultiTargetCallback {

        final Collection<Address> targets;
        final Map<Address, Object> results;

        private MultiTargetCallback(Collection<Address> targets) {
            this.targets = synchronizedSet(new HashSet<Address>(targets));
            this.results = new ConcurrentHashMap<Address, Object>(targets.size());
        }

        public void notify(Address target, Object result) {
            if (targets.remove(target)) {
                results.put(target, result);
            } else {
                if (results.containsKey(target)) {
                    throw new IllegalArgumentException("Duplicate response from -> " + target);
                }
                throw new IllegalArgumentException("Unknown target! -> " + target);
            }
            returnResponseIfNoTargetLeft(targets, results);
        }
    }

    private final class SingleTargetCallback implements Callback<Object> {

        final Address target;
        final MultiTargetCallback parent;

        private SingleTargetCallback(Address target, MultiTargetCallback parent) {
            this.target = target;
            this.parent = parent;
        }

        @Override
        public void notify(Object object) {
            parent.notify(target, object);
        }
    }
}

<code block>


package com.hazelcast.client.impl.client;

import com.hazelcast.client.ClientEndpoint;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.Callback;
import com.hazelcast.spi.InvocationBuilder;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.OperationFactory;

import java.util.Collection;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

import static java.util.Collections.synchronizedSet;


public abstract class MultiTargetClientRequest extends ClientRequest {

    @Override
    public final void process() throws Exception {
        ClientEndpoint endpoint = getEndpoint();
        OperationFactory operationFactory = createOperationFactory();
        Collection<Address> targets = getTargets();
        if (targets.isEmpty()) {
            endpoint.sendResponse(reduce(new HashMap<Address, Object>()), getCallId());
            return;
        }

        MultiTargetCallback callback = new MultiTargetCallback(targets);
        for (Address target : targets) {
            Operation op = operationFactory.createOperation();
            op.setCallerUuid(endpoint.getUuid());
            InvocationBuilder builder = operationService.createInvocationBuilder(getServiceName(), op, target)
                    .setResultDeserialized(false)
                    .setCallback(new SingleTargetCallback(target, callback));
            builder.invoke();
        }
    }

    protected abstract OperationFactory createOperationFactory();

    protected abstract Object reduce(Map<Address, Object> map);

    public abstract Collection<Address> getTargets();

    private final class MultiTargetCallback {

        final Collection<Address> targets;
        final ConcurrentMap<Address, Object> results;

        private MultiTargetCallback(Collection<Address> targets) {
            this.targets = synchronizedSet(new HashSet<Address>(targets));
            this.results = new ConcurrentHashMap<Address, Object>(targets.size());
        }

        public void notify(Address target, Object result) {
            if (targets.remove(target)) {
                results.put(target, result);
            } else {
                if (results.containsKey(target)) {
                    throw new IllegalArgumentException("Duplicate response from -> " + target);
                }
                throw new IllegalArgumentException("Unknown target! -> " + target);
            }
            if (targets.isEmpty()) {
                Object response = reduce(results);
                endpoint.sendResponse(response, getCallId());
            }
        }
    }

    private static final class SingleTargetCallback implements Callback<Object> {

        final Address target;
        final MultiTargetCallback parent;

        private SingleTargetCallback(Address target, MultiTargetCallback parent) {
            this.target = target;
            this.parent = parent;
        }

        @Override
        public void notify(Object object) {
            parent.notify(target, object);
        }
    }
}

<code block>


package com.hazelcast.executor.impl;

import com.hazelcast.core.ExecutionCallback;
import com.hazelcast.core.HazelcastInstanceNotActiveException;
import com.hazelcast.core.ICompletableFuture;
import com.hazelcast.core.IExecutorService;
import com.hazelcast.core.Member;
import com.hazelcast.core.MemberSelector;
import com.hazelcast.core.MultiExecutionCallback;
import com.hazelcast.core.PartitionAware;
import com.hazelcast.executor.impl.operations.CallableTaskOperation;
import com.hazelcast.executor.impl.operations.MemberCallableTaskOperation;
import com.hazelcast.executor.impl.operations.ShutdownOperation;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.logging.ILogger;
import com.hazelcast.monitor.LocalExecutorStats;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.spi.AbstractDistributedObject;
import com.hazelcast.spi.ExecutionService;
import com.hazelcast.spi.InternalCompletableFuture;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.OperationService;
import com.hazelcast.util.Clock;
import com.hazelcast.util.executor.CompletedFuture;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.RejectedExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
import java.util.logging.Level;

import static com.hazelcast.util.FutureUtil.ExceptionHandler;
import static com.hazelcast.util.FutureUtil.logAllExceptions;
import static com.hazelcast.util.FutureUtil.waitWithDeadline;
import static com.hazelcast.util.Preconditions.checkNotNull;
import static com.hazelcast.util.UuidUtil.buildRandomUuidString;

public class ExecutorServiceProxy
        extends AbstractDistributedObject<DistributedExecutorService>
        implements IExecutorService {

    public static final int SYNC_FREQUENCY = 100;
    public static final int SYNC_DELAY_MS = 10;

    private static final AtomicIntegerFieldUpdater<ExecutorServiceProxy> CONSECUTIVE_SUBMITS_UPDATER = AtomicIntegerFieldUpdater
            .newUpdater(ExecutorServiceProxy.class, "consecutiveSubmits");

    private static final ExceptionHandler WHILE_SHUTDOWN_EXCEPTION_HANDLER =
            logAllExceptions("Exception while ExecutorService shutdown", Level.FINEST);

    private final String name;
    private final Random random = new Random(-System.currentTimeMillis());
    private final int partitionCount;
    private final ILogger logger;

    
    private volatile int consecutiveSubmits;

    private volatile long lastSubmitTime;

    public ExecutorServiceProxy(String name, NodeEngine nodeEngine, DistributedExecutorService service) {
        super(nodeEngine, service);
        this.name = name;
        this.partitionCount = nodeEngine.getPartitionService().getPartitionCount();
        this.logger = nodeEngine.getLogger(ExecutorServiceProxy.class);
        getLocalExecutorStats();
    }

    @Override
    public void execute(Runnable command, MemberSelector memberSelector) {
        List<Member> members = selectMembers(memberSelector);
        int selectedMember = random.nextInt(members.size());
        executeOnMember(command, members.get(selectedMember));
    }

    @Override
    public void executeOnMembers(Runnable command, MemberSelector memberSelector) {
        List<Member> members = selectMembers(memberSelector);
        executeOnMembers(command, members);
    }

    @Override
    public <T> Future<T> submit(Callable<T> task, MemberSelector memberSelector) {
        List<Member> members = selectMembers(memberSelector);
        int selectedMember = random.nextInt(members.size());
        return submitToMember(task, members.get(selectedMember));
    }

    @Override
    public <T> Map<Member, Future<T>> submitToMembers(Callable<T> task, MemberSelector memberSelector) {
        List<Member> members = selectMembers(memberSelector);
        return submitToMembers(task, members);
    }

    @Override
    public void submit(Runnable task, MemberSelector memberSelector, ExecutionCallback callback) {
        List<Member> members = selectMembers(memberSelector);
        int selectedMember = random.nextInt(members.size());
        submitToMember(task, members.get(selectedMember), callback);
    }

    @Override
    public void submitToMembers(Runnable task, MemberSelector memberSelector, MultiExecutionCallback callback) {
        List<Member> members = selectMembers(memberSelector);
        submitToMembers(task, members, callback);
    }

    @Override
    public <T> void submit(Callable<T> task, MemberSelector memberSelector, ExecutionCallback<T> callback) {
        List<Member> members = selectMembers(memberSelector);
        int selectedMember = random.nextInt(members.size());
        submitToMember(task, members.get(selectedMember), callback);
    }

    @Override
    public <T> void submitToMembers(Callable<T> task, MemberSelector memberSelector, MultiExecutionCallback callback) {
        List<Member> members = selectMembers(memberSelector);
        submitToMembers(task, members, callback);
    }

    @Override
    public void execute(Runnable command) {
        Callable<?> callable = createRunnableAdapter(command);
        submit(callable);
    }

    private <T> RunnableAdapter<T> createRunnableAdapter(Runnable command) {
        checkNotNull(command, "Command can't be null");

        return new RunnableAdapter<T>(command);
    }

    @Override
    public void executeOnKeyOwner(Runnable command, Object key) {
        Callable<?> callable = createRunnableAdapter(command);
        submitToKeyOwner(callable, key);
    }

    @Override
    public void executeOnMember(Runnable command, Member member) {
        Callable<?> callable = createRunnableAdapter(command);
        submitToMember(callable, member);
    }

    @Override
    public void executeOnMembers(Runnable command, Collection<Member> members) {
        Callable<?> callable = createRunnableAdapter(command);
        submitToMembers(callable, members);
    }

    @Override
    public void executeOnAllMembers(Runnable command) {
        Callable<?> callable = createRunnableAdapter(command);
        submitToAllMembers(callable);
    }

    @Override
    public Future<?> submit(Runnable task) {
        Callable<?> callable = createRunnableAdapter(task);
        return submit(callable);
    }

    @Override
    public <T> Future<T> submit(Runnable task, T result) {
        checkNotNull(task, "task can't be null");
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Callable<T> callable = createRunnableAdapter(task);
        Data callableData = nodeEngine.toData(callable);
        String uuid = buildRandomUuidString();
        int partitionId = getTaskPartitionId(callable);

        CallableTaskOperation op = new CallableTaskOperation(name, uuid, callableData);
        ICompletableFuture future = invoke(partitionId, op);
        boolean sync = checkSync();
        if (sync) {
            try {
                future.get();
            } catch (Exception exception) {
                logger.warning(exception);
            }
            return new CompletedFuture<T>(nodeEngine.getSerializationService(), result, getAsyncExecutor());
        }
        return new CancellableDelegatingFuture<T>(future, result, nodeEngine, uuid, partitionId);
    }

    private void checkNotShutdown() {
        if (isShutdown()) {
            throw new RejectedExecutionException(getRejectionMessage());
        }
    }

    private InternalCompletableFuture invoke(int partitionId, CallableTaskOperation op) {
        NodeEngine nodeEngine = getNodeEngine();
        OperationService operationService = nodeEngine.getOperationService();
        return operationService.invokeOnPartition(DistributedExecutorService.SERVICE_NAME, op, partitionId);
    }

    @Override
    public <T> Future<T> submit(Callable<T> task) {
        final int partitionId = getTaskPartitionId(task);
        return submitToPartitionOwner(task, partitionId, false);
    }

    private <T> Future<T> submitToPartitionOwner(Callable<T> task, int partitionId, boolean preventSync) {
        checkNotNull(task, "task can't be null");
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Data taskData = nodeEngine.toData(task);
        String uuid = buildRandomUuidString();

        boolean sync = !preventSync && checkSync();
        CallableTaskOperation op = new CallableTaskOperation(name, uuid, taskData);
        ICompletableFuture future = invoke(partitionId, op);
        if (sync) {
            Object response;
            try {
                response = future.get();
            } catch (Exception e) {
                response = e;
            }
            return new CompletedFuture<T>(nodeEngine.getSerializationService(), response, getAsyncExecutor());
        }
        return new CancellableDelegatingFuture<T>(future, nodeEngine, uuid, partitionId);
    }

    
    private boolean checkSync() {
        boolean sync = false;
        long last = lastSubmitTime;
        long now = Clock.currentTimeMillis();
        if (last + SYNC_DELAY_MS < now) {
            CONSECUTIVE_SUBMITS_UPDATER.set(this, 0);
        } else if (CONSECUTIVE_SUBMITS_UPDATER.incrementAndGet(this) % SYNC_FREQUENCY == 0) {
            sync = true;
        }
        lastSubmitTime = now;
        return sync;
    }

    private <T> int getTaskPartitionId(Callable<T> task) {
        if (task instanceof PartitionAware) {
            Object partitionKey = ((PartitionAware) task).getPartitionKey();
            if (partitionKey != null) {
                return getNodeEngine().getPartitionService().getPartitionId(partitionKey);
            }
        }
        return random.nextInt(partitionCount);
    }

    @Override
    public <T> Future<T> submitToKeyOwner(Callable<T> task, Object key) {
        NodeEngine nodeEngine = getNodeEngine();
        return submitToPartitionOwner(task, nodeEngine.getPartitionService().getPartitionId(key), false);
    }

    @Override
    public <T> Future<T> submitToMember(Callable<T> task, Member member) {
        checkNotNull(task, "task can't be null");
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Data taskData = nodeEngine.toData(task);
        String uuid = buildRandomUuidString();
        Address target = ((MemberImpl) member).getAddress();

        boolean sync = checkSync();
        MemberCallableTaskOperation op = new MemberCallableTaskOperation(name, uuid, taskData);
        InternalCompletableFuture future = nodeEngine.getOperationService()
                .invokeOnTarget(DistributedExecutorService.SERVICE_NAME, op, target);
        if (sync) {
            Object response;
            try {
                response = future.get();
            } catch (Exception e) {
                response = e;
            }
            return new CompletedFuture<T>(nodeEngine.getSerializationService(), response, getAsyncExecutor());
        }
        return new CancellableDelegatingFuture<T>(future, nodeEngine, uuid, target);
    }

    @Override
    public <T> Map<Member, Future<T>> submitToMembers(Callable<T> task, Collection<Member> members) {
        Map<Member, Future<T>> futures = new HashMap<Member, Future<T>>(members.size());
        for (Member member : members) {
            futures.put(member, submitToMember(task, member));
        }
        return futures;
    }

    @Override
    public <T> Map<Member, Future<T>> submitToAllMembers(Callable<T> task) {
        NodeEngine nodeEngine = getNodeEngine();
        return submitToMembers(task, nodeEngine.getClusterService().getMembers());
    }

    @Override
    public void submit(Runnable task, ExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submit(callable, callback);
    }

    @Override
    public void submitToKeyOwner(Runnable task, Object key, ExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submitToKeyOwner(callable, key, callback);
    }

    @Override
    public void submitToMember(Runnable task, Member member, ExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submitToMember(callable, member, callback);
    }

    @Override
    public void submitToMembers(Runnable task, Collection<Member> members, MultiExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submitToMembers(callable, members, callback);
    }

    @Override
    public void submitToAllMembers(Runnable task, MultiExecutionCallback callback) {
        Callable<?> callable = createRunnableAdapter(task);
        submitToAllMembers(callable, callback);
    }

    private <T> void submitToPartitionOwner(Callable<T> task, ExecutionCallback<T> callback, int partitionId) {
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Data taskData = nodeEngine.toData(task);
        CallableTaskOperation op = new CallableTaskOperation(name, null, taskData);
        OperationService operationService = nodeEngine.getOperationService();
        operationService.createInvocationBuilder(DistributedExecutorService.SERVICE_NAME, op, partitionId)
                .setCallback(new ExecutionCallbackAdapter(callback)).invoke();
    }

    @Override
    public <T> void submit(Callable<T> task, ExecutionCallback<T> callback) {
        int partitionId = getTaskPartitionId(task);
        submitToPartitionOwner(task, callback, partitionId);
    }

    @Override
    public <T> void submitToKeyOwner(Callable<T> task, Object key, ExecutionCallback<T> callback) {
        NodeEngine nodeEngine = getNodeEngine();
        submitToPartitionOwner(task, callback, nodeEngine.getPartitionService().getPartitionId(key));
    }

    @Override
    public <T> void submitToMember(Callable<T> task, Member member, ExecutionCallback<T> callback) {
        checkNotShutdown();

        NodeEngine nodeEngine = getNodeEngine();
        Data taskData = nodeEngine.toData(task);
        MemberCallableTaskOperation op = new MemberCallableTaskOperation(name, null, taskData);
        OperationService operationService = nodeEngine.getOperationService();
        Address address = ((MemberImpl) member).getAddress();
        operationService.createInvocationBuilder(DistributedExecutorService.SERVICE_NAME, op, address)
                .setCallback(new ExecutionCallbackAdapter(callback)).invoke();
    }

    private String getRejectionMessage() {
        return "ExecutorService[" + name + "] is shutdown! In order to create a new ExecutorService with name '" + name
                + "', you need to destroy current ExecutorService first!";
    }

    @Override
    public <T> void submitToMembers(Callable<T> task, Collection<Member> members, MultiExecutionCallback callback) {
        NodeEngine nodeEngine = getNodeEngine();
        ExecutionCallbackAdapterFactory executionCallbackFactory = new ExecutionCallbackAdapterFactory(
                nodeEngine.getLogger(ExecutionCallbackAdapterFactory.class), members, callback);

        for (Member member : members) {
            submitToMember(task, member, executionCallbackFactory.<T>callbackFor(member));
        }
    }

    @Override
    public <T> void submitToAllMembers(Callable<T> task, MultiExecutionCallback callback) {
        NodeEngine nodeEngine = getNodeEngine();
        submitToMembers(task, nodeEngine.getClusterService().getMembers(), callback);
    }

    @Override
    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)
            throws InterruptedException {
        List<Future<T>> futures = new ArrayList<Future<T>>(tasks.size());
        List<Future<T>> result = new ArrayList<Future<T>>(tasks.size());
        for (Callable<T> task : tasks) {
            futures.add(submit(task));
        }
        for (Future<T> future : futures) {
            Object value;
            try {
                value = future.get();
            } catch (ExecutionException e) {
                value = e;
            }
            result.add(new CompletedFuture<T>(getNodeEngine().getSerializationService(), value, getAsyncExecutor()));
        }
        return result;
    }

    @Override
    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit)
            throws InterruptedException {
        checkNotNull(unit, "unit must not be null");
        checkNotNull(tasks, "tasks must not be null");

        long timeoutNanos = unit.toNanos(timeout);
        List<Future<T>> futures = new ArrayList<Future<T>>(tasks.size());
        boolean done = false;
        try {
            for (Callable<T> task : tasks) {
                long start = System.nanoTime();
                int partitionId = getTaskPartitionId(task);
                futures.add(submitToPartitionOwner(task, partitionId, true));
                timeoutNanos -= System.nanoTime() - start;
            }
            if (timeoutNanos <= 0L) {
                return futures;
            }

            done = wait(timeoutNanos, futures);
            return futures;
        } catch (Throwable t) {
            logger.severe(t);
            
            return futures;
        } finally {
            if (!done) {
                cancelAll(futures);
            }
        }
    }

    private <T> boolean wait(long timeoutNanos, List<Future<T>> futures) throws InterruptedException {
        boolean done = true;
        for (int i = 0, size = futures.size(); i < size; i++) {
            long start = System.nanoTime();
            Object value;
            try {
                Future<T> future = futures.get(i);
                value = future.get(timeoutNanos, TimeUnit.NANOSECONDS);
            } catch (ExecutionException e) {
                value = e;
            } catch (TimeoutException e) {
                done = false;
                for (int l = i; l < size; l++) {
                    Future<T> f = futures.get(i);
                    if (f.isDone()) {
                        Object v;
                        try {
                            v = f.get();
                        } catch (ExecutionException ex) {
                            v = ex;
                        }
                        futures.set(l, new CompletedFuture<T>(getNodeEngine().getSerializationService(), v, getAsyncExecutor()));
                    }
                }
                break;
            }

            futures.set(i, new CompletedFuture<T>(getNodeEngine().getSerializationService(), value, getAsyncExecutor()));
            timeoutNanos -= System.nanoTime() - start;
        }
        return done;
    }

    private static <T> void cancelAll(List<Future<T>> result) {
        for (Future<T> aResult : result) {
            aResult.cancel(true);
        }
    }

    @Override
    public <T> T invokeAny(Collection<? extends Callable<T>> tasks)
            throws InterruptedException, ExecutionException {
        throw new UnsupportedOperationException();
    }

    @Override
    public <T> T invokeAny(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit)
            throws InterruptedException, ExecutionException, TimeoutException {
        throw new UnsupportedOperationException();
    }

    @Override
    protected void throwNotActiveException() {
        throw new RejectedExecutionException();
    }

    @Override
    public boolean isShutdown() {
        try {
            return getService().isShutdown(name);
        } catch (HazelcastInstanceNotActiveException e) {
            return true;
        }
    }

    @Override
    public boolean isTerminated() {
        return isShutdown();
    }

    @Override
    public boolean awaitTermination(long timeout, TimeUnit unit)
            throws InterruptedException {
        return false;
    }

    @Override
    public void shutdown() {
        NodeEngine nodeEngine = getNodeEngine();
        Collection<MemberImpl> members = nodeEngine.getClusterService().getMemberList();
        OperationService operationService = nodeEngine.getOperationService();
        Collection<Future> calls = new LinkedList<Future>();

        for (MemberImpl member : members) {
            if (member.localMember()) {
                getService().shutdownExecutor(name);
            } else {
                Future f = submitShutdownOperation(operationService, member);
                calls.add(f);
            }
        }

        waitWithDeadline(calls, 1, TimeUnit.SECONDS, WHILE_SHUTDOWN_EXCEPTION_HANDLER);
    }

    private InternalCompletableFuture submitShutdownOperation(OperationService operationService, MemberImpl member) {
        ShutdownOperation op = new ShutdownOperation(name);
        return operationService.invokeOnTarget(getServiceName(), op, member.getAddress());
    }

    @Override
    public List<Runnable> shutdownNow() {
        shutdown();
        return Collections.emptyList();
    }

    @Override
    public LocalExecutorStats getLocalExecutorStats() {
        return getService().getLocalExecutorStats(name);
    }

    @Override
    public String getServiceName() {
        return DistributedExecutorService.SERVICE_NAME;
    }

    @Override
    public String getName() {
        return name;
    }

    private ExecutorService getAsyncExecutor() {
        return getNodeEngine().getExecutionService().getExecutor(ExecutionService.ASYNC_EXECUTOR);
    }

    private List<Member> selectMembers(MemberSelector memberSelector) {
        if (memberSelector == null) {
            throw new IllegalArgumentException("memberSelector must not be null");
        }
        List<Member> selected = new ArrayList<Member>();
        Collection<MemberImpl> members = getNodeEngine().getClusterService().getMemberList();
        for (MemberImpl member : members) {
            if (memberSelector.select(member)) {
                selected.add(member);
            }
        }
        if (selected.isEmpty()) {
            throw new RejectedExecutionException("No member selected with memberSelector[" + memberSelector + "]");
        }
        return selected;
    }

    @Override
    public String toString() {
        return "IExecutorService{" + "name='" + name + '\'' + '}';
    }
}
