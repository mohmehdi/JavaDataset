

package org.mapdb;

import java.io.*;
import java.lang.reflect.Method;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.MappedByteBuffer;
import java.nio.channels.ClosedByInterruptException;
import java.nio.channels.ClosedChannelException;
import java.nio.channels.FileChannel;
import java.util.Arrays;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;
import java.util.logging.Logger;


public abstract class Volume implements Closeable{

    public static abstract class VolumeFactory{
        public abstract Volume makeVolume(String file, boolean readOnly,
                                          int sliceShift, long initSize, boolean fixedSize);

        public Volume makeVolume(String file, boolean readOnly){
            return makeVolume(file,readOnly,CC.VOLUME_PAGE_SHIFT, 0, false);
        }
    }

    private static final byte[] CLEAR = new byte[1024];

    protected static final Logger LOG = Logger.getLogger(Volume.class.getName());


    public static final VolumeFactory UNSAFE_VOL_FACTORY = new VolumeFactory() {

        @Override
        public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {
            String packageName = Volume.class.getPackage().getName();
            Class clazz;
            try {
                clazz = Class.forName(packageName+".UnsafeStuff$UnsafeVolume");
            } catch (ClassNotFoundException e) {
                clazz = null;
            }

            if(clazz!=null){
                try {
                    return (Volume) clazz.getConstructor(long.class, int.class).newInstance(0L, sliceShift);
                } catch (Exception e) {
                    LOG.log(Level.WARNING, "Could not invoke UnsafeVolume constructor. " +
                            "Falling back to DirectByteBuffer",e);

                }
            }

            return MemoryVol.FACTORY.makeVolume(file, readOnly, sliceShift, initSize, fixedSize);
        }
    };

    protected volatile boolean closed;

    public boolean isClosed(){
        return closed;
    }




    @Override protected void finalize(){
        if(CC.ASSERT){
            if(!closed
                    && !(this instanceof ByteArrayVol)
                    && !(this instanceof SingleByteArrayVol)){
                LOG.log(Level.WARNING, "Open Volume was GCed, possible file handle leak."

                );
            }
        }
    }


    abstract public void ensureAvailable(final long offset);


    public abstract void truncate(long size);


    abstract public void putLong(final long offset, final long value);
    abstract public void putInt(long offset, int value);
    abstract public void putByte(final long offset, final byte value);

    abstract public void putData(final long offset, final byte[] src, int srcPos, int srcSize);
    abstract public void putData(final long offset, final ByteBuffer buf);

    public void putDataOverlap(final long offset, final byte[] src, int srcPos, int srcSize){
        putData(offset,src,srcPos,srcSize);
    }


    abstract public long getLong(final long offset);
    abstract public int getInt(long offset);
    abstract public byte getByte(final long offset);



    abstract public DataInput getDataInput(final long offset, final int size);
    public DataInput getDataInputOverlap(final long offset, final int size){
        return getDataInput(offset,size);
    }

    abstract public void getData(long offset, byte[] bytes, int bytesPos, int size);

    abstract public void close();

    abstract public void sync();


    abstract public int sliceSize();

    public abstract boolean isEmpty();

    public void deleteFile(){
        File f = getFile();
        if(f!=null && !f.delete()){
            LOG.warning("Could not delete file: "+f);
        }
    }

    public abstract boolean isSliced();

    public abstract long length();

    public void putUnsignedShort(final long offset, final int value){
        putByte(offset, (byte) (value>>8));
        putByte(offset+1, (byte) (value));
    }

    public int getUnsignedShort(long offset) {
        return (( (getByte(offset) & 0xff) << 8) |
                ( (getByte(offset+1) & 0xff)));
    }

    public int getUnsignedByte(long offset) {
        return getByte(offset) & 0xff;
    }

    public void putUnsignedByte(long offset, int b) {
        putByte(offset, (byte) (b & 0xff));
    }


    public int putLongPackBidi(long offset, long value) {
        putUnsignedByte(offset++, (((int) value & 0x7F)) | 0x80);
        value >>>= 7;
        int counter = 2;


        while ((value & ~0x7FL) != 0) {
            putUnsignedByte(offset++, (((int) value & 0x7F)));
            value >>>= 7;

            counter++;
        }

        putUnsignedByte(offset, (byte) value | 0x80);
        return counter;
    }

    public long getLongPackBidi(long offset){

        long b = getUnsignedByte(offset++); 
        if(CC.ASSERT && (b&0x80)==0)
            throw new AssertionError();
        long result = (b & 0x7F) ;
        int shift = 7;
        do {

            b = getUnsignedByte(offset++);
            result |= (b & 0x7F) << shift;
            if(CC.ASSERT && shift>64)
                throw new AssertionError();
            shift += 7;
        }while((b & 0x80) == 0);

        return (((long)(shift/7))<<56) | result;
    }

    public long getLongPackBidiReverse(long offset){

        long b = getUnsignedByte(--offset);
        if(CC.ASSERT && (b&0x80)==0)
            throw new AssertionError();
        long result = (b & 0x7F) ;
        int counter = 1;
        do {

            b = getUnsignedByte(--offset);
            result = (b & 0x7F) | (result<<7);
            if(CC.ASSERT && counter>8)
                throw new AssertionError();
            counter++;
        }while((b & 0x80) == 0);

        return (((long)counter)<<56) | result;
    }

    public long getSixLong(long pos) {
        return
                ((long) (getByte(pos++) & 0xff) << 40) |
                        ((long) (getByte(pos++) & 0xff) << 32) |
                        ((long) (getByte(pos++) & 0xff) << 24) |
                        ((long) (getByte(pos++) & 0xff) << 16) |
                        ((long) (getByte(pos++) & 0xff) << 8) |
                        ((long) (getByte(pos) & 0xff));
    }

    public void putSixLong(long pos, long value) {
        if(CC.ASSERT && (value>>>48!=0))
            throw new AssertionError();

        putByte(pos++, (byte) (0xff & (value >> 40)));
        putByte(pos++, (byte) (0xff & (value >> 32)));
        putByte(pos++, (byte) (0xff & (value >> 24)));
        putByte(pos++, (byte) (0xff & (value >> 16)));
        putByte(pos++, (byte) (0xff & (value >> 8)));
        putByte(pos, (byte) (0xff & (value)));
    }





    abstract public File getFile();


    public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {


        byte[] data = new byte[(int) size];
        try {
            getDataInput(inputOffset, (int) size).readFully(data);
        }catch(IOException e){
            throw new DBException.VolumeIOError(e);
        }
        target.putData(targetOffset,data,0, (int) size);
    }



    public abstract void clear(long startOffset, long endOffset);




    public void copyEntireVolumeTo(Volume to) {
        final long volSize = length();
        final long bufSize = 1L<<CC.VOLUME_PAGE_SHIFT;

        to.ensureAvailable(volSize);

        for(long offset=0;offset<volSize;offset+=bufSize){
            long size = Math.min(volSize,offset+bufSize)-offset;
            if(CC.ASSERT && (size<0))
                throw new AssertionError();
            transferInto(offset,to,offset, size);
        }

    }



    abstract static public class ByteBufferVol extends Volume{

        protected final ReentrantLock growLock = new ReentrantLock(CC.FAIR_LOCKS);
        protected final int sliceShift;
        protected final int sliceSizeModMask;
        protected final int sliceSize;

        protected volatile ByteBuffer[] slices = new ByteBuffer[0];
        protected final boolean readOnly;

        protected ByteBufferVol(boolean readOnly,  int sliceShift) {
            this.readOnly = readOnly;
            this.sliceShift = sliceShift;
            this.sliceSize = 1<< sliceShift;
            this.sliceSizeModMask = sliceSize -1;
        }


        @Override
        public final void ensureAvailable(long offset) {
            int slicePos = (int) (offset >>> sliceShift);


            if (slicePos < slices.length){
                return;
            }

            growLock.lock();
            try{

                if(slicePos< slices.length)
                    return;

                int oldSize = slices.length;
                ByteBuffer[] slices2 = slices;

                slices2 = Arrays.copyOf(slices2, Math.max(slicePos+1, slices2.length + slices2.length/1000));

                for(int pos=oldSize;pos<slices2.length;pos++) {
                    slices2[pos]=makeNewBuffer(1L* sliceSize *pos);
                }


                slices = slices2;
            }finally{
                growLock.unlock();
            }
        }

        protected abstract ByteBuffer makeNewBuffer(long offset);

        @Override public final void putLong(final long offset, final long value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+8){
                new IOException("VOL STACK:").printStackTrace();
            }

            slices[(int)(offset >>> sliceShift)].putLong((int) (offset & sliceSizeModMask), value);
        }

        @Override public final void putInt(final long offset, final int value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+4){
                new IOException("VOL STACK:").printStackTrace();
            }

            slices[(int)(offset >>> sliceShift)].putInt((int) (offset & sliceSizeModMask), value);
        }


        @Override public final void putByte(final long offset, final byte value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+1){
                new IOException("VOL STACK:").printStackTrace();
            }

            slices[(int)(offset >>> sliceShift)].put((int) (offset & sliceSizeModMask), value);
        }



        @Override public void putData(final long offset, final byte[] src, int srcPos, int srcSize){
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+srcSize){
                new IOException("VOL STACK:").printStackTrace();
            }


            final ByteBuffer b1 = slices[(int)(offset >>> sliceShift)].duplicate();
            final int bufPos = (int) (offset& sliceSizeModMask);

            b1.position(bufPos);
            b1.put(src, srcPos, srcSize);
        }


        @Override public final void putData(final long offset, final ByteBuffer buf) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+buf.remaining()){
                new IOException("VOL STACK:").printStackTrace();
            }

            final ByteBuffer b1 = slices[(int)(offset >>> sliceShift)].duplicate();
            final int bufPos = (int) (offset& sliceSizeModMask);

            b1.position(bufPos);
            b1.put(buf);
        }

        @Override
        public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {
            final ByteBuffer b1 = slices[(int)(inputOffset >>> sliceShift)].duplicate();
            final int bufPos = (int) (inputOffset& sliceSizeModMask);

            b1.position(bufPos);

            b1.limit((int) (bufPos+size));
            target.putData(targetOffset,b1);
        }

        @Override public void getData(final long offset, final byte[] src, int srcPos, int srcSize){
            final ByteBuffer b1 = slices[(int)(offset >>> sliceShift)].duplicate();
            final int bufPos = (int) (offset& sliceSizeModMask);

            b1.position(bufPos);
            b1.get(src, srcPos, srcSize);
        }


        @Override final public long getLong(long offset) {
            return slices[(int)(offset >>> sliceShift)].getLong((int) (offset& sliceSizeModMask));
        }

        @Override final public int getInt(long offset) {
            return slices[(int)(offset >>> sliceShift)].getInt((int) (offset& sliceSizeModMask));
        }


        @Override public final byte getByte(long offset) {
            return slices[(int)(offset >>> sliceShift)].get((int) (offset& sliceSizeModMask));
        }


        @Override
        public final DataIO.DataInputByteBuffer getDataInput(long offset, int size) {
            return new DataIO.DataInputByteBuffer(slices[(int)(offset >>> sliceShift)], (int) (offset& sliceSizeModMask));
        }



        @Override
        public void putDataOverlap(long offset, byte[] data, int pos, int len) {
            boolean overlap = (offset>>>sliceShift != (offset+len)>>>sliceShift);

            if(overlap){
                while(len>0){
                    ByteBuffer b = slices[((int) (offset >>> sliceShift))].duplicate();
                    b.position((int) (offset&sliceSizeModMask));

                    int toPut = Math.min(len,sliceSize - b.position());

                    b.limit(b.position()+toPut);
                    b.put(data, pos, toPut);

                    pos+=toPut;
                    len-=toPut;
                    offset+=toPut;
                }
            }else{
                putData(offset,data,pos,len);
            }
        }

        @Override
        public DataInput getDataInputOverlap(long offset, int size) {
            boolean overlap = (offset>>>sliceShift != (offset+size)>>>sliceShift);
            if(overlap){
                byte[] bb = new byte[size];
                final int origLen = size;
                while(size>0){
                    ByteBuffer b = slices[((int) (offset >>> sliceShift))].duplicate();
                    b.position((int) (offset&sliceSizeModMask));

                    int toPut = Math.min(size,sliceSize - b.position());

                    b.limit(b.position()+toPut);
                    b.get(bb,origLen-size,toPut);
                    size -=toPut;
                    offset+=toPut;
                }
                return new DataIO.DataInputByteArray(bb);
            }else{

                return getDataInput(offset,size);
            }
        }


        @Override
        public void clear(long startOffset, long endOffset) {
            if(CC.ASSERT && (startOffset >>> sliceShift) != ((endOffset-1) >>> sliceShift))
                throw new AssertionError();
            ByteBuffer buf = slices[(int)(startOffset >>> sliceShift)];
            int start = (int) (startOffset&sliceSizeModMask);
            int end = (int) (endOffset&sliceSizeModMask);

            int pos = start;
            while(pos<end){
                buf = buf.duplicate();
                buf.position(pos);
                buf.put(CLEAR, 0, Math.min(CLEAR.length, end-pos));
                pos+=CLEAR.length;
            }
        }

        @Override
        public boolean isEmpty() {
            return slices==null || slices.length==0;
        }

        @Override
        public boolean isSliced(){
            return true;
        }

        @Override
        public int sliceSize() {
            return sliceSize;
        }


        protected boolean unmap(MappedByteBuffer b){
            try{
                if(unmapHackSupported){



                    Method cleanerMethod = b.getClass().getMethod("cleaner", new Class[0]);
                    cleanerMethod.setAccessible(true);
                    if(cleanerMethod!=null){
                        Object cleaner = cleanerMethod.invoke(b);
                        if(cleaner!=null){
                            Method clearMethod = cleaner.getClass().getMethod("clean", new Class[0]);
                            if(clearMethod!=null) {
                                clearMethod.invoke(cleaner);
                                return true;
                            }
                        }else{

                            Method attMethod = b.getClass().getMethod("attachment", new Class[0]);
                            attMethod.setAccessible(true);
                            Object att = attMethod.invoke(b);
                            return att instanceof MappedByteBuffer &&
                                    unmap((MappedByteBuffer) att);
                        }
                    }
                }
            }catch(Exception e){
                unmapHackSupported = false;
                LOG.log(Level.WARNING, "Unmap failed", e);
            }
            return false;
        }

        private static boolean unmapHackSupported = true;
        static{
            try{
                unmapHackSupported =
                        SerializerPojo.classForName("sun.nio.ch.DirectBuffer")!=null;
            }catch(Exception e){
                unmapHackSupported = false;
            }
        }



        private static boolean windowsWorkaround = System.getProperty("os.name").toLowerCase().startsWith("win");


    }

    public static final class MappedFileVol extends ByteBufferVol {

        public static final VolumeFactory FACTORY = new VolumeFactory() {
            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {


                return new MappedFileVol(new File(file),readOnly,sliceShift);
            }
        };

        protected final File file;
        protected final FileChannel fileChannel;
        protected final FileChannel.MapMode mapMode;
        protected final java.io.RandomAccessFile raf;


        public MappedFileVol(File file, boolean readOnly, int sliceShift) {
            super(readOnly,sliceShift);
            this.file = file;
            this.mapMode = readOnly? FileChannel.MapMode.READ_ONLY: FileChannel.MapMode.READ_WRITE;
            try {
                FileChannelVol.checkFolder(file,readOnly);
                this.raf = new java.io.RandomAccessFile(file, readOnly?"r":"rw");
                this.fileChannel = raf.getChannel();

                final long fileSize = fileChannel.size();
                if(fileSize>0){

                    slices = new ByteBuffer[(int) ((fileSize>>> sliceShift))];
                    for(int i=0;i< slices.length;i++){
                        slices[i] = makeNewBuffer(1L*i* sliceSize);
                    }
                }else{
                    slices = new ByteBuffer[0];
                }
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void close() {
            growLock.lock();
            try{
                closed = true;
                fileChannel.close();
                raf.close();





                for(ByteBuffer b: slices){
                    if(b!=null && (b instanceof MappedByteBuffer)){
                        unmap((MappedByteBuffer) b);
                    }
                }

                slices = null;

            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }finally{
                growLock.unlock();
            }

        }

        @Override
        public void sync() {
            if(readOnly) return;
            growLock.lock();
            try{
                for(ByteBuffer b: slices){
                    if(b!=null && (b instanceof MappedByteBuffer)){
                        MappedByteBuffer bb = ((MappedByteBuffer) b);
                        bb.force();
                    }
                }

            }finally{
                growLock.unlock();
            }

        }

        @Override
        public int sliceSize() {
            return sliceSize;
        }

        @Override
        protected ByteBuffer makeNewBuffer(long offset) {
            try {
                if(CC.ASSERT && ! ((offset& sliceSizeModMask)==0))
                    throw new AssertionError();
                if(CC.ASSERT && ! (offset>=0))
                    throw new AssertionError();
                ByteBuffer ret = fileChannel.map(mapMode,offset, sliceSize);
                if(CC.ASSERT && ret.order() != ByteOrder.BIG_ENDIAN)
                    throw new AssertionError("Little-endian");
                if(mapMode == FileChannel.MapMode.READ_ONLY) {
                    ret = ret.asReadOnlyBuffer();
                }
                return ret;
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }


        @Override
        public boolean isEmpty() {
            return length()<=0;
        }

        @Override
        public long length() {
            return file.length();
        }

        @Override
        public File getFile() {
            return file;
        }


        @Override
        public void truncate(long size) {
            final int maxSize = 1+(int) (size >>> sliceShift);
            if(maxSize== slices.length)
                return;
            if(maxSize> slices.length) {
                ensureAvailable(size);
                return;
            }
            growLock.lock();
            try{
                if(maxSize>= slices.length)
                    return;
                ByteBuffer[] old = slices;
                slices = Arrays.copyOf(slices,maxSize);


                for(int i=maxSize;i<old.length;i++){
                    unmap((MappedByteBuffer) old[i]);
                    old[i] = null;
                }

                if (ByteBufferVol.windowsWorkaround) {
                    for(int i=0;i<maxSize;i++){
                        unmap((MappedByteBuffer) old[i]);
                        old[i] = null;
                    }
                }

                try {
                    fileChannel.truncate(1L * sliceSize *maxSize);
                } catch (IOException e) {
                    throw new DBException.VolumeIOError(e);
                }

                if (ByteBufferVol.windowsWorkaround) {
                    for(int pos=0;pos<maxSize;pos++) {
                        slices[pos]=makeNewBuffer(1L* sliceSize *pos);
                    }
                }

            }finally {
                growLock.unlock();
            }
        }

    }

    public static final class MemoryVol extends ByteBufferVol {


        public static final VolumeFactory FACTORY = new VolumeFactory() {
            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {


                return new MemoryVol(true,sliceShift);
            }
        }
                ;
        protected final boolean useDirectBuffer;

        @Override
        public String toString() {
            return super.toString()+",direct="+useDirectBuffer;
        }

        public MemoryVol(final boolean useDirectBuffer, final int sliceShift) {
            super(false, sliceShift);
            this.useDirectBuffer = useDirectBuffer;
        }

        @Override
        protected ByteBuffer makeNewBuffer(long offset) {
            try {
                ByteBuffer b =  useDirectBuffer ?
                        ByteBuffer.allocateDirect(sliceSize) :
                        ByteBuffer.allocate(sliceSize);
                if(CC.ASSERT && b.order()!= ByteOrder.BIG_ENDIAN)
                    throw new AssertionError("little-endian");
                return b;
            }catch(OutOfMemoryError e){
                throw new DBException.OutOfMemory(e);
            }
        }


        @Override
        public void truncate(long size) {
            final int maxSize = 1+(int) (size >>> sliceShift);
            if(maxSize== slices.length)
                return;
            if(maxSize> slices.length) {
                ensureAvailable(size);
                return;
            }
            growLock.lock();
            try{
                if(maxSize>= slices.length)
                    return;
                ByteBuffer[] old = slices;
                slices = Arrays.copyOf(slices,maxSize);


                for(int i=maxSize;i<old.length;i++){
                    if(old[i] instanceof  MappedByteBuffer)
                        unmap((MappedByteBuffer) old[i]);
                    old[i] = null;
                }

            }finally {
                growLock.unlock();
            }
        }

        @Override public void close() {
            growLock.lock();
            try{
                closed = true;
                for(ByteBuffer b: slices){
                    if(b!=null && (b instanceof MappedByteBuffer)){
                        unmap((MappedByteBuffer)b);
                    }
                }
                slices = null;
            }finally{
                growLock.unlock();
            }
        }

        @Override public void sync() {}

        @Override
        public long length() {
            return ((long)slices.length)*sliceSize;
        }

        @Override
        public File getFile() {
            return null;
        }
    }



    public static final class FileChannelVol extends Volume {

        public static final VolumeFactory FACTORY = new VolumeFactory() {

            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {
                return new FileChannelVol(new File(file),readOnly, sliceShift);
            }
        };

        protected final File file;
        protected final int sliceSize;
        protected RandomAccessFile raf;
        protected FileChannel channel;
        protected final boolean readOnly;

        protected volatile long size;
        protected final Lock growLock = new ReentrantLock(CC.FAIR_LOCKS);

        public FileChannelVol(File file, boolean readOnly, int sliceShift){
            this.file = file;
            this.readOnly = readOnly;
            this.sliceSize = 1<<sliceShift;
            try {
                checkFolder(file, readOnly);
                if (readOnly && !file.exists()) {
                    raf = null;
                    channel = null;
                    size = 0;
                } else {
                    raf = new RandomAccessFile(file, readOnly ? "r" : "rw");
                    channel = raf.getChannel();
                    size = channel.size();
                }
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        public FileChannelVol(File file) {
            this(file, false,CC.VOLUME_PAGE_SHIFT);
        }

        protected static void checkFolder(File file, boolean readOnly) throws IOException {
            File parent = file.getParentFile();
            if(parent == null) {
                parent = file.getCanonicalFile().getParentFile();
            }
            if (parent == null) {
                throw new IOException("Parent folder could not be determined for: "+file);
            }
            if(!parent.exists() || !parent.isDirectory())
                throw new IOException("Parent folder does not exist: "+file);
            if(!parent.canRead())
                throw new IOException("Parent folder is not readable: "+file);
            if(!readOnly && !parent.canWrite())
                throw new IOException("Parent folder is not writable: "+file);
        }

        @Override
        public void ensureAvailable(long offset) {
            if(offset% sliceSize !=0)
                offset += sliceSize - offset% sliceSize; 

            if(offset>size){
                growLock.lock();
                try {
                    raf.setLength(offset);
                    size = offset;
                } catch (IOException e) {
                    throw new DBException.VolumeIOError(e);
                }finally {
                    growLock.unlock();
                }
            }
        }

        @Override
        public void truncate(long size) {
            growLock.lock();
            try {
                this.size = size;
                channel.truncate(size);
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }finally{
                growLock.unlock();
            }
        }

        protected void writeFully(long offset, ByteBuffer buf){
            int remaining = buf.limit()-buf.position();
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+remaining){
                new IOException("VOL STACK:").printStackTrace();
            }
            try {
                while(remaining>0){
                    int write = channel.write(buf, offset);
                    if(write<0) throw new EOFException();
                    remaining-=write;
                }
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }


        @Override
        public void putLong(long offset, long value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+8){
                new IOException("VOL STACK:").printStackTrace();
            }


            ByteBuffer buf = ByteBuffer.allocate(8);
            buf.putLong(0, value);
            writeFully(offset, buf);
        }

        @Override
        public void putInt(long offset, int value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+4){
                new IOException("VOL STACK:").printStackTrace();
            }

            ByteBuffer buf = ByteBuffer.allocate(4);
            buf.putInt(0, value);
            writeFully(offset, buf);
        }

        @Override
        public void putByte(long offset, byte value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+1){
                new IOException("VOL STACK:").printStackTrace();
            }


            ByteBuffer buf = ByteBuffer.allocate(1);
            buf.put(0, value);
            writeFully(offset, buf);
        }

        @Override
        public void putData(long offset, byte[] src, int srcPos, int srcSize) {
            ByteBuffer buf = ByteBuffer.wrap(src,srcPos, srcSize);
            writeFully(offset, buf);
        }

        @Override
        public void putData(long offset, ByteBuffer buf) {
            writeFully(offset,buf);
        }

        protected void readFully(long offset, ByteBuffer buf){
            int remaining = buf.limit()-buf.position();
            try{
                while(remaining>0){
                    int read = channel.read(buf, offset);
                    if(read<0)
                        throw new EOFException();
                    remaining-=read;
                }
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public long getLong(long offset) {
            ByteBuffer buf = ByteBuffer.allocate(8);
            readFully(offset, buf);
            return buf.getLong(0);
        }

        @Override
        public int getInt(long offset) {
            ByteBuffer buf = ByteBuffer.allocate(4);
            readFully(offset,buf);
            return buf.getInt(0);
        }

        @Override
        public byte getByte(long offset) {
            ByteBuffer buf = ByteBuffer.allocate(1);
            readFully(offset,buf);
            return buf.get(0);
        }

        @Override
        public DataIO.DataInputByteBuffer getDataInput(long offset, int size) {
            ByteBuffer buf = ByteBuffer.allocate(size);
            readFully(offset,buf);
            return new DataIO.DataInputByteBuffer(buf,0);
        }

        @Override
        public void getData(long offset, byte[] bytes, int bytesPos, int size) {
            ByteBuffer buf = ByteBuffer.wrap(bytes,bytesPos,size);
            readFully(offset,buf);
        }

        @Override
        public void close() {
            try{
                closed = true;
                if(channel!=null)
                    channel.close();
                channel = null;
                if (raf != null)
                    raf.close();
                raf = null;
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void sync() {
            try{
                channel.force(true);
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public boolean isEmpty() {
            try {
                return channel==null || channel.size()==0;
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public int sliceSize() {
            return -1;
        }

        @Override
        public boolean isSliced() {
            return false;
        }

        @Override
        public long length() {
            try {
                return channel.size();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public File getFile() {
            return file;
        }

        @Override
        public void clear(long startOffset, long endOffset) {
            try {
                while(startOffset<endOffset){
                    ByteBuffer b = ByteBuffer.wrap(CLEAR);
                    b.limit((int) Math.min(CLEAR.length, endOffset - startOffset));
                    channel.write(b, startOffset);
                    startOffset+=CLEAR.length;
                }
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }
    }



    public static void volumeTransfer(long size, Volume from, Volume to){
        int bufSize = Math.min(from.sliceSize(),to.sliceSize());

        if(bufSize<0 || bufSize>1024*1024*128){
            bufSize = 64 * 1024; 
        }
        to.ensureAvailable(size);

        for(long offset=0;offset<size;offset+=bufSize){
            int bb = (int) Math.min(bufSize, size-offset);
            from.transferInto(offset,to,offset,bb);
        }
    }


    public static final class ByteArrayVol extends Volume{

        public static final VolumeFactory FACTORY = new VolumeFactory() {

            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {


                return new ByteArrayVol(sliceShift);
            }
        };

        protected final ReentrantLock growLock = new ReentrantLock(CC.FAIR_LOCKS);

        protected final int sliceShift;
        protected final int sliceSizeModMask;
        protected final int sliceSize;

        protected volatile byte[][] slices = new byte[0][];

        protected ByteArrayVol(int sliceShift) {
            this.sliceShift = sliceShift;
            this.sliceSize = 1<< sliceShift;
            this.sliceSizeModMask = sliceSize -1;
        }

        @Override
        public final void ensureAvailable(long offset) {

            int slicePos = (int) (offset >>> sliceShift);


            if (slicePos < slices.length){
                return;
            }

            growLock.lock();
            try {

                if (slicePos < slices.length)
                    return;

                int oldSize = slices.length;
                byte[][] slices2 = slices;

                slices2 = Arrays.copyOf(slices2, Math.max(slicePos + 1, slices2.length + slices2.length / 1000));

                for (int pos = oldSize; pos < slices2.length; pos++) {
                    slices2[pos] = new byte[sliceSize];
                }


                slices = slices2;
            }catch(OutOfMemoryError e){
                throw new DBException.OutOfMemory(e);
            }finally{
                growLock.unlock();
            }
        }


        @Override
        public void truncate(long size) {
            final int maxSize = 1+(int) (size >>> sliceShift);
            if(maxSize== slices.length)
                return;
            if(maxSize> slices.length) {
                ensureAvailable(size);
                return;
            }
            growLock.lock();
            try{
                if(maxSize>= slices.length)
                    return;
                slices = Arrays.copyOf(slices,maxSize);
            }finally {
                growLock.unlock();
            }
        }

        @Override
        public void putLong(long offset, long v) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            DataIO.putLong(buf,pos,v);
        }


        @Override
        public void putInt(long offset, int value) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            buf[pos++] = (byte) (0xff & (value >> 24));
            buf[pos++] = (byte) (0xff & (value >> 16));
            buf[pos++] = (byte) (0xff & (value >> 8));
            buf[pos++] = (byte) (0xff & (value));
        }

        @Override
        public void putByte(long offset, byte value) {
            final byte[] b = slices[((int) (offset >>> sliceShift))];
            b[((int) (offset & sliceSizeModMask))] = value;
        }

        @Override
        public void putData(long offset, byte[] src, int srcPos, int srcSize) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];

            System.arraycopy(src,srcPos,buf,pos,srcSize);
        }

        @Override
        public void putData(long offset, ByteBuffer buf) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] dst = slices[((int) (offset >>> sliceShift))];
            buf.get(dst, pos, buf.remaining());
        }


        @Override
        public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {
            int pos = (int) (inputOffset & sliceSizeModMask);
            byte[] buf = slices[((int) (inputOffset >>> sliceShift))];


            target.putData(targetOffset,buf,pos, (int) size);
        }



        @Override
        public void putDataOverlap(long offset, byte[] data, int pos, int len) {
            boolean overlap = (offset>>>sliceShift != (offset+len)>>>sliceShift);

            if(overlap){
                while(len>0){
                    byte[] b = slices[((int) (offset >>> sliceShift))];
                    int pos2 = (int) (offset&sliceSizeModMask);

                    int toPut = Math.min(len,sliceSize - pos2);

                    System.arraycopy(data, pos, b, pos2, toPut);

                    pos+=toPut;
                    len -=toPut;
                    offset+=toPut;
                }
            }else{
                putData(offset,data,pos,len);
            }
        }

        @Override
        public DataInput getDataInputOverlap(long offset, int size) {
            boolean overlap = (offset>>>sliceShift != (offset+size)>>>sliceShift);
            if(overlap){
                byte[] bb = new byte[size];
                final int origLen = size;
                while(size>0){
                    byte[] b = slices[((int) (offset >>> sliceShift))];
                    int pos = (int) (offset&sliceSizeModMask);

                    int toPut = Math.min(size,sliceSize - pos);

                    System.arraycopy(b,pos, bb,origLen-size,toPut);

                    size -=toPut;
                    offset+=toPut;
                }
                return new DataIO.DataInputByteArray(bb);
            }else{

                return getDataInput(offset,size);
            }
        }

        @Override
        public void clear(long startOffset, long endOffset) {
            if(CC.ASSERT && (startOffset >>> sliceShift) != ((endOffset-1) >>> sliceShift))
                throw new AssertionError();
            byte[] buf = slices[(int)(startOffset >>> sliceShift)];
            int start = (int) (startOffset&sliceSizeModMask);
            int end = (int) (endOffset&sliceSizeModMask);

            int pos = start;
            while(pos<end){
                System.arraycopy(CLEAR,0,buf,pos, Math.min(CLEAR.length, end-pos));
                pos+=CLEAR.length;
            }
        }

        @Override
        public long getLong(long offset) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            return DataIO.getLong(buf,pos);
        }



        @Override
        public int getInt(long offset) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];


            final int end = pos + 4;
            int ret = 0;
            for (; pos < end; pos++) {
                ret = (ret << 8) | (buf[pos] & 0xFF);
            }
            return ret;
        }

        @Override
        public byte getByte(long offset) {
            final byte[] b = slices[((int) (offset >>> sliceShift))];
            return b[((int) (offset & sliceSizeModMask))];
        }

        @Override
        public DataInput getDataInput(long offset, int size) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            return new DataIO.DataInputByteArray(buf,pos);
        }

        @Override
        public void getData(long offset, byte[] bytes, int bytesPos, int length) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            System.arraycopy(buf,pos,bytes,bytesPos,length);
        }

        @Override
        public void close() {
            closed = true;
            slices =null;
        }

        @Override
        public void sync() {

        }


        @Override
        public boolean isEmpty() {
            return slices.length==0;
        }

        @Override
        public int sliceSize() {
            return sliceSize;
        }

        @Override
        public boolean isSliced() {
            return true;
        }

        @Override
        public long length() {
            return ((long)slices.length)*sliceSize;
        }

        @Override
        public File getFile() {
            return null;
        }

    }


    public static final class SingleByteArrayVol extends Volume{

        protected final byte[] data;

        public SingleByteArrayVol(int size) {
            this(new byte[size]);
        }

        public SingleByteArrayVol(byte[] data){
            this.data = data;
        }


        @Override
        public void ensureAvailable(long offset) {
            if(offset >= data.length){

            }
        }

        @Override
        public void truncate(long size) {


        }

        @Override
        public void putLong(long offset, long v) {
            DataIO.putLong(data, (int) offset,v);
        }


        @Override
        public void putInt(long offset, int value) {
            int pos = (int) offset;
            data[pos++] = (byte) (0xff & (value >> 24));
            data[pos++] = (byte) (0xff & (value >> 16));
            data[pos++] = (byte) (0xff & (value >> 8));
            data[pos++] = (byte) (0xff & (value));
        }

        @Override
        public void putByte(long offset, byte value) {
            data[(int) offset] = value;
        }

        @Override
        public void putData(long offset, byte[] src, int srcPos, int srcSize) {
            System.arraycopy(src, srcPos, data, (int) offset, srcSize);
        }

        @Override
        public void putData(long offset, ByteBuffer buf) {
             buf.get(data, (int) offset, buf.remaining());
        }


        @Override
        public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {

            target.putData(targetOffset,data, (int) inputOffset, (int) size);
        }

        @Override
        public void clear(long startOffset, long endOffset) {
            int start = (int) startOffset;
            int end = (int) endOffset;

            int pos = start;
            while(pos<end){
                System.arraycopy(CLEAR,0,data,pos, Math.min(CLEAR.length, end-pos));
                pos+=CLEAR.length;
            }
        }

        @Override
        public long getLong(long offset) {
            return DataIO.getLong(data, (int) offset);
        }



        @Override
        public int getInt(long offset) {
            int pos = (int) offset;

            final int end = pos + 4;
            int ret = 0;
            for (; pos < end; pos++) {
                ret = (ret << 8) | (data[pos] & 0xFF);
            }
            return ret;
        }

        @Override
        public byte getByte(long offset) {
            return data[((int) offset)];
        }

        @Override
        public DataInput getDataInput(long offset, int size) {
             return new DataIO.DataInputByteArray(data, (int) offset);
        }

        @Override
        public void getData(long offset, byte[] bytes, int bytesPos, int length) {
            System.arraycopy(data, (int) offset,bytes,bytesPos,length);
        }

        @Override
        public void close() {
            closed = true;

        }

        @Override
        public void sync() {
        }

        @Override
        public boolean isEmpty() {

            for(byte b:data){
                if(b!=0)
                    return false;
            }
            return true;
        }


        @Override
        public int sliceSize() {
            return -1;
        }

        @Override
        public boolean isSliced() {
            return false;
        }

        @Override
        public long length() {
            return data.length;
        }

        @Override
        public File getFile() {
            return null;
        }

    }


    public static final class ReadOnly extends Volume{

        protected final Volume vol;

        public ReadOnly(Volume vol) {
            this.vol = vol;
        }

        @Override
        public void ensureAvailable(long offset) {

            return;
        }

        @Override
        public void truncate(long size) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putLong(long offset, long value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putInt(long offset, int value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putByte(long offset, byte value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putData(long offset, byte[] src, int srcPos, int srcSize) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putData(long offset, ByteBuffer buf) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putDataOverlap(long offset, byte[] src, int srcPos, int srcSize) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public long getLong(long offset) {
            return vol.getLong(offset);
        }

        @Override
        public int getInt(long offset) {
            return vol.getInt(offset);
        }

        @Override
        public byte getByte(long offset) {
            return vol.getByte(offset);
        }

        @Override
        public DataInput getDataInput(long offset, int size) {
            return vol.getDataInput(offset,size);
        }

        @Override
        public DataInput getDataInputOverlap(long offset, int size) {
            return vol.getDataInputOverlap(offset, size);
        }

        @Override
        public void getData(long offset, byte[] bytes, int bytesPos, int size) {
            vol.getData(offset,bytes,bytesPos,size);
        }

        @Override
        public void close() {
            closed = true;
            vol.close();
        }

        @Override
        public void sync() {
            vol.sync();
        }

        @Override
        public int sliceSize() {
            return vol.sliceSize();
        }

        @Override
        public boolean isEmpty() {
            return vol.isEmpty();
        }

        @Override
        public void deleteFile() {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public boolean isSliced() {
            return vol.isSliced();
        }

        @Override
        public long length() {
            return vol.length();
        }

        @Override
        public void putUnsignedShort(long offset, int value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public int getUnsignedShort(long offset) {
            return vol.getUnsignedShort(offset);
        }

        @Override
        public int getUnsignedByte(long offset) {
            return vol.getUnsignedByte(offset);
        }

        @Override
        public void putUnsignedByte(long offset, int b) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public int putLongPackBidi(long offset, long value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public long getLongPackBidi(long offset) {
            return vol.getLongPackBidi(offset);
        }

        @Override
        public long getLongPackBidiReverse(long offset) {
            return vol.getLongPackBidiReverse(offset);
        }

        @Override
        public long getSixLong(long pos) {
            return vol.getSixLong(pos);
        }

        @Override
        public void putSixLong(long pos, long value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public File getFile() {
            return vol.getFile();
        }

        @Override
        public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {
            vol.transferInto(inputOffset, target, targetOffset, size);
        }

        @Override
        public void clear(long startOffset, long endOffset) {
            throw new IllegalAccessError("read-only");
        }
    }


    public static final class RandomAccessFileVol extends Volume{


        public static final VolumeFactory FACTORY = new VolumeFactory() {
            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {

                return new RandomAccessFileVol(new File(file), readOnly);
            }
        };
        protected final File file;
        protected final RandomAccessFile raf;

        public RandomAccessFileVol(File file, boolean readOnly) {
            this.file = file;
            try {
                this.raf = new RandomAccessFile(file,readOnly?"r":"rw");
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void ensureAvailable(long offset) {

        }

        @Override
        public void truncate(long size) {
            try {
                raf.setLength(size);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized void putLong(long offset, long value) {
            try {
                raf.seek(offset);
                raf.writeLong(value);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }


        @Override
        public synchronized  void putInt(long offset, int value) {
            try {
                raf.seek(offset);
                raf.writeInt(value);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }

        }

        @Override
        public  synchronized void putByte(long offset, byte value) {
            try {
                raf.seek(offset);
                raf.writeByte(value);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }

        }

        @Override
        public  synchronized void putData(long offset, byte[] src, int srcPos, int srcSize) {
            try {
                raf.seek(offset);
                raf.write(src,srcPos,srcSize);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized void putData(long offset, ByteBuffer buf) {
            byte[] bb = buf.array();
            int pos = buf.position();
            int size = buf.limit()-pos;
            if(bb==null) {
                bb = new byte[size];
                buf.get(bb);
                pos = 0;
            }
            putData(offset,bb,pos, size);
        }

        @Override
        public synchronized long getLong(long offset) {
            try {
                raf.seek(offset);
                return raf.readLong();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized int getInt(long offset) {
            try {
                raf.seek(offset);
                return raf.readInt();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }

        }

        @Override
        public synchronized byte getByte(long offset) {
            try {
                raf.seek(offset);
                return raf.readByte();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized DataInput getDataInput(long offset, int size) {
            try {
                raf.seek(offset);
                byte[] b = new byte[size];
                raf.read(b);
                return new DataIO.DataInputByteArray(b);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized void getData(long offset, byte[] bytes, int bytesPos, int size) {
            try {
                raf.seek(offset);
                raf.read(bytes,bytesPos,size);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void close() {
            closed = true;
            try {
                raf.close();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void sync() {
            try {
                raf.getFD().sync();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public int sliceSize() {
            return 0;
        }

        @Override
        public boolean isEmpty() {
            try {
                return raf.length()==0;
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }


        @Override
        public boolean isSliced() {
            return false;
        }

        @Override
        public long length() {
            try {
                return raf.length();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public File getFile() {
            return file;
        }

        @Override
        public synchronized void clear(long startOffset, long endOffset) {
            try {
                raf.seek(startOffset);
                while(startOffset<endOffset){
                    long remaining = Math.min(CLEAR.length, endOffset - startOffset);
                    raf.write(CLEAR, 0, (int)remaining);
                    startOffset+=CLEAR.length;
                }

            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }
    }
}


<code block>
package org.mapdb;

import java.io.DataInput;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashSet;
import java.util.Set;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.locks.Lock;
import java.util.logging.Level;


public class StoreAppend extends Store {

    protected static final int I_UPDATE = 1;
    protected static final int I_INSERT = 3;
    protected static final int I_DELETE = 2;
    protected static final int I_PREALLOC = 4;
    protected static final int I_SKIP_SINGLE_BYTE = 6;

    protected static final int I_TX_VALID = 8;
    protected static final int I_TX_ROLLBACK = 9;

    protected static final long headerSize = 16;

    protected static final StoreAppend[] STORE_APPENDS_ZERO_ARRAY = new StoreAppend[0];


    protected Volume vol;
    protected Volume indexTable;


    protected long eof = 0;
    protected final AtomicLong highestRecid = new AtomicLong(0);
    protected final boolean tx;

    protected final LongLongMap[] modified;

    protected final ScheduledExecutorService compactionExecutor;

    protected final Set<StoreAppend> snapshots;

    protected final boolean isSnapshot;

    protected StoreAppend(String fileName,
                          Volume.VolumeFactory volumeFactory,
                          Cache cache,
                          int lockScale,
                          int lockingStrategy,
                          boolean checksum,
                          boolean compress,
                          byte[] password,
                          boolean readonly,
                          boolean snapshotEnable,
                          boolean txDisabled,
                          ScheduledExecutorService compactionExecutor
                    ) {
        super(fileName, volumeFactory, cache, lockScale,lockingStrategy, checksum, compress, password, readonly, snapshotEnable);
        this.tx = !txDisabled;
        if(tx){
            modified = new LongLongMap[this.lockScale];
            for(int i=0;i<modified.length;i++){
                modified[i] = new LongLongMap();
            }
        }else{
            modified = null;
        }
        this.compactionExecutor = compactionExecutor;
        this.snapshots = Collections.synchronizedSet(new HashSet<StoreAppend>());
        this.isSnapshot = false;
    }

    public StoreAppend(String fileName) {
        this(fileName,
                fileName==null? CC.DEFAULT_MEMORY_VOLUME_FACTORY : CC.DEFAULT_FILE_VOLUME_FACTORY,
                null,
                CC.DEFAULT_LOCK_SCALE,
                0,
                false,
                false,
                null,
                false,
                false,
                false,
                null
        );
    }


    protected StoreAppend(StoreAppend host, LongLongMap[] uncommitedData){
        super(null, null,null,
                host.lockScale,
                Store.LOCKING_STRATEGY_NOLOCK,
                host.checksum,
                host.compress,
                null, 
                true, 
                false);

        indexTable = host.indexTable;
        vol = host.vol;


        for(int i=0;i<locks.length;i++){
            locks[i] = host.locks[i];
        }

        tx = true;
        modified = new LongLongMap[this.lockScale];
        if(uncommitedData==null){
            for(int i=0;i<modified.length;i++) {
                modified[i] = new LongLongMap();
            }
        }else{
            for(int i=0;i<modified.length;i++) {
                Lock lock = locks[i].writeLock();
                lock.lock();
                try {
                    modified[i] = uncommitedData[i].clone();
                }finally {
                    lock.unlock();
                }
            }
        }

        this.compactionExecutor = null;
        this.snapshots = host.snapshots;
        this.isSnapshot = true;
        host.snapshots.add(StoreAppend.this);
    }

    @Override
    public void init() {
        super.init();
        structuralLock.lock();
        try {
            vol = volumeFactory.makeVolume(fileName, readonly);
            indexTable = new Volume.ByteArrayVol(CC.VOLUME_PAGE_SHIFT);
            if (!readonly)
                vol.ensureAvailable(headerSize);
            eof = headerSize;
            for (int i = 0; i <= RECID_LAST_RESERVED; i++) {
                indexTable.ensureAvailable(i * 8);
                indexTable.putLong(i * 8, -2);
            }

            if (vol.isEmpty()) {
                initCreate();
            } else {
                initOpen();
            }
        }finally {
            structuralLock.unlock();
        }
    }

    protected void initCreate() {
        highestRecid.set(RECID_LAST_RESERVED);

        long feat = makeFeaturesBitmap();
        vol.putLong(HEAD_FEATURES,feat);
        vol.sync();
    }

    protected void initOpen() {
        checkFeaturesBitmap(vol.getLong(HEAD_FEATURES));


        long pos = headerSize;
        final long volumeSize = vol.length();
        long lastValidPos= pos;
        long highestRecid2 = RECID_LAST_RESERVED;
        LongLongMap commitData = tx?new LongLongMap():null;

        try{

            while(true) {
                lastValidPos = pos;
                if(pos>=volumeSize)
                    break;
                final int inst = vol.getUnsignedByte(pos++);
                if (inst == I_INSERT || inst == I_UPDATE) {

                    final long recid = vol.getSixLong(pos);
                    pos += 6;

                    highestRecid2 = Math.max(highestRecid2, recid);

                    commitData.put(recid, pos - 6 - 1);


                    int size = vol.getInt(pos);
                    pos = pos + 4 + size;
                } else if (inst == I_DELETE) {
                    final long recid = vol.getSixLong(pos);
                    pos += 6;

                    highestRecid2 = Math.max(highestRecid2, recid);

                    commitData.put(recid, -1);
                } else if (inst == I_DELETE) {
                    final long recid = vol.getSixLong(pos);
                    pos += 6;

                    highestRecid2 = Math.max(highestRecid2, recid);

                    commitData.put(recid,-2);
                } else if (inst == I_SKIP_SINGLE_BYTE) {

                } else if (inst == I_TX_VALID) {
                    if (tx){

                        for(int i=0;i<commitData.table.length;i+=2){
                            long recidOffset = commitData.table[i]*8;
                            if(recidOffset==0)
                                continue;
                            indexTable.ensureAvailable(recidOffset + 8);
                            indexTable.putLong(recidOffset, commitData.table[i+1]);
                        }
                        commitData.clear();
                    }
                } else if (inst == I_TX_ROLLBACK) {
                    if (tx) {
                        commitData.clear();
                    }
                } else if (inst == 0) {

                    if (tx) {

                        commitData.clear();
                    }

                    break;
                } else {

                    LOG.warning("Unknown instruction " + inst);
                    break;
                }
            }
        }catch (RuntimeException e){


            LOG.log(Level.WARNING, "Log replay finished",e);
            if(tx) {

                commitData.clear();
            }

        }
        eof = lastValidPos;

        highestRecid.set(highestRecid2);
    }


    protected long alloc(int headSize, int totalSize){
        structuralLock.lock();
        try{
            while(eof/StoreDirect.PAGE_SIZE != (eof+headSize)/StoreDirect.PAGE_SIZE){

                vol.ensureAvailable(eof+1);
                vol.putUnsignedByte(eof++, I_SKIP_SINGLE_BYTE);
            }
            long ret = eof;
            eof+=totalSize;
            return ret;
        }finally {
            structuralLock.unlock();
        }
    }

    @Override
    protected <A> A get2(long recid, Serializer<A> serializer) {
        if(CC.ASSERT)
            assertReadLocked(recid);

        long offset = modified[lockPos(recid)].get(recid);
        if(offset==0) {
            try {
                offset = indexTable.getLong(recid * 8);
            } catch (ArrayIndexOutOfBoundsException e) {

                throw new DBException.EngineGetVoid();
            }
        }
        if(offset<0)
            return null; 
        if(offset == 0){ 
            throw new DBException.EngineGetVoid();
        }

        if(CC.ASSERT){
            int instruction = vol.getUnsignedByte(offset);

            if(instruction!= I_UPDATE && instruction!= I_INSERT)
                throw new RuntimeException("wrong instruction "+instruction); 

            long recid2 = vol.getSixLong(offset+1);
            if(recid!=recid2)
                throw new RuntimeException("recid does not match"); 
        }

        int size = vol.getInt(offset+1+6);
        DataInput input = vol.getDataInputOverlap(offset+1+6+4,size);
        return deserialize(serializer, size, input);
    }

    @Override
    protected void update2(long recid, DataIO.DataOutputByteArray out) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));
        int len = out==null? -1:out.pos;
        long plus = 1+6+4+len;
        long offset = alloc(1+6+4, (int) plus);
        vol.ensureAvailable(offset+plus);
        vol.putUnsignedByte(offset, I_UPDATE);
        vol.putSixLong(offset + 1, recid);
        vol.putInt(offset + 1 + 6, len);
        if(len!=-1)
            vol.putDataOverlap(offset+1+6+4, out.buf,0,out.pos);

        indexTablePut(recid, len != -1 ? offset : -3);
    }

    @Override
    protected <A> void delete2(long recid, Serializer<A> serializer) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));

        int plus = 1+6;
        long offset = alloc(plus,plus);

        vol.ensureAvailable(offset + plus);
        vol.putUnsignedByte(offset, I_DELETE); 
        vol.putSixLong(offset+1, recid);

        indexTablePut(recid, -1);
    }

    @Override
    public long getCurrSize() {
        return 0;
    }

    @Override
    public long getFreeSize() {
        return 0;
    }

    @Override
    public long preallocate() {
        long recid = highestRecid.incrementAndGet();
        Lock lock = locks[lockPos(recid)].writeLock();
        lock.lock();
        try{
            int plus = 1+6;
            long offset = alloc(plus,plus);
            vol.ensureAvailable(offset + plus);

            vol.putUnsignedByte(offset, I_PREALLOC);
            vol.putSixLong(offset + 1, recid);

            indexTablePut(recid,-2);
        }finally {
            lock.unlock();
        }

        return recid;
    }

    protected void indexTablePut(long recid, long offset) {
        if(tx){
            modified[lockPos(recid)].put(recid,offset);
        }else {
            indexTable.ensureAvailable(recid*8+8);
            indexTable.putLong(recid * 8, offset);
        }
    }

    @Override
    public <A> long put(A value, Serializer<A> serializer) {
        DataIO.DataOutputByteArray out = serialize(value,serializer);
        long recid = highestRecid.incrementAndGet();
        int lockPos = lockPos(recid);
        Cache cache = caches==null ? null : caches[lockPos] ;
        Lock lock = locks[lockPos].writeLock();
        lock.lock();
        try{
            if(cache!=null) {
                cache.put(recid, value);
            }
            long plus = 1+6+4+out.pos;
            long offset = alloc(1+6+4, (int) plus);
            vol.ensureAvailable(offset+plus);
            vol.putUnsignedByte(offset, I_INSERT);
            vol.putSixLong(offset+1,recid);
            vol.putInt(offset+1+6, out.pos);
            vol.putDataOverlap(offset+1+6+4, out.buf,0,out.pos);

            indexTablePut(recid,offset);
        }finally {
            lock.unlock();
        }

        return recid;
    }

    @Override
    public void close() {
        if(closed)
            return;
        commitLock.lock();
        try {
            if(closed)
                return;

            if(isSnapshot){
                snapshots.remove(this);
                return;
            }

            vol.sync();
            vol.close();
            indexTable.close();

            if(caches!=null){
                for(Cache c:caches){
                    c.close();
                }
                Arrays.fill(caches,null);
            }
            closed = true;
        }finally{
            commitLock.unlock();
        }
    }

    @Override
    public void commit() {
        if(isSnapshot)
            return;

        if(!tx){
            vol.sync();
            return;
        }

        commitLock.lock();
        try{
            StoreAppend[] snaps = snapshots==null ?
                    STORE_APPENDS_ZERO_ARRAY :
                    snapshots.toArray(STORE_APPENDS_ZERO_ARRAY);

            for(int i=0;i<locks.length;i++) {
                Lock lock = locks[i].writeLock();
                lock.lock();
                try {
                    long[] m = modified[i].table;
                    for(int j=0;j<m.length;j+=2){
                        long recid = m[j];
                        long recidOffset = recid*8;
                        if(recidOffset==0)
                            continue;
                        indexTable.ensureAvailable(recidOffset + 8);
                        long oldVal = indexTable.getLong(recidOffset);
                        indexTable.putLong(recidOffset,m[j+1]);

                        for(StoreAppend snap:snaps){
                            LongLongMap m2 = snap.modified[i];
                            if(m2.get(recid)==0) {
                                m2.put(recid, oldVal);
                            }
                        }
                    }
                    modified[i].clear();
                }finally {
                    lock.unlock();
                }
            }
            long offset = alloc(1,1);
            vol.putUnsignedByte(offset,I_TX_VALID);
            vol.sync();
        }finally {
            commitLock.unlock();
        }
    }

    @Override
    public void rollback() throws UnsupportedOperationException {
        if(!tx || readonly || isSnapshot)
            throw new UnsupportedOperationException();
        commitLock.lock();
        try{
            for(int i=0;i<locks.length;i++) {
                Lock lock = locks[i].writeLock();
                lock.lock();
                try {
                    modified[i].clear();
                }finally {
                    lock.unlock();
                }
            }
            long offset = alloc(1,1);
            vol.putUnsignedByte(offset,I_TX_ROLLBACK);
            vol.sync();
        }finally {
            commitLock.unlock();
        }
    }



    @Override
    public boolean canRollback() {
        return tx;
    }

    @Override
    public boolean canSnapshot() {
        return true;
    }

    @Override
    public Engine snapshot() throws UnsupportedOperationException {
        commitLock.lock();
        try {
            return new StoreAppend(this, modified);
        }finally {
            commitLock.unlock();
        }
    }


    @Override
    public void compact() {
        if(isSnapshot)
            return;

    }
}

<code block>


package org.mapdb;


import java.io.DataInput;
import java.io.File;
import java.io.IOError;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.LockSupport;
import java.util.concurrent.locks.ReentrantLock;

import static org.mapdb.DataIO.*;


public class StoreWAL extends StoreCached {


    protected static final long WAL_SEAL = 8234892392398238983L;

    protected static final int FULL_REPLAY_AFTER_N_TX = 16;



    protected final LongLongMap[] prevLongLongs;
    protected final LongLongMap[] currLongLongs;
    protected final LongLongMap[] prevDataLongs;
    protected final LongLongMap[] currDataLongs;

    protected final LongLongMap pageLongStack = new LongLongMap();
    protected final List<Volume> volumes = Collections.synchronizedList(new ArrayList<Volume>());


    protected volatile Volume walC;


    protected volatile Volume walCCompact;


    protected final List<Volume> walRec = Collections.synchronizedList(new ArrayList<Volume>());

    protected final ReentrantLock compactLock = new ReentrantLock(CC.FAIR_LOCKS);

    protected volatile boolean compactionInProgress = false;

    protected Volume curVol;

    protected int fileNum = -1;


    protected final AtomicLong walOffset = new AtomicLong();

    protected Volume headVolBackup;

    protected long[] indexPagesBackup;

    protected Volume realVol;

    protected volatile boolean $_TEST_HACK_COMPACT_PRE_COMMIT_WAIT =false;

    protected volatile boolean $_TEST_HACK_COMPACT_POST_COMMIT_WAIT =false;


    public StoreWAL(String fileName) {
        this(fileName,
                fileName == null ? CC.DEFAULT_MEMORY_VOLUME_FACTORY : CC.DEFAULT_FILE_VOLUME_FACTORY,
                null,
                CC.DEFAULT_LOCK_SCALE,
                0,
                false, false, null, false,false, 0,
                false, 0,
                null, 0L,
                0);
    }

    public StoreWAL(
            String fileName,
            Volume.VolumeFactory volumeFactory,
            Cache cache,
            int lockScale,
            int lockingStrategy,
            boolean checksum,
            boolean compress,
            byte[] password,
            boolean readonly,
            boolean snapshotEnable,
            int freeSpaceReclaimQ,
            boolean commitFileSyncDisable,
            int sizeIncrement,
            ScheduledExecutorService executor,
            long executorScheduledRate,
            int writeQueueSize
        ) {
        super(fileName, volumeFactory, cache,
                lockScale,
                lockingStrategy,
                checksum, compress, password, readonly, snapshotEnable,
                freeSpaceReclaimQ, commitFileSyncDisable, sizeIncrement,
                executor,
                executorScheduledRate,
                writeQueueSize);
        prevLongLongs = new LongLongMap[this.lockScale];
        currLongLongs = new LongLongMap[this.lockScale];
        for (int i = 0; i < prevLongLongs.length; i++) {
            prevLongLongs[i] = new LongLongMap();
            currLongLongs[i] = new LongLongMap();
        }
        prevDataLongs = new LongLongMap[this.lockScale];
        currDataLongs = new LongLongMap[this.lockScale];
        for (int i = 0; i < prevDataLongs.length; i++) {
            prevDataLongs[i] = new LongLongMap();
            currDataLongs[i] = new LongLongMap();
        }

    }


    @Override
    protected void initCreate() {
        super.initCreate();
        indexPagesBackup = indexPages.clone();
        realVol = vol;

        vol = new Volume.ReadOnly(vol);


        walStartNextFile();
    }

    @Override
    public void initOpen(){


        realVol = vol;


        String wal0Name = getWalFileName("0");
        String walCompSeal = getWalFileName("c");
        boolean walCompSealExists =
                walCompSeal!=null &&
                        new File(walCompSeal).exists();

        if(walCompSealExists ||
             (wal0Name!=null &&
                     new File(wal0Name).exists())){


            walC =  walCompSealExists?volumeFactory.makeVolume(walCompSeal, readonly) : null;
            walCCompact = walCompSealExists? volumeFactory.makeVolume(walCompSeal + ".compact", readonly) : null;

            for(int i=0;;i++){
                String rname = getWalFileName("r"+i);
                if(!new File(rname).exists())
                    break;
                walRec.add(volumeFactory.makeVolume(rname, readonly));
            }



            for(int i=0;;i++){
                String wname = getWalFileName(""+i);
                if(!new File(wname).exists())
                    break;
                volumes.add(volumeFactory.makeVolume(wname, readonly));
            }

            initOpenPost();

            replayWAL();

            if(walC!=null)
                walC.close();
            walC = null;
            if(walCCompact!=null)
                walCCompact.close();
            walCCompact = null;
            for(Volume v:walRec){
                v.close();
            }
            walRec.clear();
            volumes.clear();
        }


        walStartNextFile();

        initOpenPost();
    }

    @Override
    protected void initFailedCloseFiles() {
        if(walC!=null && !walC.isClosed()) {
            walC.close();
        }
        walC = null;

        if(walCCompact!=null && !walCCompact.isClosed()) {
            walCCompact.close();
        }
        walCCompact = null;

        if(walRec!=null){
            for(Volume v:walRec){
                if(v!=null && !v.isClosed())
                    v.close();
            }
            walRec.clear();
        }
        if(volumes!=null){
            for(Volume v:volumes){
                if(v!=null && !v.isClosed())
                    v.close();
            }
            volumes.clear();
        }
    }

    protected void initOpenPost() {
        super.initOpen();
        indexPagesBackup = indexPages.clone();



        vol = new Volume.ReadOnly(vol);
    }


    @Override
    protected void initHeadVol() {
        super.initHeadVol();

        if(headVolBackup!=null && !headVolBackup.isClosed())
            headVolBackup.close();
        headVolBackup = new Volume.ByteArrayVol(CC.VOLUME_PAGE_SHIFT);
        headVolBackup.ensureAvailable(HEAD_END);
        byte[] b = new byte[(int) HEAD_END];

        headVol.getData(0,b,0,b.length);
        headVolBackup.putData(0,b,0,b.length);
    }

    protected void walStartNextFile() {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        fileNum++;
        if (CC.ASSERT && fileNum != volumes.size())
            throw new AssertionError();
        String filewal = getWalFileName(""+fileNum);
        Volume nextVol;
        if (readonly && filewal != null && !new File(filewal).exists()){
            nextVol = new Volume.ReadOnly(new Volume.ByteArrayVol(8));
        }else {
            nextVol = volumeFactory.makeVolume(filewal, readonly);
        }
        nextVol.ensureAvailable(16);

        walOffset.set(16);
        volumes.add(nextVol);

        curVol = nextVol;
    }

    protected String getWalFileName(String ext) {
        return fileName==null? null :
                fileName+".wal"+"."+ext;
    }

    protected void walPutLong(long offset, long value){
        final int plusSize = +1+8+6;
        long walOffset2 = walOffset.getAndAdd(plusSize);

        Volume curVol2 = curVol;


        if(hadToSkip(walOffset2, plusSize)){
            walPutLong(offset, value);
            return;
        }

        if(CC.ASSERT && offset>>>48!=0)
            throw new AssertionError();
        curVol2.ensureAvailable(walOffset2+plusSize);
        int parity = 1+Long.bitCount(value)+Long.bitCount(offset);
        parity &=15;
        curVol2.putUnsignedByte(walOffset2, (1 << 4)|parity);
        walOffset2+=1;
        curVol2.putLong(walOffset2, value);
        walOffset2+=8;
        curVol2.putSixLong(walOffset2, offset);
    }


    protected void walPutUnsignedShort(long offset, int value) {
        final int plusSize = +1+8;
        long walOffset2 = walOffset.getAndAdd(plusSize);

        Volume curVol2 = curVol;


        if(hadToSkip(walOffset2, plusSize)){
            walPutUnsignedShort(offset, value);
            return;
        }

        curVol2.ensureAvailable(walOffset2+plusSize);
        if(CC.ASSERT && offset>>>48!=0)
            throw new AssertionError();
        offset = (((long)value)<<48) | offset;
        int parity = 1+Long.bitCount(offset);
        parity &=15;
        curVol2.putUnsignedByte(walOffset2, (6 << 4)|parity);
        walOffset2+=1;
        curVol2.putLong(walOffset2, offset);
    }

    protected boolean hadToSkip(long walOffset2, int plusSize) {

        if((walOffset2>>>CC.VOLUME_PAGE_SHIFT)==(walOffset2+plusSize)>>>CC.VOLUME_PAGE_SHIFT){
            return false; 
        }


        while((walOffset2&PAGE_MASK) >= PAGE_SIZE-4 || plusSize<5){

            int singleByteSkip = (4<<4)|(Long.bitCount(walOffset2)&15);
            curVol.putUnsignedByte(walOffset2++, singleByteSkip);
            plusSize--;
            if(CC.ASSERT && plusSize<0)
                throw new AssertionError();
        }


        int val = (3<<(4+3*8)) | (plusSize-4) | ((Integer.bitCount(plusSize-4)&15)<<(3*8));
        curVol.ensureAvailable(walOffset2 + 4);
        curVol.putInt(walOffset2, val);

        return true;
    }

    @Override
    protected void putDataSingleWithLink(int segment, long offset, long link, byte[] buf, int bufPos, int size) {
        if(CC.ASSERT && (size&0xFFFF)!=size)
            throw new AssertionError();

        byte[] buf2 = new  byte[size+8];
        DataIO.putLong(buf2,0,link);
        System.arraycopy(buf,bufPos,buf2,8,size);
        putDataSingleWithoutLink(segment,offset,buf2,0,buf2.length);
    }

    @Override
    protected void putDataSingleWithoutLink(int segment, long offset, byte[] buf, int bufPos, int size) {
        if(CC.ASSERT && (size&0xFFFF)!=size)
            throw new AssertionError();
        if(CC.ASSERT && (offset%16!=0 && offset!=4))
            throw new AssertionError();


        if(CC.ASSERT && segment!=-1)
            assertWriteLocked(segment);
        if(CC.ASSERT && segment==-1 && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        final int plusSize = +1+2+6+size;
        long walOffset2 = walOffset.getAndAdd(plusSize);

        if(hadToSkip(walOffset2, plusSize)){
            putDataSingleWithoutLink(segment,offset,buf,bufPos,size);
            return;
        }

        curVol.ensureAvailable(walOffset2+plusSize);
        int checksum = 1+Integer.bitCount(size)+Long.bitCount(offset)+sum(buf,bufPos,size);
        checksum &= 15;
        curVol.putUnsignedByte(walOffset2, (2 << 4)|checksum);
        walOffset2+=1;
        curVol.putLong(walOffset2, ((long) size) << 48 | offset);
        walOffset2+=8;
        curVol.putData(walOffset2, buf,bufPos,size);


        long val = ((long)size)<<48;
        val |= ((long)fileNum)<<32;
        val |= walOffset2;

        (segment==-1?pageLongStack:currDataLongs[segment]).put(offset, val);
    }


    protected DataInput walGetData(long offset, int segment) {
        if (CC.ASSERT && offset % 16 != 0)
            throw new AssertionError();

        long longval = currDataLongs[segment].get(offset);
        if(longval==0){
            longval = prevDataLongs[segment].get(offset);
        }
        if(longval==0)
            return null;

        int arraySize = (int) (longval >>> 48);
        int fileNum = (int) ((longval >>> 32) & 0xFFFFL);
        long dataOffset = longval & 0xFFFFFFFFL;

        Volume vol = volumes.get(fileNum);
        return vol.getDataInput(dataOffset, arraySize);
    }

    @Override
    protected long indexValGet(long recid) {
        if(CC.ASSERT)
            assertReadLocked(recid);
        int segment = lockPos(recid);
        long offset = recidToOffset(recid);
        long ret = currLongLongs[segment].get(offset);
        if(ret!=0) {
            return ret;
        }
        ret = prevLongLongs[segment].get(offset);
        if(ret!=0)
            return ret;
        return super.indexValGet(recid);
    }

    @Override
    protected void indexValPut(long recid, int size, long offset, boolean linked, boolean unused) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));



        long newVal = composeIndexVal(size, offset, linked, unused, true);
        currLongLongs[lockPos(recid)].put(recidToOffset(recid), newVal);
    }

    @Override
    protected void indexLongPut(long offset, long val) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw  new AssertionError();
        if(CC.ASSERT && compactionInProgress)
            throw new AssertionError();
        walPutLong(offset,val);
    }

    @Override
    protected long pageAllocate() {




        long storeSize = parity16Get(headVol.getLong(STORE_SIZE));
        headVol.putLong(STORE_SIZE, parity16Set(storeSize + PAGE_SIZE));


        if(CC.ASSERT && storeSize%PAGE_SIZE!=0)
            throw new AssertionError();


        return storeSize;
    }

    @Override
    protected byte[] loadLongStackPage(long pageOffset) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();






        byte[] page = dirtyStackPages.get(pageOffset);
        if (page != null) {
            return page;
        }


        long walval = pageLongStack.get(pageOffset);
        if(walval!=0){

            int arraySize = (int) (walval >>> 48);
            int fileNum = (int) ((walval >>> 32) & 0xFFFFL);
            long dataOffset = walval & 0xFFFFFFFFL;

            byte[] b = new byte[arraySize];
            Volume vol = volumes.get(fileNum);
            vol.getData(dataOffset, b, 0, arraySize);

            dirtyStackPages.put(pageOffset, b);
            return b;
        }


        int pageSize = (int) (parity4Get(vol.getLong(pageOffset)) >>> 48);
        page = new byte[pageSize];
        vol.getData(pageOffset, page, 0, pageSize);
        dirtyStackPages.put(pageOffset, page);
        return page;
    }

    @Override
    protected <A> A get2(long recid, Serializer<A> serializer) {
        if (CC.ASSERT)
            assertReadLocked(recid);
        int segment = lockPos(recid);


        {
            Object cached = writeCache[segment].get1(recid);
            if (cached != null) {
                if(cached==TOMBSTONE2)
                    return null;
                return (A) cached;
            }
        }

        {
            long walval = currLongLongs[segment].get(recidToOffset(recid));
            if(walval==0) {
                walval = prevLongLongs[segment].get(recidToOffset(recid));
            }

            if(walval!=0){
                if(compactionInProgress){

                    if(walval==Long.MAX_VALUE) 
                        return null;
                    final int fileNum = (int) (walval>>>(5*8));
                    Volume recVol = walRec.get(fileNum);
                    long offset = walval&0xFFFFFFFFFFL; 
                    if(CC.ASSERT){
                        int instruction = recVol.getUnsignedByte(offset);
                        if(instruction!=(5<<4))
                            throw new AssertionError("wrong instruction");
                        if(recid!=recVol.getSixLong(offset+1))
                            throw new AssertionError("wrong recid");
                    }


                    offset+=1+6;
                    final int size = recVol.getInt(offset);

                    final DataInput in = size==0?
                            new DataIO.DataInputByteArray(new byte[0]):
                            recVol.getDataInput(offset+4,size);

                    return deserialize(serializer, size, in);
                }


                boolean linked = (walval&MLINKED)!=0;
                int size = (int) (walval>>>48);
                if(linked && size==0)
                    return null;
                if(size==0){
                    return deserialize(serializer,0,new DataIO.DataInputByteArray(new byte[0]));
                }
                if(linked)try {

                    int totalSize = 0;
                    byte[] in = new byte[100];
                    long link = walval;
                    while((link&MLINKED)!=0){
                        DataInput in2 = walGetData(link&MOFFSET, segment);
                        int chunkSize = (int) (link>>>48);

                        link = in2.readLong();

                        if(in.length<totalSize+chunkSize-8){
                            in = Arrays.copyOf(in, Math.max(in.length*2,totalSize+chunkSize-8 ));
                        }
                        in2.readFully(in,totalSize, chunkSize-8);
                        totalSize+=chunkSize-8;
                    }


                    DataInput in2 = walGetData(link&MOFFSET, segment);
                    int chunkSize = (int) (link>>>48);

                    if(in.length<totalSize+chunkSize){
                        in = Arrays.copyOf(in, Math.max(in.length*2,totalSize+chunkSize ));
                    }
                    in2.readFully(in,totalSize, chunkSize);
                    totalSize+=chunkSize;

                    return deserialize(serializer, totalSize,new DataIO.DataInputByteArray(in,0));
                } catch (IOException e) {
                    throw new IOError(e);
                }


                DataInput in = walGetData(walval&MOFFSET, segment);
                return deserialize(serializer, (int) (walval>>>48),in);
            }
        }

        long[] offsets = offsetsGet(indexValGet(recid));
        if (offsets == null) {
            return null; 
        }else if (offsets.length==0){
            return deserialize(serializer,0,new DataIO.DataInputByteArray(new byte[0]));
        }else if (offsets.length == 1) {

            int size = (int) (offsets[0] >>> 48);
            long offset = offsets[0] & MOFFSET;
            DataInput in = vol.getDataInput(offset, size);
            return deserialize(serializer, size, in);
        } else {

            int totalSize = offsetsTotalSize(offsets);


            byte[] b = new byte[totalSize];
            int bpos = 0;
            for (int i = 0; i < offsets.length; i++) {
                int plus = (i == offsets.length - 1)?0:8;
                long size = (offsets[i] >>> 48) - plus;
                if(CC.ASSERT && (size&0xFFFF)!=size)
                    throw new AssertionError("size mismatch");
                long offset = offsets[i] & MOFFSET;
                vol.getData(offset + plus, b, bpos, (int) size);
                bpos += size;
            }
            if (CC.ASSERT && bpos != totalSize)
                throw new AssertionError("size does not match");

            DataInput in = new DataIO.DataInputByteArray(b);
            return deserialize(serializer, totalSize, in);
        }

    }

    @Override
    public void rollback() throws UnsupportedOperationException {
        commitLock.lock();
        try {

            for (int segment = 0; segment < locks.length; segment++) {
                Lock lock = locks[segment].writeLock();
                lock.lock();
                try {
                    writeCache[segment].clear();
                    if(caches!=null) {
                        caches[segment].clear();
                    }
                } finally {
                    lock.unlock();
                }
            }

            structuralLock.lock();
            try {
                dirtyStackPages.clear();


                byte[] b = new byte[(int) HEAD_END];

                headVolBackup.getData(0,b,0,b.length);
                headVol.putData(0,b,0,b.length);

                lastAllocatedData = parity3Get(headVol.getLong(LAST_PHYS_ALLOCATED_DATA_OFFSET));

                indexPages = indexPagesBackup.clone();
            } finally {
                structuralLock.unlock();
            }
        }finally {
            commitLock.unlock();
        }
    }

    @Override
    public void commit() {
        commitLock.lock();
        try{

            if(compactionInProgress){

                String recvalName = getWalFileName("r"+walRec.size());
                Volume v = volumeFactory.makeVolume(recvalName, readonly);
                walRec.add(v);
                v.ensureAvailable(16);
                long offset = 16;

                for(int segment=0;segment<locks.length;segment++) {
                    Lock lock = locks[segment].writeLock();
                    lock.lock();
                    try {
                        LongObjectObjectMap<Object,Serializer> writeCache1 = writeCache[segment];
                        LongLongMap prevLongs = prevLongLongs[segment];
                        long[] set = writeCache1.set;
                        Object[] values = writeCache1.values;
                        for(int i=0;i<set.length;i++){
                            long recid = set[i];
                            if(recid==0)
                                continue;
                            Object value = values[i*2];
                            DataOutputByteArray buf;
                            int size;
                            if (value == TOMBSTONE2) {
                                buf = null;
                                size = -2;
                            } else {
                                Serializer s = (Serializer) values[i*2+1];
                                buf = serialize(value, s); 
                                size = buf==null?-1:buf.pos;
                            }

                            int needed = 1+6+4 +(buf==null?0:buf.pos); 



                            prevLongs.put(recidToOffset(recid),
                                    (((long)fileNum)<<(5*8)) |  
                                    offset                  
                                    );

                            v.putUnsignedByte(offset, (5<<4));
                            offset++;

                            v.putSixLong(offset, recid);
                            offset+=6;

                            v.putInt(offset, size);
                            offset+=4;

                            if(size>0) {
                                v.putData(offset, buf.buf, 0, size);
                                offset+=size;
                            }

                            if(buf!=null)
                                recycledDataOut.lazySet(buf);

                        }
                        writeCache1.clear();

                    } finally {
                        lock.unlock();
                    }
                }
                structuralLock.lock();
                try {

                    v.putUnsignedByte(offset, 0);
                    v.sync();
                    v.putLong(8, StoreWAL.WAL_SEAL);
                    v.sync();
                    return;
                }finally {
                    structuralLock.unlock();
                }
            }


            if(volumes.size()>FULL_REPLAY_AFTER_N_TX && !compactionInProgress) {
                commitFullWALReplay();
                return;
            }



            for(int segment=0;segment<locks.length;segment++){
                Lock lock = locks[segment].writeLock();
                lock.lock();
                try{
                    flushWriteCacheSegment(segment);

                    long[] v = currLongLongs[segment].table;
                    for(int i=0;i<v.length;i+=2){
                        long offset = v[i];
                        if(offset==0)
                            continue;
                        long value = v[i+1];
                        prevLongLongs[segment].put(offset,value);
                        walPutLong(offset,value);
                        if(indexPageCRC && offset>HEAD_END && offset%PAGE_SIZE!=0) {
                            walPutUnsignedShort(offset + 8, DataIO.longHash(value) & 0xFFFF);
                        }
                    }
                    currLongLongs[segment].clear();

                    v = currDataLongs[segment].table;
                    currDataLongs[segment].size=0;
                    for(int i=0;i<v.length;i+=2){
                        long offset = v[i];
                        if(offset==0)
                            continue;
                        long value = v[i+1];
                        prevDataLongs[segment].put(offset,value);
                    }
                    currDataLongs[segment].clear();

                }finally {
                    lock.unlock();
                }
            }
            structuralLock.lock();
            try {

                {
                    long[] set = dirtyStackPages.set;
                    for(int i=0;i<set.length;i++){
                        long offset = set[i];
                        if(offset==0)
                            continue;
                        byte[] val = (byte[]) dirtyStackPages.values[i];

                        if (CC.ASSERT && offset < PAGE_SIZE)
                            throw new AssertionError();
                        if (CC.ASSERT && val.length % 16 != 0)
                            throw new AssertionError();
                        if (CC.ASSERT && val.length <= 0 || val.length > MAX_REC_SIZE)
                            throw new AssertionError();

                        putDataSingleWithoutLink(-1, offset, val, 0, val.length);

                    }
                    dirtyStackPages.clear();
                }

                headVol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET,parity3Set(lastAllocatedData));

                headVol.putInt(HEAD_CHECKSUM, headChecksum(headVol));


                byte[] b = new byte[(int) HEAD_END-4];

                headVol.getData(4, b, 0, b.length);

                putDataSingleWithoutLink(-1, 4L, b, 0, b.length);


                headVolBackup.putData(4, b, 0, b.length);
                indexPagesBackup = indexPages.clone();

                long finalOffset = walOffset.get();
                curVol.ensureAvailable(finalOffset + 1); 

                curVol.putUnsignedByte(finalOffset, (0 << 4) | (Long.bitCount(finalOffset)&15));
                curVol.sync();

                curVol.putLong(8, WAL_SEAL);
                curVol.sync();

                walStartNextFile();

            } finally {
                structuralLock.unlock();
            }
        }finally {
            commitLock.unlock();
        }
    }

    protected void commitFullWALReplay() {
        if(CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();




        for(int i=0;i<locks.length;i++){
            locks[i].writeLock().lock();
        }
        try {

            for(int segment=0;segment<locks.length;segment++){
                flushWriteCacheSegment(segment);

                long[] v = currLongLongs[segment].table;
                for(int i=0;i<v.length;i+=2){
                    long offset = v[i];
                    if(offset==0)
                        continue;
                    long value = v[i+1];
                    walPutLong(offset,value);
                    if(indexPageCRC && offset>HEAD_END && offset%PAGE_SIZE!=0) {
                        walPutUnsignedShort(offset + 8, DataIO.longHash(value) & 0xFFFF);
                    }


                    v[i] = 0;
                    v[i+1] = 0;
                }
                currLongLongs[segment].clear();

                if(CC.ASSERT && currLongLongs[segment].size()!=0)
                    throw new AssertionError();

                currDataLongs[segment].clear();
                prevDataLongs[segment].clear();
                prevLongLongs[segment].clear();
            }
            structuralLock.lock();
            try {

                {
                    long[] set = dirtyStackPages.set;
                    for(int i=0;i<set.length;i++){
                        long offset = set[i];
                        if(offset==0)
                            continue;
                        byte[] val = (byte[]) dirtyStackPages.values[i];

                        if (CC.ASSERT && offset < PAGE_SIZE)
                            throw new AssertionError();
                        if (CC.ASSERT && val.length % 16 != 0)
                            throw new AssertionError();
                        if (CC.ASSERT && val.length <= 0 || val.length > MAX_REC_SIZE)
                            throw new AssertionError();

                        putDataSingleWithoutLink(-1, offset, val, 0, val.length);
                    }
                    dirtyStackPages.clear();
                }
                if(CC.ASSERT && dirtyStackPages.size!=0)
                    throw new AssertionError();

                pageLongStack.clear();

                headVol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET,parity3Set(lastAllocatedData));


                headVol.putInt(HEAD_CHECKSUM, headChecksum(headVol));


                byte[] b = new byte[(int) HEAD_END-4];

                headVol.getData(4, b, 0, b.length);

                putDataSingleWithoutLink(-1, 4L, b, 0, b.length);


                headVolBackup.putData(4, b, 0, b.length);
                indexPagesBackup = indexPages.clone();

                long finalOffset = walOffset.get();
                curVol.ensureAvailable(finalOffset+1); 

                curVol.putUnsignedByte(finalOffset, (0<<4) | (Long.bitCount(finalOffset)&15));
                curVol.sync();

                curVol.putLong(8, WAL_SEAL);
                curVol.sync();


                replayWAL();

                walStartNextFile();
            } finally {
                structuralLock.unlock();
            }
        }finally {
            for(int i=locks.length-1;i>=0;i--){
                locks[i].writeLock().unlock();
            }
        }
    }


    protected void replayWAL(){




        final boolean compaction =
                walC!=null && !walC.isEmpty() &&
                walCCompact!=null && !walCCompact.isEmpty();


        if(compaction){

            walC.ensureAvailable(16);
            boolean walCSeal = walC.getLong(8) == WAL_SEAL;



            if(!walCSeal){
                LOG.warning("Compaction failed, seal not present. Removing incomplete compacted file, keeping old fragmented file.");
                walC.close();
                walC.deleteFile();
                walC = null;
                walCCompact.close();
                walCCompact.deleteFile();
                walCCompact = null;
            }else{


                if(vol.getFile()==null){


                    Volume oldVol = this.vol;
                    this.realVol = walCCompact;
                    this.vol = new Volume.ReadOnly(realVol);
                    this.headVol.close();
                    this.headVolBackup.close();
                    initHeadVol();

                    oldVol.close();
                }else{

                    File walCCompactFile = walCCompact.getFile();
                    walCCompact.sync();
                    walCCompact.close();
                    walCCompact = null;

                    File thisFile = new File(fileName);
                    File thisFileBackup = new File(fileName+".wal.c.orig");

                    this.vol.close();
                    if(!thisFile.renameTo(thisFileBackup)){

                        throw new AssertionError("failed to rename file " + thisFile);
                    }


                    if (!walCCompactFile.renameTo(thisFile)) {

                        throw new AssertionError("failed to rename file " + walCCompactFile);
                    }


                    this.realVol = volumeFactory.makeVolume(this.fileName, readonly);
                    this.vol = new Volume.ReadOnly(this.realVol);
                    this.initHeadVol();


                    if(!thisFileBackup.delete()){
                        LOG.warning("Could not delete original compacted file: "+thisFileBackup);
                    }
                }
                walC.close();
                walC.deleteFile();
                walC = null;

                initOpenPost();
            }
        }

        if(!walRec.isEmpty()){








            structuralLock.lock();
            try {
                walStartNextFile();
            }finally {
                structuralLock.unlock();
            }

            for(Volume wr:walRec){
                if(wr.isEmpty())
                    break;
                wr.ensureAvailable(16); 
                if(wr.getLong(8)!=StoreWAL.WAL_SEAL)
                    break;
                long pos = 16;
                for(;;) {
                    int instr = wr.getUnsignedByte(pos++);
                    if (instr >>> 4 == 0) {

                        break;
                    } else if (instr >>> 4 != 5) {

                        throw new AssertionError("Invalid instruction in WAL REC" + (instr >>> 4));
                    }

                    long recid = wr.getSixLong(pos);
                    pos += 6;
                    int size = wr.getInt(pos);

                    pos += 4;
                    byte[] arr = new byte[size]; 
                    wr.getData(pos, arr, 0, size);
                    pos += size;
                    update(recid, arr, Serializer.BYTE_ARRAY_NOSIZE);
                }
            }
            List<Volume> l = new ArrayList(walRec);
            walRec.clear();
            commitFullWALReplay();

            for(Volume wr:l){
                File f = wr.getFile();
                wr.close();
                wr.deleteFile();
                if(f!=null && f.exists() && !f.delete()){
                    LOG.warning("Could not delete WAL REC file: "+f);
                }
            }
            walRec.clear();
        }


        replayWALInstructionFiles();
    }

    private void replayWALInstructionFiles() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();

        file:for(Volume wal:volumes){
            if(wal.isEmpty()) {
                break file;
            }
            if(wal.getLong(8)!=WAL_SEAL) {
                break file;

            }

            long pos = 16;
            for(;;) {
                int checksum = wal.getUnsignedByte(pos++);
                int instruction = checksum>>>4;
                checksum = (checksum&15);
                if (instruction == 0) {

                    if((Long.bitCount(pos-1)&15) != checksum)
                        throw new InternalError("WAL corrupted");
                    continue file;
                } else if (instruction == 1) {

                    long val = wal.getLong(pos);
                    pos += 8;
                    long offset = wal.getSixLong(pos);
                    pos += 6;
                    if(((1+Long.bitCount(val)+Long.bitCount(offset))&15)!=checksum)
                        throw new InternalError("WAL corrupted");
                    realVol.ensureAvailable(offset+8);
                    realVol.putLong(offset, val);
                } else if (instruction == 2) {

                    int dataSize = wal.getUnsignedShort(pos);
                    pos += 2;
                    long offset = wal.getSixLong(pos);
                    pos += 6;
                    byte[] data = new byte[dataSize];
                    wal.getData(pos, data, 0, data.length);
                    pos += data.length;
                    if(((1+Integer.bitCount(dataSize)+Long.bitCount(offset)+sum(data))&15)!=checksum)
                        throw new InternalError("WAL corrupted");

                    realVol.ensureAvailable(offset+data.length);
                    realVol.putData(offset, data, 0, data.length);
                } else if (instruction == 3) {

                    int skipN = wal.getInt(pos - 1) & 0xFFFFFF; 
                    if((Integer.bitCount(skipN)&15) != checksum)
                        throw new InternalError("WAL corrupted");
                    pos += 3 + skipN;
                } else if (instruction == 4) {

                    if((Long.bitCount(pos-1)&15) != checksum)
                        throw new InternalError("WAL corrupted");
                } else if (instruction == 6) {

                    long s = wal.getLong(pos);
                    pos+=8;
                    if(((1+Long.bitCount(s))&15) != checksum)
                        throw new InternalError("WAL corrupted");
                    long offset = s&0xFFFFFFFFFFFFL;
                    realVol.ensureAvailable(offset + 2);
                    realVol.putUnsignedShort(offset, (int) (s>>>48));
                }else{
                    throw new InternalError("WAL corrupted, unknown instruction");
                }

            }
        }

        realVol.sync();


        for(Volume wal:volumes){
            wal.truncate(0);
            wal.close();
            wal.deleteFile();

        }
        fileNum = -1;
        curVol = null;
        volumes.clear();
    }

    private int sum(byte[] data) {
        int ret = 0;
        for(byte b:data){
            ret+=b;
        }
        return Math.abs(ret);
    }

    private int sum(byte[] buf, int bufPos, int size) {
        int ret = 0;
        size+=bufPos;
        while(bufPos<size){
            ret+=buf[bufPos++];
        }
        return Math.abs(ret);
    }


    @Override
    public boolean canRollback() {
        return true;
    }

    @Override
    public void close() {
        compactLock.lock();
        try{
            commitLock.lock();
            try{

                if(closed) {
                    return;
                }

                if(hasUncommitedData()){
                    LOG.warning("Closing storage with uncommited data, those data will be discarted.");
                }



                if(!readonly) {
                    structuralLock.lock();
                    try {
                        replayWAL();
                    } finally {
                        structuralLock.unlock();
                    }
                }

                if(walC!=null)
                    walC.close();
                if(walCCompact!=null)
                    walCCompact.close();


                for(Volume v:walRec){
                    v.close();
                }
                walRec.clear();


                for(Volume v:volumes){
                    v.close();
                }
                volumes.clear();

                vol.close();
                vol = null;

                headVol.close();
                headVol = null;
                headVolBackup.close();
                headVolBackup = null;

                curVol = null;
                dirtyStackPages.clear();

                if(caches!=null){
                    for(Cache c:caches){
                        c.close();
                    }
                    Arrays.fill(caches,null);
                }
                closed = true;
            }finally {
                commitLock.unlock();
            }
        }finally {
            compactLock.unlock();
        }
    }

    @Override
    public void compact() {
        compactLock.lock();

        try{

            if(compactOldFilesExists())
                return;

            commitLock.lock();
            try{

                if(hasUncommitedData()){

                    LOG.warning("Compaction started with uncommited data. Calling commit automatically.");
                }

                snapshotCloseAllOnCompact();


                commitFullWALReplay();

                compactionInProgress = true;


                structuralLock.lock();
                try {
                    if(CC.ASSERT && fileNum!=0)
                        throw new AssertionError();
                    if(CC.ASSERT && walC!=null)
                        throw new AssertionError();


                    String walCFileName = getWalFileName("c");
                    if(walC!=null)
                        walC.close();
                    walC = volumeFactory.makeVolume(walCFileName, readonly);
                    walC.ensureAvailable(16);
                    walC.putLong(0,0); 
                    walC.putLong(8,0);

                }finally {
                    structuralLock.unlock();
                }
            }finally {
                commitLock.unlock();
            }

            final long maxRecidOffset = parity1Get(headVol.getLong(MAX_RECID_OFFSET));


            final String targetFile = getWalFileName("c.compact");

            final StoreDirect target = new StoreDirect(targetFile,
                    volumeFactory,
                    null,lockScale,
                    executor==null?LOCKING_STRATEGY_NOLOCK:LOCKING_STRATEGY_WRITELOCK,
                    checksum,compress,null,false,false,0,false,0,
                    null);
            target.init();
            walCCompact = target.vol;

            final AtomicLong maxRecid = new AtomicLong(RECID_LAST_RESERVED);

            compactIndexPages(maxRecidOffset, target, maxRecid);

            while($_TEST_HACK_COMPACT_PRE_COMMIT_WAIT){
                LockSupport.parkNanos(10000);
            }


            target.vol.putLong(MAX_RECID_OFFSET, parity1Set(maxRecid.get() * indexValSize));


            target.commit(); 

            walC.putLong(8, WAL_SEAL);
            walC.sync();


            commitLock.lock();
            try{

                if(hasUncommitedData()){
                    LOG.warning("Uncommited data at end of compaction, autocommit");

                }

                commitFullWALReplay();

                compactionInProgress = false;
            }finally {
                commitLock.unlock();
            }

            while($_TEST_HACK_COMPACT_POST_COMMIT_WAIT){
                LockSupport.parkNanos(10000);
            }

        }finally {
            compactionInProgress = false; 
            compactLock.unlock();
        }
    }


    protected boolean hasUncommitedData() {
        for(int i=0;i<locks.length;i++){
            final Lock lock  = locks[i].readLock();
            lock.lock();
            try{
                if(currLongLongs[i].size()!=0 ||
                        currDataLongs[i].size()!=0 ||
                        writeCache[i].size!=0)
                    return true;
            }finally {
                lock.unlock();
            }
        }
        return false;
    }
}

<code block>
package org.mapdb;

import java.util.Arrays;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.Lock;

import static org.mapdb.DataIO.*;


public class StoreCached extends StoreDirect {




    protected final LongObjectMap<byte[]> dirtyStackPages = new LongObjectMap<byte[]>();
    protected final LongObjectObjectMap[] writeCache;

    protected final static Object TOMBSTONE2 = new Object(){
        @Override
        public String toString() {
            return StoreCached.class.getName()+".TOMBSTONE2";
        }
    };

    protected final int writeQueueSize;
    protected final int writeQueueSizePerSegment;
    protected final boolean flushInThread;

    public StoreCached(
            String fileName,
            Volume.VolumeFactory volumeFactory,
            Cache cache,
            int lockScale,
            int lockingStrategy,
            boolean checksum,
            boolean compress,
            byte[] password,
            boolean readonly,
            boolean snapshotEnable,
            int freeSpaceReclaimQ,
            boolean commitFileSyncDisable,
            int sizeIncrement,
            ScheduledExecutorService executor,
            long executorScheduledRate,
            final int writeQueueSize) {
        super(fileName, volumeFactory, cache,
                lockScale,
                lockingStrategy,
                checksum, compress, password, readonly, snapshotEnable,
                freeSpaceReclaimQ, commitFileSyncDisable, sizeIncrement,executor);

        this.writeQueueSize = writeQueueSize;
        this.writeQueueSizePerSegment = writeQueueSize/lockScale;

        writeCache = new LongObjectObjectMap[this.lockScale];
        for (int i = 0; i < writeCache.length; i++) {
            writeCache[i] = new LongObjectObjectMap();
        }

        flushInThread = this.executor==null &&
                writeQueueSize!=0 &&
                !(this instanceof StoreWAL); 

        if(this.executor!=null &&
                !(this instanceof StoreWAL) 
                ){
            for(int i=0;i<this.lockScale;i++){
                final int seg = i;
                final Lock lock = locks[i].writeLock();
                this.executor.scheduleAtFixedRate(new Runnable() {
                    @Override
                    public void run() {
                        lock.lock();
                        try {
                            if(writeCache[seg].size>writeQueueSizePerSegment) {
                                flushWriteCacheSegment(seg);
                            }
                        }finally {
                            lock.unlock();
                        }
                    }
                    },
                        (long) (executorScheduledRate*Math.random()),
                        executorScheduledRate,
                        TimeUnit.MILLISECONDS);
            }
        }
    }


    public StoreCached(String fileName) {
        this(fileName,
                fileName==null? CC.DEFAULT_MEMORY_VOLUME_FACTORY : CC.DEFAULT_FILE_VOLUME_FACTORY,
                null,
                CC.DEFAULT_LOCK_SCALE,
                0,
                false, false, null, false, false, 0,
                false, 0,
                null, 0L, 0);
    }



    @Override
    protected void initHeadVol() {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        if(this.headVol!=null && !this.headVol.isClosed())
            headVol.close();
        this.headVol = new Volume.SingleByteArrayVol((int) HEAD_END);
        vol.transferInto(0,headVol,0,HEAD_END);
    }


    @Override
    protected void longStackPut(long masterLinkOffset, long value, boolean recursive) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if (CC.ASSERT && (masterLinkOffset <= 0 || masterLinkOffset > PAGE_SIZE || masterLinkOffset % 8 != 0))
            throw new AssertionError();

        long masterLinkVal = parity4Get(headVol.getLong(masterLinkOffset));
        long pageOffset = masterLinkVal & MOFFSET;

        if (masterLinkVal == 0L) {
            longStackNewPage(masterLinkOffset, 0L, value);
            return;
        }

        byte[] page = loadLongStackPage(pageOffset);

        long currSize = masterLinkVal >>> 48;

        long prevLinkVal = parity4Get(DataIO.getLong(page, 0));
        long pageSize = prevLinkVal >>> 48;

        if (currSize + 8 >= pageSize) {


            Arrays.fill(page, (int) currSize, (int) pageSize, (byte) 0);

            longStackNewPage(masterLinkOffset, pageOffset, value);
            return;
        }


        currSize += DataIO.packLongBidi(page, (int) currSize, longStackValParitySet(value));


        headVol.putLong(masterLinkOffset, parity4Set(currSize << 48 | pageOffset));
    }

    @Override
    protected long longStackTake(long masterLinkOffset, boolean recursive) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if (CC.ASSERT && (masterLinkOffset < FREE_RECID_STACK ||
                masterLinkOffset > FREE_RECID_STACK + round16Up(MAX_REC_SIZE) / 2 ||
                masterLinkOffset % 8 != 0))
            throw new AssertionError();

        long masterLinkVal = parity4Get(headVol.getLong(masterLinkOffset));
        if (masterLinkVal == 0) {
            return 0;
        }
        long currSize = masterLinkVal >>> 48;
        final long pageOffset = masterLinkVal & MOFFSET;

        byte[] page = loadLongStackPage(pageOffset);


        long ret = DataIO.unpackLongBidiReverse(page, (int) currSize);

        long oldCurrSize = currSize;
        currSize -= ret >>> 56;

        Arrays.fill(page, (int) currSize, (int) oldCurrSize, (byte) 0);

        ret = longStackValParityGet(ret & DataIO.PACK_LONG_BIDI_MASK);

        if (CC.ASSERT && currSize < 8)
            throw new AssertionError();


        if (currSize > 8) {

            headVol.putLong(masterLinkOffset, parity4Set(currSize << 48 | pageOffset));
            return ret;
        }


        long prevPageOffset = parity4Get(DataIO.getLong(page, 0));
        final int currPageSize = (int) (prevPageOffset >>> 48);
        prevPageOffset &= MOFFSET;


        if (prevPageOffset != 0) {


            byte[] page2 = loadLongStackPage(prevPageOffset);





            currSize = parity4Get(DataIO.getLong(page2, 0)) >>> 48;


            while (page2[((int) (currSize - 1))] == 0) {
                currSize--;
            }

            if (CC.ASSERT && currSize < 10)
                throw new AssertionError();
        } else {

            currSize = 0;
        }


        headVol.putLong(masterLinkOffset, parity4Set(currSize << 48 | prevPageOffset));


        dirtyStackPages.remove(pageOffset);
        freeDataPut(pageOffset, currPageSize);


        return ret;
    }

    protected byte[] loadLongStackPage(long pageOffset) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        byte[] page = dirtyStackPages.get(pageOffset);
        if (page == null) {
            int pageSize = (int) (parity4Get(vol.getLong(pageOffset)) >>> 48);
            page = new byte[pageSize];
            vol.getData(pageOffset, page, 0, pageSize);
            dirtyStackPages.put(pageOffset, page);
        }
        return page;
    }

    @Override
    protected void longStackNewPage(long masterLinkOffset, long prevPageOffset, long value) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        long newPageOffset = freeDataTakeSingle((int) CHUNKSIZE);
        byte[] page = new byte[(int) CHUNKSIZE];


        dirtyStackPages.put(newPageOffset, page);

        DataIO.putLong(page, 0, parity4Set((CHUNKSIZE << 48) | prevPageOffset));

        long currSize = 8 + DataIO.packLongBidi(page, 8, longStackValParitySet(value));

        headVol.putLong(masterLinkOffset, parity4Set((currSize << 48) | newPageOffset));
    }

    @Override
    protected void flush() {
        if (CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();

        if (isReadOnly())
            return;
        flushWriteCache();


        structuralLock.lock();
        try {

            long[] set = dirtyStackPages.set;
            for(int i=0;i<set.length;i++){
                long offset = set[i];
                if(offset==0)
                    continue;
                byte[] val = (byte[]) dirtyStackPages.values[i];

                if (CC.ASSERT && offset < PAGE_SIZE)
                    throw new AssertionError();
                if (CC.ASSERT && val.length % 16 != 0)
                    throw new AssertionError();
                if (CC.ASSERT && val.length <= 0 || val.length > MAX_REC_SIZE)
                    throw new AssertionError();

                vol.putData(offset, val, 0, val.length);
            }
            dirtyStackPages.clear();
            headVol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET,parity3Set(lastAllocatedData));

            headVol.putInt(HEAD_CHECKSUM, headChecksum(headVol));

            byte[] buf = new byte[(int) HEAD_END]; 
            headVol.getData(0, buf, 0, buf.length);
            vol.putData(0, buf, 0, buf.length);
        } finally {
            structuralLock.unlock();
        }
        vol.sync();
    }

    protected void flushWriteCache() {
        if (CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();


        for (int i = 0; i < locks.length; i++) {
            Lock lock = locks[i].writeLock();
            lock.lock();
            try {
                flushWriteCacheSegment(i);

            } finally {
                lock.unlock();
            }
        }
    }

    protected void flushWriteCacheSegment(int segment) {
        if (CC.ASSERT)
            assertWriteLocked(segment);

        LongObjectObjectMap writeCache1 = writeCache[segment];
        long[] set = writeCache1.set;
        Object[] values = writeCache1.values;
        for(int i=0;i<set.length;i++){
            long recid = set[i];
            if(recid==0)
                continue;
            Object value = values[i*2];
            if (value == TOMBSTONE2) {
                super.delete2(recid, Serializer.ILLEGAL_ACCESS);
            } else {
                Serializer s = (Serializer) values[i*2+1];
                DataOutputByteArray buf = serialize(value, s); 
                super.update2(recid, buf);
                recycledDataOut.lazySet(buf);
            }
        }
        writeCache1.clear();

        if (CC.ASSERT && writeCache[segment].size!=0)
            throw new AssertionError();
    }



    @Override
    protected <A> A get2(long recid, Serializer<A> serializer) {
        LongObjectObjectMap m = writeCache[lockPos(recid)];
        Object cached = m.get1(recid);
        if (cached !=null) {
            if(cached==TOMBSTONE2)
                return null;
            return (A) cached;
        }
        return super.get2(recid, serializer);
    }

    @Override
    protected <A> void delete2(long recid, Serializer<A> serializer) {
        if (serializer == null)
            throw new NullPointerException();
        int lockPos = lockPos(recid);

        LongObjectObjectMap map = writeCache[lockPos];
        map.put(recid, TOMBSTONE2, null);

        if(flushInThread && map.size>writeQueueSize){
            flushWriteCacheSegment(lockPos);
        }
    }

    @Override
    public <A> long put(A value, Serializer<A> serializer) {
        if (serializer == null)
            throw new NullPointerException();


        long recid = preallocate();
        update(recid, value, serializer);
        return recid;
    }

    @Override
    public <A> void update(long recid, A value, Serializer<A> serializer) {
        if (serializer == null)
            throw new NullPointerException();

        int lockPos = lockPos(recid);
        Cache cache = caches==null ? null : caches[lockPos];
        Lock lock = locks[lockPos].writeLock();
        lock.lock();
        try {
            if(cache!=null) {
                cache.put(recid, value);
            }
            LongObjectObjectMap map = writeCache[lockPos];
            map.put(recid, value, serializer);
            if(flushInThread && map.size>writeQueueSizePerSegment){
                flushWriteCacheSegment(lockPos);
            }

        } finally {
            lock.unlock();
        }
    }


    @Override
    public <A> boolean compareAndSwap(long recid, A expectedOldValue, A newValue, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();


        final int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].writeLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        LongObjectObjectMap<A,Serializer<A>> map = writeCache[lockPos];
        lock.lock();
        try{
            A oldVal = cache==null ? null : (A) cache.get(recid);
            if(oldVal == null) {
                oldVal = get2(recid, serializer);
            }else if(oldVal == Cache.NULL){
                oldVal = null;
            }
            if(oldVal==expectedOldValue || (oldVal!=null && serializer.equals(oldVal,expectedOldValue))){
                if(cache!=null) {
                    cache.put(recid, newValue);
                }
                map.put(recid,newValue,serializer);
                if(flushInThread && map.size>writeQueueSizePerSegment){
                    flushWriteCacheSegment(lockPos);
                }

                return true;
            }
            return false;
        }finally {
            lock.unlock();
        }
    }


}

<code block>
package org.mapdb;

import java.io.DataInput;
import java.io.File;
import java.util.*;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.locks.Lock;
import java.util.logging.Level;

import static org.mapdb.DataIO.*;

public class StoreDirect extends Store {


    protected static final int STORE_VERSION = 100;


    protected static final int HEADER = (0xA9DB<<16) | STORE_VERSION;


    protected static final long PAGE_SIZE = 1<< CC.VOLUME_PAGE_SHIFT;
    protected static final long PAGE_MASK = PAGE_SIZE-1;
    protected static final long PAGE_MASK_INVERSE = 0xFFFFFFFFFFFFFFFFL<<CC.VOLUME_PAGE_SHIFT;


    protected static final long MOFFSET = 0x0000FFFFFFFFFFF0L;

    protected static final long MLINKED = 0x8L;
    protected static final long MUNUSED = 0x4L;
    protected static final long MARCHIVE = 0x2L;
    protected static final long MPARITY = 0x1L;


    protected static final long STORE_SIZE = 8*2;

    protected static final long MAX_RECID_OFFSET = 8*3;
    protected static final long LAST_PHYS_ALLOCATED_DATA_OFFSET = 8*4; 
    protected static final long FREE_RECID_STACK = 8*5;


    protected static final long UNUSED1 = 8*6;
    protected static final long UNUSED2 = 8*7;
    protected static final long UNUSED3 = 8*8;
    protected static final long UNUSED4 = 8*9;
    protected static final long UNUSED5 = 8*10;


    protected static final int MAX_REC_SIZE = 0xFFFF;

    protected static final int SLOTS_COUNT = 2+(MAX_REC_SIZE)/16; 

    protected static final long HEAD_END = UNUSED5 + SLOTS_COUNT * 8;


    protected static final long INITCRC_INDEX_PAGE = 4329042389490239043L;

    private static final long[] EMPTY_LONGS = new long[0];



    protected volatile Volume vol;
    protected volatile Volume headVol;


    protected volatile long[] indexPages;

    protected volatile long lastAllocatedData=0; 

    protected final ScheduledExecutorService executor;

    protected final List<Snapshot> snapshots;

    protected final boolean indexPageCRC;
    protected final long indexValSize;

    public StoreDirect(String fileName,
                       Volume.VolumeFactory volumeFactory,
                       Cache cache,
                       int lockScale,
                       int lockingStrategy,
                       boolean checksum,
                       boolean compress,
                       byte[] password,
                       boolean readonly,
                       boolean snapshotEnable,
                       int freeSpaceReclaimQ,
                       boolean commitFileSyncDisable,
                       int sizeIncrement,
                       ScheduledExecutorService executor
                       ) {
        super(fileName,volumeFactory, cache, lockScale, lockingStrategy, checksum,compress,password,readonly, snapshotEnable);
        this.vol = volumeFactory.makeVolume(fileName, readonly);
        this.executor = executor;
        this.snapshots = snapshotEnable?
                new CopyOnWriteArrayList<Snapshot>():
                null;
        this.indexPageCRC = checksum;
        this.indexValSize = indexPageCRC ? 10 : 8;
    }

    @Override
    public void init() {
        commitLock.lock();
        try {
            structuralLock.lock();
            try {
                if (vol.isEmpty()) {
                    initCreate();
                } else {
                    initOpen();
                }
            } finally {
                structuralLock.unlock();
            }
        }catch(RuntimeException e){
            initFailedCloseFiles();
            if(vol!=null && !vol.isClosed()) {
                vol.close();
            }
            vol = null;
            throw e;
        }finally {
            commitLock.unlock();
        }
    }

    protected void initFailedCloseFiles() {

    }

    protected void initOpen() {
        if(CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        int header = vol.getInt(0);
        if(header!=header){
            throw new DBException.WrongConfig("This is not MapDB file");
        }



        checkFeaturesBitmap(vol.getLong(HEAD_FEATURES));


        initHeadVol();

        int expectedChecksum = vol.getInt(HEAD_CHECKSUM);
        int actualChecksum = headChecksum(vol);
        if (actualChecksum != expectedChecksum) {
            throw new DBException.HeadChecksumBroken();
        }



        long[] ip = new long[]{0};
        long indexPage = parity16Get(vol.getLong(HEAD_END));
        int i=1;
        for(;indexPage!=0;i++){
            if(CC.ASSERT && indexPage%PAGE_SIZE!=0)
                throw new AssertionError();
            if(ip.length==i){
                ip = Arrays.copyOf(ip, ip.length * 4);
            }
            ip[i] = indexPage;


            indexPage = parity16Get(vol.getLong(indexPage));
        }
        indexPages = Arrays.copyOf(ip,i);
        lastAllocatedData = parity3Get(vol.getLong(LAST_PHYS_ALLOCATED_DATA_OFFSET));
    }

    protected void initCreate() {
        if(CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();




        indexPages = new long[]{0};

        vol.ensureAvailable(PAGE_SIZE);
        vol.clear(0, PAGE_SIZE);


        vol.putLong(STORE_SIZE, parity16Set(PAGE_SIZE));
        vol.putLong(MAX_RECID_OFFSET, parity1Set(RECID_LAST_RESERVED * indexValSize));

        vol.putLong(HEAD_END, parity16Set(0));

        lastAllocatedData = 0L;
        vol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET,parity3Set(lastAllocatedData));


        for(long recid=1;recid<RECID_FIRST;recid++){
            long indexVal = parity1Set(MLINKED | MARCHIVE);
            long indexOffset = recidToOffset(recid);
            vol.putLong(indexOffset, indexVal);
            if(indexPageCRC) {
                vol.putUnsignedShort(indexOffset + 8, DataIO.longHash(indexVal)&0xFFFF);
            }
        }


        for(long masterLinkOffset = FREE_RECID_STACK;masterLinkOffset<HEAD_END;masterLinkOffset+=8){
            vol.putLong(masterLinkOffset,parity4Set(0));
        }


        vol.putInt(0,HEADER);


        long features = makeFeaturesBitmap();

        vol.putLong(HEAD_FEATURES, features);



        vol.putInt(HEAD_CHECKSUM, headChecksum(vol));
        vol.sync();
        initHeadVol();
    }


    protected void initHeadVol() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        this.headVol = vol;
    }

    public StoreDirect(String fileName) {
        this(fileName,
                fileName==null? CC.DEFAULT_MEMORY_VOLUME_FACTORY : CC.DEFAULT_FILE_VOLUME_FACTORY,
                null,
                CC.DEFAULT_LOCK_SCALE,
                0,
                false,false,null,false,false,0,
                false,0,
                null);
    }

    protected int headChecksum(Volume vol2) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        int ret = 0;
        for(int offset = 8;
            offset< HEAD_END;
            offset+=8){
            long val = vol2.getLong(offset);
            ret += DataIO.longHash(offset+val);
        }
        return ret;
    }

    @Override
    protected <A> A get2(long recid, Serializer<A> serializer) {
        if (CC.ASSERT)
            assertReadLocked(recid);

        long[] offsets = offsetsGet(indexValGet(recid));
        return getFromOffset(serializer, offsets);
    }

    protected <A> A getFromOffset(Serializer<A> serializer, long[] offsets) {
        if (offsets == null) {
            return null; 
        }else if (offsets.length==0){
            return deserialize(serializer,0,new DataInputByteArray(new byte[0]));
        }else if (offsets.length == 1) {

            int size = (int) (offsets[0] >>> 48);
            long offset = offsets[0] & MOFFSET;
            DataInput in = vol.getDataInput(offset, size);
            return deserialize(serializer, size, in);
        } else {

            int totalSize = offsetsTotalSize(offsets);
            byte[] b = getLoadLinkedRecord(offsets, totalSize);

            DataInput in = new DataInputByteArray(b);
            return deserialize(serializer, totalSize, in);
        }
    }

    private byte[] getLoadLinkedRecord(long[] offsets, int totalSize) {

        byte[] b = new byte[totalSize];
        int bpos = 0;
        for (int i = 0; i < offsets.length; i++) {
            int plus = (i == offsets.length - 1)?0:8;
            long size = (offsets[i] >>> 48) - plus;
            if(CC.ASSERT && (size&0xFFFF)!=size)
                throw new AssertionError("size mismatch");
            long offset = offsets[i] & MOFFSET;

            vol.getData(offset + plus, b, bpos, (int) size);
            bpos += size;
        }
        if (CC.ASSERT && bpos != totalSize)
            throw new AssertionError("size does not match");
        return b;
    }

    protected int offsetsTotalSize(long[] offsets) {
        if(offsets==null || offsets.length==0)
            return 0;
        int totalSize = 8;
        for (long l : offsets) {
            totalSize += (l >>> 48) - 8;
        }
        return totalSize;
    }


    @Override
    protected void update2(long recid, DataOutputByteArray out) {
        int pos = lockPos(recid);

        if(CC.ASSERT)
            assertWriteLocked(pos);
        long oldIndexVal = indexValGet(recid);

        boolean releaseOld = true;
        if(snapshotEnable){
            for(Snapshot snap:snapshots){
                snap.oldRecids[pos].putIfAbsent(recid,oldIndexVal);
                releaseOld = false;
            }
        }

        long[] oldOffsets = offsetsGet(oldIndexVal);
        int oldSize = offsetsTotalSize(oldOffsets);
        int newSize = out==null?0:out.pos;
        long[] newOffsets;


        if(releaseOld && oldSize==newSize){


            newOffsets = oldOffsets;
        }else {
            structuralLock.lock();
            try {
                if(releaseOld && oldOffsets!=null)
                    freeDataPut(oldOffsets);
                newOffsets = newSize==0?null:freeDataTake(out.pos);

            } finally {
                structuralLock.unlock();
            }
        }

        if(CC.ASSERT)
            offsetsVerify(newOffsets);

        putData(recid, newOffsets, out==null?null:out.buf, out==null?0:out.pos);
    }

    protected void offsetsVerify(long[] linkedOffsets) {


    }



    protected long[] offsetsGet(long indexVal) {;
        if(indexVal>>>48==0){

            return ((indexVal&MLINKED)!=0) ? null : EMPTY_LONGS;
        }

        long[] ret = new long[]{indexVal};
        while((ret[ret.length-1]&MLINKED)!=0){
            ret = Arrays.copyOf(ret,ret.length+1);
            ret[ret.length-1] = parity3Get(vol.getLong(ret[ret.length-2]&MOFFSET));
        }

        if(CC.ASSERT){
            for(int i=0;i<ret.length;i++) {
                boolean last = (i==ret.length-1);
                boolean linked = (ret[i]&MLINKED)!=0;
                if(!last && !linked)
                    throw new AssertionError("body not linked");
                if(last && linked)
                    throw new AssertionError("tail is linked");

                long offset = ret[i]&MOFFSET;
                if(offset<PAGE_SIZE)
                    throw new AssertionError("offset is too small");
                if(((offset&MOFFSET)%16)!=0)
                    throw new AssertionError("offset not mod 16");

                int size = (int) (ret[i] >>>48);
                if(size<=0)
                    throw new AssertionError("size too small");
            }

        }

        return ret;
    }

    protected void indexValPut(long recid, int size, long offset, boolean linked, boolean unused) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));

        long indexOffset = recidToOffset(recid);
        long newval = composeIndexVal(size, offset, linked, unused, true);
        vol.putLong(indexOffset, newval);
        if(indexPageCRC){
            vol.putUnsignedShort(indexOffset+8, DataIO.longHash(newval)&0xFFFF);
        }
    }


    @Override
    protected <A> void delete2(long recid, Serializer<A> serializer) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));

        long oldIndexVal = indexValGet(recid);
        long[] offsets = offsetsGet(oldIndexVal);
        boolean releaseOld = true;
        if(snapshotEnable){
            int pos = lockPos(recid);
            for(Snapshot snap:snapshots){
                snap.oldRecids[pos].putIfAbsent(recid,oldIndexVal);
                releaseOld = false;
            }
        }

        if(offsets!=null && releaseOld) {
            structuralLock.lock();
            try {
                freeDataPut(offsets);
            } finally {
                structuralLock.unlock();
            }
        }
        indexValPut(recid,0,0,true,true);
    }

    @Override
    public long getCurrSize() {
        return vol.length() - lastAllocatedData % CHUNKSIZE;
    }

    @Override
    public long getFreeSize() {
        return -1; 
    }

    @Override
    public long preallocate() {
        long recid;
        structuralLock.lock();
        try {
             recid = freeRecidTake();
        }finally {
            structuralLock.unlock();
        }
        Lock lock = locks[lockPos(recid)].writeLock();
        lock.lock();
        try {
            indexValPut(recid, 0, 0L, true, true);
        }finally {
            lock.unlock();
        }
        return recid;
    }


    @Override
    public <A> long put(A value, Serializer<A> serializer) {
        long recid;
        long[] offsets;
        DataOutputByteArray out = serialize(value,serializer);
        boolean notalloc = out==null || out.pos==0;
        structuralLock.lock();
        try {
            recid = freeRecidTake();
            offsets = notalloc?null:freeDataTake(out.pos);
        }finally {
            structuralLock.unlock();
        }
        if(CC.ASSERT && offsets!=null && (offsets[0]&MOFFSET)<PAGE_SIZE)
            throw new AssertionError();

        int pos = lockPos(recid);
        Lock lock = locks[pos].writeLock();
        lock.lock();
        try {
            if(caches!=null) {
                caches[pos].put(recid, value);
            }
            if(snapshotEnable){
                for(Snapshot snap:snapshots){
                    snap.oldRecids[pos].putIfAbsent(recid,0);
                }
            }

            putData(recid, offsets, out==null?null:out.buf, out==null?0:out.pos);
        }finally {
            lock.unlock();
        }

        return recid;
    }

    protected void putData(long recid, long[] offsets, byte[] src, int srcLen) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));
        if(CC.ASSERT && offsetsTotalSize(offsets)!=(src==null?0:srcLen))
            throw new AssertionError("size mismatch");

        if(offsets!=null) {
            int outPos = 0;
            for (int i = 0; i < offsets.length; i++) {
                final boolean last = (i == offsets.length - 1);
                if (CC.ASSERT && ((offsets[i] & MLINKED) == 0) != last)
                    throw new AssertionError("linked bit set wrong way");

                long offset = (offsets[i] & MOFFSET);
                if(CC.ASSERT && offset%16!=0)
                    throw new AssertionError("not aligned to 16");

                int plus = (last?0:8);
                int size = (int) ((offsets[i]>>>48) - plus);
                if(CC.ASSERT && ((size&0xFFFF)!=size || size==0))
                    throw new AssertionError("size mismatch");

                int segment = lockPos(recid);

                if (!last) {
                    putDataSingleWithLink(segment, offset,parity3Set(offsets[i + 1]), src,outPos,size);
                }else{
                    putDataSingleWithoutLink(segment, offset, src, outPos, size);
                }
                outPos += size;

            }
            if(CC.ASSERT && outPos!=srcLen)
                throw new AssertionError("size mismatch");
        }

        boolean firstLinked =
                (offsets!=null && offsets.length>1) || 
                (src==null); 
        boolean empty = offsets==null || offsets.length==0;
        int firstSize = (int) (empty ? 0L : offsets[0]>>>48);
        long firstOffset =  empty? 0L : offsets[0]&MOFFSET;
        indexValPut(recid, firstSize, firstOffset, firstLinked, false);
    }

    protected void putDataSingleWithoutLink(int segment, long offset, byte[] buf, int bufPos, int size) {
        vol.putData(offset,buf,bufPos,size);
    }

    protected void putDataSingleWithLink(int segment, long offset, long link, byte[] buf, int bufPos, int size) {
        vol.putLong(offset,link);
        vol.putData(offset+8, buf,bufPos,size);
    }

    protected void freeDataPut(long[] linkedOffsets) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        for(long v:linkedOffsets){
            int size = round16Up((int) (v >>> 48));
            v &= MOFFSET;
            freeDataPut(v,size);
        }
    }


    protected void freeDataPut(long offset, int size) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && size%16!=0 )
            throw new AssertionError();
        if(CC.ASSERT && (offset%16!=0 || offset<PAGE_SIZE))
            throw new AssertionError();

        if(!(this instanceof  StoreWAL)) 
            vol.clear(offset,offset+size);


        if(offset+size==lastAllocatedData){
            lastAllocatedData-=size;
            return;
        }

        long masterPointerOffset = size/2 + FREE_RECID_STACK; 
        longStackPut(
                masterPointerOffset,
                offset>>>4, 
                false);
    }


    protected long[] freeDataTake(int size) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && size<=0)
            throw new AssertionError();


        long[] ret = EMPTY_LONGS;
        while(size>MAX_REC_SIZE){
            ret = Arrays.copyOf(ret,ret.length+1);
            ret[ret.length-1] = (((long)MAX_REC_SIZE)<<48) | freeDataTakeSingle(round16Up(MAX_REC_SIZE)) | MLINKED;
            size = size-MAX_REC_SIZE+8;
        }

        ret = Arrays.copyOf(ret,ret.length+1);
        ret[ret.length-1] = (((long)size)<<48) | freeDataTakeSingle(round16Up(size)) ;
        return ret;
    }

    protected long freeDataTakeSingle(int size) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && size%16!=0)
            throw new AssertionError();
        if(CC.ASSERT && size>round16Up(MAX_REC_SIZE))
            throw new AssertionError();

        long masterPointerOffset = size/2 + FREE_RECID_STACK; 
        long ret = longStackTake(masterPointerOffset,false) <<4; 
        if(ret!=0) {
            if(CC.ASSERT && ret<PAGE_SIZE)
                throw new AssertionError();
            if(CC.ASSERT && ret%16!=0)
                throw new AssertionError();

            return ret;
        }

        if(lastAllocatedData==0){

            long page = pageAllocate();
            lastAllocatedData = page+size;
            if(CC.ASSERT && page<PAGE_SIZE)
                throw new AssertionError();
            if(CC.ASSERT && page%16!=0)
                throw new AssertionError();
            return page;
        }


        if((lastAllocatedData%PAGE_SIZE + size)/PAGE_SIZE !=0){

            lastAllocatedData=0;
            freeDataTakeSingle(size);




        }

        ret = lastAllocatedData;
        lastAllocatedData+=size;

        if(CC.ASSERT && ret%16!=0)
            throw new AssertionError();
        if(CC.ASSERT && lastAllocatedData%16!=0)
            throw new AssertionError();
        if(CC.ASSERT && ret<PAGE_SIZE)
            throw new AssertionError();

        return ret;
    }



    protected final static long CHUNKSIZE = 100*16;

    protected void longStackPut(final long masterLinkOffset, final long value, boolean recursive){
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && (masterLinkOffset<=0 || masterLinkOffset>PAGE_SIZE || masterLinkOffset % 8!=0)) 
            throw new AssertionError();

        long masterLinkVal = parity4Get(headVol.getLong(masterLinkOffset));
        long pageOffset = masterLinkVal&MOFFSET;

        if(masterLinkVal==0L){
            longStackNewPage(masterLinkOffset, 0L, value);
            return;
        }

        long currSize = masterLinkVal>>>48;

        long prevLinkVal = parity4Get(vol.getLong(pageOffset));
        long pageSize = prevLinkVal>>>48;

        if(currSize+8>=pageSize){ 


            vol.clear(pageOffset+currSize, pageOffset+pageSize);

            longStackNewPage(masterLinkOffset,pageOffset,value);
            return;
        }


        currSize += vol.putLongPackBidi(pageOffset+currSize,longStackValParitySet(value));

        headVol.putLong(masterLinkOffset, parity4Set(currSize<<48 | pageOffset));
    }

    protected final long longStackValParitySet(long value) {
        return indexPageCRC?
                DataIO.parity16Set(value << 16):
                DataIO.parity1Set(value<<1);
    }

    protected final long longStackValParityGet(long value) {
        return indexPageCRC?
                DataIO.parity16Get(value)>>>16:
                DataIO.parity1Get(value)>>>1;
    }


    protected void longStackNewPage(long masterLinkOffset, long prevPageOffset, long value) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        long newPageOffset = freeDataTakeSingle((int) CHUNKSIZE);

        vol.putLong(newPageOffset, parity4Set((CHUNKSIZE<<48) | prevPageOffset));

        long currSize = 8 + vol.putLongPackBidi(newPageOffset+8, longStackValParitySet(value));

        headVol.putLong(masterLinkOffset, parity4Set((currSize<<48)|newPageOffset));
    }


    protected long longStackTake(long masterLinkOffset, boolean recursive){
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && (masterLinkOffset<FREE_RECID_STACK ||
                masterLinkOffset>FREE_RECID_STACK+round16Up(MAX_REC_SIZE)/2 ||
                masterLinkOffset % 8!=0))
            throw new AssertionError();

        long masterLinkVal = parity4Get(headVol.getLong(masterLinkOffset));
        if(masterLinkVal==0 ){
            return 0;
        }
        long currSize = masterLinkVal>>>48;
        final long pageOffset = masterLinkVal&MOFFSET;


        long ret = vol.getLongPackBidiReverse(pageOffset+currSize);

        long oldCurrSize = currSize;
        currSize-= ret >>>56;

        vol.clear(pageOffset+currSize, pageOffset+oldCurrSize);

        ret = longStackValParityGet(ret & DataIO.PACK_LONG_BIDI_MASK);

        if(CC.ASSERT && currSize<8)
            throw new AssertionError();


        if(currSize>8){

            headVol.putLong(masterLinkOffset, parity4Set(currSize << 48 | pageOffset));
            return ret;
        }


        long prevPageOffset = parity4Get(vol.getLong(pageOffset));
        final int currPageSize = (int) (prevPageOffset>>>48);
        prevPageOffset &= MOFFSET;


        if(prevPageOffset!=0) {






            currSize = parity4Get(vol.getLong(prevPageOffset)) >>> 48;


            while (vol.getUnsignedByte(prevPageOffset + currSize-1) == 0) {
                currSize--;
            }

            if (CC.ASSERT && currSize < 10)
                throw new AssertionError();
        }else{

            currSize=0;
        }


        headVol.putLong(masterLinkOffset, parity4Set(currSize<<48 | prevPageOffset));


        freeDataPut(pageOffset, currPageSize);

        return ret;
    }

    @Override
    public void close() {
        if(closed==true)
            return;
        
        commitLock.lock();
        try {
            if(closed==true)
                return;
            flush();
            vol.close();
            vol = null;
            if(this instanceof StoreCached)
                headVol.close();

            if (caches != null) {
                for (Cache c : caches) {
                    c.close();
                }
                Arrays.fill(caches,null);
            }
            closed = true;
        }finally{
            commitLock.unlock();
        }
    }


    @Override
    public void commit() {
        commitLock.lock();
        try {
            flush();
        }finally{
            commitLock.unlock();
        }
    }

    protected void flush() {
        if(isReadOnly())
            return;
        structuralLock.lock();
        try{
            headVol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET, parity3Set(lastAllocatedData));

            vol.putInt(HEAD_CHECKSUM, headChecksum(vol));
        }finally {
            structuralLock.unlock();
        }
        vol.sync();
    }

    @Override
    public void rollback() throws UnsupportedOperationException {
        throw new UnsupportedOperationException();
    }


    @Override
    public boolean canRollback() {
        return false;
    }

    @Override
    public Engine snapshot() throws UnsupportedOperationException {
        if(!snapshotEnable)
            throw new UnsupportedOperationException();
        return new Snapshot(StoreDirect.this);
    }

    @Override
    public void clearCache() {

    }

    @Override
    public void compact() {

        if(compactOldFilesExists()){
            return;
        }

        final boolean isStoreCached = this instanceof StoreCached;
        for(int i=0;i<locks.length;i++){
            Lock lock = isStoreCached?locks[i].readLock():locks[i].writeLock();
            lock.lock();
        }

        try{
            commitLock.lock();
            try {


                if(caches!=null) {
                    for (Cache c : caches) {
                        c.clear();
                    }
                }
                snapshotCloseAllOnCompact();


                final long maxRecidOffset = parity1Get(headVol.getLong(MAX_RECID_OFFSET));

                String compactedFile = vol.getFile()==null? null : fileName+".compact";
                final StoreDirect target = new StoreDirect(compactedFile,
                        volumeFactory,
                        null,lockScale,
                        executor==null?LOCKING_STRATEGY_NOLOCK:LOCKING_STRATEGY_WRITELOCK,
                        checksum,compress,null,false,false,0,false,0,
                        null);
                target.init();
                final AtomicLong maxRecid = new AtomicLong(RECID_LAST_RESERVED);





                compactIndexPages(maxRecidOffset, target, maxRecid);



                structuralLock.lock();
                try {

                    target.vol.putLong(MAX_RECID_OFFSET, parity1Set(maxRecid.get() * indexValSize));
                    this.indexPages = target.indexPages;
                    this.lastAllocatedData = target.lastAllocatedData;



                    if(compactedFile==null) {

                        Volume oldVol = this.vol;
                        if(this instanceof StoreCached)
                            headVol.close();
                        this.headVol = this.vol = target.vol;

                        oldVol.close();
                    }else{
                        File compactedFileF = new File(compactedFile);

                        target.vol.sync();
                        target.close();
                        this.vol.sync();
                        this.vol.close();

                        File currFile = new File(this.fileName);
                        File currFileRenamed = new File(currFile.getPath()+".compact_orig");
                        if(!currFile.renameTo(currFileRenamed)){


                            throw new AssertionError("failed to rename file "+currFile+" - "+currFile.exists()+" - "+currFileRenamed.exists());
                        }


                        if(!compactedFileF.renameTo(currFile)) {

                            throw new AssertionError("failed to rename file " + compactedFileF);
                        }


                        if(this instanceof StoreCached)
                            this.headVol.close();
                        this.headVol = this.vol = volumeFactory.makeVolume(this.fileName, readonly);

                        if(isStoreCached){
                            ((StoreCached)this).dirtyStackPages.clear();
                        }


                        if(!currFileRenamed.delete()){
                            LOG.warning("Could not delete old compaction file: "+currFileRenamed);
                        }

                    }
                }finally {
                    structuralLock.unlock();
                }
            }finally{
                commitLock.unlock();
            }
        }finally {
            for(int i=locks.length-1;i>=0;i--) {
                Lock lock = isStoreCached ? locks[i].readLock() : locks[i].writeLock();
                lock.unlock();
            }
        }
    }

    protected boolean compactOldFilesExists() {
        if(fileName!=null){
            for(String s:new String[]{".compact_orig",".compact",".wal.c" ,".wal.c.compact" }) {
                File oldData = new File(fileName + s);
                if (oldData.exists()) {
                    LOG.warning("Old compaction data exists, compaction not started: " + oldData);
                    return true;
                }
            }

        }
        return false;
    }

    protected void snapshotCloseAllOnCompact() {

        if(snapshotEnable){
            boolean someClosed = false;
            for(Snapshot snap:snapshots){
                someClosed = true;
                snap.close();
            }
            if(someClosed)
                LOG.log(Level.WARNING, "Compaction closed existing snapshots.");
        }
    }

    protected void compactIndexPages(final long maxRecidOffset, final StoreDirect target, final AtomicLong maxRecid) {

        if(executor == null) {
            for (int indexPageI = 0; indexPageI < indexPages.length; indexPageI++) {
                compactIndexPage(maxRecidOffset, target, maxRecid, indexPageI);
            }
        }else {




            final List<Future> tasks = new ArrayList();
            for (int indexPageI = 0; indexPageI < indexPages.length; indexPageI++) {
                final int indexPageI2 = indexPageI;


                Future f = executor.submit(new Runnable() {
                    @Override
                    public void run() {
                      compactIndexPage(maxRecidOffset, target, maxRecid, indexPageI2);
                    }
                });
                tasks.add(f);
            }


            for(Future f:tasks){
                try {
                    f.get();
                } catch (InterruptedException e) {
                    throw new DBException.Interrupted(e);
                } catch (ExecutionException e) {

                    throw new RuntimeException(e);
                }
            }

        }
    }

    protected void compactIndexPage(long maxRecidOffset, StoreDirect target, AtomicLong maxRecid, int indexPageI) {
        final long indexPage = indexPages[indexPageI];

        long recid = (indexPageI==0? 0 : indexPageI * PAGE_SIZE/indexValSize - HEAD_END/indexValSize);
        final long indexPageStart = (indexPage==0?HEAD_END+8 : indexPage);
        final long indexPageEnd = indexPage+PAGE_SIZE;



        indexVal:
        for( long indexOffset=indexPageStart;
                indexOffset<indexPageEnd;
                indexOffset+= indexValSize){
            recid++;

            if(CC.ASSERT && indexOffset!=recidToOffset(recid))
                throw new AssertionError();

            if(recid*indexValSize>maxRecidOffset)
                break indexVal;


            for(long oldMaxRecid=maxRecid.get();
                !maxRecid.compareAndSet(oldMaxRecid, Math.max(recid,oldMaxRecid));
                oldMaxRecid=maxRecid.get()){
            }

            final long indexVal = vol.getLong(indexOffset);
            if(indexPageCRC &&
                    vol.getUnsignedShort(indexOffset+8)!=
                            (DataIO.longHash(indexVal)&0xFFFF)){
                throw new DBException.ChecksumBroken();
            }


            if((indexVal&MUNUSED)!=0||indexVal == 0){

                target.structuralLock.lock();
                target.longStackPut(FREE_RECID_STACK, recid, false);
                target.structuralLock.unlock();
                continue indexVal;
            }



            if((indexVal & MLINKED)!=0 && indexVal>>>48!=0){

                long[] offsets = offsetsGet(indexValGet(recid));
                int totalSize = offsetsTotalSize(offsets);
                byte[] b = getLoadLinkedRecord(offsets, totalSize);


                target.locks[lockPos(recid)].writeLock().lock();
                target.structuralLock.lock();

                long[] newOffsets = target.freeDataTake(totalSize);

                target.pageIndexEnsurePageForRecidAllocated(recid);
                target.putData(recid,newOffsets,b, totalSize);

                target.structuralLock.unlock();
                target.locks[lockPos(recid)].writeLock().unlock();


                continue indexVal;
            }

            target.locks[lockPos(recid)].writeLock().lock();
            target.structuralLock.lock();
            target.pageIndexEnsurePageForRecidAllocated(recid);

            target.updateFromCompact(recid, indexVal, vol);
            target.structuralLock.unlock();
            target.locks[lockPos(recid)].writeLock().unlock();

        }
    }


    private void updateFromCompact(long recid, long indexVal, Volume oldVol) {

        int size = (int) (indexVal>>>48);
        long newOffset[];
        if(size>0) {
            newOffset=freeDataTake(size);
            if (newOffset.length != 1)
                throw new AssertionError();


            oldVol.transferInto(indexVal & MOFFSET, this.vol, newOffset[0]&MOFFSET, size);
        }else{
            newOffset = new long[1];
        }



        indexValPut(recid, size, newOffset[0]&MOFFSET, (indexVal&MLINKED)!=0, false);
    }


    protected long indexValGet(long recid) {
        long offset = recidToOffset(recid);
        long indexVal = vol.getLong(offset);
        if(indexVal == 0)
            throw new DBException.EngineGetVoid();
        if(indexPageCRC){
            int checksum = vol.getUnsignedShort(offset+8);
            if(checksum!=(DataIO.longHash(indexVal)&0xFFFF)){
                throw new DBException.ChecksumBroken();
            }
        }

        return DataIO.parity1Get(indexVal);
    }

    protected final long recidToOffset(long recid){
        if(CC.ASSERT && recid<=0)
            throw new AssertionError("negative recid: "+recid);
        if(indexPageCRC){
            return recidToOffsetChecksum(recid);
        }


        recid = (recid-1) * indexValSize + HEAD_END + 8;

        recid+= Math.min(1, recid/PAGE_SIZE)*    
                (8 + ((recid-PAGE_SIZE)/(PAGE_SIZE-8))*8);


        recid = indexPages[((int) (recid / PAGE_SIZE))] + recid%PAGE_SIZE;
        return recid;
    }

    private long recidToOffsetChecksum(long recid) {

        recid = (recid-1) * indexValSize + HEAD_END + 8;

        if(recid+ indexValSize >PAGE_SIZE){

            recid+=2+8;
        }



        for(long page=PAGE_SIZE*2;recid+ indexValSize >page;page+=PAGE_SIZE){
            recid+=8+(PAGE_SIZE-8)% indexValSize;
        }


        recid = indexPages[((int) (recid / PAGE_SIZE))] + recid%PAGE_SIZE;
        return recid;

    }


    protected boolean recidTooLarge(long recid) {
        try{
            recidToOffset(recid);
            return false;
        }catch(ArrayIndexOutOfBoundsException e){

            return true;
        }
    }


    protected static long composeIndexVal(int size, long offset,
        boolean linked, boolean unused, boolean archive){
        if(CC.ASSERT && (size&0xFFFF)!=size)
            throw new AssertionError("size too large");
        if(CC.ASSERT && (offset&MOFFSET)!=offset)
            throw new AssertionError("offset too large");
        offset = (((long)size)<<48) |
                offset |
                (linked?MLINKED:0L)|
                (unused?MUNUSED:0L)|
                (archive?MARCHIVE:0L);
        return parity1Set(offset);
    }



    protected long freeRecidTake() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();


        long currentRecid = longStackTake(FREE_RECID_STACK,false);
        if(currentRecid!=0)
            return currentRecid;

        currentRecid = parity1Get(headVol.getLong(MAX_RECID_OFFSET));
        currentRecid+=indexValSize;
        headVol.putLong(MAX_RECID_OFFSET, parity1Set(currentRecid));

        currentRecid/=indexValSize;

        if(recidTooLarge(currentRecid)){
            pageIndexExtend();
        }

        return currentRecid;
    }

    protected void indexLongPut(long offset, long val){
        vol.putLong(offset,val);
    }

    protected void pageIndexEnsurePageForRecidAllocated(long recid) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();



        recid = recid * indexValSize + HEAD_END;
        recid = recid / (PAGE_SIZE-8);

        while(indexPages.length<=recid)
            pageIndexExtend();
    }

    protected void pageIndexExtend() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();


        long indexPage = pageAllocate();


        long nextPagePointerOffset = indexPages[indexPages.length-1];

        nextPagePointerOffset = Math.max(nextPagePointerOffset, HEAD_END);
        indexLongPut(nextPagePointerOffset, parity16Set(indexPage));


        indexLongPut(indexPage,parity16Set(0));


        long[] indexPages2 = Arrays.copyOf(indexPages,indexPages.length+1);
        indexPages2[indexPages.length]=indexPage;
        indexPages = indexPages2;
    }

    protected long pageAllocate() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        long storeSize = parity16Get(headVol.getLong(STORE_SIZE));
        vol.ensureAvailable(storeSize+PAGE_SIZE);
        vol.clear(storeSize,storeSize+PAGE_SIZE);
        headVol.putLong(STORE_SIZE, parity16Set(storeSize + PAGE_SIZE));

        if(CC.ASSERT && storeSize%PAGE_SIZE!=0)
            throw new AssertionError();

        return storeSize;
    }

    protected static int round16Up(int pos) {

        int rem = pos&15;  
        if(rem!=0) pos +=16-rem;
        return pos;
    }

    public static final class Snapshot extends ReadOnly{

        protected StoreDirect engine;
        protected LongLongMap[] oldRecids;

        public Snapshot(StoreDirect engine){
            this.engine = engine;
            oldRecids = new LongLongMap[engine.lockScale];
            for(int i=0;i<oldRecids.length;i++){
                oldRecids[i] = new LongLongMap();
            }
            engine.snapshots.add(Snapshot.this);
        }

        @Override
        public <A> A get(long recid, Serializer<A> serializer) {
            StoreDirect engine = this.engine;
            int pos = engine.lockPos(recid);
            Lock lock = engine.locks[pos].readLock();
            lock.lock();
            try{
                long indexVal = oldRecids[pos].get(recid);
                if(indexVal==-1)
                    return null; 
                if(indexVal==-2)
                    return null; 

                if(indexVal!=0){
                    long[] offsets = engine.offsetsGet(indexVal);
                    return engine.getFromOffset(serializer,offsets);
                }

                return engine.get2(recid,serializer);
            }finally {
                lock.unlock();
            }
        }

        @Override
        public void close() {

            engine.snapshots.remove(Snapshot.this);
            engine = null;
            oldRecids = null;

        }

        @Override
        public boolean isClosed() {
            return engine!=null;
        }

        @Override
        public boolean canRollback() {
            return false;
        }

        @Override
        public boolean canSnapshot() {
            return true;
        }

        @Override
        public Engine snapshot() throws UnsupportedOperationException {
            return this;
        }

        @Override
        public Engine getWrappedEngine() {
            return engine;
        }

        @Override
        public void clearCache() {

        }
    }
}

<code block>
package org.mapdb;

import java.io.*;
import java.nio.ByteBuffer;
import java.util.Arrays;


public final class DataIO {

    private DataIO(){}


    static public int unpackInt(DataInput is) throws IOException {
        int ret = 0;
        byte v;
        do{
            v = is.readByte();
            ret = (ret<<7 ) | (v & 0x7F);
        }while(v<0);

        return ret;
    }


    static public long unpackLong(DataInput in) throws IOException {
        long ret = 0;
        byte v;
        do{
            v = in.readByte();
            ret = (ret<<7 ) | (v & 0x7F);
        }while(v<0);

        return ret;
    }



    static public void packLong(DataOutput out, long value) throws IOException {

        int shift = 63-Long.numberOfLeadingZeros(value);
        shift -= shift%7; 
        while(shift!=0){
            out.writeByte((byte) (((value>>>shift) & 0x7F) | 0x80));

            shift-=7;
        }
        out.writeByte((byte) (value & 0x7F));
    }




    static public long unpackRecid(DataInput in) throws IOException {
        long val = unpackLong(in);
        val = DataIO.parity3Get(val);
        return val >>> 3;
    }



    static public void packRecid(DataOutput out, long value) throws IOException {
        value = DataIO.parity3Set(value<<3);
        packLong(out,value);
    }




    static public void packInt(DataOutput out, int value) throws IOException {




        int shift = (value & ~0x7F); 
        if (shift != 0) {

            shift = 31-Integer.numberOfLeadingZeros(value);
            shift -= shift%7; 
            while(shift!=0){
                out.writeByte((byte) (((value>>>shift) & 0x7F) | 0x80));

                shift-=7;
            }
        }

        out.writeByte((byte) (value & 0x7F));
    }



    static public void packIntBigger(DataOutput out, int value) throws IOException {

        int shift = 31-Integer.numberOfLeadingZeros(value);
        shift -= shift%7; 
        while(shift!=0){
            out.writeByte((byte) (((value>>>shift) & 0x7F) | 0x80));

            shift-=7;
        }

        out.writeByte((byte) (value & 0x7F));
    }

    public static int longHash(long h) {

        h = h * -7046029254386353131L;
        h ^= h >> 32;
        return (int)(h ^ h >> 16);

    }

    public static int intHash(int h) {

        h = h * -1640531527;
        return h ^ h >> 16;

    }

    public static final long PACK_LONG_BIDI_MASK = 0xFFFFFFFFFFFFFFL;


    public static int packLongBidi(DataOutput out, long value) throws IOException {
        out.write((((int) value & 0x7F)) | 0x80);
        value >>>= 7;
        int counter = 2;


        while ((value & ~0x7FL) != 0) {
            out.write((((int) value & 0x7F)));
            value >>>= 7;

            counter++;
        }

        out.write((byte) value| 0x80);
        return counter;
    }

    public static int packLongBidi(byte[] buf, int pos, long value) {
        buf[pos++] = (byte) ((((int) value & 0x7F))| 0x80);
        value >>>= 7;
        int counter = 2;


        while ((value & ~0x7FL) != 0) {
            buf[pos++] = (byte) (((int) value & 0x7F));
            value >>>= 7;

            counter++;
        }

        buf[pos++] = (byte) ((byte) value| 0x80);
        return counter;
    }


    public static long unpackLongBidi(byte[] bb, int pos){

        long b = bb[pos++];
        if(CC.ASSERT && (b&0x80)==0)
            throw new AssertionError();
        long result = (b & 0x7F) ;
        int offset = 7;
        do {

            b = bb[pos++];
            result |= (b & 0x7F) << offset;
            if(CC.ASSERT && offset>64)
                throw new AssertionError();
            offset += 7;
        }while((b & 0x80) == 0);

        return (((long)(offset/7))<<56) | result;
    }


    public static long unpackLongBidiReverse(byte[] bb, int pos){

        long b = bb[--pos];
        if(CC.ASSERT && (b&0x80)==0)
            throw new AssertionError();
        long result = (b & 0x7F) ;
        int counter = 1;
        do {

            b = bb[--pos];
            result = (b & 0x7F) | (result<<7);
            if(CC.ASSERT && counter>8)
                throw new AssertionError();
            counter++;
        }while((b & 0x80) == 0);

        return (((long)counter)<<56) | result;
    }

    public static long getLong(byte[] buf, int pos) {
       return
               ((((long)buf[pos++]) << 56) |
                (((long)buf[pos++] & 0xFF) << 48) |
                (((long)buf[pos++] & 0xFF) << 40) |
                (((long)buf[pos++] & 0xFF) << 32) |
                (((long)buf[pos++] & 0xFF) << 24) |
                (((long)buf[pos++] & 0xFF) << 16) |
                (((long)buf[pos++] & 0xFF) <<  8) |
                (((long)buf[pos] & 0xFF)));

    }

    public static void putLong(byte[] buf, int pos,long v) {
        buf[pos++] = (byte) (0xff & (v >> 56));
        buf[pos++] = (byte) (0xff & (v >> 48));
        buf[pos++] = (byte) (0xff & (v >> 40));
        buf[pos++] = (byte) (0xff & (v >> 32));
        buf[pos++] = (byte) (0xff & (v >> 24));
        buf[pos++] = (byte) (0xff & (v >> 16));
        buf[pos++] = (byte) (0xff & (v >> 8));
        buf[pos] = (byte) (0xff & (v));
    }


    public static long getSixLong(byte[] buf, int pos) {
        return
                        ((long) (buf[pos++] & 0xff) << 40) |
                        ((long) (buf[pos++] & 0xff) << 32) |
                        ((long) (buf[pos++] & 0xff) << 24) |
                        ((long) (buf[pos++] & 0xff) << 16) |
                        ((long) (buf[pos++] & 0xff) << 8) |
                        ((long) (buf[pos] & 0xff));
    }

    public static void putSixLong(byte[] buf, int pos, long value) {
        if(CC.ASSERT && (value>>>48!=0))
            throw new AssertionError();

        buf[pos++] = (byte) (0xff & (value >> 40));
        buf[pos++] = (byte) (0xff & (value >> 32));
        buf[pos++] = (byte) (0xff & (value >> 24));
        buf[pos++] = (byte) (0xff & (value >> 16));
        buf[pos++] = (byte) (0xff & (value >> 8));
        buf[pos] = (byte) (0xff & (value));
    }




    public static int nextPowTwo(final int a)
    {
        return 1 << (32 - Integer.numberOfLeadingZeros(a - 1));
    }



    public interface DataInputInternal extends DataInput,Closeable {

        int getPos();
        void setPos(int pos);


        byte[] internalByteArray();


        ByteBuffer internalByteBuffer();


        void close();

        long unpackLong() throws IOException;

        int unpackInt() throws IOException;

        long[] unpackLongArrayDeltaCompression(int size) throws IOException;

        void unpackLongArray(long[] ret, int i, int len);
        void unpackIntArray(int[] ret, int i, int len);
    }


    static public final class DataInputByteArray implements DataInput, DataInputInternal {
        protected final byte[] buf;
        protected int pos;


        public DataInputByteArray(byte[] b) {
            this(b, 0);
        }

        public DataInputByteArray(byte[] bb, int pos) {

            buf = bb;
            this.pos = pos;
        }

        @Override
        public void readFully(byte[] b) throws IOException {
            readFully(b, 0, b.length);
        }

        @Override
        public void readFully(byte[] b, int off, int len) throws IOException {
            System.arraycopy(buf, pos, b, off, len);

            pos += len;
        }

        @Override
        public int skipBytes(final int n) throws IOException {
            pos += n;

            return n;
        }

        @Override
        public boolean readBoolean() throws IOException {

            return buf[pos++] == 1;
        }

        @Override
        public byte readByte() throws IOException {

            return buf[pos++];
        }

        @Override
        public int readUnsignedByte() throws IOException {

            return buf[pos++] & 0xff;
        }

        @Override
        public short readShort() throws IOException {

            return (short)((buf[pos++] << 8) | (buf[pos++] & 0xff));
        }

        @Override
        public int readUnsignedShort() throws IOException {

            return readChar();
        }

        @Override
        public char readChar() throws IOException {

            return (char) (
                    ((buf[pos++] & 0xff) << 8) |
                    (buf[pos++] & 0xff));
        }

        @Override
        public int readInt() throws IOException {
            int p = pos;
            final byte[] b = buf;
            final int ret =
                    ((((int)b[p++]) << 24) |
                     (((int)b[p++] & 0xFF) << 16) |
                     (((int)b[p++] & 0xFF) <<  8) |
                     (((int)b[p++] & 0xFF)));
            pos = p;
            return ret;
        }

        @Override
        public long readLong() throws IOException {
            int p = pos;
            final byte[] b = buf;
            final long ret =
                    ((((long)b[p++]) << 56) |
                    (((long)b[p++] & 0xFF) << 48) |
                    (((long)b[p++] & 0xFF) << 40) |
                    (((long)b[p++] & 0xFF) << 32) |
                    (((long)b[p++] & 0xFF) << 24) |
                    (((long)b[p++] & 0xFF) << 16) |
                    (((long)b[p++] & 0xFF) <<  8) |
                    (((long)b[p++] & 0xFF)));
            pos = p;
            return ret;
        }

        @Override
        public float readFloat() throws IOException {
            return Float.intBitsToFloat(readInt());
        }

        @Override
        public double readDouble() throws IOException {
            return Double.longBitsToDouble(readLong());
        }

        @Override
        public String readLine() throws IOException {
            return readUTF();
        }

        @Override
        public String readUTF() throws IOException {
            final int len = unpackInt();
            char[] b = new char[len];
            for (int i = 0; i < len; i++)

                b[i] = (char) unpackInt();
            return new String(b);
        }

        @Override
        public int getPos() {
            return pos;
        }

        @Override
        public void setPos(int pos) {
            this.pos = pos;
        }

        @Override
        public byte[] internalByteArray() {
            return buf;
        }

        @Override
        public ByteBuffer internalByteBuffer() {
            return null;
        }

        @Override
        public void close() {
        }

        @Override
        public long unpackLong() throws IOException {
            byte[] b = buf;
            int p = pos;
            long ret = 0;
            byte v;
            do{

                v = b[p++];
                ret = (ret<<7 ) | (v & 0x7F);
            }while(v<0);
            pos = p;
            return ret;
        }

        @Override
        public int unpackInt() throws IOException {
            byte[] b = buf;
            int p = pos;
            int ret = 0;
            byte v;
            do{

                v = b[p++];
                ret = (ret<<7 ) | (v & 0x7F);
            }while(v<0);
            pos = p;
            return ret;
        }

        @Override
        public long[] unpackLongArrayDeltaCompression(final int size) throws IOException {
            long[] ret = new long[size];
            int pos2 = pos;
            byte[] buf2 = buf;
            long prev =0;
            byte v;
            for(int i=0;i<size;i++){
                long r = 0;
                do {

                    v = buf2[pos2++];
                    r = (r << 7) | (v & 0x7F);
                } while (v < 0);
                prev+=r;
                ret[i]=prev;
            }
            pos = pos2;
            return ret;
        }

        @Override
        public void unpackLongArray(long[] array, int start, int end) {
            int pos2 = pos;
            byte[] buf2 = buf;
            long ret;
            byte v;
            for(;start<end;start++) {
                ret = 0;
                do {

                    v = buf2[pos2++];
                    ret = (ret << 7) | (v & 0x7F);
                } while (v < 0);
                array[start]=ret;
            }
            pos = pos2;
        }

        @Override
        public void unpackIntArray(int[] array, int start, int end) {
            int pos2 = pos;
            byte[] buf2 = buf;
            int ret;
            byte v;
            for(;start<end;start++) {
                ret = 0;
                do {

                    v = buf2[pos2++];
                    ret = (ret << 7) | (v & 0x7F);
                } while (v < 0);
                array[start]=ret;
            }
            pos = pos2;
        }

    }


    public static final class DataInputToStream extends InputStream {

        protected final DataInput in;

        public DataInputToStream(DataInput in) {
            this.in = in;
        }

        @Override
        public int read(byte[] b, int off, int len) throws IOException {
            in.readFully(b,off,len);
            return len;
        }

        @Override
        public long skip(long n) throws IOException {
            n = Math.min(n, Integer.MAX_VALUE);

            return in.skipBytes((int) n);
        }

        @Override
        public void close() throws IOException {
            if(in instanceof Closeable)
                ((Closeable) in).close();
        }

        @Override
        public int read() throws IOException {
            return in.readUnsignedByte();
        }
    }



    public static final class DataInputByteBuffer implements DataInput, DataInputInternal {

        public final ByteBuffer buf;
        public int pos;

        public DataInputByteBuffer(final ByteBuffer buf, final int pos) {

            this.buf = buf;
            this.pos = pos;
        }


        public DataInputByteBuffer(byte[] b) {
            this(ByteBuffer.wrap(b),0);
        }

        @Override
        public void readFully(byte[] b) throws IOException {
            readFully(b, 0, b.length);
        }

        @Override
        public void readFully(byte[] b, int off, int len) throws IOException {
            ByteBuffer clone = buf.duplicate();
            clone.position(pos);

            pos+=len;
            clone.get(b, off, len);
        }

        @Override
        public int skipBytes(final int n) throws IOException {
            pos +=n;

            return n;
        }

        @Override
        public boolean readBoolean() throws IOException {

            return buf.get(pos++) ==1;
        }

        @Override
        public byte readByte() throws IOException {

            return buf.get(pos++);
        }

        @Override
        public int readUnsignedByte() throws IOException {

            return buf.get(pos++)& 0xff;
        }

        @Override
        public short readShort() throws IOException {
            final short ret = buf.getShort(pos);

            pos+=2;
            return ret;
        }

        @Override
        public int readUnsignedShort() throws IOException {
            return readChar();
        }

        @Override
        public char readChar() throws IOException {

            return (char) (
                    ((buf.get(pos++) & 0xff) << 8) |
                     (buf.get(pos++) & 0xff));
        }

        @Override
        public int readInt() throws IOException {
            final int ret = buf.getInt(pos);

            pos+=4;
            return ret;
        }

        @Override
        public long readLong() throws IOException {
            final long ret = buf.getLong(pos);

            pos+=8;
            return ret;
        }

        @Override
        public float readFloat() throws IOException {
            final float ret = buf.getFloat(pos);

            pos+=4;
            return ret;
        }

        @Override
        public double readDouble() throws IOException {
            final double ret = buf.getDouble(pos);

            pos+=8;
            return ret;
        }

        @Override
        public String readLine() throws IOException {
            return readUTF();
        }

        @Override
        public String readUTF() throws IOException {

            final int size = unpackInt();

            return SerializerBase.deserializeString(this, size);
        }


        @Override
        public int getPos() {
            return pos;
        }

        @Override
        public void setPos(int pos) {
            this.pos = pos;
        }

        @Override
        public byte[] internalByteArray() {
            return null;
        }

        @Override
        public ByteBuffer internalByteBuffer() {
            return buf;
        }

        @Override
        public void close() {
        }

        @Override
        public long unpackLong() throws IOException {
            long ret = 0;
            byte v;
            do{
                v = buf.get(pos++);
                ret = (ret<<7 ) | (v & 0x7F);
            }while(v<0);

            return ret;
        }

        @Override
        public int unpackInt() throws IOException {
            int ret = 0;
            byte v;
            do{
                v = buf.get(pos++);
                ret = (ret<<7 ) | (v & 0x7F);
            }while(v<0);

            return ret;
        }


        @Override
        public long[] unpackLongArrayDeltaCompression(final int size) throws IOException {
            long[] ret = new long[size];
            int pos2 = pos;
            ByteBuffer buf2 = buf;
            long prev=0;
            byte v;
            for(int i=0;i<size;i++){
                long r = 0;
                do {

                    v = buf2.get(pos2++);
                    r = (r << 7) | (v & 0x7F);
                } while (v < 0);
                prev+=r;
                ret[i]=prev;
            }
            pos = pos2;
            return ret;
        }

        @Override
        public void unpackLongArray(long[] array, int start, int end) {
            int pos2 = pos;
            ByteBuffer buf2 = buf;
            long ret;
            byte v;
            for(;start<end;start++) {
                ret = 0;
                do {

                    v = buf2.get(pos2++);
                    ret = (ret << 7) | (v & 0x7F);
                } while (v < 0);
                array[start] = ret;
            }
            pos = pos2;

        }

        @Override
        public void unpackIntArray(int[] array, int start, int end) {
            int pos2 = pos;
            ByteBuffer buf2 = buf;
            int ret;
            byte v;
            for(;start<end;start++) {
                ret = 0;
                do {

                    v = buf2.get(pos2++);
                    ret = (ret << 7) | (v & 0x7F);
                } while (v < 0);
                array[start] = ret;
            }
            pos = pos2;
        }

    }


    public static final class DataOutputByteArray extends OutputStream implements DataOutput {

        public byte[] buf;
        public int pos;
        public int sizeMask;


        public DataOutputByteArray(){
            pos = 0;
            buf = new byte[128]; 
            sizeMask = 0xFFFFFFFF-(buf.length-1);
        }


        public byte[] copyBytes(){
            return Arrays.copyOf(buf, pos);
        }


        public void ensureAvail(int n) {

            n+=pos;
            if ((n&sizeMask)!=0) {
                grow(n);
            }
        }

        private void grow(int n) {

            int newSize = Math.max(nextPowTwo(n),buf.length);
            sizeMask = 0xFFFFFFFF-(newSize-1);
            buf = Arrays.copyOf(buf, newSize);
        }


        @Override
        public void write(final int b) throws IOException {
            ensureAvail(1);

            buf[pos++] = (byte) b;
        }

        @Override
        public void write(final byte[] b, final int off, final int len) throws IOException {
            ensureAvail(len);

            System.arraycopy(b, off, buf, pos, len);
            pos += len;
        }

        @Override
        public void writeBoolean(final boolean v) throws IOException {
            ensureAvail(1);

            buf[pos++] = (byte) (v ? 1 : 0);
        }

        @Override
        public void writeByte(final int v) throws IOException {
            ensureAvail(1);

            buf[pos++] = (byte) (v);
        }

        @Override
        public void writeShort(final int v) throws IOException {
            ensureAvail(2);

            buf[pos++] = (byte) (0xff & (v >> 8));

            buf[pos++] = (byte) (0xff & (v));
        }

        @Override
        public void writeChar(final int v) throws IOException {
            ensureAvail(2);
            buf[pos++] = (byte) (v>>>8);
            buf[pos++] = (byte) (v);
        }

        @Override
        public void writeInt(final int v) throws IOException {
            ensureAvail(4);
            buf[pos++] = (byte) (0xff & (v >> 24));

            buf[pos++] = (byte) (0xff & (v >> 16));
            buf[pos++] = (byte) (0xff & (v >> 8));

            buf[pos++] = (byte) (0xff & (v));
        }

        @Override
        public void writeLong(final long v) throws IOException {
            ensureAvail(8);
            buf[pos++] = (byte) (0xff & (v >> 56));
            buf[pos++] = (byte) (0xff & (v >> 48));

            buf[pos++] = (byte) (0xff & (v >> 40));
            buf[pos++] = (byte) (0xff & (v >> 32));
            buf[pos++] = (byte) (0xff & (v >> 24));

            buf[pos++] = (byte) (0xff & (v >> 16));
            buf[pos++] = (byte) (0xff & (v >> 8));
            buf[pos++] = (byte) (0xff & (v));

        }

        @Override
        public void writeFloat(final float v) throws IOException {
            writeInt(Float.floatToIntBits(v));
        }

        @Override
        public void writeDouble(final double v) throws IOException {
            writeLong(Double.doubleToLongBits(v));
        }

        @Override
        public void writeBytes(final String s) throws IOException {
            writeUTF(s);
        }

        @Override
        public void writeChars(final String s) throws IOException {
            writeUTF(s);
        }

        @Override
        public void writeUTF(final String s) throws IOException {
            final int len = s.length();
            packInt(len);
            for (int i = 0; i < len; i++) {

                int c = (int) s.charAt(i);
                packInt(c);
            }
        }

        public void packInt(int value) throws IOException {
            ensureAvail(5); 




            int shift = (value & ~0x7F); 
            if (shift != 0) {
                shift = 31 - Integer.numberOfLeadingZeros(value);
                shift -= shift % 7; 
                while (shift != 0) {
                    buf[pos++] = (byte) (((value >>> shift) & 0x7F) | 0x80);
                    shift -= 7;
                }
            }
            buf[pos++] = (byte) (value & 0x7F);
        }

        public void packIntBigger(int value) throws IOException {
            ensureAvail(5); 
            int shift = 31-Integer.numberOfLeadingZeros(value);
            shift -= shift%7; 
            while(shift!=0){
                buf[pos++] = (byte) (((value>>>shift) & 0x7F) | 0x80);
                shift-=7;
            }
            buf[pos++] = (byte) (value & 0x7F);
        }

        public void packLong(long value) {
            ensureAvail(10); 
            int shift = 63-Long.numberOfLeadingZeros(value);
            shift -= shift%7; 
            while(shift!=0){
                buf[pos++] = (byte) (((value>>>shift) & 0x7F) | 0x80);
                shift-=7;
            }
            buf[pos++] = (byte) (value & 0x7F);
        }
    }


    public static long parity1Set(long i) {
        if(CC.ASSERT && (i&1)!=0)
            throw new DBException.PointerChecksumBroken();
        return i | ((Long.bitCount(i)+1)%2);
    }

    public static long parity1Get(long i) {
        if(Long.bitCount(i)%2!=1){
            throw new DBException.PointerChecksumBroken();
        }
        return i&0xFFFFFFFFFFFFFFFEL;
    }

    public static long parity3Set(long i) {
        if(CC.ASSERT && (i&0x7)!=0)
            throw new DBException.PointerChecksumBroken();
        return i | ((Long.bitCount(i)+1)%8);
    }

    public static long parity3Get(long i) {
        long ret = i&0xFFFFFFFFFFFFFFF8L;
        if((Long.bitCount(ret)+1)%8!=(i&0x7)){
            throw new DBException.PointerChecksumBroken();
        }
        return ret;
    }

    public static long parity4Set(long i) {
        if(CC.ASSERT && (i&0xF)!=0)
            throw new DBException.PointerChecksumBroken();
        return i | ((Long.bitCount(i)+1)%16);
    }

    public static long parity4Get(long i) {
        long ret = i&0xFFFFFFFFFFFFFFF0L;
        if((Long.bitCount(ret)+1)%16!=(i&0xF)){
            throw new DBException.PointerChecksumBroken();
        }
        return ret;
    }


    public static long parity16Set(long i) {
        if(CC.ASSERT && (i&0xFFFF)!=0)
            throw new DBException.PointerChecksumBroken();
        return i | (DataIO.longHash(i)&0xFFFFL);
    }

    public static long parity16Get(long i) {
        long ret = i&0xFFFFFFFFFFFF0000L;
        if((DataIO.longHash(ret)&0xFFFFL) != (i&0xFFFFL)){
            throw new DBException.PointerChecksumBroken();
        }
        return ret;
    }



    public static String toHexa( byte [] bb ) {
        char[] HEXA_CHARS = {'0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F'};
        char[] ret = new char[bb.length*2];
        for(int i=0;i<bb.length;i++){
            ret[i*2] =HEXA_CHARS[((bb[i]& 0xF0) >> 4)];
            ret[i*2+1] = HEXA_CHARS[((bb[i] & 0x0F))];
        }
        return new String(ret);
    }


    public static byte[] fromHexa(String s ) {
        byte[] ret = new byte[s.length()/2];
        for(int i=0;i<ret.length;i++){
            ret[i] = (byte) Integer.parseInt(s.substring(i*2,i*2+2),16);
        }
        return ret;
    }


}

<code block>
package org.mapdb;

import java.io.DataInput;
import java.io.IOError;
import java.io.IOException;
import java.lang.ref.ReferenceQueue;
import java.lang.ref.SoftReference;
import java.lang.ref.WeakReference;
import java.nio.ByteBuffer;
import java.util.*;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.locks.*;
import java.util.logging.Level;
import java.util.logging.Logger;
import java.util.zip.CRC32;


public abstract class Store implements Engine {

    protected static final Logger LOG = Logger.getLogger(Store.class.getName());

    protected static final long FEAT_COMP_LZW = 64L-1L;
    protected static final long FEAT_ENC_XTEA = 64L-2L;
    protected static final long FEAT_CRC = 64L-3L;

    protected static final long HEAD_CHECKSUM = 4;
    protected static final long HEAD_FEATURES = 8;





    protected final ReentrantLock structuralLock = new ReentrantLock(CC.FAIR_LOCKS);


    protected final ReentrantLock commitLock = new ReentrantLock(CC.FAIR_LOCKS);


    protected final ReadWriteLock[] locks;
    protected final int lockScale;
    protected final int lockMask;


    protected volatile boolean closed = false;
    protected final boolean readonly;

    protected final String fileName;
    protected final Volume.VolumeFactory volumeFactory;
    protected final boolean checksum;
    protected final boolean compress;
    protected final boolean encrypt;
    protected final EncryptionXTEA encryptionXTEA;
    protected final ThreadLocal<CompressLZF> LZF;
    protected final boolean snapshotEnable;

    protected final AtomicLong metricsDataWrite;
    protected final AtomicLong metricsRecordWrite;
    protected final AtomicLong metricsDataRead;
    protected final AtomicLong metricsRecordRead;


    protected final Cache[] caches;

    public static final int LOCKING_STRATEGY_READWRITELOCK=0;
    public static final int LOCKING_STRATEGY_WRITELOCK=1;
    public static final int LOCKING_STRATEGY_NOLOCK=2;

    protected Store(
            String fileName,
            Volume.VolumeFactory volumeFactory,
            Cache cache,
            int lockScale,
            int lockingStrategy,
            boolean checksum,
            boolean compress,
            byte[] password,
            boolean readonly,
            boolean snapshotEnable) {
        this.fileName = fileName;
        this.volumeFactory = volumeFactory;
        this.lockScale = lockScale;
        this.snapshotEnable = snapshotEnable;
        this.lockMask = lockScale-1;
        if(Integer.bitCount(lockScale)!=1)
            throw new IllegalArgumentException();

        metricsDataWrite = new AtomicLong();
        metricsRecordWrite = new AtomicLong();
        metricsDataRead = new AtomicLong();
        metricsRecordRead = new AtomicLong();

        locks = new ReadWriteLock[lockScale];
        for(int i=0;i< locks.length;i++){
            if(lockingStrategy==LOCKING_STRATEGY_READWRITELOCK)
                locks[i] = new ReentrantReadWriteLock(CC.FAIR_LOCKS);
            else if(lockingStrategy==LOCKING_STRATEGY_WRITELOCK){
                locks[i] = new ReadWriteSingleLock(new ReentrantLock(CC.FAIR_LOCKS));
            }else if(lockingStrategy==LOCKING_STRATEGY_NOLOCK){
                locks[i] = new ReadWriteSingleLock(NOLOCK);
            }else{
                throw new IllegalArgumentException("Illegal locking strategy: "+lockingStrategy);
            }
        }

        if(cache==null) {
            caches = null;
        }else {
            caches = new Cache[lockScale];
            caches[0] = cache;
            for (int i = 1; i < caches.length; i++) {

                caches[i] = cache.newCacheForOtherSegment();
            }
        }


        this.checksum = checksum;
        this.compress = compress;
        this.encrypt =  password!=null;
        this.readonly = readonly;
        this.encryptionXTEA = !encrypt?null:new EncryptionXTEA(password);

        this.LZF = !compress?null:new ThreadLocal<CompressLZF>() {
            @Override
            protected CompressLZF initialValue() {
                return new CompressLZF();
            }
        };
    }

    public void init(){}

    protected void checkFeaturesBitmap(final long feat){
        boolean xteaEnc = (feat>>>FEAT_ENC_XTEA&1)!=0;
        if(xteaEnc&& !encrypt){
            throw new DBException.WrongConfig("Store was created with encryption, but no password is set in config.");
        }
        if(!xteaEnc&& encrypt){
            throw new DBException.WrongConfig("Password is set, but store is not encrypted.");
        }

        boolean lzwComp = (feat>>>FEAT_COMP_LZW&1)!=0;
        if(lzwComp&& !compress){
            throw new DBException.WrongConfig("Store was created with compression, but no compression is enabled in config.");
        }
        if(!lzwComp&& compress){
            throw new DBException.WrongConfig("Compression is set in config, but store was created with compression.");
        }

        boolean crc = (feat>>>FEAT_CRC&1)!=0;
        if(crc&& !checksum){
            throw new DBException.WrongConfig("Store was created with CRC32 checksum, but it is not enabled in config.");
        }
        if(!crc&& checksum){
            throw new DBException.WrongConfig("Checksum us enabled, but store was created without it.");
        }

        int endZeroes = Long.numberOfTrailingZeros(feat);
        if(endZeroes<FEAT_CRC){
            throw new DBException.WrongConfig("Unknown feature #"+endZeroes+". Store was created with never MapDB version, this version does not support this feature.");
        }
    }

    protected long makeFeaturesBitmap(){
        return
            (compress ? 1L<<FEAT_COMP_LZW : 0) |
            (encrypt  ? 1L<<FEAT_ENC_XTEA : 0) |
            (checksum  ? 1L<<FEAT_CRC : 0)
        ;
    }

    @Override
    public <A> A get(long recid, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();
        if(closed)
            throw new IllegalAccessError("closed");

        int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].readLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        lock.lock();
        try{
            A o = cache==null ? null : (A) cache.get(recid);
            if(o!=null) {
                return o== Cache.NULL?null:o;
            }
            o =  get2(recid,serializer);
            if(cache!=null) {
                cache.put(recid, o);
            }
            return o;
        }finally {
            lock.unlock();
        }
    }

    protected abstract <A> A get2(long recid, Serializer<A> serializer);

    @Override
    public <A> void update(long recid, A value, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();
        if(closed)
            throw new IllegalAccessError("closed");



        DataIO.DataOutputByteArray out = serialize(value, serializer);
        int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].writeLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        lock.lock();
        try{
            if(cache!=null) {
                cache.put(recid, value);
            }
            update2(recid,out);
        }finally {
            lock.unlock();
        }
    }


    protected final AtomicReference<DataIO.DataOutputByteArray> recycledDataOut =
            new AtomicReference<DataIO.DataOutputByteArray>();

    protected <A> DataIO.DataOutputByteArray serialize(A value, Serializer<A> serializer){
        if(value==null)
            return null;
        try {
            DataIO.DataOutputByteArray out = newDataOut2();

            serializer.serialize(out,value);

            if(out.pos>0){

                if(compress){
                    DataIO.DataOutputByteArray tmp = newDataOut2();
                    tmp.ensureAvail(out.pos+40);
                    final CompressLZF lzf = LZF.get();
                    int newLen;
                    try{
                        newLen = lzf.compress(out.buf,out.pos,tmp.buf,0);
                    }catch(IndexOutOfBoundsException e){
                        newLen=0; 
                    }
                    if(newLen>=out.pos) newLen= 0; 

                    if(newLen==0){
                        recycledDataOut.lazySet(tmp);

                        out.ensureAvail(out.pos+1);
                        System.arraycopy(out.buf,0,out.buf,1,out.pos);
                        out.pos+=1;
                        out.buf[0] = 0;
                    }else{

                        final int decompSize = out.pos;
                        out.pos=0;
                        DataIO.packInt(out,decompSize);
                        out.write(tmp.buf,0,newLen);
                        recycledDataOut.lazySet(tmp);
                    }

                }


                if(encrypt){
                    int size = out.pos;

                    if(size%EncryptionXTEA.ALIGN!=0)
                        size += EncryptionXTEA.ALIGN - size%EncryptionXTEA.ALIGN;
                    final int sizeDif=size-out.pos;

                    out.ensureAvail(sizeDif+1);
                    encryptionXTEA.encrypt(out.buf,0,size);

                    out.pos = size;
                    out.writeByte(sizeDif);
                }

                if(checksum){
                    CRC32 crc = new CRC32();
                    crc.update(out.buf,0,out.pos);
                    out.writeInt((int)crc.getValue());
                }

                if(CC.PARANOID)try{

                    DataInput inp = new DataIO.DataInputByteArray(Arrays.copyOf(out.buf, out.pos));
                    byte[] decompress = deserialize(Serializer.BYTE_ARRAY_NOSIZE,out.pos,inp);

                    DataIO.DataOutputByteArray expected = newDataOut2();
                    serializer.serialize(expected,value);

                    byte[] expected2 = Arrays.copyOf(expected.buf, expected.pos);

                    if(CC.ASSERT && ! (Arrays.equals(expected2,decompress)))
                        throw new AssertionError();


                }catch(Exception e){
                    throw new RuntimeException(e);
                }
            }

            metricsDataWrite.getAndAdd(out.pos);
            metricsRecordWrite.incrementAndGet();

            return out;
        } catch (IOException e) {
            throw new IOError(e);
        }

    }

    protected DataIO.DataOutputByteArray newDataOut2() {
        DataIO.DataOutputByteArray tmp = recycledDataOut.getAndSet(null);
        if(tmp==null) tmp = new DataIO.DataOutputByteArray();
        else tmp.pos=0;
        return tmp;
    }


    protected <A> A deserialize(Serializer<A> serializer, int size, DataInput input){
        try {



            DataIO.DataInputInternal di = (DataIO.DataInputInternal) input;
            if (size > 0 && (checksum || encrypt || compress))  {
                return deserializeExtra(serializer,size,di);
            }

            int start = di.getPos();

            A ret = serializer.deserialize(di, size);
            if (size + start > di.getPos())
                throw new AssertionError("data were not fully read, check your serializer ");
            if (size + start < di.getPos())
                throw new AssertionError("data were read beyond record size, check your serializer");

            metricsDataRead.getAndAdd(size);
            metricsRecordRead.getAndIncrement();

            return ret;
        }catch(IOException e){
            throw new IOError(e);
        }
    }


    private <A> A deserializeExtra(Serializer<A> serializer, int size, DataIO.DataInputInternal di) throws IOException {
        if (checksum) {

            size -= 4;


            DataIO.DataOutputByteArray tmp = newDataOut2();
            tmp.ensureAvail(size);
            int oldPos = di.getPos();
            di.readFully(tmp.buf, 0, size);
            final int checkExpected = di.readInt();
            di.setPos(oldPos);

            CRC32 crc = new CRC32();
            crc.update(tmp.buf, 0, size);
            recycledDataOut.lazySet(tmp);
            int check = (int) crc.getValue();
            if (check != checkExpected)
                throw new IOException("Checksum does not match, data broken");
        }

        if (encrypt) {
            DataIO.DataOutputByteArray tmp = newDataOut2();
            size -= 1;
            tmp.ensureAvail(size);
            di.readFully(tmp.buf, 0, size);
            encryptionXTEA.decrypt(tmp.buf, 0, size);
            int cut = di.readUnsignedByte(); 
            di = new DataIO.DataInputByteArray(tmp.buf);
            size -= cut;
        }

        if (compress) {

            int decompSize = DataIO.unpackInt(di);
            if (decompSize == 0) {
                size -= 1;

            } else {
                DataIO.DataOutputByteArray out = newDataOut2();
                out.ensureAvail(decompSize);
                CompressLZF lzf = LZF.get();


                byte[] b = di.internalByteArray();
                if (b != null) {
                    lzf.expand(b, di.getPos(), out.buf, 0, decompSize);
                } else {
                    ByteBuffer bb = di.internalByteBuffer();
                    if (bb != null) {
                        lzf.expand(bb, di.getPos(), out.buf, 0, decompSize);
                    } else {
                        lzf.expand(di, out.buf, 0, decompSize);
                    }
                }
                di = new DataIO.DataInputByteArray(out.buf);
                size = decompSize;
            }
        }


        int start = di.getPos();

        A ret = serializer.deserialize(di, size);
        if (size + start > di.getPos())
            throw new AssertionError("data were not fully read, check your serializer ");
        if (size + start < di.getPos())
            throw new AssertionError("data were read beyond record size, check your serializer");
        return ret;
    }

    protected abstract  void update2(long recid, DataIO.DataOutputByteArray out);

    @Override
    public <A> boolean compareAndSwap(long recid, A expectedOldValue, A newValue, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();
        if(closed)
            throw new IllegalAccessError("closed");



        final int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].writeLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        lock.lock();
        try{
            A oldVal =  cache==null ? null : (A)cache.get(recid);
            if(oldVal == null) {
                oldVal = get2(recid, serializer);
            }else if(oldVal == Cache.NULL){
                oldVal = null;
            }
            if(oldVal==expectedOldValue || (oldVal!=null && serializer.equals(oldVal,expectedOldValue))){
                update2(recid,serialize(newValue,serializer));
                if(cache!=null) {
                    cache.put(recid, newValue);
                }
                return true;
            }
            return false;
        }finally {
            lock.unlock();
        }
    }


    @Override
    public <A> void delete(long recid, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();
        if(closed)
            throw new IllegalAccessError("closed");


        final int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].writeLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        lock.lock();
        try{
            if(cache!=null) {
                cache.put(recid, null);
            }
            delete2(recid, serializer);
        }finally {
            lock.unlock();
        }
    }

    protected abstract <A> void delete2(long recid, Serializer<A> serializer);

    protected final int lockPos(final long recid) {
        int h = (int)(recid ^ (recid >>> 32));

        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        return h & lockMask;
    }

    protected void assertReadLocked(long recid) {



    }

    protected void assertWriteLocked(int segment) {
        ReadWriteLock l = locks[segment];
        if(l instanceof ReentrantReadWriteLock && !((ReentrantReadWriteLock) l).isWriteLockedByCurrentThread()){
            throw new AssertionError();
        }
    }


    @Override
    public boolean isClosed() {
        return closed;
    }

    @Override
    public boolean isReadOnly() {
        return readonly;
    }


    public static Store forDB(DB db){
        return forEngine(db.engine);
    }


    public static Store forEngine(Engine e){
        Engine engine2 = e.getWrappedEngine();
        if(engine2!=null)
            return forEngine(engine2);

        return (Store) e;
    }

    public abstract long getCurrSize();

    public abstract long getFreeSize();

    @Override
    public void clearCache() {
        if(closed)
            throw new IllegalAccessError("closed");

        if(caches==null)
            return;

        for(int i=0;i<locks.length;i++){
            Lock lock = locks[i].readLock();
            lock.lock();
            try{
                caches[i].clear();
            }finally {
                lock.unlock();
            }
        }
    }


    public void metricsCollect(Map<String,Long> map) {
        map.put(DB.METRICS_DATA_WRITE,metricsDataWrite.getAndSet(0));
        map.put(DB.METRICS_RECORD_WRITE,metricsRecordWrite.getAndSet(0));
        map.put(DB.METRICS_DATA_READ,metricsDataRead.getAndSet(0));
        map.put(DB.METRICS_RECORD_READ,metricsRecordRead.getAndSet(0));

        long cacheHit = 0;
        long cacheMiss = 0;
        if(caches!=null) {
            for (Cache c : caches) {
                cacheHit += c.metricsCacheHit();
                cacheMiss += c.metricsCacheMiss();
            }
        }

        map.put(DB.METRICS_CACHE_HIT,cacheHit);
        map.put(DB.METRICS_CACHE_MISS, cacheMiss);
    }


    public static abstract class Cache {

        protected final Lock lock;
        protected long cacheHitCounter = 0;
        protected long cacheMissCounter = 0;

        protected static final Object NULL = new Object();

        public Cache(boolean disableLocks) {
            this.lock = disableLocks?null:  new ReentrantLock(CC.FAIR_LOCKS);
        }


        public abstract Object get(long recid);
        public abstract void put(long recid, Object item);

        public abstract void clear();
        public abstract void close();

        public abstract Cache newCacheForOtherSegment();


        public long metricsCacheHit() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try {
                long ret = cacheHitCounter;
                cacheHitCounter=0;
                return ret;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }



        public long metricsCacheMiss() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try {
                long ret = cacheMissCounter;
                cacheMissCounter=0;
                return ret;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }


        public static final class HashTable extends Cache {


            protected final long[] recids; 
            protected final Object[] items;

            protected final int cacheMaxSizeMask;


            public HashTable(int cacheMaxSize, boolean disableLocks) {
                super(disableLocks);
                cacheMaxSize = DataIO.nextPowTwo(cacheMaxSize); 

                this.cacheMaxSizeMask = cacheMaxSize-1;

                this.recids = new long[cacheMaxSize];
                this.items = new Object[cacheMaxSize];
            }

            @Override
            public Object get(long recid) {
                int pos = pos(recid);
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try {
                    boolean hit = recids[pos] == recid;
                    if(hit){
                        if(CC.METRICS_CACHE)
                            cacheHitCounter++;
                        return items[pos];
                    }else{
                        if(CC.METRICS_CACHE)
                            cacheMissCounter++;
                        return null;
                    }
                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            @Override
            public void put(long recid, Object item) {
                if(item == null)
                    item = NULL;
                int pos = pos(recid);
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try {
                    recids[pos] = recid;
                    items[pos] = item;
                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            protected int pos(long recid) {
                return DataIO.longHash(recid)&cacheMaxSizeMask;
            }

            @Override
            public void clear() {
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try {
                    Arrays.fill(recids, 0L);
                    Arrays.fill(items, null);
                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            @Override
            public void close() {
                clear();
            }

            @Override
            public Cache newCacheForOtherSegment() {
                return new HashTable(recids.length,lock==null);
            }

        }



    public static class WeakSoftRef extends Store.Cache {


        protected interface CacheItem{
            long getRecid();
            Object get();
            void clear();
        }

        protected static final class CacheWeakItem<A> extends WeakReference<A> implements CacheItem {

            final long recid;

            public CacheWeakItem(A referent, ReferenceQueue<A> q, long recid) {
                super(referent, q);
                this.recid = recid;
            }

            @Override
            public long getRecid() {
                return recid;
            }
        }

        protected static final class CacheSoftItem<A> extends SoftReference<A> implements CacheItem {

            final long recid;

            public CacheSoftItem(A referent, ReferenceQueue<A> q, long recid) {
                super(referent, q);
                this.recid = recid;
            }

            @Override
            public long getRecid() {
                return recid;
            }
        }

        protected ReferenceQueue<Object> queue = new ReferenceQueue<Object>();

        protected LongObjectMap<CacheItem> items = new LongObjectMap<CacheItem>();

        protected final static int CHECK_EVERY_N = 0xFFFF;
        protected int counter = 0;
        protected final ScheduledExecutorService executor;

        protected final boolean useWeakRef;
        protected final long executorScheduledRate;

        public WeakSoftRef(boolean useWeakRef, boolean disableLocks,
                           ScheduledExecutorService executor,
                           long executorScheduledRate) {
            super(disableLocks);
            if(CC.ASSERT && disableLocks && executor!=null) {
                throw new IllegalArgumentException("Lock can not be disabled with executor enabled");
            }
            this.useWeakRef = useWeakRef;
            this.executor = executor;
            this.executorScheduledRate = executorScheduledRate;
            if(executor!=null){
                executor.scheduleAtFixedRate(new Runnable() {
                    @Override
                    public void run() {
                        WeakSoftRef.this.flushGCedLocked();
                    }
                    },
                    (long) (executorScheduledRate*Math.random()),
                    executorScheduledRate,
                    TimeUnit.MILLISECONDS);
            }
        }


        @Override
        public Object get(long recid) {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                CacheItem item = items.get(recid);
                Object ret;
                if(item==null){
                    if(CC.METRICS_CACHE)
                        cacheMissCounter++;
                    ret = null;
                }else{
                    if(CC.METRICS_CACHE)
                        cacheHitCounter++;
                    ret = item.get();
                }

                if (executor==null && (((counter++) & CHECK_EVERY_N) == 0)) {
                    flushGCed();
                }
                return ret;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public void put(long recid, Object item) {
            if(item ==null)
                item = Cache.NULL;
            CacheItem cacheItem = useWeakRef?
                    new CacheWeakItem(item,queue,recid):
                    new CacheSoftItem(item,queue,recid);
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                CacheItem older = items.put(recid,cacheItem);
                if(older!=null)
                    older.clear();
                if (executor==null && (((counter++) & CHECK_EVERY_N) == 0)) {
                    flushGCed();
                }
            }finally {
                if(lock!=null)
                    lock.unlock();
            }

        }

        @Override
        public void clear() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                items.clear(); 
            }finally {
                if(lock!=null)
                    lock.unlock();
            }

        }

        @Override
        public void close() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{

                items.clear();
                items = null;
                flushGCed();
                queue = null;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public Cache newCacheForOtherSegment() {
            return new Cache.WeakSoftRef(
                    useWeakRef,
                    lock==null,
                    executor,
                    executorScheduledRate);
        }

        protected void flushGCed() {
            if(CC.ASSERT && lock!=null &&
                    (lock instanceof ReentrantLock) &&
                    !((ReentrantLock)lock).isHeldByCurrentThread()) {
                throw new AssertionError("Not locked by current thread");
            }
            counter = 1;
            CacheItem item = (CacheItem) queue.poll();
            while(item!=null){
                long recid = item.getRecid();

                CacheItem otherEntry = items.get(recid);
                if(otherEntry !=null && otherEntry.get()==null)
                    items.remove(recid);

                item = (CacheItem) queue.poll();
            }
        }


        protected void flushGCedLocked() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                flushGCed();
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

    }


    public static final class HardRef extends  Store.Cache{

        protected final static int CHECK_EVERY_N = 0xFFFF;

        protected int counter;

        protected final Store.LongObjectMap cache;

        protected final int initialCapacity;

        protected final ScheduledExecutorService executor;
        protected final long executorPeriod;


        public HardRef(int initialCapacity, boolean disableLocks, ScheduledExecutorService executor, long executorPeriod) {
            super(disableLocks);
            if(disableLocks && executor!=null)
                throw new IllegalArgumentException("Executor can not be enabled with lock disabled");
            
            this.initialCapacity = initialCapacity;
            cache = new Store.LongObjectMap(initialCapacity);
            this.executor = executor;
            this.executorPeriod = executorPeriod;
            if(executor!=null){
                executor.scheduleAtFixedRate(new Runnable() {
                    @Override
                    public void run() {
                        Lock lock = HardRef.this.lock;
                        lock.lock();
                        try {
                            checkFreeMem();
                        }finally {
                            lock.unlock();
                        }
                    }
                },executorPeriod,executorPeriod,TimeUnit.MILLISECONDS);
            }
        }


        private void checkFreeMem() {
            counter=1;
            Runtime r = Runtime.getRuntime();
            long max = r.maxMemory();
            if(max == Long.MAX_VALUE)
                return;

            double free = r.freeMemory();
            double total = r.totalMemory();


            free = free + (max-total);

            if(CC.LOG_EWRAP && LOG.isLoggable(Level.FINE))
                LOG.fine("HardRefCache: freemem = " +free + " = "+(free/max)+"%");

            if(free<1e7 || free*4 <max){
                cache.clear();
                if(CC.LOG_EWRAP && LOG.isLoggable(Level.FINE))
                    LOG.fine("Clear HardRef cache");
            }
        }

        @Override
        public Object get(long recid) {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try {
                if (executor==null && ((counter++) & CHECK_EVERY_N) == 0) {
                    checkFreeMem();
                }
                Object item = cache.get(recid);

                if(CC.METRICS_CACHE){
                    if(item!=null){
                        cacheHitCounter++;
                    }else{
                        cacheMissCounter++;
                    }
                }

                return item;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public void put(long recid, Object item) {
            if(item == null)
                item = Cache.NULL;
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try {
                if (executor==null && ((counter++) & CHECK_EVERY_N) == 0) {
                    checkFreeMem();
                }
                cache.put(recid,item);
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public void clear() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                cache.clear();
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public void close() {
            clear();
        }

        @Override
        public Cache newCacheForOtherSegment() {
            return new HardRef(initialCapacity,lock==null,executor,executorPeriod);
        }
    }

        public static final class LRU extends Cache {

            protected final int cacheSize;


            protected final LinkedHashMap<Long, Object> items = new LinkedHashMap<Long,Object>();

            public LRU(int cacheSize, boolean disableLocks) {
                super(disableLocks);
                this.cacheSize = cacheSize;
            }

            @Override
            public Object get(long recid) {
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try{
                    Object ret =  items.get(recid);
                    if(CC.METRICS_CACHE){
                        if(ret!=null){
                            cacheHitCounter++;
                        }else{
                            cacheMissCounter++;
                        }
                    }
                    return ret;

                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            @Override
            public void put(long recid, Object item) {
                if(item == null)
                    item = Cache.NULL;

                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try{
                    items.put(recid,item);


                    int itemsSize = items.size();
                    if(itemsSize>cacheSize) {
                        Iterator iter = items.entrySet().iterator();
                        while(itemsSize-- > cacheSize && iter.hasNext()){
                            iter.next();
                            iter.remove();
                        }
                    }

                }finally {
                    if(lock!=null)
                        lock.unlock();
                }

            }

            @Override
            public void clear() {
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try{
                    items.clear();
                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            @Override
            public void close() {
                clear();
            }

            @Override
            public Cache newCacheForOtherSegment() {
                return new LRU(cacheSize,lock==null);
            }
        }
    }




    public static final class LongLongMap {

        int size;

        int maxSize;

        long[] table;

        public LongLongMap(){
            this(32);
        }

        public LongLongMap(int initCapacity) {
            initCapacity = DataIO.nextPowTwo(initCapacity)*2;
            table = new long[initCapacity];
        }


        public long get(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return table[index + 1];
            } else {

                return 0;
            }
        }

        public long put(long key, long value) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            if(CC.ASSERT && value==0)
                throw new IllegalArgumentException("zero val");

            int index = insert(key, value);
            if (index < 0) {

                return 0;
            } else {

                long[] tab = table;
                long prevValue = tab[index + 1];
                tab[index + 1] = value;
                return prevValue;
            }
        }

        int insert(long key, long value) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            long[] tab = table;
            int capacityMask, index;
            long cur;
            keyAbsent:
            if ((cur = tab[index = DataIO.longHash(key) & (capacityMask = tab.length - 2)]) != 0) {
                if (cur == key) {

                    return index;
                } else {
                    while (true) {
                        if ((cur = tab[(index = (index - 2) & capacityMask)]) == 0) {
                            break keyAbsent;
                        } else if (cur == key) {

                            return index;
                        }
                    }
                }
            }

            tab[index] = key;
            tab[index + 1] = value;


            if (++size > maxSize) {
                int capacity = table.length >> 1;
                if (!isMaxCapacity(capacity)) {
                    rehash(capacity << 1);
                }
            }


            return -1;
        }

        int index(long key) {
            if (key != 0) {
                long[] tab = table;
                int capacityMask, index;
                long cur;
                if ((cur = tab[index = DataIO.longHash(key) & (capacityMask = tab.length - 2)]) == key) {

                    return index;
                } else {
                    if (cur == 0) {

                        return -1;
                    } else {
                        while (true) {
                            if ((cur = tab[(index = (index - 2) & capacityMask)]) == key) {

                                return index;
                            } else if (cur == 0) {

                                return -1;
                            }
                        }
                    }
                }
            } else {

                return -1;
            }
        }

        public int size(){
            return size;
        }

        public void clear() {
            size = 0;
            Arrays.fill(table,0);
        }


        void rehash(int newCapacity) {
            long[] tab = table;
            if(CC.ASSERT && !((newCapacity & (newCapacity - 1)) == 0)) 
                throw new AssertionError();
            maxSize = maxSize(newCapacity);
            table = new long[newCapacity * 2];

            long[] newTab = table;
            int capacityMask = newTab.length - 2;
            for (int i = tab.length - 2; i >= 0; i -= 2) {
                long key;
                if ((key = tab[i]) != 0) {
                    int index;
                    if (newTab[index = DataIO.longHash(key) & capacityMask] != 0) {
                        while (true) {
                            if (newTab[(index = (index - 2) & capacityMask)] == 0) {
                                break;
                            }
                        }
                    }
                    newTab[index] = key;
                    newTab[index + 1] = tab[i + 1];
                }
            }
        }

        static int maxSize(int capacity) {


            return !isMaxCapacity(capacity) ?
                    capacity/2 
                    : capacity - 1;
        }

        private static final int MAX_INT_CAPACITY = 1 << 30;

        private static boolean isMaxCapacity(int capacity) {
            int maxCapacity = MAX_INT_CAPACITY;
            maxCapacity >>= 1;
            return capacity == maxCapacity;
        }


        public LongLongMap clone(){
            LongLongMap ret = new LongLongMap();
            ret.maxSize = maxSize;
            ret.size = size;
            ret.table = table.clone();
            return ret;
        }

        public boolean putIfAbsent(long key, long value) {
            if(get(key)==0){
                put(key,value);
                return true;
            }else{
                return false;
            }
        }
    }



    public static final class LongObjectMap<V> {

        int size;

        int maxSize;

        long[] set;
        Object[] values;

        public LongObjectMap(){
            this(32);
        }

        public LongObjectMap(int initCapacity) {
            initCapacity = DataIO.nextPowTwo(initCapacity);
            set = new long[initCapacity];
            values = (V[]) new Object[initCapacity];
        }

        public V get(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return (V) values[index];
            } else {

                return null;
            }
        }

        int index(long key) {
            if (key != 0) {
                long[] keys = set;
                int capacityMask, index;
                long cur;
                if ((cur = keys[index = DataIO.longHash(key) & (capacityMask = keys.length - 1)]) == key) {

                    return index;
                } else {
                    if (cur == 0) {

                        return -1;
                    } else {
                        while (true) {
                            if ((cur = keys[(index = (index - 1) & capacityMask)]) == key) {

                                return index;
                            } else if (cur == 0) {

                                return -1;
                            }
                        }
                    }
                }
            } else {

                return -1;
            }
        }

        public V put(long key, V value) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = insert(key, value);
            if (index < 0) {

                return null;
            } else {

                Object[] vals = values;
                V prevValue = (V) vals[index];
                vals[index] = value;
                return prevValue;
            }
        }

        int insert(long key, V value) {
            long[] keys = set;
            int capacityMask, index;
            long cur;
            keyAbsent:
            if ((cur = keys[index = DataIO.longHash(key) & (capacityMask = keys.length - 1)]) != 0) {
                if (cur == key) {

                    return index;
                } else {
                    while (true) {
                        if ((cur = keys[(index = (index - 1) & capacityMask)]) == 0) {
                            break keyAbsent;
                        } else if (cur == key) {

                            return index;
                        }
                    }
                }
            }


            keys[index] = key;
            values[index] = value;
            postInsertHook();
            return -1;
        }

        void postInsertHook() {
            if (++size > maxSize) {

                int capacity = set.length;
                if (!LongLongMap.isMaxCapacity(capacity)) {
                    rehash(capacity << 1);
                }
            }
        }


        void rehash(int newCapacity) {
            long[] keys = set;
            Object[] vals = values;

            maxSize = LongLongMap.maxSize(newCapacity);
            set = new long[newCapacity];
            values = new Object[newCapacity];

            long[] newKeys = set;
            int capacityMask = newKeys.length - 1;
            Object[] newVals = values;
            for (int i = keys.length - 1; i >= 0; i--) {
                long key;
                if ((key = keys[i]) != 0) {
                    int index;
                    if (newKeys[index = DataIO.longHash(key) & capacityMask] != 0) {
                        while (true) {
                            if (newKeys[(index = (index - 1) & capacityMask)] == 0) {
                                break;
                            }
                        }
                    }
                    newKeys[index] = key;
                    newVals[index] = vals[i];
                }
            }
        }


        public void clear() {
            size = 0;
            Arrays.fill(set,0);
            Arrays.fill(values,null);
        }

        public V remove(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");
            long[] keys = set;
            int capacityMask = keys.length - 1;
            int index;
            long cur;
            keyPresent:
            if ((cur = keys[index = DataIO.longHash(key) & capacityMask]) != key) {
                if (cur == 0) {

                    return null;
                } else {
                    while (true) {
                        if ((cur = keys[(index = (index - 1) & capacityMask)]) == key) {
                            break keyPresent;
                        } else if (cur == 0) {

                            return null;
                        }
                    }
                }
            }

            Object[] vals = values;
            V val = (V) vals[index];

            int indexToRemove = index;
            int indexToShift = indexToRemove;
            int shiftDistance = 1;
            while (true) {
                indexToShift = (indexToShift - 1) & capacityMask;
                long keyToShift;
                if ((keyToShift = keys[indexToShift]) == 0) {
                    break;
                }
                if (((DataIO.longHash(keyToShift) - indexToShift) & capacityMask) >= shiftDistance) {
                    keys[indexToRemove] = keyToShift;
                    vals[indexToRemove] = vals[indexToShift];
                    indexToRemove = indexToShift;
                    shiftDistance = 1;
                } else {
                    shiftDistance++;
                    if (indexToShift == 1 + index) {
                        throw new java.util.ConcurrentModificationException();
                    }
                }
            }
            keys[indexToRemove] = 0;
            vals[indexToRemove] = null;


            size--;

            return val;
        }

        public boolean putIfAbsent(long key, V value) {
            if(get(key)==null){
                put(key,value);
                return true;
            }else{
                return false;
            }
        }
    }




    public static final Lock NOLOCK = new Lock(){

        @Override
        public void lock() {
        }

        @Override
        public void lockInterruptibly() throws InterruptedException {
        }

        @Override
        public boolean tryLock() {
            return true;
        }

        @Override
        public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {
            return true;
        }

        @Override
        public void unlock() {
        }

        @Override
        public Condition newCondition() {
            throw new UnsupportedOperationException();
        }
    };


    public static final class ReadWriteSingleLock implements ReadWriteLock{

        protected final Lock lock;

        public ReadWriteSingleLock(Lock lock) {
            this.lock = lock;
        }


        @Override
        public Lock readLock() {
            return lock;
        }

        @Override
        public Lock writeLock() {
            return lock;
        }
    }


    public static final class MemoryBarrierLessLock implements Lock{

        final static int WAIT_NANOS = 100;

        final protected AtomicLong lockedThread = new AtomicLong(Long.MAX_VALUE); 

        @Override
        public void lock() {
            long hash = Thread.currentThread().hashCode();
            while(!lockedThread.compareAndSet(Long.MAX_VALUE,hash)){
                LockSupport.parkNanos(WAIT_NANOS);
            }
        }

        @Override
        public void lockInterruptibly() throws InterruptedException {
            Thread currThread = Thread.currentThread();
            long hash = currThread.hashCode();
            while(!lockedThread.compareAndSet(Long.MAX_VALUE,hash)){
                LockSupport.parkNanos(WAIT_NANOS);
                if(currThread.isInterrupted())
                    throw new InterruptedException();
            }
        }

        @Override
        public boolean tryLock() {
            long hash = Thread.currentThread().hashCode();
            return lockedThread.compareAndSet(Long.MAX_VALUE, hash);
        }

        @Override
        public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {
            long hash = Thread.currentThread().hashCode();
            long time2 = unit.toNanos(time);
            while(!lockedThread.compareAndSet(Long.MAX_VALUE,hash) && time2>0){
                LockSupport.parkNanos(WAIT_NANOS);
                time2-=WAIT_NANOS;
            }
            return time2>0;
        }

        @Override
        public void unlock() {
            long hash = Thread.currentThread().hashCode();
            if(!lockedThread.compareAndSet(hash,Long.MAX_VALUE)){
                throw new IllegalMonitorStateException("Can not unlock, current thread does not hold this lock");
            }
        }

        @Override
        public Condition newCondition() {
            throw new UnsupportedOperationException();
        }
    }


    public static final class LongObjectObjectMap<V1,V2> {

        int size;

        int maxSize;

        long[] set;
        Object[] values;

        public LongObjectObjectMap(){
            this(32);
        }

        public LongObjectObjectMap(int initCapacity) {
            initCapacity = DataIO.nextPowTwo(initCapacity);
            set = new long[initCapacity];
            values =  new Object[initCapacity*2];
        }

        public int get(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return index;
            } else {

                return -1;
            }
        }


        public V1 get1(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return (V1) values[index*2];
            } else {

                return null;
            }
        }

        public V2 get2(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return (V2) values[index*2+1];
            } else {

                return null;
            }
        }


        int index(long key) {
            if (key != 0) {
                long[] keys = set;
                int capacityMask, index;
                long cur;
                if ((cur = keys[index = DataIO.longHash(key) & (capacityMask = keys.length - 1)]) == key) {

                    return index;
                } else {
                    if (cur == 0) {

                        return -1;
                    } else {
                        while (true) {
                            if ((cur = keys[(index = (index - 1) & capacityMask)]) == key) {

                                return index;
                            } else if (cur == 0) {

                                return -1;
                            }
                        }
                    }
                }
            } else {

                return -1;
            }
        }

        public int put(long key, V1 val1, V2 val2) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = insert(key, val1,val2);
            if (index < 0) {

                return -1;
            } else {

                Object[] vals = values;
                vals[index*2] = val1;
                vals[index*2+1] = val2;
                return index;
            }
        }

        int insert(long key, V1 val1, V2 val2) {
            long[] keys = set;
            int capacityMask, index;
            long cur;
            keyAbsent:
            if ((cur = keys[index = DataIO.longHash(key) & (capacityMask = keys.length - 1)]) != 0) {
                if (cur == key) {

                    return index;
                } else {
                    while (true) {
                        if ((cur = keys[(index = (index - 1) & capacityMask)]) == 0) {
                            break keyAbsent;
                        } else if (cur == key) {

                            return index;
                        }
                    }
                }
            }


            keys[index] = key;
            index*=2;
            values[index] = val1;
            values[index+1] = val2;
            postInsertHook();
            return -1;
        }

        void postInsertHook() {
            if (++size > maxSize) {

                int capacity = set.length;
                if (!LongLongMap.isMaxCapacity(capacity)) {
                    rehash(capacity << 1);
                }
            }
        }


        void rehash(int newCapacity) {
            long[] keys = set;
            Object[] vals = values;

            maxSize = LongLongMap.maxSize(newCapacity);
            set = new long[newCapacity];
            values = new Object[newCapacity*2];

            long[] newKeys = set;
            int capacityMask = newKeys.length - 1;
            Object[] newVals = values;
            for (int i = keys.length - 1; i >= 0; i--) {
                long key;
                if ((key = keys[i]) != 0) {
                    int index;
                    if (newKeys[index = DataIO.longHash(key) & capacityMask] != 0) {
                        while (true) {
                            if (newKeys[(index = (index - 1) & capacityMask)] == 0) {
                                break;
                            }
                        }
                    }
                    newKeys[index] = key;
                    newVals[index*2] = vals[i*2];
                    newVals[index*2+1] = vals[i*2+1];
                }
            }
        }


        public void clear() {
            size = 0;
            Arrays.fill(set,0);
            Arrays.fill(values,null);
        }

        public int  remove(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");
            long[] keys = set;
            int capacityMask = keys.length - 1;
            int index;
            long cur;
            keyPresent:
            if ((cur = keys[index = DataIO.longHash(key) & capacityMask]) != key) {
                if (cur == 0) {

                    return -1;
                } else {
                    while (true) {
                        if ((cur = keys[(index = (index - 1) & capacityMask)]) == key) {
                            break keyPresent;
                        } else if (cur == 0) {

                            return -1;
                        }
                    }
                }
            }

            Object[] vals = values;
            int val = index;

            int indexToRemove = index;
            int indexToShift = indexToRemove;
            int shiftDistance = 1;
            while (true) {
                indexToShift = (indexToShift - 1) & capacityMask;
                long keyToShift;
                if ((keyToShift = keys[indexToShift]) == 0) {
                    break;
                }
                if (((DataIO.longHash(keyToShift) - indexToShift) & capacityMask) >= shiftDistance) {
                    keys[indexToRemove] = keyToShift;
                    vals[indexToRemove] = vals[indexToShift];
                    indexToRemove = indexToShift;
                    shiftDistance = 1;
                } else {
                    shiftDistance++;
                    if (indexToShift == 1 + index) {
                        throw new java.util.ConcurrentModificationException();
                    }
                }
            }
            keys[indexToRemove] = 0;
            indexToRemove*=2;
            vals[indexToRemove] = null;
            vals[indexToRemove+1] = null;


            size--;

            return val;
        }

    }

    @Override
    public Engine getWrappedEngine() {
        return null;
    }


    @Override
    public boolean canSnapshot() {
        return snapshotEnable;
    }

}

<code block>
package org.mapdb;

import org.junit.Test;

import java.io.File;
import java.io.IOError;
import java.io.IOException;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

import static org.junit.Assert.*;
import static org.mapdb.DataIO.*;
import static org.mapdb.StoreDirect.*;

public class StoreDirectTest2 {


    @Test public void store_create(){
        StoreDirect st = newStore();
        assertArrayEquals(new long[]{0},st.indexPages);
        st.structuralLock.lock();
        assertEquals(st.headChecksum(st.vol), st.vol.getInt(StoreDirect.HEAD_CHECKSUM));
        assertEquals(parity16Set(st.PAGE_SIZE), st.vol.getLong(StoreDirect.STORE_SIZE));
        assertEquals(parity16Set(0), st.vol.getLong(StoreDirect.HEAD_END)); 
        assertEquals(parity1Set(st.RECID_LAST_RESERVED * 8), st.vol.getLong(StoreDirect.MAX_RECID_OFFSET));
    }

    @Test public void constants(){
        assertEquals(0,(StoreDirect.MAX_REC_SIZE+1)%16);
    }

    @Test public void preallocate1(){
        StoreDirect st = newStore();
        long recid = st.preallocate();
        assertEquals(Engine.RECID_FIRST,recid);
        assertEquals(st.composeIndexVal(0,0,true,true,true),st.vol.getLong(st.recidToOffset(recid)));
        assertEquals(parity1Set(8 * Engine.RECID_FIRST), st.vol.getLong(st.MAX_RECID_OFFSET));
    }


    @Test public void preallocate_M(){
        StoreDirect st = newStore();
        for(long i=0;i<1e6;i++) {
            long recid = st.preallocate();
            assertEquals(Engine.RECID_FIRST+i, recid);
            assertEquals(st.composeIndexVal(0, 0, true, true, true), st.vol.getLong(st.recidToOffset(recid)));
            assertEquals(parity1Set(8 * (Engine.RECID_FIRST + i)), st.vol.getLong(st.MAX_RECID_OFFSET));
        }
    }

    protected StoreDirect newStore() {
        StoreDirect st =  new StoreDirect(null);
        st.init();
        return st;
    }

    @Test public void round16Up__(){
        assertEquals(0, round16Up(0));
        assertEquals(16, round16Up(1));
        assertEquals(16, round16Up(15));
        assertEquals(16, round16Up(16));
        assertEquals(32, round16Up(17));
        assertEquals(32, round16Up(31));
        assertEquals(32, round16Up(32));
    }



    @Test public void reopen_after_insert(){
        final Volume vol = new Volume.ByteArrayVol(CC.VOLUME_PAGE_SHIFT);

        Volume.VolumeFactory fab = new Volume.VolumeFactory() {
            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {
                return vol;
            }
        };
        StoreDirect st = new StoreDirect(null, fab, null, CC.DEFAULT_LOCK_SCALE, 0, false, false,null, false,false,  0,false,0, null);
        st.init();

        Map<Long,String> recids = new HashMap();
        for(long i=0;i<1e6;i++){
            String val = "adskasldaksld "+i;
            long recid = st.put(val,Serializer.STRING);
            recids.put(recid,val);
        }


        st.commit();

        st = new StoreDirect(null, fab, null, CC.DEFAULT_LOCK_SCALE, 0, false, false,null, false, false, 0,false,0, null);
        st.init();

        for(Map.Entry<Long,String> e:recids.entrySet()){
            assertEquals(e.getValue(), st.get(e.getKey(),Serializer.STRING));
        }
    }

    @Test
    public void linked_allocate_two(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int recSize = 100000;
        long[] bufs = st.freeDataTake(recSize);

        assertEquals(2,bufs.length);
        assertEquals(MAX_REC_SIZE, bufs[0]>>>48);
        assertEquals(PAGE_SIZE, bufs[0]&MOFFSET);
        assertEquals(MLINKED,bufs[0]&MLINKED);

        assertEquals(recSize-MAX_REC_SIZE+8, bufs[1]>>>48);
        assertEquals(st.PAGE_SIZE + round16Up(MAX_REC_SIZE), bufs[1]&MOFFSET);
        assertEquals(0, bufs[1] & MLINKED);
    }

    @Test
    public void linked_allocate_three(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int recSize = 140000;
        long[] bufs = st.freeDataTake(recSize);

        assertEquals(3,bufs.length);
        assertEquals(MAX_REC_SIZE, bufs[0]>>>48);
        assertEquals(PAGE_SIZE, bufs[0]&MOFFSET);
        assertEquals(MLINKED,bufs[0]&MLINKED);

        assertEquals(MAX_REC_SIZE, bufs[1]>>>48);
        assertEquals(st.PAGE_SIZE + round16Up(MAX_REC_SIZE), bufs[1]&MOFFSET);
        assertEquals(MLINKED, bufs[1] & MLINKED);

        assertEquals(recSize-2*MAX_REC_SIZE+2*8, bufs[2]>>>48);
        assertEquals(st.PAGE_SIZE + 2*round16Up(MAX_REC_SIZE), bufs[2]&MOFFSET);
        assertEquals(0, bufs[2] & MLINKED);
    }

    DataOutputByteArray newBuf(int size){
        DataOutputByteArray ret = new DataOutputByteArray();
        for(int i=0;i<size;i++){
            try {
                ret.writeByte(i%255);
            } catch (IOException e) {
                throw new IOError(e);
            }
        }
        return ret;
    }

    @Test public void put_data_single(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int totalSize = round16Up(1000);
        long o = st.freeDataTakeSingle(totalSize)&MOFFSET;


        long recid = RECID_FIRST;
        long[] offsets = {19L << 48 | o};
        st.locks[st.lockPos(recid)].writeLock().lock();
        st.putData(recid,offsets,newBuf(19).buf,19);


        assertEquals(19L << 48 | o | MARCHIVE, st.indexValGet(recid));

        for(int i=0;i<totalSize;i++){
            int b = st.vol.getUnsignedByte(o+i);
            assertEquals(i<19?i:0,b);
        }
    }

    @Test public void put_data_double(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int totalSize = round16Up(1000);
        long o = st.freeDataTakeSingle(totalSize)&MOFFSET;


        long recid = RECID_FIRST;
        long[] offsets = {
                19L << 48 | o | MLINKED,
                100L <<48 | o+round16Up(19)
        };
        st.locks[st.lockPos(recid)].writeLock().lock();
        int bufSize = 19+100-8;
        st.putData(recid,offsets,newBuf(bufSize).buf,bufSize);


        assertEquals(19L << 48 | o | MLINKED | MARCHIVE, st.indexValGet(recid));

        assertEquals((100L)<<48 | o+round16Up(19) , parity3Get(st.vol.getLong(o)));


        for(int i=0;i<19-8;i++){
            int b = st.vol.getUnsignedByte(o+8+i);
            assertEquals(i,b);
        }
        for(int i=19-8;i<19+100-8;i++){
            int b = st.vol.getUnsignedByte(o+round16Up(19)+i-19+8);
            assertEquals(i,b);
        }

    }

    @Test public void put_data_triple(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int totalSize = round16Up(1000);
        long o = st.freeDataTakeSingle(totalSize)&MOFFSET;


        long recid = RECID_FIRST;
        long[] offsets = {
                101L << 48 | o | MLINKED,
                102L <<48 | o+round16Up(101) | MLINKED,
                103L <<48 | o+round16Up(101)+round16Up(102)

        };
        st.locks[st.lockPos(recid)].writeLock().lock();
        int bufSize = 101+102+103-2*8;
        st.putData(recid,offsets,newBuf(bufSize).buf,bufSize);


        assertEquals(101L << 48 | o | MLINKED | MARCHIVE, st.indexValGet(recid));
        assertEquals(102L<<48 | o+round16Up(101) | MLINKED , parity3Get(st.vol.getLong(o)));

        assertEquals(103L<<48 | o+round16Up(101)+round16Up(102) , parity3Get(st.vol.getLong(o+round16Up(101))));


        for(int i=0;i<101-8;i++){
            int b = st.vol.getUnsignedByte(o+8+i);
            assertEquals(i,b);
        }
        for(int i=0;i<102-8;i++){
            int b = st.vol.getUnsignedByte(o+round16Up(101)+8+i);
            assertEquals(i+101-8,b);
        }

        for(int i=0;i<103-16;i++){
            int b = st.vol.getUnsignedByte(o+round16Up(101)+round16Up(102)+i);
            assertEquals((i+101+102-2*8)%255,b);
        }

    }

    @Test public void zero_index_page_checksum() throws IOException {
        File f = File.createTempFile("mapdb", "mapdb");
        StoreDirect st = (StoreDirect) DBMaker.fileDB(f)
                .transactionDisable()
                .checksumEnable()
                .mmapFileEnableIfSupported()
                .makeEngine();


        verifyIndexPageChecksum(st);

        st.commit();
        st.close();
        st = (StoreDirect) DBMaker.fileDB(f)
                .transactionDisable()
                .checksumEnable()
                .mmapFileEnableIfSupported()
                .makeEngine();

        for(int i=0;i<2e6;i++){
            st.put(i,Serializer.INTEGER);
        }

        verifyIndexPageChecksum(st);

        st.commit();
        st.close();

        st = (StoreDirect) DBMaker.fileDB(f)
                .transactionDisable()
                .checksumEnable()
                .mmapFileEnableIfSupported()
                .makeEngine();

        verifyIndexPageChecksum(st);

        st.close();
    }

    protected void verifyIndexPageChecksum(StoreDirect st) {
        assertTrue(st.indexPageCRC);

        for(long offset=HEAD_END+8;offset+10<=PAGE_SIZE;offset+=10){
            long indexVal = st.vol.getLong(offset);
            int check = st.vol.getUnsignedShort(offset+8);
            if(indexVal==0){
                assertEquals(0,check);
                continue; 
            }
            assertEquals(check, DataIO.longHash(indexVal)&0xFFFF);
        }


        for(long page:st.indexPages){
            if(page==0)
                continue;

            for(long offset=page+8;offset+10<=page+PAGE_SIZE;offset+=10){
                long indexVal = st.vol.getLong(offset);
                int check = st.vol.getUnsignedShort(offset+8);
                if(indexVal==0){
                    assertEquals(0,check);
                    continue; 
                }
                assertEquals(check, DataIO.longHash(indexVal)&0xFFFF);
            }
        }
    }

    @Test public void recidToOffset(){
        StoreDirect st = (StoreDirect) DBMaker.memoryDB()
                .transactionDisable()
                .makeEngine();


        st.indexPages = new long[]{0, PAGE_SIZE*10, PAGE_SIZE*20, PAGE_SIZE*30, PAGE_SIZE*40};

        Set<Long> m = new HashSet<Long>();
        for(long offset=HEAD_END+8;offset<PAGE_SIZE;offset+=8){
            m.add(offset);
        }

        for(long page=PAGE_SIZE*10;page<=PAGE_SIZE*40; page+=PAGE_SIZE*10){
            for(long offset=page+8;offset<page+PAGE_SIZE;offset+=8){
                m.add(offset);
            }
        }

        long maxRecid = PAGE_SIZE-8-HEAD_END + 4*PAGE_SIZE-4*8;

        assertEquals(0,maxRecid%8);
        maxRecid/=8;


        for(long recid=1;recid<=maxRecid;recid++){
            long offset = st.recidToOffset(recid);
            assertTrue(""+recid + " - "+offset+" - "+(offset%PAGE_SIZE),
                    m.remove(offset));
        }
        assertTrue(m.isEmpty());
    }

    @Test public void recidToOffset_with_checksum(){
        StoreDirect st = (StoreDirect) DBMaker.memoryDB()
                .transactionDisable()
                .checksumEnable()
                .makeEngine();


        st.indexPages = new long[]{0, PAGE_SIZE*10, PAGE_SIZE*20, PAGE_SIZE*30, PAGE_SIZE*40};

        Set<Long> m = new HashSet<Long>();
        for(long offset=HEAD_END+8;offset<=PAGE_SIZE-10;offset+=10){
            m.add(offset);
        }

        for(long page=PAGE_SIZE*10;page<=PAGE_SIZE*40; page+=PAGE_SIZE*10){
            for(long offset=page+8;offset<=page+PAGE_SIZE-10;offset+=10){
                m.add(offset);
            }
        }

        long maxRecid = (PAGE_SIZE-8-HEAD_END)/10 + 4*((PAGE_SIZE-8)/10);



        for(long recid=1;recid<=maxRecid;recid++){
            long offset = st.recidToOffset(recid);
            assertTrue("" + recid + " - " + offset + " - " + (offset % PAGE_SIZE)+ " - " + (offset - PAGE_SIZE),
                    m.remove(offset));
        }
        assertTrue(m.isEmpty());
    }

}
<code block>
package org.mapdb;

import org.junit.Test;

import java.io.IOException;
import java.nio.ByteBuffer;

import static org.junit.Assert.*;
import static org.mapdb.DataIO.*;

public class DataIOTest {

    @Test public void parity1() {
        assertEquals(Long.parseLong("1", 2), parity1Set(0));
        assertEquals(Long.parseLong("10", 2), parity1Set(2));
        assertEquals(Long.parseLong("111", 2), parity1Set(Long.parseLong("110", 2)));
        assertEquals(Long.parseLong("1110", 2), parity1Set(Long.parseLong("1110", 2)));
        assertEquals(Long.parseLong("1011", 2), parity1Set(Long.parseLong("1010", 2)));
        assertEquals(Long.parseLong("11111", 2), parity1Set(Long.parseLong("11110", 2)));

        assertEquals(0, parity1Get(Long.parseLong("1", 2)));
        try {
            parity1Get(Long.parseLong("0", 2));
            fail();
        }catch(DBException.PointerChecksumBroken e){

        }
        try {
            parity1Get(Long.parseLong("110", 2));
            fail();
        }catch(DBException.PointerChecksumBroken e){

        }
    }

    @Test
    public void testPackLongBidi() throws Exception {
        DataOutputByteArray b = new DataOutputByteArray();

        long max = (long) 1e14;
        for(long i=0;i<max;i=i+1 +i/100000){
            b.pos=0;
            long size = packLongBidi(b,i);
            assertTrue(i>100000 || size<6);
            assertEquals(b.pos,size);
            assertEquals(i | (size<<56), unpackLongBidi(b.buf,0));
            assertEquals(i | (size<<56), unpackLongBidiReverse(b.buf, (int) size));
        }
    }

    @Test public void parityBasic(){
        for(long i=0;i<Integer.MAX_VALUE;i+= 1 + i/1000000L){
            if(i%2==0)
                assertEquals(i, parity1Get(parity1Set(i)));
            if(i%8==0)
                assertEquals(i, parity3Get(parity3Set(i)));
            if(i%16==0)
                assertEquals(i, parity4Get(parity4Set(i)));
            if((i&0xFFFF)==0)
                assertEquals(i, parity16Get(parity16Set(i)));
        }
    }

    @Test public void testSixLong(){
        byte[] b = new byte[8];
        for(long i=0;i>>>48==0;i=i+1+i/10000){
            DataIO.putSixLong(b,2,i);
            assertEquals(i, DataIO.getSixLong(b,2));
        }
    }

    @Test public void testNextPowTwo(){
        assertEquals(1, DataIO.nextPowTwo(1));
        assertEquals(2, DataIO.nextPowTwo(2));
        assertEquals(4, DataIO.nextPowTwo(3));
        assertEquals(4, DataIO.nextPowTwo(4));

        assertEquals(64, DataIO.nextPowTwo(33));
        assertEquals(64, DataIO.nextPowTwo(61));

        assertEquals(1024, DataIO.nextPowTwo(777));
        assertEquals(1024, DataIO.nextPowTwo(1024));

        assertEquals(1073741824, DataIO.nextPowTwo(1073741824-100));
        assertEquals(1073741824, DataIO.nextPowTwo((int) (1073741824*0.7)));
        assertEquals(1073741824, DataIO.nextPowTwo(1073741824));
    }

    @Test public void testNextPowTwo2(){
        for(int i=1;i<1073750016;i+= 1 + i/100000){
            int pow = nextPowTwo(i);
            assertTrue(pow>=i);
            assertTrue(Integer.bitCount(pow)==1);

        }
    }

    @Test public void packLongCompat() throws IOException {
        DataOutputByteArray b = new DataOutputByteArray();
        b.packLong(2111L);
        b.packLong(100);
        b.packLong(1111L);

        DataInputByteArray b2 = new DataInputByteArray(b.buf);
        assertEquals(2111L, b2.unpackLong());
        assertEquals(100L, b2.unpackLong());
        assertEquals(1111L, b2.unpackLong());

        DataInputByteBuffer b3 = new DataInputByteBuffer(ByteBuffer.wrap(b.buf),0);
        assertEquals(2111L, b3.unpackLong());
        assertEquals(100L, b3.unpackLong());
        assertEquals(1111L, b3.unpackLong());
    }

    @Test public void packIntCompat() throws IOException {
        DataOutputByteArray b = new DataOutputByteArray();
        b.packInt(2111);
        b.packInt(100);
        b.packInt(1111);

        DataInputByteArray b2 = new DataInputByteArray(b.buf);
        assertEquals(2111, b2.unpackInt());
        assertEquals(100, b2.unpackInt());
        assertEquals(1111, b2.unpackInt());

        DataInputByteBuffer b3 = new DataInputByteBuffer(ByteBuffer.wrap(b.buf),0);
        assertEquals(2111, b3.unpackInt());
        assertEquals(100, b3.unpackInt());
        assertEquals(1111, b3.unpackInt());
    }


    @Test public void testHexaConversion(){
        byte[] b = new byte[]{11,112,11,0,39,90};
        assertTrue(Serializer.BYTE_ARRAY.equals(b, DataIO.fromHexa(DataIO.toHexa(b))));
    }
}
<code block>
package org.mapdb;

import org.junit.Test;

import java.io.File;
import java.io.IOException;
import java.util.Random;
import java.util.concurrent.Callable;
import java.util.concurrent.atomic.AtomicReference;

import static org.junit.Assert.*;

public class VolumeTest {

    public static final Fun.Function1<Volume,String>[] VOL_FABS = new Fun.Function1[] {

                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.ByteArrayVol(CC.VOLUME_PAGE_SHIFT);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.SingleByteArrayVol((int) 4e7);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.MemoryVol(true, CC.VOLUME_PAGE_SHIFT);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.MemoryVol(false, CC.VOLUME_PAGE_SHIFT);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return Volume.UNSAFE_VOL_FACTORY.makeVolume(null, false, CC.VOLUME_PAGE_SHIFT, 0, false);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.FileChannelVol(new File(file), false, CC.VOLUME_PAGE_SHIFT);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.RandomAccessFileVol(new File(file), false);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.MappedFileVol(new File(file), false, CC.VOLUME_PAGE_SHIFT);
                        }
                    }
    };

    @Test
    public void all() throws Throwable {
        System.out.println("Run volume tests. Free space: "+File.createTempFile("mapdb","mapdb").getFreeSpace());


        for (Fun.Function1<Volume,String> fab1 : VOL_FABS) {

            Volume v = fab1.run(UtilsTest.tempDbFile().getPath());
            System.out.println(" "+v);
            testPackLongBidi(v);

            putGetOverlap(fab1.run(UtilsTest.tempDbFile().getPath()), 100, 1000);
            putGetOverlap(fab1.run(UtilsTest.tempDbFile().getPath()), StoreDirect.PAGE_SIZE - 500, 1000);
            putGetOverlap(fab1.run(UtilsTest.tempDbFile().getPath()), (long) 2e7 + 2000, (int) 1e7);
            putGetOverlapUnalligned(fab1.run(UtilsTest.tempDbFile().getPath()));

            for (Fun.Function1<Volume,String> fab2 : VOL_FABS) try{
                long_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                long_six_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                long_pack_bidi(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                int_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                byte_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                unsignedShort_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                unsignedByte_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
            }catch(Throwable e){
                System.err.println("test failed: \n"+
                        fab1.run(UtilsTest.tempDbFile().getPath()).getClass().getName()+"\n"+
                        fab2.run(UtilsTest.tempDbFile().getPath()).getClass().getName());
                throw e;
            }
        }
    }

    void unsignedShort_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (int i =Character.MIN_VALUE;i<=Character.MAX_VALUE; i++) {
            v1.putUnsignedShort(7,i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getUnsignedShort(7));
        }

        v1.close();
        v2.close();
    }


    void unsignedByte_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (int i =0;i<=255; i++) {
            v1.putUnsignedByte(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getUnsignedByte(7));
        }

        v1.close();
        v2.close();
    }


    void testPackLongBidi(Volume v) throws Exception {
        v.ensureAvailable(10000);

        long max = (long) 1e14;
        for (long i = 0; i < max; i = i + 1 + i / 1000) {
            v.clear(0, 20);
            long size = v.putLongPackBidi(10, i);
            assertTrue(i > 100000 || size < 6);

            assertEquals(i | (size << 56), v.getLongPackBidi(10));
            assertEquals(i | (size << 56), v.getLongPackBidiReverse(10 + size));
        }
        v.close();
    }

    void long_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (long i : new long[]{1L, 2L, Integer.MAX_VALUE, Integer.MIN_VALUE, Long.MAX_VALUE, Long.MIN_VALUE,
                -1, 0x982e923e8989229L, -2338998239922323233L,
                0xFFF8FFL, -0xFFF8FFL, 0xFFL, -0xFFL,
                0xFFFFFFFFFF0000L, -0xFFFFFFFFFF0000L}) {
            v1.putLong(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getLong(7));
        }

        v1.close();
        v2.close();
    }


    void long_pack_bidi(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[9];

        for (long i = 0; i > 0; i = i + 1 + i / 1000) {
            v1.putLongPackBidi(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getLongPackBidi(7));
        }

        v1.close();
        v2.close();
    }


    void long_six_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[9];

        for (long i = 0; i >> 48 == 0; i = i + 1 + i / 1000) {
            v1.putSixLong(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getSixLong(7));
        }

        v1.close();
        v2.close();
    }

    void int_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (int i : new int[]{1, 2, Integer.MAX_VALUE, Integer.MIN_VALUE,
                -1, 0x982e9229, -233899233,
                0xFFF8FF, -0xFFF8FF, 0xFF, -0xFF,
                0xFFFF000, -0xFFFFF00}) {
            v1.putInt(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getInt(7));
        }

        v1.close();
        v2.close();
    }


    void byte_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (byte i = Byte.MIN_VALUE; i < Byte.MAX_VALUE - 1; i++) {
            v1.putByte(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getByte(7));
        }


        for (int i = 0; i < 256; i++) {
            v1.putUnsignedByte(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getUnsignedByte(7));
        }


        v1.close();
        v2.close();
    }


    void putGetOverlap(Volume vol, long offset, int size) throws IOException {
        byte[] b = UtilsTest.randomByteArray(size);

        vol.ensureAvailable(offset+size);
        vol.putDataOverlap(offset, b, 0, b.length);

        byte[] b2 = new byte[size];
        vol.getDataInputOverlap(offset, size).readFully(b2, 0, size);

        assertTrue(Serializer.BYTE_ARRAY.equals(b, b2));
        vol.close();
    }



    void putGetOverlapUnalligned(Volume vol) throws IOException {
        int size = (int) 1e7;
        long offset = (long) (2e6 + 2000);
        vol.ensureAvailable(offset+size);

        byte[] b = UtilsTest.randomByteArray(size);

        byte[] b2 = new byte[size + 2000];

        System.arraycopy(b, 0, b2, 1000, size);

        vol.putDataOverlap(offset, b2, 1000, size);

        byte[] b3 = new byte[size + 200];
        vol.getDataInputOverlap(offset, size).readFully(b3, 100, size);


        for (int i = 0; i < size; i++) {
            assertEquals(b2[i + 1000], b3[i + 100]);
        }
        vol.close();
    }



}

<code block>
package org.mapdb;


import org.junit.Ignore;
import org.junit.Test;

import java.io.File;
import java.io.IOError;
import java.io.IOException;
import java.util.*;
import java.util.concurrent.locks.Lock;

import static org.junit.Assert.*;
import static org.mapdb.StoreDirect.*;

@SuppressWarnings({"rawtypes","unchecked"})
public class StoreDirectTest <E extends StoreDirect> extends EngineTest<E>{

    @Override boolean canRollback(){return false;}

    File f = UtilsTest.tempDbFile();




    @Override protected E openEngine() {
        StoreDirect e =new StoreDirect(f.getPath());
        e.init();
        return (E)e;
    }




































































































































































































    @Test public void test_index_record_delete_and_reuse_large_COMPACT(){
        e = openEngine();
        final long MAX = 10;

        List<Long> recids= new ArrayList<Long>();
        for(int i = 0;i<MAX;i++){
            recids.add(e.put(0L, Serializer.LONG));
        }

        for(long recid:recids){
            e.delete(recid,Serializer.LONG);
        }


        e.commit();
        e.compact();


        List<Long> recids2= new ArrayList<Long>();
        for(int i = 0;i<MAX;i++){
            recids2.add(e.put(0L, Serializer.LONG));
        }


        Collections.reverse(recids);
        assertEquals(recids, recids2);
    }














    @Test public void test_phys_record_reused_COMPACT(){
        e = openEngine();
        final long recid = e.put(1L, Serializer.LONG);
        assertEquals((Long)1L, e.get(recid, Serializer.LONG));

        e.delete(recid, Serializer.LONG);
        e.commit();
        e.compact();
        final long recid2 = e.put(1L, Serializer.LONG);
        assertEquals((Long)1L, e.get(recid2, Serializer.LONG));
        e.commit();
        assertEquals((Long)1L, e.get(recid2, Serializer.LONG));
        assertEquals(recid, recid2);

        long indexVal = e.indexValGet(recid);
        assertEquals(8L, indexVal>>>48); 
        assertEquals(e.PAGE_SIZE,
                indexVal&MOFFSET); 
        assertEquals(0, indexVal & StoreDirect.MLINKED);
        assertEquals(0, indexVal & StoreDirect.MUNUSED);
        assertNotEquals(0, indexVal & StoreDirect.MARCHIVE);
        e.close();
    }
















    @Test public void test_long_stack_puts_record_offset_into_index() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 1,false);
        e.commit();
        assertEquals(8 + 2,
                e.headVol.getLong(FREE_RECID_STACK)>>>48);

    }

    @Test public void test_long_stack_put_take() throws IOException {
        e = openEngine();
        e.structuralLock.lock();

        final long max = 150;
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
        }

        for(long i = max-1;i>0;i--){
            assertEquals(i, e.longStackTake(FREE_RECID_STACK,false));
        }

        assertEquals(0, getLongStack(FREE_RECID_STACK).size());

    }

    protected List<Long> getLongStack(long masterLinkOffset) {
        List<Long> ret = new ArrayList<Long>();
        for(long v = e.longStackTake(masterLinkOffset,false); v!=0; v=e.longStackTake(masterLinkOffset,false)){
            ret.add(v);
        }
        return ret;
    }

    @Test public void test_long_stack_put_take_simple() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        assertEquals(111L, e.longStackTake(FREE_RECID_STACK,false));
    }


    @Test public void test_basic_long_stack() throws IOException {
        e = openEngine();

        e.structuralLock.lock();
        final long max = 150;
        ArrayList<Long> list = new ArrayList<Long>();
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
            list.add(i);
        }

        Collections.reverse(list);
        e.commit();

        assertEquals(list, getLongStack(FREE_RECID_STACK));
    }

    @Test public void test_large_long_stack() throws IOException {
        e = openEngine();

        e.structuralLock.lock();
        final long max = 15000;
        ArrayList<Long> list = new ArrayList<Long>();
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
            list.add(i);
        }

        Collections.reverse(list);
        e.commit();

        assertEquals(list, getLongStack(FREE_RECID_STACK));
    }

    @Test public void test_basic_long_stack_no_commit() throws IOException {
        e = openEngine();

        e.structuralLock.lock();
        final long max = 150;
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
        }

        for(long i =max-1;i>=1;i--){
            assertEquals(i, e.longStackTake(FREE_RECID_STACK,false));
        }
    }

    @Test public void test_large_long_stack_no_commit() throws IOException {
        e = openEngine();

        e.structuralLock.lock();
        final long max = 15000;
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
        }


        for(long i =max-1;i>=1;i--){
            assertEquals(i, e.longStackTake(FREE_RECID_STACK,false));
        }
    }



    @Test public void long_stack_page_created_after_put() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        e.commit();

        if(e instanceof StoreWAL){

            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
        }

        long pageId = e.vol.getLong(FREE_RECID_STACK);
        assertEquals(8+2, pageId>>>48);
        pageId = pageId & StoreDirect.MOFFSET;
        assertEquals(PAGE_SIZE, pageId);
        assertEquals(CHUNKSIZE, DataIO.parity4Get(e.vol.getLong(pageId))>>>48);
        assertEquals(0, DataIO.parity4Get(e.vol.getLong(pageId))&MOFFSET);
        assertEquals(DataIO.parity1Set(111<<1), e.vol.getLongPackBidi(pageId + 8)&DataIO.PACK_LONG_BIDI_MASK);
    }

    @Test public void long_stack_put_five() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        e.longStackPut(FREE_RECID_STACK, 112,false);
        e.longStackPut(FREE_RECID_STACK, 113,false);
        e.longStackPut(FREE_RECID_STACK, 114,false);
        e.longStackPut(FREE_RECID_STACK, 115,false);

        e.commit();
        if(e instanceof  StoreWAL){
            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
        }
        long pageId = e.vol.getLong(FREE_RECID_STACK);
        long currPageSize = pageId>>>48;
        pageId = pageId & StoreDirect.MOFFSET;
        assertEquals(PAGE_SIZE, pageId);
        assertEquals(CHUNKSIZE, e.vol.getLong(pageId)>>>48);
        assertEquals(0, e.vol.getLong(pageId)&MOFFSET); 
        long offset = pageId + 8;
        for(int i=111;i<=115;i++){
            long val = e.vol.getLongPackBidi(offset);
            assertEquals(i, DataIO.parity1Get(val & DataIO.PACK_LONG_BIDI_MASK)>>>1);
            offset += val >>> 56;
        }
        assertEquals(currPageSize, offset-pageId);
    }

    @Test public void long_stack_page_deleted_after_take() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        e.commit();
        if(e instanceof  StoreWAL){
            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
            ((StoreWAL)e).walStartNextFile();
        }

        assertEquals(111L, e.longStackTake(FREE_RECID_STACK,false));
        e.commit();
        if(e instanceof  StoreWAL){
            ((StoreWAL)e).replayWAL();
            clearEverything();
            ((StoreWAL)e).walStartNextFile();
        }

        assertEquals(0L, DataIO.parity1Get(e.headVol.getLong(FREE_RECID_STACK)));
    }

    @Test public void long_stack_page_deleted_after_take2() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        e.commit();

        assertEquals(111L, e.longStackTake(FREE_RECID_STACK,false));
        e.commit();
        if(e instanceof  StoreWAL){
            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
        }

        assertEquals(0L, DataIO.parity1Get(e.headVol.getLong(FREE_RECID_STACK)));
    }



    @Test public void long_stack_page_overflow() throws IOException {
        e = openEngine();
        e.structuralLock.lock();


        int actualChunkSize = 8;
        for(int i=0;;i++){
            long val = 1000L+i;
            e.longStackPut(FREE_RECID_STACK, val ,false);
            actualChunkSize += DataIO.packLongBidi(new byte[8],0,val<<1);
            if(e.headVol.getLong(FREE_RECID_STACK)>>48 >CHUNKSIZE-10)
                break;
        }
        e.commit();
        if(e instanceof  StoreWAL){

            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
            ((StoreWAL)e).walStartNextFile();
        }


        long pageId = e.headVol.getLong(FREE_RECID_STACK);
        assertEquals(actualChunkSize, pageId>>>48);
        pageId = pageId & StoreDirect.MOFFSET;
        assertEquals(PAGE_SIZE, pageId);
        assertEquals(StoreDirect.CHUNKSIZE, e.vol.getLong(pageId)>>>48);
        for(long i=1000,pos=8;;i++){
            long val = e.vol.getLongPackBidi(pageId+pos);
            assertEquals(i, DataIO.parity1Get(val&DataIO.PACK_LONG_BIDI_MASK)>>>1);
            pos+=val>>>56;
            if(pos==actualChunkSize){
                break;
            }
        }


        e.longStackPut(FREE_RECID_STACK, 11L,false);
        e.commit();
        if(e instanceof  StoreWAL){
            ((StoreWAL)e).replayWAL();
            clearEverything();
            ((StoreWAL)e).walStartNextFile();
        }


        pageId = e.headVol.getLong(FREE_RECID_STACK);
        assertEquals(8+2, pageId>>>48);
        pageId = pageId & StoreDirect.MOFFSET;
        assertEquals(PAGE_SIZE + StoreDirect.CHUNKSIZE, pageId);
        assertEquals(PAGE_SIZE, DataIO.parity4Get(e.vol.getLong(pageId)) & StoreDirect.MOFFSET); 
        assertEquals(CHUNKSIZE, e.vol.getLong(pageId)>>>48); 

        assertEquals(11L, DataIO.parity1Get(e.vol.getLongPackBidi(pageId+8)&DataIO.PACK_LONG_BIDI_MASK)>>>1);


        for(long offset = pageId+8+2;offset<pageId+CHUNKSIZE;offset++){
            assertEquals(0,e.vol.getByte(offset));
        }
    }


    @Test public void test_constants(){
        assertTrue(StoreDirect.CHUNKSIZE%16==0);
        
    }


    @Test public void delete_files_after_close(){
        File f = UtilsTest.tempDbFile();
        File phys = new File(f.getPath());

        DB db = DBMaker.fileDB(f).transactionDisable().deleteFilesAfterClose().make();

        db.hashMap("test").put("aa","bb");
        db.commit();
        assertTrue(f.exists());
        assertTrue(phys.exists());
        db.close();
        assertFalse(f.exists());
        assertFalse(new File(f+".0.wal").exists());
        assertFalse(phys.exists());
    }

    @Test @Ignore 
    public void freeSpaceWorks(){
        long oldFree = e.getFreeSize();
        long recid = e.put(new byte[10000],Serializer.BYTE_ARRAY_NOSIZE);
        e.commit();
        assertEquals(oldFree, e.getFreeSize());
        e.delete(recid,Serializer.BYTE_ARRAY_NOSIZE);
        assertEquals(oldFree+10000,e.getFreeSize());
        e.commit();
        assertEquals(oldFree+10000,e.getFreeSize());
    }


    @Test public void prealloc(){
        e = openEngine();
        long recid = e.preallocate();
        assertNull(e.get(recid,UtilsTest.FAIL));
        e.commit();
        assertNull(e.get(recid,UtilsTest.FAIL));
    }

    @Ignore 
    @Test public void header_index_inc() throws IOException {
        e.put(new byte[10000],Serializer.BYTE_ARRAY_NOSIZE);
        e.commit();
        e.close();


        Volume v = Volume.FileChannelVol.FACTORY.makeVolume(f.getPath(), true);
        v.putUnsignedShort(4,StoreDirect.STORE_VERSION+1);
        v.sync();
        v.close();

        try{
            e = openEngine();
            fail();
        }catch(IOError e){
            Throwable e2 = e;
            while (e2 instanceof IOError){
                e2 = e2.getCause();
            }
            assertTrue(e2.getMessage().contains("version"));
        }
    }

    @Test @Ignore 
    public void header_phys_inc() throws IOException {
        e.put(new byte[10000],Serializer.BYTE_ARRAY_NOSIZE);
        e.commit();
        e.close();


        File phys = new File(f.getPath());
        Volume v = Volume.FileChannelVol.FACTORY.makeVolume(phys.getPath(), true);
        v.putUnsignedShort(4,StoreDirect.STORE_VERSION+1);
        v.sync();
        v.close();

        try{
            e = openEngine();
            fail();
        }catch(IOError e){
            Throwable e2 = e;
            while (e2 instanceof IOError){
                e2 = e2.getCause();
            }
            assertTrue(e2.getMessage().contains("version"));
        }
    }


    protected void clearEverything(){
        StoreWAL wal = (StoreWAL)e;

        for (int segment = 0; segment < wal.locks.length; segment++) {
            Lock lock = wal.locks[segment].writeLock();
            lock.lock();
            try {
                wal.writeCache[segment].clear();
            } finally {
                lock.unlock();
            }
        }

        wal.structuralLock.lock();
        try {
            wal.dirtyStackPages.clear();


            byte[] b = new byte[(int) HEAD_END];

            wal.headVolBackup.getData(0,b,0,b.length);
            wal.headVol.putData(0,b,0,b.length);

            wal.indexPages = wal.indexPagesBackup.clone();
            wal.pageLongStack.clear();
        } finally {
            wal.structuralLock.unlock();
        }

    }


    @Test public void compact_keeps_volume_type(){
        for(final Fun.Function1<Volume,String> fab : VolumeTest.VOL_FABS){
            Volume.VolumeFactory fac = new Volume.VolumeFactory() {
                @Override
                public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {
                    return fab.run(file);
                }
            };

            File f = UtilsTest.tempDbFile();
            e = (E) new StoreDirect(f.getPath(), fac,
                    null,
                    CC.DEFAULT_LOCK_SCALE,
                    0,
                    false,false,null,
                    false,false,0,
                    false,0,
                    null);
            e.init();



            Map<Long, String> data = new LinkedHashMap();
            for(int i=0;i<1000;i++){
                String ss = UtilsTest.randomString(1000);
                long recid = e.put(ss,Serializer.STRING);
            }


            Volume vol = e.vol;
            e.commit();
            e.compact();

            assertEquals(vol.getClass(), e.vol.getClass());
            if(e.vol.getFile()!=null)
                assertEquals(f, e.vol.getFile());

            for(Long recid:data.keySet()){
                assertEquals(data.get(recid), e.get(recid, Serializer.STRING));
            }
            e.close();
            f.delete();
        }
    }

}

<code block>


package org.mapdb;

import java.io.*;
import java.lang.reflect.Method;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.MappedByteBuffer;
import java.nio.channels.ClosedByInterruptException;
import java.nio.channels.ClosedChannelException;
import java.nio.channels.FileChannel;
import java.util.Arrays;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
import java.util.logging.Level;
import java.util.logging.Logger;


public abstract class Volume implements Closeable{

    public static abstract class VolumeFactory{
        public abstract Volume makeVolume(String file, boolean readOnly,
                                          int sliceShift, long initSize, boolean fixedSize);

        public Volume makeVolume(String file, boolean readOnly){
            return makeVolume(file,readOnly,CC.VOLUME_PAGE_SHIFT, 0, false);
        }
    }

    private static final byte[] CLEAR = new byte[1024];

    protected static final Logger LOG = Logger.getLogger(Volume.class.getName());


    public static final VolumeFactory UNSAFE_VOL_FACTORY = new VolumeFactory() {

        @Override
        public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {
            String packageName = Volume.class.getPackage().getName();
            Class clazz;
            try {
                clazz = Class.forName(packageName+".UnsafeStuff$UnsafeVolume");
            } catch (ClassNotFoundException e) {
                clazz = null;
            }

            if(clazz!=null){
                try {
                    return (Volume) clazz.getConstructor(long.class, int.class).newInstance(0L, sliceShift);
                } catch (Exception e) {
                    LOG.log(Level.WARNING, "Could not invoke UnsafeVolume constructor. " +
                            "Falling back to DirectByteBuffer",e);

                }
            }

            return MemoryVol.FACTORY.makeVolume(file, readOnly, sliceShift, initSize, fixedSize);
        }
    };

    protected volatile boolean closed;

    public boolean isClosed(){
        return closed;
    }




    @Override protected void finalize(){
        if(CC.ASSERT){
            if(!closed
                    && !(this instanceof ByteArrayVol)
                    && !(this instanceof SingleByteArrayVol)){
                LOG.log(Level.WARNING, "Open Volume was GCed, possible file handle leak."

                );
            }
        }
    }


    abstract public void ensureAvailable(final long offset);


    public abstract void truncate(long size);


    abstract public void putLong(final long offset, final long value);
    abstract public void putInt(long offset, int value);
    abstract public void putByte(final long offset, final byte value);

    abstract public void putData(final long offset, final byte[] src, int srcPos, int srcSize);
    abstract public void putData(final long offset, final ByteBuffer buf);

    public void putDataOverlap(final long offset, final byte[] src, int srcPos, int srcSize){
        putData(offset,src,srcPos,srcSize);
    }


    abstract public long getLong(final long offset);
    abstract public int getInt(long offset);
    abstract public byte getByte(final long offset);



    abstract public DataInput getDataInput(final long offset, final int size);
    public DataInput getDataInputOverlap(final long offset, final int size){
        return getDataInput(offset,size);
    }

    abstract public void getData(long offset, byte[] bytes, int bytesPos, int size);

    abstract public void close();

    abstract public void sync();


    abstract public int sliceSize();

    public abstract boolean isEmpty();

    public void deleteFile(){
        File f = getFile();
        if(f!=null && !f.delete()){
            LOG.warning("Could not delete file: "+f);
        }
    }

    public abstract boolean isSliced();

    public abstract long length();

    public void putUnsignedShort(final long offset, final int value){
        putByte(offset, (byte) (value>>8));
        putByte(offset+1, (byte) (value));
    }

    public int getUnsignedShort(long offset) {
        return (( (getByte(offset) & 0xff) << 8) |
                ( (getByte(offset+1) & 0xff)));
    }

    public int getUnsignedByte(long offset) {
        return getByte(offset) & 0xff;
    }

    public void putUnsignedByte(long offset, int b) {
        putByte(offset, (byte) (b & 0xff));
    }


    public int putLongPackBidi(long offset, long value) {
        putUnsignedByte(offset++, (((int) value & 0x7F)) | 0x80);
        value >>>= 7;
        int counter = 2;


        while ((value & ~0x7FL) != 0) {
            putUnsignedByte(offset++, (((int) value & 0x7F)));
            value >>>= 7;

            counter++;
        }

        putUnsignedByte(offset, (byte) value | 0x80);
        return counter;
    }

    public long getLongPackBidi(long offset){

        long b = getUnsignedByte(offset++); 
        if(CC.ASSERT && (b&0x80)==0)
            throw new AssertionError();
        long result = (b & 0x7F) ;
        int shift = 7;
        do {

            b = getUnsignedByte(offset++);
            result |= (b & 0x7F) << shift;
            if(CC.ASSERT && shift>64)
                throw new AssertionError();
            shift += 7;
        }while((b & 0x80) == 0);

        return (((long)(shift/7))<<56) | result;
    }

    public long getLongPackBidiReverse(long offset){

        long b = getUnsignedByte(--offset);
        if(CC.ASSERT && (b&0x80)==0)
            throw new AssertionError();
        long result = (b & 0x7F) ;
        int counter = 1;
        do {

            b = getUnsignedByte(--offset);
            result = (b & 0x7F) | (result<<7);
            if(CC.ASSERT && counter>8)
                throw new AssertionError();
            counter++;
        }while((b & 0x80) == 0);

        return (((long)counter)<<56) | result;
    }

    public long getSixLong(long pos) {
        return
                ((long) (getByte(pos++) & 0xff) << 40) |
                        ((long) (getByte(pos++) & 0xff) << 32) |
                        ((long) (getByte(pos++) & 0xff) << 24) |
                        ((long) (getByte(pos++) & 0xff) << 16) |
                        ((long) (getByte(pos++) & 0xff) << 8) |
                        ((long) (getByte(pos) & 0xff));
    }

    public void putSixLong(long pos, long value) {
        if(CC.ASSERT && (value>>>48!=0))
            throw new AssertionError();

        putByte(pos++, (byte) (0xff & (value >> 40)));
        putByte(pos++, (byte) (0xff & (value >> 32)));
        putByte(pos++, (byte) (0xff & (value >> 24)));
        putByte(pos++, (byte) (0xff & (value >> 16)));
        putByte(pos++, (byte) (0xff & (value >> 8)));
        putByte(pos, (byte) (0xff & (value)));
    }



    public int putPackedLong(long pos, long value){

        int ret = 0;
        int shift = 63-Long.numberOfLeadingZeros(value);
        shift -= shift%7; 
        while(shift!=0){
            putByte(pos + (ret++), (byte) (((value >>> shift) & 0x7F) | 0x80));

            shift-=7;
        }
        putByte(pos+(ret++),(byte) (value & 0x7F));
        return ret;
    }




    public long getPackedLong(long position){
        long ret = 0;
        long pos2 = 0;
        byte v;
        do{
            v = getByte(position+(pos2++));
            ret = (ret<<7 ) | (v & 0x7F);
        }while(v<0);

        return (pos2<<60) | ret;
    }



    abstract public File getFile();


    public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {


        byte[] data = new byte[(int) size];
        try {
            getDataInput(inputOffset, (int) size).readFully(data);
        }catch(IOException e){
            throw new DBException.VolumeIOError(e);
        }
        target.putData(targetOffset,data,0, (int) size);
    }



    public abstract void clear(long startOffset, long endOffset);




    public void copyEntireVolumeTo(Volume to) {
        final long volSize = length();
        final long bufSize = 1L<<CC.VOLUME_PAGE_SHIFT;

        to.ensureAvailable(volSize);

        for(long offset=0;offset<volSize;offset+=bufSize){
            long size = Math.min(volSize,offset+bufSize)-offset;
            if(CC.ASSERT && (size<0))
                throw new AssertionError();
            transferInto(offset,to,offset, size);
        }

    }



    abstract static public class ByteBufferVol extends Volume{

        protected final ReentrantLock growLock = new ReentrantLock(CC.FAIR_LOCKS);
        protected final int sliceShift;
        protected final int sliceSizeModMask;
        protected final int sliceSize;

        protected volatile ByteBuffer[] slices = new ByteBuffer[0];
        protected final boolean readOnly;

        protected ByteBufferVol(boolean readOnly,  int sliceShift) {
            this.readOnly = readOnly;
            this.sliceShift = sliceShift;
            this.sliceSize = 1<< sliceShift;
            this.sliceSizeModMask = sliceSize -1;
        }


        @Override
        public final void ensureAvailable(long offset) {
            int slicePos = (int) (offset >>> sliceShift);


            if (slicePos < slices.length){
                return;
            }

            growLock.lock();
            try{

                if(slicePos< slices.length)
                    return;

                int oldSize = slices.length;
                ByteBuffer[] slices2 = slices;

                slices2 = Arrays.copyOf(slices2, Math.max(slicePos+1, slices2.length + slices2.length/1000));

                for(int pos=oldSize;pos<slices2.length;pos++) {
                    slices2[pos]=makeNewBuffer(1L* sliceSize *pos);
                }


                slices = slices2;
            }finally{
                growLock.unlock();
            }
        }

        protected abstract ByteBuffer makeNewBuffer(long offset);

        @Override public final void putLong(final long offset, final long value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+8){
                new IOException("VOL STACK:").printStackTrace();
            }

            slices[(int)(offset >>> sliceShift)].putLong((int) (offset & sliceSizeModMask), value);
        }

        @Override public final void putInt(final long offset, final int value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+4){
                new IOException("VOL STACK:").printStackTrace();
            }

            slices[(int)(offset >>> sliceShift)].putInt((int) (offset & sliceSizeModMask), value);
        }


        @Override public final void putByte(final long offset, final byte value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+1){
                new IOException("VOL STACK:").printStackTrace();
            }

            slices[(int)(offset >>> sliceShift)].put((int) (offset & sliceSizeModMask), value);
        }



        @Override public void putData(final long offset, final byte[] src, int srcPos, int srcSize){
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+srcSize){
                new IOException("VOL STACK:").printStackTrace();
            }


            final ByteBuffer b1 = slices[(int)(offset >>> sliceShift)].duplicate();
            final int bufPos = (int) (offset& sliceSizeModMask);

            b1.position(bufPos);
            b1.put(src, srcPos, srcSize);
        }


        @Override public final void putData(final long offset, final ByteBuffer buf) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+buf.remaining()){
                new IOException("VOL STACK:").printStackTrace();
            }

            final ByteBuffer b1 = slices[(int)(offset >>> sliceShift)].duplicate();
            final int bufPos = (int) (offset& sliceSizeModMask);

            b1.position(bufPos);
            b1.put(buf);
        }

        @Override
        public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {
            final ByteBuffer b1 = slices[(int)(inputOffset >>> sliceShift)].duplicate();
            final int bufPos = (int) (inputOffset& sliceSizeModMask);

            b1.position(bufPos);

            b1.limit((int) (bufPos+size));
            target.putData(targetOffset,b1);
        }

        @Override public void getData(final long offset, final byte[] src, int srcPos, int srcSize){
            final ByteBuffer b1 = slices[(int)(offset >>> sliceShift)].duplicate();
            final int bufPos = (int) (offset& sliceSizeModMask);

            b1.position(bufPos);
            b1.get(src, srcPos, srcSize);
        }


        @Override final public long getLong(long offset) {
            return slices[(int)(offset >>> sliceShift)].getLong((int) (offset& sliceSizeModMask));
        }

        @Override final public int getInt(long offset) {
            return slices[(int)(offset >>> sliceShift)].getInt((int) (offset& sliceSizeModMask));
        }


        @Override public final byte getByte(long offset) {
            return slices[(int)(offset >>> sliceShift)].get((int) (offset& sliceSizeModMask));
        }


        @Override
        public final DataIO.DataInputByteBuffer getDataInput(long offset, int size) {
            return new DataIO.DataInputByteBuffer(slices[(int)(offset >>> sliceShift)], (int) (offset& sliceSizeModMask));
        }



        @Override
        public void putDataOverlap(long offset, byte[] data, int pos, int len) {
            boolean overlap = (offset>>>sliceShift != (offset+len)>>>sliceShift);

            if(overlap){
                while(len>0){
                    ByteBuffer b = slices[((int) (offset >>> sliceShift))].duplicate();
                    b.position((int) (offset&sliceSizeModMask));

                    int toPut = Math.min(len,sliceSize - b.position());

                    b.limit(b.position()+toPut);
                    b.put(data, pos, toPut);

                    pos+=toPut;
                    len-=toPut;
                    offset+=toPut;
                }
            }else{
                putData(offset,data,pos,len);
            }
        }

        @Override
        public DataInput getDataInputOverlap(long offset, int size) {
            boolean overlap = (offset>>>sliceShift != (offset+size)>>>sliceShift);
            if(overlap){
                byte[] bb = new byte[size];
                final int origLen = size;
                while(size>0){
                    ByteBuffer b = slices[((int) (offset >>> sliceShift))].duplicate();
                    b.position((int) (offset&sliceSizeModMask));

                    int toPut = Math.min(size,sliceSize - b.position());

                    b.limit(b.position()+toPut);
                    b.get(bb,origLen-size,toPut);
                    size -=toPut;
                    offset+=toPut;
                }
                return new DataIO.DataInputByteArray(bb);
            }else{

                return getDataInput(offset,size);
            }
        }


        @Override
        public void clear(long startOffset, long endOffset) {
            if(CC.ASSERT && (startOffset >>> sliceShift) != ((endOffset-1) >>> sliceShift))
                throw new AssertionError();
            ByteBuffer buf = slices[(int)(startOffset >>> sliceShift)];
            int start = (int) (startOffset&sliceSizeModMask);
            int end = (int) (endOffset&sliceSizeModMask);

            int pos = start;
            while(pos<end){
                buf = buf.duplicate();
                buf.position(pos);
                buf.put(CLEAR, 0, Math.min(CLEAR.length, end-pos));
                pos+=CLEAR.length;
            }
        }

        @Override
        public boolean isEmpty() {
            return slices==null || slices.length==0;
        }

        @Override
        public boolean isSliced(){
            return true;
        }

        @Override
        public int sliceSize() {
            return sliceSize;
        }


        protected boolean unmap(MappedByteBuffer b){
            try{
                if(unmapHackSupported){



                    Method cleanerMethod = b.getClass().getMethod("cleaner", new Class[0]);
                    cleanerMethod.setAccessible(true);
                    if(cleanerMethod!=null){
                        Object cleaner = cleanerMethod.invoke(b);
                        if(cleaner!=null){
                            Method clearMethod = cleaner.getClass().getMethod("clean", new Class[0]);
                            if(clearMethod!=null) {
                                clearMethod.invoke(cleaner);
                                return true;
                            }
                        }else{

                            Method attMethod = b.getClass().getMethod("attachment", new Class[0]);
                            attMethod.setAccessible(true);
                            Object att = attMethod.invoke(b);
                            return att instanceof MappedByteBuffer &&
                                    unmap((MappedByteBuffer) att);
                        }
                    }
                }
            }catch(Exception e){
                unmapHackSupported = false;
                LOG.log(Level.WARNING, "Unmap failed", e);
            }
            return false;
        }

        private static boolean unmapHackSupported = true;
        static{
            try{
                unmapHackSupported =
                        SerializerPojo.classForName("sun.nio.ch.DirectBuffer")!=null;
            }catch(Exception e){
                unmapHackSupported = false;
            }
        }



        private static boolean windowsWorkaround = System.getProperty("os.name").toLowerCase().startsWith("win");


    }

    public static final class MappedFileVol extends ByteBufferVol {

        public static final VolumeFactory FACTORY = new VolumeFactory() {
            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {


                return new MappedFileVol(new File(file),readOnly,sliceShift);
            }
        };

        protected final File file;
        protected final FileChannel fileChannel;
        protected final FileChannel.MapMode mapMode;
        protected final java.io.RandomAccessFile raf;


        public MappedFileVol(File file, boolean readOnly, int sliceShift) {
            super(readOnly,sliceShift);
            this.file = file;
            this.mapMode = readOnly? FileChannel.MapMode.READ_ONLY: FileChannel.MapMode.READ_WRITE;
            try {
                FileChannelVol.checkFolder(file,readOnly);
                this.raf = new java.io.RandomAccessFile(file, readOnly?"r":"rw");
                this.fileChannel = raf.getChannel();

                final long fileSize = fileChannel.size();
                if(fileSize>0){

                    slices = new ByteBuffer[(int) ((fileSize>>> sliceShift))];
                    for(int i=0;i< slices.length;i++){
                        slices[i] = makeNewBuffer(1L*i* sliceSize);
                    }
                }else{
                    slices = new ByteBuffer[0];
                }
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void close() {
            growLock.lock();
            try{
                closed = true;
                fileChannel.close();
                raf.close();





                for(ByteBuffer b: slices){
                    if(b!=null && (b instanceof MappedByteBuffer)){
                        unmap((MappedByteBuffer) b);
                    }
                }

                slices = null;

            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }finally{
                growLock.unlock();
            }

        }

        @Override
        public void sync() {
            if(readOnly) return;
            growLock.lock();
            try{
                for(ByteBuffer b: slices){
                    if(b!=null && (b instanceof MappedByteBuffer)){
                        MappedByteBuffer bb = ((MappedByteBuffer) b);
                        bb.force();
                    }
                }

            }finally{
                growLock.unlock();
            }

        }

        @Override
        public int sliceSize() {
            return sliceSize;
        }

        @Override
        protected ByteBuffer makeNewBuffer(long offset) {
            try {
                if(CC.ASSERT && ! ((offset& sliceSizeModMask)==0))
                    throw new AssertionError();
                if(CC.ASSERT && ! (offset>=0))
                    throw new AssertionError();
                ByteBuffer ret = fileChannel.map(mapMode,offset, sliceSize);
                if(CC.ASSERT && ret.order() != ByteOrder.BIG_ENDIAN)
                    throw new AssertionError("Little-endian");
                if(mapMode == FileChannel.MapMode.READ_ONLY) {
                    ret = ret.asReadOnlyBuffer();
                }
                return ret;
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }


        @Override
        public boolean isEmpty() {
            return length()<=0;
        }

        @Override
        public long length() {
            return file.length();
        }

        @Override
        public File getFile() {
            return file;
        }


        @Override
        public void truncate(long size) {
            final int maxSize = 1+(int) (size >>> sliceShift);
            if(maxSize== slices.length)
                return;
            if(maxSize> slices.length) {
                ensureAvailable(size);
                return;
            }
            growLock.lock();
            try{
                if(maxSize>= slices.length)
                    return;
                ByteBuffer[] old = slices;
                slices = Arrays.copyOf(slices,maxSize);


                for(int i=maxSize;i<old.length;i++){
                    unmap((MappedByteBuffer) old[i]);
                    old[i] = null;
                }

                if (ByteBufferVol.windowsWorkaround) {
                    for(int i=0;i<maxSize;i++){
                        unmap((MappedByteBuffer) old[i]);
                        old[i] = null;
                    }
                }

                try {
                    fileChannel.truncate(1L * sliceSize *maxSize);
                } catch (IOException e) {
                    throw new DBException.VolumeIOError(e);
                }

                if (ByteBufferVol.windowsWorkaround) {
                    for(int pos=0;pos<maxSize;pos++) {
                        slices[pos]=makeNewBuffer(1L* sliceSize *pos);
                    }
                }

            }finally {
                growLock.unlock();
            }
        }

    }

    public static final class MemoryVol extends ByteBufferVol {


        public static final VolumeFactory FACTORY = new VolumeFactory() {
            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {


                return new MemoryVol(true,sliceShift);
            }
        }
                ;
        protected final boolean useDirectBuffer;

        @Override
        public String toString() {
            return super.toString()+",direct="+useDirectBuffer;
        }

        public MemoryVol(final boolean useDirectBuffer, final int sliceShift) {
            super(false, sliceShift);
            this.useDirectBuffer = useDirectBuffer;
        }

        @Override
        protected ByteBuffer makeNewBuffer(long offset) {
            try {
                ByteBuffer b =  useDirectBuffer ?
                        ByteBuffer.allocateDirect(sliceSize) :
                        ByteBuffer.allocate(sliceSize);
                if(CC.ASSERT && b.order()!= ByteOrder.BIG_ENDIAN)
                    throw new AssertionError("little-endian");
                return b;
            }catch(OutOfMemoryError e){
                throw new DBException.OutOfMemory(e);
            }
        }


        @Override
        public void truncate(long size) {
            final int maxSize = 1+(int) (size >>> sliceShift);
            if(maxSize== slices.length)
                return;
            if(maxSize> slices.length) {
                ensureAvailable(size);
                return;
            }
            growLock.lock();
            try{
                if(maxSize>= slices.length)
                    return;
                ByteBuffer[] old = slices;
                slices = Arrays.copyOf(slices,maxSize);


                for(int i=maxSize;i<old.length;i++){
                    if(old[i] instanceof  MappedByteBuffer)
                        unmap((MappedByteBuffer) old[i]);
                    old[i] = null;
                }

            }finally {
                growLock.unlock();
            }
        }

        @Override public void close() {
            growLock.lock();
            try{
                closed = true;
                for(ByteBuffer b: slices){
                    if(b!=null && (b instanceof MappedByteBuffer)){
                        unmap((MappedByteBuffer)b);
                    }
                }
                slices = null;
            }finally{
                growLock.unlock();
            }
        }

        @Override public void sync() {}

        @Override
        public long length() {
            return ((long)slices.length)*sliceSize;
        }

        @Override
        public File getFile() {
            return null;
        }
    }



    public static final class FileChannelVol extends Volume {

        public static final VolumeFactory FACTORY = new VolumeFactory() {

            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {
                return new FileChannelVol(new File(file),readOnly, sliceShift);
            }
        };

        protected final File file;
        protected final int sliceSize;
        protected RandomAccessFile raf;
        protected FileChannel channel;
        protected final boolean readOnly;

        protected volatile long size;
        protected final Lock growLock = new ReentrantLock(CC.FAIR_LOCKS);

        public FileChannelVol(File file, boolean readOnly, int sliceShift){
            this.file = file;
            this.readOnly = readOnly;
            this.sliceSize = 1<<sliceShift;
            try {
                checkFolder(file, readOnly);
                if (readOnly && !file.exists()) {
                    raf = null;
                    channel = null;
                    size = 0;
                } else {
                    raf = new RandomAccessFile(file, readOnly ? "r" : "rw");
                    channel = raf.getChannel();
                    size = channel.size();
                }
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        public FileChannelVol(File file) {
            this(file, false,CC.VOLUME_PAGE_SHIFT);
        }

        protected static void checkFolder(File file, boolean readOnly) throws IOException {
            File parent = file.getParentFile();
            if(parent == null) {
                parent = file.getCanonicalFile().getParentFile();
            }
            if (parent == null) {
                throw new IOException("Parent folder could not be determined for: "+file);
            }
            if(!parent.exists() || !parent.isDirectory())
                throw new IOException("Parent folder does not exist: "+file);
            if(!parent.canRead())
                throw new IOException("Parent folder is not readable: "+file);
            if(!readOnly && !parent.canWrite())
                throw new IOException("Parent folder is not writable: "+file);
        }

        @Override
        public void ensureAvailable(long offset) {
            if(offset% sliceSize !=0)
                offset += sliceSize - offset% sliceSize; 

            if(offset>size){
                growLock.lock();
                try {
                    raf.setLength(offset);
                    size = offset;
                } catch (IOException e) {
                    throw new DBException.VolumeIOError(e);
                }finally {
                    growLock.unlock();
                }
            }
        }

        @Override
        public void truncate(long size) {
            growLock.lock();
            try {
                this.size = size;
                channel.truncate(size);
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }finally{
                growLock.unlock();
            }
        }

        protected void writeFully(long offset, ByteBuffer buf){
            int remaining = buf.limit()-buf.position();
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+remaining){
                new IOException("VOL STACK:").printStackTrace();
            }
            try {
                while(remaining>0){
                    int write = channel.write(buf, offset);
                    if(write<0) throw new EOFException();
                    remaining-=write;
                }
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }


        @Override
        public void putLong(long offset, long value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+8){
                new IOException("VOL STACK:").printStackTrace();
            }


            ByteBuffer buf = ByteBuffer.allocate(8);
            buf.putLong(0, value);
            writeFully(offset, buf);
        }

        @Override
        public void putInt(long offset, int value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+4){
                new IOException("VOL STACK:").printStackTrace();
            }

            ByteBuffer buf = ByteBuffer.allocate(4);
            buf.putInt(0, value);
            writeFully(offset, buf);
        }

        @Override
        public void putByte(long offset, byte value) {
            if(CC.VOLUME_PRINT_STACK_AT_OFFSET!=0 && CC.VOLUME_PRINT_STACK_AT_OFFSET>=offset && CC.VOLUME_PRINT_STACK_AT_OFFSET <= offset+1){
                new IOException("VOL STACK:").printStackTrace();
            }


            ByteBuffer buf = ByteBuffer.allocate(1);
            buf.put(0, value);
            writeFully(offset, buf);
        }

        @Override
        public void putData(long offset, byte[] src, int srcPos, int srcSize) {
            ByteBuffer buf = ByteBuffer.wrap(src,srcPos, srcSize);
            writeFully(offset, buf);
        }

        @Override
        public void putData(long offset, ByteBuffer buf) {
            writeFully(offset,buf);
        }

        protected void readFully(long offset, ByteBuffer buf){
            int remaining = buf.limit()-buf.position();
            try{
                while(remaining>0){
                    int read = channel.read(buf, offset);
                    if(read<0)
                        throw new EOFException();
                    remaining-=read;
                }
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public long getLong(long offset) {
            ByteBuffer buf = ByteBuffer.allocate(8);
            readFully(offset, buf);
            return buf.getLong(0);
        }

        @Override
        public int getInt(long offset) {
            ByteBuffer buf = ByteBuffer.allocate(4);
            readFully(offset,buf);
            return buf.getInt(0);
        }

        @Override
        public byte getByte(long offset) {
            ByteBuffer buf = ByteBuffer.allocate(1);
            readFully(offset,buf);
            return buf.get(0);
        }

        @Override
        public DataIO.DataInputByteBuffer getDataInput(long offset, int size) {
            ByteBuffer buf = ByteBuffer.allocate(size);
            readFully(offset,buf);
            return new DataIO.DataInputByteBuffer(buf,0);
        }

        @Override
        public void getData(long offset, byte[] bytes, int bytesPos, int size) {
            ByteBuffer buf = ByteBuffer.wrap(bytes,bytesPos,size);
            readFully(offset,buf);
        }

        @Override
        public void close() {
            try{
                closed = true;
                if(channel!=null)
                    channel.close();
                channel = null;
                if (raf != null)
                    raf.close();
                raf = null;
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void sync() {
            try{
                channel.force(true);
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public boolean isEmpty() {
            try {
                return channel==null || channel.size()==0;
            }catch(ClosedByInterruptException e){
                throw new DBException.VolumeClosedByInterrupt(e);
            }catch(ClosedChannelException e){
                throw new DBException.VolumeClosed(e);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public int sliceSize() {
            return -1;
        }

        @Override
        public boolean isSliced() {
            return false;
        }

        @Override
        public long length() {
            try {
                return channel.size();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public File getFile() {
            return file;
        }

        @Override
        public void clear(long startOffset, long endOffset) {
            try {
                while(startOffset<endOffset){
                    ByteBuffer b = ByteBuffer.wrap(CLEAR);
                    b.limit((int) Math.min(CLEAR.length, endOffset - startOffset));
                    channel.write(b, startOffset);
                    startOffset+=CLEAR.length;
                }
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }
    }



    public static void volumeTransfer(long size, Volume from, Volume to){
        int bufSize = Math.min(from.sliceSize(),to.sliceSize());

        if(bufSize<0 || bufSize>1024*1024*128){
            bufSize = 64 * 1024; 
        }
        to.ensureAvailable(size);

        for(long offset=0;offset<size;offset+=bufSize){
            int bb = (int) Math.min(bufSize, size-offset);
            from.transferInto(offset,to,offset,bb);
        }
    }


    public static final class ByteArrayVol extends Volume{

        public static final VolumeFactory FACTORY = new VolumeFactory() {

            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {


                return new ByteArrayVol(sliceShift);
            }
        };

        protected final ReentrantLock growLock = new ReentrantLock(CC.FAIR_LOCKS);

        protected final int sliceShift;
        protected final int sliceSizeModMask;
        protected final int sliceSize;

        protected volatile byte[][] slices = new byte[0][];

        protected ByteArrayVol(int sliceShift) {
            this.sliceShift = sliceShift;
            this.sliceSize = 1<< sliceShift;
            this.sliceSizeModMask = sliceSize -1;
        }

        @Override
        public final void ensureAvailable(long offset) {

            int slicePos = (int) (offset >>> sliceShift);


            if (slicePos < slices.length){
                return;
            }

            growLock.lock();
            try {

                if (slicePos < slices.length)
                    return;

                int oldSize = slices.length;
                byte[][] slices2 = slices;

                slices2 = Arrays.copyOf(slices2, Math.max(slicePos + 1, slices2.length + slices2.length / 1000));

                for (int pos = oldSize; pos < slices2.length; pos++) {
                    slices2[pos] = new byte[sliceSize];
                }


                slices = slices2;
            }catch(OutOfMemoryError e){
                throw new DBException.OutOfMemory(e);
            }finally{
                growLock.unlock();
            }
        }


        @Override
        public void truncate(long size) {
            final int maxSize = 1+(int) (size >>> sliceShift);
            if(maxSize== slices.length)
                return;
            if(maxSize> slices.length) {
                ensureAvailable(size);
                return;
            }
            growLock.lock();
            try{
                if(maxSize>= slices.length)
                    return;
                slices = Arrays.copyOf(slices,maxSize);
            }finally {
                growLock.unlock();
            }
        }

        @Override
        public void putLong(long offset, long v) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            DataIO.putLong(buf,pos,v);
        }


        @Override
        public void putInt(long offset, int value) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            buf[pos++] = (byte) (0xff & (value >> 24));
            buf[pos++] = (byte) (0xff & (value >> 16));
            buf[pos++] = (byte) (0xff & (value >> 8));
            buf[pos++] = (byte) (0xff & (value));
        }

        @Override
        public void putByte(long offset, byte value) {
            final byte[] b = slices[((int) (offset >>> sliceShift))];
            b[((int) (offset & sliceSizeModMask))] = value;
        }

        @Override
        public void putData(long offset, byte[] src, int srcPos, int srcSize) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];

            System.arraycopy(src,srcPos,buf,pos,srcSize);
        }

        @Override
        public void putData(long offset, ByteBuffer buf) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] dst = slices[((int) (offset >>> sliceShift))];
            buf.get(dst, pos, buf.remaining());
        }


        @Override
        public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {
            int pos = (int) (inputOffset & sliceSizeModMask);
            byte[] buf = slices[((int) (inputOffset >>> sliceShift))];


            target.putData(targetOffset,buf,pos, (int) size);
        }



        @Override
        public void putDataOverlap(long offset, byte[] data, int pos, int len) {
            boolean overlap = (offset>>>sliceShift != (offset+len)>>>sliceShift);

            if(overlap){
                while(len>0){
                    byte[] b = slices[((int) (offset >>> sliceShift))];
                    int pos2 = (int) (offset&sliceSizeModMask);

                    int toPut = Math.min(len,sliceSize - pos2);

                    System.arraycopy(data, pos, b, pos2, toPut);

                    pos+=toPut;
                    len -=toPut;
                    offset+=toPut;
                }
            }else{
                putData(offset,data,pos,len);
            }
        }

        @Override
        public DataInput getDataInputOverlap(long offset, int size) {
            boolean overlap = (offset>>>sliceShift != (offset+size)>>>sliceShift);
            if(overlap){
                byte[] bb = new byte[size];
                final int origLen = size;
                while(size>0){
                    byte[] b = slices[((int) (offset >>> sliceShift))];
                    int pos = (int) (offset&sliceSizeModMask);

                    int toPut = Math.min(size,sliceSize - pos);

                    System.arraycopy(b,pos, bb,origLen-size,toPut);

                    size -=toPut;
                    offset+=toPut;
                }
                return new DataIO.DataInputByteArray(bb);
            }else{

                return getDataInput(offset,size);
            }
        }

        @Override
        public void clear(long startOffset, long endOffset) {
            if(CC.ASSERT && (startOffset >>> sliceShift) != ((endOffset-1) >>> sliceShift))
                throw new AssertionError();
            byte[] buf = slices[(int)(startOffset >>> sliceShift)];
            int start = (int) (startOffset&sliceSizeModMask);
            int end = (int) (endOffset&sliceSizeModMask);

            int pos = start;
            while(pos<end){
                System.arraycopy(CLEAR,0,buf,pos, Math.min(CLEAR.length, end-pos));
                pos+=CLEAR.length;
            }
        }

        @Override
        public long getLong(long offset) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            return DataIO.getLong(buf,pos);
        }



        @Override
        public int getInt(long offset) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];


            final int end = pos + 4;
            int ret = 0;
            for (; pos < end; pos++) {
                ret = (ret << 8) | (buf[pos] & 0xFF);
            }
            return ret;
        }

        @Override
        public byte getByte(long offset) {
            final byte[] b = slices[((int) (offset >>> sliceShift))];
            return b[((int) (offset & sliceSizeModMask))];
        }

        @Override
        public DataInput getDataInput(long offset, int size) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            return new DataIO.DataInputByteArray(buf,pos);
        }

        @Override
        public void getData(long offset, byte[] bytes, int bytesPos, int length) {
            int pos = (int) (offset & sliceSizeModMask);
            byte[] buf = slices[((int) (offset >>> sliceShift))];
            System.arraycopy(buf,pos,bytes,bytesPos,length);
        }

        @Override
        public void close() {
            closed = true;
            slices =null;
        }

        @Override
        public void sync() {

        }


        @Override
        public boolean isEmpty() {
            return slices.length==0;
        }

        @Override
        public int sliceSize() {
            return sliceSize;
        }

        @Override
        public boolean isSliced() {
            return true;
        }

        @Override
        public long length() {
            return ((long)slices.length)*sliceSize;
        }

        @Override
        public File getFile() {
            return null;
        }

    }


    public static final class SingleByteArrayVol extends Volume{

        protected final byte[] data;

        public SingleByteArrayVol(int size) {
            this(new byte[size]);
        }

        public SingleByteArrayVol(byte[] data){
            this.data = data;
        }


        @Override
        public void ensureAvailable(long offset) {
            if(offset >= data.length){

            }
        }

        @Override
        public void truncate(long size) {


        }

        @Override
        public void putLong(long offset, long v) {
            DataIO.putLong(data, (int) offset,v);
        }


        @Override
        public void putInt(long offset, int value) {
            int pos = (int) offset;
            data[pos++] = (byte) (0xff & (value >> 24));
            data[pos++] = (byte) (0xff & (value >> 16));
            data[pos++] = (byte) (0xff & (value >> 8));
            data[pos++] = (byte) (0xff & (value));
        }

        @Override
        public void putByte(long offset, byte value) {
            data[(int) offset] = value;
        }

        @Override
        public void putData(long offset, byte[] src, int srcPos, int srcSize) {
            System.arraycopy(src, srcPos, data, (int) offset, srcSize);
        }

        @Override
        public void putData(long offset, ByteBuffer buf) {
             buf.get(data, (int) offset, buf.remaining());
        }


        @Override
        public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {

            target.putData(targetOffset,data, (int) inputOffset, (int) size);
        }

        @Override
        public void clear(long startOffset, long endOffset) {
            int start = (int) startOffset;
            int end = (int) endOffset;

            int pos = start;
            while(pos<end){
                System.arraycopy(CLEAR,0,data,pos, Math.min(CLEAR.length, end-pos));
                pos+=CLEAR.length;
            }
        }

        @Override
        public long getLong(long offset) {
            return DataIO.getLong(data, (int) offset);
        }



        @Override
        public int getInt(long offset) {
            int pos = (int) offset;

            final int end = pos + 4;
            int ret = 0;
            for (; pos < end; pos++) {
                ret = (ret << 8) | (data[pos] & 0xFF);
            }
            return ret;
        }

        @Override
        public byte getByte(long offset) {
            return data[((int) offset)];
        }

        @Override
        public DataInput getDataInput(long offset, int size) {
             return new DataIO.DataInputByteArray(data, (int) offset);
        }

        @Override
        public void getData(long offset, byte[] bytes, int bytesPos, int length) {
            System.arraycopy(data, (int) offset,bytes,bytesPos,length);
        }

        @Override
        public void close() {
            closed = true;

        }

        @Override
        public void sync() {
        }

        @Override
        public boolean isEmpty() {

            for(byte b:data){
                if(b!=0)
                    return false;
            }
            return true;
        }


        @Override
        public int sliceSize() {
            return -1;
        }

        @Override
        public boolean isSliced() {
            return false;
        }

        @Override
        public long length() {
            return data.length;
        }

        @Override
        public File getFile() {
            return null;
        }

    }


    public static final class ReadOnly extends Volume{

        protected final Volume vol;

        public ReadOnly(Volume vol) {
            this.vol = vol;
        }

        @Override
        public void ensureAvailable(long offset) {

            return;
        }

        @Override
        public void truncate(long size) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putLong(long offset, long value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putInt(long offset, int value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putByte(long offset, byte value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putData(long offset, byte[] src, int srcPos, int srcSize) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putData(long offset, ByteBuffer buf) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public void putDataOverlap(long offset, byte[] src, int srcPos, int srcSize) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public long getLong(long offset) {
            return vol.getLong(offset);
        }

        @Override
        public int getInt(long offset) {
            return vol.getInt(offset);
        }

        @Override
        public byte getByte(long offset) {
            return vol.getByte(offset);
        }

        @Override
        public DataInput getDataInput(long offset, int size) {
            return vol.getDataInput(offset,size);
        }

        @Override
        public DataInput getDataInputOverlap(long offset, int size) {
            return vol.getDataInputOverlap(offset, size);
        }

        @Override
        public void getData(long offset, byte[] bytes, int bytesPos, int size) {
            vol.getData(offset,bytes,bytesPos,size);
        }

        @Override
        public void close() {
            closed = true;
            vol.close();
        }

        @Override
        public void sync() {
            vol.sync();
        }

        @Override
        public int sliceSize() {
            return vol.sliceSize();
        }

        @Override
        public boolean isEmpty() {
            return vol.isEmpty();
        }

        @Override
        public void deleteFile() {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public boolean isSliced() {
            return vol.isSliced();
        }

        @Override
        public long length() {
            return vol.length();
        }

        @Override
        public void putUnsignedShort(long offset, int value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public int getUnsignedShort(long offset) {
            return vol.getUnsignedShort(offset);
        }

        @Override
        public int getUnsignedByte(long offset) {
            return vol.getUnsignedByte(offset);
        }

        @Override
        public void putUnsignedByte(long offset, int b) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public int putLongPackBidi(long offset, long value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public long getLongPackBidi(long offset) {
            return vol.getLongPackBidi(offset);
        }

        @Override
        public long getLongPackBidiReverse(long offset) {
            return vol.getLongPackBidiReverse(offset);
        }

        @Override
        public long getSixLong(long pos) {
            return vol.getSixLong(pos);
        }

        @Override
        public void putSixLong(long pos, long value) {
            throw new IllegalAccessError("read-only");
        }

        @Override
        public File getFile() {
            return vol.getFile();
        }

        @Override
        public void transferInto(long inputOffset, Volume target, long targetOffset, long size) {
            vol.transferInto(inputOffset, target, targetOffset, size);
        }

        @Override
        public void clear(long startOffset, long endOffset) {
            throw new IllegalAccessError("read-only");
        }
    }


    public static final class RandomAccessFileVol extends Volume{


        public static final VolumeFactory FACTORY = new VolumeFactory() {
            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {

                return new RandomAccessFileVol(new File(file), readOnly);
            }
        };
        protected final File file;
        protected final RandomAccessFile raf;

        public RandomAccessFileVol(File file, boolean readOnly) {
            this.file = file;
            try {
                this.raf = new RandomAccessFile(file,readOnly?"r":"rw");
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void ensureAvailable(long offset) {

        }

        @Override
        public void truncate(long size) {
            try {
                raf.setLength(size);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized void putLong(long offset, long value) {
            try {
                raf.seek(offset);
                raf.writeLong(value);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }


        @Override
        public synchronized  void putInt(long offset, int value) {
            try {
                raf.seek(offset);
                raf.writeInt(value);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }

        }

        @Override
        public  synchronized void putByte(long offset, byte value) {
            try {
                raf.seek(offset);
                raf.writeByte(value);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }

        }

        @Override
        public  synchronized void putData(long offset, byte[] src, int srcPos, int srcSize) {
            try {
                raf.seek(offset);
                raf.write(src,srcPos,srcSize);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized void putData(long offset, ByteBuffer buf) {
            byte[] bb = buf.array();
            int pos = buf.position();
            int size = buf.limit()-pos;
            if(bb==null) {
                bb = new byte[size];
                buf.get(bb);
                pos = 0;
            }
            putData(offset,bb,pos, size);
        }

        @Override
        public synchronized long getLong(long offset) {
            try {
                raf.seek(offset);
                return raf.readLong();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized int getInt(long offset) {
            try {
                raf.seek(offset);
                return raf.readInt();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }

        }

        @Override
        public synchronized byte getByte(long offset) {
            try {
                raf.seek(offset);
                return raf.readByte();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized DataInput getDataInput(long offset, int size) {
            try {
                raf.seek(offset);
                byte[] b = new byte[size];
                raf.read(b);
                return new DataIO.DataInputByteArray(b);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public synchronized void getData(long offset, byte[] bytes, int bytesPos, int size) {
            try {
                raf.seek(offset);
                raf.read(bytes,bytesPos,size);
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void close() {
            closed = true;
            try {
                raf.close();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public void sync() {
            try {
                raf.getFD().sync();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public int sliceSize() {
            return 0;
        }

        @Override
        public boolean isEmpty() {
            try {
                return raf.length()==0;
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }


        @Override
        public boolean isSliced() {
            return false;
        }

        @Override
        public long length() {
            try {
                return raf.length();
            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }

        @Override
        public File getFile() {
            return file;
        }

        @Override
        public synchronized void clear(long startOffset, long endOffset) {
            try {
                raf.seek(startOffset);
                while(startOffset<endOffset){
                    long remaining = Math.min(CLEAR.length, endOffset - startOffset);
                    raf.write(CLEAR, 0, (int)remaining);
                    startOffset+=CLEAR.length;
                }

            } catch (IOException e) {
                throw new DBException.VolumeIOError(e);
            }
        }
    }
}


<code block>
package org.mapdb;

import java.io.DataInput;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashSet;
import java.util.Set;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.locks.Lock;
import java.util.logging.Level;


public class StoreAppend extends Store {

    protected static final int I_UPDATE = 1;
    protected static final int I_INSERT = 3;
    protected static final int I_DELETE = 2;
    protected static final int I_PREALLOC = 4;
    protected static final int I_SKIP_SINGLE_BYTE = 6;
    protected static final int I_SKIP_MULTI_BYTE = 7;

    protected static final int I_TX_VALID = 8;
    protected static final int I_TX_ROLLBACK = 9;

    protected static final long headerSize = 16;

    protected static final StoreAppend[] STORE_APPENDS_ZERO_ARRAY = new StoreAppend[0];


    protected Volume vol;



    protected Volume indexTable;


    protected long eof = 0;
    protected final AtomicLong highestRecid = new AtomicLong(0);
    protected final boolean tx;

    protected final LongLongMap[] modified;

    protected final ScheduledExecutorService compactionExecutor;

    protected final Set<StoreAppend> snapshots;

    protected final boolean isSnapshot;

    protected StoreAppend(String fileName,
                          Volume.VolumeFactory volumeFactory,
                          Cache cache,
                          int lockScale,
                          int lockingStrategy,
                          boolean checksum,
                          boolean compress,
                          byte[] password,
                          boolean readonly,
                          boolean snapshotEnable,
                          boolean txDisabled,
                          ScheduledExecutorService compactionExecutor
                    ) {
        super(fileName, volumeFactory, cache, lockScale,lockingStrategy, checksum, compress, password, readonly, snapshotEnable);
        this.tx = !txDisabled;
        if(tx){
            modified = new LongLongMap[this.lockScale];
            for(int i=0;i<modified.length;i++){
                modified[i] = new LongLongMap();
            }
        }else{
            modified = null;
        }
        this.compactionExecutor = compactionExecutor;
        this.snapshots = Collections.synchronizedSet(new HashSet<StoreAppend>());
        this.isSnapshot = false;
    }

    public StoreAppend(String fileName) {
        this(fileName,
                fileName==null? CC.DEFAULT_MEMORY_VOLUME_FACTORY : CC.DEFAULT_FILE_VOLUME_FACTORY,
                null,
                CC.DEFAULT_LOCK_SCALE,
                0,
                false,
                false,
                null,
                false,
                false,
                false,
                null
        );
    }


    protected StoreAppend(StoreAppend host, LongLongMap[] uncommitedData){
        super(null, null,null,
                host.lockScale,
                Store.LOCKING_STRATEGY_NOLOCK,
                host.checksum,
                host.compress,
                null, 
                true, 
                false);

        indexTable = host.indexTable;
        vol = host.vol;


        for(int i=0;i<locks.length;i++){
            locks[i] = host.locks[i];
        }

        tx = true;
        modified = new LongLongMap[this.lockScale];
        if(uncommitedData==null){
            for(int i=0;i<modified.length;i++) {
                modified[i] = new LongLongMap();
            }
        }else{
            for(int i=0;i<modified.length;i++) {
                Lock lock = locks[i].writeLock();
                lock.lock();
                try {
                    modified[i] = uncommitedData[i].clone();
                }finally {
                    lock.unlock();
                }
            }
        }

        this.compactionExecutor = null;
        this.snapshots = host.snapshots;
        this.isSnapshot = true;
        host.snapshots.add(StoreAppend.this);
    }

    @Override
    public void init() {
        super.init();
        structuralLock.lock();
        try {
            vol = volumeFactory.makeVolume(fileName, readonly);
            indexTable = new Volume.ByteArrayVol(CC.VOLUME_PAGE_SHIFT);
            if (!readonly)
                vol.ensureAvailable(headerSize);
            eof = headerSize;
            for (int i = 0; i <= RECID_LAST_RESERVED; i++) {
                indexTable.ensureAvailable(i * 8);
                indexTable.putLong(i * 8, -3);
            }

            if (vol.isEmpty()) {
                initCreate();
            } else {
                initOpen();
            }
        }finally {
            structuralLock.unlock();
        }
    }

    protected void initCreate() {
        highestRecid.set(RECID_LAST_RESERVED);

        long feat = makeFeaturesBitmap();
        vol.putLong(HEAD_FEATURES, feat);
        vol.sync();
    }

    protected void initOpen() {
        checkFeaturesBitmap(vol.getLong(HEAD_FEATURES));


        long pos = headerSize;
        final long volumeSize = vol.length();
        long lastValidPos= pos;
        long highestRecid2 = RECID_LAST_RESERVED;
        LongLongMap commitData = tx?new LongLongMap():null;

        try{

            while(true) {
                lastValidPos = pos;
                if(pos>=volumeSize)
                    break;
                final long instPos = pos;
                final int inst = vol.getUnsignedByte(pos++);

                if (inst == I_INSERT || inst == I_UPDATE) {

                    long recid = vol.getPackedLong(pos);
                    pos += recid>>>60;
                    recid =  longParityGet(recid & DataIO.PACK_LONG_RESULT_MASK);

                    highestRecid2 = Math.max(highestRecid2, recid);

                    commitData.put(recid, instPos);


                    long size = vol.getPackedLong(pos);
                    long dataLen = longParityGet(size & DataIO.PACK_LONG_RESULT_MASK) - 1;
                    dataLen = Math.max(0,dataLen);
                    pos = pos + (size>>>60) + dataLen;
                } else if (inst == I_DELETE) {
                    long recid = vol.getPackedLong(pos);
                    pos += recid>>>60;
                    recid =  longParityGet(recid & DataIO.PACK_LONG_RESULT_MASK);

                    highestRecid2 = Math.max(highestRecid2, recid);

                    commitData.put(recid, -1);
                } else if (inst == I_DELETE) {
                    long recid = vol.getPackedLong(pos);
                    pos += recid>>>60;
                    recid =  longParityGet(recid & DataIO.PACK_LONG_RESULT_MASK);
                    highestRecid2 = Math.max(highestRecid2, recid);
                    commitData.put(recid,-2);

                } else if (inst == I_SKIP_SINGLE_BYTE) {

                } else if (inst == I_SKIP_MULTI_BYTE) {


                    long size = vol.getPackedLong(pos);
                    pos += (size>>>60) + longParityGet(size & DataIO.PACK_LONG_RESULT_MASK);
                } else if (inst == I_TX_VALID) {
                    if (tx){

                        for(int i=0;i<commitData.table.length;i+=2){
                            long recidOffset = commitData.table[i]*8;
                            if(recidOffset==0)
                                continue;
                            indexTable.ensureAvailable(recidOffset + 8);
                            indexTable.putLong(recidOffset, commitData.table[i+1]);
                        }
                        commitData.clear();
                    }
                } else if (inst == I_TX_ROLLBACK) {
                    if (tx) {
                        commitData.clear();
                    }
                } else if (inst == 0) {

                    if (tx) {

                        commitData.clear();
                    }

                    break;
                } else {

                    LOG.warning("Unknown instruction " + inst);
                    break;
                }
            }
        }catch (RuntimeException e){


            LOG.log(Level.WARNING, "Log replay finished",e);
            if(tx) {

                commitData.clear();
            }

        }
        eof = lastValidPos;

        highestRecid.set(highestRecid2);
    }

    protected long alloc(int headSize, int totalSize){
        structuralLock.lock();
        try{
            while(eof/StoreDirect.PAGE_SIZE != (eof+headSize)/StoreDirect.PAGE_SIZE){

                vol.ensureAvailable(eof+1);
                vol.putUnsignedByte(eof++, I_SKIP_SINGLE_BYTE);
            }
            long ret = eof;
            eof+=totalSize;
            return ret;
        }finally {
            structuralLock.unlock();
        }
    }

    @Override
    protected <A> A get2(long recid, Serializer<A> serializer) {
        if(CC.ASSERT)
            assertReadLocked(recid);

        long offset = modified[lockPos(recid)].get(recid);
        if(offset==0) {
            try {
                offset = indexTable.getLong(recid * 8);
            } catch (ArrayIndexOutOfBoundsException e) {

                throw new DBException.EngineGetVoid();
            }
        }

        if(offset==-3||offset==-1) 
            return null;
        if(offset == 0){ 
            throw new DBException.EngineGetVoid();
        }
        if(offset == -2){

            return deserialize(serializer,0,new DataIO.DataInputByteArray(new byte[0]));
        }

        final long packedRecidSize = DataIO.packLongSize(longParitySet(recid));

        if(CC.ASSERT){
            int instruction = vol.getUnsignedByte(offset);

            if(instruction!= I_UPDATE && instruction!= I_INSERT)
                throw new AssertionError("wrong instruction "+instruction);

            long recid2 = vol.getPackedLong(offset+1);

            if(packedRecidSize!=recid2>>>60)
                throw new AssertionError("inconsistent recid len");

            recid2 = longParityGet(recid2&DataIO.PACK_LONG_RESULT_MASK);
            if(recid!=recid2)
                throw new AssertionError("recid does not match");
        }

        offset += 1 + 
                packedRecidSize; 



        long size = vol.getPackedLong(offset);
        offset+=size>>>60;
        size = longParityGet(size & DataIO.PACK_LONG_RESULT_MASK);

        size -= 1; 
        if(CC.ASSERT && size<=0)
            throw new AssertionError();

        DataInput input = vol.getDataInputOverlap(offset, (int) size);
        return deserialize(serializer, (int) size, input);
    }

    @Override
    protected void update2(long recid, DataIO.DataOutputByteArray out) {
        insertOrUpdate(recid, out, false);
    }

    private void insertOrUpdate(long recid, DataIO.DataOutputByteArray out, boolean isInsert) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));



        final int realSize = out==null ? 0: out.pos;
        final int shiftedSize = out==null ?0 : realSize+1;  
        final int headSize = 1 +  
                DataIO.packLongSize(longParitySet(recid)) + 
                DataIO.packLongSize(longParitySet(shiftedSize));   

        long offset = alloc(headSize, headSize+realSize);
        final long origOffset = offset;

        vol.ensureAvailable(offset+headSize+realSize);

        vol.putUnsignedByte(offset, isInsert ? I_INSERT : I_UPDATE);
        offset++;

        offset+=vol.putPackedLong(offset,longParitySet(recid));

        offset+=vol.putPackedLong(offset,longParitySet(shiftedSize));

        if(realSize!=0)
            vol.putDataOverlap(offset, out.buf,0,out.pos);



        indexTablePut(recid, out==null? -3 : (realSize==0) ? -2:origOffset);
    }

    @Override
    protected <A> void delete2(long recid, Serializer<A> serializer) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));

        final int headSize = 1 + DataIO.packLongSize(longParitySet(recid));
        long offset = alloc(headSize,headSize);
        vol.ensureAvailable(offset + headSize);

        vol.putUnsignedByte(offset, I_DELETE); 
        offset++;
        vol.putPackedLong(offset,longParitySet(recid));

        indexTablePut(recid, -1); 
    }

    @Override
    public long getCurrSize() {
        return 0;
    }

    @Override
    public long getFreeSize() {
        return 0;
    }

    @Override
    public long preallocate() {
        long recid = highestRecid.incrementAndGet();
        Lock lock = locks[lockPos(recid)].writeLock();
        lock.lock();
        try{
            final int headSize = 1 + DataIO.packLongSize(longParitySet(recid));
            long offset = alloc(headSize,headSize);
            vol.ensureAvailable(offset + headSize);

            vol.putUnsignedByte(offset, I_PREALLOC);
            offset++;
            vol.putPackedLong(offset, longParitySet(recid));

            indexTablePut(recid,-3);
        }finally {
            lock.unlock();
        }

        return recid;
    }

    protected void indexTablePut(long recid, long offset) {
        if(tx){
            modified[lockPos(recid)].put(recid,offset);
        }else {
            indexTable.ensureAvailable(recid*8+8);
            indexTable.putLong(recid * 8, offset);
        }
    }

    @Override
    public <A> long put(A value, Serializer<A> serializer) {
        DataIO.DataOutputByteArray out = serialize(value,serializer);
        long recid = highestRecid.incrementAndGet();
        int lockPos = lockPos(recid);
        Cache cache = caches==null ? null : caches[lockPos] ;
        Lock lock = locks[lockPos].writeLock();
        lock.lock();
        try{
            if(cache!=null) {
                cache.put(recid, value);
            }

            insertOrUpdate(recid,out,true);
        }finally {
            lock.unlock();
        }

        return recid;
    }

    @Override
    public void close() {
        if(closed)
            return;
        commitLock.lock();
        try {
            if(closed)
                return;

            if(isSnapshot){
                snapshots.remove(this);
                return;
            }

            vol.sync();
            vol.close();
            indexTable.close();

            if(caches!=null){
                for(Cache c:caches){
                    c.close();
                }
                Arrays.fill(caches,null);
            }
            closed = true;
        }finally{
            commitLock.unlock();
        }
    }

    @Override
    public void commit() {
        if(isSnapshot)
            return;

        if(!tx){
            vol.sync();
            return;
        }

        commitLock.lock();
        try{
            StoreAppend[] snaps = snapshots==null ?
                    STORE_APPENDS_ZERO_ARRAY :
                    snapshots.toArray(STORE_APPENDS_ZERO_ARRAY);

            for(int i=0;i<locks.length;i++) {
                Lock lock = locks[i].writeLock();
                lock.lock();
                try {
                    long[] m = modified[i].table;
                    for(int j=0;j<m.length;j+=2){
                        long recid = m[j];
                        long recidOffset = recid*8;
                        if(recidOffset==0)
                            continue;
                        indexTable.ensureAvailable(recidOffset + 8);
                        long oldVal = indexTable.getLong(recidOffset);
                        indexTable.putLong(recidOffset,m[j+1]);

                        for(StoreAppend snap:snaps){
                            LongLongMap m2 = snap.modified[i];
                            if(m2.get(recid)==0) {
                                m2.put(recid, oldVal);
                            }
                        }
                    }
                    modified[i].clear();
                }finally {
                    lock.unlock();
                }
            }
            long offset = alloc(1,1);
            vol.putUnsignedByte(offset,I_TX_VALID);
            vol.sync();
        }finally {
            commitLock.unlock();
        }
    }

    @Override
    public void rollback() throws UnsupportedOperationException {
        if(!tx || readonly || isSnapshot)
            throw new UnsupportedOperationException();
        commitLock.lock();
        try{
            for(int i=0;i<locks.length;i++) {
                Lock lock = locks[i].writeLock();
                lock.lock();
                try {
                    modified[i].clear();
                }finally {
                    lock.unlock();
                }
            }
            long offset = alloc(1,1);
            vol.putUnsignedByte(offset,I_TX_ROLLBACK);
            vol.sync();
        }finally {
            commitLock.unlock();
        }
    }



    @Override
    public boolean canRollback() {
        return tx;
    }

    @Override
    public boolean canSnapshot() {
        return true;
    }

    @Override
    public Engine snapshot() throws UnsupportedOperationException {
        commitLock.lock();
        try {
            return new StoreAppend(this, modified);
        }finally {
            commitLock.unlock();
        }
    }


    @Override
    public void compact() {
        if(isSnapshot)
            return;

    }
}

<code block>


package org.mapdb;


import java.io.DataInput;
import java.io.File;
import java.io.IOError;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.LockSupport;
import java.util.concurrent.locks.ReentrantLock;

import static org.mapdb.DataIO.*;


public class StoreWAL extends StoreCached {


    protected static final long WAL_SEAL = 8234892392398238983L;

    protected static final int FULL_REPLAY_AFTER_N_TX = 16;



    protected final LongLongMap[] prevLongLongs;
    protected final LongLongMap[] currLongLongs;
    protected final LongLongMap[] prevDataLongs;
    protected final LongLongMap[] currDataLongs;

    protected final LongLongMap pageLongStack = new LongLongMap();
    protected final List<Volume> volumes = Collections.synchronizedList(new ArrayList<Volume>());


    protected volatile Volume walC;


    protected volatile Volume walCCompact;


    protected final List<Volume> walRec = Collections.synchronizedList(new ArrayList<Volume>());

    protected final ReentrantLock compactLock = new ReentrantLock(CC.FAIR_LOCKS);

    protected volatile boolean compactionInProgress = false;

    protected Volume curVol;

    protected int fileNum = -1;


    protected final AtomicLong walOffset = new AtomicLong();

    protected Volume headVolBackup;

    protected long[] indexPagesBackup;

    protected Volume realVol;

    protected volatile boolean $_TEST_HACK_COMPACT_PRE_COMMIT_WAIT =false;

    protected volatile boolean $_TEST_HACK_COMPACT_POST_COMMIT_WAIT =false;


    public StoreWAL(String fileName) {
        this(fileName,
                fileName == null ? CC.DEFAULT_MEMORY_VOLUME_FACTORY : CC.DEFAULT_FILE_VOLUME_FACTORY,
                null,
                CC.DEFAULT_LOCK_SCALE,
                0,
                false, false, null, false,false, 0,
                false, 0,
                null, 0L,
                0);
    }

    public StoreWAL(
            String fileName,
            Volume.VolumeFactory volumeFactory,
            Cache cache,
            int lockScale,
            int lockingStrategy,
            boolean checksum,
            boolean compress,
            byte[] password,
            boolean readonly,
            boolean snapshotEnable,
            int freeSpaceReclaimQ,
            boolean commitFileSyncDisable,
            int sizeIncrement,
            ScheduledExecutorService executor,
            long executorScheduledRate,
            int writeQueueSize
        ) {
        super(fileName, volumeFactory, cache,
                lockScale,
                lockingStrategy,
                checksum, compress, password, readonly, snapshotEnable,
                freeSpaceReclaimQ, commitFileSyncDisable, sizeIncrement,
                executor,
                executorScheduledRate,
                writeQueueSize);
        prevLongLongs = new LongLongMap[this.lockScale];
        currLongLongs = new LongLongMap[this.lockScale];
        for (int i = 0; i < prevLongLongs.length; i++) {
            prevLongLongs[i] = new LongLongMap();
            currLongLongs[i] = new LongLongMap();
        }
        prevDataLongs = new LongLongMap[this.lockScale];
        currDataLongs = new LongLongMap[this.lockScale];
        for (int i = 0; i < prevDataLongs.length; i++) {
            prevDataLongs[i] = new LongLongMap();
            currDataLongs[i] = new LongLongMap();
        }

    }


    @Override
    protected void initCreate() {
        super.initCreate();
        indexPagesBackup = indexPages.clone();
        realVol = vol;

        vol = new Volume.ReadOnly(vol);


        walStartNextFile();
    }

    @Override
    public void initOpen(){


        realVol = vol;


        String wal0Name = getWalFileName("0");
        String walCompSeal = getWalFileName("c");
        boolean walCompSealExists =
                walCompSeal!=null &&
                        new File(walCompSeal).exists();

        if(walCompSealExists ||
             (wal0Name!=null &&
                     new File(wal0Name).exists())){


            walC =  walCompSealExists?volumeFactory.makeVolume(walCompSeal, readonly) : null;
            walCCompact = walCompSealExists? volumeFactory.makeVolume(walCompSeal + ".compact", readonly) : null;

            for(int i=0;;i++){
                String rname = getWalFileName("r"+i);
                if(!new File(rname).exists())
                    break;
                walRec.add(volumeFactory.makeVolume(rname, readonly));
            }



            for(int i=0;;i++){
                String wname = getWalFileName(""+i);
                if(!new File(wname).exists())
                    break;
                volumes.add(volumeFactory.makeVolume(wname, readonly));
            }

            initOpenPost();

            replayWAL();

            if(walC!=null)
                walC.close();
            walC = null;
            if(walCCompact!=null)
                walCCompact.close();
            walCCompact = null;
            for(Volume v:walRec){
                v.close();
            }
            walRec.clear();
            volumes.clear();
        }


        walStartNextFile();

        initOpenPost();
    }

    @Override
    protected void initFailedCloseFiles() {
        if(walC!=null && !walC.isClosed()) {
            walC.close();
        }
        walC = null;

        if(walCCompact!=null && !walCCompact.isClosed()) {
            walCCompact.close();
        }
        walCCompact = null;

        if(walRec!=null){
            for(Volume v:walRec){
                if(v!=null && !v.isClosed())
                    v.close();
            }
            walRec.clear();
        }
        if(volumes!=null){
            for(Volume v:volumes){
                if(v!=null && !v.isClosed())
                    v.close();
            }
            volumes.clear();
        }
    }

    protected void initOpenPost() {
        super.initOpen();
        indexPagesBackup = indexPages.clone();



        vol = new Volume.ReadOnly(vol);
    }


    @Override
    protected void initHeadVol() {
        super.initHeadVol();

        if(headVolBackup!=null && !headVolBackup.isClosed())
            headVolBackup.close();
        headVolBackup = new Volume.ByteArrayVol(CC.VOLUME_PAGE_SHIFT);
        headVolBackup.ensureAvailable(HEAD_END);
        byte[] b = new byte[(int) HEAD_END];

        headVol.getData(0,b,0,b.length);
        headVolBackup.putData(0,b,0,b.length);
    }

    protected void walStartNextFile() {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        fileNum++;
        if (CC.ASSERT && fileNum != volumes.size())
            throw new AssertionError();
        String filewal = getWalFileName(""+fileNum);
        Volume nextVol;
        if (readonly && filewal != null && !new File(filewal).exists()){
            nextVol = new Volume.ReadOnly(new Volume.ByteArrayVol(8));
        }else {
            nextVol = volumeFactory.makeVolume(filewal, readonly);
        }
        nextVol.ensureAvailable(16);

        walOffset.set(16);
        volumes.add(nextVol);

        curVol = nextVol;
    }

    protected String getWalFileName(String ext) {
        return fileName==null? null :
                fileName+".wal"+"."+ext;
    }

    protected void walPutLong(long offset, long value){
        final int plusSize = +1+8+6;
        long walOffset2 = walOffset.getAndAdd(plusSize);

        Volume curVol2 = curVol;


        if(hadToSkip(walOffset2, plusSize)){
            walPutLong(offset, value);
            return;
        }

        if(CC.ASSERT && offset>>>48!=0)
            throw new AssertionError();
        curVol2.ensureAvailable(walOffset2+plusSize);
        int parity = 1+Long.bitCount(value)+Long.bitCount(offset);
        parity &=15;
        curVol2.putUnsignedByte(walOffset2, (1 << 4)|parity);
        walOffset2+=1;
        curVol2.putLong(walOffset2, value);
        walOffset2+=8;
        curVol2.putSixLong(walOffset2, offset);
    }


    protected void walPutUnsignedShort(long offset, int value) {
        final int plusSize = +1+8;
        long walOffset2 = walOffset.getAndAdd(plusSize);

        Volume curVol2 = curVol;


        if(hadToSkip(walOffset2, plusSize)){
            walPutUnsignedShort(offset, value);
            return;
        }

        curVol2.ensureAvailable(walOffset2+plusSize);
        if(CC.ASSERT && offset>>>48!=0)
            throw new AssertionError();
        offset = (((long)value)<<48) | offset;
        int parity = 1+Long.bitCount(offset);
        parity &=15;
        curVol2.putUnsignedByte(walOffset2, (6 << 4)|parity);
        walOffset2+=1;
        curVol2.putLong(walOffset2, offset);
    }

    protected boolean hadToSkip(long walOffset2, int plusSize) {

        if((walOffset2>>>CC.VOLUME_PAGE_SHIFT)==(walOffset2+plusSize)>>>CC.VOLUME_PAGE_SHIFT){
            return false; 
        }


        while((walOffset2&PAGE_MASK) >= PAGE_SIZE-4 || plusSize<5){

            int singleByteSkip = (4<<4)|(Long.bitCount(walOffset2)&15);
            curVol.putUnsignedByte(walOffset2++, singleByteSkip);
            plusSize--;
            if(CC.ASSERT && plusSize<0)
                throw new AssertionError();
        }


        int val = (3<<(4+3*8)) | (plusSize-4) | ((Integer.bitCount(plusSize-4)&15)<<(3*8));
        curVol.ensureAvailable(walOffset2 + 4);
        curVol.putInt(walOffset2, val);

        return true;
    }

    @Override
    protected void putDataSingleWithLink(int segment, long offset, long link, byte[] buf, int bufPos, int size) {
        if(CC.ASSERT && (size&0xFFFF)!=size)
            throw new AssertionError();

        byte[] buf2 = new  byte[size+8];
        DataIO.putLong(buf2,0,link);
        System.arraycopy(buf,bufPos,buf2,8,size);
        putDataSingleWithoutLink(segment,offset,buf2,0,buf2.length);
    }

    @Override
    protected void putDataSingleWithoutLink(int segment, long offset, byte[] buf, int bufPos, int size) {
        if(CC.ASSERT && (size&0xFFFF)!=size)
            throw new AssertionError();
        if(CC.ASSERT && (offset%16!=0 && offset!=4))
            throw new AssertionError();


        if(CC.ASSERT && segment!=-1)
            assertWriteLocked(segment);
        if(CC.ASSERT && segment==-1 && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        final int plusSize = +1+2+6+size;
        long walOffset2 = walOffset.getAndAdd(plusSize);

        if(hadToSkip(walOffset2, plusSize)){
            putDataSingleWithoutLink(segment,offset,buf,bufPos,size);
            return;
        }

        curVol.ensureAvailable(walOffset2+plusSize);
        int checksum = 1+Integer.bitCount(size)+Long.bitCount(offset)+sum(buf,bufPos,size);
        checksum &= 15;
        curVol.putUnsignedByte(walOffset2, (2 << 4)|checksum);
        walOffset2+=1;
        curVol.putLong(walOffset2, ((long) size) << 48 | offset);
        walOffset2+=8;
        curVol.putData(walOffset2, buf,bufPos,size);


        long val = ((long)size)<<48;
        val |= ((long)fileNum)<<32;
        val |= walOffset2;

        (segment==-1?pageLongStack:currDataLongs[segment]).put(offset, val);
    }


    protected DataInput walGetData(long offset, int segment) {
        if (CC.ASSERT && offset % 16 != 0)
            throw new AssertionError();

        long longval = currDataLongs[segment].get(offset);
        if(longval==0){
            longval = prevDataLongs[segment].get(offset);
        }
        if(longval==0)
            return null;

        int arraySize = (int) (longval >>> 48);
        int fileNum = (int) ((longval >>> 32) & 0xFFFFL);
        long dataOffset = longval & 0xFFFFFFFFL;

        Volume vol = volumes.get(fileNum);
        return vol.getDataInput(dataOffset, arraySize);
    }

    @Override
    protected long indexValGet(long recid) {
        if(CC.ASSERT)
            assertReadLocked(recid);
        int segment = lockPos(recid);
        long offset = recidToOffset(recid);
        long ret = currLongLongs[segment].get(offset);
        if(ret!=0) {
            return ret;
        }
        ret = prevLongLongs[segment].get(offset);
        if(ret!=0)
            return ret;
        return super.indexValGet(recid);
    }

    @Override
    protected void indexValPut(long recid, int size, long offset, boolean linked, boolean unused) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));



        long newVal = composeIndexVal(size, offset, linked, unused, true);
        currLongLongs[lockPos(recid)].put(recidToOffset(recid), newVal);
    }

    @Override
    protected void indexLongPut(long offset, long val) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw  new AssertionError();
        if(CC.ASSERT && compactionInProgress)
            throw new AssertionError();
        walPutLong(offset,val);
    }

    @Override
    protected long pageAllocate() {




        long storeSize = parity16Get(headVol.getLong(STORE_SIZE));
        headVol.putLong(STORE_SIZE, parity16Set(storeSize + PAGE_SIZE));


        if(CC.ASSERT && storeSize%PAGE_SIZE!=0)
            throw new AssertionError();


        return storeSize;
    }

    @Override
    protected byte[] loadLongStackPage(long pageOffset) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();






        byte[] page = dirtyStackPages.get(pageOffset);
        if (page != null) {
            return page;
        }


        long walval = pageLongStack.get(pageOffset);
        if(walval!=0){

            int arraySize = (int) (walval >>> 48);
            int fileNum = (int) ((walval >>> 32) & 0xFFFFL);
            long dataOffset = walval & 0xFFFFFFFFL;

            byte[] b = new byte[arraySize];
            Volume vol = volumes.get(fileNum);
            vol.getData(dataOffset, b, 0, arraySize);

            dirtyStackPages.put(pageOffset, b);
            return b;
        }


        int pageSize = (int) (parity4Get(vol.getLong(pageOffset)) >>> 48);
        page = new byte[pageSize];
        vol.getData(pageOffset, page, 0, pageSize);
        dirtyStackPages.put(pageOffset, page);
        return page;
    }

    @Override
    protected <A> A get2(long recid, Serializer<A> serializer) {
        if (CC.ASSERT)
            assertReadLocked(recid);
        int segment = lockPos(recid);


        {
            Object cached = writeCache[segment].get1(recid);
            if (cached != null) {
                if(cached==TOMBSTONE2)
                    return null;
                return (A) cached;
            }
        }

        {
            long walval = currLongLongs[segment].get(recidToOffset(recid));
            if(walval==0) {
                walval = prevLongLongs[segment].get(recidToOffset(recid));
            }

            if(walval!=0){
                if(compactionInProgress){

                    if(walval==Long.MAX_VALUE) 
                        return null;
                    final int fileNum = (int) (walval>>>(5*8));
                    Volume recVol = walRec.get(fileNum);
                    long offset = walval&0xFFFFFFFFFFL; 
                    if(CC.ASSERT){
                        int instruction = recVol.getUnsignedByte(offset);
                        if(instruction!=(5<<4))
                            throw new AssertionError("wrong instruction");
                        if(recid!=recVol.getSixLong(offset+1))
                            throw new AssertionError("wrong recid");
                    }


                    offset+=1+6;
                    final int size = recVol.getInt(offset);

                    final DataInput in = size==0?
                            new DataIO.DataInputByteArray(new byte[0]):
                            recVol.getDataInput(offset+4,size);

                    return deserialize(serializer, size, in);
                }


                boolean linked = (walval&MLINKED)!=0;
                int size = (int) (walval>>>48);
                if(linked && size==0)
                    return null;
                if(size==0){
                    return deserialize(serializer,0,new DataIO.DataInputByteArray(new byte[0]));
                }
                if(linked)try {

                    int totalSize = 0;
                    byte[] in = new byte[100];
                    long link = walval;
                    while((link&MLINKED)!=0){
                        DataInput in2 = walGetData(link&MOFFSET, segment);
                        int chunkSize = (int) (link>>>48);

                        link = in2.readLong();

                        if(in.length<totalSize+chunkSize-8){
                            in = Arrays.copyOf(in, Math.max(in.length*2,totalSize+chunkSize-8 ));
                        }
                        in2.readFully(in,totalSize, chunkSize-8);
                        totalSize+=chunkSize-8;
                    }


                    DataInput in2 = walGetData(link&MOFFSET, segment);
                    int chunkSize = (int) (link>>>48);

                    if(in.length<totalSize+chunkSize){
                        in = Arrays.copyOf(in, Math.max(in.length*2,totalSize+chunkSize ));
                    }
                    in2.readFully(in,totalSize, chunkSize);
                    totalSize+=chunkSize;

                    return deserialize(serializer, totalSize,new DataIO.DataInputByteArray(in,0));
                } catch (IOException e) {
                    throw new IOError(e);
                }


                DataInput in = walGetData(walval&MOFFSET, segment);
                return deserialize(serializer, (int) (walval>>>48),in);
            }
        }

        long[] offsets = offsetsGet(indexValGet(recid));
        if (offsets == null) {
            return null; 
        }else if (offsets.length==0){
            return deserialize(serializer,0,new DataIO.DataInputByteArray(new byte[0]));
        }else if (offsets.length == 1) {

            int size = (int) (offsets[0] >>> 48);
            long offset = offsets[0] & MOFFSET;
            DataInput in = vol.getDataInput(offset, size);
            return deserialize(serializer, size, in);
        } else {

            int totalSize = offsetsTotalSize(offsets);


            byte[] b = new byte[totalSize];
            int bpos = 0;
            for (int i = 0; i < offsets.length; i++) {
                int plus = (i == offsets.length - 1)?0:8;
                long size = (offsets[i] >>> 48) - plus;
                if(CC.ASSERT && (size&0xFFFF)!=size)
                    throw new AssertionError("size mismatch");
                long offset = offsets[i] & MOFFSET;
                vol.getData(offset + plus, b, bpos, (int) size);
                bpos += size;
            }
            if (CC.ASSERT && bpos != totalSize)
                throw new AssertionError("size does not match");

            DataInput in = new DataIO.DataInputByteArray(b);
            return deserialize(serializer, totalSize, in);
        }

    }

    @Override
    public void rollback() throws UnsupportedOperationException {
        commitLock.lock();
        try {

            for (int segment = 0; segment < locks.length; segment++) {
                Lock lock = locks[segment].writeLock();
                lock.lock();
                try {
                    writeCache[segment].clear();
                    if(caches!=null) {
                        caches[segment].clear();
                    }
                } finally {
                    lock.unlock();
                }
            }

            structuralLock.lock();
            try {
                dirtyStackPages.clear();


                byte[] b = new byte[(int) HEAD_END];

                headVolBackup.getData(0,b,0,b.length);
                headVol.putData(0,b,0,b.length);

                lastAllocatedData = parity3Get(headVol.getLong(LAST_PHYS_ALLOCATED_DATA_OFFSET));

                indexPages = indexPagesBackup.clone();
            } finally {
                structuralLock.unlock();
            }
        }finally {
            commitLock.unlock();
        }
    }

    @Override
    public void commit() {
        commitLock.lock();
        try{

            if(compactionInProgress){

                String recvalName = getWalFileName("r"+walRec.size());
                Volume v = volumeFactory.makeVolume(recvalName, readonly);
                walRec.add(v);
                v.ensureAvailable(16);
                long offset = 16;

                for(int segment=0;segment<locks.length;segment++) {
                    Lock lock = locks[segment].writeLock();
                    lock.lock();
                    try {
                        LongObjectObjectMap<Object,Serializer> writeCache1 = writeCache[segment];
                        LongLongMap prevLongs = prevLongLongs[segment];
                        long[] set = writeCache1.set;
                        Object[] values = writeCache1.values;
                        for(int i=0;i<set.length;i++){
                            long recid = set[i];
                            if(recid==0)
                                continue;
                            Object value = values[i*2];
                            DataOutputByteArray buf;
                            int size;
                            if (value == TOMBSTONE2) {
                                buf = null;
                                size = -2;
                            } else {
                                Serializer s = (Serializer) values[i*2+1];
                                buf = serialize(value, s); 
                                size = buf==null?-1:buf.pos;
                            }

                            int needed = 1+6+4 +(buf==null?0:buf.pos); 



                            prevLongs.put(recidToOffset(recid),
                                    (((long)fileNum)<<(5*8)) |  
                                    offset                  
                                    );

                            v.putUnsignedByte(offset, (5<<4));
                            offset++;

                            v.putSixLong(offset, recid);
                            offset+=6;

                            v.putInt(offset, size);
                            offset+=4;

                            if(size>0) {
                                v.putData(offset, buf.buf, 0, size);
                                offset+=size;
                            }

                            if(buf!=null)
                                recycledDataOut.lazySet(buf);

                        }
                        writeCache1.clear();

                    } finally {
                        lock.unlock();
                    }
                }
                structuralLock.lock();
                try {

                    v.putUnsignedByte(offset, 0);
                    v.sync();
                    v.putLong(8, StoreWAL.WAL_SEAL);
                    v.sync();
                    return;
                }finally {
                    structuralLock.unlock();
                }
            }


            if(volumes.size()>FULL_REPLAY_AFTER_N_TX && !compactionInProgress) {
                commitFullWALReplay();
                return;
            }



            for(int segment=0;segment<locks.length;segment++){
                Lock lock = locks[segment].writeLock();
                lock.lock();
                try{
                    flushWriteCacheSegment(segment);

                    long[] v = currLongLongs[segment].table;
                    for(int i=0;i<v.length;i+=2){
                        long offset = v[i];
                        if(offset==0)
                            continue;
                        long value = v[i+1];
                        prevLongLongs[segment].put(offset,value);
                        walPutLong(offset,value);
                        if(checksum && offset>HEAD_END && offset%PAGE_SIZE!=0) {
                            walPutUnsignedShort(offset + 8, DataIO.longHash(value) & 0xFFFF);
                        }
                    }
                    currLongLongs[segment].clear();

                    v = currDataLongs[segment].table;
                    currDataLongs[segment].size=0;
                    for(int i=0;i<v.length;i+=2){
                        long offset = v[i];
                        if(offset==0)
                            continue;
                        long value = v[i+1];
                        prevDataLongs[segment].put(offset,value);
                    }
                    currDataLongs[segment].clear();

                }finally {
                    lock.unlock();
                }
            }
            structuralLock.lock();
            try {

                {
                    long[] set = dirtyStackPages.set;
                    for(int i=0;i<set.length;i++){
                        long offset = set[i];
                        if(offset==0)
                            continue;
                        byte[] val = (byte[]) dirtyStackPages.values[i];

                        if (CC.ASSERT && offset < PAGE_SIZE)
                            throw new AssertionError();
                        if (CC.ASSERT && val.length % 16 != 0)
                            throw new AssertionError();
                        if (CC.ASSERT && val.length <= 0 || val.length > MAX_REC_SIZE)
                            throw new AssertionError();

                        putDataSingleWithoutLink(-1, offset, val, 0, val.length);

                    }
                    dirtyStackPages.clear();
                }

                headVol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET,parity3Set(lastAllocatedData));

                headVol.putInt(HEAD_CHECKSUM, headChecksum(headVol));


                byte[] b = new byte[(int) HEAD_END-4];

                headVol.getData(4, b, 0, b.length);

                putDataSingleWithoutLink(-1, 4L, b, 0, b.length);


                headVolBackup.putData(4, b, 0, b.length);
                indexPagesBackup = indexPages.clone();

                long finalOffset = walOffset.get();
                curVol.ensureAvailable(finalOffset + 1); 

                curVol.putUnsignedByte(finalOffset, (0 << 4) | (Long.bitCount(finalOffset)&15));
                curVol.sync();

                curVol.putLong(8, WAL_SEAL);
                curVol.sync();

                walStartNextFile();

            } finally {
                structuralLock.unlock();
            }
        }finally {
            commitLock.unlock();
        }
    }

    protected void commitFullWALReplay() {
        if(CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();




        for(int i=0;i<locks.length;i++){
            locks[i].writeLock().lock();
        }
        try {

            for(int segment=0;segment<locks.length;segment++){
                flushWriteCacheSegment(segment);

                long[] v = currLongLongs[segment].table;
                for(int i=0;i<v.length;i+=2){
                    long offset = v[i];
                    if(offset==0)
                        continue;
                    long value = v[i+1];
                    walPutLong(offset,value);
                    if(checksum && offset>HEAD_END && offset%PAGE_SIZE!=0) {
                        walPutUnsignedShort(offset + 8, DataIO.longHash(value) & 0xFFFF);
                    }


                    v[i] = 0;
                    v[i+1] = 0;
                }
                currLongLongs[segment].clear();

                if(CC.ASSERT && currLongLongs[segment].size()!=0)
                    throw new AssertionError();

                currDataLongs[segment].clear();
                prevDataLongs[segment].clear();
                prevLongLongs[segment].clear();
            }
            structuralLock.lock();
            try {

                {
                    long[] set = dirtyStackPages.set;
                    for(int i=0;i<set.length;i++){
                        long offset = set[i];
                        if(offset==0)
                            continue;
                        byte[] val = (byte[]) dirtyStackPages.values[i];

                        if (CC.ASSERT && offset < PAGE_SIZE)
                            throw new AssertionError();
                        if (CC.ASSERT && val.length % 16 != 0)
                            throw new AssertionError();
                        if (CC.ASSERT && val.length <= 0 || val.length > MAX_REC_SIZE)
                            throw new AssertionError();

                        putDataSingleWithoutLink(-1, offset, val, 0, val.length);
                    }
                    dirtyStackPages.clear();
                }
                if(CC.ASSERT && dirtyStackPages.size!=0)
                    throw new AssertionError();

                pageLongStack.clear();

                headVol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET,parity3Set(lastAllocatedData));


                headVol.putInt(HEAD_CHECKSUM, headChecksum(headVol));


                byte[] b = new byte[(int) HEAD_END-4];

                headVol.getData(4, b, 0, b.length);

                putDataSingleWithoutLink(-1, 4L, b, 0, b.length);


                headVolBackup.putData(4, b, 0, b.length);
                indexPagesBackup = indexPages.clone();

                long finalOffset = walOffset.get();
                curVol.ensureAvailable(finalOffset+1); 

                curVol.putUnsignedByte(finalOffset, (0<<4) | (Long.bitCount(finalOffset)&15));
                curVol.sync();

                curVol.putLong(8, WAL_SEAL);
                curVol.sync();


                replayWAL();

                walStartNextFile();
            } finally {
                structuralLock.unlock();
            }
        }finally {
            for(int i=locks.length-1;i>=0;i--){
                locks[i].writeLock().unlock();
            }
        }
    }


    protected void replayWAL(){




        final boolean compaction =
                walC!=null && !walC.isEmpty() &&
                walCCompact!=null && !walCCompact.isEmpty();


        if(compaction){

            walC.ensureAvailable(16);
            boolean walCSeal = walC.getLong(8) == WAL_SEAL;



            if(!walCSeal){
                LOG.warning("Compaction failed, seal not present. Removing incomplete compacted file, keeping old fragmented file.");
                walC.close();
                walC.deleteFile();
                walC = null;
                walCCompact.close();
                walCCompact.deleteFile();
                walCCompact = null;
            }else{


                if(vol.getFile()==null){


                    Volume oldVol = this.vol;
                    this.realVol = walCCompact;
                    this.vol = new Volume.ReadOnly(realVol);
                    this.headVol.close();
                    this.headVolBackup.close();
                    initHeadVol();

                    oldVol.close();
                }else{

                    File walCCompactFile = walCCompact.getFile();
                    walCCompact.sync();
                    walCCompact.close();
                    walCCompact = null;

                    File thisFile = new File(fileName);
                    File thisFileBackup = new File(fileName+".wal.c.orig");

                    this.vol.close();
                    if(!thisFile.renameTo(thisFileBackup)){

                        throw new AssertionError("failed to rename file " + thisFile);
                    }


                    if (!walCCompactFile.renameTo(thisFile)) {

                        throw new AssertionError("failed to rename file " + walCCompactFile);
                    }


                    this.realVol = volumeFactory.makeVolume(this.fileName, readonly);
                    this.vol = new Volume.ReadOnly(this.realVol);
                    this.initHeadVol();


                    if(!thisFileBackup.delete()){
                        LOG.warning("Could not delete original compacted file: "+thisFileBackup);
                    }
                }
                walC.close();
                walC.deleteFile();
                walC = null;

                initOpenPost();
            }
        }

        if(!walRec.isEmpty()){








            structuralLock.lock();
            try {
                walStartNextFile();
            }finally {
                structuralLock.unlock();
            }

            for(Volume wr:walRec){
                if(wr.isEmpty())
                    break;
                wr.ensureAvailable(16); 
                if(wr.getLong(8)!=StoreWAL.WAL_SEAL)
                    break;
                long pos = 16;
                for(;;) {
                    int instr = wr.getUnsignedByte(pos++);
                    if (instr >>> 4 == 0) {

                        break;
                    } else if (instr >>> 4 != 5) {

                        throw new AssertionError("Invalid instruction in WAL REC" + (instr >>> 4));
                    }

                    long recid = wr.getSixLong(pos);
                    pos += 6;
                    int size = wr.getInt(pos);

                    pos += 4;
                    byte[] arr = new byte[size]; 
                    wr.getData(pos, arr, 0, size);
                    pos += size;
                    update(recid, arr, Serializer.BYTE_ARRAY_NOSIZE);
                }
            }
            List<Volume> l = new ArrayList(walRec);
            walRec.clear();
            commitFullWALReplay();

            for(Volume wr:l){
                File f = wr.getFile();
                wr.close();
                wr.deleteFile();
                if(f!=null && f.exists() && !f.delete()){
                    LOG.warning("Could not delete WAL REC file: "+f);
                }
            }
            walRec.clear();
        }


        replayWALInstructionFiles();
    }

    private void replayWALInstructionFiles() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();

        file:for(Volume wal:volumes){
            if(wal.isEmpty()) {
                break file;
            }
            if(wal.getLong(8)!=WAL_SEAL) {
                break file;

            }

            long pos = 16;
            for(;;) {
                int checksum = wal.getUnsignedByte(pos++);
                int instruction = checksum>>>4;
                checksum = (checksum&15);
                if (instruction == 0) {

                    if((Long.bitCount(pos-1)&15) != checksum)
                        throw new InternalError("WAL corrupted");
                    continue file;
                } else if (instruction == 1) {

                    long val = wal.getLong(pos);
                    pos += 8;
                    long offset = wal.getSixLong(pos);
                    pos += 6;
                    if(((1+Long.bitCount(val)+Long.bitCount(offset))&15)!=checksum)
                        throw new InternalError("WAL corrupted");
                    realVol.ensureAvailable(offset+8);
                    realVol.putLong(offset, val);
                } else if (instruction == 2) {

                    int dataSize = wal.getUnsignedShort(pos);
                    pos += 2;
                    long offset = wal.getSixLong(pos);
                    pos += 6;
                    byte[] data = new byte[dataSize];
                    wal.getData(pos, data, 0, data.length);
                    pos += data.length;
                    if(((1+Integer.bitCount(dataSize)+Long.bitCount(offset)+sum(data))&15)!=checksum)
                        throw new InternalError("WAL corrupted");

                    realVol.ensureAvailable(offset+data.length);
                    realVol.putData(offset, data, 0, data.length);
                } else if (instruction == 3) {

                    int skipN = wal.getInt(pos - 1) & 0xFFFFFF; 
                    if((Integer.bitCount(skipN)&15) != checksum)
                        throw new InternalError("WAL corrupted");
                    pos += 3 + skipN;
                } else if (instruction == 4) {

                    if((Long.bitCount(pos-1)&15) != checksum)
                        throw new InternalError("WAL corrupted");
                } else if (instruction == 6) {

                    long s = wal.getLong(pos);
                    pos+=8;
                    if(((1+Long.bitCount(s))&15) != checksum)
                        throw new InternalError("WAL corrupted");
                    long offset = s&0xFFFFFFFFFFFFL;
                    realVol.ensureAvailable(offset + 2);
                    realVol.putUnsignedShort(offset, (int) (s>>>48));
                }else{
                    throw new InternalError("WAL corrupted, unknown instruction");
                }

            }
        }

        realVol.sync();


        for(Volume wal:volumes){
            wal.truncate(0);
            wal.close();
            wal.deleteFile();

        }
        fileNum = -1;
        curVol = null;
        volumes.clear();
    }

    private int sum(byte[] data) {
        int ret = 0;
        for(byte b:data){
            ret+=b;
        }
        return Math.abs(ret);
    }

    private int sum(byte[] buf, int bufPos, int size) {
        int ret = 0;
        size+=bufPos;
        while(bufPos<size){
            ret+=buf[bufPos++];
        }
        return Math.abs(ret);
    }


    @Override
    public boolean canRollback() {
        return true;
    }

    @Override
    public void close() {
        compactLock.lock();
        try{
            commitLock.lock();
            try{

                if(closed) {
                    return;
                }

                if(hasUncommitedData()){
                    LOG.warning("Closing storage with uncommited data, those data will be discarted.");
                }



                if(!readonly) {
                    structuralLock.lock();
                    try {
                        replayWAL();
                    } finally {
                        structuralLock.unlock();
                    }
                }

                if(walC!=null)
                    walC.close();
                if(walCCompact!=null)
                    walCCompact.close();


                for(Volume v:walRec){
                    v.close();
                }
                walRec.clear();


                for(Volume v:volumes){
                    v.close();
                }
                volumes.clear();

                vol.close();
                vol = null;

                headVol.close();
                headVol = null;
                headVolBackup.close();
                headVolBackup = null;

                curVol = null;
                dirtyStackPages.clear();

                if(caches!=null){
                    for(Cache c:caches){
                        c.close();
                    }
                    Arrays.fill(caches,null);
                }
                closed = true;
            }finally {
                commitLock.unlock();
            }
        }finally {
            compactLock.unlock();
        }
    }

    @Override
    public void compact() {
        compactLock.lock();

        try{

            if(compactOldFilesExists())
                return;

            commitLock.lock();
            try{

                if(hasUncommitedData()){

                    LOG.warning("Compaction started with uncommited data. Calling commit automatically.");
                }

                snapshotCloseAllOnCompact();


                commitFullWALReplay();

                compactionInProgress = true;


                structuralLock.lock();
                try {
                    if(CC.ASSERT && fileNum!=0)
                        throw new AssertionError();
                    if(CC.ASSERT && walC!=null)
                        throw new AssertionError();


                    String walCFileName = getWalFileName("c");
                    if(walC!=null)
                        walC.close();
                    walC = volumeFactory.makeVolume(walCFileName, readonly);
                    walC.ensureAvailable(16);
                    walC.putLong(0,0); 
                    walC.putLong(8,0);

                }finally {
                    structuralLock.unlock();
                }
            }finally {
                commitLock.unlock();
            }

            final long maxRecidOffset = parity1Get(headVol.getLong(MAX_RECID_OFFSET));


            final String targetFile = getWalFileName("c.compact");

            final StoreDirect target = new StoreDirect(targetFile,
                    volumeFactory,
                    null,lockScale,
                    executor==null?LOCKING_STRATEGY_NOLOCK:LOCKING_STRATEGY_WRITELOCK,
                    checksum,compress,null,false,false,0,false,0,
                    null);
            target.init();
            walCCompact = target.vol;

            final AtomicLong maxRecid = new AtomicLong(RECID_LAST_RESERVED);

            compactIndexPages(maxRecidOffset, target, maxRecid);

            while($_TEST_HACK_COMPACT_PRE_COMMIT_WAIT){
                LockSupport.parkNanos(10000);
            }


            target.vol.putLong(MAX_RECID_OFFSET, parity1Set(maxRecid.get() * indexValSize));


            target.commit(); 

            walC.putLong(8, WAL_SEAL);
            walC.sync();


            commitLock.lock();
            try{

                if(hasUncommitedData()){
                    LOG.warning("Uncommited data at end of compaction, autocommit");

                }

                commitFullWALReplay();

                compactionInProgress = false;
            }finally {
                commitLock.unlock();
            }

            while($_TEST_HACK_COMPACT_POST_COMMIT_WAIT){
                LockSupport.parkNanos(10000);
            }

        }finally {
            compactionInProgress = false; 
            compactLock.unlock();
        }
    }


    protected boolean hasUncommitedData() {
        for(int i=0;i<locks.length;i++){
            final Lock lock  = locks[i].readLock();
            lock.lock();
            try{
                if(currLongLongs[i].size()!=0 ||
                        currDataLongs[i].size()!=0 ||
                        writeCache[i].size!=0)
                    return true;
            }finally {
                lock.unlock();
            }
        }
        return false;
    }
}

<code block>
package org.mapdb;

import java.util.Arrays;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.Lock;

import static org.mapdb.DataIO.*;


public class StoreCached extends StoreDirect {




    protected final LongObjectMap<byte[]> dirtyStackPages = new LongObjectMap<byte[]>();
    protected final LongObjectObjectMap[] writeCache;

    protected final static Object TOMBSTONE2 = new Object(){
        @Override
        public String toString() {
            return StoreCached.class.getName()+".TOMBSTONE2";
        }
    };

    protected final int writeQueueSize;
    protected final int writeQueueSizePerSegment;
    protected final boolean flushInThread;

    public StoreCached(
            String fileName,
            Volume.VolumeFactory volumeFactory,
            Cache cache,
            int lockScale,
            int lockingStrategy,
            boolean checksum,
            boolean compress,
            byte[] password,
            boolean readonly,
            boolean snapshotEnable,
            int freeSpaceReclaimQ,
            boolean commitFileSyncDisable,
            int sizeIncrement,
            ScheduledExecutorService executor,
            long executorScheduledRate,
            final int writeQueueSize) {
        super(fileName, volumeFactory, cache,
                lockScale,
                lockingStrategy,
                checksum, compress, password, readonly, snapshotEnable,
                freeSpaceReclaimQ, commitFileSyncDisable, sizeIncrement,executor);

        this.writeQueueSize = writeQueueSize;
        this.writeQueueSizePerSegment = writeQueueSize/lockScale;

        writeCache = new LongObjectObjectMap[this.lockScale];
        for (int i = 0; i < writeCache.length; i++) {
            writeCache[i] = new LongObjectObjectMap();
        }

        flushInThread = this.executor==null &&
                writeQueueSize!=0 &&
                !(this instanceof StoreWAL); 

        if(this.executor!=null &&
                !(this instanceof StoreWAL) 
                ){
            for(int i=0;i<this.lockScale;i++){
                final int seg = i;
                final Lock lock = locks[i].writeLock();
                this.executor.scheduleAtFixedRate(new Runnable() {
                    @Override
                    public void run() {
                        lock.lock();
                        try {
                            if(writeCache[seg].size>writeQueueSizePerSegment) {
                                flushWriteCacheSegment(seg);
                            }
                        }finally {
                            lock.unlock();
                        }
                    }
                    },
                        (long) (executorScheduledRate*Math.random()),
                        executorScheduledRate,
                        TimeUnit.MILLISECONDS);
            }
        }
    }


    public StoreCached(String fileName) {
        this(fileName,
                fileName==null? CC.DEFAULT_MEMORY_VOLUME_FACTORY : CC.DEFAULT_FILE_VOLUME_FACTORY,
                null,
                CC.DEFAULT_LOCK_SCALE,
                0,
                false, false, null, false, false, 0,
                false, 0,
                null, 0L, 0);
    }



    @Override
    protected void initHeadVol() {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        if(this.headVol!=null && !this.headVol.isClosed())
            headVol.close();
        this.headVol = new Volume.SingleByteArrayVol((int) HEAD_END);
        vol.transferInto(0,headVol,0,HEAD_END);
    }


    @Override
    protected void longStackPut(long masterLinkOffset, long value, boolean recursive) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if (CC.ASSERT && (masterLinkOffset <= 0 || masterLinkOffset > PAGE_SIZE || masterLinkOffset % 8 != 0))
            throw new AssertionError();

        long masterLinkVal = parity4Get(headVol.getLong(masterLinkOffset));
        long pageOffset = masterLinkVal & MOFFSET;

        if (masterLinkVal == 0L) {
            longStackNewPage(masterLinkOffset, 0L, value);
            return;
        }

        byte[] page = loadLongStackPage(pageOffset);

        long currSize = masterLinkVal >>> 48;

        long prevLinkVal = parity4Get(DataIO.getLong(page, 0));
        long pageSize = prevLinkVal >>> 48;

        if (currSize + 8 >= pageSize) {


            Arrays.fill(page, (int) currSize, (int) pageSize, (byte) 0);

            longStackNewPage(masterLinkOffset, pageOffset, value);
            return;
        }


        currSize += DataIO.packLongBidi(page, (int) currSize, longParitySet(value));


        headVol.putLong(masterLinkOffset, parity4Set(currSize << 48 | pageOffset));
    }

    @Override
    protected long longStackTake(long masterLinkOffset, boolean recursive) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if (CC.ASSERT && (masterLinkOffset < FREE_RECID_STACK ||
                masterLinkOffset > FREE_RECID_STACK + round16Up(MAX_REC_SIZE) / 2 ||
                masterLinkOffset % 8 != 0))
            throw new AssertionError();

        long masterLinkVal = parity4Get(headVol.getLong(masterLinkOffset));
        if (masterLinkVal == 0) {
            return 0;
        }
        long currSize = masterLinkVal >>> 48;
        final long pageOffset = masterLinkVal & MOFFSET;

        byte[] page = loadLongStackPage(pageOffset);


        long ret = DataIO.unpackLongBidiReverse(page, (int) currSize);

        long oldCurrSize = currSize;
        currSize -= ret >>> 56;

        Arrays.fill(page, (int) currSize, (int) oldCurrSize, (byte) 0);

        ret = longParityGet(ret & DataIO.PACK_LONG_RESULT_MASK);

        if (CC.ASSERT && currSize < 8)
            throw new AssertionError();


        if (currSize > 8) {

            headVol.putLong(masterLinkOffset, parity4Set(currSize << 48 | pageOffset));
            return ret;
        }


        long prevPageOffset = parity4Get(DataIO.getLong(page, 0));
        final int currPageSize = (int) (prevPageOffset >>> 48);
        prevPageOffset &= MOFFSET;


        if (prevPageOffset != 0) {


            byte[] page2 = loadLongStackPage(prevPageOffset);





            currSize = parity4Get(DataIO.getLong(page2, 0)) >>> 48;


            while (page2[((int) (currSize - 1))] == 0) {
                currSize--;
            }

            if (CC.ASSERT && currSize < 10)
                throw new AssertionError();
        } else {

            currSize = 0;
        }


        headVol.putLong(masterLinkOffset, parity4Set(currSize << 48 | prevPageOffset));


        dirtyStackPages.remove(pageOffset);
        freeDataPut(pageOffset, currPageSize);


        return ret;
    }

    protected byte[] loadLongStackPage(long pageOffset) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        byte[] page = dirtyStackPages.get(pageOffset);
        if (page == null) {
            int pageSize = (int) (parity4Get(vol.getLong(pageOffset)) >>> 48);
            page = new byte[pageSize];
            vol.getData(pageOffset, page, 0, pageSize);
            dirtyStackPages.put(pageOffset, page);
        }
        return page;
    }

    @Override
    protected void longStackNewPage(long masterLinkOffset, long prevPageOffset, long value) {
        if (CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        long newPageOffset = freeDataTakeSingle((int) CHUNKSIZE);
        byte[] page = new byte[(int) CHUNKSIZE];


        dirtyStackPages.put(newPageOffset, page);

        DataIO.putLong(page, 0, parity4Set((CHUNKSIZE << 48) | prevPageOffset));

        long currSize = 8 + DataIO.packLongBidi(page, 8, longParitySet(value));

        headVol.putLong(masterLinkOffset, parity4Set((currSize << 48) | newPageOffset));
    }

    @Override
    protected void flush() {
        if (CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();

        if (isReadOnly())
            return;
        flushWriteCache();


        structuralLock.lock();
        try {

            long[] set = dirtyStackPages.set;
            for(int i=0;i<set.length;i++){
                long offset = set[i];
                if(offset==0)
                    continue;
                byte[] val = (byte[]) dirtyStackPages.values[i];

                if (CC.ASSERT && offset < PAGE_SIZE)
                    throw new AssertionError();
                if (CC.ASSERT && val.length % 16 != 0)
                    throw new AssertionError();
                if (CC.ASSERT && val.length <= 0 || val.length > MAX_REC_SIZE)
                    throw new AssertionError();

                vol.putData(offset, val, 0, val.length);
            }
            dirtyStackPages.clear();
            headVol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET,parity3Set(lastAllocatedData));

            headVol.putInt(HEAD_CHECKSUM, headChecksum(headVol));

            byte[] buf = new byte[(int) HEAD_END]; 
            headVol.getData(0, buf, 0, buf.length);
            vol.putData(0, buf, 0, buf.length);
        } finally {
            structuralLock.unlock();
        }
        vol.sync();
    }

    protected void flushWriteCache() {
        if (CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();


        for (int i = 0; i < locks.length; i++) {
            Lock lock = locks[i].writeLock();
            lock.lock();
            try {
                flushWriteCacheSegment(i);

            } finally {
                lock.unlock();
            }
        }
    }

    protected void flushWriteCacheSegment(int segment) {
        if (CC.ASSERT)
            assertWriteLocked(segment);

        LongObjectObjectMap writeCache1 = writeCache[segment];
        long[] set = writeCache1.set;
        Object[] values = writeCache1.values;
        for(int i=0;i<set.length;i++){
            long recid = set[i];
            if(recid==0)
                continue;
            Object value = values[i*2];
            if (value == TOMBSTONE2) {
                super.delete2(recid, Serializer.ILLEGAL_ACCESS);
            } else {
                Serializer s = (Serializer) values[i*2+1];
                DataOutputByteArray buf = serialize(value, s); 
                super.update2(recid, buf);
                recycledDataOut.lazySet(buf);
            }
        }
        writeCache1.clear();

        if (CC.ASSERT && writeCache[segment].size!=0)
            throw new AssertionError();
    }



    @Override
    protected <A> A get2(long recid, Serializer<A> serializer) {
        LongObjectObjectMap m = writeCache[lockPos(recid)];
        Object cached = m.get1(recid);
        if (cached !=null) {
            if(cached==TOMBSTONE2)
                return null;
            return (A) cached;
        }
        return super.get2(recid, serializer);
    }

    @Override
    protected <A> void delete2(long recid, Serializer<A> serializer) {
        if (serializer == null)
            throw new NullPointerException();
        int lockPos = lockPos(recid);

        LongObjectObjectMap map = writeCache[lockPos];
        map.put(recid, TOMBSTONE2, null);

        if(flushInThread && map.size>writeQueueSize){
            flushWriteCacheSegment(lockPos);
        }
    }

    @Override
    public <A> long put(A value, Serializer<A> serializer) {
        if (serializer == null)
            throw new NullPointerException();


        long recid = preallocate();
        update(recid, value, serializer);
        return recid;
    }

    @Override
    public <A> void update(long recid, A value, Serializer<A> serializer) {
        if (serializer == null)
            throw new NullPointerException();

        int lockPos = lockPos(recid);
        Cache cache = caches==null ? null : caches[lockPos];
        Lock lock = locks[lockPos].writeLock();
        lock.lock();
        try {
            if(cache!=null) {
                cache.put(recid, value);
            }
            LongObjectObjectMap map = writeCache[lockPos];
            map.put(recid, value, serializer);
            if(flushInThread && map.size>writeQueueSizePerSegment){
                flushWriteCacheSegment(lockPos);
            }

        } finally {
            lock.unlock();
        }
    }


    @Override
    public <A> boolean compareAndSwap(long recid, A expectedOldValue, A newValue, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();


        final int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].writeLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        LongObjectObjectMap<A,Serializer<A>> map = writeCache[lockPos];
        lock.lock();
        try{
            A oldVal = cache==null ? null : (A) cache.get(recid);
            if(oldVal == null) {
                oldVal = get2(recid, serializer);
            }else if(oldVal == Cache.NULL){
                oldVal = null;
            }
            if(oldVal==expectedOldValue || (oldVal!=null && serializer.equals(oldVal,expectedOldValue))){
                if(cache!=null) {
                    cache.put(recid, newValue);
                }
                map.put(recid,newValue,serializer);
                if(flushInThread && map.size>writeQueueSizePerSegment){
                    flushWriteCacheSegment(lockPos);
                }

                return true;
            }
            return false;
        }finally {
            lock.unlock();
        }
    }


}

<code block>
package org.mapdb;

import java.io.DataInput;
import java.io.File;
import java.util.*;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.locks.Lock;
import java.util.logging.Level;

import static org.mapdb.DataIO.*;

public class StoreDirect extends Store {


    protected static final int STORE_VERSION = 100;


    protected static final int HEADER = (0xA9DB<<16) | STORE_VERSION;


    protected static final long PAGE_SIZE = 1<< CC.VOLUME_PAGE_SHIFT;
    protected static final long PAGE_MASK = PAGE_SIZE-1;
    protected static final long PAGE_MASK_INVERSE = 0xFFFFFFFFFFFFFFFFL<<CC.VOLUME_PAGE_SHIFT;


    protected static final long MOFFSET = 0x0000FFFFFFFFFFF0L;

    protected static final long MLINKED = 0x8L;
    protected static final long MUNUSED = 0x4L;
    protected static final long MARCHIVE = 0x2L;
    protected static final long MPARITY = 0x1L;


    protected static final long STORE_SIZE = 8*2;

    protected static final long MAX_RECID_OFFSET = 8*3;
    protected static final long LAST_PHYS_ALLOCATED_DATA_OFFSET = 8*4; 
    protected static final long FREE_RECID_STACK = 8*5;


    protected static final long UNUSED1 = 8*6;
    protected static final long UNUSED2 = 8*7;
    protected static final long UNUSED3 = 8*8;
    protected static final long UNUSED4 = 8*9;
    protected static final long UNUSED5 = 8*10;


    protected static final int MAX_REC_SIZE = 0xFFFF;

    protected static final int SLOTS_COUNT = 2+(MAX_REC_SIZE)/16; 

    protected static final long HEAD_END = UNUSED5 + SLOTS_COUNT * 8;


    protected static final long INITCRC_INDEX_PAGE = 4329042389490239043L;

    private static final long[] EMPTY_LONGS = new long[0];



    protected volatile Volume vol;
    protected volatile Volume headVol;


    protected volatile long[] indexPages;

    protected volatile long lastAllocatedData=0; 

    protected final ScheduledExecutorService executor;

    protected final List<Snapshot> snapshots;

    protected final long indexValSize;

    public StoreDirect(String fileName,
                       Volume.VolumeFactory volumeFactory,
                       Cache cache,
                       int lockScale,
                       int lockingStrategy,
                       boolean checksum,
                       boolean compress,
                       byte[] password,
                       boolean readonly,
                       boolean snapshotEnable,
                       int freeSpaceReclaimQ,
                       boolean commitFileSyncDisable,
                       int sizeIncrement,
                       ScheduledExecutorService executor
                       ) {
        super(fileName,volumeFactory, cache, lockScale, lockingStrategy, checksum,compress,password,readonly, snapshotEnable);
        this.vol = volumeFactory.makeVolume(fileName, readonly);
        this.executor = executor;
        this.snapshots = snapshotEnable?
                new CopyOnWriteArrayList<Snapshot>():
                null;
        this.indexValSize = checksum ? 10 : 8;
    }

    @Override
    public void init() {
        commitLock.lock();
        try {
            structuralLock.lock();
            try {
                if (vol.isEmpty()) {
                    initCreate();
                } else {
                    initOpen();
                }
            } finally {
                structuralLock.unlock();
            }
        }catch(RuntimeException e){
            initFailedCloseFiles();
            if(vol!=null && !vol.isClosed()) {
                vol.close();
            }
            vol = null;
            throw e;
        }finally {
            commitLock.unlock();
        }
    }

    protected void initFailedCloseFiles() {

    }

    protected void initOpen() {
        if(CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        int header = vol.getInt(0);
        if(header!=header){
            throw new DBException.WrongConfig("This is not MapDB file");
        }



        checkFeaturesBitmap(vol.getLong(HEAD_FEATURES));


        initHeadVol();

        int expectedChecksum = vol.getInt(HEAD_CHECKSUM);
        int actualChecksum = headChecksum(vol);
        if (actualChecksum != expectedChecksum) {
            throw new DBException.HeadChecksumBroken();
        }



        long[] ip = new long[]{0};
        long indexPage = parity16Get(vol.getLong(HEAD_END));
        int i=1;
        for(;indexPage!=0;i++){
            if(CC.ASSERT && indexPage%PAGE_SIZE!=0)
                throw new AssertionError();
            if(ip.length==i){
                ip = Arrays.copyOf(ip, ip.length * 4);
            }
            ip[i] = indexPage;


            indexPage = parity16Get(vol.getLong(indexPage));
        }
        indexPages = Arrays.copyOf(ip,i);
        lastAllocatedData = parity3Get(vol.getLong(LAST_PHYS_ALLOCATED_DATA_OFFSET));
    }

    protected void initCreate() {
        if(CC.ASSERT && !commitLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();




        indexPages = new long[]{0};

        vol.ensureAvailable(PAGE_SIZE);
        vol.clear(0, PAGE_SIZE);


        vol.putLong(STORE_SIZE, parity16Set(PAGE_SIZE));
        vol.putLong(MAX_RECID_OFFSET, parity1Set(RECID_LAST_RESERVED * indexValSize));

        vol.putLong(HEAD_END, parity16Set(0));

        lastAllocatedData = 0L;
        vol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET,parity3Set(lastAllocatedData));


        for(long recid=1;recid<RECID_FIRST;recid++){
            long indexVal = parity1Set(MLINKED | MARCHIVE);
            long indexOffset = recidToOffset(recid);
            vol.putLong(indexOffset, indexVal);
            if(checksum) {
                vol.putUnsignedShort(indexOffset + 8, DataIO.longHash(indexVal)&0xFFFF);
            }
        }


        for(long masterLinkOffset = FREE_RECID_STACK;masterLinkOffset<HEAD_END;masterLinkOffset+=8){
            vol.putLong(masterLinkOffset,parity4Set(0));
        }


        vol.putInt(0,HEADER);


        long features = makeFeaturesBitmap();

        vol.putLong(HEAD_FEATURES, features);



        vol.putInt(HEAD_CHECKSUM, headChecksum(vol));
        vol.sync();
        initHeadVol();
    }


    protected void initHeadVol() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        this.headVol = vol;
    }

    public StoreDirect(String fileName) {
        this(fileName,
                fileName==null? CC.DEFAULT_MEMORY_VOLUME_FACTORY : CC.DEFAULT_FILE_VOLUME_FACTORY,
                null,
                CC.DEFAULT_LOCK_SCALE,
                0,
                false,false,null,false,false,0,
                false,0,
                null);
    }

    protected int headChecksum(Volume vol2) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        int ret = 0;
        for(int offset = 8;
            offset< HEAD_END;
            offset+=8){
            long val = vol2.getLong(offset);
            ret += DataIO.longHash(offset+val);
        }
        return ret;
    }

    @Override
    protected <A> A get2(long recid, Serializer<A> serializer) {
        if (CC.ASSERT)
            assertReadLocked(recid);

        long[] offsets = offsetsGet(indexValGet(recid));
        return getFromOffset(serializer, offsets);
    }

    protected <A> A getFromOffset(Serializer<A> serializer, long[] offsets) {
        if (offsets == null) {
            return null; 
        }else if (offsets.length==0){
            return deserialize(serializer,0,new DataInputByteArray(new byte[0]));
        }else if (offsets.length == 1) {

            int size = (int) (offsets[0] >>> 48);
            long offset = offsets[0] & MOFFSET;
            DataInput in = vol.getDataInput(offset, size);
            return deserialize(serializer, size, in);
        } else {

            int totalSize = offsetsTotalSize(offsets);
            byte[] b = getLoadLinkedRecord(offsets, totalSize);

            DataInput in = new DataInputByteArray(b);
            return deserialize(serializer, totalSize, in);
        }
    }

    private byte[] getLoadLinkedRecord(long[] offsets, int totalSize) {

        byte[] b = new byte[totalSize];
        int bpos = 0;
        for (int i = 0; i < offsets.length; i++) {
            int plus = (i == offsets.length - 1)?0:8;
            long size = (offsets[i] >>> 48) - plus;
            if(CC.ASSERT && (size&0xFFFF)!=size)
                throw new AssertionError("size mismatch");
            long offset = offsets[i] & MOFFSET;

            vol.getData(offset + plus, b, bpos, (int) size);
            bpos += size;
        }
        if (CC.ASSERT && bpos != totalSize)
            throw new AssertionError("size does not match");
        return b;
    }

    protected int offsetsTotalSize(long[] offsets) {
        if(offsets==null || offsets.length==0)
            return 0;
        int totalSize = 8;
        for (long l : offsets) {
            totalSize += (l >>> 48) - 8;
        }
        return totalSize;
    }


    @Override
    protected void update2(long recid, DataOutputByteArray out) {
        int pos = lockPos(recid);

        if(CC.ASSERT)
            assertWriteLocked(pos);
        long oldIndexVal = indexValGet(recid);

        boolean releaseOld = true;
        if(snapshotEnable){
            for(Snapshot snap:snapshots){
                snap.oldRecids[pos].putIfAbsent(recid,oldIndexVal);
                releaseOld = false;
            }
        }

        long[] oldOffsets = offsetsGet(oldIndexVal);
        int oldSize = offsetsTotalSize(oldOffsets);
        int newSize = out==null?0:out.pos;
        long[] newOffsets;


        if(releaseOld && oldSize==newSize){


            newOffsets = oldOffsets;
        }else {
            structuralLock.lock();
            try {
                if(releaseOld && oldOffsets!=null)
                    freeDataPut(oldOffsets);
                newOffsets = newSize==0?null:freeDataTake(out.pos);

            } finally {
                structuralLock.unlock();
            }
        }

        if(CC.ASSERT)
            offsetsVerify(newOffsets);

        putData(recid, newOffsets, out==null?null:out.buf, out==null?0:out.pos);
    }

    protected void offsetsVerify(long[] linkedOffsets) {


    }



    protected long[] offsetsGet(long indexVal) {;
        if(indexVal>>>48==0){

            return ((indexVal&MLINKED)!=0) ? null : EMPTY_LONGS;
        }

        long[] ret = new long[]{indexVal};
        while((ret[ret.length-1]&MLINKED)!=0){
            ret = Arrays.copyOf(ret,ret.length+1);
            ret[ret.length-1] = parity3Get(vol.getLong(ret[ret.length-2]&MOFFSET));
        }

        if(CC.ASSERT){
            for(int i=0;i<ret.length;i++) {
                boolean last = (i==ret.length-1);
                boolean linked = (ret[i]&MLINKED)!=0;
                if(!last && !linked)
                    throw new AssertionError("body not linked");
                if(last && linked)
                    throw new AssertionError("tail is linked");

                long offset = ret[i]&MOFFSET;
                if(offset<PAGE_SIZE)
                    throw new AssertionError("offset is too small");
                if(((offset&MOFFSET)%16)!=0)
                    throw new AssertionError("offset not mod 16");

                int size = (int) (ret[i] >>>48);
                if(size<=0)
                    throw new AssertionError("size too small");
            }

        }

        return ret;
    }

    protected void indexValPut(long recid, int size, long offset, boolean linked, boolean unused) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));

        long indexOffset = recidToOffset(recid);
        long newval = composeIndexVal(size, offset, linked, unused, true);
        vol.putLong(indexOffset, newval);
        if(checksum){
            vol.putUnsignedShort(indexOffset+8, DataIO.longHash(newval)&0xFFFF);
        }
    }


    @Override
    protected <A> void delete2(long recid, Serializer<A> serializer) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));

        long oldIndexVal = indexValGet(recid);
        long[] offsets = offsetsGet(oldIndexVal);
        boolean releaseOld = true;
        if(snapshotEnable){
            int pos = lockPos(recid);
            for(Snapshot snap:snapshots){
                snap.oldRecids[pos].putIfAbsent(recid,oldIndexVal);
                releaseOld = false;
            }
        }

        if(offsets!=null && releaseOld) {
            structuralLock.lock();
            try {
                freeDataPut(offsets);
            } finally {
                structuralLock.unlock();
            }
        }
        indexValPut(recid,0,0,true,true);
    }

    @Override
    public long getCurrSize() {
        return vol.length() - lastAllocatedData % CHUNKSIZE;
    }

    @Override
    public long getFreeSize() {
        return -1; 
    }

    @Override
    public long preallocate() {
        long recid;
        structuralLock.lock();
        try {
             recid = freeRecidTake();
        }finally {
            structuralLock.unlock();
        }
        Lock lock = locks[lockPos(recid)].writeLock();
        lock.lock();
        try {
            indexValPut(recid, 0, 0L, true, true);
        }finally {
            lock.unlock();
        }
        return recid;
    }


    @Override
    public <A> long put(A value, Serializer<A> serializer) {
        long recid;
        long[] offsets;
        DataOutputByteArray out = serialize(value,serializer);
        boolean notalloc = out==null || out.pos==0;
        structuralLock.lock();
        try {
            recid = freeRecidTake();
            offsets = notalloc?null:freeDataTake(out.pos);
        }finally {
            structuralLock.unlock();
        }
        if(CC.ASSERT && offsets!=null && (offsets[0]&MOFFSET)<PAGE_SIZE)
            throw new AssertionError();

        int pos = lockPos(recid);
        Lock lock = locks[pos].writeLock();
        lock.lock();
        try {
            if(caches!=null) {
                caches[pos].put(recid, value);
            }
            if(snapshotEnable){
                for(Snapshot snap:snapshots){
                    snap.oldRecids[pos].putIfAbsent(recid,0);
                }
            }

            putData(recid, offsets, out==null?null:out.buf, out==null?0:out.pos);
        }finally {
            lock.unlock();
        }

        return recid;
    }

    protected void putData(long recid, long[] offsets, byte[] src, int srcLen) {
        if(CC.ASSERT)
            assertWriteLocked(lockPos(recid));
        if(CC.ASSERT && offsetsTotalSize(offsets)!=(src==null?0:srcLen))
            throw new AssertionError("size mismatch");

        if(offsets!=null) {
            int outPos = 0;
            for (int i = 0; i < offsets.length; i++) {
                final boolean last = (i == offsets.length - 1);
                if (CC.ASSERT && ((offsets[i] & MLINKED) == 0) != last)
                    throw new AssertionError("linked bit set wrong way");

                long offset = (offsets[i] & MOFFSET);
                if(CC.ASSERT && offset%16!=0)
                    throw new AssertionError("not aligned to 16");

                int plus = (last?0:8);
                int size = (int) ((offsets[i]>>>48) - plus);
                if(CC.ASSERT && ((size&0xFFFF)!=size || size==0))
                    throw new AssertionError("size mismatch");

                int segment = lockPos(recid);

                if (!last) {
                    putDataSingleWithLink(segment, offset,parity3Set(offsets[i + 1]), src,outPos,size);
                }else{
                    putDataSingleWithoutLink(segment, offset, src, outPos, size);
                }
                outPos += size;

            }
            if(CC.ASSERT && outPos!=srcLen)
                throw new AssertionError("size mismatch");
        }

        boolean firstLinked =
                (offsets!=null && offsets.length>1) || 
                (src==null); 
        boolean empty = offsets==null || offsets.length==0;
        int firstSize = (int) (empty ? 0L : offsets[0]>>>48);
        long firstOffset =  empty? 0L : offsets[0]&MOFFSET;
        indexValPut(recid, firstSize, firstOffset, firstLinked, false);
    }

    protected void putDataSingleWithoutLink(int segment, long offset, byte[] buf, int bufPos, int size) {
        vol.putData(offset,buf,bufPos,size);
    }

    protected void putDataSingleWithLink(int segment, long offset, long link, byte[] buf, int bufPos, int size) {
        vol.putLong(offset,link);
        vol.putData(offset+8, buf,bufPos,size);
    }

    protected void freeDataPut(long[] linkedOffsets) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        for(long v:linkedOffsets){
            int size = round16Up((int) (v >>> 48));
            v &= MOFFSET;
            freeDataPut(v,size);
        }
    }


    protected void freeDataPut(long offset, int size) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && size%16!=0 )
            throw new AssertionError();
        if(CC.ASSERT && (offset%16!=0 || offset<PAGE_SIZE))
            throw new AssertionError();

        if(!(this instanceof  StoreWAL)) 
            vol.clear(offset,offset+size);


        if(offset+size==lastAllocatedData){
            lastAllocatedData-=size;
            return;
        }

        long masterPointerOffset = size/2 + FREE_RECID_STACK; 
        longStackPut(
                masterPointerOffset,
                offset>>>4, 
                false);
    }


    protected long[] freeDataTake(int size) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && size<=0)
            throw new AssertionError();


        long[] ret = EMPTY_LONGS;
        while(size>MAX_REC_SIZE){
            ret = Arrays.copyOf(ret,ret.length+1);
            ret[ret.length-1] = (((long)MAX_REC_SIZE)<<48) | freeDataTakeSingle(round16Up(MAX_REC_SIZE)) | MLINKED;
            size = size-MAX_REC_SIZE+8;
        }

        ret = Arrays.copyOf(ret,ret.length+1);
        ret[ret.length-1] = (((long)size)<<48) | freeDataTakeSingle(round16Up(size)) ;
        return ret;
    }

    protected long freeDataTakeSingle(int size) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && size%16!=0)
            throw new AssertionError();
        if(CC.ASSERT && size>round16Up(MAX_REC_SIZE))
            throw new AssertionError();

        long masterPointerOffset = size/2 + FREE_RECID_STACK; 
        long ret = longStackTake(masterPointerOffset,false) <<4; 
        if(ret!=0) {
            if(CC.ASSERT && ret<PAGE_SIZE)
                throw new AssertionError();
            if(CC.ASSERT && ret%16!=0)
                throw new AssertionError();

            return ret;
        }

        if(lastAllocatedData==0){

            long page = pageAllocate();
            lastAllocatedData = page+size;
            if(CC.ASSERT && page<PAGE_SIZE)
                throw new AssertionError();
            if(CC.ASSERT && page%16!=0)
                throw new AssertionError();
            return page;
        }


        if((lastAllocatedData%PAGE_SIZE + size)/PAGE_SIZE !=0){

            lastAllocatedData=0;
            freeDataTakeSingle(size);




        }

        ret = lastAllocatedData;
        lastAllocatedData+=size;

        if(CC.ASSERT && ret%16!=0)
            throw new AssertionError();
        if(CC.ASSERT && lastAllocatedData%16!=0)
            throw new AssertionError();
        if(CC.ASSERT && ret<PAGE_SIZE)
            throw new AssertionError();

        return ret;
    }



    protected final static long CHUNKSIZE = 100*16;

    protected void longStackPut(final long masterLinkOffset, final long value, boolean recursive){
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && (masterLinkOffset<=0 || masterLinkOffset>PAGE_SIZE || masterLinkOffset % 8!=0)) 
            throw new AssertionError();

        long masterLinkVal = parity4Get(headVol.getLong(masterLinkOffset));
        long pageOffset = masterLinkVal&MOFFSET;

        if(masterLinkVal==0L){
            longStackNewPage(masterLinkOffset, 0L, value);
            return;
        }

        long currSize = masterLinkVal>>>48;

        long prevLinkVal = parity4Get(vol.getLong(pageOffset));
        long pageSize = prevLinkVal>>>48;

        if(currSize+8>=pageSize){ 


            vol.clear(pageOffset+currSize, pageOffset+pageSize);

            longStackNewPage(masterLinkOffset,pageOffset,value);
            return;
        }


        currSize += vol.putLongPackBidi(pageOffset+currSize, longParitySet(value));

        headVol.putLong(masterLinkOffset, parity4Set(currSize<<48 | pageOffset));
    }


    protected void longStackNewPage(long masterLinkOffset, long prevPageOffset, long value) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        long newPageOffset = freeDataTakeSingle((int) CHUNKSIZE);

        vol.putLong(newPageOffset, parity4Set((CHUNKSIZE<<48) | prevPageOffset));

        long currSize = 8 + vol.putLongPackBidi(newPageOffset+8, longParitySet(value));

        headVol.putLong(masterLinkOffset, parity4Set((currSize<<48)|newPageOffset));
    }


    protected long longStackTake(long masterLinkOffset, boolean recursive){
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();
        if(CC.ASSERT && (masterLinkOffset<FREE_RECID_STACK ||
                masterLinkOffset>FREE_RECID_STACK+round16Up(MAX_REC_SIZE)/2 ||
                masterLinkOffset % 8!=0))
            throw new AssertionError();

        long masterLinkVal = parity4Get(headVol.getLong(masterLinkOffset));
        if(masterLinkVal==0 ){
            return 0;
        }
        long currSize = masterLinkVal>>>48;
        final long pageOffset = masterLinkVal&MOFFSET;


        long ret = vol.getLongPackBidiReverse(pageOffset+currSize);

        long oldCurrSize = currSize;
        currSize-= ret >>>56;

        vol.clear(pageOffset+currSize, pageOffset+oldCurrSize);

        ret = longParityGet(ret & DataIO.PACK_LONG_RESULT_MASK);

        if(CC.ASSERT && currSize<8)
            throw new AssertionError();


        if(currSize>8){

            headVol.putLong(masterLinkOffset, parity4Set(currSize << 48 | pageOffset));
            return ret;
        }


        long prevPageOffset = parity4Get(vol.getLong(pageOffset));
        final int currPageSize = (int) (prevPageOffset>>>48);
        prevPageOffset &= MOFFSET;


        if(prevPageOffset!=0) {






            currSize = parity4Get(vol.getLong(prevPageOffset)) >>> 48;


            while (vol.getUnsignedByte(prevPageOffset + currSize-1) == 0) {
                currSize--;
            }

            if (CC.ASSERT && currSize < 10)
                throw new AssertionError();
        }else{

            currSize=0;
        }


        headVol.putLong(masterLinkOffset, parity4Set(currSize<<48 | prevPageOffset));


        freeDataPut(pageOffset, currPageSize);

        return ret;
    }

    @Override
    public void close() {
        if(closed==true)
            return;
        
        commitLock.lock();
        try {
            if(closed==true)
                return;
            flush();
            vol.close();
            vol = null;
            if(this instanceof StoreCached)
                headVol.close();

            if (caches != null) {
                for (Cache c : caches) {
                    c.close();
                }
                Arrays.fill(caches,null);
            }
            closed = true;
        }finally{
            commitLock.unlock();
        }
    }


    @Override
    public void commit() {
        commitLock.lock();
        try {
            flush();
        }finally{
            commitLock.unlock();
        }
    }

    protected void flush() {
        if(isReadOnly())
            return;
        structuralLock.lock();
        try{
            headVol.putLong(LAST_PHYS_ALLOCATED_DATA_OFFSET, parity3Set(lastAllocatedData));

            vol.putInt(HEAD_CHECKSUM, headChecksum(vol));
        }finally {
            structuralLock.unlock();
        }
        vol.sync();
    }

    @Override
    public void rollback() throws UnsupportedOperationException {
        throw new UnsupportedOperationException();
    }


    @Override
    public boolean canRollback() {
        return false;
    }

    @Override
    public Engine snapshot() throws UnsupportedOperationException {
        if(!snapshotEnable)
            throw new UnsupportedOperationException();
        return new Snapshot(StoreDirect.this);
    }

    @Override
    public void clearCache() {

    }

    @Override
    public void compact() {

        if(compactOldFilesExists()){
            return;
        }

        final boolean isStoreCached = this instanceof StoreCached;
        for(int i=0;i<locks.length;i++){
            Lock lock = isStoreCached?locks[i].readLock():locks[i].writeLock();
            lock.lock();
        }

        try{
            commitLock.lock();
            try {


                if(caches!=null) {
                    for (Cache c : caches) {
                        c.clear();
                    }
                }
                snapshotCloseAllOnCompact();


                final long maxRecidOffset = parity1Get(headVol.getLong(MAX_RECID_OFFSET));

                String compactedFile = vol.getFile()==null? null : fileName+".compact";
                final StoreDirect target = new StoreDirect(compactedFile,
                        volumeFactory,
                        null,lockScale,
                        executor==null?LOCKING_STRATEGY_NOLOCK:LOCKING_STRATEGY_WRITELOCK,
                        checksum,compress,null,false,false,0,false,0,
                        null);
                target.init();
                final AtomicLong maxRecid = new AtomicLong(RECID_LAST_RESERVED);





                compactIndexPages(maxRecidOffset, target, maxRecid);



                structuralLock.lock();
                try {

                    target.vol.putLong(MAX_RECID_OFFSET, parity1Set(maxRecid.get() * indexValSize));
                    this.indexPages = target.indexPages;
                    this.lastAllocatedData = target.lastAllocatedData;



                    if(compactedFile==null) {

                        Volume oldVol = this.vol;
                        if(this instanceof StoreCached)
                            headVol.close();
                        this.headVol = this.vol = target.vol;

                        oldVol.close();
                    }else{
                        File compactedFileF = new File(compactedFile);

                        target.vol.sync();
                        target.close();
                        this.vol.sync();
                        this.vol.close();

                        File currFile = new File(this.fileName);
                        File currFileRenamed = new File(currFile.getPath()+".compact_orig");
                        if(!currFile.renameTo(currFileRenamed)){


                            throw new AssertionError("failed to rename file "+currFile+" - "+currFile.exists()+" - "+currFileRenamed.exists());
                        }


                        if(!compactedFileF.renameTo(currFile)) {

                            throw new AssertionError("failed to rename file " + compactedFileF);
                        }


                        if(this instanceof StoreCached)
                            this.headVol.close();
                        this.headVol = this.vol = volumeFactory.makeVolume(this.fileName, readonly);

                        if(isStoreCached){
                            ((StoreCached)this).dirtyStackPages.clear();
                        }


                        if(!currFileRenamed.delete()){
                            LOG.warning("Could not delete old compaction file: "+currFileRenamed);
                        }

                    }
                }finally {
                    structuralLock.unlock();
                }
            }finally{
                commitLock.unlock();
            }
        }finally {
            for(int i=locks.length-1;i>=0;i--) {
                Lock lock = isStoreCached ? locks[i].readLock() : locks[i].writeLock();
                lock.unlock();
            }
        }
    }

    protected boolean compactOldFilesExists() {
        if(fileName!=null){
            for(String s:new String[]{".compact_orig",".compact",".wal.c" ,".wal.c.compact" }) {
                File oldData = new File(fileName + s);
                if (oldData.exists()) {
                    LOG.warning("Old compaction data exists, compaction not started: " + oldData);
                    return true;
                }
            }

        }
        return false;
    }

    protected void snapshotCloseAllOnCompact() {

        if(snapshotEnable){
            boolean someClosed = false;
            for(Snapshot snap:snapshots){
                someClosed = true;
                snap.close();
            }
            if(someClosed)
                LOG.log(Level.WARNING, "Compaction closed existing snapshots.");
        }
    }

    protected void compactIndexPages(final long maxRecidOffset, final StoreDirect target, final AtomicLong maxRecid) {

        if(executor == null) {
            for (int indexPageI = 0; indexPageI < indexPages.length; indexPageI++) {
                compactIndexPage(maxRecidOffset, target, maxRecid, indexPageI);
            }
        }else {




            final List<Future> tasks = new ArrayList();
            for (int indexPageI = 0; indexPageI < indexPages.length; indexPageI++) {
                final int indexPageI2 = indexPageI;


                Future f = executor.submit(new Runnable() {
                    @Override
                    public void run() {
                      compactIndexPage(maxRecidOffset, target, maxRecid, indexPageI2);
                    }
                });
                tasks.add(f);
            }


            for(Future f:tasks){
                try {
                    f.get();
                } catch (InterruptedException e) {
                    throw new DBException.Interrupted(e);
                } catch (ExecutionException e) {

                    throw new RuntimeException(e);
                }
            }

        }
    }

    protected void compactIndexPage(long maxRecidOffset, StoreDirect target, AtomicLong maxRecid, int indexPageI) {
        final long indexPage = indexPages[indexPageI];

        long recid = (indexPageI==0? 0 : indexPageI * PAGE_SIZE/indexValSize - HEAD_END/indexValSize);
        final long indexPageStart = (indexPage==0?HEAD_END+8 : indexPage);
        final long indexPageEnd = indexPage+PAGE_SIZE;



        indexVal:
        for( long indexOffset=indexPageStart;
                indexOffset<indexPageEnd;
                indexOffset+= indexValSize){
            recid++;

            if(CC.ASSERT && indexOffset!=recidToOffset(recid))
                throw new AssertionError();

            if(recid*indexValSize>maxRecidOffset)
                break indexVal;


            for(long oldMaxRecid=maxRecid.get();
                !maxRecid.compareAndSet(oldMaxRecid, Math.max(recid,oldMaxRecid));
                oldMaxRecid=maxRecid.get()){
            }

            final long indexVal = vol.getLong(indexOffset);
            if(checksum &&
                    vol.getUnsignedShort(indexOffset+8)!=
                            (DataIO.longHash(indexVal)&0xFFFF)){
                throw new DBException.ChecksumBroken();
            }


            if((indexVal&MUNUSED)!=0||indexVal == 0){

                target.structuralLock.lock();
                target.longStackPut(FREE_RECID_STACK, recid, false);
                target.structuralLock.unlock();
                continue indexVal;
            }



            if((indexVal & MLINKED)!=0 && indexVal>>>48!=0){

                long[] offsets = offsetsGet(indexValGet(recid));
                int totalSize = offsetsTotalSize(offsets);
                byte[] b = getLoadLinkedRecord(offsets, totalSize);


                target.locks[lockPos(recid)].writeLock().lock();
                target.structuralLock.lock();

                long[] newOffsets = target.freeDataTake(totalSize);

                target.pageIndexEnsurePageForRecidAllocated(recid);
                target.putData(recid,newOffsets,b, totalSize);

                target.structuralLock.unlock();
                target.locks[lockPos(recid)].writeLock().unlock();


                continue indexVal;
            }

            target.locks[lockPos(recid)].writeLock().lock();
            target.structuralLock.lock();
            target.pageIndexEnsurePageForRecidAllocated(recid);

            target.updateFromCompact(recid, indexVal, vol);
            target.structuralLock.unlock();
            target.locks[lockPos(recid)].writeLock().unlock();

        }
    }


    private void updateFromCompact(long recid, long indexVal, Volume oldVol) {

        int size = (int) (indexVal>>>48);
        long newOffset[];
        if(size>0) {
            newOffset=freeDataTake(size);
            if (newOffset.length != 1)
                throw new AssertionError();


            oldVol.transferInto(indexVal & MOFFSET, this.vol, newOffset[0]&MOFFSET, size);
        }else{
            newOffset = new long[1];
        }



        indexValPut(recid, size, newOffset[0]&MOFFSET, (indexVal&MLINKED)!=0, false);
    }


    protected long indexValGet(long recid) {
        long offset = recidToOffset(recid);
        long indexVal = vol.getLong(offset);
        if(indexVal == 0)
            throw new DBException.EngineGetVoid();
        if(checksum){
            int checksum = vol.getUnsignedShort(offset+8);
            if(checksum!=(DataIO.longHash(indexVal)&0xFFFF)){
                throw new DBException.ChecksumBroken();
            }
        }

        return DataIO.parity1Get(indexVal);
    }

    protected final long recidToOffset(long recid){
        if(CC.ASSERT && recid<=0)
            throw new AssertionError("negative recid: "+recid);
        if(checksum){
            return recidToOffsetChecksum(recid);
        }


        recid = (recid-1) * indexValSize + HEAD_END + 8;

        recid+= Math.min(1, recid/PAGE_SIZE)*    
                (8 + ((recid-PAGE_SIZE)/(PAGE_SIZE-8))*8);


        recid = indexPages[((int) (recid / PAGE_SIZE))] + recid%PAGE_SIZE;
        return recid;
    }

    private long recidToOffsetChecksum(long recid) {

        recid = (recid-1) * indexValSize + HEAD_END + 8;

        if(recid+ indexValSize >PAGE_SIZE){

            recid+=2+8;
        }



        for(long page=PAGE_SIZE*2;recid+ indexValSize >page;page+=PAGE_SIZE){
            recid+=8+(PAGE_SIZE-8)% indexValSize;
        }


        recid = indexPages[((int) (recid / PAGE_SIZE))] + recid%PAGE_SIZE;
        return recid;

    }


    protected boolean recidTooLarge(long recid) {
        try{
            recidToOffset(recid);
            return false;
        }catch(ArrayIndexOutOfBoundsException e){

            return true;
        }
    }


    protected static long composeIndexVal(int size, long offset,
        boolean linked, boolean unused, boolean archive){
        if(CC.ASSERT && (size&0xFFFF)!=size)
            throw new AssertionError("size too large");
        if(CC.ASSERT && (offset&MOFFSET)!=offset)
            throw new AssertionError("offset too large");
        offset = (((long)size)<<48) |
                offset |
                (linked?MLINKED:0L)|
                (unused?MUNUSED:0L)|
                (archive?MARCHIVE:0L);
        return parity1Set(offset);
    }



    protected long freeRecidTake() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();


        long currentRecid = longStackTake(FREE_RECID_STACK,false);
        if(currentRecid!=0)
            return currentRecid;

        currentRecid = parity1Get(headVol.getLong(MAX_RECID_OFFSET));
        currentRecid+=indexValSize;
        headVol.putLong(MAX_RECID_OFFSET, parity1Set(currentRecid));

        currentRecid/=indexValSize;

        if(recidTooLarge(currentRecid)){
            pageIndexExtend();
        }

        return currentRecid;
    }

    protected void indexLongPut(long offset, long val){
        vol.putLong(offset,val);
    }

    protected void pageIndexEnsurePageForRecidAllocated(long recid) {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();



        recid = recid * indexValSize + HEAD_END;
        recid = recid / (PAGE_SIZE-8);

        while(indexPages.length<=recid)
            pageIndexExtend();
    }

    protected void pageIndexExtend() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();


        long indexPage = pageAllocate();


        long nextPagePointerOffset = indexPages[indexPages.length-1];

        nextPagePointerOffset = Math.max(nextPagePointerOffset, HEAD_END);
        indexLongPut(nextPagePointerOffset, parity16Set(indexPage));


        indexLongPut(indexPage,parity16Set(0));


        long[] indexPages2 = Arrays.copyOf(indexPages,indexPages.length+1);
        indexPages2[indexPages.length]=indexPage;
        indexPages = indexPages2;
    }

    protected long pageAllocate() {
        if(CC.ASSERT && !structuralLock.isHeldByCurrentThread())
            throw new AssertionError();

        long storeSize = parity16Get(headVol.getLong(STORE_SIZE));
        vol.ensureAvailable(storeSize+PAGE_SIZE);
        vol.clear(storeSize,storeSize+PAGE_SIZE);
        headVol.putLong(STORE_SIZE, parity16Set(storeSize + PAGE_SIZE));

        if(CC.ASSERT && storeSize%PAGE_SIZE!=0)
            throw new AssertionError();

        return storeSize;
    }

    protected static int round16Up(int pos) {

        int rem = pos&15;  
        if(rem!=0) pos +=16-rem;
        return pos;
    }

    public static final class Snapshot extends ReadOnly{

        protected StoreDirect engine;
        protected LongLongMap[] oldRecids;

        public Snapshot(StoreDirect engine){
            this.engine = engine;
            oldRecids = new LongLongMap[engine.lockScale];
            for(int i=0;i<oldRecids.length;i++){
                oldRecids[i] = new LongLongMap();
            }
            engine.snapshots.add(Snapshot.this);
        }

        @Override
        public <A> A get(long recid, Serializer<A> serializer) {
            StoreDirect engine = this.engine;
            int pos = engine.lockPos(recid);
            Lock lock = engine.locks[pos].readLock();
            lock.lock();
            try{
                long indexVal = oldRecids[pos].get(recid);
                if(indexVal==-1)
                    return null; 
                if(indexVal==-2)
                    return null; 

                if(indexVal!=0){
                    long[] offsets = engine.offsetsGet(indexVal);
                    return engine.getFromOffset(serializer,offsets);
                }

                return engine.get2(recid,serializer);
            }finally {
                lock.unlock();
            }
        }

        @Override
        public void close() {

            engine.snapshots.remove(Snapshot.this);
            engine = null;
            oldRecids = null;

        }

        @Override
        public boolean isClosed() {
            return engine!=null;
        }

        @Override
        public boolean canRollback() {
            return false;
        }

        @Override
        public boolean canSnapshot() {
            return true;
        }

        @Override
        public Engine snapshot() throws UnsupportedOperationException {
            return this;
        }

        @Override
        public Engine getWrappedEngine() {
            return engine;
        }

        @Override
        public void clearCache() {

        }
    }
}

<code block>
package org.mapdb;

import java.io.*;
import java.nio.ByteBuffer;
import java.util.Arrays;


public final class DataIO {

    private DataIO(){}


    static public int unpackInt(DataInput is) throws IOException {
        int ret = 0;
        byte v;
        do{
            v = is.readByte();
            ret = (ret<<7 ) | (v & 0x7F);
        }while(v<0);

        return ret;
    }


    static public long unpackLong(DataInput in) throws IOException {
        long ret = 0;
        byte v;
        do{
            v = in.readByte();
            ret = (ret<<7 ) | (v & 0x7F);
        }while(v<0);

        return ret;
    }



    static public void packLong(DataOutput out, long value) throws IOException {

        int shift = 63-Long.numberOfLeadingZeros(value);
        shift -= shift%7; 
        while(shift!=0){
            out.writeByte((byte) (((value>>>shift) & 0x7F) | 0x80));

            shift-=7;
        }
        out.writeByte((byte) (value & 0x7F));
    }


    public static int packLongSize(long value) {
        int shift = 63-Long.numberOfLeadingZeros(value);
        shift -= shift%7; 
        int ret = 1;
        while(shift!=0){

            shift-=7;
            ret++;
        }
        return ret;
    }



    static public long unpackRecid(DataInput in) throws IOException {
        long val = unpackLong(in);
        val = DataIO.parity3Get(val);
        return val >>> 3;
    }



    static public void packRecid(DataOutput out, long value) throws IOException {
        value = DataIO.parity3Set(value<<3);
        packLong(out,value);
    }




    static public void packInt(DataOutput out, int value) throws IOException {




        int shift = (value & ~0x7F); 
        if (shift != 0) {

            shift = 31-Integer.numberOfLeadingZeros(value);
            shift -= shift%7; 
            while(shift!=0){
                out.writeByte((byte) (((value>>>shift) & 0x7F) | 0x80));

                shift-=7;
            }
        }

        out.writeByte((byte) (value & 0x7F));
    }



    static public void packIntBigger(DataOutput out, int value) throws IOException {

        int shift = 31-Integer.numberOfLeadingZeros(value);
        shift -= shift%7; 
        while(shift!=0){
            out.writeByte((byte) (((value>>>shift) & 0x7F) | 0x80));

            shift-=7;
        }

        out.writeByte((byte) (value & 0x7F));
    }

    public static int longHash(long h) {

        h = h * -7046029254386353131L;
        h ^= h >> 32;
        return (int)(h ^ h >> 16);

    }

    public static int intHash(int h) {

        h = h * -1640531527;
        return h ^ h >> 16;

    }

    public static final long PACK_LONG_RESULT_MASK = 0xFFFFFFFFFFFFFFL;


    public static int packLongBidi(DataOutput out, long value) throws IOException {
        out.write((((int) value & 0x7F)) | 0x80);
        value >>>= 7;
        int counter = 2;


        while ((value & ~0x7FL) != 0) {
            out.write((((int) value & 0x7F)));
            value >>>= 7;

            counter++;
        }

        out.write((byte) value| 0x80);
        return counter;
    }

    public static int packLongBidi(byte[] buf, int pos, long value) {
        buf[pos++] = (byte) ((((int) value & 0x7F))| 0x80);
        value >>>= 7;
        int counter = 2;


        while ((value & ~0x7FL) != 0) {
            buf[pos++] = (byte) (((int) value & 0x7F));
            value >>>= 7;

            counter++;
        }

        buf[pos++] = (byte) ((byte) value| 0x80);
        return counter;
    }


    public static long unpackLongBidi(byte[] bb, int pos){

        long b = bb[pos++];
        if(CC.ASSERT && (b&0x80)==0)
            throw new AssertionError();
        long result = (b & 0x7F) ;
        int offset = 7;
        do {

            b = bb[pos++];
            result |= (b & 0x7F) << offset;
            if(CC.ASSERT && offset>64)
                throw new AssertionError();
            offset += 7;
        }while((b & 0x80) == 0);

        return (((long)(offset/7))<<56) | result;
    }


    public static long unpackLongBidiReverse(byte[] bb, int pos){

        long b = bb[--pos];
        if(CC.ASSERT && (b&0x80)==0)
            throw new AssertionError();
        long result = (b & 0x7F) ;
        int counter = 1;
        do {

            b = bb[--pos];
            result = (b & 0x7F) | (result<<7);
            if(CC.ASSERT && counter>8)
                throw new AssertionError();
            counter++;
        }while((b & 0x80) == 0);

        return (((long)counter)<<56) | result;
    }

    public static long getLong(byte[] buf, int pos) {
       return
               ((((long)buf[pos++]) << 56) |
                (((long)buf[pos++] & 0xFF) << 48) |
                (((long)buf[pos++] & 0xFF) << 40) |
                (((long)buf[pos++] & 0xFF) << 32) |
                (((long)buf[pos++] & 0xFF) << 24) |
                (((long)buf[pos++] & 0xFF) << 16) |
                (((long)buf[pos++] & 0xFF) <<  8) |
                (((long)buf[pos] & 0xFF)));

    }

    public static void putLong(byte[] buf, int pos,long v) {
        buf[pos++] = (byte) (0xff & (v >> 56));
        buf[pos++] = (byte) (0xff & (v >> 48));
        buf[pos++] = (byte) (0xff & (v >> 40));
        buf[pos++] = (byte) (0xff & (v >> 32));
        buf[pos++] = (byte) (0xff & (v >> 24));
        buf[pos++] = (byte) (0xff & (v >> 16));
        buf[pos++] = (byte) (0xff & (v >> 8));
        buf[pos] = (byte) (0xff & (v));
    }


    public static long getSixLong(byte[] buf, int pos) {
        return
                        ((long) (buf[pos++] & 0xff) << 40) |
                        ((long) (buf[pos++] & 0xff) << 32) |
                        ((long) (buf[pos++] & 0xff) << 24) |
                        ((long) (buf[pos++] & 0xff) << 16) |
                        ((long) (buf[pos++] & 0xff) << 8) |
                        ((long) (buf[pos] & 0xff));
    }

    public static void putSixLong(byte[] buf, int pos, long value) {
        if(CC.ASSERT && (value>>>48!=0))
            throw new AssertionError();

        buf[pos++] = (byte) (0xff & (value >> 40));
        buf[pos++] = (byte) (0xff & (value >> 32));
        buf[pos++] = (byte) (0xff & (value >> 24));
        buf[pos++] = (byte) (0xff & (value >> 16));
        buf[pos++] = (byte) (0xff & (value >> 8));
        buf[pos] = (byte) (0xff & (value));
    }




    public static int nextPowTwo(final int a)
    {
        return 1 << (32 - Integer.numberOfLeadingZeros(a - 1));
    }



    public interface DataInputInternal extends DataInput,Closeable {

        int getPos();
        void setPos(int pos);


        byte[] internalByteArray();


        ByteBuffer internalByteBuffer();


        void close();

        long unpackLong() throws IOException;

        int unpackInt() throws IOException;

        long[] unpackLongArrayDeltaCompression(int size) throws IOException;

        void unpackLongArray(long[] ret, int i, int len);
        void unpackIntArray(int[] ret, int i, int len);
    }


    static public final class DataInputByteArray implements DataInput, DataInputInternal {
        protected final byte[] buf;
        protected int pos;


        public DataInputByteArray(byte[] b) {
            this(b, 0);
        }

        public DataInputByteArray(byte[] bb, int pos) {

            buf = bb;
            this.pos = pos;
        }

        @Override
        public void readFully(byte[] b) throws IOException {
            readFully(b, 0, b.length);
        }

        @Override
        public void readFully(byte[] b, int off, int len) throws IOException {
            System.arraycopy(buf, pos, b, off, len);

            pos += len;
        }

        @Override
        public int skipBytes(final int n) throws IOException {
            pos += n;

            return n;
        }

        @Override
        public boolean readBoolean() throws IOException {

            return buf[pos++] == 1;
        }

        @Override
        public byte readByte() throws IOException {

            return buf[pos++];
        }

        @Override
        public int readUnsignedByte() throws IOException {

            return buf[pos++] & 0xff;
        }

        @Override
        public short readShort() throws IOException {

            return (short)((buf[pos++] << 8) | (buf[pos++] & 0xff));
        }

        @Override
        public int readUnsignedShort() throws IOException {

            return readChar();
        }

        @Override
        public char readChar() throws IOException {

            return (char) (
                    ((buf[pos++] & 0xff) << 8) |
                    (buf[pos++] & 0xff));
        }

        @Override
        public int readInt() throws IOException {
            int p = pos;
            final byte[] b = buf;
            final int ret =
                    ((((int)b[p++]) << 24) |
                     (((int)b[p++] & 0xFF) << 16) |
                     (((int)b[p++] & 0xFF) <<  8) |
                     (((int)b[p++] & 0xFF)));
            pos = p;
            return ret;
        }

        @Override
        public long readLong() throws IOException {
            int p = pos;
            final byte[] b = buf;
            final long ret =
                    ((((long)b[p++]) << 56) |
                    (((long)b[p++] & 0xFF) << 48) |
                    (((long)b[p++] & 0xFF) << 40) |
                    (((long)b[p++] & 0xFF) << 32) |
                    (((long)b[p++] & 0xFF) << 24) |
                    (((long)b[p++] & 0xFF) << 16) |
                    (((long)b[p++] & 0xFF) <<  8) |
                    (((long)b[p++] & 0xFF)));
            pos = p;
            return ret;
        }

        @Override
        public float readFloat() throws IOException {
            return Float.intBitsToFloat(readInt());
        }

        @Override
        public double readDouble() throws IOException {
            return Double.longBitsToDouble(readLong());
        }

        @Override
        public String readLine() throws IOException {
            return readUTF();
        }

        @Override
        public String readUTF() throws IOException {
            final int len = unpackInt();
            char[] b = new char[len];
            for (int i = 0; i < len; i++)

                b[i] = (char) unpackInt();
            return new String(b);
        }

        @Override
        public int getPos() {
            return pos;
        }

        @Override
        public void setPos(int pos) {
            this.pos = pos;
        }

        @Override
        public byte[] internalByteArray() {
            return buf;
        }

        @Override
        public ByteBuffer internalByteBuffer() {
            return null;
        }

        @Override
        public void close() {
        }

        @Override
        public long unpackLong() throws IOException {
            byte[] b = buf;
            int p = pos;
            long ret = 0;
            byte v;
            do{

                v = b[p++];
                ret = (ret<<7 ) | (v & 0x7F);
            }while(v<0);
            pos = p;
            return ret;
        }

        @Override
        public int unpackInt() throws IOException {
            byte[] b = buf;
            int p = pos;
            int ret = 0;
            byte v;
            do{

                v = b[p++];
                ret = (ret<<7 ) | (v & 0x7F);
            }while(v<0);
            pos = p;
            return ret;
        }

        @Override
        public long[] unpackLongArrayDeltaCompression(final int size) throws IOException {
            long[] ret = new long[size];
            int pos2 = pos;
            byte[] buf2 = buf;
            long prev =0;
            byte v;
            for(int i=0;i<size;i++){
                long r = 0;
                do {

                    v = buf2[pos2++];
                    r = (r << 7) | (v & 0x7F);
                } while (v < 0);
                prev+=r;
                ret[i]=prev;
            }
            pos = pos2;
            return ret;
        }

        @Override
        public void unpackLongArray(long[] array, int start, int end) {
            int pos2 = pos;
            byte[] buf2 = buf;
            long ret;
            byte v;
            for(;start<end;start++) {
                ret = 0;
                do {

                    v = buf2[pos2++];
                    ret = (ret << 7) | (v & 0x7F);
                } while (v < 0);
                array[start]=ret;
            }
            pos = pos2;
        }

        @Override
        public void unpackIntArray(int[] array, int start, int end) {
            int pos2 = pos;
            byte[] buf2 = buf;
            int ret;
            byte v;
            for(;start<end;start++) {
                ret = 0;
                do {

                    v = buf2[pos2++];
                    ret = (ret << 7) | (v & 0x7F);
                } while (v < 0);
                array[start]=ret;
            }
            pos = pos2;
        }

    }


    public static final class DataInputToStream extends InputStream {

        protected final DataInput in;

        public DataInputToStream(DataInput in) {
            this.in = in;
        }

        @Override
        public int read(byte[] b, int off, int len) throws IOException {
            in.readFully(b,off,len);
            return len;
        }

        @Override
        public long skip(long n) throws IOException {
            n = Math.min(n, Integer.MAX_VALUE);

            return in.skipBytes((int) n);
        }

        @Override
        public void close() throws IOException {
            if(in instanceof Closeable)
                ((Closeable) in).close();
        }

        @Override
        public int read() throws IOException {
            return in.readUnsignedByte();
        }
    }



    public static final class DataInputByteBuffer implements DataInput, DataInputInternal {

        public final ByteBuffer buf;
        public int pos;

        public DataInputByteBuffer(final ByteBuffer buf, final int pos) {

            this.buf = buf;
            this.pos = pos;
        }


        public DataInputByteBuffer(byte[] b) {
            this(ByteBuffer.wrap(b),0);
        }

        @Override
        public void readFully(byte[] b) throws IOException {
            readFully(b, 0, b.length);
        }

        @Override
        public void readFully(byte[] b, int off, int len) throws IOException {
            ByteBuffer clone = buf.duplicate();
            clone.position(pos);

            pos+=len;
            clone.get(b, off, len);
        }

        @Override
        public int skipBytes(final int n) throws IOException {
            pos +=n;

            return n;
        }

        @Override
        public boolean readBoolean() throws IOException {

            return buf.get(pos++) ==1;
        }

        @Override
        public byte readByte() throws IOException {

            return buf.get(pos++);
        }

        @Override
        public int readUnsignedByte() throws IOException {

            return buf.get(pos++)& 0xff;
        }

        @Override
        public short readShort() throws IOException {
            final short ret = buf.getShort(pos);

            pos+=2;
            return ret;
        }

        @Override
        public int readUnsignedShort() throws IOException {
            return readChar();
        }

        @Override
        public char readChar() throws IOException {

            return (char) (
                    ((buf.get(pos++) & 0xff) << 8) |
                     (buf.get(pos++) & 0xff));
        }

        @Override
        public int readInt() throws IOException {
            final int ret = buf.getInt(pos);

            pos+=4;
            return ret;
        }

        @Override
        public long readLong() throws IOException {
            final long ret = buf.getLong(pos);

            pos+=8;
            return ret;
        }

        @Override
        public float readFloat() throws IOException {
            final float ret = buf.getFloat(pos);

            pos+=4;
            return ret;
        }

        @Override
        public double readDouble() throws IOException {
            final double ret = buf.getDouble(pos);

            pos+=8;
            return ret;
        }

        @Override
        public String readLine() throws IOException {
            return readUTF();
        }

        @Override
        public String readUTF() throws IOException {

            final int size = unpackInt();

            return SerializerBase.deserializeString(this, size);
        }


        @Override
        public int getPos() {
            return pos;
        }

        @Override
        public void setPos(int pos) {
            this.pos = pos;
        }

        @Override
        public byte[] internalByteArray() {
            return null;
        }

        @Override
        public ByteBuffer internalByteBuffer() {
            return buf;
        }

        @Override
        public void close() {
        }

        @Override
        public long unpackLong() throws IOException {
            long ret = 0;
            byte v;
            do{
                v = buf.get(pos++);
                ret = (ret<<7 ) | (v & 0x7F);
            }while(v<0);

            return ret;
        }

        @Override
        public int unpackInt() throws IOException {
            int ret = 0;
            byte v;
            do{
                v = buf.get(pos++);
                ret = (ret<<7 ) | (v & 0x7F);
            }while(v<0);

            return ret;
        }


        @Override
        public long[] unpackLongArrayDeltaCompression(final int size) throws IOException {
            long[] ret = new long[size];
            int pos2 = pos;
            ByteBuffer buf2 = buf;
            long prev=0;
            byte v;
            for(int i=0;i<size;i++){
                long r = 0;
                do {

                    v = buf2.get(pos2++);
                    r = (r << 7) | (v & 0x7F);
                } while (v < 0);
                prev+=r;
                ret[i]=prev;
            }
            pos = pos2;
            return ret;
        }

        @Override
        public void unpackLongArray(long[] array, int start, int end) {
            int pos2 = pos;
            ByteBuffer buf2 = buf;
            long ret;
            byte v;
            for(;start<end;start++) {
                ret = 0;
                do {

                    v = buf2.get(pos2++);
                    ret = (ret << 7) | (v & 0x7F);
                } while (v < 0);
                array[start] = ret;
            }
            pos = pos2;

        }

        @Override
        public void unpackIntArray(int[] array, int start, int end) {
            int pos2 = pos;
            ByteBuffer buf2 = buf;
            int ret;
            byte v;
            for(;start<end;start++) {
                ret = 0;
                do {

                    v = buf2.get(pos2++);
                    ret = (ret << 7) | (v & 0x7F);
                } while (v < 0);
                array[start] = ret;
            }
            pos = pos2;
        }

    }


    public static final class DataOutputByteArray extends OutputStream implements DataOutput {

        public byte[] buf;
        public int pos;
        public int sizeMask;


        public DataOutputByteArray(){
            pos = 0;
            buf = new byte[128]; 
            sizeMask = 0xFFFFFFFF-(buf.length-1);
        }


        public byte[] copyBytes(){
            return Arrays.copyOf(buf, pos);
        }


        public void ensureAvail(int n) {

            n+=pos;
            if ((n&sizeMask)!=0) {
                grow(n);
            }
        }

        private void grow(int n) {

            int newSize = Math.max(nextPowTwo(n),buf.length);
            sizeMask = 0xFFFFFFFF-(newSize-1);
            buf = Arrays.copyOf(buf, newSize);
        }


        @Override
        public void write(final int b) throws IOException {
            ensureAvail(1);

            buf[pos++] = (byte) b;
        }

        @Override
        public void write(final byte[] b, final int off, final int len) throws IOException {
            ensureAvail(len);

            System.arraycopy(b, off, buf, pos, len);
            pos += len;
        }

        @Override
        public void writeBoolean(final boolean v) throws IOException {
            ensureAvail(1);

            buf[pos++] = (byte) (v ? 1 : 0);
        }

        @Override
        public void writeByte(final int v) throws IOException {
            ensureAvail(1);

            buf[pos++] = (byte) (v);
        }

        @Override
        public void writeShort(final int v) throws IOException {
            ensureAvail(2);

            buf[pos++] = (byte) (0xff & (v >> 8));

            buf[pos++] = (byte) (0xff & (v));
        }

        @Override
        public void writeChar(final int v) throws IOException {
            ensureAvail(2);
            buf[pos++] = (byte) (v>>>8);
            buf[pos++] = (byte) (v);
        }

        @Override
        public void writeInt(final int v) throws IOException {
            ensureAvail(4);
            buf[pos++] = (byte) (0xff & (v >> 24));

            buf[pos++] = (byte) (0xff & (v >> 16));
            buf[pos++] = (byte) (0xff & (v >> 8));

            buf[pos++] = (byte) (0xff & (v));
        }

        @Override
        public void writeLong(final long v) throws IOException {
            ensureAvail(8);
            buf[pos++] = (byte) (0xff & (v >> 56));
            buf[pos++] = (byte) (0xff & (v >> 48));

            buf[pos++] = (byte) (0xff & (v >> 40));
            buf[pos++] = (byte) (0xff & (v >> 32));
            buf[pos++] = (byte) (0xff & (v >> 24));

            buf[pos++] = (byte) (0xff & (v >> 16));
            buf[pos++] = (byte) (0xff & (v >> 8));
            buf[pos++] = (byte) (0xff & (v));

        }

        @Override
        public void writeFloat(final float v) throws IOException {
            writeInt(Float.floatToIntBits(v));
        }

        @Override
        public void writeDouble(final double v) throws IOException {
            writeLong(Double.doubleToLongBits(v));
        }

        @Override
        public void writeBytes(final String s) throws IOException {
            writeUTF(s);
        }

        @Override
        public void writeChars(final String s) throws IOException {
            writeUTF(s);
        }

        @Override
        public void writeUTF(final String s) throws IOException {
            final int len = s.length();
            packInt(len);
            for (int i = 0; i < len; i++) {

                int c = (int) s.charAt(i);
                packInt(c);
            }
        }

        public void packInt(int value) throws IOException {
            ensureAvail(5); 




            int shift = (value & ~0x7F); 
            if (shift != 0) {
                shift = 31 - Integer.numberOfLeadingZeros(value);
                shift -= shift % 7; 
                while (shift != 0) {
                    buf[pos++] = (byte) (((value >>> shift) & 0x7F) | 0x80);
                    shift -= 7;
                }
            }
            buf[pos++] = (byte) (value & 0x7F);
        }

        public void packIntBigger(int value) throws IOException {
            ensureAvail(5); 
            int shift = 31-Integer.numberOfLeadingZeros(value);
            shift -= shift%7; 
            while(shift!=0){
                buf[pos++] = (byte) (((value>>>shift) & 0x7F) | 0x80);
                shift-=7;
            }
            buf[pos++] = (byte) (value & 0x7F);
        }

        public void packLong(long value) {
            ensureAvail(10); 
            int shift = 63-Long.numberOfLeadingZeros(value);
            shift -= shift%7; 
            while(shift!=0){
                buf[pos++] = (byte) (((value>>>shift) & 0x7F) | 0x80);
                shift-=7;
            }
            buf[pos++] = (byte) (value & 0x7F);
        }
    }


    public static long parity1Set(long i) {
        if(CC.ASSERT && (i&1)!=0)
            throw new DBException.PointerChecksumBroken();
        return i | ((Long.bitCount(i)+1)%2);
    }

    public static long parity1Get(long i) {
        if(Long.bitCount(i)%2!=1){
            throw new DBException.PointerChecksumBroken();
        }
        return i&0xFFFFFFFFFFFFFFFEL;
    }

    public static long parity3Set(long i) {
        if(CC.ASSERT && (i&0x7)!=0)
            throw new DBException.PointerChecksumBroken();
        return i | ((Long.bitCount(i)+1)%8);
    }

    public static long parity3Get(long i) {
        long ret = i&0xFFFFFFFFFFFFFFF8L;
        if((Long.bitCount(ret)+1)%8!=(i&0x7)){
            throw new DBException.PointerChecksumBroken();
        }
        return ret;
    }

    public static long parity4Set(long i) {
        if(CC.ASSERT && (i&0xF)!=0)
            throw new DBException.PointerChecksumBroken();
        return i | ((Long.bitCount(i)+1)%16);
    }

    public static long parity4Get(long i) {
        long ret = i&0xFFFFFFFFFFFFFFF0L;
        if((Long.bitCount(ret)+1)%16!=(i&0xF)){
            throw new DBException.PointerChecksumBroken();
        }
        return ret;
    }


    public static long parity16Set(long i) {
        if(CC.ASSERT && (i&0xFFFF)!=0)
            throw new DBException.PointerChecksumBroken();
        return i | (DataIO.longHash(i)&0xFFFFL);
    }

    public static long parity16Get(long i) {
        long ret = i&0xFFFFFFFFFFFF0000L;
        if((DataIO.longHash(ret)&0xFFFFL) != (i&0xFFFFL)){
            throw new DBException.PointerChecksumBroken();
        }
        return ret;
    }



    public static String toHexa( byte [] bb ) {
        char[] HEXA_CHARS = {'0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F'};
        char[] ret = new char[bb.length*2];
        for(int i=0;i<bb.length;i++){
            ret[i*2] =HEXA_CHARS[((bb[i]& 0xF0) >> 4)];
            ret[i*2+1] = HEXA_CHARS[((bb[i] & 0x0F))];
        }
        return new String(ret);
    }


    public static byte[] fromHexa(String s ) {
        byte[] ret = new byte[s.length()/2];
        for(int i=0;i<ret.length;i++){
            ret[i] = (byte) Integer.parseInt(s.substring(i*2,i*2+2),16);
        }
        return ret;
    }


}

<code block>
package org.mapdb;

import java.io.DataInput;
import java.io.IOError;
import java.io.IOException;
import java.lang.ref.ReferenceQueue;
import java.lang.ref.SoftReference;
import java.lang.ref.WeakReference;
import java.nio.ByteBuffer;
import java.util.*;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.locks.*;
import java.util.logging.Level;
import java.util.logging.Logger;
import java.util.zip.CRC32;


public abstract class Store implements Engine {

    protected static final Logger LOG = Logger.getLogger(Store.class.getName());

    protected static final long FEAT_COMP_LZW = 64L-1L;
    protected static final long FEAT_ENC_XTEA = 64L-2L;
    protected static final long FEAT_CRC = 64L-3L;

    protected static final long HEAD_CHECKSUM = 4;
    protected static final long HEAD_FEATURES = 8;





    protected final ReentrantLock structuralLock = new ReentrantLock(CC.FAIR_LOCKS);


    protected final ReentrantLock commitLock = new ReentrantLock(CC.FAIR_LOCKS);


    protected final ReadWriteLock[] locks;
    protected final int lockScale;
    protected final int lockMask;


    protected volatile boolean closed = false;
    protected final boolean readonly;

    protected final String fileName;
    protected final Volume.VolumeFactory volumeFactory;
    protected final boolean checksum;
    protected final boolean compress;
    protected final boolean encrypt;
    protected final EncryptionXTEA encryptionXTEA;
    protected final ThreadLocal<CompressLZF> LZF;
    protected final boolean snapshotEnable;

    protected final AtomicLong metricsDataWrite;
    protected final AtomicLong metricsRecordWrite;
    protected final AtomicLong metricsDataRead;
    protected final AtomicLong metricsRecordRead;


    protected final Cache[] caches;

    public static final int LOCKING_STRATEGY_READWRITELOCK=0;
    public static final int LOCKING_STRATEGY_WRITELOCK=1;
    public static final int LOCKING_STRATEGY_NOLOCK=2;

    protected Store(
            String fileName,
            Volume.VolumeFactory volumeFactory,
            Cache cache,
            int lockScale,
            int lockingStrategy,
            boolean checksum,
            boolean compress,
            byte[] password,
            boolean readonly,
            boolean snapshotEnable) {
        this.fileName = fileName;
        this.volumeFactory = volumeFactory;
        this.lockScale = lockScale;
        this.snapshotEnable = snapshotEnable;
        this.lockMask = lockScale-1;
        if(Integer.bitCount(lockScale)!=1)
            throw new IllegalArgumentException();

        metricsDataWrite = new AtomicLong();
        metricsRecordWrite = new AtomicLong();
        metricsDataRead = new AtomicLong();
        metricsRecordRead = new AtomicLong();

        locks = new ReadWriteLock[lockScale];
        for(int i=0;i< locks.length;i++){
            if(lockingStrategy==LOCKING_STRATEGY_READWRITELOCK)
                locks[i] = new ReentrantReadWriteLock(CC.FAIR_LOCKS);
            else if(lockingStrategy==LOCKING_STRATEGY_WRITELOCK){
                locks[i] = new ReadWriteSingleLock(new ReentrantLock(CC.FAIR_LOCKS));
            }else if(lockingStrategy==LOCKING_STRATEGY_NOLOCK){
                locks[i] = new ReadWriteSingleLock(NOLOCK);
            }else{
                throw new IllegalArgumentException("Illegal locking strategy: "+lockingStrategy);
            }
        }

        if(cache==null) {
            caches = null;
        }else {
            caches = new Cache[lockScale];
            caches[0] = cache;
            for (int i = 1; i < caches.length; i++) {

                caches[i] = cache.newCacheForOtherSegment();
            }
        }


        this.checksum = checksum;
        this.compress = compress;
        this.encrypt =  password!=null;
        this.readonly = readonly;
        this.encryptionXTEA = !encrypt?null:new EncryptionXTEA(password);

        this.LZF = !compress?null:new ThreadLocal<CompressLZF>() {
            @Override
            protected CompressLZF initialValue() {
                return new CompressLZF();
            }
        };
    }

    public void init(){}

    protected void checkFeaturesBitmap(final long feat){
        boolean xteaEnc = (feat>>>FEAT_ENC_XTEA&1)!=0;
        if(xteaEnc&& !encrypt){
            throw new DBException.WrongConfig("Store was created with encryption, but no password is set in config.");
        }
        if(!xteaEnc&& encrypt){
            throw new DBException.WrongConfig("Password is set, but store is not encrypted.");
        }

        boolean lzwComp = (feat>>>FEAT_COMP_LZW&1)!=0;
        if(lzwComp&& !compress){
            throw new DBException.WrongConfig("Store was created with compression, but no compression is enabled in config.");
        }
        if(!lzwComp&& compress){
            throw new DBException.WrongConfig("Compression is set in config, but store was created with compression.");
        }

        boolean crc = (feat>>>FEAT_CRC&1)!=0;
        if(crc&& !checksum){
            throw new DBException.WrongConfig("Store was created with CRC32 checksum, but it is not enabled in config.");
        }
        if(!crc&& checksum){
            throw new DBException.WrongConfig("Checksum us enabled, but store was created without it.");
        }

        int endZeroes = Long.numberOfTrailingZeros(feat);
        if(endZeroes<FEAT_CRC){
            throw new DBException.WrongConfig("Unknown feature #"+endZeroes+". Store was created with never MapDB version, this version does not support this feature.");
        }
    }

    protected long makeFeaturesBitmap(){
        return
            (compress ? 1L<<FEAT_COMP_LZW : 0) |
            (encrypt  ? 1L<<FEAT_ENC_XTEA : 0) |
            (checksum  ? 1L<<FEAT_CRC : 0)
        ;
    }

    @Override
    public <A> A get(long recid, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();
        if(closed)
            throw new IllegalAccessError("closed");

        int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].readLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        lock.lock();
        try{
            A o = cache==null ? null : (A) cache.get(recid);
            if(o!=null) {
                return o== Cache.NULL?null:o;
            }
            o =  get2(recid,serializer);
            if(cache!=null) {
                cache.put(recid, o);
            }
            return o;
        }finally {
            lock.unlock();
        }
    }

    protected abstract <A> A get2(long recid, Serializer<A> serializer);

    @Override
    public <A> void update(long recid, A value, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();
        if(closed)
            throw new IllegalAccessError("closed");



        DataIO.DataOutputByteArray out = serialize(value, serializer);
        int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].writeLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        lock.lock();
        try{
            if(cache!=null) {
                cache.put(recid, value);
            }
            update2(recid,out);
        }finally {
            lock.unlock();
        }
    }


    protected final AtomicReference<DataIO.DataOutputByteArray> recycledDataOut =
            new AtomicReference<DataIO.DataOutputByteArray>();

    protected <A> DataIO.DataOutputByteArray serialize(A value, Serializer<A> serializer){
        if(value==null)
            return null;
        try {
            DataIO.DataOutputByteArray out = newDataOut2();

            serializer.serialize(out,value);

            if(out.pos>0){

                if(compress){
                    DataIO.DataOutputByteArray tmp = newDataOut2();
                    tmp.ensureAvail(out.pos+40);
                    final CompressLZF lzf = LZF.get();
                    int newLen;
                    try{
                        newLen = lzf.compress(out.buf,out.pos,tmp.buf,0);
                    }catch(IndexOutOfBoundsException e){
                        newLen=0; 
                    }
                    if(newLen>=out.pos) newLen= 0; 

                    if(newLen==0){
                        recycledDataOut.lazySet(tmp);

                        out.ensureAvail(out.pos+1);
                        System.arraycopy(out.buf,0,out.buf,1,out.pos);
                        out.pos+=1;
                        out.buf[0] = 0;
                    }else{

                        final int decompSize = out.pos;
                        out.pos=0;
                        DataIO.packInt(out,decompSize);
                        out.write(tmp.buf,0,newLen);
                        recycledDataOut.lazySet(tmp);
                    }

                }


                if(encrypt){
                    int size = out.pos;

                    if(size%EncryptionXTEA.ALIGN!=0)
                        size += EncryptionXTEA.ALIGN - size%EncryptionXTEA.ALIGN;
                    final int sizeDif=size-out.pos;

                    out.ensureAvail(sizeDif+1);
                    encryptionXTEA.encrypt(out.buf,0,size);

                    out.pos = size;
                    out.writeByte(sizeDif);
                }

                if(checksum){
                    CRC32 crc = new CRC32();
                    crc.update(out.buf,0,out.pos);
                    out.writeInt((int)crc.getValue());
                }

                if(CC.PARANOID)try{

                    DataInput inp = new DataIO.DataInputByteArray(Arrays.copyOf(out.buf, out.pos));
                    byte[] decompress = deserialize(Serializer.BYTE_ARRAY_NOSIZE,out.pos,inp);

                    DataIO.DataOutputByteArray expected = newDataOut2();
                    serializer.serialize(expected,value);

                    byte[] expected2 = Arrays.copyOf(expected.buf, expected.pos);

                    if(CC.ASSERT && ! (Arrays.equals(expected2,decompress)))
                        throw new AssertionError();


                }catch(Exception e){
                    throw new RuntimeException(e);
                }
            }

            metricsDataWrite.getAndAdd(out.pos);
            metricsRecordWrite.incrementAndGet();

            return out;
        } catch (IOException e) {
            throw new IOError(e);
        }

    }

    protected DataIO.DataOutputByteArray newDataOut2() {
        DataIO.DataOutputByteArray tmp = recycledDataOut.getAndSet(null);
        if(tmp==null) tmp = new DataIO.DataOutputByteArray();
        else tmp.pos=0;
        return tmp;
    }


    protected <A> A deserialize(Serializer<A> serializer, int size, DataInput input){
        try {



            DataIO.DataInputInternal di = (DataIO.DataInputInternal) input;
            if (size > 0 && (checksum || encrypt || compress))  {
                return deserializeExtra(serializer,size,di);
            }

            int start = di.getPos();

            A ret = serializer.deserialize(di, size);
            if (size + start > di.getPos())
                throw new AssertionError("data were not fully read, check your serializer ");
            if (size + start < di.getPos())
                throw new AssertionError("data were read beyond record size, check your serializer");

            metricsDataRead.getAndAdd(size);
            metricsRecordRead.getAndIncrement();

            return ret;
        }catch(IOException e){
            throw new IOError(e);
        }
    }


    private <A> A deserializeExtra(Serializer<A> serializer, int size, DataIO.DataInputInternal di) throws IOException {
        if (checksum) {

            size -= 4;


            DataIO.DataOutputByteArray tmp = newDataOut2();
            tmp.ensureAvail(size);
            int oldPos = di.getPos();
            di.readFully(tmp.buf, 0, size);
            final int checkExpected = di.readInt();
            di.setPos(oldPos);

            CRC32 crc = new CRC32();
            crc.update(tmp.buf, 0, size);
            recycledDataOut.lazySet(tmp);
            int check = (int) crc.getValue();
            if (check != checkExpected)
                throw new IOException("Checksum does not match, data broken");
        }

        if (encrypt) {
            DataIO.DataOutputByteArray tmp = newDataOut2();
            size -= 1;
            tmp.ensureAvail(size);
            di.readFully(tmp.buf, 0, size);
            encryptionXTEA.decrypt(tmp.buf, 0, size);
            int cut = di.readUnsignedByte(); 
            di = new DataIO.DataInputByteArray(tmp.buf);
            size -= cut;
        }

        if (compress) {

            int decompSize = DataIO.unpackInt(di);
            if (decompSize == 0) {
                size -= 1;

            } else {
                DataIO.DataOutputByteArray out = newDataOut2();
                out.ensureAvail(decompSize);
                CompressLZF lzf = LZF.get();


                byte[] b = di.internalByteArray();
                if (b != null) {
                    lzf.expand(b, di.getPos(), out.buf, 0, decompSize);
                } else {
                    ByteBuffer bb = di.internalByteBuffer();
                    if (bb != null) {
                        lzf.expand(bb, di.getPos(), out.buf, 0, decompSize);
                    } else {
                        lzf.expand(di, out.buf, 0, decompSize);
                    }
                }
                di = new DataIO.DataInputByteArray(out.buf);
                size = decompSize;
            }
        }


        int start = di.getPos();

        A ret = serializer.deserialize(di, size);
        if (size + start > di.getPos())
            throw new AssertionError("data were not fully read, check your serializer ");
        if (size + start < di.getPos())
            throw new AssertionError("data were read beyond record size, check your serializer");
        return ret;
    }

    protected abstract  void update2(long recid, DataIO.DataOutputByteArray out);

    @Override
    public <A> boolean compareAndSwap(long recid, A expectedOldValue, A newValue, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();
        if(closed)
            throw new IllegalAccessError("closed");



        final int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].writeLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        lock.lock();
        try{
            A oldVal =  cache==null ? null : (A)cache.get(recid);
            if(oldVal == null) {
                oldVal = get2(recid, serializer);
            }else if(oldVal == Cache.NULL){
                oldVal = null;
            }
            if(oldVal==expectedOldValue || (oldVal!=null && serializer.equals(oldVal,expectedOldValue))){
                update2(recid,serialize(newValue,serializer));
                if(cache!=null) {
                    cache.put(recid, newValue);
                }
                return true;
            }
            return false;
        }finally {
            lock.unlock();
        }
    }


    @Override
    public <A> void delete(long recid, Serializer<A> serializer) {
        if(serializer==null)
            throw new NullPointerException();
        if(closed)
            throw new IllegalAccessError("closed");


        final int lockPos = lockPos(recid);
        final Lock lock = locks[lockPos].writeLock();
        final Cache cache = caches==null ? null : caches[lockPos];
        lock.lock();
        try{
            if(cache!=null) {
                cache.put(recid, null);
            }
            delete2(recid, serializer);
        }finally {
            lock.unlock();
        }
    }

    protected abstract <A> void delete2(long recid, Serializer<A> serializer);

    protected final int lockPos(final long recid) {
        int h = (int)(recid ^ (recid >>> 32));

        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        h ^= (h<<4);
        return h & lockMask;
    }

    protected void assertReadLocked(long recid) {



    }

    protected void assertWriteLocked(int segment) {
        ReadWriteLock l = locks[segment];
        if(l instanceof ReentrantReadWriteLock && !((ReentrantReadWriteLock) l).isWriteLockedByCurrentThread()){
            throw new AssertionError();
        }
    }


    @Override
    public boolean isClosed() {
        return closed;
    }

    @Override
    public boolean isReadOnly() {
        return readonly;
    }


    public static Store forDB(DB db){
        return forEngine(db.engine);
    }


    public static Store forEngine(Engine e){
        Engine engine2 = e.getWrappedEngine();
        if(engine2!=null)
            return forEngine(engine2);

        return (Store) e;
    }

    public abstract long getCurrSize();

    public abstract long getFreeSize();

    @Override
    public void clearCache() {
        if(closed)
            throw new IllegalAccessError("closed");

        if(caches==null)
            return;

        for(int i=0;i<locks.length;i++){
            Lock lock = locks[i].readLock();
            lock.lock();
            try{
                caches[i].clear();
            }finally {
                lock.unlock();
            }
        }
    }


    public void metricsCollect(Map<String,Long> map) {
        map.put(DB.METRICS_DATA_WRITE,metricsDataWrite.getAndSet(0));
        map.put(DB.METRICS_RECORD_WRITE,metricsRecordWrite.getAndSet(0));
        map.put(DB.METRICS_DATA_READ,metricsDataRead.getAndSet(0));
        map.put(DB.METRICS_RECORD_READ,metricsRecordRead.getAndSet(0));

        long cacheHit = 0;
        long cacheMiss = 0;
        if(caches!=null) {
            for (Cache c : caches) {
                cacheHit += c.metricsCacheHit();
                cacheMiss += c.metricsCacheMiss();
            }
        }

        map.put(DB.METRICS_CACHE_HIT,cacheHit);
        map.put(DB.METRICS_CACHE_MISS, cacheMiss);
    }


    public static abstract class Cache {

        protected final Lock lock;
        protected long cacheHitCounter = 0;
        protected long cacheMissCounter = 0;

        protected static final Object NULL = new Object();

        public Cache(boolean disableLocks) {
            this.lock = disableLocks?null:  new ReentrantLock(CC.FAIR_LOCKS);
        }


        public abstract Object get(long recid);
        public abstract void put(long recid, Object item);

        public abstract void clear();
        public abstract void close();

        public abstract Cache newCacheForOtherSegment();


        public long metricsCacheHit() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try {
                long ret = cacheHitCounter;
                cacheHitCounter=0;
                return ret;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }



        public long metricsCacheMiss() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try {
                long ret = cacheMissCounter;
                cacheMissCounter=0;
                return ret;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }


        public static final class HashTable extends Cache {


            protected final long[] recids; 
            protected final Object[] items;

            protected final int cacheMaxSizeMask;


            public HashTable(int cacheMaxSize, boolean disableLocks) {
                super(disableLocks);
                cacheMaxSize = DataIO.nextPowTwo(cacheMaxSize); 

                this.cacheMaxSizeMask = cacheMaxSize-1;

                this.recids = new long[cacheMaxSize];
                this.items = new Object[cacheMaxSize];
            }

            @Override
            public Object get(long recid) {
                int pos = pos(recid);
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try {
                    boolean hit = recids[pos] == recid;
                    if(hit){
                        if(CC.METRICS_CACHE)
                            cacheHitCounter++;
                        return items[pos];
                    }else{
                        if(CC.METRICS_CACHE)
                            cacheMissCounter++;
                        return null;
                    }
                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            @Override
            public void put(long recid, Object item) {
                if(item == null)
                    item = NULL;
                int pos = pos(recid);
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try {
                    recids[pos] = recid;
                    items[pos] = item;
                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            protected int pos(long recid) {
                return DataIO.longHash(recid)&cacheMaxSizeMask;
            }

            @Override
            public void clear() {
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try {
                    Arrays.fill(recids, 0L);
                    Arrays.fill(items, null);
                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            @Override
            public void close() {
                clear();
            }

            @Override
            public Cache newCacheForOtherSegment() {
                return new HashTable(recids.length,lock==null);
            }

        }



    public static class WeakSoftRef extends Store.Cache {


        protected interface CacheItem{
            long getRecid();
            Object get();
            void clear();
        }

        protected static final class CacheWeakItem<A> extends WeakReference<A> implements CacheItem {

            final long recid;

            public CacheWeakItem(A referent, ReferenceQueue<A> q, long recid) {
                super(referent, q);
                this.recid = recid;
            }

            @Override
            public long getRecid() {
                return recid;
            }
        }

        protected static final class CacheSoftItem<A> extends SoftReference<A> implements CacheItem {

            final long recid;

            public CacheSoftItem(A referent, ReferenceQueue<A> q, long recid) {
                super(referent, q);
                this.recid = recid;
            }

            @Override
            public long getRecid() {
                return recid;
            }
        }

        protected ReferenceQueue<Object> queue = new ReferenceQueue<Object>();

        protected LongObjectMap<CacheItem> items = new LongObjectMap<CacheItem>();

        protected final static int CHECK_EVERY_N = 0xFFFF;
        protected int counter = 0;
        protected final ScheduledExecutorService executor;

        protected final boolean useWeakRef;
        protected final long executorScheduledRate;

        public WeakSoftRef(boolean useWeakRef, boolean disableLocks,
                           ScheduledExecutorService executor,
                           long executorScheduledRate) {
            super(disableLocks);
            if(CC.ASSERT && disableLocks && executor!=null) {
                throw new IllegalArgumentException("Lock can not be disabled with executor enabled");
            }
            this.useWeakRef = useWeakRef;
            this.executor = executor;
            this.executorScheduledRate = executorScheduledRate;
            if(executor!=null){
                executor.scheduleAtFixedRate(new Runnable() {
                    @Override
                    public void run() {
                        WeakSoftRef.this.flushGCedLocked();
                    }
                    },
                    (long) (executorScheduledRate*Math.random()),
                    executorScheduledRate,
                    TimeUnit.MILLISECONDS);
            }
        }


        @Override
        public Object get(long recid) {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                CacheItem item = items.get(recid);
                Object ret;
                if(item==null){
                    if(CC.METRICS_CACHE)
                        cacheMissCounter++;
                    ret = null;
                }else{
                    if(CC.METRICS_CACHE)
                        cacheHitCounter++;
                    ret = item.get();
                }

                if (executor==null && (((counter++) & CHECK_EVERY_N) == 0)) {
                    flushGCed();
                }
                return ret;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public void put(long recid, Object item) {
            if(item ==null)
                item = Cache.NULL;
            CacheItem cacheItem = useWeakRef?
                    new CacheWeakItem(item,queue,recid):
                    new CacheSoftItem(item,queue,recid);
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                CacheItem older = items.put(recid,cacheItem);
                if(older!=null)
                    older.clear();
                if (executor==null && (((counter++) & CHECK_EVERY_N) == 0)) {
                    flushGCed();
                }
            }finally {
                if(lock!=null)
                    lock.unlock();
            }

        }

        @Override
        public void clear() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                items.clear(); 
            }finally {
                if(lock!=null)
                    lock.unlock();
            }

        }

        @Override
        public void close() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{

                items.clear();
                items = null;
                flushGCed();
                queue = null;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public Cache newCacheForOtherSegment() {
            return new Cache.WeakSoftRef(
                    useWeakRef,
                    lock==null,
                    executor,
                    executorScheduledRate);
        }

        protected void flushGCed() {
            if(CC.ASSERT && lock!=null &&
                    (lock instanceof ReentrantLock) &&
                    !((ReentrantLock)lock).isHeldByCurrentThread()) {
                throw new AssertionError("Not locked by current thread");
            }
            counter = 1;
            CacheItem item = (CacheItem) queue.poll();
            while(item!=null){
                long recid = item.getRecid();

                CacheItem otherEntry = items.get(recid);
                if(otherEntry !=null && otherEntry.get()==null)
                    items.remove(recid);

                item = (CacheItem) queue.poll();
            }
        }


        protected void flushGCedLocked() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                flushGCed();
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

    }


    public static final class HardRef extends  Store.Cache{

        protected final static int CHECK_EVERY_N = 0xFFFF;

        protected int counter;

        protected final Store.LongObjectMap cache;

        protected final int initialCapacity;

        protected final ScheduledExecutorService executor;
        protected final long executorPeriod;


        public HardRef(int initialCapacity, boolean disableLocks, ScheduledExecutorService executor, long executorPeriod) {
            super(disableLocks);
            if(disableLocks && executor!=null)
                throw new IllegalArgumentException("Executor can not be enabled with lock disabled");
            
            this.initialCapacity = initialCapacity;
            cache = new Store.LongObjectMap(initialCapacity);
            this.executor = executor;
            this.executorPeriod = executorPeriod;
            if(executor!=null){
                executor.scheduleAtFixedRate(new Runnable() {
                    @Override
                    public void run() {
                        Lock lock = HardRef.this.lock;
                        lock.lock();
                        try {
                            checkFreeMem();
                        }finally {
                            lock.unlock();
                        }
                    }
                },executorPeriod,executorPeriod,TimeUnit.MILLISECONDS);
            }
        }


        private void checkFreeMem() {
            counter=1;
            Runtime r = Runtime.getRuntime();
            long max = r.maxMemory();
            if(max == Long.MAX_VALUE)
                return;

            double free = r.freeMemory();
            double total = r.totalMemory();


            free = free + (max-total);

            if(CC.LOG_EWRAP && LOG.isLoggable(Level.FINE))
                LOG.fine("HardRefCache: freemem = " +free + " = "+(free/max)+"%");

            if(free<1e7 || free*4 <max){
                cache.clear();
                if(CC.LOG_EWRAP && LOG.isLoggable(Level.FINE))
                    LOG.fine("Clear HardRef cache");
            }
        }

        @Override
        public Object get(long recid) {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try {
                if (executor==null && ((counter++) & CHECK_EVERY_N) == 0) {
                    checkFreeMem();
                }
                Object item = cache.get(recid);

                if(CC.METRICS_CACHE){
                    if(item!=null){
                        cacheHitCounter++;
                    }else{
                        cacheMissCounter++;
                    }
                }

                return item;
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public void put(long recid, Object item) {
            if(item == null)
                item = Cache.NULL;
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try {
                if (executor==null && ((counter++) & CHECK_EVERY_N) == 0) {
                    checkFreeMem();
                }
                cache.put(recid,item);
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public void clear() {
            Lock lock = this.lock;
            if(lock!=null)
                lock.lock();
            try{
                cache.clear();
            }finally {
                if(lock!=null)
                    lock.unlock();
            }
        }

        @Override
        public void close() {
            clear();
        }

        @Override
        public Cache newCacheForOtherSegment() {
            return new HardRef(initialCapacity,lock==null,executor,executorPeriod);
        }
    }

        public static final class LRU extends Cache {

            protected final int cacheSize;


            protected final LinkedHashMap<Long, Object> items = new LinkedHashMap<Long,Object>();

            public LRU(int cacheSize, boolean disableLocks) {
                super(disableLocks);
                this.cacheSize = cacheSize;
            }

            @Override
            public Object get(long recid) {
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try{
                    Object ret =  items.get(recid);
                    if(CC.METRICS_CACHE){
                        if(ret!=null){
                            cacheHitCounter++;
                        }else{
                            cacheMissCounter++;
                        }
                    }
                    return ret;

                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            @Override
            public void put(long recid, Object item) {
                if(item == null)
                    item = Cache.NULL;

                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try{
                    items.put(recid,item);


                    int itemsSize = items.size();
                    if(itemsSize>cacheSize) {
                        Iterator iter = items.entrySet().iterator();
                        while(itemsSize-- > cacheSize && iter.hasNext()){
                            iter.next();
                            iter.remove();
                        }
                    }

                }finally {
                    if(lock!=null)
                        lock.unlock();
                }

            }

            @Override
            public void clear() {
                Lock lock = this.lock;
                if(lock!=null)
                    lock.lock();
                try{
                    items.clear();
                }finally {
                    if(lock!=null)
                        lock.unlock();
                }
            }

            @Override
            public void close() {
                clear();
            }

            @Override
            public Cache newCacheForOtherSegment() {
                return new LRU(cacheSize,lock==null);
            }
        }
    }




    public static final class LongLongMap {

        int size;

        int maxSize;

        long[] table;

        public LongLongMap(){
            this(32);
        }

        public LongLongMap(int initCapacity) {
            initCapacity = DataIO.nextPowTwo(initCapacity)*2;
            table = new long[initCapacity];
        }


        public long get(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return table[index + 1];
            } else {

                return 0;
            }
        }

        public long put(long key, long value) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            if(CC.ASSERT && value==0)
                throw new IllegalArgumentException("zero val");

            int index = insert(key, value);
            if (index < 0) {

                return 0;
            } else {

                long[] tab = table;
                long prevValue = tab[index + 1];
                tab[index + 1] = value;
                return prevValue;
            }
        }

        int insert(long key, long value) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            long[] tab = table;
            int capacityMask, index;
            long cur;
            keyAbsent:
            if ((cur = tab[index = DataIO.longHash(key) & (capacityMask = tab.length - 2)]) != 0) {
                if (cur == key) {

                    return index;
                } else {
                    while (true) {
                        if ((cur = tab[(index = (index - 2) & capacityMask)]) == 0) {
                            break keyAbsent;
                        } else if (cur == key) {

                            return index;
                        }
                    }
                }
            }

            tab[index] = key;
            tab[index + 1] = value;


            if (++size > maxSize) {
                int capacity = table.length >> 1;
                if (!isMaxCapacity(capacity)) {
                    rehash(capacity << 1);
                }
            }


            return -1;
        }

        int index(long key) {
            if (key != 0) {
                long[] tab = table;
                int capacityMask, index;
                long cur;
                if ((cur = tab[index = DataIO.longHash(key) & (capacityMask = tab.length - 2)]) == key) {

                    return index;
                } else {
                    if (cur == 0) {

                        return -1;
                    } else {
                        while (true) {
                            if ((cur = tab[(index = (index - 2) & capacityMask)]) == key) {

                                return index;
                            } else if (cur == 0) {

                                return -1;
                            }
                        }
                    }
                }
            } else {

                return -1;
            }
        }

        public int size(){
            return size;
        }

        public void clear() {
            size = 0;
            Arrays.fill(table,0);
        }


        void rehash(int newCapacity) {
            long[] tab = table;
            if(CC.ASSERT && !((newCapacity & (newCapacity - 1)) == 0)) 
                throw new AssertionError();
            maxSize = maxSize(newCapacity);
            table = new long[newCapacity * 2];

            long[] newTab = table;
            int capacityMask = newTab.length - 2;
            for (int i = tab.length - 2; i >= 0; i -= 2) {
                long key;
                if ((key = tab[i]) != 0) {
                    int index;
                    if (newTab[index = DataIO.longHash(key) & capacityMask] != 0) {
                        while (true) {
                            if (newTab[(index = (index - 2) & capacityMask)] == 0) {
                                break;
                            }
                        }
                    }
                    newTab[index] = key;
                    newTab[index + 1] = tab[i + 1];
                }
            }
        }

        static int maxSize(int capacity) {


            return !isMaxCapacity(capacity) ?
                    capacity/2 
                    : capacity - 1;
        }

        private static final int MAX_INT_CAPACITY = 1 << 30;

        private static boolean isMaxCapacity(int capacity) {
            int maxCapacity = MAX_INT_CAPACITY;
            maxCapacity >>= 1;
            return capacity == maxCapacity;
        }


        public LongLongMap clone(){
            LongLongMap ret = new LongLongMap();
            ret.maxSize = maxSize;
            ret.size = size;
            ret.table = table.clone();
            return ret;
        }

        public boolean putIfAbsent(long key, long value) {
            if(get(key)==0){
                put(key,value);
                return true;
            }else{
                return false;
            }
        }
    }



    public static final class LongObjectMap<V> {

        int size;

        int maxSize;

        long[] set;
        Object[] values;

        public LongObjectMap(){
            this(32);
        }

        public LongObjectMap(int initCapacity) {
            initCapacity = DataIO.nextPowTwo(initCapacity);
            set = new long[initCapacity];
            values = (V[]) new Object[initCapacity];
        }

        public V get(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return (V) values[index];
            } else {

                return null;
            }
        }

        int index(long key) {
            if (key != 0) {
                long[] keys = set;
                int capacityMask, index;
                long cur;
                if ((cur = keys[index = DataIO.longHash(key) & (capacityMask = keys.length - 1)]) == key) {

                    return index;
                } else {
                    if (cur == 0) {

                        return -1;
                    } else {
                        while (true) {
                            if ((cur = keys[(index = (index - 1) & capacityMask)]) == key) {

                                return index;
                            } else if (cur == 0) {

                                return -1;
                            }
                        }
                    }
                }
            } else {

                return -1;
            }
        }

        public V put(long key, V value) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = insert(key, value);
            if (index < 0) {

                return null;
            } else {

                Object[] vals = values;
                V prevValue = (V) vals[index];
                vals[index] = value;
                return prevValue;
            }
        }

        int insert(long key, V value) {
            long[] keys = set;
            int capacityMask, index;
            long cur;
            keyAbsent:
            if ((cur = keys[index = DataIO.longHash(key) & (capacityMask = keys.length - 1)]) != 0) {
                if (cur == key) {

                    return index;
                } else {
                    while (true) {
                        if ((cur = keys[(index = (index - 1) & capacityMask)]) == 0) {
                            break keyAbsent;
                        } else if (cur == key) {

                            return index;
                        }
                    }
                }
            }


            keys[index] = key;
            values[index] = value;
            postInsertHook();
            return -1;
        }

        void postInsertHook() {
            if (++size > maxSize) {

                int capacity = set.length;
                if (!LongLongMap.isMaxCapacity(capacity)) {
                    rehash(capacity << 1);
                }
            }
        }


        void rehash(int newCapacity) {
            long[] keys = set;
            Object[] vals = values;

            maxSize = LongLongMap.maxSize(newCapacity);
            set = new long[newCapacity];
            values = new Object[newCapacity];

            long[] newKeys = set;
            int capacityMask = newKeys.length - 1;
            Object[] newVals = values;
            for (int i = keys.length - 1; i >= 0; i--) {
                long key;
                if ((key = keys[i]) != 0) {
                    int index;
                    if (newKeys[index = DataIO.longHash(key) & capacityMask] != 0) {
                        while (true) {
                            if (newKeys[(index = (index - 1) & capacityMask)] == 0) {
                                break;
                            }
                        }
                    }
                    newKeys[index] = key;
                    newVals[index] = vals[i];
                }
            }
        }


        public void clear() {
            size = 0;
            Arrays.fill(set,0);
            Arrays.fill(values,null);
        }

        public V remove(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");
            long[] keys = set;
            int capacityMask = keys.length - 1;
            int index;
            long cur;
            keyPresent:
            if ((cur = keys[index = DataIO.longHash(key) & capacityMask]) != key) {
                if (cur == 0) {

                    return null;
                } else {
                    while (true) {
                        if ((cur = keys[(index = (index - 1) & capacityMask)]) == key) {
                            break keyPresent;
                        } else if (cur == 0) {

                            return null;
                        }
                    }
                }
            }

            Object[] vals = values;
            V val = (V) vals[index];

            int indexToRemove = index;
            int indexToShift = indexToRemove;
            int shiftDistance = 1;
            while (true) {
                indexToShift = (indexToShift - 1) & capacityMask;
                long keyToShift;
                if ((keyToShift = keys[indexToShift]) == 0) {
                    break;
                }
                if (((DataIO.longHash(keyToShift) - indexToShift) & capacityMask) >= shiftDistance) {
                    keys[indexToRemove] = keyToShift;
                    vals[indexToRemove] = vals[indexToShift];
                    indexToRemove = indexToShift;
                    shiftDistance = 1;
                } else {
                    shiftDistance++;
                    if (indexToShift == 1 + index) {
                        throw new java.util.ConcurrentModificationException();
                    }
                }
            }
            keys[indexToRemove] = 0;
            vals[indexToRemove] = null;


            size--;

            return val;
        }

        public boolean putIfAbsent(long key, V value) {
            if(get(key)==null){
                put(key,value);
                return true;
            }else{
                return false;
            }
        }
    }




    public static final Lock NOLOCK = new Lock(){

        @Override
        public void lock() {
        }

        @Override
        public void lockInterruptibly() throws InterruptedException {
        }

        @Override
        public boolean tryLock() {
            return true;
        }

        @Override
        public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {
            return true;
        }

        @Override
        public void unlock() {
        }

        @Override
        public Condition newCondition() {
            throw new UnsupportedOperationException();
        }
    };


    public static final class ReadWriteSingleLock implements ReadWriteLock{

        protected final Lock lock;

        public ReadWriteSingleLock(Lock lock) {
            this.lock = lock;
        }


        @Override
        public Lock readLock() {
            return lock;
        }

        @Override
        public Lock writeLock() {
            return lock;
        }
    }


    public static final class MemoryBarrierLessLock implements Lock{

        final static int WAIT_NANOS = 100;

        final protected AtomicLong lockedThread = new AtomicLong(Long.MAX_VALUE); 

        @Override
        public void lock() {
            long hash = Thread.currentThread().hashCode();
            while(!lockedThread.compareAndSet(Long.MAX_VALUE,hash)){
                LockSupport.parkNanos(WAIT_NANOS);
            }
        }

        @Override
        public void lockInterruptibly() throws InterruptedException {
            Thread currThread = Thread.currentThread();
            long hash = currThread.hashCode();
            while(!lockedThread.compareAndSet(Long.MAX_VALUE,hash)){
                LockSupport.parkNanos(WAIT_NANOS);
                if(currThread.isInterrupted())
                    throw new InterruptedException();
            }
        }

        @Override
        public boolean tryLock() {
            long hash = Thread.currentThread().hashCode();
            return lockedThread.compareAndSet(Long.MAX_VALUE, hash);
        }

        @Override
        public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {
            long hash = Thread.currentThread().hashCode();
            long time2 = unit.toNanos(time);
            while(!lockedThread.compareAndSet(Long.MAX_VALUE,hash) && time2>0){
                LockSupport.parkNanos(WAIT_NANOS);
                time2-=WAIT_NANOS;
            }
            return time2>0;
        }

        @Override
        public void unlock() {
            long hash = Thread.currentThread().hashCode();
            if(!lockedThread.compareAndSet(hash,Long.MAX_VALUE)){
                throw new IllegalMonitorStateException("Can not unlock, current thread does not hold this lock");
            }
        }

        @Override
        public Condition newCondition() {
            throw new UnsupportedOperationException();
        }
    }


    public static final class LongObjectObjectMap<V1,V2> {

        int size;

        int maxSize;

        long[] set;
        Object[] values;

        public LongObjectObjectMap(){
            this(32);
        }

        public LongObjectObjectMap(int initCapacity) {
            initCapacity = DataIO.nextPowTwo(initCapacity);
            set = new long[initCapacity];
            values =  new Object[initCapacity*2];
        }

        public int get(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return index;
            } else {

                return -1;
            }
        }


        public V1 get1(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return (V1) values[index*2];
            } else {

                return null;
            }
        }

        public V2 get2(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = index(key);
            if (index >= 0) {

                return (V2) values[index*2+1];
            } else {

                return null;
            }
        }


        int index(long key) {
            if (key != 0) {
                long[] keys = set;
                int capacityMask, index;
                long cur;
                if ((cur = keys[index = DataIO.longHash(key) & (capacityMask = keys.length - 1)]) == key) {

                    return index;
                } else {
                    if (cur == 0) {

                        return -1;
                    } else {
                        while (true) {
                            if ((cur = keys[(index = (index - 1) & capacityMask)]) == key) {

                                return index;
                            } else if (cur == 0) {

                                return -1;
                            }
                        }
                    }
                }
            } else {

                return -1;
            }
        }

        public int put(long key, V1 val1, V2 val2) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");

            int index = insert(key, val1,val2);
            if (index < 0) {

                return -1;
            } else {

                Object[] vals = values;
                vals[index*2] = val1;
                vals[index*2+1] = val2;
                return index;
            }
        }

        int insert(long key, V1 val1, V2 val2) {
            long[] keys = set;
            int capacityMask, index;
            long cur;
            keyAbsent:
            if ((cur = keys[index = DataIO.longHash(key) & (capacityMask = keys.length - 1)]) != 0) {
                if (cur == key) {

                    return index;
                } else {
                    while (true) {
                        if ((cur = keys[(index = (index - 1) & capacityMask)]) == 0) {
                            break keyAbsent;
                        } else if (cur == key) {

                            return index;
                        }
                    }
                }
            }


            keys[index] = key;
            index*=2;
            values[index] = val1;
            values[index+1] = val2;
            postInsertHook();
            return -1;
        }

        void postInsertHook() {
            if (++size > maxSize) {

                int capacity = set.length;
                if (!LongLongMap.isMaxCapacity(capacity)) {
                    rehash(capacity << 1);
                }
            }
        }


        void rehash(int newCapacity) {
            long[] keys = set;
            Object[] vals = values;

            maxSize = LongLongMap.maxSize(newCapacity);
            set = new long[newCapacity];
            values = new Object[newCapacity*2];

            long[] newKeys = set;
            int capacityMask = newKeys.length - 1;
            Object[] newVals = values;
            for (int i = keys.length - 1; i >= 0; i--) {
                long key;
                if ((key = keys[i]) != 0) {
                    int index;
                    if (newKeys[index = DataIO.longHash(key) & capacityMask] != 0) {
                        while (true) {
                            if (newKeys[(index = (index - 1) & capacityMask)] == 0) {
                                break;
                            }
                        }
                    }
                    newKeys[index] = key;
                    newVals[index*2] = vals[i*2];
                    newVals[index*2+1] = vals[i*2+1];
                }
            }
        }


        public void clear() {
            size = 0;
            Arrays.fill(set,0);
            Arrays.fill(values,null);
        }

        public int  remove(long key) {
            if(CC.ASSERT && key==0)
                throw new IllegalArgumentException("zero key");
            long[] keys = set;
            int capacityMask = keys.length - 1;
            int index;
            long cur;
            keyPresent:
            if ((cur = keys[index = DataIO.longHash(key) & capacityMask]) != key) {
                if (cur == 0) {

                    return -1;
                } else {
                    while (true) {
                        if ((cur = keys[(index = (index - 1) & capacityMask)]) == key) {
                            break keyPresent;
                        } else if (cur == 0) {

                            return -1;
                        }
                    }
                }
            }

            Object[] vals = values;
            int val = index;

            int indexToRemove = index;
            int indexToShift = indexToRemove;
            int shiftDistance = 1;
            while (true) {
                indexToShift = (indexToShift - 1) & capacityMask;
                long keyToShift;
                if ((keyToShift = keys[indexToShift]) == 0) {
                    break;
                }
                if (((DataIO.longHash(keyToShift) - indexToShift) & capacityMask) >= shiftDistance) {
                    keys[indexToRemove] = keyToShift;
                    vals[indexToRemove] = vals[indexToShift];
                    indexToRemove = indexToShift;
                    shiftDistance = 1;
                } else {
                    shiftDistance++;
                    if (indexToShift == 1 + index) {
                        throw new java.util.ConcurrentModificationException();
                    }
                }
            }
            keys[indexToRemove] = 0;
            indexToRemove*=2;
            vals[indexToRemove] = null;
            vals[indexToRemove+1] = null;


            size--;

            return val;
        }

    }

    @Override
    public Engine getWrappedEngine() {
        return null;
    }


    @Override
    public boolean canSnapshot() {
        return snapshotEnable;
    }

    protected final long longParitySet(long value) {
        return checksum?
                DataIO.parity16Set(value << 16):
                DataIO.parity1Set(value<<1);
    }

    protected final long longParityGet(long value) {
        return checksum?
                DataIO.parity16Get(value)>>>16:
                DataIO.parity1Get(value)>>>1;
    }


}

<code block>
package org.mapdb;

import org.junit.Test;

import java.io.File;
import java.io.IOError;
import java.io.IOException;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

import static org.junit.Assert.*;
import static org.mapdb.DataIO.*;
import static org.mapdb.StoreDirect.*;

public class StoreDirectTest2 {


    @Test public void store_create(){
        StoreDirect st = newStore();
        assertArrayEquals(new long[]{0},st.indexPages);
        st.structuralLock.lock();
        assertEquals(st.headChecksum(st.vol), st.vol.getInt(StoreDirect.HEAD_CHECKSUM));
        assertEquals(parity16Set(st.PAGE_SIZE), st.vol.getLong(StoreDirect.STORE_SIZE));
        assertEquals(parity16Set(0), st.vol.getLong(StoreDirect.HEAD_END)); 
        assertEquals(parity1Set(st.RECID_LAST_RESERVED * 8), st.vol.getLong(StoreDirect.MAX_RECID_OFFSET));
    }

    @Test public void constants(){
        assertEquals(0,(StoreDirect.MAX_REC_SIZE+1)%16);
    }

    @Test public void preallocate1(){
        StoreDirect st = newStore();
        long recid = st.preallocate();
        assertEquals(Engine.RECID_FIRST,recid);
        assertEquals(st.composeIndexVal(0,0,true,true,true),st.vol.getLong(st.recidToOffset(recid)));
        assertEquals(parity1Set(8 * Engine.RECID_FIRST), st.vol.getLong(st.MAX_RECID_OFFSET));
    }


    @Test public void preallocate_M(){
        StoreDirect st = newStore();
        for(long i=0;i<1e6;i++) {
            long recid = st.preallocate();
            assertEquals(Engine.RECID_FIRST+i, recid);
            assertEquals(st.composeIndexVal(0, 0, true, true, true), st.vol.getLong(st.recidToOffset(recid)));
            assertEquals(parity1Set(8 * (Engine.RECID_FIRST + i)), st.vol.getLong(st.MAX_RECID_OFFSET));
        }
    }

    protected StoreDirect newStore() {
        StoreDirect st =  new StoreDirect(null);
        st.init();
        return st;
    }

    @Test public void round16Up__(){
        assertEquals(0, round16Up(0));
        assertEquals(16, round16Up(1));
        assertEquals(16, round16Up(15));
        assertEquals(16, round16Up(16));
        assertEquals(32, round16Up(17));
        assertEquals(32, round16Up(31));
        assertEquals(32, round16Up(32));
    }



    @Test public void reopen_after_insert(){
        final Volume vol = new Volume.ByteArrayVol(CC.VOLUME_PAGE_SHIFT);

        Volume.VolumeFactory fab = new Volume.VolumeFactory() {
            @Override
            public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {
                return vol;
            }
        };
        StoreDirect st = new StoreDirect(null, fab, null, CC.DEFAULT_LOCK_SCALE, 0, false, false,null, false,false,  0,false,0, null);
        st.init();

        Map<Long,String> recids = new HashMap();
        for(long i=0;i<1e6;i++){
            String val = "adskasldaksld "+i;
            long recid = st.put(val,Serializer.STRING);
            recids.put(recid,val);
        }


        st.commit();

        st = new StoreDirect(null, fab, null, CC.DEFAULT_LOCK_SCALE, 0, false, false,null, false, false, 0,false,0, null);
        st.init();

        for(Map.Entry<Long,String> e:recids.entrySet()){
            assertEquals(e.getValue(), st.get(e.getKey(),Serializer.STRING));
        }
    }

    @Test
    public void linked_allocate_two(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int recSize = 100000;
        long[] bufs = st.freeDataTake(recSize);

        assertEquals(2,bufs.length);
        assertEquals(MAX_REC_SIZE, bufs[0]>>>48);
        assertEquals(PAGE_SIZE, bufs[0]&MOFFSET);
        assertEquals(MLINKED,bufs[0]&MLINKED);

        assertEquals(recSize-MAX_REC_SIZE+8, bufs[1]>>>48);
        assertEquals(st.PAGE_SIZE + round16Up(MAX_REC_SIZE), bufs[1]&MOFFSET);
        assertEquals(0, bufs[1] & MLINKED);
    }

    @Test
    public void linked_allocate_three(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int recSize = 140000;
        long[] bufs = st.freeDataTake(recSize);

        assertEquals(3,bufs.length);
        assertEquals(MAX_REC_SIZE, bufs[0]>>>48);
        assertEquals(PAGE_SIZE, bufs[0]&MOFFSET);
        assertEquals(MLINKED,bufs[0]&MLINKED);

        assertEquals(MAX_REC_SIZE, bufs[1]>>>48);
        assertEquals(st.PAGE_SIZE + round16Up(MAX_REC_SIZE), bufs[1]&MOFFSET);
        assertEquals(MLINKED, bufs[1] & MLINKED);

        assertEquals(recSize-2*MAX_REC_SIZE+2*8, bufs[2]>>>48);
        assertEquals(st.PAGE_SIZE + 2*round16Up(MAX_REC_SIZE), bufs[2]&MOFFSET);
        assertEquals(0, bufs[2] & MLINKED);
    }

    DataOutputByteArray newBuf(int size){
        DataOutputByteArray ret = new DataOutputByteArray();
        for(int i=0;i<size;i++){
            try {
                ret.writeByte(i%255);
            } catch (IOException e) {
                throw new IOError(e);
            }
        }
        return ret;
    }

    @Test public void put_data_single(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int totalSize = round16Up(1000);
        long o = st.freeDataTakeSingle(totalSize)&MOFFSET;


        long recid = RECID_FIRST;
        long[] offsets = {19L << 48 | o};
        st.locks[st.lockPos(recid)].writeLock().lock();
        st.putData(recid,offsets,newBuf(19).buf,19);


        assertEquals(19L << 48 | o | MARCHIVE, st.indexValGet(recid));

        for(int i=0;i<totalSize;i++){
            int b = st.vol.getUnsignedByte(o+i);
            assertEquals(i<19?i:0,b);
        }
    }

    @Test public void put_data_double(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int totalSize = round16Up(1000);
        long o = st.freeDataTakeSingle(totalSize)&MOFFSET;


        long recid = RECID_FIRST;
        long[] offsets = {
                19L << 48 | o | MLINKED,
                100L <<48 | o+round16Up(19)
        };
        st.locks[st.lockPos(recid)].writeLock().lock();
        int bufSize = 19+100-8;
        st.putData(recid,offsets,newBuf(bufSize).buf,bufSize);


        assertEquals(19L << 48 | o | MLINKED | MARCHIVE, st.indexValGet(recid));

        assertEquals((100L)<<48 | o+round16Up(19) , parity3Get(st.vol.getLong(o)));


        for(int i=0;i<19-8;i++){
            int b = st.vol.getUnsignedByte(o+8+i);
            assertEquals(i,b);
        }
        for(int i=19-8;i<19+100-8;i++){
            int b = st.vol.getUnsignedByte(o+round16Up(19)+i-19+8);
            assertEquals(i,b);
        }

    }

    @Test public void put_data_triple(){
        StoreDirect st = newStore();
        st.structuralLock.lock();
        int totalSize = round16Up(1000);
        long o = st.freeDataTakeSingle(totalSize)&MOFFSET;


        long recid = RECID_FIRST;
        long[] offsets = {
                101L << 48 | o | MLINKED,
                102L <<48 | o+round16Up(101) | MLINKED,
                103L <<48 | o+round16Up(101)+round16Up(102)

        };
        st.locks[st.lockPos(recid)].writeLock().lock();
        int bufSize = 101+102+103-2*8;
        st.putData(recid,offsets,newBuf(bufSize).buf,bufSize);


        assertEquals(101L << 48 | o | MLINKED | MARCHIVE, st.indexValGet(recid));
        assertEquals(102L<<48 | o+round16Up(101) | MLINKED , parity3Get(st.vol.getLong(o)));

        assertEquals(103L<<48 | o+round16Up(101)+round16Up(102) , parity3Get(st.vol.getLong(o+round16Up(101))));


        for(int i=0;i<101-8;i++){
            int b = st.vol.getUnsignedByte(o+8+i);
            assertEquals(i,b);
        }
        for(int i=0;i<102-8;i++){
            int b = st.vol.getUnsignedByte(o+round16Up(101)+8+i);
            assertEquals(i+101-8,b);
        }

        for(int i=0;i<103-16;i++){
            int b = st.vol.getUnsignedByte(o+round16Up(101)+round16Up(102)+i);
            assertEquals((i+101+102-2*8)%255,b);
        }

    }

    @Test public void zero_index_page_checksum() throws IOException {
        File f = File.createTempFile("mapdb", "mapdb");
        StoreDirect st = (StoreDirect) DBMaker.fileDB(f)
                .transactionDisable()
                .checksumEnable()
                .mmapFileEnableIfSupported()
                .makeEngine();


        verifyIndexPageChecksum(st);

        st.commit();
        st.close();
        st = (StoreDirect) DBMaker.fileDB(f)
                .transactionDisable()
                .checksumEnable()
                .mmapFileEnableIfSupported()
                .makeEngine();

        for(int i=0;i<2e6;i++){
            st.put(i,Serializer.INTEGER);
        }

        verifyIndexPageChecksum(st);

        st.commit();
        st.close();

        st = (StoreDirect) DBMaker.fileDB(f)
                .transactionDisable()
                .checksumEnable()
                .mmapFileEnableIfSupported()
                .makeEngine();

        verifyIndexPageChecksum(st);

        st.close();
    }

    protected void verifyIndexPageChecksum(StoreDirect st) {
        assertTrue(st.checksum);

        for(long offset=HEAD_END+8;offset+10<=PAGE_SIZE;offset+=10){
            long indexVal = st.vol.getLong(offset);
            int check = st.vol.getUnsignedShort(offset+8);
            if(indexVal==0){
                assertEquals(0,check);
                continue; 
            }
            assertEquals(check, DataIO.longHash(indexVal)&0xFFFF);
        }


        for(long page:st.indexPages){
            if(page==0)
                continue;

            for(long offset=page+8;offset+10<=page+PAGE_SIZE;offset+=10){
                long indexVal = st.vol.getLong(offset);
                int check = st.vol.getUnsignedShort(offset+8);
                if(indexVal==0){
                    assertEquals(0,check);
                    continue; 
                }
                assertEquals(check, DataIO.longHash(indexVal)&0xFFFF);
            }
        }
    }

    @Test public void recidToOffset(){
        StoreDirect st = (StoreDirect) DBMaker.memoryDB()
                .transactionDisable()
                .makeEngine();


        st.indexPages = new long[]{0, PAGE_SIZE*10, PAGE_SIZE*20, PAGE_SIZE*30, PAGE_SIZE*40};

        Set<Long> m = new HashSet<Long>();
        for(long offset=HEAD_END+8;offset<PAGE_SIZE;offset+=8){
            m.add(offset);
        }

        for(long page=PAGE_SIZE*10;page<=PAGE_SIZE*40; page+=PAGE_SIZE*10){
            for(long offset=page+8;offset<page+PAGE_SIZE;offset+=8){
                m.add(offset);
            }
        }

        long maxRecid = PAGE_SIZE-8-HEAD_END + 4*PAGE_SIZE-4*8;

        assertEquals(0,maxRecid%8);
        maxRecid/=8;


        for(long recid=1;recid<=maxRecid;recid++){
            long offset = st.recidToOffset(recid);
            assertTrue(""+recid + " - "+offset+" - "+(offset%PAGE_SIZE),
                    m.remove(offset));
        }
        assertTrue(m.isEmpty());
    }

    @Test public void recidToOffset_with_checksum(){
        StoreDirect st = (StoreDirect) DBMaker.memoryDB()
                .transactionDisable()
                .checksumEnable()
                .makeEngine();


        st.indexPages = new long[]{0, PAGE_SIZE*10, PAGE_SIZE*20, PAGE_SIZE*30, PAGE_SIZE*40};

        Set<Long> m = new HashSet<Long>();
        for(long offset=HEAD_END+8;offset<=PAGE_SIZE-10;offset+=10){
            m.add(offset);
        }

        for(long page=PAGE_SIZE*10;page<=PAGE_SIZE*40; page+=PAGE_SIZE*10){
            for(long offset=page+8;offset<=page+PAGE_SIZE-10;offset+=10){
                m.add(offset);
            }
        }

        long maxRecid = (PAGE_SIZE-8-HEAD_END)/10 + 4*((PAGE_SIZE-8)/10);



        for(long recid=1;recid<=maxRecid;recid++){
            long offset = st.recidToOffset(recid);
            assertTrue("" + recid + " - " + offset + " - " + (offset % PAGE_SIZE)+ " - " + (offset - PAGE_SIZE),
                    m.remove(offset));
        }
        assertTrue(m.isEmpty());
    }

}
<code block>
package org.mapdb;

import org.junit.Test;

import java.io.IOException;
import java.nio.ByteBuffer;

import static org.junit.Assert.*;
import static org.mapdb.DataIO.*;

public class DataIOTest {

    @Test public void parity1() {
        assertEquals(Long.parseLong("1", 2), parity1Set(0));
        assertEquals(Long.parseLong("10", 2), parity1Set(2));
        assertEquals(Long.parseLong("111", 2), parity1Set(Long.parseLong("110", 2)));
        assertEquals(Long.parseLong("1110", 2), parity1Set(Long.parseLong("1110", 2)));
        assertEquals(Long.parseLong("1011", 2), parity1Set(Long.parseLong("1010", 2)));
        assertEquals(Long.parseLong("11111", 2), parity1Set(Long.parseLong("11110", 2)));

        assertEquals(0, parity1Get(Long.parseLong("1", 2)));
        try {
            parity1Get(Long.parseLong("0", 2));
            fail();
        }catch(DBException.PointerChecksumBroken e){

        }
        try {
            parity1Get(Long.parseLong("110", 2));
            fail();
        }catch(DBException.PointerChecksumBroken e){

        }
    }

    @Test
    public void testPackLongBidi() throws Exception {
        DataOutputByteArray b = new DataOutputByteArray();

        long max = (long) 1e14;
        for(long i=0;i<max;i=i+1 +i/100000){
            b.pos=0;
            long size = packLongBidi(b,i);
            assertTrue(i>100000 || size<6);
            assertEquals(b.pos,size);
            assertEquals(i | (size<<56), unpackLongBidi(b.buf,0));
            assertEquals(i | (size<<56), unpackLongBidiReverse(b.buf, (int) size));
        }
    }

    @Test public void parityBasic(){
        for(long i=0;i<Integer.MAX_VALUE;i+= 1 + i/1000000L){
            if(i%2==0)
                assertEquals(i, parity1Get(parity1Set(i)));
            if(i%8==0)
                assertEquals(i, parity3Get(parity3Set(i)));
            if(i%16==0)
                assertEquals(i, parity4Get(parity4Set(i)));
            if((i&0xFFFF)==0)
                assertEquals(i, parity16Get(parity16Set(i)));
        }
    }

    @Test public void testSixLong(){
        byte[] b = new byte[8];
        for(long i=0;i>>>48==0;i=i+1+i/10000){
            DataIO.putSixLong(b,2,i);
            assertEquals(i, DataIO.getSixLong(b,2));
        }
    }

    @Test public void testNextPowTwo(){
        assertEquals(1, DataIO.nextPowTwo(1));
        assertEquals(2, DataIO.nextPowTwo(2));
        assertEquals(4, DataIO.nextPowTwo(3));
        assertEquals(4, DataIO.nextPowTwo(4));

        assertEquals(64, DataIO.nextPowTwo(33));
        assertEquals(64, DataIO.nextPowTwo(61));

        assertEquals(1024, DataIO.nextPowTwo(777));
        assertEquals(1024, DataIO.nextPowTwo(1024));

        assertEquals(1073741824, DataIO.nextPowTwo(1073741824-100));
        assertEquals(1073741824, DataIO.nextPowTwo((int) (1073741824*0.7)));
        assertEquals(1073741824, DataIO.nextPowTwo(1073741824));
    }

    @Test public void testNextPowTwo2(){
        for(int i=1;i<1073750016;i+= 1 + i/100000){
            int pow = nextPowTwo(i);
            assertTrue(pow>=i);
            assertTrue(Integer.bitCount(pow)==1);

        }
    }

    @Test public void packLongCompat() throws IOException {
        DataOutputByteArray b = new DataOutputByteArray();
        b.packLong(2111L);
        b.packLong(100);
        b.packLong(1111L);

        DataInputByteArray b2 = new DataInputByteArray(b.buf);
        assertEquals(2111L, b2.unpackLong());
        assertEquals(100L, b2.unpackLong());
        assertEquals(1111L, b2.unpackLong());

        DataInputByteBuffer b3 = new DataInputByteBuffer(ByteBuffer.wrap(b.buf),0);
        assertEquals(2111L, b3.unpackLong());
        assertEquals(100L, b3.unpackLong());
        assertEquals(1111L, b3.unpackLong());
    }

    @Test public void packIntCompat() throws IOException {
        DataOutputByteArray b = new DataOutputByteArray();
        b.packInt(2111);
        b.packInt(100);
        b.packInt(1111);

        DataInputByteArray b2 = new DataInputByteArray(b.buf);
        assertEquals(2111, b2.unpackInt());
        assertEquals(100, b2.unpackInt());
        assertEquals(1111, b2.unpackInt());

        DataInputByteBuffer b3 = new DataInputByteBuffer(ByteBuffer.wrap(b.buf),0);
        assertEquals(2111, b3.unpackInt());
        assertEquals(100, b3.unpackInt());
        assertEquals(1111, b3.unpackInt());
    }


    @Test public void testHexaConversion(){
        byte[] b = new byte[]{11,112,11,0,39,90};
        assertTrue(Serializer.BYTE_ARRAY.equals(b, DataIO.fromHexa(DataIO.toHexa(b))));
    }

    @Test public void packLong() throws IOException {
        DataInputByteArray in = new DataInputByteArray(new byte[20]);
        DataOutputByteArray out = new DataOutputByteArray();
        out.buf = in.buf;
        for (long i = 0; i >0; i = i + 1 + i / 10000) {
            in.pos = 10;
            out.pos = 10;

            DataIO.packLong(out,i);
            long i2 = DataIO.unpackLong(in);

            assertEquals(i,i2);
            assertEquals(in.pos,out.pos);
        }

    }
}
<code block>
package org.mapdb;

import org.junit.Test;

import java.io.File;
import java.io.IOException;
import java.util.Random;
import java.util.concurrent.Callable;
import java.util.concurrent.atomic.AtomicReference;

import static org.junit.Assert.*;

public class VolumeTest {

    public static final Fun.Function1<Volume,String>[] VOL_FABS = new Fun.Function1[] {

                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.ByteArrayVol(CC.VOLUME_PAGE_SHIFT);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.SingleByteArrayVol((int) 4e7);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.MemoryVol(true, CC.VOLUME_PAGE_SHIFT);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.MemoryVol(false, CC.VOLUME_PAGE_SHIFT);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return Volume.UNSAFE_VOL_FACTORY.makeVolume(null, false, CC.VOLUME_PAGE_SHIFT, 0, false);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.FileChannelVol(new File(file), false, CC.VOLUME_PAGE_SHIFT);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.RandomAccessFileVol(new File(file), false);
                        }
                    },
                    new Fun.Function1<Volume,String>() {
                        @Override
                        public Volume run(String file) {
                            return new Volume.MappedFileVol(new File(file), false, CC.VOLUME_PAGE_SHIFT);
                        }
                    }
    };

    @Test
    public void all() throws Throwable {
        System.out.println("Run volume tests. Free space: "+File.createTempFile("mapdb","mapdb").getFreeSpace());


        for (Fun.Function1<Volume,String> fab1 : VOL_FABS) {

            Volume v = fab1.run(UtilsTest.tempDbFile().getPath());
            System.out.println(" "+v);
            testPackLongBidi(v);
            testPackLong(v);
            v.close();
            v=null;

            putGetOverlap(fab1.run(UtilsTest.tempDbFile().getPath()), 100, 1000);
            putGetOverlap(fab1.run(UtilsTest.tempDbFile().getPath()), StoreDirect.PAGE_SIZE - 500, 1000);
            putGetOverlap(fab1.run(UtilsTest.tempDbFile().getPath()), (long) 2e7 + 2000, (int) 1e7);
            putGetOverlapUnalligned(fab1.run(UtilsTest.tempDbFile().getPath()));

            for (Fun.Function1<Volume,String> fab2 : VOL_FABS) try{
                long_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                long_six_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                long_pack_bidi(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                long_pack(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                int_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                byte_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                unsignedShort_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
                unsignedByte_compatible(fab1.run(UtilsTest.tempDbFile().getPath()), fab2.run(UtilsTest.tempDbFile().getPath()));
            }catch(Throwable e){
                System.err.println("test failed: \n"+
                        fab1.run(UtilsTest.tempDbFile().getPath()).getClass().getName()+"\n"+
                        fab2.run(UtilsTest.tempDbFile().getPath()).getClass().getName());
                throw e;
            }
        }
    }

    void unsignedShort_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (int i =Character.MIN_VALUE;i<=Character.MAX_VALUE; i++) {
            v1.putUnsignedShort(7,i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getUnsignedShort(7));
        }

        v1.close();
        v2.close();
    }


    void unsignedByte_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (int i =0;i<=255; i++) {
            v1.putUnsignedByte(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getUnsignedByte(7));
        }

        v1.close();
        v2.close();
    }


    void testPackLongBidi(Volume v) throws Exception {
        v.ensureAvailable(10000);

        long max = (long) 1e14;
        for (long i = 0; i < max; i = i + 1 + i / 1000) {
            v.clear(0, 20);
            long size = v.putLongPackBidi(10, i);
            assertTrue(i > 100000 || size < 6);

            assertEquals(i | (size << 56), v.getLongPackBidi(10));
            assertEquals(i | (size << 56), v.getLongPackBidiReverse(10 + size));
        }
    }


    void testPackLong(Volume v) throws Exception {
        v.ensureAvailable(10000);

        for (long i = 0; i < DataIO.PACK_LONG_RESULT_MASK; i = i + 1 + i / 1000) {
            v.clear(0, 20);
            long size = v.putPackedLong(10,i);
            assertTrue(i > 100000 || size < 6);

            assertEquals(i | (size << 60), v.getPackedLong(10));
        }
    }

    void long_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (long i : new long[]{1L, 2L, Integer.MAX_VALUE, Integer.MIN_VALUE, Long.MAX_VALUE, Long.MIN_VALUE,
                -1, 0x982e923e8989229L, -2338998239922323233L,
                0xFFF8FFL, -0xFFF8FFL, 0xFFL, -0xFFL,
                0xFFFFFFFFFF0000L, -0xFFFFFFFFFF0000L}) {
            v1.putLong(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getLong(7));
        }

        v1.close();
        v2.close();
    }


    void long_pack_bidi(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[9];

        for (long i = 0; i > 0; i = i + 1 + i / 1000) {
            v1.putLongPackBidi(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getLongPackBidi(7));
        }

        v1.close();
        v2.close();
    }

    void long_pack(Volume v1, Volume v2) {
        v1.ensureAvailable(21);
        v2.ensureAvailable(20);
        byte[] b = new byte[12];

        for (long i = 0; i <DataIO.PACK_LONG_RESULT_MASK; i = i + 1 + i / 1000) {
            long len = v1.putPackedLong(7, i);
            v1.getData(7, b, 0, 12);
            v2.putData(7, b, 0, 12);
            assertTrue(len<=10);
            assertEquals((len << 60) | i, v2.getPackedLong(7));
        }

        v1.close();
        v2.close();
    }


    void long_six_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[9];

        for (long i = 0; i >> 48 == 0; i = i + 1 + i / 1000) {
            v1.putSixLong(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getSixLong(7));
        }

        v1.close();
        v2.close();
    }

    void int_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (int i : new int[]{1, 2, Integer.MAX_VALUE, Integer.MIN_VALUE,
                -1, 0x982e9229, -233899233,
                0xFFF8FF, -0xFFF8FF, 0xFF, -0xFF,
                0xFFFF000, -0xFFFFF00}) {
            v1.putInt(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getInt(7));
        }

        v1.close();
        v2.close();
    }


    void byte_compatible(Volume v1, Volume v2) {
        v1.ensureAvailable(16);
        v2.ensureAvailable(16);
        byte[] b = new byte[8];

        for (byte i = Byte.MIN_VALUE; i < Byte.MAX_VALUE - 1; i++) {
            v1.putByte(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getByte(7));
        }


        for (int i = 0; i < 256; i++) {
            v1.putUnsignedByte(7, i);
            v1.getData(7, b, 0, 8);
            v2.putData(7, b, 0, 8);
            assertEquals(i, v2.getUnsignedByte(7));
        }


        v1.close();
        v2.close();
    }


    void putGetOverlap(Volume vol, long offset, int size) throws IOException {
        byte[] b = UtilsTest.randomByteArray(size);

        vol.ensureAvailable(offset+size);
        vol.putDataOverlap(offset, b, 0, b.length);

        byte[] b2 = new byte[size];
        vol.getDataInputOverlap(offset, size).readFully(b2, 0, size);

        assertTrue(Serializer.BYTE_ARRAY.equals(b, b2));
        vol.close();
    }



    void putGetOverlapUnalligned(Volume vol) throws IOException {
        int size = (int) 1e7;
        long offset = (long) (2e6 + 2000);
        vol.ensureAvailable(offset+size);

        byte[] b = UtilsTest.randomByteArray(size);

        byte[] b2 = new byte[size + 2000];

        System.arraycopy(b, 0, b2, 1000, size);

        vol.putDataOverlap(offset, b2, 1000, size);

        byte[] b3 = new byte[size + 200];
        vol.getDataInputOverlap(offset, size).readFully(b3, 100, size);


        for (int i = 0; i < size; i++) {
            assertEquals(b2[i + 1000], b3[i + 100]);
        }
        vol.close();
    }



}

<code block>
package org.mapdb;


import org.junit.Ignore;
import org.junit.Test;

import java.io.File;
import java.io.IOError;
import java.io.IOException;
import java.util.*;
import java.util.concurrent.locks.Lock;

import static org.junit.Assert.*;
import static org.mapdb.StoreDirect.*;

@SuppressWarnings({"rawtypes","unchecked"})
public class StoreDirectTest <E extends StoreDirect> extends EngineTest<E>{

    @Override boolean canRollback(){return false;}

    File f = UtilsTest.tempDbFile();




    @Override protected E openEngine() {
        StoreDirect e =new StoreDirect(f.getPath());
        e.init();
        return (E)e;
    }




































































































































































































    @Test public void test_index_record_delete_and_reuse_large_COMPACT(){
        e = openEngine();
        final long MAX = 10;

        List<Long> recids= new ArrayList<Long>();
        for(int i = 0;i<MAX;i++){
            recids.add(e.put(0L, Serializer.LONG));
        }

        for(long recid:recids){
            e.delete(recid,Serializer.LONG);
        }


        e.commit();
        e.compact();


        List<Long> recids2= new ArrayList<Long>();
        for(int i = 0;i<MAX;i++){
            recids2.add(e.put(0L, Serializer.LONG));
        }


        Collections.reverse(recids);
        assertEquals(recids, recids2);
    }














    @Test public void test_phys_record_reused_COMPACT(){
        e = openEngine();
        final long recid = e.put(1L, Serializer.LONG);
        assertEquals((Long)1L, e.get(recid, Serializer.LONG));

        e.delete(recid, Serializer.LONG);
        e.commit();
        e.compact();
        final long recid2 = e.put(1L, Serializer.LONG);
        assertEquals((Long)1L, e.get(recid2, Serializer.LONG));
        e.commit();
        assertEquals((Long)1L, e.get(recid2, Serializer.LONG));
        assertEquals(recid, recid2);

        long indexVal = e.indexValGet(recid);
        assertEquals(8L, indexVal>>>48); 
        assertEquals(e.PAGE_SIZE,
                indexVal&MOFFSET); 
        assertEquals(0, indexVal & StoreDirect.MLINKED);
        assertEquals(0, indexVal & StoreDirect.MUNUSED);
        assertNotEquals(0, indexVal & StoreDirect.MARCHIVE);
        e.close();
    }
















    @Test public void test_long_stack_puts_record_offset_into_index() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 1,false);
        e.commit();
        assertEquals(8 + 2,
                e.headVol.getLong(FREE_RECID_STACK)>>>48);

    }

    @Test public void test_long_stack_put_take() throws IOException {
        e = openEngine();
        e.structuralLock.lock();

        final long max = 150;
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
        }

        for(long i = max-1;i>0;i--){
            assertEquals(i, e.longStackTake(FREE_RECID_STACK,false));
        }

        assertEquals(0, getLongStack(FREE_RECID_STACK).size());

    }

    protected List<Long> getLongStack(long masterLinkOffset) {
        List<Long> ret = new ArrayList<Long>();
        for(long v = e.longStackTake(masterLinkOffset,false); v!=0; v=e.longStackTake(masterLinkOffset,false)){
            ret.add(v);
        }
        return ret;
    }

    @Test public void test_long_stack_put_take_simple() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        assertEquals(111L, e.longStackTake(FREE_RECID_STACK,false));
    }


    @Test public void test_basic_long_stack() throws IOException {
        e = openEngine();

        e.structuralLock.lock();
        final long max = 150;
        ArrayList<Long> list = new ArrayList<Long>();
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
            list.add(i);
        }

        Collections.reverse(list);
        e.commit();

        assertEquals(list, getLongStack(FREE_RECID_STACK));
    }

    @Test public void test_large_long_stack() throws IOException {
        e = openEngine();

        e.structuralLock.lock();
        final long max = 15000;
        ArrayList<Long> list = new ArrayList<Long>();
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
            list.add(i);
        }

        Collections.reverse(list);
        e.commit();

        assertEquals(list, getLongStack(FREE_RECID_STACK));
    }

    @Test public void test_basic_long_stack_no_commit() throws IOException {
        e = openEngine();

        e.structuralLock.lock();
        final long max = 150;
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
        }

        for(long i =max-1;i>=1;i--){
            assertEquals(i, e.longStackTake(FREE_RECID_STACK,false));
        }
    }

    @Test public void test_large_long_stack_no_commit() throws IOException {
        e = openEngine();

        e.structuralLock.lock();
        final long max = 15000;
        for(long i=1;i<max;i++){
            e.longStackPut(FREE_RECID_STACK, i,false);
        }


        for(long i =max-1;i>=1;i--){
            assertEquals(i, e.longStackTake(FREE_RECID_STACK,false));
        }
    }



    @Test public void long_stack_page_created_after_put() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        e.commit();

        if(e instanceof StoreWAL){

            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
        }

        long pageId = e.vol.getLong(FREE_RECID_STACK);
        assertEquals(8+2, pageId>>>48);
        pageId = pageId & StoreDirect.MOFFSET;
        assertEquals(PAGE_SIZE, pageId);
        assertEquals(CHUNKSIZE, DataIO.parity4Get(e.vol.getLong(pageId))>>>48);
        assertEquals(0, DataIO.parity4Get(e.vol.getLong(pageId))&MOFFSET);
        assertEquals(DataIO.parity1Set(111<<1), e.vol.getLongPackBidi(pageId + 8)&DataIO.PACK_LONG_RESULT_MASK);
    }

    @Test public void long_stack_put_five() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        e.longStackPut(FREE_RECID_STACK, 112,false);
        e.longStackPut(FREE_RECID_STACK, 113,false);
        e.longStackPut(FREE_RECID_STACK, 114,false);
        e.longStackPut(FREE_RECID_STACK, 115,false);

        e.commit();
        if(e instanceof  StoreWAL){
            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
        }
        long pageId = e.vol.getLong(FREE_RECID_STACK);
        long currPageSize = pageId>>>48;
        pageId = pageId & StoreDirect.MOFFSET;
        assertEquals(PAGE_SIZE, pageId);
        assertEquals(CHUNKSIZE, e.vol.getLong(pageId)>>>48);
        assertEquals(0, e.vol.getLong(pageId)&MOFFSET); 
        long offset = pageId + 8;
        for(int i=111;i<=115;i++){
            long val = e.vol.getLongPackBidi(offset);
            assertEquals(i, DataIO.parity1Get(val & DataIO.PACK_LONG_RESULT_MASK)>>>1);
            offset += val >>> 56;
        }
        assertEquals(currPageSize, offset-pageId);
    }

    @Test public void long_stack_page_deleted_after_take() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        e.commit();
        if(e instanceof  StoreWAL){
            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
            ((StoreWAL)e).walStartNextFile();
        }

        assertEquals(111L, e.longStackTake(FREE_RECID_STACK,false));
        e.commit();
        if(e instanceof  StoreWAL){
            ((StoreWAL)e).replayWAL();
            clearEverything();
            ((StoreWAL)e).walStartNextFile();
        }

        assertEquals(0L, DataIO.parity1Get(e.headVol.getLong(FREE_RECID_STACK)));
    }

    @Test public void long_stack_page_deleted_after_take2() throws IOException {
        e = openEngine();
        e.structuralLock.lock();
        e.longStackPut(FREE_RECID_STACK, 111,false);
        e.commit();

        assertEquals(111L, e.longStackTake(FREE_RECID_STACK,false));
        e.commit();
        if(e instanceof  StoreWAL){
            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
        }

        assertEquals(0L, DataIO.parity1Get(e.headVol.getLong(FREE_RECID_STACK)));
    }



    @Test public void long_stack_page_overflow() throws IOException {
        e = openEngine();
        e.structuralLock.lock();


        int actualChunkSize = 8;
        for(int i=0;;i++){
            long val = 1000L+i;
            e.longStackPut(FREE_RECID_STACK, val ,false);
            actualChunkSize += DataIO.packLongBidi(new byte[8],0,val<<1);
            if(e.headVol.getLong(FREE_RECID_STACK)>>48 >CHUNKSIZE-10)
                break;
        }
        e.commit();
        if(e instanceof  StoreWAL){

            e.commitLock.lock();
            e.structuralLock.lock();
            ((StoreWAL)e).replayWAL();
            clearEverything();
            ((StoreWAL)e).walStartNextFile();
        }


        long pageId = e.headVol.getLong(FREE_RECID_STACK);
        assertEquals(actualChunkSize, pageId>>>48);
        pageId = pageId & StoreDirect.MOFFSET;
        assertEquals(PAGE_SIZE, pageId);
        assertEquals(StoreDirect.CHUNKSIZE, e.vol.getLong(pageId)>>>48);
        for(long i=1000,pos=8;;i++){
            long val = e.vol.getLongPackBidi(pageId+pos);
            assertEquals(i, DataIO.parity1Get(val&DataIO.PACK_LONG_RESULT_MASK)>>>1);
            pos+=val>>>56;
            if(pos==actualChunkSize){
                break;
            }
        }


        e.longStackPut(FREE_RECID_STACK, 11L,false);
        e.commit();
        if(e instanceof  StoreWAL){
            ((StoreWAL)e).replayWAL();
            clearEverything();
            ((StoreWAL)e).walStartNextFile();
        }


        pageId = e.headVol.getLong(FREE_RECID_STACK);
        assertEquals(8+2, pageId>>>48);
        pageId = pageId & StoreDirect.MOFFSET;
        assertEquals(PAGE_SIZE + StoreDirect.CHUNKSIZE, pageId);
        assertEquals(PAGE_SIZE, DataIO.parity4Get(e.vol.getLong(pageId)) & StoreDirect.MOFFSET); 
        assertEquals(CHUNKSIZE, e.vol.getLong(pageId)>>>48); 

        assertEquals(11L, DataIO.parity1Get(e.vol.getLongPackBidi(pageId+8)&DataIO.PACK_LONG_RESULT_MASK)>>>1);


        for(long offset = pageId+8+2;offset<pageId+CHUNKSIZE;offset++){
            assertEquals(0,e.vol.getByte(offset));
        }
    }


    @Test public void test_constants(){
        assertTrue(StoreDirect.CHUNKSIZE%16==0);
        
    }


    @Test public void delete_files_after_close(){
        File f = UtilsTest.tempDbFile();
        File phys = new File(f.getPath());

        DB db = DBMaker.fileDB(f).transactionDisable().deleteFilesAfterClose().make();

        db.hashMap("test").put("aa","bb");
        db.commit();
        assertTrue(f.exists());
        assertTrue(phys.exists());
        db.close();
        assertFalse(f.exists());
        assertFalse(new File(f+".0.wal").exists());
        assertFalse(phys.exists());
    }

    @Test @Ignore 
    public void freeSpaceWorks(){
        long oldFree = e.getFreeSize();
        long recid = e.put(new byte[10000],Serializer.BYTE_ARRAY_NOSIZE);
        e.commit();
        assertEquals(oldFree, e.getFreeSize());
        e.delete(recid,Serializer.BYTE_ARRAY_NOSIZE);
        assertEquals(oldFree+10000,e.getFreeSize());
        e.commit();
        assertEquals(oldFree+10000,e.getFreeSize());
    }


    @Test public void prealloc(){
        e = openEngine();
        long recid = e.preallocate();
        assertNull(e.get(recid,UtilsTest.FAIL));
        e.commit();
        assertNull(e.get(recid,UtilsTest.FAIL));
    }

    @Ignore 
    @Test public void header_index_inc() throws IOException {
        e.put(new byte[10000],Serializer.BYTE_ARRAY_NOSIZE);
        e.commit();
        e.close();


        Volume v = Volume.FileChannelVol.FACTORY.makeVolume(f.getPath(), true);
        v.putUnsignedShort(4,StoreDirect.STORE_VERSION+1);
        v.sync();
        v.close();

        try{
            e = openEngine();
            fail();
        }catch(IOError e){
            Throwable e2 = e;
            while (e2 instanceof IOError){
                e2 = e2.getCause();
            }
            assertTrue(e2.getMessage().contains("version"));
        }
    }

    @Test @Ignore 
    public void header_phys_inc() throws IOException {
        e.put(new byte[10000],Serializer.BYTE_ARRAY_NOSIZE);
        e.commit();
        e.close();


        File phys = new File(f.getPath());
        Volume v = Volume.FileChannelVol.FACTORY.makeVolume(phys.getPath(), true);
        v.putUnsignedShort(4,StoreDirect.STORE_VERSION+1);
        v.sync();
        v.close();

        try{
            e = openEngine();
            fail();
        }catch(IOError e){
            Throwable e2 = e;
            while (e2 instanceof IOError){
                e2 = e2.getCause();
            }
            assertTrue(e2.getMessage().contains("version"));
        }
    }


    protected void clearEverything(){
        StoreWAL wal = (StoreWAL)e;

        for (int segment = 0; segment < wal.locks.length; segment++) {
            Lock lock = wal.locks[segment].writeLock();
            lock.lock();
            try {
                wal.writeCache[segment].clear();
            } finally {
                lock.unlock();
            }
        }

        wal.structuralLock.lock();
        try {
            wal.dirtyStackPages.clear();


            byte[] b = new byte[(int) HEAD_END];

            wal.headVolBackup.getData(0,b,0,b.length);
            wal.headVol.putData(0,b,0,b.length);

            wal.indexPages = wal.indexPagesBackup.clone();
            wal.pageLongStack.clear();
        } finally {
            wal.structuralLock.unlock();
        }

    }


    @Test public void compact_keeps_volume_type(){
        for(final Fun.Function1<Volume,String> fab : VolumeTest.VOL_FABS){
            Volume.VolumeFactory fac = new Volume.VolumeFactory() {
                @Override
                public Volume makeVolume(String file, boolean readOnly, int sliceShift, long initSize, boolean fixedSize) {
                    return fab.run(file);
                }
            };

            File f = UtilsTest.tempDbFile();
            e = (E) new StoreDirect(f.getPath(), fac,
                    null,
                    CC.DEFAULT_LOCK_SCALE,
                    0,
                    false,false,null,
                    false,false,0,
                    false,0,
                    null);
            e.init();



            Map<Long, String> data = new LinkedHashMap();
            for(int i=0;i<1000;i++){
                String ss = UtilsTest.randomString(1000);
                long recid = e.put(ss,Serializer.STRING);
            }


            Volume vol = e.vol;
            e.commit();
            e.compact();

            assertEquals(vol.getClass(), e.vol.getClass());
            if(e.vol.getFile()!=null)
                assertEquals(f, e.vol.getFile());

            for(Long recid:data.keySet()){
                assertEquals(data.get(recid), e.get(recid, Serializer.STRING));
            }
            e.close();
            f.delete();
        }
    }

}
